{
  "repo": "pydantic/pydantic",
  "scraped_at": "2026-02-03T10:36:32.917848",
  "stats": {
    "total_comments": 375,
    "filtered": {
      "not_python": 105,
      "too_short": 74,
      "no_diff_hunk": 10,
      "too_long": 4
    },
    "kept": 182
  },
  "examples": [
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12494,
      "file_path": "tests/test_json_schema.py",
      "line": 7198,
      "side": "RIGHT",
      "diff_hunk": "@@ -7193,3 +7193,25 @@ def test_union_format_primitive_type_array_deduplicated() -> None:\n             ]\n         )\n     ) == {'anyOf': [{'type': 'integer'}, {'type': 'string'}, {'type': 'string', 'maxLength': 1}]}\n+\n+\n+def test_nested_model_deduplication():",
      "comment": "```suggestion\r\ndef test_nested_model_deduplication() -> None:\r\n    \"\"\"https://github.com/pydantic/pydantic/issues/12492\"\"\"\r\n\r\n```",
      "comment_id": 2502696314,
      "user": "Viicos",
      "created_at": "2025-11-07T10:36:26Z",
      "url": "https://github.com/pydantic/pydantic/pull/12494#discussion_r2502696314"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12741,
      "file_path": "tests/test_dataclasses.py",
      "line": 3308,
      "side": "RIGHT",
      "diff_hunk": "@@ -3282,3 +3282,27 @@ class Foo:\n     assert ta.dump_json(Foo(foo='bar', bar=1)).decode('utf-8') == '{\"bar\":1}'\n     assert ta.dump_json(Foo(foo='bar', bar=1), exclude={'bar'}).decode('utf-8') == '{}'\n     assert ta.dump_json(Foo(foo='bar', bar=2)).decode('utf-8') == '{}'\n+\n+\n+@pytest.mark.skipif(sys.version_info < (3, 10), reason='kw_only is not available in python < 3.10')\n+@pytest.mark.parametrize('class_kw_only', [True, False], ids=['class_kw=True', 'class_kw=False'])\n+@pytest.mark.parametrize('field_kw_only', [True, False], ids=['field_kw=True', 'field_kw=False'])\n+def test_dataclass_field_override_kw_only(class_kw_only, field_kw_only) -> None:\n+    \"\"\"\n+    Verifies that pydantic.Field(kw_only=...) is able to correctly\n+        override class-level kw_only\n+    \"\"\"\n+\n+    @pydantic.dataclasses.dataclass(kw_only=class_kw_only)\n+    class Foo:\n+        a: int = Field(kw_only=field_kw_only)\n+\n+    sig = str(inspect.signature(Foo))\n+    if (field_kw_only) or (class_kw_only and field_kw_only is None):\n+        with pytest.raises(ValidationError):\n+            Foo(1)\n+\n+        assert re.match(r'\\(\\*,.+', sig)\n+\n+    else:\n+        assert re.match(r'\\([^\\*]+', sig)",
      "comment": "```suggestion\r\n@pytest.mark.skipif(sys.version_info < (3, 10), reason='kw_only is not available in python >= 3.10')\r\ndef test_dataclass_field_override_kw_only() -> None:\r\n    \"\"\"https://github.com/pydantic/pydantic/issues/12736\"\"\"\r\n\r\n    @pydantic.dataclasses.dataclass(kw_only=True)\r\n    class Foo:\r\n        a: int = Field(kw_only=False)\r\n\r\n    a_param = inspect.signature(Foo).parameters['a']\r\n\r\n    assert a_param.kind is inspect.Parameter.POSITIONAL_OR_KEYWORD\r\n    assert a_param.default is inspect.Parameter.empty\r\n```",
      "comment_id": 2726927326,
      "user": "Viicos",
      "created_at": "2026-01-26T09:41:26Z",
      "url": "https://github.com/pydantic/pydantic/pull/12741#discussion_r2726927326"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12712,
      "file_path": "tests/test_pickle.py",
      "line": 328,
      "side": "RIGHT",
      "diff_hunk": "@@ -318,3 +321,51 @@ def test_pickle_model_with_config(model_type: type, use_cloudpickle: bool):\n         model_type = pickle.loads(pickle.dumps(model_type))\n \n     assert model_type.model_config['title'] == 'MyTitle'\n+\n+\n+@pytest.mark.skipif(\n+    sys.version_info[:2] != (3, 14),\n+    reason='Pickle data generated on 3.14',",
      "comment": "Rather than hard-coding, could potentially use `multiprocessing` to produce a pickle bytes, to unpickle in the current process?",
      "comment_id": 2701057019,
      "user": "davidhewitt",
      "created_at": "2026-01-17T12:38:30Z",
      "url": "https://github.com/pydantic/pydantic/pull/12712#discussion_r2701057019"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12712,
      "file_path": "tests/test_pickle.py",
      "line": 328,
      "side": "RIGHT",
      "diff_hunk": "@@ -318,3 +321,51 @@ def test_pickle_model_with_config(model_type: type, use_cloudpickle: bool):\n         model_type = pickle.loads(pickle.dumps(model_type))\n \n     assert model_type.model_config['title'] == 'MyTitle'\n+\n+\n+@pytest.mark.skipif(\n+    sys.version_info[:2] != (3, 14),\n+    reason='Pickle data generated on 3.14',",
      "comment": "It doesn't pickle it properly, that's why I went with this option.\r\n\r\n```python\r\nfrom multiprocessing import Process, Manager\r\n\r\nimport cloudpickle\r\n\r\nfrom pydantic import BaseModel\r\n\r\n\r\nclass Foo(BaseModel):\r\n    foo: int\r\n\r\n\r\nclass Bar(BaseModel):\r\n    bar1: Foo\r\n    bar2: Foo\r\n\r\n\r\ndef bar_repr() -> str:\r\n    json = '{\"bar1\": {\"foo\": 1}, \"bar2\": {\"foo\": 2}}'\r\n    bar = Bar.model_validate_json(json)\r\n    return repr(bar)\r\n\r\n\r\ndef create_pickled(return_dict):\r\n    pickled = cloudpickle.dumps(bar_repr)\r\n    return_dict['return'] = pickled\r\n\r\ndef test_tmp():\r\n    manager = Manager()\r\n    return_dict = manager.dict()\r\n\r\n    p = Process(target=create_pickled, args=(return_dict,))\r\n    p.start()\r\n    p.join()\r\n\r\n    print(return_dict)\r\n    #> {'return': b'\\x80\\x05\\x95\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x8c\\x11tests.test_pickle\\x94\\x8c\\x08bar_repr\\x94\\x93\\x94.'}\r\n```",
      "comment_id": 2701209494,
      "user": "Viicos",
      "created_at": "2026-01-17T15:05:24Z",
      "url": "https://github.com/pydantic/pydantic/pull/12712#discussion_r2701209494"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12712,
      "file_path": "tests/test_pickle.py",
      "line": 328,
      "side": "RIGHT",
      "diff_hunk": "@@ -318,3 +321,51 @@ def test_pickle_model_with_config(model_type: type, use_cloudpickle: bool):\n         model_type = pickle.loads(pickle.dumps(model_type))\n \n     assert model_type.model_config['title'] == 'MyTitle'\n+\n+\n+@pytest.mark.skipif(\n+    sys.version_info[:2] != (3, 14),\n+    reason='Pickle data generated on 3.14',",
      "comment": "I managed to find a way to make it work with `subprocess`. I've pushed a commit doing so, I also confirmed that the issue reproduces with that approach on the commit before #12689 merged.",
      "comment_id": 2708626832,
      "user": "davidhewitt",
      "created_at": "2026-01-20T14:34:37Z",
      "url": "https://github.com/pydantic/pydantic/pull/12712#discussion_r2708626832"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12712,
      "file_path": "tests/test_pickle.py",
      "line": 328,
      "side": "RIGHT",
      "diff_hunk": "@@ -318,3 +321,51 @@ def test_pickle_model_with_config(model_type: type, use_cloudpickle: bool):\n         model_type = pickle.loads(pickle.dumps(model_type))\n \n     assert model_type.model_config['title'] == 'MyTitle'\n+\n+\n+@pytest.mark.skipif(\n+    sys.version_info[:2] != (3, 14),\n+    reason='Pickle data generated on 3.14',",
      "comment": "Did not want to mess with `subprocess` initially but this looks simple enough",
      "comment_id": 2709332051,
      "user": "Viicos",
      "created_at": "2026-01-20T17:20:34Z",
      "url": "https://github.com/pydantic/pydantic/pull/12712#discussion_r2709332051"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12681,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 322,
      "side": "RIGHT",
      "diff_hunk": "@@ -312,27 +311,27 @@ def collect_model_fields(  # noqa: C901\n                 f\"Unexpected field with name {ann_name!r}; only 'root' is allowed as a field of a `RootModel`\"\n             )\n \n-        # when building a generic model with `MyModel[int]`, the generic_origin check makes sure we don't get\n-        # \"... shadows an attribute\" warnings\n-        generic_origin = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')\n         for base in bases:\n-            dataclass_fields = {\n-                field.name for field in (dataclasses.fields(base) if dataclasses.is_dataclass(base) else ())\n-            }\n             if hasattr(base, ann_name):\n+                if ann_name not in cls_annotations:\n+                    # Don't warn when a field exists in a parent class but has not been defined in the current class\n+                    continue\n+\n+                # when building a generic model with `MyModel[int]`, the generic_origin check makes sure we don't get\n+                # \"... shadows an attribute\" warnings\n+                generic_origin = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')",
      "comment": "I'm surprised this was worth moving to a lower loop level, it's presumably not expensive to evaluate. Should we instead be moving this up to the top level above the loop on line 273?",
      "comment_id": 2697569904,
      "user": "davidhewitt",
      "created_at": "2026-01-16T09:01:57Z",
      "url": "https://github.com/pydantic/pydantic/pull/12681#discussion_r2697569904"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12681,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 329,
      "side": "RIGHT",
      "diff_hunk": "@@ -312,27 +311,27 @@ def collect_model_fields(  # noqa: C901\n                 f\"Unexpected field with name {ann_name!r}; only 'root' is allowed as a field of a `RootModel`\"\n             )\n \n-        # when building a generic model with `MyModel[int]`, the generic_origin check makes sure we don't get\n-        # \"... shadows an attribute\" warnings\n-        generic_origin = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')\n         for base in bases:\n-            dataclass_fields = {\n-                field.name for field in (dataclasses.fields(base) if dataclasses.is_dataclass(base) else ())\n-            }\n             if hasattr(base, ann_name):\n+                if ann_name not in cls_annotations:\n+                    # Don't warn when a field exists in a parent class but has not been defined in the current class\n+                    continue\n+\n+                # when building a generic model with `MyModel[int]`, the generic_origin check makes sure we don't get\n+                # \"... shadows an attribute\" warnings\n+                generic_origin = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')\n                 if base is generic_origin:\n                     # Don't warn when \"shadowing\" of attributes in parametrized generics\n                     continue\n \n+                dataclass_fields = {\n+                    field.name for field in (dataclasses.fields(base) if dataclasses.is_dataclass(base) else ())\n+                }",
      "comment": "Is this worth caching in a function-local dict? We might evaluate this repeatedly for each `(ann_name, base)` pair when really it looks like we only need to ever evaluate this once per base?",
      "comment_id": 2697573727,
      "user": "davidhewitt",
      "created_at": "2026-01-16T09:03:02Z",
      "url": "https://github.com/pydantic/pydantic/pull/12681#discussion_r2697573727"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12681,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 322,
      "side": "RIGHT",
      "diff_hunk": "@@ -312,27 +311,27 @@ def collect_model_fields(  # noqa: C901\n                 f\"Unexpected field with name {ann_name!r}; only 'root' is allowed as a field of a `RootModel`\"\n             )\n \n-        # when building a generic model with `MyModel[int]`, the generic_origin check makes sure we don't get\n-        # \"... shadows an attribute\" warnings\n-        generic_origin = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')\n         for base in bases:\n-            dataclass_fields = {\n-                field.name for field in (dataclasses.fields(base) if dataclasses.is_dataclass(base) else ())\n-            }\n             if hasattr(base, ann_name):\n+                if ann_name not in cls_annotations:\n+                    # Don't warn when a field exists in a parent class but has not been defined in the current class\n+                    continue\n+\n+                # when building a generic model with `MyModel[int]`, the generic_origin check makes sure we don't get\n+                # \"... shadows an attribute\" warnings\n+                generic_origin = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')",
      "comment": "My assumption was that hitting this code path is really uncommon (in fact I'm even wondering if the origin check is possible; it is currently uncovered and I'm not sure there's a case for this).\r\n\r\nWe could move the `generic_origin` fetch up, although I'm pretty sure both would be equivalent.",
      "comment_id": 2703881914,
      "user": "Viicos",
      "created_at": "2026-01-19T09:12:33Z",
      "url": "https://github.com/pydantic/pydantic/pull/12681#discussion_r2703881914"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12681,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 329,
      "side": "RIGHT",
      "diff_hunk": "@@ -312,27 +311,27 @@ def collect_model_fields(  # noqa: C901\n                 f\"Unexpected field with name {ann_name!r}; only 'root' is allowed as a field of a `RootModel`\"\n             )\n \n-        # when building a generic model with `MyModel[int]`, the generic_origin check makes sure we don't get\n-        # \"... shadows an attribute\" warnings\n-        generic_origin = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')\n         for base in bases:\n-            dataclass_fields = {\n-                field.name for field in (dataclasses.fields(base) if dataclasses.is_dataclass(base) else ())\n-            }\n             if hasattr(base, ann_name):\n+                if ann_name not in cls_annotations:\n+                    # Don't warn when a field exists in a parent class but has not been defined in the current class\n+                    continue\n+\n+                # when building a generic model with `MyModel[int]`, the generic_origin check makes sure we don't get\n+                # \"... shadows an attribute\" warnings\n+                generic_origin = getattr(cls, '__pydantic_generic_metadata__', {}).get('origin')\n                 if base is generic_origin:\n                     # Don't warn when \"shadowing\" of attributes in parametrized generics\n                     continue\n \n+                dataclass_fields = {\n+                    field.name for field in (dataclasses.fields(base) if dataclasses.is_dataclass(base) else ())\n+                }",
      "comment": "We could have a local cache of the `dataclass_fields` for each base, so that we can reuse it when we process the other `ann_names`, but hitting this path is really uncommon (see added test), so I don't think we should worry too much.",
      "comment_id": 2703888774,
      "user": "Viicos",
      "created_at": "2026-01-19T09:14:39Z",
      "url": "https://github.com/pydantic/pydantic/pull/12681#discussion_r2703888774"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12689,
      "file_path": "pydantic/_internal/_model_construction.py",
      "line": 602,
      "side": "RIGHT",
      "diff_hunk": "@@ -599,6 +599,7 @@ def complete_model_class(\n     raise_errors: bool = True,\n     call_on_complete_hook: bool = True,\n     create_model_module: str | None = None,\n+    rebuild: bool = False,",
      "comment": "```suggestion\r\n    is_force_rebuild: bool = False,\r\n```",
      "comment_id": 2689585331,
      "user": "Viicos",
      "created_at": "2026-01-14T09:08:20Z",
      "url": "https://github.com/pydantic/pydantic/pull/12689#discussion_r2689585331"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12689,
      "file_path": "pydantic/_internal/_model_construction.py",
      "line": 602,
      "side": "RIGHT",
      "diff_hunk": "@@ -599,6 +599,7 @@ def complete_model_class(\n     raise_errors: bool = True,\n     call_on_complete_hook: bool = True,\n     create_model_module: str | None = None,\n+    rebuild: bool = False,",
      "comment": "Just amended this here (not also in SchemaValidator/PluggableSchemaValidator) since they were not commented on [but let me know if that's the wrong assumption]",
      "comment_id": 2690124736,
      "user": "lmmx",
      "created_at": "2026-01-14T11:47:48Z",
      "url": "https://github.com/pydantic/pydantic/pull/12689#discussion_r2690124736"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12568,
      "file_path": "pydantic-core/tests/serializers/test_functions.py",
      "line": 671,
      "side": "RIGHT",
      "diff_hunk": "@@ -667,7 +668,10 @@ def f(value, handler, _info):\n \n \n @pytest.mark.skipif(\n-    platform.python_implementation() in ('PyPy', 'GraalVM') or sys.platform in {'emscripten', 'win32'},\n+    # Also skip in local, as segfaults may happen on some platforms for Python < 3.14:",
      "comment": "```suggestion\n    # Also skip in local, as segfaults may happen on some platforms for Python < 3.14:\n    # TODO: re-enable locally after https://github.com/pydantic/pydantic/issues/12592\n```",
      "comment_id": 2697658712,
      "user": "davidhewitt",
      "created_at": "2026-01-16T09:25:16Z",
      "url": "https://github.com/pydantic/pydantic/pull/12568#discussion_r2697658712"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12522,
      "file_path": "tests/test_missing_sentinel.py",
      "line": 74,
      "side": "RIGHT",
      "diff_hunk": "@@ -69,3 +69,14 @@ class Model(BaseModel):\n     assert Model.model_json_schema()['properties'] == {\n         'f': {'title': 'F', 'type': 'integer'},\n     }\n+\n+\n+def test_model_construct_with_missing_default_does_not_crash():",
      "comment": "```suggestion\r\ndef test_model_construct_with_missing_default_does_not_crash() -> None:\r\n```",
      "comment_id": 2516006789,
      "user": "Viicos",
      "created_at": "2025-11-11T22:26:45Z",
      "url": "https://github.com/pydantic/pydantic/pull/12522#discussion_r2516006789"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12604,
      "file_path": "tests/types/test_union.py",
      "line": 75,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,75 @@\n+from typing import ClassVar, Literal, TypedDict\n+\n+import pydantic\n+\n+\n+def test_field_serializer_in_nested_union_called_only_twice():\n+    class MyModel(pydantic.BaseModel):\n+        a: int\n+        b: int\n+\n+        field_a_serializer_calls: ClassVar[int] = 0\n+\n+        @pydantic.field_serializer('a')\n+        def serialize_my_field(self, value: int) -> str:\n+            self.__class__.field_a_serializer_calls += 1\n+            return str(value)\n+\n+    class Container(TypedDict):\n+        u: MyModel | int\n+\n+    class Container2(TypedDict):\n+        u: Container | int\n+\n+    value = MyModel(a=1, b=False)\n+    assert value.b is False\n+\n+    ta = pydantic.TypeAdapter(Container2 | int)\n+    ta.dump_json(Container2(u=Container(u=value)), warnings=False)\n+\n+    # Historical implementations of pydantic would call the field serializer many times\n+    # as nested unions were individually attempted with each of strict and lax checking.\n+    #\n+    # 2 comes from:\n+    # - one attempt in strict mode, which fails because of `b=False` as a subclass\n+    # - one attempt in lax mode, which succeeds\n+    assert MyModel.field_a_serializer_calls == 2\n+\n+\n+def test_field_serializer_in_nested_tagged_union_called_only_twice():\n+    class MyModel(pydantic.BaseModel):\n+        type_: Literal['a'] = 'a'\n+\n+        a: int\n+        b: int\n+\n+        field_a_serializer_calls: ClassVar[int] = 0\n+\n+        @pydantic.field_serializer('a')\n+        def serialize_my_field(self, value: int) -> str:\n+            self.__class__.field_a_serializer_calls += 1\n+            return str(value)\n+\n+    class ModelB(pydantic.BaseModel):\n+        type_: Literal['b'] = 'b'\n+\n+    class Container(pydantic.BaseModel):\n+        type_: Literal['a'] = 'a'\n+        u: MyModel | ModelB = pydantic.Field(..., discriminator='type_')\n+\n+    class Container2(pydantic.BaseModel):\n+        u: Container | ModelB = pydantic.Field(..., discriminator='type_')\n+\n+    ta = pydantic.TypeAdapter(Container2 | int)\n+    ta.dump_json(Container2(u=Container(u=MyModel.model_construct(a=1, b=False))), warnings=False)\n+\n+    # Historical implementations of pydantic would call the field serializer many MANY times\n+    # as nested unions were individually attempted with each of strict and lax checking.\n+    #\n+    # 5 comes from:\n+    # - tagged discriminator in outer union at strict mode\n+    # - fall back to left to right in outer union at strict mode\n+    # - tagged discriminator in inner union at strict mode\n+    # - fall back to left to right in inner union still at strict mode\n+    # - tagged discriminator in outer union at lax mode, which calls tagged discriminator in inner union at lax mode, which finally succeeds\n+    assert MyModel.field_a_serializer_calls == 5",
      "comment": "I think we could do better here; when making tagged union serialization fall back to left-to-right we could potentially try all variants except the one which we already attempted (and failed) in the tagged union serialization.\n\ni.e. this should be 2 like above, I think.",
      "comment_id": 2584568651,
      "user": "davidhewitt",
      "created_at": "2025-12-03T10:39:37Z",
      "url": "https://github.com/pydantic/pydantic/pull/12604#discussion_r2584568651"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12627,
      "file_path": "tests/test_type_adapter.py",
      "line": 690,
      "side": "RIGHT",
      "diff_hunk": "@@ -681,3 +681,30 @@ def module_1() -> None:\n \n     with pytest.raises(ValidationError):\n         module_1.ta.validate_python('a')\n+\n+\n+def test_validate_python_with_incorrect_configuration():\n+    ta = TypeAdapter(int)\n+\n+    with pytest.raises(PydanticUserError) as exc_info:\n+        ta.validate_python({'foo': [1, '2']}, by_alias=False, by_name=False)",
      "comment": "```suggestion\r\n        ta.validate_python(1, by_alias=False, by_name=False)\r\n```",
      "comment_id": 2618579209,
      "user": "Viicos",
      "created_at": "2025-12-15T09:10:37Z",
      "url": "https://github.com/pydantic/pydantic/pull/12627#discussion_r2618579209"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12627,
      "file_path": "tests/test_type_adapter.py",
      "line": 699,
      "side": "RIGHT",
      "diff_hunk": "@@ -681,3 +681,30 @@ def module_1() -> None:\n \n     with pytest.raises(ValidationError):\n         module_1.ta.validate_python('a')\n+\n+\n+def test_validate_python_with_incorrect_configuration():\n+    ta = TypeAdapter(int)\n+\n+    with pytest.raises(PydanticUserError) as exc_info:\n+        ta.validate_python({'foo': [1, '2']}, by_alias=False, by_name=False)\n+\n+    assert 'At least one of `by_alias` or `by_name` must be set to True.' in str(exc_info.value)\n+\n+\n+def test_validate_json_with_incorrect_configuration():\n+    ta = TypeAdapter(int)\n+\n+    with pytest.raises(PydanticUserError) as exc_info:\n+        ta.validate_json(json.dumps({'x': '1'}), by_alias=False, by_name=False)",
      "comment": "```suggestion\r\n        ta.validate_json(1, by_alias=False, by_name=False)\r\n```",
      "comment_id": 2618580194,
      "user": "Viicos",
      "created_at": "2025-12-15T09:10:55Z",
      "url": "https://github.com/pydantic/pydantic/pull/12627#discussion_r2618580194"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12627,
      "file_path": "tests/test_type_adapter.py",
      "line": 708,
      "side": "RIGHT",
      "diff_hunk": "@@ -681,3 +681,30 @@ def module_1() -> None:\n \n     with pytest.raises(ValidationError):\n         module_1.ta.validate_python('a')\n+\n+\n+def test_validate_python_with_incorrect_configuration():\n+    ta = TypeAdapter(int)\n+\n+    with pytest.raises(PydanticUserError) as exc_info:\n+        ta.validate_python({'foo': [1, '2']}, by_alias=False, by_name=False)\n+\n+    assert 'At least one of `by_alias` or `by_name` must be set to True.' in str(exc_info.value)\n+\n+\n+def test_validate_json_with_incorrect_configuration():\n+    ta = TypeAdapter(int)\n+\n+    with pytest.raises(PydanticUserError) as exc_info:\n+        ta.validate_json(json.dumps({'x': '1'}), by_alias=False, by_name=False)\n+\n+    assert 'At least one of `by_alias` or `by_name` must be set to True.' in str(exc_info.value)\n+\n+\n+def test_validate_strings_with_incorrect_configuration():\n+    ta = TypeAdapter(int)\n+\n+    with pytest.raises(PydanticUserError) as exc_info:\n+        ta.validate_strings({'x': 'true', 'y': 'true'}, by_alias=False, by_name=False)",
      "comment": "```suggestion\r\n        ta.validate_strings(1, by_alias=False, by_name=False)\r\n```",
      "comment_id": 2618580573,
      "user": "Viicos",
      "created_at": "2025-12-15T09:11:03Z",
      "url": "https://github.com/pydantic/pydantic/pull/12627#discussion_r2618580573"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12627,
      "file_path": "tests/test_internal.py",
      "line": 196,
      "side": "RIGHT",
      "diff_hunk": "@@ -188,3 +191,128 @@ def test_decimal_digits_calculation(decimal: Decimal, decimal_places: int, digit\n def test_decimal_digits_calculation_type_error(value) -> None:\n     with pytest.raises(TypeError, match=f'Unable to extract decimal digits info from supplied value {value}'):\n         _extract_decimal_digits_info(value)\n+\n+\n+class TestCoreMetadata:",
      "comment": "We don't use test classes, plain functions are fine.\r\n\r\nLet's keep only `test_update_js_extra_as_callable_when_existing_js_extra_is_dict_type()`, `test_update_js_extra_as_callable_when_existing_js_extra_is_callable_type()`, and a simple test with `pydantic_js_functions` only being provided.",
      "comment_id": 2618639511,
      "user": "Viicos",
      "created_at": "2025-12-15T09:28:20Z",
      "url": "https://github.com/pydantic/pydantic/pull/12627#discussion_r2618639511"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12627,
      "file_path": "tests/test_plugin_loader.py",
      "line": 110,
      "side": "RIGHT",
      "diff_hunk": "@@ -81,3 +93,49 @@ def test_disable_multiple(reset_plugins):\n     assert len(list(res)) == 1\n     assert 'test_plugin:plugin1' not in list(res)\n     assert 'test_plugin:plugin2' not in list(res)\n+\n+\n+def test_caching_of_loaded_plugins(reset_plugins):\n+    os.environ['PYDANTIC_DISABLE_PLUGINS'] = 'test_plugin1,test_plugin2'\n+    res = loader.get_plugins()\n+    assert list(res) == ['test_plugin:plugin3']\n+    res = loader.get_plugins()\n+    assert list(res) == ['test_plugin:plugin3']\n+\n+\n+def test_load_same_plugin_multiple_times(reset_plugins):\n+    mock_entry_1 = EntryPoint(name='test_plugin1', value='test_plugin:plugin1', group='pydantic')\n+    mock_dist = Dist([mock_entry_1, mock_entry_1])\n+\n+    os.environ.pop('PYDANTIC_DISABLE_PLUGINS', None)",
      "comment": "This should be done using the [`monkeypatch` fixture](https://docs.pytest.org/en/stable/reference/reference.html#pytest.MonkeyPatch.setenv).",
      "comment_id": 2618654388,
      "user": "Viicos",
      "created_at": "2025-12-15T09:32:51Z",
      "url": "https://github.com/pydantic/pydantic/pull/12627#discussion_r2618654388"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12627,
      "file_path": "tests/test_internal.py",
      "line": 196,
      "side": "RIGHT",
      "diff_hunk": "@@ -188,3 +191,128 @@ def test_decimal_digits_calculation(decimal: Decimal, decimal_places: int, digit\n def test_decimal_digits_calculation_type_error(value) -> None:\n     with pytest.raises(TypeError, match=f'Unable to extract decimal digits info from supplied value {value}'):\n         _extract_decimal_digits_info(value)\n+\n+\n+class TestCoreMetadata:",
      "comment": "I understand. Removed the class. Retained only the tests sufficient to cover the missed lines.",
      "comment_id": 2620319121,
      "user": "sesmi123",
      "created_at": "2025-12-15T17:50:47Z",
      "url": "https://github.com/pydantic/pydantic/pull/12627#discussion_r2620319121"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12627,
      "file_path": "tests/test_plugin_loader.py",
      "line": 110,
      "side": "RIGHT",
      "diff_hunk": "@@ -81,3 +93,49 @@ def test_disable_multiple(reset_plugins):\n     assert len(list(res)) == 1\n     assert 'test_plugin:plugin1' not in list(res)\n     assert 'test_plugin:plugin2' not in list(res)\n+\n+\n+def test_caching_of_loaded_plugins(reset_plugins):\n+    os.environ['PYDANTIC_DISABLE_PLUGINS'] = 'test_plugin1,test_plugin2'\n+    res = loader.get_plugins()\n+    assert list(res) == ['test_plugin:plugin3']\n+    res = loader.get_plugins()\n+    assert list(res) == ['test_plugin:plugin3']\n+\n+\n+def test_load_same_plugin_multiple_times(reset_plugins):\n+    mock_entry_1 = EntryPoint(name='test_plugin1', value='test_plugin:plugin1', group='pydantic')\n+    mock_dist = Dist([mock_entry_1, mock_entry_1])\n+\n+    os.environ.pop('PYDANTIC_DISABLE_PLUGINS', None)",
      "comment": "Thanks for the review! I learnt to use monkeypatch for handling global state for tests :)",
      "comment_id": 2620324239,
      "user": "sesmi123",
      "created_at": "2025-12-15T17:52:36Z",
      "url": "https://github.com/pydantic/pydantic/pull/12627#discussion_r2620324239"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12627,
      "file_path": "tests/test_internal.py",
      "line": 238,
      "side": "RIGHT",
      "diff_hunk": "@@ -188,3 +191,128 @@ def test_decimal_digits_calculation(decimal: Decimal, decimal_places: int, digit\n def test_decimal_digits_calculation_type_error(value) -> None:\n     with pytest.raises(TypeError, match=f'Unable to extract decimal digits info from supplied value {value}'):\n         _extract_decimal_digits_info(value)\n+\n+\n+class TestCoreMetadata:\n+    def test_update_adds_key_to_existing_metadata(self):\n+        metadata = {'pydantic_js_prefer_positional_arguments': True}\n+        update_core_metadata(metadata, pydantic_js_updates={'title': 'Test'})\n+        assert metadata['pydantic_js_prefer_positional_arguments']\n+        assert metadata['pydantic_js_updates'] == {'title': 'Test'}\n+\n+    def test_multiple_updates_merge_js_updates_dict(self):\n+        metadata: dict[str, Any] = {}\n+        update_core_metadata(metadata, pydantic_js_updates={'title': 'Test'})\n+        update_core_metadata(metadata, pydantic_js_updates={'description': 'A test field'})\n+\n+        assert metadata['pydantic_js_updates']['title'] == 'Test'\n+        assert metadata['pydantic_js_updates']['description'] == 'A test field'\n+\n+    def test_update_override_earlier_values_for_existing_keys(self):\n+        metadata: dict[str, Any] = {}\n+        update_core_metadata(metadata, pydantic_js_updates={'title': 'First'})\n+        update_core_metadata(metadata, pydantic_js_updates={'title': 'Second'})\n+        assert metadata['pydantic_js_updates']['title'] == 'Second'\n+\n+    def test_update_js_extra_as_callable_when_existing_js_extra_is_none(self):\n+        metadata: dict[str, Any] = {}\n+\n+        def extra_func(schema: JsonDict) -> None:\n+            schema['testKey'] = 'testValue'\n+\n+        update_core_metadata(metadata, pydantic_js_extra=extra_func)\n+        assert metadata['pydantic_js_extra'] is extra_func\n+\n+    def test_update_js_extra_as_callable_when_existing_js_extra_is_dict_type(self):\n+        \"\"\"\n+        It should ignore the callable with a warning.\n+        \"\"\"\n+        metadata: dict[str, Any] = {}\n+\n+        extra_dict: JsonDict = {'testKey': 'testValue'}\n+\n+        def extra_func(schema: JsonDict) -> None:\n+            schema['testKey'] = 'testValue'\n+\n+        update_core_metadata(metadata, pydantic_js_extra=extra_dict)\n+        from pydantic.json_schema import PydanticJsonSchemaWarning",
      "comment": "I've moved the import to the top of the file. Resolving.",
      "comment_id": 2620327577,
      "user": "sesmi123",
      "created_at": "2025-12-15T17:53:51Z",
      "url": "https://github.com/pydantic/pydantic/pull/12627#discussion_r2620327577"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12579,
      "file_path": "pydantic/errors.py",
      "line": 101,
      "side": "RIGHT",
      "diff_hunk": "@@ -98,7 +98,7 @@ def __str__(self) -> str:\n             return f'{self.message}\\n\\nFor further information visit {DEV_ERROR_DOCS_URL}{self.code}'\n \n \n-class PydanticUserError(PydanticErrorMixin, TypeError):\n+class PydanticUserError(PydanticErrorMixin, Exception):",
      "comment": "```suggestion\r\nclass PydanticUserError(PydanticErrorMixin, RuntimeError):\r\n```",
      "comment_id": 2577110115,
      "user": "Viicos",
      "created_at": "2025-12-01T13:37:29Z",
      "url": "https://github.com/pydantic/pydantic/pull/12579#discussion_r2577110115"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11898,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 331,
      "side": "RIGHT",
      "diff_hunk": "@@ -326,20 +326,17 @@ def collect_model_fields(  # noqa: C901\n                 # Note that we only do this for method descriptors for now, we might want to\n                 # extend this to any descriptor in the future (by simply checking for\n                 # `hasattr(assigned_value.default, '__get__')`).\n-                assigned_value.default = assigned_value.default.__get__(None, cls)\n-\n-            # The `from_annotated_attribute()` call below mutates the assigned `Field()`, so make a copy:\n-            original_assignment = (\n-                copy(assigned_value) if not evaluated and isinstance(assigned_value, FieldInfo_) else assigned_value\n-            )\n+                default = assigned_value.default.__get__(None, cls)\n+                assigned_value.default = default\n+                assigned_value._attributes_set['default'] = default",
      "comment": "Next step would be to get rid of the `_attributes_set` logic when merging instances, which is error prone as you need to update it whenever you do a manual assignment on a `FieldInfo` instance.",
      "comment_id": 2101124381,
      "user": "Viicos",
      "created_at": "2025-05-21T20:37:27Z",
      "url": "https://github.com/pydantic/pydantic/pull/11898#discussion_r2101124381"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11898,
      "file_path": "pydantic/fields.py",
      "line": 217,
      "side": "RIGHT",
      "diff_hunk": "@@ -213,7 +213,7 @@ def __init__(self, **kwargs: Unpack[_FieldInfoInputs]) -> None:\n \n         See the signature of `pydantic.fields.Field` for more details about the expected arguments.\n         \"\"\"\n-        self._attributes_set = {k: v for k, v in kwargs.items() if v is not _Unset}\n+        self._attributes_set = {k: v for k, v in kwargs.items() if v is not _Unset and k not in self.metadata_lookup}",
      "comment": "This is kind of important, although it also works without the change:\r\n\r\nWhen we merge field infos, we don't want to reinclude kwargs that are transformed to metadata elements (`gt` -> `annotated_types.Gt`, etc). This will result in unnecessary metadata classes to be created (at the end of the `FieldInfo.__init__()` logic). ",
      "comment_id": 2101126466,
      "user": "Viicos",
      "created_at": "2025-05-21T20:39:10Z",
      "url": "https://github.com/pydantic/pydantic/pull/11898#discussion_r2101126466"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11898,
      "file_path": "pydantic/fields.py",
      "line": 762,
      "side": "RIGHT",
      "diff_hunk": "@@ -700,6 +738,19 @@ def apply_typevars_map(\n             self._complete = False\n             self._original_annotation = self.annotation\n \n+    def _copy(self) -> Self:\n+        \"\"\"Return a copy of the `FieldInfo` instance.\"\"\"\n+        # Note: we can't define a custom `__copy__()`, as `FieldInfo` is being subclassed\n+        # by some third-party libraries with extra attributes defined (and as `FieldInfo`\n+        # is slotted, we can't make a copy of the `__dict__`).",
      "comment": "Alternatively, we can drop slots on `FieldInfo`, and do the following:\r\n\r\n\r\n```python\r\n    def __copy__(self) -> Self:\r\n        copied = type(self)()\r\n        copied.__dict__ = self.__dict__\r\n        for attr_name in ('metadata', '_attributes_set', '_qualifiers'):\r\n             # Apply \"deep-copy\" behavior on collections attributes:\r\n             value = getattr(self, attr_name).copy()\r\n             setattr(copied, attr_name, value)\r\n\r\n        return copied\r\n```",
      "comment_id": 2104889496,
      "user": "Viicos",
      "created_at": "2025-05-23T15:54:47Z",
      "url": "https://github.com/pydantic/pydantic/pull/11898#discussion_r2104889496"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11898,
      "file_path": "tests/test_annotated.py",
      "line": 508,
      "side": "LEFT",
      "diff_hunk": "@@ -505,28 +505,6 @@ class AnnotatedFieldModel(BaseModel):\n         }\n     ]\n \n-    # Ensure that the inner annotation does not override the outer, even for metadata:",
      "comment": "Due to one of the bugs being fixed in this PR (related to the usage of forward references), the constraint in `Annotated` was dropped. Now the test is failing because the unexpected order (described in https://github.com/pydantic/pydantic/issues/10507) applies.",
      "comment_id": 2104893756,
      "user": "Viicos",
      "created_at": "2025-05-23T15:56:20Z",
      "url": "https://github.com/pydantic/pydantic/pull/11898#discussion_r2104893756"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11898,
      "file_path": "pydantic/fields.py",
      "line": 418,
      "side": "RIGHT",
      "diff_hunk": "@@ -417,57 +399,124 @@ class MyModel(pydantic.BaseModel):\n         final = 'final' in inspected_ann.qualifiers\n         metadata = inspected_ann.metadata\n \n-        if isinstance(default, FieldInfo):\n-            # e.g. `field: int = Field(...)`\n-            default.annotation = type_expr\n-            default.metadata += metadata\n-            merged_default = FieldInfo.merge_field_infos(\n-                *[x for x in metadata if isinstance(x, FieldInfo)],\n-                default,\n-                annotation=default.annotation,\n-            )\n-            merged_default.frozen = final or merged_default.frozen\n-            merged_default._qualifiers = inspected_ann.qualifiers\n-            return merged_default\n-\n-        if isinstance(default, dataclasses.Field):\n-            # `collect_dataclass_fields()` passes the dataclass Field as a default.\n-            pydantic_field = FieldInfo._from_dataclass_field(default)\n-            pydantic_field.annotation = type_expr\n-            pydantic_field.metadata += metadata\n-            pydantic_field = FieldInfo.merge_field_infos(\n-                *[x for x in metadata if isinstance(x, FieldInfo)],\n-                pydantic_field,\n-                annotation=pydantic_field.annotation,\n-            )\n-            pydantic_field.frozen = final or pydantic_field.frozen\n-            pydantic_field.init_var = 'init_var' in inspected_ann.qualifiers\n-            pydantic_field.init = getattr(default, 'init', None)\n-            pydantic_field.kw_only = getattr(default, 'kw_only', None)\n-            pydantic_field._qualifiers = inspected_ann.qualifiers\n-            return pydantic_field\n-\n-        if not metadata:\n-            # No metadata, e.g. `field: int = ...`, or `field: Final[str] = ...`:\n-            field_info = FieldInfo(annotation=type_expr, default=default, frozen=final or None)\n-            field_info._qualifiers = inspected_ann.qualifiers\n+        # HACK 1: the order in which the metadata is merged is inconsistent; we need to prepend\n+        # metadata from the assignment at the beginning of the metadata. Changing this is only\n+        # possible in v3 (at least). See https://github.com/pydantic/pydantic/issues/10507\n+        prepend_metadata: list[Any] | None = None\n+        attr_overrides = {'annotation': type_expr}\n+        if final:\n+            attr_overrides['frozen'] = True\n+\n+        # HACK 2: FastAPI is subclassing `FieldInfo` and historically expected the actual\n+        # instance's type to be preserved when constructing new models with its subclasses as assignments.\n+        # This code is never reached by Pydantic itself, and in an ideal world this shouldn't be necessary.\n+        if not metadata and isinstance(default, FieldInfo) and type(default) is not FieldInfo:\n+            field_info = default._copy()\n+            field_info._attributes_set.update(attr_overrides)\n+            for k, v in attr_overrides.items():\n+                setattr(field_info, k, v)",
      "comment": "Unfortunate stuff introduced since https://github.com/pydantic/pydantic/pull/6862..",
      "comment_id": 2104943652,
      "user": "Viicos",
      "created_at": "2025-05-23T16:12:40Z",
      "url": "https://github.com/pydantic/pydantic/pull/11898#discussion_r2104943652"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11898,
      "file_path": "pydantic/fields.py",
      "line": 425,
      "side": "RIGHT",
      "diff_hunk": "@@ -417,58 +400,130 @@ class MyModel(pydantic.BaseModel):\n         final = 'final' in inspected_ann.qualifiers\n         metadata = inspected_ann.metadata\n \n-        if isinstance(default, FieldInfo):\n-            # e.g. `field: int = Field(...)`\n-            default.annotation = type_expr\n-            default.metadata += metadata\n-            merged_default = FieldInfo.merge_field_infos(\n-                *[x for x in metadata if isinstance(x, FieldInfo)],\n-                default,\n-                annotation=default.annotation,\n-            )\n-            merged_default.frozen = final or merged_default.frozen\n-            merged_default._qualifiers = inspected_ann.qualifiers\n-            return merged_default\n-\n-        if isinstance(default, dataclasses.Field):\n-            # `collect_dataclass_fields()` passes the dataclass Field as a default.\n-            pydantic_field = FieldInfo._from_dataclass_field(default)\n-            pydantic_field.annotation = type_expr\n-            pydantic_field.metadata += metadata\n-            pydantic_field = FieldInfo.merge_field_infos(\n-                *[x for x in metadata if isinstance(x, FieldInfo)],\n-                pydantic_field,\n-                annotation=pydantic_field.annotation,\n-            )\n-            pydantic_field.frozen = final or pydantic_field.frozen\n-            pydantic_field.init_var = 'init_var' in inspected_ann.qualifiers\n-            pydantic_field.init = getattr(default, 'init', None)\n-            pydantic_field.kw_only = getattr(default, 'kw_only', None)\n-            pydantic_field._qualifiers = inspected_ann.qualifiers\n-            return pydantic_field\n-\n-        if not metadata:\n-            # No metadata, e.g. `field: int = ...`, or `field: Final[str] = ...`:\n-            field_info = FieldInfo(annotation=type_expr, default=default, frozen=final or None)\n-            field_info._qualifiers = inspected_ann.qualifiers\n+        # HACK 1: the order in which the metadata is merged is inconsistent; we need to prepend\n+        # metadata from the assignment at the beginning of the metadata. Changing this is only\n+        # possible in v3 (at least). See https://github.com/pydantic/pydantic/issues/10507\n+        prepend_metadata: list[Any] | None = None\n+        attr_overrides = {'annotation': type_expr}\n+        if final:\n+            attr_overrides['frozen'] = True\n+\n+        # HACK 2: FastAPI is subclassing `FieldInfo` and historically expected the actual\n+        # instance's type to be preserved when constructing new models with its subclasses as assignments.\n+        # This code is never reached by Pydantic itself, and in an ideal world this shouldn't be necessary.\n+        if not metadata and isinstance(default, FieldInfo) and type(default) is not FieldInfo:\n+            field_info = default._copy()\n+            field_info._attributes_set.update(attr_overrides)\n+            for k, v in attr_overrides.items():\n+                setattr(field_info, k, v)\n             return field_info\n \n-        # With metadata, e.g. `field: Annotated[int, Field(...), Gt(1)] = ...`:\n-        field_infos = [a for a in metadata if isinstance(a, FieldInfo)]\n-        field_info = FieldInfo.merge_field_infos(*field_infos, annotation=type_expr, default=default)\n-        field_metadata: list[Any] = []\n-        for a in metadata:\n-            if typing_objects.is_deprecated(a):\n-                field_info.deprecated = a.message\n-            elif not isinstance(a, FieldInfo):\n-                field_metadata.append(a)\n-            else:\n-                field_metadata.extend(a.metadata)\n-        field_info.metadata = field_metadata\n+        if isinstance(default, FieldInfo):\n+            default_copy = default._copy()  # Copy unnecessary when we remove HACK 1.\n+            prepend_metadata = default_copy.metadata\n+            default_copy.metadata = []\n+            metadata = metadata + [default_copy]",
      "comment": "Why couldn't this be the following?\r\n\r\n```suggestion\r\n            metadata = [default] + metadata\r\n```\r\n\r\nI guess because we want other properties on `default` to still be applied at the end?",
      "comment_id": 2143393776,
      "user": "DouweM",
      "created_at": "2025-06-12T18:39:02Z",
      "url": "https://github.com/pydantic/pydantic/pull/11898#discussion_r2143393776"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11898,
      "file_path": "pydantic/fields.py",
      "line": 444,
      "side": "RIGHT",
      "diff_hunk": "@@ -417,58 +400,130 @@ class MyModel(pydantic.BaseModel):\n         final = 'final' in inspected_ann.qualifiers\n         metadata = inspected_ann.metadata\n \n-        if isinstance(default, FieldInfo):\n-            # e.g. `field: int = Field(...)`\n-            default.annotation = type_expr\n-            default.metadata += metadata\n-            merged_default = FieldInfo.merge_field_infos(\n-                *[x for x in metadata if isinstance(x, FieldInfo)],\n-                default,\n-                annotation=default.annotation,\n-            )\n-            merged_default.frozen = final or merged_default.frozen\n-            merged_default._qualifiers = inspected_ann.qualifiers\n-            return merged_default\n-\n-        if isinstance(default, dataclasses.Field):\n-            # `collect_dataclass_fields()` passes the dataclass Field as a default.\n-            pydantic_field = FieldInfo._from_dataclass_field(default)\n-            pydantic_field.annotation = type_expr\n-            pydantic_field.metadata += metadata\n-            pydantic_field = FieldInfo.merge_field_infos(\n-                *[x for x in metadata if isinstance(x, FieldInfo)],\n-                pydantic_field,\n-                annotation=pydantic_field.annotation,\n-            )\n-            pydantic_field.frozen = final or pydantic_field.frozen\n-            pydantic_field.init_var = 'init_var' in inspected_ann.qualifiers\n-            pydantic_field.init = getattr(default, 'init', None)\n-            pydantic_field.kw_only = getattr(default, 'kw_only', None)\n-            pydantic_field._qualifiers = inspected_ann.qualifiers\n-            return pydantic_field\n-\n-        if not metadata:\n-            # No metadata, e.g. `field: int = ...`, or `field: Final[str] = ...`:\n-            field_info = FieldInfo(annotation=type_expr, default=default, frozen=final or None)\n-            field_info._qualifiers = inspected_ann.qualifiers\n+        # HACK 1: the order in which the metadata is merged is inconsistent; we need to prepend\n+        # metadata from the assignment at the beginning of the metadata. Changing this is only\n+        # possible in v3 (at least). See https://github.com/pydantic/pydantic/issues/10507\n+        prepend_metadata: list[Any] | None = None\n+        attr_overrides = {'annotation': type_expr}\n+        if final:\n+            attr_overrides['frozen'] = True\n+\n+        # HACK 2: FastAPI is subclassing `FieldInfo` and historically expected the actual\n+        # instance's type to be preserved when constructing new models with its subclasses as assignments.\n+        # This code is never reached by Pydantic itself, and in an ideal world this shouldn't be necessary.\n+        if not metadata and isinstance(default, FieldInfo) and type(default) is not FieldInfo:\n+            field_info = default._copy()\n+            field_info._attributes_set.update(attr_overrides)\n+            for k, v in attr_overrides.items():\n+                setattr(field_info, k, v)\n             return field_info\n \n-        # With metadata, e.g. `field: Annotated[int, Field(...), Gt(1)] = ...`:\n-        field_infos = [a for a in metadata if isinstance(a, FieldInfo)]\n-        field_info = FieldInfo.merge_field_infos(*field_infos, annotation=type_expr, default=default)\n-        field_metadata: list[Any] = []\n-        for a in metadata:\n-            if typing_objects.is_deprecated(a):\n-                field_info.deprecated = a.message\n-            elif not isinstance(a, FieldInfo):\n-                field_metadata.append(a)\n-            else:\n-                field_metadata.extend(a.metadata)\n-        field_info.metadata = field_metadata\n+        if isinstance(default, FieldInfo):\n+            default_copy = default._copy()  # Copy unnecessary when we remove HACK 1.\n+            prepend_metadata = default_copy.metadata\n+            default_copy.metadata = []\n+            metadata = metadata + [default_copy]\n+        elif isinstance(default, dataclasses.Field):\n+            from_field = FieldInfo._from_dataclass_field(default)\n+            prepend_metadata = from_field.metadata  # Unnecessary when we remove HACK 1.\n+            from_field.metadata = []\n+            metadata = metadata + [from_field]\n+            if 'init_var' in inspected_ann.qualifiers:\n+                attr_overrides['init_var'] = True\n+            if (init := getattr(default, 'init', None)) is not None:\n+                attr_overrides['init'] = init\n+            if (kw_only := getattr(default, 'kw_only', None)) is not None:\n+                attr_overrides['kw_only'] = kw_only\n+        else:\n+            # `default` is the actual default value\n+            attr_overrides['default'] = default\n+\n+        field_info = FieldInfo._construct(metadata, **attr_overrides)\n         field_info._qualifiers = inspected_ann.qualifiers\n+        if prepend_metadata is not None:\n+            field_info.metadata = prepend_metadata + field_info.metadata",
      "comment": "Why are we assigning this after `_construct` instead of passing it `prepend_metadata + metadata`?",
      "comment_id": 2143396716,
      "user": "DouweM",
      "created_at": "2025-06-12T18:41:38Z",
      "url": "https://github.com/pydantic/pydantic/pull/11898#discussion_r2143396716"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11898,
      "file_path": "pydantic/fields.py",
      "line": 425,
      "side": "RIGHT",
      "diff_hunk": "@@ -417,58 +400,130 @@ class MyModel(pydantic.BaseModel):\n         final = 'final' in inspected_ann.qualifiers\n         metadata = inspected_ann.metadata\n \n-        if isinstance(default, FieldInfo):\n-            # e.g. `field: int = Field(...)`\n-            default.annotation = type_expr\n-            default.metadata += metadata\n-            merged_default = FieldInfo.merge_field_infos(\n-                *[x for x in metadata if isinstance(x, FieldInfo)],\n-                default,\n-                annotation=default.annotation,\n-            )\n-            merged_default.frozen = final or merged_default.frozen\n-            merged_default._qualifiers = inspected_ann.qualifiers\n-            return merged_default\n-\n-        if isinstance(default, dataclasses.Field):\n-            # `collect_dataclass_fields()` passes the dataclass Field as a default.\n-            pydantic_field = FieldInfo._from_dataclass_field(default)\n-            pydantic_field.annotation = type_expr\n-            pydantic_field.metadata += metadata\n-            pydantic_field = FieldInfo.merge_field_infos(\n-                *[x for x in metadata if isinstance(x, FieldInfo)],\n-                pydantic_field,\n-                annotation=pydantic_field.annotation,\n-            )\n-            pydantic_field.frozen = final or pydantic_field.frozen\n-            pydantic_field.init_var = 'init_var' in inspected_ann.qualifiers\n-            pydantic_field.init = getattr(default, 'init', None)\n-            pydantic_field.kw_only = getattr(default, 'kw_only', None)\n-            pydantic_field._qualifiers = inspected_ann.qualifiers\n-            return pydantic_field\n-\n-        if not metadata:\n-            # No metadata, e.g. `field: int = ...`, or `field: Final[str] = ...`:\n-            field_info = FieldInfo(annotation=type_expr, default=default, frozen=final or None)\n-            field_info._qualifiers = inspected_ann.qualifiers\n+        # HACK 1: the order in which the metadata is merged is inconsistent; we need to prepend\n+        # metadata from the assignment at the beginning of the metadata. Changing this is only\n+        # possible in v3 (at least). See https://github.com/pydantic/pydantic/issues/10507\n+        prepend_metadata: list[Any] | None = None\n+        attr_overrides = {'annotation': type_expr}\n+        if final:\n+            attr_overrides['frozen'] = True\n+\n+        # HACK 2: FastAPI is subclassing `FieldInfo` and historically expected the actual\n+        # instance's type to be preserved when constructing new models with its subclasses as assignments.\n+        # This code is never reached by Pydantic itself, and in an ideal world this shouldn't be necessary.\n+        if not metadata and isinstance(default, FieldInfo) and type(default) is not FieldInfo:\n+            field_info = default._copy()\n+            field_info._attributes_set.update(attr_overrides)\n+            for k, v in attr_overrides.items():\n+                setattr(field_info, k, v)\n             return field_info\n \n-        # With metadata, e.g. `field: Annotated[int, Field(...), Gt(1)] = ...`:\n-        field_infos = [a for a in metadata if isinstance(a, FieldInfo)]\n-        field_info = FieldInfo.merge_field_infos(*field_infos, annotation=type_expr, default=default)\n-        field_metadata: list[Any] = []\n-        for a in metadata:\n-            if typing_objects.is_deprecated(a):\n-                field_info.deprecated = a.message\n-            elif not isinstance(a, FieldInfo):\n-                field_metadata.append(a)\n-            else:\n-                field_metadata.extend(a.metadata)\n-        field_info.metadata = field_metadata\n+        if isinstance(default, FieldInfo):\n+            default_copy = default._copy()  # Copy unnecessary when we remove HACK 1.\n+            prepend_metadata = default_copy.metadata\n+            default_copy.metadata = []\n+            metadata = metadata + [default_copy]",
      "comment": "> I guess because we want other properties on `default` to still be applied at the end?\r\n\r\nExactly, as per https://github.com/pydantic/pydantic/issues/10507, any `FieldInfo` attribute that isn't converted into the `metadata` array (e.g. `description`) is applied correctly.",
      "comment_id": 2144537661,
      "user": "Viicos",
      "created_at": "2025-06-13T08:57:19Z",
      "url": "https://github.com/pydantic/pydantic/pull/11898#discussion_r2144537661"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11898,
      "file_path": "pydantic/fields.py",
      "line": 444,
      "side": "RIGHT",
      "diff_hunk": "@@ -417,58 +400,130 @@ class MyModel(pydantic.BaseModel):\n         final = 'final' in inspected_ann.qualifiers\n         metadata = inspected_ann.metadata\n \n-        if isinstance(default, FieldInfo):\n-            # e.g. `field: int = Field(...)`\n-            default.annotation = type_expr\n-            default.metadata += metadata\n-            merged_default = FieldInfo.merge_field_infos(\n-                *[x for x in metadata if isinstance(x, FieldInfo)],\n-                default,\n-                annotation=default.annotation,\n-            )\n-            merged_default.frozen = final or merged_default.frozen\n-            merged_default._qualifiers = inspected_ann.qualifiers\n-            return merged_default\n-\n-        if isinstance(default, dataclasses.Field):\n-            # `collect_dataclass_fields()` passes the dataclass Field as a default.\n-            pydantic_field = FieldInfo._from_dataclass_field(default)\n-            pydantic_field.annotation = type_expr\n-            pydantic_field.metadata += metadata\n-            pydantic_field = FieldInfo.merge_field_infos(\n-                *[x for x in metadata if isinstance(x, FieldInfo)],\n-                pydantic_field,\n-                annotation=pydantic_field.annotation,\n-            )\n-            pydantic_field.frozen = final or pydantic_field.frozen\n-            pydantic_field.init_var = 'init_var' in inspected_ann.qualifiers\n-            pydantic_field.init = getattr(default, 'init', None)\n-            pydantic_field.kw_only = getattr(default, 'kw_only', None)\n-            pydantic_field._qualifiers = inspected_ann.qualifiers\n-            return pydantic_field\n-\n-        if not metadata:\n-            # No metadata, e.g. `field: int = ...`, or `field: Final[str] = ...`:\n-            field_info = FieldInfo(annotation=type_expr, default=default, frozen=final or None)\n-            field_info._qualifiers = inspected_ann.qualifiers\n+        # HACK 1: the order in which the metadata is merged is inconsistent; we need to prepend\n+        # metadata from the assignment at the beginning of the metadata. Changing this is only\n+        # possible in v3 (at least). See https://github.com/pydantic/pydantic/issues/10507\n+        prepend_metadata: list[Any] | None = None\n+        attr_overrides = {'annotation': type_expr}\n+        if final:\n+            attr_overrides['frozen'] = True\n+\n+        # HACK 2: FastAPI is subclassing `FieldInfo` and historically expected the actual\n+        # instance's type to be preserved when constructing new models with its subclasses as assignments.\n+        # This code is never reached by Pydantic itself, and in an ideal world this shouldn't be necessary.\n+        if not metadata and isinstance(default, FieldInfo) and type(default) is not FieldInfo:\n+            field_info = default._copy()\n+            field_info._attributes_set.update(attr_overrides)\n+            for k, v in attr_overrides.items():\n+                setattr(field_info, k, v)\n             return field_info\n \n-        # With metadata, e.g. `field: Annotated[int, Field(...), Gt(1)] = ...`:\n-        field_infos = [a for a in metadata if isinstance(a, FieldInfo)]\n-        field_info = FieldInfo.merge_field_infos(*field_infos, annotation=type_expr, default=default)\n-        field_metadata: list[Any] = []\n-        for a in metadata:\n-            if typing_objects.is_deprecated(a):\n-                field_info.deprecated = a.message\n-            elif not isinstance(a, FieldInfo):\n-                field_metadata.append(a)\n-            else:\n-                field_metadata.extend(a.metadata)\n-        field_info.metadata = field_metadata\n+        if isinstance(default, FieldInfo):\n+            default_copy = default._copy()  # Copy unnecessary when we remove HACK 1.\n+            prepend_metadata = default_copy.metadata\n+            default_copy.metadata = []\n+            metadata = metadata + [default_copy]\n+        elif isinstance(default, dataclasses.Field):\n+            from_field = FieldInfo._from_dataclass_field(default)\n+            prepend_metadata = from_field.metadata  # Unnecessary when we remove HACK 1.\n+            from_field.metadata = []\n+            metadata = metadata + [from_field]\n+            if 'init_var' in inspected_ann.qualifiers:\n+                attr_overrides['init_var'] = True\n+            if (init := getattr(default, 'init', None)) is not None:\n+                attr_overrides['init'] = init\n+            if (kw_only := getattr(default, 'kw_only', None)) is not None:\n+                attr_overrides['kw_only'] = kw_only\n+        else:\n+            # `default` is the actual default value\n+            attr_overrides['default'] = default\n+\n+        field_info = FieldInfo._construct(metadata, **attr_overrides)\n         field_info._qualifiers = inspected_ann.qualifiers\n+        if prepend_metadata is not None:\n+            field_info.metadata = prepend_metadata + field_info.metadata",
      "comment": "Both are equivalent, but indeed passing all the metadata directly to `_construct()` is cleaner. Applied.",
      "comment_id": 2144563306,
      "user": "Viicos",
      "created_at": "2025-06-13T09:12:19Z",
      "url": "https://github.com/pydantic/pydantic/pull/11898#discussion_r2144563306"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11898,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 331,
      "side": "RIGHT",
      "diff_hunk": "@@ -326,20 +326,17 @@ def collect_model_fields(  # noqa: C901\n                 # Note that we only do this for method descriptors for now, we might want to\n                 # extend this to any descriptor in the future (by simply checking for\n                 # `hasattr(assigned_value.default, '__get__')`).\n-                assigned_value.default = assigned_value.default.__get__(None, cls)\n-\n-            # The `from_annotated_attribute()` call below mutates the assigned `Field()`, so make a copy:\n-            original_assignment = (\n-                copy(assigned_value) if not evaluated and isinstance(assigned_value, FieldInfo_) else assigned_value\n-            )\n+                default = assigned_value.default.__get__(None, cls)\n+                assigned_value.default = default\n+                assigned_value._attributes_set['default'] = default",
      "comment": "Where can I subscribe to see when this happens?\n\nApologies if this seems weird to respond to now, please let me know if I should turn this into a proper issue or some such for visibility.\n\nI just spent a few hours adjusting to the v2.12 release, which broke our filter-system. In essence, we're creating lots of filters dynamically using a MetaClass and these filters have pydantic `Field`s. We usually just pass some extra information by setting\n\n```python\n    field.json_schema_extra = {\"sqla_column\": name}\n```\n\nThis used to work with previous versions, but now we need to add\n\n```python\n    field._attributes_set[\"json_schema_extra\"] = {\"sqla_column\": name}\n```\n\nto make the final `pydantic.BaseModel.__new__()` call recognize the `json_schema_extra` attribute.\n\nSo thanks for providing the fix in this comment :)",
      "comment_id": 2413630831,
      "user": "glatterf42",
      "created_at": "2025-10-08T12:04:09Z",
      "url": "https://github.com/pydantic/pydantic/pull/11898#discussion_r2413630831"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11898,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 331,
      "side": "RIGHT",
      "diff_hunk": "@@ -326,20 +326,17 @@ def collect_model_fields(  # noqa: C901\n                 # Note that we only do this for method descriptors for now, we might want to\n                 # extend this to any descriptor in the future (by simply checking for\n                 # `hasattr(assigned_value.default, '__get__')`).\n-                assigned_value.default = assigned_value.default.__get__(None, cls)\n-\n-            # The `from_annotated_attribute()` call below mutates the assigned `Field()`, so make a copy:\n-            original_assignment = (\n-                copy(assigned_value) if not evaluated and isinstance(assigned_value, FieldInfo_) else assigned_value\n-            )\n+                default = assigned_value.default.__get__(None, cls)\n+                assigned_value.default = default\n+                assigned_value._attributes_set['default'] = default",
      "comment": "Not really a specific issue for `_attributes_set`, but I gathered everything into https://github.com/pydantic/pydantic/issues/12374. To be help to give some feedback on your approach (and if extending our metaclass is the only possible option=, I would just require a small example of what your library achieves if possible!",
      "comment_id": 2418264128,
      "user": "Viicos",
      "created_at": "2025-10-10T00:52:17Z",
      "url": "https://github.com/pydantic/pydantic/pull/11898#discussion_r2418264128"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11898,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 331,
      "side": "RIGHT",
      "diff_hunk": "@@ -326,20 +326,17 @@ def collect_model_fields(  # noqa: C901\n                 # Note that we only do this for method descriptors for now, we might want to\n                 # extend this to any descriptor in the future (by simply checking for\n                 # `hasattr(assigned_value.default, '__get__')`).\n-                assigned_value.default = assigned_value.default.__get__(None, cls)\n-\n-            # The `from_annotated_attribute()` call below mutates the assigned `Field()`, so make a copy:\n-            original_assignment = (\n-                copy(assigned_value) if not evaluated and isinstance(assigned_value, FieldInfo_) else assigned_value\n-            )\n+                default = assigned_value.default.__get__(None, cls)\n+                assigned_value.default = default\n+                assigned_value._attributes_set['default'] = default",
      "comment": "Thanks for your offer and sorry for the late reply! In the meantime, our library was refactored quite substantially, which eliminated our usage of `_attributes_set` :)",
      "comment_id": 2572118575,
      "user": "glatterf42",
      "created_at": "2025-11-28T16:33:51Z",
      "url": "https://github.com/pydantic/pydantic/pull/11898#discussion_r2572118575"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12563,
      "file_path": "tests/test_forward_ref.py",
      "line": 1094,
      "side": "RIGHT",
      "diff_hunk": "@@ -1090,10 +1090,12 @@ def test_pydantic_extra_forward_ref_separate_module(create_module: Any) -> None:\n     def module_1():\n         from pydantic import BaseModel, ConfigDict\n \n+        MyDict = dict\n+",
      "comment": "This was wrongly updated when dropping support for Python 3.9.",
      "comment_id": 2553174445,
      "user": "Viicos",
      "created_at": "2025-11-22T14:55:04Z",
      "url": "https://github.com/pydantic/pydantic/pull/12563#discussion_r2553174445"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12563,
      "file_path": "tests/test_forward_ref.py",
      "line": 1118,
      "side": "RIGHT",
      "diff_hunk": "@@ -1113,6 +1115,42 @@ class Foo(BaseModel):\n     assert extras_schema == {'type': 'int'}\n \n \n+def test_pydantic_extra_forward_ref_separate_module_subclass(create_module: Any) -> None:",
      "comment": "This was a use case that wasn't working until now.",
      "comment_id": 2553174547,
      "user": "Viicos",
      "created_at": "2025-11-22T14:55:20Z",
      "url": "https://github.com/pydantic/pydantic/pull/12563#discussion_r2553174547"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12563,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 48,
      "side": "RIGHT",
      "diff_hunk": "@@ -41,6 +42,13 @@ class PydanticMetadata(Representation):\n     __slots__ = ()\n \n \n+@dataclasses.dataclass(**slots_true)  # TODO: make kw_only when we drop support for 3.9.\n+class PydanticExtraInfo:\n+    # TODO: make use of PEP 747:\n+    annotation: Any",
      "comment": "`typing_extensions.TypeForm`? Or is the point that we'll need to update places across the code for this?",
      "comment_id": 2555593501,
      "user": "davidhewitt",
      "created_at": "2025-11-24T10:14:36Z",
      "url": "https://github.com/pydantic/pydantic/pull/12563#discussion_r2555593501"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12563,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 970,
      "side": "RIGHT",
      "diff_hunk": "@@ -978,6 +965,9 @@ def _get_args_resolving_forward_refs(self, obj: Any, required: bool = False) ->\n         if args:\n             if isinstance(obj, GenericAlias):\n                 # PEP 585 generic aliases don't convert args to ForwardRefs, unlike `typing.List/Dict` etc.\n+                # This was fixed in https://github.com/python/cpython/pull/30900 (Python 3.11).\n+                # TODO: this shouldn't be necessary (probably even this `_get_args_resolving_forward_refs()` function)\n+                # once we drop support for Python 3.10 *or* if we implement our own `typing._eval_type()` implementation.",
      "comment": "Should we update the `isinstance` to have a condition on `sys.version_info < (3, 11)` (or even just make the whole function just return early)?",
      "comment_id": 2555611087,
      "user": "davidhewitt",
      "created_at": "2025-11-24T10:18:19Z",
      "url": "https://github.com/pydantic/pydantic/pull/12563#discussion_r2555611087"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12563,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 48,
      "side": "RIGHT",
      "diff_hunk": "@@ -41,6 +42,13 @@ class PydanticMetadata(Representation):\n     __slots__ = ()\n \n \n+@dataclasses.dataclass(**slots_true)  # TODO: make kw_only when we drop support for 3.9.\n+class PydanticExtraInfo:\n+    # TODO: make use of PEP 747:\n+    annotation: Any",
      "comment": "Yes, once the PEP is accepted I'll grep for this type of comment and replace.",
      "comment_id": 2555793503,
      "user": "Viicos",
      "created_at": "2025-11-24T11:00:59Z",
      "url": "https://github.com/pydantic/pydantic/pull/12563#discussion_r2555793503"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12563,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 970,
      "side": "RIGHT",
      "diff_hunk": "@@ -978,6 +965,9 @@ def _get_args_resolving_forward_refs(self, obj: Any, required: bool = False) ->\n         if args:\n             if isinstance(obj, GenericAlias):\n                 # PEP 585 generic aliases don't convert args to ForwardRefs, unlike `typing.List/Dict` etc.\n+                # This was fixed in https://github.com/python/cpython/pull/30900 (Python 3.11).\n+                # TODO: this shouldn't be necessary (probably even this `_get_args_resolving_forward_refs()` function)\n+                # once we drop support for Python 3.10 *or* if we implement our own `typing._eval_type()` implementation.",
      "comment": "In theory we could, but I'm a bit worried this would introduce subtle regressions for other annotations that were not actually evaluated (and not due to the <3.11 bug). The end goal is to have the guarantee that everything passed to `GenerateSchema` is evaluated, but I'm not entirely sure this is the case yet, so probably I'll try to tackle this properly separately.",
      "comment_id": 2555802965,
      "user": "Viicos",
      "created_at": "2025-11-24T11:03:00Z",
      "url": "https://github.com/pydantic/pydantic/pull/12563#discussion_r2555802965"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12560,
      "file_path": "pydantic/config.py",
      "line": 599,
      "side": "RIGHT",
      "diff_hunk": "@@ -588,10 +595,10 @@ class Transaction(BaseModel):\n \n     Defaults to `'iso8601'`.\n \n-    !!! note\n-        This setting was introduced in v2.12. It overlaps with the [`ser_json_timedelta`][pydantic.config.ConfigDict.ser_json_timedelta]\n-        setting which will be deprecated in v3. It also adds more configurability for\n-        the other temporal types.\n+    /// version-added | v2.12\n+    This setting is meant to be a replacement for [`ser_json_timedelta`][pydantic.config.ConfigDict.ser_json_timedelta],",
      "comment": "```suggestion\n    This setting replaces [`ser_json_timedelta`][pydantic.config.ConfigDict.ser_json_timedelta],\n```",
      "comment_id": 2549669485,
      "user": "davidhewitt",
      "created_at": "2025-11-21T12:51:42Z",
      "url": "https://github.com/pydantic/pydantic/pull/12560#discussion_r2549669485"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12560,
      "file_path": "pydantic/config.py",
      "line": 1148,
      "side": "RIGHT",
      "diff_hunk": "@@ -1120,6 +1141,12 @@ class Model(BaseModel):\n         This would make it impossible to populate an attribute.\n \n         See [usage errors](../errors/usage_errors.md#validate-by-alias-and-name-false) for an example.\n+\n+    /// version-added | v2.11\n+    This setting was introduced in conjunction with [`validate_by_alias`][pydantic.ConfigDict.validate_by_alias]\n+    to empower users with more fine grained validation control. It is an alternative to [`populate_by_name`][pydantic.ConfigDict.populate_by_name],\n+    thas enames validation by name **and** by alias.",
      "comment": "```suggestion\n    that enables validation by name **and** by alias.\n```",
      "comment_id": 2549674368,
      "user": "davidhewitt",
      "created_at": "2025-11-21T12:53:40Z",
      "url": "https://github.com/pydantic/pydantic/pull/12560#discussion_r2549674368"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12536,
      "file_path": "tests/test_decorators.py",
      "line": 146,
      "side": "RIGHT",
      "diff_hunk": "@@ -115,3 +115,32 @@ def serializer():\n         inspect_annotated_serializer(serializer, mode=mode)\n \n     assert e.value.code == 'field-serializer-signature'\n+\n+\n+def test_plain_class_not_mutated() -> None:\n+    class A:\n+        @computed_field\n+        def func(self) -> int:\n+            return 1\n+\n+    class B(A, BaseModel):\n+        pass\n+\n+    assert B.__pydantic_decorators__.computed_fields['func'].cls_var_name == 'func'\n+\n+    assert '__pydantic_decorators__' not in A.__dict__\n+\n+\n+def test_decorator_info_not_mutated() -> None:\n+    class A(BaseModel):\n+        @computed_field\n+        def func(self) -> int:\n+            return 1\n+\n+    assert A.__pydantic_decorators__.computed_fields['func'].info.title is None\n+\n+    class B(A, field_title_generator=lambda _, __: 'test'):\n+        pass\n+\n+    assert A.__pydantic_decorators__.computed_fields['func'].info.title is None\n+    assert B.__pydantic_decorators__.computed_fields['func'].info.title == 'test'",
      "comment": "This seems strange that `B` is able to change semantics of fields on A?",
      "comment_id": 2534468162,
      "user": "davidhewitt",
      "created_at": "2025-11-17T15:10:21Z",
      "url": "https://github.com/pydantic/pydantic/pull/12536#discussion_r2534468162"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12536,
      "file_path": "pydantic/fields.py",
      "line": 1522,
      "side": "RIGHT",
      "diff_hunk": "@@ -1519,7 +1519,7 @@ def PrivateAttr(\n     )\n \n \n-@dataclasses.dataclass(**_internal_dataclass.slots_true)\n+@dataclasses.dataclass",
      "comment": "I guess removing slots made the copy implementation _easier_, but if it's better performance to keep it, should we just do the more complex `copy` implementation which does all fields by hand?.",
      "comment_id": 2534473000,
      "user": "davidhewitt",
      "created_at": "2025-11-17T15:11:46Z",
      "url": "https://github.com/pydantic/pydantic/pull/12536#discussion_r2534473000"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12536,
      "file_path": "tests/test_decorators.py",
      "line": 146,
      "side": "RIGHT",
      "diff_hunk": "@@ -115,3 +115,32 @@ def serializer():\n         inspect_annotated_serializer(serializer, mode=mode)\n \n     assert e.value.code == 'field-serializer-signature'\n+\n+\n+def test_plain_class_not_mutated() -> None:\n+    class A:\n+        @computed_field\n+        def func(self) -> int:\n+            return 1\n+\n+    class B(A, BaseModel):\n+        pass\n+\n+    assert B.__pydantic_decorators__.computed_fields['func'].cls_var_name == 'func'\n+\n+    assert '__pydantic_decorators__' not in A.__dict__\n+\n+\n+def test_decorator_info_not_mutated() -> None:\n+    class A(BaseModel):\n+        @computed_field\n+        def func(self) -> int:\n+            return 1\n+\n+    assert A.__pydantic_decorators__.computed_fields['func'].info.title is None\n+\n+    class B(A, field_title_generator=lambda _, __: 'test'):\n+        pass\n+\n+    assert A.__pydantic_decorators__.computed_fields['func'].info.title is None\n+    assert B.__pydantic_decorators__.computed_fields['func'].info.title == 'test'",
      "comment": "It also applies to normal fields. In some way, the inheritance can be seen as a way to reuse existing fields, similar to what it means to make subclasses of `TypedDict`s. Anyway, this is only relevant for `field_title_generator` and `alias_generator` _and_ when subclassing and specifying these config, so quite unusual.",
      "comment_id": 2534611673,
      "user": "Viicos",
      "created_at": "2025-11-17T15:49:16Z",
      "url": "https://github.com/pydantic/pydantic/pull/12536#discussion_r2534611673"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12500,
      "file_path": "pydantic-core/tests/validators/test_decimal.py",
      "line": 120,
      "side": "RIGHT",
      "diff_hunk": "@@ -92,6 +92,41 @@ def test_decimal(py_and_json: PyAndJson, input_value, expected):\n         assert isinstance(output, Decimal)\n \n \n+@pytest.mark.parametrize(\n+    'input_value,expected',\n+    [\n+        # Three-tuple constructor: (sign, (digits...), exponent)\n+        # sign: 0 for positive, 1 for negative\n+        # digits: tuple of digits\n+        # exponent: integer exponent\n+        ((0, (1, 4, 1, 4), -3), Decimal('1.414')),\n+        ((0, (1, 2, 3), 0), Decimal('123')),\n+        ((0, (1, 2, 3), 2), Decimal('12300')),\n+        ((0, (1, 2, 3), -2), Decimal('1.23')),\n+        ((1, (1, 4, 1, 4), -3), Decimal('-1.414')),\n+        ((1, (1, 2, 3), 0), Decimal('-123')),\n+        ((1, (1, 2, 3), 2), Decimal('-12300')),\n+        ((1, (1, 2, 3), -2), Decimal('-1.23')),\n+        ((0, (0,), 0), Decimal('0')),\n+        ((0, (5,), -1), Decimal('0.5')),\n+        ((1, (5,), -1), Decimal('-0.5')),\n+        ((0, (1, 0, 0), -2), Decimal('1.00')),\n+        ((0, (9, 9, 9), 3), Decimal('999000')),\n+    ],\n+    ids=repr,\n+)\n+def test_decimal_three_tuple_constructor(py_and_json: PyAndJson, input_value, expected):\n+    \"\"\"Test that Decimal can be constructed from a three-tuple (sign, digits, exponent).\"\"\"\n+    v = py_and_json({'type': 'decimal'})",
      "comment": "```suggestion\r\n    v = py_and_json(cs.decimal_schema())\r\n```",
      "comment_id": 2517465961,
      "user": "Viicos",
      "created_at": "2025-11-12T09:00:41Z",
      "url": "https://github.com/pydantic/pydantic/pull/12500#discussion_r2517465961"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12500,
      "file_path": "pydantic-core/tests/validators/test_decimal.py",
      "line": 124,
      "side": "RIGHT",
      "diff_hunk": "@@ -92,6 +92,41 @@ def test_decimal(py_and_json: PyAndJson, input_value, expected):\n         assert isinstance(output, Decimal)\n \n \n+@pytest.mark.parametrize(\n+    'input_value,expected',\n+    [\n+        # Three-tuple constructor: (sign, (digits...), exponent)\n+        # sign: 0 for positive, 1 for negative\n+        # digits: tuple of digits\n+        # exponent: integer exponent\n+        ((0, (1, 4, 1, 4), -3), Decimal('1.414')),\n+        ((0, (1, 2, 3), 0), Decimal('123')),\n+        ((0, (1, 2, 3), 2), Decimal('12300')),\n+        ((0, (1, 2, 3), -2), Decimal('1.23')),\n+        ((1, (1, 4, 1, 4), -3), Decimal('-1.414')),\n+        ((1, (1, 2, 3), 0), Decimal('-123')),\n+        ((1, (1, 2, 3), 2), Decimal('-12300')),\n+        ((1, (1, 2, 3), -2), Decimal('-1.23')),\n+        ((0, (0,), 0), Decimal('0')),\n+        ((0, (5,), -1), Decimal('0.5')),\n+        ((1, (5,), -1), Decimal('-0.5')),\n+        ((0, (1, 0, 0), -2), Decimal('1.00')),\n+        ((0, (9, 9, 9), 3), Decimal('999000')),\n+    ],\n+    ids=repr,\n+)\n+def test_decimal_three_tuple_constructor(py_and_json: PyAndJson, input_value, expected):\n+    \"\"\"Test that Decimal can be constructed from a three-tuple (sign, digits, exponent).\"\"\"\n+    v = py_and_json({'type': 'decimal'})\n+    # Three-tuple constructor is only valid for Python input, not JSON\n+    if v.validator_type == 'json':\n+        # For JSON, we skip this test as tuples aren't JSON serializable\n+        pytest.skip('Three-tuple constructor is only valid for Python input')",
      "comment": "We actually want to validate in JSON as well (with array values).",
      "comment_id": 2517469953,
      "user": "Viicos",
      "created_at": "2025-11-12T09:01:44Z",
      "url": "https://github.com/pydantic/pydantic/pull/12500#discussion_r2517469953"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12373,
      "file_path": "tests/test_fields.py",
      "line": 371,
      "side": "RIGHT",
      "diff_hunk": "@@ -353,3 +353,19 @@ def test_default_factory_validated_data_argument_unsupported() -> None:\n         ),\n     ):\n         TypeAdapter(Annotated[int, Field(default_factory=lambda v: v['key'])])\n+\n+\n+def test_default_factory_without_validated_data_unsupported() -> None:\n+    with pytest.raises(ValueError):\n+\n+        class FooBar(BaseModel):\n+            a: int = Field(default_factory=lambda x: x)\n+\n+        [field.get_default(call_default_factory=True) for field in FooBar.model_fields.values()]\n+\n+\n+def test_default_factory_without_flag() -> None:\n+    class FooBar(BaseModel):\n+        a: int = Field(default_factory=lambda x: x)\n+\n+    assert [field.get_default() for field in FooBar.model_fields.values()] == [None]",
      "comment": "```suggestion\r\ndef test_default_factory_without_validated_data_unsupported() -> None:\r\n    class FooBar(BaseModel):\r\n        a: int = Field(default_factory=lambda x: x)\r\n \r\n    assert FooBar.model_fields['a'].get_default() is None\r\n          \r\n    with pytest.raises(ValueError):\r\n        FooBar.model_fields['a'].get_default(call_default_factory=True)\r\n```",
      "comment_id": 2418103389,
      "user": "Viicos",
      "created_at": "2025-10-09T22:39:14Z",
      "url": "https://github.com/pydantic/pydantic/pull/12373#discussion_r2418103389"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12511,
      "file_path": "pydantic/config.py",
      "line": 536,
      "side": "LEFT",
      "diff_hunk": "@@ -491,123 +491,70 @@ class Model(BaseModel):\n     # whether instances of models and dataclasses (including subclass instances) should re-validate, default 'never'\n     revalidate_instances: Literal['always', 'never', 'subclass-instances']\n     \"\"\"\n-    When and how to revalidate models and dataclasses during validation. Accepts the string\n-    values of `'never'`, `'always'` and `'subclass-instances'`. Defaults to `'never'`.\n+    When and how to revalidate models and dataclasses during validation. Can be one of:\n \n-    - `'never'` will not revalidate models and dataclasses during validation\n-    - `'always'` will revalidate models and dataclasses during validation\n-    - `'subclass-instances'` will revalidate models and dataclasses during validation if the instance is a\n+    - `'never'`: will *not* revalidate models and dataclasses during validation\n+    - `'always'`: will revalidate models and dataclasses during validation\n+    - `'subclass-instances'`: will revalidate models and dataclasses during validation if the instance is a\n         subclass of the model or dataclass\n \n-    By default, model and dataclass instances are not revalidated during validation.\n+    The default is `'never'` (no revalidation).\n+\n+    This configuration only affects *the current model* it is applied on, and does *not* populate to the models\n+    referenced in fields.\n \n     ```python\n     from pydantic import BaseModel\n \n     class User(BaseModel, revalidate_instances='never'):  # (1)!\n-        hobbies: list[str]\n-\n-    class SubUser(User):\n-        sins: list[str]\n+        name: str\n \n     class Transaction(BaseModel):\n         user: User\n \n-    my_user = User(hobbies=['reading'])\n+    my_user = User(name='John')\n     t = Transaction(user=my_user)\n-    print(t)\n-    #> user=User(hobbies=['reading'])\n \n-    my_user.hobbies = [1]  # (2)!\n+    my_user.name = 1  # (2)!\n     t = Transaction(user=my_user)  # (3)!\n     print(t)\n-    #> user=User(hobbies=[1])\n-\n-    my_sub_user = SubUser(hobbies=['scuba diving'], sins=['lying'])\n-    t = Transaction(user=my_sub_user)\n-    print(t)\n-    #> user=SubUser(hobbies=['scuba diving'], sins=['lying'])\n+    #> user=User(name=1)\n     ```\n \n-    1. `revalidate_instances` is set to `'never'` by **default.\n-    2. The assignment is not validated, unless you set `validate_assignment` to `True` in the model's config.\n-    3. Since `revalidate_instances` is set to `never`, this is not revalidated.\n+    1. This is the default behavior.\n+    2. The assignment is *not* validated, unless you set [`validate_assignment`][pydantic.ConfigDict.validate_assignment] in the configuration.\n+    3. Since `revalidate_instances` is set to `'never'`, the user instance is not revalidated.\n \n-    If you want to revalidate instances during validation, you can set `revalidate_instances` to `'always'`",
      "comment": "Don't think this example hurt but it's also fine to delete",
      "comment_id": 2512032415,
      "user": "davidhewitt",
      "created_at": "2025-11-10T21:32:03Z",
      "url": "https://github.com/pydantic/pydantic/pull/12511#discussion_r2512032415"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12511,
      "file_path": "pydantic/config.py",
      "line": 536,
      "side": "LEFT",
      "diff_hunk": "@@ -491,123 +491,70 @@ class Model(BaseModel):\n     # whether instances of models and dataclasses (including subclass instances) should re-validate, default 'never'\n     revalidate_instances: Literal['always', 'never', 'subclass-instances']\n     \"\"\"\n-    When and how to revalidate models and dataclasses during validation. Accepts the string\n-    values of `'never'`, `'always'` and `'subclass-instances'`. Defaults to `'never'`.\n+    When and how to revalidate models and dataclasses during validation. Can be one of:\n \n-    - `'never'` will not revalidate models and dataclasses during validation\n-    - `'always'` will revalidate models and dataclasses during validation\n-    - `'subclass-instances'` will revalidate models and dataclasses during validation if the instance is a\n+    - `'never'`: will *not* revalidate models and dataclasses during validation\n+    - `'always'`: will revalidate models and dataclasses during validation\n+    - `'subclass-instances'`: will revalidate models and dataclasses during validation if the instance is a\n         subclass of the model or dataclass\n \n-    By default, model and dataclass instances are not revalidated during validation.\n+    The default is `'never'` (no revalidation).\n+\n+    This configuration only affects *the current model* it is applied on, and does *not* populate to the models\n+    referenced in fields.\n \n     ```python\n     from pydantic import BaseModel\n \n     class User(BaseModel, revalidate_instances='never'):  # (1)!\n-        hobbies: list[str]\n-\n-    class SubUser(User):\n-        sins: list[str]\n+        name: str\n \n     class Transaction(BaseModel):\n         user: User\n \n-    my_user = User(hobbies=['reading'])\n+    my_user = User(name='John')\n     t = Transaction(user=my_user)\n-    print(t)\n-    #> user=User(hobbies=['reading'])\n \n-    my_user.hobbies = [1]  # (2)!\n+    my_user.name = 1  # (2)!\n     t = Transaction(user=my_user)  # (3)!\n     print(t)\n-    #> user=User(hobbies=[1])\n-\n-    my_sub_user = SubUser(hobbies=['scuba diving'], sins=['lying'])\n-    t = Transaction(user=my_sub_user)\n-    print(t)\n-    #> user=SubUser(hobbies=['scuba diving'], sins=['lying'])\n+    #> user=User(name=1)\n     ```\n \n-    1. `revalidate_instances` is set to `'never'` by **default.\n-    2. The assignment is not validated, unless you set `validate_assignment` to `True` in the model's config.\n-    3. Since `revalidate_instances` is set to `never`, this is not revalidated.\n+    1. This is the default behavior.\n+    2. The assignment is *not* validated, unless you set [`validate_assignment`][pydantic.ConfigDict.validate_assignment] in the configuration.\n+    3. Since `revalidate_instances` is set to `'never'`, the user instance is not revalidated.\n \n-    If you want to revalidate instances during validation, you can set `revalidate_instances` to `'always'`",
      "comment": "I kept only the `'subclass-instances'` example as it somehow also shows what is the behavior with a \"direct\" instance, and the fact that it is _not_ revalidated with `'subclass-instances'` (and then users can easily assume it would have been with `'always'`). I generally try to reduce the size of the examples as it adds cognitive overhead to understand them, and when I see too long examples by brain usually just gives up.",
      "comment_id": 2513568128,
      "user": "Viicos",
      "created_at": "2025-11-11T09:55:20Z",
      "url": "https://github.com/pydantic/pydantic/pull/12511#discussion_r2513568128"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12495,
      "file_path": "tests/test_dataclasses.py",
      "line": 706,
      "side": "RIGHT",
      "diff_hunk": "@@ -686,6 +686,35 @@ class TestInitVar:\n         TestInitVar(1, 2, 0)\n \n \n+def test_initvar_pydantic_field() -> None:\n+    @pydantic.dataclasses.dataclass\n+    class TestInitVar:\n+        x: InitVar[int] = Field(title='X')\n+\n+        def __post_init__(self, x: int):\n+            assert x == 1\n+\n+    assert TestInitVar.__pydantic_fields__['x'].init_var\n+\n+    t = TestInitVar(x=1)\n+\n+    with pytest.raises(AttributeError):\n+        t.x\n+\n+\n+@pytest.mark.xfail(reason='Ideally we should raise an attribute error, like stdlib dataclasses')\n+def test_initvar_pydantic_field() -> None:",
      "comment": "```suggestion\r\ndef test_initvar_pydantic_field_attribute_access() -> None:\r\n```",
      "comment_id": 2503936803,
      "user": "Viicos",
      "created_at": "2025-11-07T14:45:20Z",
      "url": "https://github.com/pydantic/pydantic/pull/12495#discussion_r2503936803"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12028,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 429,
      "side": "LEFT",
      "diff_hunk": "@@ -413,22 +411,6 @@ def collect_model_fields(  # noqa: C901\n     return fields, class_vars\n \n \n-def _warn_on_nested_alias_in_annotation(ann_type: type[Any], ann_name: str) -> None:\n-    FieldInfo = import_cached_field_info()\n-\n-    args = getattr(ann_type, '__args__', None)\n-    if args:\n-        for anno_arg in args:\n-            if typing_objects.is_annotated(get_origin(anno_arg)):\n-                for anno_type_arg in _typing_extra.get_args(anno_arg):\n-                    if isinstance(anno_type_arg, FieldInfo) and anno_type_arg.alias is not None:\n-                        warnings.warn(\n-                            f'`alias` specification on field \"{ann_name}\" must be set on outermost annotation to take effect.',\n-                            UserWarning,\n-                        )\n-                        return",
      "comment": "This was fragile logic implemented a long time ago, that is now fully covered by the new warning.",
      "comment_id": 2175579732,
      "user": "Viicos",
      "created_at": "2025-06-30T17:36:38Z",
      "url": "https://github.com/pydantic/pydantic/pull/12028#discussion_r2175579732"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12028,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 587,
      "side": "RIGHT",
      "diff_hunk": "@@ -562,7 +579,15 @@ def _mapping_schema(self, tp: Any, keys_type: Any, values_type: Any) -> CoreSche\n \n         mapped_origin = MAPPING_ORIGIN_MAP[tp]\n         keys_schema = self.generate_schema(keys_type)\n-        values_schema = self.generate_schema(values_type)\n+        with warnings.catch_warnings():\n+            # We kind of abused `Field()` default factories to be able to specify\n+            # the `defaultdict`'s `default_factory`. As a consequence, we get warnings\n+            # as normally `FieldInfo.default_factory` is unsupported in the context where\n+            # `Field()` is used and our only solution is to ignore them (note that this might\n+            # wrongfully ignore valid warnings, e.g. if the `value_type` to a PEP 695 type alias",
      "comment": "This is referring to the following use case:\n\n```python\nclass Model(BaseModel):\n    a: defaultdict[int, Annotated[list[int], Field(default_factory=lambda: MyList())]]\n```",
      "comment_id": 2175581350,
      "user": "Viicos",
      "created_at": "2025-06-30T17:37:55Z",
      "url": "https://github.com/pydantic/pydantic/pull/12028#discussion_r2175581350"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12028,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 1559,
      "side": "RIGHT",
      "diff_hunk": "@@ -1525,7 +1550,14 @@ def _generate_parameter_schema(\n         update_field_from_config(self._config_wrapper, name, field)\n \n         with self.field_name_stack.push(name):\n-            schema = self._apply_annotations(field.annotation, [field])\n+            schema = self._apply_annotations(\n+                field.annotation,\n+                [field],\n+                # Because we pass `field` as metadata above (required for attributes relevant for\n+                # JSON Scheme generation), we need to ignore the potential warnings about `FieldInfo`\n+                # attributes that will not be used:\n+                check_unsupported_field_info_attributes=False,",
      "comment": "This is for validated function calls (see `test_unsupported_field_attribute_nested_with_function()`). We don't want to raise a warning for:\n\n```python\n@validate_call\ndef func(a: Annotated[int, Field(alias='b')]): ...\n```",
      "comment_id": 2175584535,
      "user": "Viicos",
      "created_at": "2025-06-30T17:39:21Z",
      "url": "https://github.com/pydantic/pydantic/pull/12028#discussion_r2175584535"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12028,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 2220,
      "side": "RIGHT",
      "diff_hunk": "@@ -2159,10 +2202,27 @@ def inner_handler(obj: Any) -> CoreSchema:\n             update_core_metadata(core_metadata, pydantic_js_annotation_functions=pydantic_js_annotation_functions)\n         return _add_custom_serialization_from_json_encoders(self._config_wrapper.json_encoders, source_type, schema)\n \n-    def _apply_single_annotation(self, schema: core_schema.CoreSchema, metadata: Any) -> core_schema.CoreSchema:\n+    def _apply_single_annotation(\n+        self,\n+        schema: core_schema.CoreSchema,\n+        metadata: Any,\n+        check_unsupported_field_info_attributes: bool = True,\n+    ) -> core_schema.CoreSchema:\n         FieldInfo = import_cached_field_info()\n \n         if isinstance(metadata, FieldInfo):\n+            if check_unsupported_field_info_attributes and (\n+                unsupported_attributes := self._get_unsupported_field_info_attributes(metadata)\n+            ):\n+                for unsupported_attr in unsupported_attributes:\n+                    warnings.warn(\n+                        f'The {unsupported_attr[0]!r} attribute with value {unsupported_attr[1]!r} was provided '\n+                        'to the `Field()` function, which is unsupported in the context it was used. '",
      "comment": "```suggestion\n                        'to the `Field()` function, which has no effect in the context it was used. '\n```\n\nmaybe?",
      "comment_id": 2175585140,
      "user": "Viicos",
      "created_at": "2025-06-30T17:39:40Z",
      "url": "https://github.com/pydantic/pydantic/pull/12028#discussion_r2175585140"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12028,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 2217,
      "side": "RIGHT",
      "diff_hunk": "@@ -2158,10 +2202,27 @@ def inner_handler(obj: Any) -> CoreSchema:\n             update_core_metadata(core_metadata, pydantic_js_annotation_functions=pydantic_js_annotation_functions)\n         return _add_custom_serialization_from_json_encoders(self._config_wrapper.json_encoders, source_type, schema)\n \n-    def _apply_single_annotation(self, schema: core_schema.CoreSchema, metadata: Any) -> core_schema.CoreSchema:\n+    def _apply_single_annotation(\n+        self,\n+        schema: core_schema.CoreSchema,\n+        metadata: Any,\n+        check_unsupported_field_info_attributes: bool = True,\n+    ) -> core_schema.CoreSchema:\n         FieldInfo = import_cached_field_info()\n \n         if isinstance(metadata, FieldInfo):\n+            if check_unsupported_field_info_attributes and (\n+                unsupported_attributes := self._get_unsupported_field_info_attributes(metadata)\n+            ):\n+                for unsupported_attr in unsupported_attributes:",
      "comment": "Can we do `for (attr, value) in unsupported_attributes` so we don't need `[0]` and `[1]`?",
      "comment_id": 2177807207,
      "user": "DouweM",
      "created_at": "2025-07-01T14:46:54Z",
      "url": "https://github.com/pydantic/pydantic/pull/12028#discussion_r2177807207"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12028,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 2285,
      "side": "RIGHT",
      "diff_hunk": "@@ -2216,11 +2277,34 @@ def _apply_single_annotation_json_schema(\n             )\n         return schema\n \n+    def _get_unsupported_field_info_attributes(self, field_info: FieldInfo) -> list[tuple[str, Any]]:\n+        \"\"\"Get the list of unsupported `FieldInfo` attributes when not directly used in `Annotated` for field annotations.\"\"\"\n+        unused_metadata: list[tuple[str, Any]] = []\n+        for unused_metadata_name in UNSUPPORTED_STANDALONE_FIELDINFO_ATTRIBUTES:\n+            if (\n+                unused_metadata_name in field_info._attributes_set",
      "comment": "If we make `UNSUPPORTED_STANDALONE_FIELDINFO_ATTRIBUTES` a set as well, we could potentially clean this up a bit by using `unsupported_attributes = UNSUPPORTED_STANDALONE_FIELDINFO_ATTRIBUTES & field_info._attributes_set` and then iterating over those\r\n\r\nEdit: Likely not relevant because we added the default values to `UNSUPPORTED_STANDALONE_FIELDINFO_ATTRIBUTES` in a later commit",
      "comment_id": 2177816765,
      "user": "DouweM",
      "created_at": "2025-07-01T14:49:09Z",
      "url": "https://github.com/pydantic/pydantic/pull/12028#discussion_r2177816765"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12420,
      "file_path": "tests/test_validators.py",
      "line": 3105,
      "side": "RIGHT",
      "diff_hunk": "@@ -3101,3 +3101,23 @@ def wrapped_field_serializer(cls, field_value, validator):\n \n     my_model = MyParentModel.model_validate({'nested': {'inner_value': 'foo'}})\n     assert my_model.nested.inner_value == 'after_prefix:wrap_prefix:foo'\n+\n+@pytest.mark.xfail(reason=\"Bug: Nested 'after' model_validator is re-executed. See issue #8452.\", raises=AssertionError)",
      "comment": "```suggestion\n@pytest.mark.xfail(reason=\"Bug: Nested 'after' model_validator is re-executed. See issue #8452.\", raises=ValidationError)\n```",
      "comment_id": 2454969535,
      "user": "davidhewitt",
      "created_at": "2025-10-23T12:31:46Z",
      "url": "https://github.com/pydantic/pydantic/pull/12420#discussion_r2454969535"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12420,
      "file_path": "tests/test_validators.py",
      "line": 3123,
      "side": "RIGHT",
      "diff_hunk": "@@ -3101,3 +3101,23 @@ def wrapped_field_serializer(cls, field_value, validator):\n \n     my_model = MyParentModel.model_validate({'nested': {'inner_value': 'foo'}})\n     assert my_model.nested.inner_value == 'after_prefix:wrap_prefix:foo'\n+\n+@pytest.mark.xfail(reason=\"Bug: Nested 'after' model_validator is re-executed. See issue #8452.\", raises=AssertionError)\n+def test_nested_model_validator_not_reexecuted():\n+    \"\"\"See https://github.com/pydantic/pydantic/issues/8452 for context.\n+\n+    Reproduces the bug in issue #8452 where a nested model's `model_validator` with `mode='after'` is unexpectedly re-executed.\n+    \"\"\"\n+    class Sub(BaseModel):\n+        @model_validator(mode='after')\n+        def _validate(self):\n+            # This line should not be reached when `Sub` is nested inside `Base`\n+            assert False, 'Sub model_validator was re-executed'\n+\n+    class Base(BaseModel):\n+        sub: Sub #<-- This throws assertionerror\n+\n+    sub: Sub = Sub.model_construct() # Create a Sub instance without triggering validation (e.g., using model_construct)\n+    \n+    # Attempt to create Base with the Sub instance. This line should succeed if the bug is fixed, but currently raises ValidationError.\n+    base: Base = Base(sub=sub) # <-- This throws AssertionError because Sub's 'after' validator runs again.",
      "comment": "```suggestion\n    Base(sub=sub) # <-- This throws AssertionError because Sub's 'after' validator runs again.\n```",
      "comment_id": 2454970072,
      "user": "davidhewitt",
      "created_at": "2025-10-23T12:31:56Z",
      "url": "https://github.com/pydantic/pydantic/pull/12420#discussion_r2454970072"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12430,
      "file_path": "pydantic/json_schema.py",
      "line": 1760,
      "side": "LEFT",
      "diff_hunk": "@@ -1756,13 +1756,19 @@ def field_is_required(\n         Returns:\n             `True` if the field should be marked as required in the generated JSON schema, `False` otherwise.\n         \"\"\"\n-        if self.mode == 'serialization' and self._config.json_schema_serialization_defaults_required:\n-            return not field.get('serialization_exclude')",
      "comment": "Note that there's a change in behavior here, but should be considered as a bug fix: we only take into account `serialization_exclude` if `json_schema_serialization_defaults_required=True`, which doesn't really make sense.",
      "comment_id": 2445335651,
      "user": "Viicos",
      "created_at": "2025-10-20T15:20:08Z",
      "url": "https://github.com/pydantic/pydantic/pull/12430#discussion_r2445335651"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12411,
      "file_path": "pydantic/fields.py",
      "line": 241,
      "side": "RIGHT",
      "diff_hunk": "@@ -215,10 +231,14 @@ def __init__(self, **kwargs: Unpack[_FieldInfoInputs]) -> None:\n \n         See the signature of `pydantic.fields.Field` for more details about the expected arguments.\n         \"\"\"\n+        # Tracking the explicitly set attributes is necessary to correctly merge `Field()` functions\n+        # (e.g. with `Annotated[int, Field(alias='a'), Field(alias=None)]`, even though `None` is the default value,\n+        # we need to track that `alias=None` was explicitly set):\n         self._attributes_set = {k: v for k, v in kwargs.items() if v is not _Unset and k not in self.metadata_lookup}\n         kwargs = {k: _DefaultValues.get(k) if v is _Unset else v for k, v in kwargs.items()}  # type: ignore\n         self.annotation = kwargs.get('annotation')\n \n+        # Note: in theory, the second `pop()` arguments are not required below, as defaults are already set from `_DefaultsValues`.",
      "comment": "As you can see in this PR, I added the missing default values in `_DefaultsValues`, including the one for `deprecated` (but it is only bound to happen again with this complex logic..)  ",
      "comment_id": 2439409032,
      "user": "Viicos",
      "created_at": "2025-10-17T11:14:09Z",
      "url": "https://github.com/pydantic/pydantic/pull/12411#discussion_r2439409032"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11957,
      "file_path": "pydantic/functional_validators.py",
      "line": 716,
      "side": "RIGHT",
      "diff_hunk": "@@ -713,7 +713,8 @@ def verify_square(self) -> Self:\n \n     def dec(f: Any) -> _decorators.PydanticDescriptorProxy[Any]:\n         # auto apply the @classmethod decorator\n-        f = _decorators.ensure_classmethod_based_on_signature(f)\n+        if mode != 'after':",
      "comment": "I think it's worth putting a comment in to explain why we want this in all modes except for `after`.",
      "comment_id": 2143334773,
      "user": "DouweM",
      "created_at": "2025-06-12T17:55:58Z",
      "url": "https://github.com/pydantic/pydantic/pull/11957#discussion_r2143334773"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11957,
      "file_path": "tests/test_model_validator.py",
      "line": 148,
      "side": "RIGHT",
      "diff_hunk": "@@ -136,3 +136,13 @@ def validate_model_after(self) -> Model:\n     Model.model_validate({'inner': {'inner': {'inner': None}}})\n     assert calls == ['before'] * 3 + ['after'] * 3\n     calls.clear()\n+\n+\n+def test_after_validator_wrong_signature() -> None:\n+    with pytest.raises(PydanticUserError):\n+\n+        class Model(BaseModel):\n+            @model_validator(mode='after')\n+            # This used to be converted into a classmethod, resulting\n+            # in this inconsistent signature still accepted:\n+            def validator(cls, model, info): ...",
      "comment": "Shouldn't this be `self` instead of `cls` in this case?",
      "comment_id": 2417020325,
      "user": "antazoey",
      "created_at": "2025-10-09T14:32:44Z",
      "url": "https://github.com/pydantic/pydantic/pull/11957#discussion_r2417020325"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11957,
      "file_path": "tests/test_model_validator.py",
      "line": 148,
      "side": "RIGHT",
      "diff_hunk": "@@ -136,3 +136,13 @@ def validate_model_after(self) -> Model:\n     Model.model_validate({'inner': {'inner': {'inner': None}}})\n     assert calls == ['before'] * 3 + ['after'] * 3\n     calls.clear()\n+\n+\n+def test_after_validator_wrong_signature() -> None:\n+    with pytest.raises(PydanticUserError):\n+\n+        class Model(BaseModel):\n+            @model_validator(mode='after')\n+            # This used to be converted into a classmethod, resulting\n+            # in this inconsistent signature still accepted:\n+            def validator(cls, model, info): ...",
      "comment": "This is wrapped in a `pytest.raises()` context manager, and was meant to test that this particular invalid signature is now rejected.",
      "comment_id": 2417108247,
      "user": "Viicos",
      "created_at": "2025-10-09T15:17:37Z",
      "url": "https://github.com/pydantic/pydantic/pull/11957#discussion_r2417108247"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12366,
      "file_path": "pydantic/_internal/_decorators.py",
      "line": 560,
      "side": "RIGHT",
      "diff_hunk": "@@ -554,7 +557,7 @@ def inspect_validator(validator: Callable[..., Any], mode: FieldValidatorModes)\n             return False\n \n     raise PydanticUserError(\n-        f'Unrecognized field_validator function signature for {validator} with `mode={mode}`:{sig}',\n+        f'Unrecognized {type} function signature for {validator} with `mode={mode}`: {sig}',",
      "comment": "```suggestion\n        f'Unrecognized {type}_validator function signature for {validator} with `mode={mode}`: {sig}',\n```",
      "comment_id": 2419159200,
      "user": "davidhewitt",
      "created_at": "2025-10-10T10:00:22Z",
      "url": "https://github.com/pydantic/pydantic/pull/12366#discussion_r2419159200"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12366,
      "file_path": "pydantic/_internal/_decorators.py",
      "line": 560,
      "side": "RIGHT",
      "diff_hunk": "@@ -554,7 +557,7 @@ def inspect_validator(validator: Callable[..., Any], mode: FieldValidatorModes)\n             return False\n \n     raise PydanticUserError(\n-        f'Unrecognized field_validator function signature for {validator} with `mode={mode}`:{sig}',\n+        f'Unrecognized {type} function signature for {validator} with `mode={mode}`: {sig}',",
      "comment": "I removed the underscore in particular for field validators, that aren't necessarily defined using the `@field_validator` decorator (i.e. with the `*Validator` metadata classes).",
      "comment_id": 2422854022,
      "user": "Viicos",
      "created_at": "2025-10-11T13:41:53Z",
      "url": "https://github.com/pydantic/pydantic/pull/12366#discussion_r2422854022"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12370,
      "file_path": "pydantic/_internal/_typing_extra.py",
      "line": 522,
      "side": "RIGHT",
      "diff_hunk": "@@ -518,7 +518,19 @@ def _eval_type(\n     localns: MappingNamespace | None = None,\n     type_params: tuple[Any, ...] | None = None,\n ) -> Any:\n-    if sys.version_info >= (3, 13):\n+    if sys.version_info >= (3, 14):\n+        # Starting in 3.14, `_eval_type()` does *not* apply `_type_convert()`",
      "comment": "Did `_type_convert()` do anything else, do those cases also matter?",
      "comment_id": 2419153873,
      "user": "davidhewitt",
      "created_at": "2025-10-10T09:57:55Z",
      "url": "https://github.com/pydantic/pydantic/pull/12370#discussion_r2419153873"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12370,
      "file_path": "pydantic/_internal/_typing_extra.py",
      "line": 522,
      "side": "RIGHT",
      "diff_hunk": "@@ -518,7 +518,19 @@ def _eval_type(\n     localns: MappingNamespace | None = None,\n     type_params: tuple[Any, ...] | None = None,\n ) -> Any:\n-    if sys.version_info >= (3, 13):\n+    if sys.version_info >= (3, 14):\n+        # Starting in 3.14, `_eval_type()` does *not* apply `_type_convert()`",
      "comment": "It converts str values to forward refs, but this is already handled by `_eval_type()` so after calling it we are guaranteed to not have to deal with forward refs anymore.",
      "comment_id": 2422853593,
      "user": "Viicos",
      "created_at": "2025-10-11T13:40:48Z",
      "url": "https://github.com/pydantic/pydantic/pull/12370#discussion_r2422853593"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12355,
      "file_path": "tests/test_deferred_annotations.py",
      "line": 93,
      "side": "RIGHT",
      "diff_hunk": "@@ -80,3 +88,31 @@ class A:\n     Int = int\n \n     assert A(a='1').a == 1\n+\n+\n+def test_deferred_annotations_return_values() -> None:",
      "comment": "The decorated function inspection doesn't special case modes, so I think this should be fine",
      "comment_id": 2413886829,
      "user": "Viicos",
      "created_at": "2025-10-08T13:34:51Z",
      "url": "https://github.com/pydantic/pydantic/pull/12355#discussion_r2413886829"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12001,
      "file_path": "pydantic/main.py",
      "line": 1751,
      "side": "RIGHT",
      "diff_hunk": "@@ -1744,6 +1748,7 @@ def create_model(  # noqa: C901\n     namespace: dict[str, Any] = {'__annotations__': annotations, '__module__': __module__}\n     if __doc__:\n         namespace.update({'__doc__': __doc__})\n+    namespace.update({'__qualname__': __qualname__ or model_name})",
      "comment": "```suggestion\r\n    if __qualname__ is not None:\r\n        namespace.update({'__qualname__': __qualname__})\r\n```",
      "comment_id": 2410781701,
      "user": "Viicos",
      "created_at": "2025-10-07T14:10:30Z",
      "url": "https://github.com/pydantic/pydantic/pull/12001#discussion_r2410781701"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12001,
      "file_path": "pydantic/main.py",
      "line": 1752,
      "side": "RIGHT",
      "diff_hunk": "@@ -1744,6 +1748,8 @@ def create_model(  # noqa: C901\n     namespace: dict[str, Any] = {'__annotations__': annotations, '__module__': __module__}\n     if __doc__:\n         namespace.update({'__doc__': __doc__})\n+    if __qualname__ is not None:\n+        namespace.update({'__qualname__': __qualname__})",
      "comment": "```suggestion\r\n    if __doc__:\r\n        namespace['__doc__'] = __doc__\r\n    if __qualname__ is not None:\r\n        namespace['__qualname__'] = __qualname__\r\n```",
      "comment_id": 2410797171,
      "user": "Viicos",
      "created_at": "2025-10-07T14:15:13Z",
      "url": "https://github.com/pydantic/pydantic/pull/12001#discussion_r2410797171"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12147,
      "file_path": "pydantic/main.py",
      "line": 544,
      "side": "RIGHT",
      "diff_hunk": "@@ -541,6 +541,7 @@ def model_json_schema(\n         cls,\n         by_alias: bool = True,\n         ref_template: str = DEFAULT_REF_TEMPLATE,\n+        union_format: Literal['any_of', 'primitive_type_array'] = 'any_of',",
      "comment": "Adding extra parameters like this is fine, but can be annoying for users subclassing `BaseModel` and overriding the `model_json_schema()` method, as they will need to update the definition.\r\n\r\nOne alternative is to have a single parameter (e.g. `TypedDict`) holding all the configuration, but it adds complexity on the caller side:\r\n\r\n```python\r\nModel.model_json_schema(settings={'union_format': ...})\r\n```\r\n\r\nAnd overriding the method isn't really a robust solution anyway.\r\n\r\nHowever, we should definitely make these keyword only. This will be a breaking change, so either we do it know but make sure to properly announce it, or wait for V3 (and use deprecated overloads until then).",
      "comment_id": 2261377497,
      "user": "Viicos",
      "created_at": "2025-08-07T20:54:58Z",
      "url": "https://github.com/pydantic/pydantic/pull/12147#discussion_r2261377497"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12147,
      "file_path": "pydantic/main.py",
      "line": 544,
      "side": "RIGHT",
      "diff_hunk": "@@ -541,6 +541,7 @@ def model_json_schema(\n         cls,\n         by_alias: bool = True,\n         ref_template: str = DEFAULT_REF_TEMPLATE,\n+        union_format: Literal['any_of', 'primitive_type_array'] = 'any_of',",
      "comment": "Can you make `union_format` keyword-only now, and leave the rest for later? I guess that would also then not be breaking?",
      "comment_id": 2401562807,
      "user": "davidhewitt",
      "created_at": "2025-10-03T11:15:56Z",
      "url": "https://github.com/pydantic/pydantic/pull/12147#discussion_r2401562807"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12147,
      "file_path": "tests/test_json_schema.py",
      "line": 7131,
      "side": "RIGHT",
      "diff_hunk": "@@ -7072,3 +7073,58 @@ def test_decimal_pattern_reject_invalid_not_numerical_values_with_decimal_places\n ) -> None:\n     pattern = get_decimal_pattern()\n     assert re.fullmatch(pattern, invalid_decimal) is None\n+\n+\n+def test_union_format_primitive_type_array() -> None:\n+    class Sub(BaseModel):\n+        pass\n+\n+    class Model(BaseModel):\n+        a: Optional[int]\n+        b: Union[int, str, bool]\n+        c: Union[Annotated[str, Field(max_length=3)], Annotated[str, Field(min_length=5)]]\n+        d: Union[int, str, Annotated[bool, Field(description='test')]]\n+        e: Union[int, list[int]]\n+        f: Union[int, Sub]\n+\n+    assert Model.model_json_schema(union_format='primitive_type_array') == {\n+        '$defs': {'Sub': {'properties': {}, 'title': 'Sub', 'type': 'object'}},\n+        'properties': {\n+            'a': {'title': 'A', 'type': ['integer', 'null']},\n+            'b': {'title': 'B', 'type': ['integer', 'string', 'boolean']},\n+            'c': {\n+                'anyOf': [\n+                    {'maxLength': 3, 'type': 'string'},\n+                    {'minLength': 5, 'type': 'string'},\n+                ],\n+                'title': 'C',\n+            },\n+            'd': {\n+                'anyOf': [\n+                    {'type': 'integer'},\n+                    {'type': 'string'},\n+                    {'description': 'test', 'type': 'boolean'},\n+                ],\n+                'title': 'D',\n+            },\n+            'e': {\n+                'anyOf': [\n+                    {'type': 'integer'},\n+                    {'items': {'type': 'integer'}, 'type': 'array'},\n+                ],\n+                'title': 'E',\n+            },\n+            'f': {'anyOf': [{'type': 'integer'}, {'$ref': '#/$defs/Sub'}], 'title': 'F'},\n+        },\n+        'required': ['a', 'b', 'c', 'd', 'e', 'f'],\n+        'title': 'Model',\n+        'type': 'object',\n+    }\n+\n+\n+def test_union_format_primitive_type_array_deduplicated() -> None:\n+    gen_js = GenerateJsonSchema(union_format='primitive_type_array')\n+\n+    assert gen_js.union_schema(\n+        core_schema.union_schema([core_schema.int_schema(), core_schema.str_schema(), core_schema.int_schema()])\n+    ) == {'type': ['integer', 'string']}",
      "comment": "Maybe add a case where there's a str schema with a constraint too, and check the result still deduplicates the ints even if it switches back to `anyOf`?",
      "comment_id": 2401567816,
      "user": "davidhewitt",
      "created_at": "2025-10-03T11:18:52Z",
      "url": "https://github.com/pydantic/pydantic/pull/12147#discussion_r2401567816"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12147,
      "file_path": "pydantic/main.py",
      "line": 544,
      "side": "RIGHT",
      "diff_hunk": "@@ -541,6 +541,7 @@ def model_json_schema(\n         cls,\n         by_alias: bool = True,\n         ref_template: str = DEFAULT_REF_TEMPLATE,\n+        union_format: Literal['any_of', 'primitive_type_array'] = 'any_of',",
      "comment": ":+1: , created https://github.com/pydantic/pydantic/issues/12332 as well.",
      "comment_id": 2406276369,
      "user": "Viicos",
      "created_at": "2025-10-06T13:22:12Z",
      "url": "https://github.com/pydantic/pydantic/pull/12147#discussion_r2406276369"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11987,
      "file_path": "tests/test_json_schema.py",
      "line": 6951,
      "side": "RIGHT",
      "diff_hunk": "@@ -6811,3 +6946,147 @@ def test_json_schema_arguments_v3_aliases() -> None:\n         },\n         'required': ['b'],\n     }\n+\n+\n+class TestDecimalPattern:",
      "comment": "Let's flatten this to use functions instead of methods.",
      "comment_id": 2180865070,
      "user": "Viicos",
      "created_at": "2025-07-02T19:56:07Z",
      "url": "https://github.com/pydantic/pydantic/pull/11987#discussion_r2180865070"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11987,
      "file_path": "pydantic/json_schema.py",
      "line": 690,
      "side": "RIGHT",
      "diff_hunk": "@@ -674,7 +674,31 @@ def decimal_schema(self, schema: core_schema.DecimalSchema) -> JsonSchemaValue:\n         Returns:\n             The generated JSON schema.\n         \"\"\"\n-        json_schema = self.str_schema(core_schema.str_schema())\n+\n+        def get_decimal_pattern(schema: core_schema.DecimalSchema) -> str:\n+            max_digits = schema.get('max_digits', '')\n+            decimal_places = schema.get('decimal_places', '')\n+            integer_places = max_digits\n+\n+            if isinstance(max_digits, int) and isinstance(decimal_places, int):\n+                if (diff := max_digits - decimal_places) > 0:\n+                    integer_places = diff\n+                else:\n+                    integer_places = 0\n+\n+            pattern = (\n+                r'^(?!^[+-\\.]*$)'  # check string is not empty and not single or sequence of \".+-\" characters.",
      "comment": "I think you don't need to escape the `.` when inside brackets.",
      "comment_id": 2180866129,
      "user": "Viicos",
      "created_at": "2025-07-02T19:56:48Z",
      "url": "https://github.com/pydantic/pydantic/pull/11987#discussion_r2180866129"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11987,
      "file_path": "tests/test_json_schema.py",
      "line": 6951,
      "side": "RIGHT",
      "diff_hunk": "@@ -6811,3 +6946,147 @@ def test_json_schema_arguments_v3_aliases() -> None:\n         },\n         'required': ['b'],\n     }\n+\n+\n+class TestDecimalPattern:",
      "comment": "Resolved with [this commit](https://github.com/pydantic/pydantic/pull/11987/commits/73afd017f4cb1683540cdc08f3601dc90886cd61)\r\n",
      "comment_id": 2184144466,
      "user": "Dima-Bulavenko",
      "created_at": "2025-07-04T02:16:08Z",
      "url": "https://github.com/pydantic/pydantic/pull/11987#discussion_r2184144466"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11987,
      "file_path": "pydantic/json_schema.py",
      "line": 690,
      "side": "RIGHT",
      "diff_hunk": "@@ -674,7 +674,31 @@ def decimal_schema(self, schema: core_schema.DecimalSchema) -> JsonSchemaValue:\n         Returns:\n             The generated JSON schema.\n         \"\"\"\n-        json_schema = self.str_schema(core_schema.str_schema())\n+\n+        def get_decimal_pattern(schema: core_schema.DecimalSchema) -> str:\n+            max_digits = schema.get('max_digits', '')\n+            decimal_places = schema.get('decimal_places', '')\n+            integer_places = max_digits\n+\n+            if isinstance(max_digits, int) and isinstance(decimal_places, int):\n+                if (diff := max_digits - decimal_places) > 0:\n+                    integer_places = diff\n+                else:\n+                    integer_places = 0\n+\n+            pattern = (\n+                r'^(?!^[+-\\.]*$)'  # check string is not empty and not single or sequence of \".+-\" characters.",
      "comment": "Thanks for pointing that out! I\u2019ve resolved it in commit https://github.com/pydantic/pydantic/commit/5874292e75f955fe80334c7c083be0832edcf0df.",
      "comment_id": 2184340350,
      "user": "Dima-Bulavenko",
      "created_at": "2025-07-04T04:38:24Z",
      "url": "https://github.com/pydantic/pydantic/pull/11987#discussion_r2184340350"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11987,
      "file_path": "pydantic/json_schema.py",
      "line": 715,
      "side": "RIGHT",
      "diff_hunk": "@@ -674,7 +674,49 @@ def decimal_schema(self, schema: core_schema.DecimalSchema) -> JsonSchemaValue:\n         Returns:\n             The generated JSON schema.\n         \"\"\"\n-        json_schema = self.str_schema(core_schema.str_schema())\n+\n+        def get_decimal_pattern(schema: core_schema.DecimalSchema) -> str:\n+            max_digits = schema.get('max_digits')\n+            decimal_places = schema.get('decimal_places')\n+\n+            pattern = (\n+                r'^(?!^[-+.]*$)[+-]?0*'  # check it is not empty string and not one or sequence of \".+-\" characters.\n+            )\n+\n+            # Case 1: Both max_digits and decimal_places are set\n+            if max_digits is not None and decimal_places is not None:\n+                integer_places = max(0, max_digits - decimal_places)\n+                pattern += (\n+                    rf'(?:'\n+                    rf'\\d{{0,{integer_places}}}'\n+                    rf'|'\n+                    rf'(?=[\\d.]{{1,{max_digits + 1}}}0*$)'\n+                    rf'\\d{{0,{integer_places}}}\\.\\d{{0,{decimal_places}}}0*$'\n+                    rf')'\n+                )\n+\n+            # Case 2: Only max_digits is set\n+            elif max_digits is not None and decimal_places is None:\n+                pattern += (\n+                    rf'(?:'\n+                    rf'\\d{{0,{max_digits}}}'\n+                    rf'|'\n+                    rf'(?=[\\d.]{{1,{max_digits + 1}}}0*$)'\n+                    rf'\\d*\\.\\d*0*$'\n+                    rf')'\n+                )\n+\n+            # Case 3: Only decimal_places is set\n+            elif max_digits is None and decimal_places is not None:\n+                pattern += rf'\\d*\\.?\\d{{0,{decimal_places}}}0*$'\n+\n+            # Case 4: Both are None (no restrictions)\n+            else:\n+                pattern += r'\\d*\\.?\\d*$'  # look for arbitrary integer or decimal",
      "comment": "This allows `'.'` as an input, which can't be validated.",
      "comment_id": 2187005604,
      "user": "Viicos",
      "created_at": "2025-07-05T09:17:10Z",
      "url": "https://github.com/pydantic/pydantic/pull/11987#discussion_r2187005604"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11987,
      "file_path": "pydantic/json_schema.py",
      "line": 699,
      "side": "RIGHT",
      "diff_hunk": "@@ -674,7 +674,49 @@ def decimal_schema(self, schema: core_schema.DecimalSchema) -> JsonSchemaValue:\n         Returns:\n             The generated JSON schema.\n         \"\"\"\n-        json_schema = self.str_schema(core_schema.str_schema())\n+\n+        def get_decimal_pattern(schema: core_schema.DecimalSchema) -> str:\n+            max_digits = schema.get('max_digits')\n+            decimal_places = schema.get('decimal_places')\n+\n+            pattern = (\n+                r'^(?!^[-+.]*$)[+-]?0*'  # check it is not empty string and not one or sequence of \".+-\" characters.\n+            )\n+\n+            # Case 1: Both max_digits and decimal_places are set\n+            if max_digits is not None and decimal_places is not None:\n+                integer_places = max(0, max_digits - decimal_places)\n+                pattern += (\n+                    rf'(?:'\n+                    rf'\\d{{0,{integer_places}}}'\n+                    rf'|'\n+                    rf'(?=[\\d.]{{1,{max_digits + 1}}}0*$)'\n+                    rf'\\d{{0,{integer_places}}}\\.\\d{{0,{decimal_places}}}0*$'\n+                    rf')'\n+                )\n+\n+            # Case 2: Only max_digits is set\n+            elif max_digits is not None and decimal_places is None:",
      "comment": "With `max_digits` set to e.g. 5, it wrongfully matches `'1000.1111111'`, etc.",
      "comment_id": 2187013721,
      "user": "Viicos",
      "created_at": "2025-07-05T09:26:46Z",
      "url": "https://github.com/pydantic/pydantic/pull/11987#discussion_r2187013721"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11987,
      "file_path": "pydantic/json_schema.py",
      "line": 715,
      "side": "RIGHT",
      "diff_hunk": "@@ -674,7 +674,49 @@ def decimal_schema(self, schema: core_schema.DecimalSchema) -> JsonSchemaValue:\n         Returns:\n             The generated JSON schema.\n         \"\"\"\n-        json_schema = self.str_schema(core_schema.str_schema())\n+\n+        def get_decimal_pattern(schema: core_schema.DecimalSchema) -> str:\n+            max_digits = schema.get('max_digits')\n+            decimal_places = schema.get('decimal_places')\n+\n+            pattern = (\n+                r'^(?!^[-+.]*$)[+-]?0*'  # check it is not empty string and not one or sequence of \".+-\" characters.\n+            )\n+\n+            # Case 1: Both max_digits and decimal_places are set\n+            if max_digits is not None and decimal_places is not None:\n+                integer_places = max(0, max_digits - decimal_places)\n+                pattern += (\n+                    rf'(?:'\n+                    rf'\\d{{0,{integer_places}}}'\n+                    rf'|'\n+                    rf'(?=[\\d.]{{1,{max_digits + 1}}}0*$)'\n+                    rf'\\d{{0,{integer_places}}}\\.\\d{{0,{decimal_places}}}0*$'\n+                    rf')'\n+                )\n+\n+            # Case 2: Only max_digits is set\n+            elif max_digits is not None and decimal_places is None:\n+                pattern += (\n+                    rf'(?:'\n+                    rf'\\d{{0,{max_digits}}}'\n+                    rf'|'\n+                    rf'(?=[\\d.]{{1,{max_digits + 1}}}0*$)'\n+                    rf'\\d*\\.\\d*0*$'\n+                    rf')'\n+                )\n+\n+            # Case 3: Only decimal_places is set\n+            elif max_digits is None and decimal_places is not None:\n+                pattern += rf'\\d*\\.?\\d{{0,{decimal_places}}}0*$'\n+\n+            # Case 4: Both are None (no restrictions)\n+            else:\n+                pattern += r'\\d*\\.?\\d*$'  # look for arbitrary integer or decimal",
      "comment": "Thank you for pointing this out.\r\nHowever, `r'\\d*\\.?\\d*$'` is not the full pattern used for validation.\r\n\r\nThe complete pattern includes an additional regex component that prevents `'.'` from being a valid input:\r\nhttps://github.com/pydantic/pydantic/blob/88adb2d4806a37fd21ae06f88d4670190759974f/pydantic/json_schema.py#L682-L684\r\n\r\nAdditionally, the edge case for `'.'` is covered by the following test:\r\nhttps://github.com/pydantic/pydantic/blob/88adb2d4806a37fd21ae06f88d4670190759974f/tests/test_json_schema.py#L7005-L7009",
      "comment_id": 2187273655,
      "user": "Dima-Bulavenko",
      "created_at": "2025-07-05T13:35:22Z",
      "url": "https://github.com/pydantic/pydantic/pull/11987#discussion_r2187273655"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11987,
      "file_path": "pydantic/json_schema.py",
      "line": 699,
      "side": "RIGHT",
      "diff_hunk": "@@ -674,7 +674,49 @@ def decimal_schema(self, schema: core_schema.DecimalSchema) -> JsonSchemaValue:\n         Returns:\n             The generated JSON schema.\n         \"\"\"\n-        json_schema = self.str_schema(core_schema.str_schema())\n+\n+        def get_decimal_pattern(schema: core_schema.DecimalSchema) -> str:\n+            max_digits = schema.get('max_digits')\n+            decimal_places = schema.get('decimal_places')\n+\n+            pattern = (\n+                r'^(?!^[-+.]*$)[+-]?0*'  # check it is not empty string and not one or sequence of \".+-\" characters.\n+            )\n+\n+            # Case 1: Both max_digits and decimal_places are set\n+            if max_digits is not None and decimal_places is not None:\n+                integer_places = max(0, max_digits - decimal_places)\n+                pattern += (\n+                    rf'(?:'\n+                    rf'\\d{{0,{integer_places}}}'\n+                    rf'|'\n+                    rf'(?=[\\d.]{{1,{max_digits + 1}}}0*$)'\n+                    rf'\\d{{0,{integer_places}}}\\.\\d{{0,{decimal_places}}}0*$'\n+                    rf')'\n+                )\n+\n+            # Case 2: Only max_digits is set\n+            elif max_digits is not None and decimal_places is None:",
      "comment": "Thank you for your feedback.\r\n\r\nFrom my testing, the pattern appears to work correctly when\u00a0`max_digits=5`\u00a0and the invalid value\u00a0`'1000.1111111'`\u00a0is rejected as expected.\r\n\r\nHere is a test demonstrating this behavior:\r\n```python\r\n@pytest.fixture\r\ndef get_decimal_pattern():\r\n    def pattern(max_digits=None, decimal_places=None) -> str:\r\n        field = TypeAdapter(Annotated[Decimal, Field(max_digits=max_digits, decimal_places=decimal_places)])\r\n        return field.json_schema()['anyOf'][1]['pattern']\r\n    return pattern\r\n\r\n@pytest.mark.parametrize('invalid_decimal', ['1000.1111111'])\r\ndef test_only_max_digits_set(invalid_decimal, get_decimal_pattern):\r\n    pattern = get_decimal_pattern(max_digits=5, decimal_places=None)\r\n    assert re.fullmatch(pattern, invalid_decimal) is None\r\n```\r\n\r\nLet me know if there's a specific case I may have missed!",
      "comment_id": 2187293022,
      "user": "Dima-Bulavenko",
      "created_at": "2025-07-05T13:47:39Z",
      "url": "https://github.com/pydantic/pydantic/pull/11987#discussion_r2187293022"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12324,
      "file_path": "pydantic/type_adapter.py",
      "line": 225,
      "side": "RIGHT",
      "diff_hunk": "@@ -215,19 +216,36 @@ def __init__(\n         self.pydantic_complete = False\n \n         parent_frame = self._fetch_parent_frame()\n-        if parent_frame is not None:\n-            globalns = parent_frame.f_globals\n-            # Do not provide a local ns if the type adapter happens to be instantiated at the module level:\n-            localns = parent_frame.f_locals if parent_frame.f_locals is not globalns else {}\n+        if isinstance(type, types.FunctionType):\n+            # Special case functions, which are *not* pushed to the `NsResolver` stack and without this special case\n+            # would only have access to the parent namespace where the `TypeAdapter` was instantiated (if the function is defined\n+            # in another module, we need to look at that module's globals).\n+            if parent_frame is not None:\n+                parent_ns = (\n+                    parent_frame.f_globals if parent_frame.f_globals is parent_frame.f_locals else parent_frame.f_locals",
      "comment": "`globals if globals is locals else locals` .. isn't this always going to be equivalent to `locals`?\r\n\r\n```suggestion\r\n                    parent_frame.f_locals\r\n```",
      "comment_id": 2404459009,
      "user": "davidhewitt",
      "created_at": "2025-10-05T12:22:09Z",
      "url": "https://github.com/pydantic/pydantic/pull/12324#discussion_r2404459009"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12324,
      "file_path": "pydantic/type_adapter.py",
      "line": 225,
      "side": "RIGHT",
      "diff_hunk": "@@ -215,19 +216,36 @@ def __init__(\n         self.pydantic_complete = False\n \n         parent_frame = self._fetch_parent_frame()\n-        if parent_frame is not None:\n-            globalns = parent_frame.f_globals\n-            # Do not provide a local ns if the type adapter happens to be instantiated at the module level:\n-            localns = parent_frame.f_locals if parent_frame.f_locals is not globalns else {}\n+        if isinstance(type, types.FunctionType):\n+            # Special case functions, which are *not* pushed to the `NsResolver` stack and without this special case\n+            # would only have access to the parent namespace where the `TypeAdapter` was instantiated (if the function is defined\n+            # in another module, we need to look at that module's globals).\n+            if parent_frame is not None:\n+                parent_ns = (\n+                    parent_frame.f_globals if parent_frame.f_globals is parent_frame.f_locals else parent_frame.f_locals",
      "comment": "In other words, this means _use the globals if the TypeAdapter was created at the module level, else use the locals (e.g. in a function)_. In the former, globals and locals are the same (module's `__dict__`).",
      "comment_id": 2404659532,
      "user": "Viicos",
      "created_at": "2025-10-05T20:43:16Z",
      "url": "https://github.com/pydantic/pydantic/pull/12324#discussion_r2404659532"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12324,
      "file_path": "pydantic/type_adapter.py",
      "line": 225,
      "side": "RIGHT",
      "diff_hunk": "@@ -215,19 +216,36 @@ def __init__(\n         self.pydantic_complete = False\n \n         parent_frame = self._fetch_parent_frame()\n-        if parent_frame is not None:\n-            globalns = parent_frame.f_globals\n-            # Do not provide a local ns if the type adapter happens to be instantiated at the module level:\n-            localns = parent_frame.f_locals if parent_frame.f_locals is not globalns else {}\n+        if isinstance(type, types.FunctionType):\n+            # Special case functions, which are *not* pushed to the `NsResolver` stack and without this special case\n+            # would only have access to the parent namespace where the `TypeAdapter` was instantiated (if the function is defined\n+            # in another module, we need to look at that module's globals).\n+            if parent_frame is not None:\n+                parent_ns = (\n+                    parent_frame.f_globals if parent_frame.f_globals is parent_frame.f_locals else parent_frame.f_locals",
      "comment": "Right, but even if the intent is to do that, the expression written here completely simplifies away? Maybe a bug?",
      "comment_id": 2404675968,
      "user": "davidhewitt",
      "created_at": "2025-10-05T21:27:58Z",
      "url": "https://github.com/pydantic/pydantic/pull/12324#discussion_r2404675968"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12324,
      "file_path": "pydantic/type_adapter.py",
      "line": 225,
      "side": "RIGHT",
      "diff_hunk": "@@ -215,19 +216,36 @@ def __init__(\n         self.pydantic_complete = False\n \n         parent_frame = self._fetch_parent_frame()\n-        if parent_frame is not None:\n-            globalns = parent_frame.f_globals\n-            # Do not provide a local ns if the type adapter happens to be instantiated at the module level:\n-            localns = parent_frame.f_locals if parent_frame.f_locals is not globalns else {}\n+        if isinstance(type, types.FunctionType):\n+            # Special case functions, which are *not* pushed to the `NsResolver` stack and without this special case\n+            # would only have access to the parent namespace where the `TypeAdapter` was instantiated (if the function is defined\n+            # in another module, we need to look at that module's globals).\n+            if parent_frame is not None:\n+                parent_ns = (\n+                    parent_frame.f_globals if parent_frame.f_globals is parent_frame.f_locals else parent_frame.f_locals",
      "comment": "Hum I'm not sure? It's not `locals if globals is locals else locals`, but `globals if globals is locals else locals`",
      "comment_id": 2405256165,
      "user": "Viicos",
      "created_at": "2025-10-06T08:01:39Z",
      "url": "https://github.com/pydantic/pydantic/pull/12324#discussion_r2405256165"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12324,
      "file_path": "pydantic/type_adapter.py",
      "line": 225,
      "side": "RIGHT",
      "diff_hunk": "@@ -215,19 +216,36 @@ def __init__(\n         self.pydantic_complete = False\n \n         parent_frame = self._fetch_parent_frame()\n-        if parent_frame is not None:\n-            globalns = parent_frame.f_globals\n-            # Do not provide a local ns if the type adapter happens to be instantiated at the module level:\n-            localns = parent_frame.f_locals if parent_frame.f_locals is not globalns else {}\n+        if isinstance(type, types.FunctionType):\n+            # Special case functions, which are *not* pushed to the `NsResolver` stack and without this special case\n+            # would only have access to the parent namespace where the `TypeAdapter` was instantiated (if the function is defined\n+            # in another module, we need to look at that module's globals).\n+            if parent_frame is not None:\n+                parent_ns = (\n+                    parent_frame.f_globals if parent_frame.f_globals is parent_frame.f_locals else parent_frame.f_locals",
      "comment": "But I think that `if globals is locals` implies that `locals` and `globals` are the same object, so\r\n\r\n`locals if globals is locals else locals`\r\nand\r\n`globals if globals is locals else locals`\r\n\r\nare equivalent?\r\n",
      "comment_id": 2405461212,
      "user": "davidhewitt",
      "created_at": "2025-10-06T09:21:13Z",
      "url": "https://github.com/pydantic/pydantic/pull/12324#discussion_r2405461212"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12324,
      "file_path": "pydantic/type_adapter.py",
      "line": 225,
      "side": "RIGHT",
      "diff_hunk": "@@ -215,19 +216,36 @@ def __init__(\n         self.pydantic_complete = False\n \n         parent_frame = self._fetch_parent_frame()\n-        if parent_frame is not None:\n-            globalns = parent_frame.f_globals\n-            # Do not provide a local ns if the type adapter happens to be instantiated at the module level:\n-            localns = parent_frame.f_locals if parent_frame.f_locals is not globalns else {}\n+        if isinstance(type, types.FunctionType):\n+            # Special case functions, which are *not* pushed to the `NsResolver` stack and without this special case\n+            # would only have access to the parent namespace where the `TypeAdapter` was instantiated (if the function is defined\n+            # in another module, we need to look at that module's globals).\n+            if parent_frame is not None:\n+                parent_ns = (\n+                    parent_frame.f_globals if parent_frame.f_globals is parent_frame.f_locals else parent_frame.f_locals",
      "comment": "Ah yeah right, I'll use locals but add a comment to explain what it is referring to ~~(also update the same code later in this branch)~~.",
      "comment_id": 2405470178,
      "user": "Viicos",
      "created_at": "2025-10-06T09:24:40Z",
      "url": "https://github.com/pydantic/pydantic/pull/12324#discussion_r2405470178"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12254,
      "file_path": "pydantic/mypy.py",
      "line": 213,
      "side": "RIGHT",
      "diff_hunk": "@@ -209,14 +209,16 @@ def _pydantic_field_callback(self, ctx: FunctionContext) -> 'Type':\n                     default_factory_type = default_factory_type.items()[0]  # type: ignore[operator]\n \n             if isinstance(default_factory_type, CallableType):\n-                ret_type = default_factory_type.ret_type\n+                ret_type = get_proper_type(default_factory_type.ret_type)\n                 # mypy doesn't think `ret_type` has `args`, you'd think mypy should know,",
      "comment": "This comment is now obsolete (and has never been correct, `ret_type` isn't guaranteed to be an Instance)",
      "comment_id": 2353155864,
      "user": "sterliakov",
      "created_at": "2025-09-16T17:15:10Z",
      "url": "https://github.com/pydantic/pydantic/pull/12254#discussion_r2353155864"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12289,
      "file_path": "pydantic/_internal/_known_annotated_metadata.py",
      "line": 302,
      "side": "RIGHT",
      "diff_hunk": "@@ -296,25 +297,28 @@ def _apply_constraint_with_incompatibility_info(\n             )\n             continue\n         elif isinstance(annotation, (at.Predicate, at.Not)):\n-            predicate_name = f'{annotation.func.__qualname__}' if hasattr(annotation.func, '__qualname__') else ''\n+            predicate_name = f'{annotation.func.__qualname__!r} ' if hasattr(annotation.func, '__qualname__') else ''\n \n             def val_func(v: Any) -> Any:",
      "comment": "For performance we could consider formatting the error message before the `def val_func`, so it's reused on each error. Or could have it be cached in some way.\n\nSimilarly might want to have the `at.Predicate` / `at.Not` branches define two separate `val_func`?\n\n",
      "comment_id": 2401609542,
      "user": "davidhewitt",
      "created_at": "2025-10-03T11:40:58Z",
      "url": "https://github.com/pydantic/pydantic/pull/12289#discussion_r2401609542"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12077,
      "file_path": "tests/test_dataclasses.py",
      "line": 1844,
      "side": "RIGHT",
      "diff_hunk": "@@ -1841,6 +1841,20 @@ class Child(Parent):\n     assert child.y == 1\n \n \n+def test_kw_only_inheritance_on_field() -> None:",
      "comment": "This would previously fail with an unhandled exception with 3.9. Although it doesn't make sense to use it in 3.9 (and we could add a warning -- not worth the effort as we'll drop support for it soon), still better to not hard error.",
      "comment_id": 2219806416,
      "user": "Viicos",
      "created_at": "2025-07-21T17:21:16Z",
      "url": "https://github.com/pydantic/pydantic/pull/12077#discussion_r2219806416"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12179,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 1493,
      "side": "RIGHT",
      "diff_hunk": "@@ -1474,13 +1479,44 @@ def _typed_dict_schema(self, typed_dict_cls: Any, origin: Any) -> core_schema.Co\n                         UserWarning,\n                     )\n \n+                extra_behavior: core_schema.ExtraBehavior = 'ignore'\n+                extras_schema: CoreSchema | None = None  # For 'allow', equivalent to `Any` - no validation performed.\n+\n+                # `__closed__` is `None` when not specified (equivalent to `False`):\n+                is_closed = bool(getattr(typed_dict_cls, '__closed__', False))\n+                extra_items = getattr(typed_dict_cls, '__extra_items__', typing_extensions.NoExtraItems)\n+                if is_closed:\n+                    extra_behavior = 'forbid'\n+                    extras_schema = None\n+                elif not typing_objects.is_noextraitems(extra_items):\n+                    extra_behavior = 'allow'\n+                    extras_schema = self.generate_schema(replace_types(extra_items, typevars_map))",
      "comment": "Under what conditions does `extra_behavior` remain `'ignore'`?",
      "comment_id": 2394077681,
      "user": "davidhewitt",
      "created_at": "2025-10-01T10:12:38Z",
      "url": "https://github.com/pydantic/pydantic/pull/12179#discussion_r2394077681"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12179,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 1493,
      "side": "RIGHT",
      "diff_hunk": "@@ -1474,13 +1479,44 @@ def _typed_dict_schema(self, typed_dict_cls: Any, origin: Any) -> core_schema.Co\n                         UserWarning,\n                     )\n \n+                extra_behavior: core_schema.ExtraBehavior = 'ignore'\n+                extras_schema: CoreSchema | None = None  # For 'allow', equivalent to `Any` - no validation performed.\n+\n+                # `__closed__` is `None` when not specified (equivalent to `False`):\n+                is_closed = bool(getattr(typed_dict_cls, '__closed__', False))\n+                extra_items = getattr(typed_dict_cls, '__extra_items__', typing_extensions.NoExtraItems)\n+                if is_closed:\n+                    extra_behavior = 'forbid'\n+                    extras_schema = None\n+                elif not typing_objects.is_noextraitems(extra_items):\n+                    extra_behavior = 'allow'\n+                    extras_schema = self.generate_schema(replace_types(extra_items, typevars_map))",
      "comment": "It is first assigned the value of `'ignore'`, so if:\r\n- the TD is not closed\r\n- the TD has no extra items\r\n- the extra from the config is not `'allow'` or `'forbid'`",
      "comment_id": 2394130478,
      "user": "Viicos",
      "created_at": "2025-10-01T10:37:02Z",
      "url": "https://github.com/pydantic/pydantic/pull/12179#discussion_r2394130478"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12179,
      "file_path": "tests/test_types_typeddict.py",
      "line": 971,
      "side": "RIGHT",
      "diff_hunk": "@@ -957,3 +958,111 @@ class Foo(TypedDict):\n     assert ta.dump_json(Foo(foo='bar', bar=1)).decode('utf-8') == '{\"bar\":1}'\n     assert ta.dump_json(Foo(foo='bar', bar=1), exclude={'bar'}).decode('utf-8') == '{}'\n     assert ta.dump_json(Foo(foo='bar', bar=2)).decode('utf-8') == '{}'\n+\n+\n+def test_typeddict_extra_allow_serialization() -> None:\n+    \"\"\"https://github.com/pydantic/pydantic/issues/11136.\n+\n+    Seems like specifying `extra_behavior` in the core schema (which was done when implementing PEP 728)\n+    was necessary to make this work.\n+    \"\"\"\n+\n+    @with_config(extra='allow')\n+    class TD(TypedDict, closed=False):",
      "comment": "Answering in https://github.com/pydantic/pydantic/issues/10785.",
      "comment_id": 2394135784,
      "user": "Viicos",
      "created_at": "2025-10-01T10:39:33Z",
      "url": "https://github.com/pydantic/pydantic/pull/12179#discussion_r2394135784"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12290,
      "file_path": "tests/mypy/modules/frozen_field.py",
      "line": 17,
      "side": "RIGHT",
      "diff_hunk": "@@ -8,3 +8,16 @@ class Foo(BaseModel):\n foo = Foo()\n \n foo.a = 2\n+\n+\n+class Parent(BaseModel):\n+    parent_attr: str = Field(exclude=True)\n+\n+\n+# We don't wan't to froze `parent_attr` in the plugin:",
      "comment": "See the fixed issue, it results in unexpected errors.",
      "comment_id": 2387753994,
      "user": "Viicos",
      "created_at": "2025-09-29T12:24:40Z",
      "url": "https://github.com/pydantic/pydantic/pull/12290#discussion_r2387753994"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12290,
      "file_path": "tests/mypy/modules/frozen_field.py",
      "line": 17,
      "side": "RIGHT",
      "diff_hunk": "@@ -8,3 +8,16 @@ class Foo(BaseModel):\n foo = Foo()\n \n foo.a = 2\n+\n+\n+class Parent(BaseModel):\n+    parent_attr: str = Field(exclude=True)\n+\n+\n+# We don't wan't to froze `parent_attr` in the plugin:",
      "comment": "I see, maybe this is clearer:\n\n```suggestion\n# `parent_attr` is writable, mypy should error when overriding with a read-only property\n```",
      "comment_id": 2390980473,
      "user": "davidhewitt",
      "created_at": "2025-09-30T11:17:30Z",
      "url": "https://github.com/pydantic/pydantic/pull/12290#discussion_r2390980473"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12290,
      "file_path": "tests/mypy/modules/frozen_field.py",
      "line": 17,
      "side": "RIGHT",
      "diff_hunk": "@@ -8,3 +8,16 @@ class Foo(BaseModel):\n foo = Foo()\n \n foo.a = 2\n+\n+\n+class Parent(BaseModel):\n+    parent_attr: str = Field(exclude=True)\n+\n+\n+# We don't want to freeze `parent_attr` in the plugin:",
      "comment": "```suggestion\r\n# `parent_attr` is writable, mypy should error when overriding with a read-only property\r\n```",
      "comment_id": 2391286202,
      "user": "Viicos",
      "created_at": "2025-09-30T12:42:50Z",
      "url": "https://github.com/pydantic/pydantic/pull/12290#discussion_r2391286202"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12290,
      "file_path": "tests/mypy/outputs/mypy-plugin_ini/frozen_field.py",
      "line": 18,
      "side": "RIGHT",
      "diff_hunk": "@@ -9,3 +9,18 @@ class Foo(BaseModel):\n \n foo.a = 2\n # MYPY: error: Property \"a\" defined in \"Foo\" is read-only  [misc]\n+\n+\n+class Parent(BaseModel):\n+    parent_attr: str = Field(exclude=True)\n+\n+\n+# We don't want to freeze `parent_attr` in the plugin:",
      "comment": "```suggestion\r\n# `parent_attr` is writable, mypy should error when overriding with a read-only property\r\n```",
      "comment_id": 2391286422,
      "user": "Viicos",
      "created_at": "2025-09-30T12:42:57Z",
      "url": "https://github.com/pydantic/pydantic/pull/12290#discussion_r2391286422"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 7196,
      "file_path": "tests/test_abc.py",
      "line": 14,
      "side": "RIGHT",
      "diff_hunk": "@@ -10,6 +11,7 @@ class Model(BaseModel, abc.ABC):\n         some_field: str\n \n \n+@pytest.mark.skipif(sys.version_info < (3, 12), reason='error value different on older versions')",
      "comment": "I'd rather don't throw out tests for everything except an unreleased Python version.",
      "comment_id": 1331429375,
      "user": "lig",
      "created_at": "2023-09-20T10:40:05Z",
      "url": "https://github.com/pydantic/pydantic/pull/7196#discussion_r1331429375"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 9953,
      "file_path": "pydantic/_internal/_config.py",
      "line": 173,
      "side": "RIGHT",
      "diff_hunk": "@@ -166,37 +166,38 @@ def core_config(self, obj: Any) -> core_schema.CoreConfig:\n         Returns:\n             A `CoreConfig` object created from config.\n         \"\"\"\n-\n-        def dict_not_none(**kwargs: Any) -> Any:\n-            return {k: v for k, v in kwargs.items() if v is not None}\n-\n-        core_config = core_schema.CoreConfig(\n-            **dict_not_none(\n-                title=self.config_dict.get('title') or (obj and obj.__name__),\n-                extra_fields_behavior=self.config_dict.get('extra'),\n-                allow_inf_nan=self.config_dict.get('allow_inf_nan'),\n-                populate_by_name=self.config_dict.get('populate_by_name'),\n-                str_strip_whitespace=self.config_dict.get('str_strip_whitespace'),\n-                str_to_lower=self.config_dict.get('str_to_lower'),\n-                str_to_upper=self.config_dict.get('str_to_upper'),\n-                strict=self.config_dict.get('strict'),\n-                ser_json_timedelta=self.config_dict.get('ser_json_timedelta'),\n-                ser_json_bytes=self.config_dict.get('ser_json_bytes'),\n-                ser_json_inf_nan=self.config_dict.get('ser_json_inf_nan'),\n-                from_attributes=self.config_dict.get('from_attributes'),\n-                loc_by_alias=self.config_dict.get('loc_by_alias'),\n-                revalidate_instances=self.config_dict.get('revalidate_instances'),\n-                validate_default=self.config_dict.get('validate_default'),\n-                str_max_length=self.config_dict.get('str_max_length'),\n-                str_min_length=self.config_dict.get('str_min_length'),\n-                hide_input_in_errors=self.config_dict.get('hide_input_in_errors'),\n-                coerce_numbers_to_str=self.config_dict.get('coerce_numbers_to_str'),\n-                regex_engine=self.config_dict.get('regex_engine'),\n-                validation_error_cause=self.config_dict.get('validation_error_cause'),\n-                cache_strings=self.config_dict.get('cache_strings'),\n-            )\n-        )\n-        return core_config\n+        config = self.config_dict\n+        title = config.get('title') or (obj and obj.__name__)\n+\n+        core_config_values = {\n+            'title': title,",
      "comment": "```suggestion\r\n\r\n        core_config_values = {\r\n            'title': config.get('title') or (obj and obj.__name__),\r\n```",
      "comment_id": 1689989522,
      "user": "sydney-runkle",
      "created_at": "2024-07-24T15:07:08Z",
      "url": "https://github.com/pydantic/pydantic/pull/9953#discussion_r1689989522"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 9953,
      "file_path": "pydantic/_internal/_config.py",
      "line": 200,
      "side": "RIGHT",
      "diff_hunk": "@@ -166,37 +166,38 @@ def core_config(self, obj: Any) -> core_schema.CoreConfig:\n         Returns:\n             A `CoreConfig` object created from config.\n         \"\"\"\n-\n-        def dict_not_none(**kwargs: Any) -> Any:\n-            return {k: v for k, v in kwargs.items() if v is not None}\n-\n-        core_config = core_schema.CoreConfig(\n-            **dict_not_none(\n-                title=self.config_dict.get('title') or (obj and obj.__name__),\n-                extra_fields_behavior=self.config_dict.get('extra'),\n-                allow_inf_nan=self.config_dict.get('allow_inf_nan'),\n-                populate_by_name=self.config_dict.get('populate_by_name'),\n-                str_strip_whitespace=self.config_dict.get('str_strip_whitespace'),\n-                str_to_lower=self.config_dict.get('str_to_lower'),\n-                str_to_upper=self.config_dict.get('str_to_upper'),\n-                strict=self.config_dict.get('strict'),\n-                ser_json_timedelta=self.config_dict.get('ser_json_timedelta'),\n-                ser_json_bytes=self.config_dict.get('ser_json_bytes'),\n-                ser_json_inf_nan=self.config_dict.get('ser_json_inf_nan'),\n-                from_attributes=self.config_dict.get('from_attributes'),\n-                loc_by_alias=self.config_dict.get('loc_by_alias'),\n-                revalidate_instances=self.config_dict.get('revalidate_instances'),\n-                validate_default=self.config_dict.get('validate_default'),\n-                str_max_length=self.config_dict.get('str_max_length'),\n-                str_min_length=self.config_dict.get('str_min_length'),\n-                hide_input_in_errors=self.config_dict.get('hide_input_in_errors'),\n-                coerce_numbers_to_str=self.config_dict.get('coerce_numbers_to_str'),\n-                regex_engine=self.config_dict.get('regex_engine'),\n-                validation_error_cause=self.config_dict.get('validation_error_cause'),\n-                cache_strings=self.config_dict.get('cache_strings'),\n-            )\n-        )\n-        return core_config\n+        config = self.config_dict\n+        title = config.get('title') or (obj and obj.__name__)\n+\n+        core_config_values = {\n+            'title': title,\n+            'extra_fields_behavior': config.get('extra'),\n+            'allow_inf_nan': config.get('allow_inf_nan'),\n+            'populate_by_name': config.get('populate_by_name'),\n+            'str_strip_whitespace': config.get('str_strip_whitespace'),\n+            'str_to_lower': config.get('str_to_lower'),\n+            'str_to_upper': config.get('str_to_upper'),\n+            'strict': config.get('strict'),\n+            'ser_json_timedelta': config.get('ser_json_timedelta'),\n+            'ser_json_bytes': config.get('ser_json_bytes'),\n+            'ser_json_inf_nan': config.get('ser_json_inf_nan'),\n+            'from_attributes': config.get('from_attributes'),\n+            'loc_by_alias': config.get('loc_by_alias'),\n+            'revalidate_instances': config.get('revalidate_instances'),\n+            'validate_default': config.get('validate_default'),\n+            'str_max_length': config.get('str_max_length'),\n+            'str_min_length': config.get('str_min_length'),\n+            'hide_input_in_errors': config.get('hide_input_in_errors'),\n+            'coerce_numbers_to_str': config.get('coerce_numbers_to_str'),\n+            'regex_engine': config.get('regex_engine'),\n+            'validation_error_cause': config.get('validation_error_cause'),\n+            'cache_strings': config.get('cache_strings'),\n+        }\n+\n+        # Create dictionary excluding None values\n+        non_none_config = {k: v for k, v in core_config_values.items() if v is not None}\n+\n+        return core_schema.CoreConfig(**non_none_config)",
      "comment": "```suggestion\r\n        return core_schema.CoreConfig(**{k: v for k, v in core_config_values.items() if v is not None})\r\n```",
      "comment_id": 1689990512,
      "user": "sydney-runkle",
      "created_at": "2024-07-24T15:07:46Z",
      "url": "https://github.com/pydantic/pydantic/pull/9953#discussion_r1689990512"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12173,
      "file_path": "tests/test_dataclasses.py",
      "line": 3189,
      "side": "RIGHT",
      "diff_hunk": "@@ -3152,7 +3186,7 @@ class MyDataclass2:\n     try:\n         inst.x = 'other'\n     except ValidationError as e:\n-        assert 'Instance is frozen' in repr(e)\n+        assert \"cannot assign to field 'x'\" in repr(e)",
      "comment": "Previously the error was thrown from pydantic-core. I think it's better this way, as it is now consistent with the `frozen=True` dataclass argument above this one.",
      "comment_id": 2282016535,
      "user": "Viicos",
      "created_at": "2025-08-18T10:38:12Z",
      "url": "https://github.com/pydantic/pydantic/pull/12173#discussion_r2282016535"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12219,
      "file_path": "tests/test_types.py",
      "line": 1053,
      "side": "RIGHT",
      "diff_hunk": "@@ -1050,6 +1050,18 @@ class ImportThings(BaseModel):\n     assert import_things.model_dump_json() == '{\"obj\":\"sys.stdout\"}'\n \n \n+def test_import_string_thing_with_name() -> None:",
      "comment": "```suggestion\r\ndef test_import_string_thing_with_name() -> None:\r\n    \"\"\"https://github.com/pydantic/pydantic/issues/12218\"\"\"\r\n```",
      "comment_id": 2346394555,
      "user": "Viicos",
      "created_at": "2025-09-13T11:13:26Z",
      "url": "https://github.com/pydantic/pydantic/pull/12219#discussion_r2346394555"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12219,
      "file_path": "tests/test_types.py",
      "line": 1054,
      "side": "RIGHT",
      "diff_hunk": "@@ -1050,6 +1050,19 @@ class ImportThings(BaseModel):\n     assert import_things.model_dump_json() == '{\"obj\":\"sys.stdout\"}'\n \n \n+def test_import_string_thing_with_name() -> None:\n+    \"\"\"https://github.com/pydantic/pydantic/issues/12218\"\"\"",
      "comment": "```suggestion\r\n    \"\"\"https://github.com/pydantic/pydantic/issues/12218\"\"\"\r\n\r\n```",
      "comment_id": 2346646743,
      "user": "Viicos",
      "created_at": "2025-09-13T13:38:20Z",
      "url": "https://github.com/pydantic/pydantic/pull/12219#discussion_r2346646743"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12068,
      "file_path": "pydantic/config.py",
      "line": 601,
      "side": "RIGHT",
      "diff_hunk": "@@ -594,10 +594,43 @@ class Transaction(BaseModel):\n     The format of JSON serialized timedeltas. Accepts the string values of `'iso8601'` and\n     `'float'`. Defaults to `'iso8601'`.\n \n-    - `'iso8601'` will serialize timedeltas to ISO 8601 durations.\n+    !!! warning\n+        In v2.11+ it is recommended to use the [`ser_json_temporal`][pydantic.config.ConfigDict.ser_json_temporal]\n+        setting instead of `ser_json_timedelta`. This setting will be deprecated in v3.\n+    - `'iso8601'` will serialize timedeltas to [ISO 8601 text format](https://en.wikipedia.org/wiki/ISO_8601#Durations).\n     - `'float'` will serialize timedeltas to the total number of seconds.",
      "comment": "```suggestion\r\n    - `'iso8601'` will serialize timedeltas to [ISO 8601 text format](https://en.wikipedia.org/wiki/ISO_8601#Durations).\r\n    - `'float'` will serialize timedeltas to the total number of seconds.\r\n    \r\n    !!! warning\r\n        Starting in v2.11, it is recommended to use the [`ser_json_temporal`][pydantic.config.ConfigDict.ser_json_temporal]\r\n        setting instead of `ser_json_timedelta`. This setting will be deprecated in v3.\r\n```",
      "comment_id": 2281395813,
      "user": "Viicos",
      "created_at": "2025-08-18T06:18:32Z",
      "url": "https://github.com/pydantic/pydantic/pull/12068#discussion_r2281395813"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12068,
      "file_path": "pydantic/config.py",
      "line": 631,
      "side": "RIGHT",
      "diff_hunk": "@@ -594,10 +594,43 @@ class Transaction(BaseModel):\n     The format of JSON serialized timedeltas. Accepts the string values of `'iso8601'` and\n     `'float'`. Defaults to `'iso8601'`.\n \n-    - `'iso8601'` will serialize timedeltas to ISO 8601 durations.\n+    !!! warning\n+        In v2.11+ it is recommended to use the [`ser_json_temporal`][pydantic.config.ConfigDict.ser_json_temporal]\n+        setting instead of `ser_json_timedelta`. This setting will be deprecated in v3.\n+    - `'iso8601'` will serialize timedeltas to [ISO 8601 text format](https://en.wikipedia.org/wiki/ISO_8601#Durations).\n     - `'float'` will serialize timedeltas to the total number of seconds.\n     \"\"\"\n \n+    ser_json_temporal: Literal['iso8601', 'seconds', 'milliseconds']\n+    \"\"\"\n+    The format of JSON serialized temporal types from the `datetime` library. This includes:\n+    - [`datetime.datetime`][]\n+    - [`datetime.date`][]\n+    - [`datetime.time`][]\n+    - [`datetime.timedelta`][]\n+    !!! note\n+        This setting was introduced in v2.11. It overlaps with the `ser_json_timedelta`\n+        setting which will likely be deprecated in v3. It also adds more configurability for\n+        the other temporal types.\n+    Accepts the string values of `'iso8601'`, `'milliseconds'`, and `'seconds'`. Defaults to `'iso8601'`.\n+    - `'iso8601'` will serialize date-like types to [ISO 8601 text format](https://en.wikipedia.org/wiki/ISO_8601#Durations).\n+    - `'milliseconds'` will serialize date-like types to a floating point number of milliseconds since the epoch.\n+    - `'seconds'` will serialize date-like types to a floating point number of seconds since the epoch.\n+    \"\"\"\n+\n+    val_temporal_unit: Literal['seconds', 'milliseconds', 'infer']\n+    \"\"\"\n+    The unit to assume for validating numeric input for datetime-like types. This includes:\n+    - [`datetime.datetime`][]\n+    - [`datetime.date`][]\n+    Defaults to `'infer'`.\n+    The \"epoch\" references below refer to the Unix epoch, which is 1970-01-01 00:00:00 UTC.\n+    - `'seconds'` will validate date or time numeric inputs as seconds since the epoch.\n+    - `'milliseconds'` will validate date or time numeric inputs as milliseconds since the epoch.\n+    - `'infer'` will infer the unit from the string numeric input on unix time:\n+        i.e. seconds (if >= -2^10 and <= 2^10) or milliseconds (if < -2^10or > 2^10) since the epoch.",
      "comment": "Let's add the necessary [configuration for MathJax](https://squidfunk.github.io/mkdocs-material/reference/math/#mathjax) and use it:\r\n\r\n```suggestion\r\n    The unit to assume for validating numeric input for datetime-like types ([`datetime.datetime`][] and [`datetime.date`][]). Can be one of:\r\n\r\n    - `'seconds'` will validate date or time numeric inputs as seconds since the [epoch].\r\n    - `'milliseconds'` will validate date or time numeric inputs as milliseconds since the [epoch].\r\n    - `'infer'` will infer the unit from the string numeric input on unix time as:\r\n\r\n        * seconds since the [epoch] if $-2^{10} <= v <= 2^{10}$\r\n        * milliseconds since the [epoch] (if $v < -2^{10}$ or $v > 2^{10}$).\r\n\r\n    Defaults to `'infer'`.\r\n\r\n    [epoch]: https://en.wikipedia.org/wiki/Unix_time\r\n```",
      "comment_id": 2281435837,
      "user": "Viicos",
      "created_at": "2025-08-18T06:42:23Z",
      "url": "https://github.com/pydantic/pydantic/pull/12068#discussion_r2281435837"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12068,
      "file_path": "pydantic/config.py",
      "line": 618,
      "side": "RIGHT",
      "diff_hunk": "@@ -594,10 +594,43 @@ class Transaction(BaseModel):\n     The format of JSON serialized timedeltas. Accepts the string values of `'iso8601'` and\n     `'float'`. Defaults to `'iso8601'`.\n \n-    - `'iso8601'` will serialize timedeltas to ISO 8601 durations.\n+    !!! warning\n+        In v2.11+ it is recommended to use the [`ser_json_temporal`][pydantic.config.ConfigDict.ser_json_temporal]\n+        setting instead of `ser_json_timedelta`. This setting will be deprecated in v3.\n+    - `'iso8601'` will serialize timedeltas to [ISO 8601 text format](https://en.wikipedia.org/wiki/ISO_8601#Durations).\n     - `'float'` will serialize timedeltas to the total number of seconds.\n     \"\"\"\n \n+    ser_json_temporal: Literal['iso8601', 'seconds', 'milliseconds']\n+    \"\"\"\n+    The format of JSON serialized temporal types from the `datetime` library. This includes:\n+    - [`datetime.datetime`][]\n+    - [`datetime.date`][]\n+    - [`datetime.time`][]\n+    - [`datetime.timedelta`][]\n+    !!! note\n+        This setting was introduced in v2.11. It overlaps with the `ser_json_timedelta`\n+        setting which will likely be deprecated in v3. It also adds more configurability for\n+        the other temporal types.\n+    Accepts the string values of `'iso8601'`, `'milliseconds'`, and `'seconds'`. Defaults to `'iso8601'`.\n+    - `'iso8601'` will serialize date-like types to [ISO 8601 text format](https://en.wikipedia.org/wiki/ISO_8601#Durations).\n+    - `'milliseconds'` will serialize date-like types to a floating point number of milliseconds since the epoch.\n+    - `'seconds'` will serialize date-like types to a floating point number of seconds since the epoch.",
      "comment": "```suggestion\r\n    The format of JSON serialized temporal types from the [`datetime`][] module. This includes:\r\n\r\n    - [`datetime.datetime`][]\r\n    - [`datetime.date`][]\r\n    - [`datetime.time`][]\r\n    - [`datetime.timedelta`][]\r\n\r\n    Can be one of:\r\n\r\n    - `'iso8601'` will serialize date-like types to [ISO 8601 text format](https://en.wikipedia.org/wiki/ISO_8601#Durations).\r\n    - `'milliseconds'` will serialize date-like types to a floating point number of milliseconds since the epoch.\r\n    - `'seconds'` will serialize date-like types to a floating point number of seconds since the epoch.\r\n\r\n    Defaults to `'iso8601'`.\r\n\r\n    !!! note\r\n        This setting was introduced in v2.11. It overlaps with the [`ser_json_timedelta`][pydantic.config.ConfigDict.ser_json_timedelta]\r\n        setting which will be deprecated in v3. It also adds more configurability for\r\n        the other temporal types.\r\n```",
      "comment_id": 2281436895,
      "user": "Viicos",
      "created_at": "2025-08-18T06:43:05Z",
      "url": "https://github.com/pydantic/pydantic/pull/12068#discussion_r2281436895"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 7188,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 1599,
      "side": "LEFT",
      "diff_hunk": "@@ -1497,7 +1498,6 @@ def _get_prepare_pydantic_annotations_for_known_type(\n     ) -> tuple[Any, list[Any]] | None:\n         from ._std_types_schema import PREPARE_METHODS\n \n-        # This check for hashability is only necessary for python 3.7",
      "comment": "Seem we need this check for other versions as well. by removing this check some tests fail. like https://github.com/pydantic/pydantic/blob/8989f96415b0c693585fa9363eaf520d5b9a30a2/tests/test_json_schema.py#L4891",
      "comment_id": 1300047061,
      "user": "hramezani",
      "created_at": "2023-08-21T12:31:22Z",
      "url": "https://github.com/pydantic/pydantic/pull/7188#discussion_r1300047061"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12196,
      "file_path": "pydantic/version.py",
      "line": 87,
      "side": "RIGHT",
      "diff_hunk": "@@ -72,8 +77,26 @@ def version_info() -> str:\n \n def check_pydantic_core_version() -> bool:\n     \"\"\"Check that the installed `pydantic-core` dependency is compatible.\"\"\"\n-    # Keep this in sync with the version constraint in the `pyproject.toml` dependencies:\n-    return __pydantic_core_version__ == '2.37.2'\n+    return __pydantic_core_version__ == _COMPATIBLE_PYDANTIC_CORE_VERSION\n+\n+\n+def _ensure_pydantic_core_version() -> None:  # pragma: no cover\n+    if not check_pydantic_core_version():\n+        raise_error = True\n+        # Do not raise the error if pydantic is installed in editable mode (i.e. in development):\n+        if sys.version_info >= (3, 13):  # origin property added in 3.13",
      "comment": "Do we potentially want an env var to silence this for development on older Python versions?",
      "comment_id": 2303898997,
      "user": "davidhewitt",
      "created_at": "2025-08-27T13:14:39Z",
      "url": "https://github.com/pydantic/pydantic/pull/12196#discussion_r2303898997"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12196,
      "file_path": "pydantic/version.py",
      "line": 87,
      "side": "RIGHT",
      "diff_hunk": "@@ -72,8 +77,26 @@ def version_info() -> str:\n \n def check_pydantic_core_version() -> bool:\n     \"\"\"Check that the installed `pydantic-core` dependency is compatible.\"\"\"\n-    # Keep this in sync with the version constraint in the `pyproject.toml` dependencies:\n-    return __pydantic_core_version__ == '2.37.2'\n+    return __pydantic_core_version__ == _COMPATIBLE_PYDANTIC_CORE_VERSION\n+\n+\n+def _ensure_pydantic_core_version() -> None:  # pragma: no cover\n+    if not check_pydantic_core_version():\n+        raise_error = True\n+        # Do not raise the error if pydantic is installed in editable mode (i.e. in development):\n+        if sys.version_info >= (3, 13):  # origin property added in 3.13",
      "comment": "I thought about it, but I think most one-time contributors will have the version right on `uv sync`, and for us well I can only recommend using 3.13 or soon 3.14 :smile: ",
      "comment_id": 2304000700,
      "user": "Viicos",
      "created_at": "2025-08-27T13:49:21Z",
      "url": "https://github.com/pydantic/pydantic/pull/12196#discussion_r2304000700"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11942,
      "file_path": "pydantic/functional_validators.py",
      "line": 881,
      "side": "RIGHT",
      "diff_hunk": "@@ -831,3 +831,53 @@ def __get_pydantic_core_schema__(cls, source: Any, handler: GetCoreSchemaHandler\n             )\n \n         __hash__ = object.__hash__\n+\n+\n+_FromTypeT = TypeVar('_FromTypeT')\n+\n+\n+class ValidateFrom:\n+    \"\"\"A helper class to validate a custom type from a type natively supported by Pydantic.\n+\n+    Args:\n+        from_type: The type natively supported by Pydantic to use to perform validation.\n+        instantiation_hook: A callable taking the validated type as an argument, and returning\n+            the populated custom type.\n+\n+    Example:\n+        ```python {lint=\"skip\"}\n+        from typing import Annotated\n+\n+        from pydantic import BaseModel, TypeAdapter, ValidateFrom\n+\n+        class MyCls:\n+            def __init__(self, a: int) -> None:\n+                self.a = a\n+\n+            def __repr__(self) -> str:\n+                return f\"MyCls(a={self.a})\"\n+\n+        class Model(BaseModel):\n+            a: int\n+\n+\n+        ta = TypeAdapter(\n+            Annotated[MyCls, ValidateFrom(Model, instantiation_hook=lambda v: MyCls(a=v.a))]\n+        )\n+\n+        print(ta.validate_python({'a': 1}))\n+        #> MyCls(a=1)\n+        ```\n+    \"\"\"\n+\n+    # TODO: make use of PEP 747\n+    def __init__(self, from_type: type[_FromTypeT], /, *, instantiation_hook: Callable[[_FromTypeT], Any]) -> None:\n+        self.from_type = from_type\n+        self.instantiation_hook = instantiation_hook\n+\n+    def __get_pydantic_core_schema__(self, source: Any, handler: GetCoreSchemaHandler) -> core_schema.CoreSchema:\n+        schema = handler(self.from_type)\n+        return core_schema.no_info_after_validator_function(\n+            lambda value: self.instantiation_hook(value),",
      "comment": "Would this work?\r\n\r\n```suggestion\r\n            self.instantiation_hook,\r\n```",
      "comment_id": 2278964398,
      "user": "DouweM",
      "created_at": "2025-08-15T13:10:49Z",
      "url": "https://github.com/pydantic/pydantic/pull/11942#discussion_r2278964398"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11942,
      "file_path": "pydantic/functional_validators.py",
      "line": 881,
      "side": "RIGHT",
      "diff_hunk": "@@ -831,3 +831,53 @@ def __get_pydantic_core_schema__(cls, source: Any, handler: GetCoreSchemaHandler\n             )\n \n         __hash__ = object.__hash__\n+\n+\n+_FromTypeT = TypeVar('_FromTypeT')\n+\n+\n+class ValidateFrom:\n+    \"\"\"A helper class to validate a custom type from a type natively supported by Pydantic.\n+\n+    Args:\n+        from_type: The type natively supported by Pydantic to use to perform validation.\n+        instantiation_hook: A callable taking the validated type as an argument, and returning\n+            the populated custom type.\n+\n+    Example:\n+        ```python {lint=\"skip\"}\n+        from typing import Annotated\n+\n+        from pydantic import BaseModel, TypeAdapter, ValidateFrom\n+\n+        class MyCls:\n+            def __init__(self, a: int) -> None:\n+                self.a = a\n+\n+            def __repr__(self) -> str:\n+                return f\"MyCls(a={self.a})\"\n+\n+        class Model(BaseModel):\n+            a: int\n+\n+\n+        ta = TypeAdapter(\n+            Annotated[MyCls, ValidateFrom(Model, instantiation_hook=lambda v: MyCls(a=v.a))]\n+        )\n+\n+        print(ta.validate_python({'a': 1}))\n+        #> MyCls(a=1)\n+        ```\n+    \"\"\"\n+\n+    # TODO: make use of PEP 747\n+    def __init__(self, from_type: type[_FromTypeT], /, *, instantiation_hook: Callable[[_FromTypeT], Any]) -> None:\n+        self.from_type = from_type\n+        self.instantiation_hook = instantiation_hook\n+\n+    def __get_pydantic_core_schema__(self, source: Any, handler: GetCoreSchemaHandler) -> core_schema.CoreSchema:\n+        schema = handler(self.from_type)\n+        return core_schema.no_info_after_validator_function(\n+            lambda value: self.instantiation_hook(value),",
      "comment": "> > It can currently be anything (supported by Pydantic: models, dataclasses, typeddicts, etc), but we will have to constrain it to some specific types (perhaps only supporting Pydantic models?) as we will most likely have to assume `__dict__` is present to fetch the instance attributes and pass them to `__new__()`.\r\n\r\nCould `TypeAdapter(from_type).dump_python(value)` work instead of `__dict__`?",
      "comment_id": 2278971975,
      "user": "DouweM",
      "created_at": "2025-08-15T13:16:08Z",
      "url": "https://github.com/pydantic/pydantic/pull/11942#discussion_r2278971975"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11942,
      "file_path": "pydantic/functional_validators.py",
      "line": 874,
      "side": "RIGHT",
      "diff_hunk": "@@ -831,3 +831,53 @@ def __get_pydantic_core_schema__(cls, source: Any, handler: GetCoreSchemaHandler\n             )\n \n         __hash__ = object.__hash__\n+\n+\n+_FromTypeT = TypeVar('_FromTypeT')\n+\n+\n+class ValidateFrom:\n+    \"\"\"A helper class to validate a custom type from a type natively supported by Pydantic.\n+\n+    Args:\n+        from_type: The type natively supported by Pydantic to use to perform validation.\n+        instantiation_hook: A callable taking the validated type as an argument, and returning\n+            the populated custom type.\n+\n+    Example:\n+        ```python {lint=\"skip\"}\n+        from typing import Annotated\n+\n+        from pydantic import BaseModel, TypeAdapter, ValidateFrom\n+\n+        class MyCls:\n+            def __init__(self, a: int) -> None:\n+                self.a = a\n+\n+            def __repr__(self) -> str:\n+                return f\"MyCls(a={self.a})\"\n+\n+        class Model(BaseModel):\n+            a: int\n+\n+\n+        ta = TypeAdapter(\n+            Annotated[MyCls, ValidateFrom(Model, instantiation_hook=lambda v: MyCls(a=v.a))]\n+        )\n+\n+        print(ta.validate_python({'a': 1}))\n+        #> MyCls(a=1)\n+        ```\n+    \"\"\"\n+\n+    # TODO: make use of PEP 747\n+    def __init__(self, from_type: type[_FromTypeT], /, *, instantiation_hook: Callable[[_FromTypeT], Any]) -> None:",
      "comment": "`instantiation_hook` is pretty long, does it have to be a kwarg? `ValidateFrom(Model, lambda v: MyCls(a=v.a))` is pretty clear ",
      "comment_id": 2278973814,
      "user": "DouweM",
      "created_at": "2025-08-15T13:17:29Z",
      "url": "https://github.com/pydantic/pydantic/pull/11942#discussion_r2278973814"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11942,
      "file_path": "pydantic/functional_validators.py",
      "line": 881,
      "side": "RIGHT",
      "diff_hunk": "@@ -831,3 +831,53 @@ def __get_pydantic_core_schema__(cls, source: Any, handler: GetCoreSchemaHandler\n             )\n \n         __hash__ = object.__hash__\n+\n+\n+_FromTypeT = TypeVar('_FromTypeT')\n+\n+\n+class ValidateFrom:\n+    \"\"\"A helper class to validate a custom type from a type natively supported by Pydantic.\n+\n+    Args:\n+        from_type: The type natively supported by Pydantic to use to perform validation.\n+        instantiation_hook: A callable taking the validated type as an argument, and returning\n+            the populated custom type.\n+\n+    Example:\n+        ```python {lint=\"skip\"}\n+        from typing import Annotated\n+\n+        from pydantic import BaseModel, TypeAdapter, ValidateFrom\n+\n+        class MyCls:\n+            def __init__(self, a: int) -> None:\n+                self.a = a\n+\n+            def __repr__(self) -> str:\n+                return f\"MyCls(a={self.a})\"\n+\n+        class Model(BaseModel):\n+            a: int\n+\n+\n+        ta = TypeAdapter(\n+            Annotated[MyCls, ValidateFrom(Model, instantiation_hook=lambda v: MyCls(a=v.a))]\n+        )\n+\n+        print(ta.validate_python({'a': 1}))\n+        #> MyCls(a=1)\n+        ```\n+    \"\"\"\n+\n+    # TODO: make use of PEP 747\n+    def __init__(self, from_type: type[_FromTypeT], /, *, instantiation_hook: Callable[[_FromTypeT], Any]) -> None:\n+        self.from_type = from_type\n+        self.instantiation_hook = instantiation_hook\n+\n+    def __get_pydantic_core_schema__(self, source: Any, handler: GetCoreSchemaHandler) -> core_schema.CoreSchema:\n+        schema = handler(self.from_type)\n+        return core_schema.no_info_after_validator_function(\n+            lambda value: self.instantiation_hook(value),",
      "comment": "> Would this work?\r\n\r\nNice catch, updated.\r\n\r\n> Could `TypeAdapter(from_type).dump_python(value)` work instead of `__dict__`?\r\n\r\nWell even this way, if `from_type` happens to be e.g. a list we can't make assumptions on the dumped value, and how to use it to populate the final custom type.",
      "comment_id": 2279216054,
      "user": "Viicos",
      "created_at": "2025-08-15T15:19:23Z",
      "url": "https://github.com/pydantic/pydantic/pull/11942#discussion_r2279216054"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11942,
      "file_path": "pydantic/functional_validators.py",
      "line": 874,
      "side": "RIGHT",
      "diff_hunk": "@@ -831,3 +831,53 @@ def __get_pydantic_core_schema__(cls, source: Any, handler: GetCoreSchemaHandler\n             )\n \n         __hash__ = object.__hash__\n+\n+\n+_FromTypeT = TypeVar('_FromTypeT')\n+\n+\n+class ValidateFrom:\n+    \"\"\"A helper class to validate a custom type from a type natively supported by Pydantic.\n+\n+    Args:\n+        from_type: The type natively supported by Pydantic to use to perform validation.\n+        instantiation_hook: A callable taking the validated type as an argument, and returning\n+            the populated custom type.\n+\n+    Example:\n+        ```python {lint=\"skip\"}\n+        from typing import Annotated\n+\n+        from pydantic import BaseModel, TypeAdapter, ValidateFrom\n+\n+        class MyCls:\n+            def __init__(self, a: int) -> None:\n+                self.a = a\n+\n+            def __repr__(self) -> str:\n+                return f\"MyCls(a={self.a})\"\n+\n+        class Model(BaseModel):\n+            a: int\n+\n+\n+        ta = TypeAdapter(\n+            Annotated[MyCls, ValidateFrom(Model, instantiation_hook=lambda v: MyCls(a=v.a))]\n+        )\n+\n+        print(ta.validate_python({'a': 1}))\n+        #> MyCls(a=1)\n+        ```\n+    \"\"\"\n+\n+    # TODO: make use of PEP 747\n+    def __init__(self, from_type: type[_FromTypeT], /, *, instantiation_hook: Callable[[_FromTypeT], Any]) -> None:",
      "comment": "I'm a bit worried that if users end up using the positional form, it won't be obvious to know what `ValidateFrom` is doing:\r\n\r\n```python\r\nclass Model(BaseModel):\r\n    a: Annotated[MyType, ValidateFrom(SomeModel, lambda v: ...)]\r\n```\r\n\r\nbut if I don't manage to find a shorter name, I'll make it positional or kw.",
      "comment_id": 2279226566,
      "user": "Viicos",
      "created_at": "2025-08-15T15:21:04Z",
      "url": "https://github.com/pydantic/pydantic/pull/11942#discussion_r2279226566"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11942,
      "file_path": "pydantic/functional_validators.py",
      "line": 881,
      "side": "RIGHT",
      "diff_hunk": "@@ -831,3 +831,53 @@ def __get_pydantic_core_schema__(cls, source: Any, handler: GetCoreSchemaHandler\n             )\n \n         __hash__ = object.__hash__\n+\n+\n+_FromTypeT = TypeVar('_FromTypeT')\n+\n+\n+class ValidateFrom:\n+    \"\"\"A helper class to validate a custom type from a type natively supported by Pydantic.\n+\n+    Args:\n+        from_type: The type natively supported by Pydantic to use to perform validation.\n+        instantiation_hook: A callable taking the validated type as an argument, and returning\n+            the populated custom type.\n+\n+    Example:\n+        ```python {lint=\"skip\"}\n+        from typing import Annotated\n+\n+        from pydantic import BaseModel, TypeAdapter, ValidateFrom\n+\n+        class MyCls:\n+            def __init__(self, a: int) -> None:\n+                self.a = a\n+\n+            def __repr__(self) -> str:\n+                return f\"MyCls(a={self.a})\"\n+\n+        class Model(BaseModel):\n+            a: int\n+\n+\n+        ta = TypeAdapter(\n+            Annotated[MyCls, ValidateFrom(Model, instantiation_hook=lambda v: MyCls(a=v.a))]\n+        )\n+\n+        print(ta.validate_python({'a': 1}))\n+        #> MyCls(a=1)\n+        ```\n+    \"\"\"\n+\n+    # TODO: make use of PEP 747\n+    def __init__(self, from_type: type[_FromTypeT], /, *, instantiation_hook: Callable[[_FromTypeT], Any]) -> None:\n+        self.from_type = from_type\n+        self.instantiation_hook = instantiation_hook\n+\n+    def __get_pydantic_core_schema__(self, source: Any, handler: GetCoreSchemaHandler) -> core_schema.CoreSchema:\n+        schema = handler(self.from_type)\n+        return core_schema.no_info_after_validator_function(\n+            lambda value: self.instantiation_hook(value),",
      "comment": "@Viicos Right, then keeping it like this at least to start makes sense",
      "comment_id": 2279274658,
      "user": "DouweM",
      "created_at": "2025-08-15T15:31:01Z",
      "url": "https://github.com/pydantic/pydantic/pull/11942#discussion_r2279274658"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11942,
      "file_path": "pydantic/functional_validators.py",
      "line": 874,
      "side": "RIGHT",
      "diff_hunk": "@@ -831,3 +831,53 @@ def __get_pydantic_core_schema__(cls, source: Any, handler: GetCoreSchemaHandler\n             )\n \n         __hash__ = object.__hash__\n+\n+\n+_FromTypeT = TypeVar('_FromTypeT')\n+\n+\n+class ValidateFrom:\n+    \"\"\"A helper class to validate a custom type from a type natively supported by Pydantic.\n+\n+    Args:\n+        from_type: The type natively supported by Pydantic to use to perform validation.\n+        instantiation_hook: A callable taking the validated type as an argument, and returning\n+            the populated custom type.\n+\n+    Example:\n+        ```python {lint=\"skip\"}\n+        from typing import Annotated\n+\n+        from pydantic import BaseModel, TypeAdapter, ValidateFrom\n+\n+        class MyCls:\n+            def __init__(self, a: int) -> None:\n+                self.a = a\n+\n+            def __repr__(self) -> str:\n+                return f\"MyCls(a={self.a})\"\n+\n+        class Model(BaseModel):\n+            a: int\n+\n+\n+        ta = TypeAdapter(\n+            Annotated[MyCls, ValidateFrom(Model, instantiation_hook=lambda v: MyCls(a=v.a))]\n+        )\n+\n+        print(ta.validate_python({'a': 1}))\n+        #> MyCls(a=1)\n+        ```\n+    \"\"\"\n+\n+    # TODO: make use of PEP 747\n+    def __init__(self, from_type: type[_FromTypeT], /, *, instantiation_hook: Callable[[_FromTypeT], Any]) -> None:",
      "comment": "I think `Annotated[MyType, ValidateAs(SomeModel, lambda v: ...)]` implies pretty well that the input will be validated as a `SomeModel`, and then you're supposed to turn a `SomeModel` into a `MyType`. `ValidateAs` implies that a bit more clearly to me than `ValidateFrom`",
      "comment_id": 2279282215,
      "user": "DouweM",
      "created_at": "2025-08-15T15:32:37Z",
      "url": "https://github.com/pydantic/pydantic/pull/11942#discussion_r2279282215"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12002,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 622,
      "side": "RIGHT",
      "diff_hunk": "@@ -619,7 +619,7 @@ def _arbitrary_type_schema(self, tp: Any) -> CoreSchema:\n                 ' Pydantic will allow any object with no validation since we cannot even'\n                 ' enforce that the input is an instance of the given type.'\n                 ' To get rid of this error wrap the type with `pydantic.SkipValidation`.',\n-                UserWarning,\n+                PydanticSkipValidationWarning,  # Updated warning type,",
      "comment": "```suggestion\r\n                PydanticArbitraryTypeWarning,\r\n```",
      "comment_id": 2161109248,
      "user": "Viicos",
      "created_at": "2025-06-23T09:10:17Z",
      "url": "https://github.com/pydantic/pydantic/pull/12002#discussion_r2161109248"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12002,
      "file_path": "pydantic/functional_validators.py",
      "line": 831,
      "side": "RIGHT",
      "diff_hunk": "@@ -817,13 +819,15 @@ def __class_getitem__(cls, item: Any) -> Any:\n \n         @classmethod\n         def __get_pydantic_core_schema__(cls, source: Any, handler: GetCoreSchemaHandler) -> core_schema.CoreSchema:\n-            original_schema = handler(source)\n-            metadata = {'pydantic_js_annotation_functions': [lambda _c, h: h(original_schema)]}\n-            return core_schema.any_schema(\n-                metadata=metadata,\n-                serialization=core_schema.wrap_serializer_function_ser_schema(\n-                    function=lambda v, h: h(v), schema=original_schema\n-                ),\n-            )\n+            with warnings.catch_warnings():\n+                warnings.simplefilter('ignore', PydanticSkipValidationWarning)\n+                original_schema = handler(source)\n+                metadata = {'pydantic_js_annotation_functions': [lambda _c, h: h(original_schema)]}\n+                return core_schema.any_schema(\n+                    metadata=metadata,\n+                    serialization=core_schema.wrap_serializer_function_ser_schema(\n+                        function=lambda v, h: h(v), schema=original_schema\n+                    ),\n+                )",
      "comment": "```suggestion\r\n            metadata = {'pydantic_js_annotation_functions': [lambda _c, h: h(original_schema)]}\r\n            return core_schema.any_schema(\r\n                metadata=metadata,\r\n                serialization=core_schema.wrap_serializer_function_ser_schema(\r\n                    function=lambda v, h: h(v), schema=original_schema\r\n                ),\r\n            )\r\n```",
      "comment_id": 2161110729,
      "user": "Viicos",
      "created_at": "2025-06-23T09:11:02Z",
      "url": "https://github.com/pydantic/pydantic/pull/12002#discussion_r2161110729"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12002,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 65,
      "side": "RIGHT",
      "diff_hunk": "@@ -62,7 +62,7 @@\n from ..functional_validators import AfterValidator, BeforeValidator, FieldValidatorModes, PlainValidator, WrapValidator\n from ..json_schema import JsonSchemaValue\n from ..version import version_short\n-from ..warnings import PydanticDeprecatedSince20\n+from ..warnings import PydanticDeprecatedSince20, PydanticSkipValidationWarning",
      "comment": "```suggestion\r\nfrom ..warnings import PydanticArbitraryTypeWarning, PydanticDeprecatedSince20\r\n```",
      "comment_id": 2161114862,
      "user": "Viicos",
      "created_at": "2025-06-23T09:13:11Z",
      "url": "https://github.com/pydantic/pydantic/pull/12002#discussion_r2161114862"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12002,
      "file_path": "pydantic/functional_validators.py",
      "line": 18,
      "side": "RIGHT",
      "diff_hunk": "@@ -14,6 +15,7 @@\n from ._internal import _decorators, _generics, _internal_dataclass\n from .annotated_handlers import GetCoreSchemaHandler\n from .errors import PydanticUserError\n+from .warnings import PydanticSkipValidationWarning",
      "comment": "```suggestion\r\nfrom .warnings import PydanticArbitraryTypeWarning\r\n```",
      "comment_id": 2161115592,
      "user": "Viicos",
      "created_at": "2025-06-23T09:13:24Z",
      "url": "https://github.com/pydantic/pydantic/pull/12002#discussion_r2161115592"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12002,
      "file_path": "pydantic/functional_validators.py",
      "line": 823,
      "side": "RIGHT",
      "diff_hunk": "@@ -817,13 +819,15 @@ def __class_getitem__(cls, item: Any) -> Any:\n \n         @classmethod\n         def __get_pydantic_core_schema__(cls, source: Any, handler: GetCoreSchemaHandler) -> core_schema.CoreSchema:\n-            original_schema = handler(source)\n-            metadata = {'pydantic_js_annotation_functions': [lambda _c, h: h(original_schema)]}\n-            return core_schema.any_schema(\n-                metadata=metadata,\n-                serialization=core_schema.wrap_serializer_function_ser_schema(\n-                    function=lambda v, h: h(v), schema=original_schema\n-                ),\n-            )\n+            with warnings.catch_warnings():\n+                warnings.simplefilter('ignore', PydanticSkipValidationWarning)",
      "comment": "```suggestion\r\n                warnings.simplefilter('ignore', PydanticArbitraryTypeWarning)\r\n```",
      "comment_id": 2161115936,
      "user": "Viicos",
      "created_at": "2025-06-23T09:13:32Z",
      "url": "https://github.com/pydantic/pydantic/pull/12002#discussion_r2161115936"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12002,
      "file_path": "pydantic/warnings.py",
      "line": 100,
      "side": "RIGHT",
      "diff_hunk": "@@ -94,3 +94,7 @@ class PydanticExperimentalWarning(Warning):\n     This warning is raised when using experimental functionality in Pydantic.\n     It is raised to warn users that the functionality may change or be removed in future versions of Pydantic.\n     \"\"\"\n+\n+\n+class PydanticSkipValidationWarning(UserWarning):\n+    \"\"\"Warning raised when SkipValidation is used for unsupported types.\"\"\"",
      "comment": "```suggestion\r\nclass PydanticArbitraryTypeWarning(UserWarning):\r\n    \"\"\"Warning raised when Pydantic fails to generate a core schema for an arbitrary type.\"\"\"\r\n```",
      "comment_id": 2161117398,
      "user": "Viicos",
      "created_at": "2025-06-23T09:14:09Z",
      "url": "https://github.com/pydantic/pydantic/pull/12002#discussion_r2161117398"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11858,
      "file_path": "pydantic/functional_validators.py",
      "line": 98,
      "side": "RIGHT",
      "diff_hunk": "@@ -94,7 +94,7 @@ class BeforeValidator:\n \n     Attributes:\n         func: The validator function.\n-        json_schema_input_type: The input type of the function. This is only used to generate the appropriate\n+        json_schema_input_type: This is only used to generate the appropriate\n             JSON Schema (in validation mode).",
      "comment": "```suggestion\r\n        json_schema_input_type: The input type used to generate the appropriate\r\n            JSON Schema (in validation mode). The actual input type is `Any`.\r\n```",
      "comment_id": 2084439283,
      "user": "DouweM",
      "created_at": "2025-05-12T11:06:59Z",
      "url": "https://github.com/pydantic/pydantic/pull/11858#discussion_r2084439283"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 1881,
      "file_path": "pydantic/main.py",
      "line": 316,
      "side": "RIGHT",
      "diff_hunk": "@@ -313,6 +313,7 @@ def __new__(mcs, name, bases, namespace, **kwargs):  # noqa C901\n             '__schema_cache__': {},\n             '__json_encoder__': staticmethod(json_encoder),\n             '__custom_root_type__': _custom_root_type,\n+            '__hash__': (lambda self: hash(tuple(self.__dict__.values()))) if not config.allow_mutation else None,",
      "comment": "Instead of `.values` we should probably have `.items` here.  The keys ought to be considered a part of the identity of the object.\r\n\r\nExample:\r\n```\r\nx = {\"a\": 1, \"b\": True}\r\ny = {\"d\": 1, \"c\": True}\r\nhash(tuple(x.values())) == hash(tuple(y.values()))  # True\r\nhash(tuple(x.items())) == hash(tuple(y.items()))  # False\r\n```",
      "comment_id": 490409076,
      "user": "wozniakty",
      "created_at": "2020-09-17T16:45:59Z",
      "url": "https://github.com/pydantic/pydantic/pull/1881#discussion_r490409076"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 1881,
      "file_path": "tests/test_main.py",
      "line": 421,
      "side": "RIGHT",
      "diff_hunk": "@@ -373,6 +386,32 @@ class Config:\n     assert '\"TestModel\" object has no field \"b\"' in exc_info.value.args[0]\n \n \n+def test_immutable_with_hashable_fields_are_hashable():\n+    class TestModel(BaseModel):\n+        a: int = 10\n+\n+        class Config:\n+            allow_mutation = False\n+\n+    m = TestModel()\n+    assert m.__hash__ is not None\n+    assert isinstance(hash(m), int)\n+\n+\n+def test_immutable_with_unhashable_fields_are_not_hashable():\n+    class TestModel(BaseModel):\n+        a: int = 10\n+        y: List[int] = [1, 2, 3]\n+\n+        class Config:\n+            allow_mutation = False\n+\n+    m = TestModel()\n+    with pytest.raises(TypeError) as exc_info:\n+        hash(m)\n+    assert \"unhashable type: 'list'\" in exc_info.value.args[0]",
      "comment": "IMO would be nice for the exception message to be more like \"unhashable type: 'TestModel' contains unhashable type: 'list'  but I wouldn't say it's a strong opinion.  Food for thought.",
      "comment_id": 490416671,
      "user": "wozniakty",
      "created_at": "2020-09-17T16:57:54Z",
      "url": "https://github.com/pydantic/pydantic/pull/1881#discussion_r490416671"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 1881,
      "file_path": "pydantic/main.py",
      "line": 316,
      "side": "RIGHT",
      "diff_hunk": "@@ -313,6 +313,7 @@ def __new__(mcs, name, bases, namespace, **kwargs):  # noqa C901\n             '__schema_cache__': {},\n             '__json_encoder__': staticmethod(json_encoder),\n             '__custom_root_type__': _custom_root_type,\n+            '__hash__': (lambda self: hash(tuple(self.__dict__.values()))) if not config.allow_mutation else None,",
      "comment": "In that case, we diverge from behaviour of the built-in dataclass. But I do not know if it is a problem.\r\nIf it not a problem, then I agree with you ! :)",
      "comment_id": 498257798,
      "user": "rhuille",
      "created_at": "2020-10-01T13:48:07Z",
      "url": "https://github.com/pydantic/pydantic/pull/1881#discussion_r498257798"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 1881,
      "file_path": "pydantic/main.py",
      "line": 316,
      "side": "RIGHT",
      "diff_hunk": "@@ -313,6 +313,7 @@ def __new__(mcs, name, bases, namespace, **kwargs):  # noqa C901\n             '__schema_cache__': {},\n             '__json_encoder__': staticmethod(json_encoder),\n             '__custom_root_type__': _custom_root_type,\n+            '__hash__': (lambda self: hash(tuple(self.__dict__.values()))) if not config.allow_mutation else None,",
      "comment": "I don't think this needs to be a lambda, it can be proper method on `BaseModel` I imagine. It could raise an error if `allow_mutation is True` .\r\n",
      "comment_id": 502362557,
      "user": "samuelcolvin",
      "created_at": "2020-10-09T11:25:49Z",
      "url": "https://github.com/pydantic/pydantic/pull/1881#discussion_r502362557"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 1881,
      "file_path": "pydantic/main.py",
      "line": 316,
      "side": "RIGHT",
      "diff_hunk": "@@ -313,6 +313,7 @@ def __new__(mcs, name, bases, namespace, **kwargs):  # noqa C901\n             '__schema_cache__': {},\n             '__json_encoder__': staticmethod(json_encoder),\n             '__custom_root_type__': _custom_root_type,\n+            '__hash__': (lambda self: hash(tuple(self.__dict__.values()))) if not config.allow_mutation else None,",
      "comment": "okay, so it can't just be a method on `BaseModel`, but let's make it a proper function, not a lambda.",
      "comment_id": 502392221,
      "user": "samuelcolvin",
      "created_at": "2020-10-09T12:28:13Z",
      "url": "https://github.com/pydantic/pydantic/pull/1881#discussion_r502392221"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 1881,
      "file_path": "pydantic/main.py",
      "line": 316,
      "side": "RIGHT",
      "diff_hunk": "@@ -313,6 +313,7 @@ def __new__(mcs, name, bases, namespace, **kwargs):  # noqa C901\n             '__schema_cache__': {},\n             '__json_encoder__': staticmethod(json_encoder),\n             '__custom_root_type__': _custom_root_type,\n+            '__hash__': (lambda self: hash(tuple(self.__dict__.values()))) if not config.allow_mutation else None,",
      "comment": "> Instead of `.values` we should probably have `.items` here. The keys ought to be considered a part of the identity of the object.\r\n\r\nI think this would be unnecessary if we include a reference to the model class.",
      "comment_id": 502398896,
      "user": "layday",
      "created_at": "2020-10-09T12:40:45Z",
      "url": "https://github.com/pydantic/pydantic/pull/1881#discussion_r502398896"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 1881,
      "file_path": "pydantic/main.py",
      "line": 332,
      "side": "RIGHT",
      "diff_hunk": "@@ -321,6 +329,7 @@ def __new__(mcs, name, bases, namespace, **kwargs):  # noqa C901\n             '__custom_root_type__': _custom_root_type,\n             '__private_attributes__': private_attributes,\n             '__slots__': slots | private_attributes.keys(),\n+            '__hash__': generate_hash_function(config.frozen, super()),",
      "comment": "`super()` is the metaclass here. I don't understand why you need to do that \ud83e\udd14 ",
      "comment_id": 560801908,
      "user": "PrettyWood",
      "created_at": "2021-01-20T09:16:48Z",
      "url": "https://github.com/pydantic/pydantic/pull/1881#discussion_r560801908"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 1881,
      "file_path": "pydantic/main.py",
      "line": 204,
      "side": "RIGHT",
      "diff_hunk": "@@ -198,6 +199,13 @@ def validate_custom_root_type(fields: Dict[str, ModelField]) -> None:\n         raise ValueError('__root__ cannot be mixed with other fields')\n \n \n+def generate_hash_function(frozen: bool, super_class: Any) -> Optional[Callable[[Any], int]]:\n+    def hash_function(self_: Any) -> int:\n+        return hash(super_class) + hash(tuple(self_.__dict__.values()))",
      "comment": "IMO you could just do `hash(self_.__class__)` instead of using `super_class`",
      "comment_id": 560802090,
      "user": "PrettyWood",
      "created_at": "2021-01-20T09:17:07Z",
      "url": "https://github.com/pydantic/pydantic/pull/1881#discussion_r560802090"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 1881,
      "file_path": "pydantic/main.py",
      "line": 204,
      "side": "RIGHT",
      "diff_hunk": "@@ -198,6 +199,13 @@ def validate_custom_root_type(fields: Dict[str, ModelField]) -> None:\n         raise ValueError('__root__ cannot be mixed with other fields')\n \n \n+def generate_hash_function(frozen: bool, super_class: Any) -> Optional[Callable[[Any], int]]:\n+    def hash_function(self_: Any) -> int:\n+        return hash(super_class) + hash(tuple(self_.__dict__.values()))",
      "comment": "Yes your are right ! https://github.com/samuelcolvin/pydantic/pull/1881/commits/12cff48de640035718d1308c04eb007fe5e1ef05 (I was overthinked this...)",
      "comment_id": 565464587,
      "user": "rhuille",
      "created_at": "2021-01-27T16:45:40Z",
      "url": "https://github.com/pydantic/pydantic/pull/1881#discussion_r565464587"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 1881,
      "file_path": "tests/mypy/modules/plugin_fail.py",
      "line": 224,
      "side": "RIGHT",
      "diff_hunk": "@@ -202,3 +202,37 @@ class AddProject:\n \n \n p = AddProject(name='x', slug='y', description='z')\n+\n+\n+# Same as Model, but with frozen = True\n+class FrozenModel(BaseModel):\n+    x: int\n+    y: str\n+\n+    def method(self) -> None:\n+        pass\n+\n+    class Config:\n+        alias_generator = None\n+        frozen = True\n+        extra = Extra.forbid\n+\n+        def config_method(self) -> None:\n+            ...\n+\n+\n+frozenmodel = FrozenModel(x=1, y='y', z='z')",
      "comment": "this isn't testing frozen behaviour I think, again can be removed.",
      "comment_id": 575662771,
      "user": "samuelcolvin",
      "created_at": "2021-02-13T12:40:41Z",
      "url": "https://github.com/pydantic/pydantic/pull/1881#discussion_r575662771"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 1881,
      "file_path": "tests/mypy/modules/plugin_success.py",
      "line": 152,
      "side": "RIGHT",
      "diff_hunk": "@@ -139,3 +139,22 @@ class Model(BaseModel):\n \n dynamic_model = DynamicModel(x=1, y='y')\n dynamic_model.x = 2\n+\n+\n+class FrozenModel(BaseModel):\n+    x: int\n+\n+    class Config:\n+        frozen = True\n+\n+\n+class NotFrozenModel(FrozenModel):\n+    a = 1",
      "comment": "add a type here to avoid extra errors in `plugin-success-strict.txt `",
      "comment_id": 575662903,
      "user": "samuelcolvin",
      "created_at": "2021-02-13T12:42:16Z",
      "url": "https://github.com/pydantic/pydantic/pull/1881#discussion_r575662903"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 1881,
      "file_path": "tests/test_main.py",
      "line": 368,
      "side": "RIGHT",
      "diff_hunk": "@@ -351,39 +351,96 @@ class Model(BaseModel):\n     assert exc_info.value.errors() == [{'loc': ('a',), 'msg': 'field required', 'type': 'value_error.missing'}]\n \n \n-def test_not_immutability():\n+@pytest.mark.parametrize('allow_mutation_, frozen_', [(False, False), (True, False), (False, True), (True, True)])\n+def test_immutability(allow_mutation_, frozen_):\n     class TestModel(BaseModel):\n         a: int = 10\n \n         class Config:\n-            allow_mutation = True\n+            allow_mutation = allow_mutation_\n             extra = Extra.forbid\n+            frozen = frozen_\n \n     m = TestModel()\n-    assert m.a == 10\n-    m.a = 11\n-    assert m.a == 11\n-    with pytest.raises(ValueError) as exc_info:\n-        m.b = 11\n-    assert '\"TestModel\" object has no field \"b\"' in exc_info.value.args[0]\n+\n+    immutable = allow_mutation_ is False or frozen_ is True\n+\n+    if immutable:",
      "comment": "rather than this if clause, better to setup two separate tests.",
      "comment_id": 575662957,
      "user": "samuelcolvin",
      "created_at": "2021-02-13T12:43:25Z",
      "url": "https://github.com/pydantic/pydantic/pull/1881#discussion_r575662957"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12051,
      "file_path": "tests/test_dataclasses.py",
      "line": 2146,
      "side": "RIGHT",
      "diff_hunk": "@@ -2115,6 +2115,34 @@ class Child(Parent):\n     assert Child().a == 1\n \n \n+def test_dataclasses_inheritance_bare_class_not_used() -> None:\n+    \"\"\"https://github.com/pydantic/pydantic/issues/12045\"\"\"\n+\n+    class BareClass:\n+        a: int = Field(kw_only=True)\n+\n+    @pydantic.dataclasses.dataclass\n+    class DC(BareClass):\n+        pass\n+\n+    assert len(DC.__dataclass_fields__) == 0\n+    assert len(DC.__pydantic_fields__) == 0\n+\n+\n+def test_dataclasses_type_override_pydantic_field() -> None:\n+    \"\"\"https://github.com/pydantic/pydantic/issues/12045\"\"\"\n+\n+    @dataclasses.dataclass\n+    class A:\n+        a: int = Field()\n+\n+    @pydantic.dataclasses.dataclass\n+    class B(A):\n+        a: str = dataclasses.field()\n+\n+    assert B(a='test').a == 'test'",
      "comment": "These two tests are technically breaking changes, but this was just undefined behavior and imo actual bugs. I think we should update our [stability policy](https://docs.pydantic.dev/latest/version-policy/#pydantic-v2) to state that bug fixes resulting in theoretical breaking change can be occur in minor releases. ",
      "comment_id": 2197144618,
      "user": "Viicos",
      "created_at": "2025-07-10T09:38:27Z",
      "url": "https://github.com/pydantic/pydantic/pull/12051#discussion_r2197144618"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12051,
      "file_path": "tests/test_dataclasses.py",
      "line": 2146,
      "side": "RIGHT",
      "diff_hunk": "@@ -2115,6 +2115,34 @@ class Child(Parent):\n     assert Child().a == 1\n \n \n+def test_dataclasses_inheritance_bare_class_not_used() -> None:\n+    \"\"\"https://github.com/pydantic/pydantic/issues/12045\"\"\"\n+\n+    class BareClass:\n+        a: int = Field(kw_only=True)\n+\n+    @pydantic.dataclasses.dataclass\n+    class DC(BareClass):\n+        pass\n+\n+    assert len(DC.__dataclass_fields__) == 0\n+    assert len(DC.__pydantic_fields__) == 0\n+\n+\n+def test_dataclasses_type_override_pydantic_field() -> None:\n+    \"\"\"https://github.com/pydantic/pydantic/issues/12045\"\"\"\n+\n+    @dataclasses.dataclass\n+    class A:\n+        a: int = Field()\n+\n+    @pydantic.dataclasses.dataclass\n+    class B(A):\n+        a: str = dataclasses.field()\n+\n+    assert B(a='test').a == 'test'",
      "comment": "I think yes, as long as we also qualify that by saying that we'll make judgement call based on how much we expect the theoretical breaking change to actually be a real-world problem.",
      "comment_id": 2197348987,
      "user": "davidhewitt",
      "created_at": "2025-07-10T10:45:32Z",
      "url": "https://github.com/pydantic/pydantic/pull/12051#discussion_r2197348987"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12051,
      "file_path": "tests/test_dataclasses.py",
      "line": 2146,
      "side": "RIGHT",
      "diff_hunk": "@@ -2115,6 +2115,34 @@ class Child(Parent):\n     assert Child().a == 1\n \n \n+def test_dataclasses_inheritance_bare_class_not_used() -> None:\n+    \"\"\"https://github.com/pydantic/pydantic/issues/12045\"\"\"\n+\n+    class BareClass:\n+        a: int = Field(kw_only=True)\n+\n+    @pydantic.dataclasses.dataclass\n+    class DC(BareClass):\n+        pass\n+\n+    assert len(DC.__dataclass_fields__) == 0\n+    assert len(DC.__pydantic_fields__) == 0\n+\n+\n+def test_dataclasses_type_override_pydantic_field() -> None:\n+    \"\"\"https://github.com/pydantic/pydantic/issues/12045\"\"\"\n+\n+    @dataclasses.dataclass\n+    class A:\n+        a: int = Field()\n+\n+    @pydantic.dataclasses.dataclass\n+    class B(A):\n+        a: str = dataclasses.field()\n+\n+    assert B(a='test').a == 'test'",
      "comment": "Yep, in this case you'd have to make use of a stdlib (that is not a Pydantic) dataclass or a bare class _with_ a Pydantic field used on it, which is pretty uncommon already.",
      "comment_id": 2197559701,
      "user": "Viicos",
      "created_at": "2025-07-10T12:15:11Z",
      "url": "https://github.com/pydantic/pydantic/pull/12051#discussion_r2197559701"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12051,
      "file_path": "pydantic/_internal/_dataclasses.py",
      "line": 278,
      "side": "RIGHT",
      "diff_hunk": "@@ -203,3 +208,105 @@ def is_stdlib_dataclass(cls: type[Any], /) -> TypeIs[type[StandardDataclass]]:\n         `True` if the class is a stdlib dataclass, `False` otherwise.\n     \"\"\"\n     return '__dataclass_fields__' in cls.__dict__ and not hasattr(cls, '__pydantic_validator__')\n+\n+\n+def as_dataclass_field(pydantic_field: FieldInfo) -> dataclasses.Field[Any]:\n+    field_args: dict[str, Any] = {'default': pydantic_field}\n+\n+    if sys.version_info >= (3, 10) and pydantic_field.kw_only:\n+        field_args['kw_only'] = True\n+\n+    if pydantic_field.repr is not True:\n+        field_args['repr'] = pydantic_field.repr\n+\n+    return dataclasses.field(**field_args)\n+\n+\n+DcFields: TypeAlias = dict[str, dataclasses.Field[Any]]\n+\n+\n+@contextmanager\n+def patch_base_fields(cls: type[Any]) -> Generator[None]:\n+    \"\"\"Temporarily patch the stdlib dataclasses bases of `cls` if the Pydantic `Field()` function is used.\n+\n+    When creating a Pydantic dataclass, it is possible to inherit from stdlib dataclasses, where\n+    the Pydantic `Field()` function is used. To create this Pydantic dataclass, we first apply\n+    the stdlib `@dataclass` decorator on it. During the construction of the stdlib dataclass,\n+    the `kw_only` and `repr` field arguments need to be understood by the stdlib *during* the\n+    dataclass construction. To do so, we temporarily patch the fields dictionary of the affected\n+    bases.\n+\n+    For instance, with the following example:\n+\n+    ```python {test=\"skip\" lint=\"skip\"}\n+    import dataclasses as stdlib_dc\n+\n+    import pydantic\n+    import pydantic.dataclasses as pydantic_dc\n+\n+    @stdlib_dc.dataclass\n+    class A:\n+        a: int = pydantic.Field(repr=False)\n+\n+    # Notice that the `repr` attribute of the dataclass field is `True`:\n+    A.__dataclass_fields__['a']\n+    #> dataclass.Field(default=FieldInfo(repr=False), repr=True, ...)\n+\n+    @pydantic_dc.dataclass\n+    class B(A):\n+        b: int = pydantic.Field(repr=False)\n+    ```\n+\n+    When passing `B` to the stdlib `@dataclass` decorator, it will look for fields in the parent classes\n+    and reuse them directly. When this contextmanager is active, `A` will be temporarily patched to be\n+    equivalent to:\n+\n+    ```python {test=\"skip\" lint=\"skip\"}\n+    @stdlib_dc.dataclass\n+    class A:\n+        a: int = stdlib_dc.field(default=Field(repr=False), repr=False)\n+    ```\n+\n+    !!! note\n+        This is only applied to the bases of `cls`, and not `cls` itself. The reason is that the Pydantic\n+        dataclass decorator \"owns\" `cls` (in the previous example, `B`). As such, we instead modify the fields\n+        directly (in the previous example, we simply do `setattr(B, 'b', as_dataclass_field(pydantic_field))`).\n+\n+    !!! note\n+        This approach is far from ideal, and can probably be the source of unwanted side effects/race conditions.\n+        The previous implemented approach was mutating the `__annotations__` dict of `cls`, which is no longer a\n+        safe operation in Python 3.14+, and resulted in unexpected behavior with field ordering anyway.",
      "comment": "Agreed, scary. If this became a problem, I think we could do stuff like set the field to be a wrapper object which checks what thread it's on and only exhibits the patched behaviour on this thread, but even that is observable so why bother \ud83d\ude22 ",
      "comment_id": 2210853813,
      "user": "davidhewitt",
      "created_at": "2025-07-16T16:02:36Z",
      "url": "https://github.com/pydantic/pydantic/pull/12051#discussion_r2210853813"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12051,
      "file_path": "pydantic/_internal/_dataclasses.py",
      "line": 305,
      "side": "RIGHT",
      "diff_hunk": "@@ -203,3 +208,105 @@ def is_stdlib_dataclass(cls: type[Any], /) -> TypeIs[type[StandardDataclass]]:\n         `True` if the class is a stdlib dataclass, `False` otherwise.\n     \"\"\"\n     return '__dataclass_fields__' in cls.__dict__ and not hasattr(cls, '__pydantic_validator__')\n+\n+\n+def as_dataclass_field(pydantic_field: FieldInfo) -> dataclasses.Field[Any]:\n+    field_args: dict[str, Any] = {'default': pydantic_field}\n+\n+    if sys.version_info >= (3, 10) and pydantic_field.kw_only:\n+        field_args['kw_only'] = True\n+\n+    if pydantic_field.repr is not True:\n+        field_args['repr'] = pydantic_field.repr\n+\n+    return dataclasses.field(**field_args)\n+\n+\n+DcFields: TypeAlias = dict[str, dataclasses.Field[Any]]\n+\n+\n+@contextmanager\n+def patch_base_fields(cls: type[Any]) -> Generator[None]:\n+    \"\"\"Temporarily patch the stdlib dataclasses bases of `cls` if the Pydantic `Field()` function is used.\n+\n+    When creating a Pydantic dataclass, it is possible to inherit from stdlib dataclasses, where\n+    the Pydantic `Field()` function is used. To create this Pydantic dataclass, we first apply\n+    the stdlib `@dataclass` decorator on it. During the construction of the stdlib dataclass,\n+    the `kw_only` and `repr` field arguments need to be understood by the stdlib *during* the\n+    dataclass construction. To do so, we temporarily patch the fields dictionary of the affected\n+    bases.\n+\n+    For instance, with the following example:\n+\n+    ```python {test=\"skip\" lint=\"skip\"}\n+    import dataclasses as stdlib_dc\n+\n+    import pydantic\n+    import pydantic.dataclasses as pydantic_dc\n+\n+    @stdlib_dc.dataclass\n+    class A:\n+        a: int = pydantic.Field(repr=False)\n+\n+    # Notice that the `repr` attribute of the dataclass field is `True`:\n+    A.__dataclass_fields__['a']\n+    #> dataclass.Field(default=FieldInfo(repr=False), repr=True, ...)\n+\n+    @pydantic_dc.dataclass\n+    class B(A):\n+        b: int = pydantic.Field(repr=False)\n+    ```\n+\n+    When passing `B` to the stdlib `@dataclass` decorator, it will look for fields in the parent classes\n+    and reuse them directly. When this contextmanager is active, `A` will be temporarily patched to be\n+    equivalent to:\n+\n+    ```python {test=\"skip\" lint=\"skip\"}\n+    @stdlib_dc.dataclass\n+    class A:\n+        a: int = stdlib_dc.field(default=Field(repr=False), repr=False)\n+    ```\n+\n+    !!! note\n+        This is only applied to the bases of `cls`, and not `cls` itself. The reason is that the Pydantic\n+        dataclass decorator \"owns\" `cls` (in the previous example, `B`). As such, we instead modify the fields\n+        directly (in the previous example, we simply do `setattr(B, 'b', as_dataclass_field(pydantic_field))`).\n+\n+    !!! note\n+        This approach is far from ideal, and can probably be the source of unwanted side effects/race conditions.\n+        The previous implemented approach was mutating the `__annotations__` dict of `cls`, which is no longer a\n+        safe operation in Python 3.14+, and resulted in unexpected behavior with field ordering anyway.\n+    \"\"\"\n+    # A list of two-tuples, the first element being a reference to the\n+    # dataclass fields dictionary, the second element being a mapping between\n+    # the field names that were modified, and their original `Field`:\n+    original_fields_list: list[tuple[DcFields, DcFields]] = []\n+\n+    for base in cls.__mro__[1:]:\n+        dc_fields: dict[str, dataclasses.Field[Any]] = base.__dict__.get('__dataclass_fields__', {})\n+        dc_fields_with_pydantic_field_defaults = {\n+            field_name: field\n+            for field_name, field in dc_fields.items()\n+            if isinstance(field.default, FieldInfo)\n+            # Only do the patching if one of the affected attributes is set:\n+            and (field.default.kw_only or field.default.repr is not True)\n+        }\n+        if dc_fields_with_pydantic_field_defaults:\n+            original_fields_list.append((dc_fields, dc_fields_with_pydantic_field_defaults))\n+            for field_name, field in dc_fields_with_pydantic_field_defaults.items():\n+                default = cast(FieldInfo, field.default)\n+                # `dataclasses.Field` isn't documented as working with `copy.copy()`.\n+                # It is a class with `__slots__`, so should work (and we hope for the best):\n+                new_dc_field = copy.copy(field)\n+                if default.kw_only:\n+                    new_dc_field.kw_only = True\n+                if default.repr is not True:\n+                    new_dc_field.repr = default.repr\n+                dc_fields[field_name] = new_dc_field",
      "comment": "I wonder, rather than mutating the fields of the base objects, is there a world where we instead patch the class attributes of the type under construction? That might be significantly less far-reaching in potential conflict?",
      "comment_id": 2210866912,
      "user": "davidhewitt",
      "created_at": "2025-07-16T16:08:41Z",
      "url": "https://github.com/pydantic/pydantic/pull/12051#discussion_r2210866912"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12051,
      "file_path": "pydantic/_internal/_dataclasses.py",
      "line": 305,
      "side": "RIGHT",
      "diff_hunk": "@@ -203,3 +208,105 @@ def is_stdlib_dataclass(cls: type[Any], /) -> TypeIs[type[StandardDataclass]]:\n         `True` if the class is a stdlib dataclass, `False` otherwise.\n     \"\"\"\n     return '__dataclass_fields__' in cls.__dict__ and not hasattr(cls, '__pydantic_validator__')\n+\n+\n+def as_dataclass_field(pydantic_field: FieldInfo) -> dataclasses.Field[Any]:\n+    field_args: dict[str, Any] = {'default': pydantic_field}\n+\n+    if sys.version_info >= (3, 10) and pydantic_field.kw_only:\n+        field_args['kw_only'] = True\n+\n+    if pydantic_field.repr is not True:\n+        field_args['repr'] = pydantic_field.repr\n+\n+    return dataclasses.field(**field_args)\n+\n+\n+DcFields: TypeAlias = dict[str, dataclasses.Field[Any]]\n+\n+\n+@contextmanager\n+def patch_base_fields(cls: type[Any]) -> Generator[None]:\n+    \"\"\"Temporarily patch the stdlib dataclasses bases of `cls` if the Pydantic `Field()` function is used.\n+\n+    When creating a Pydantic dataclass, it is possible to inherit from stdlib dataclasses, where\n+    the Pydantic `Field()` function is used. To create this Pydantic dataclass, we first apply\n+    the stdlib `@dataclass` decorator on it. During the construction of the stdlib dataclass,\n+    the `kw_only` and `repr` field arguments need to be understood by the stdlib *during* the\n+    dataclass construction. To do so, we temporarily patch the fields dictionary of the affected\n+    bases.\n+\n+    For instance, with the following example:\n+\n+    ```python {test=\"skip\" lint=\"skip\"}\n+    import dataclasses as stdlib_dc\n+\n+    import pydantic\n+    import pydantic.dataclasses as pydantic_dc\n+\n+    @stdlib_dc.dataclass\n+    class A:\n+        a: int = pydantic.Field(repr=False)\n+\n+    # Notice that the `repr` attribute of the dataclass field is `True`:\n+    A.__dataclass_fields__['a']\n+    #> dataclass.Field(default=FieldInfo(repr=False), repr=True, ...)\n+\n+    @pydantic_dc.dataclass\n+    class B(A):\n+        b: int = pydantic.Field(repr=False)\n+    ```\n+\n+    When passing `B` to the stdlib `@dataclass` decorator, it will look for fields in the parent classes\n+    and reuse them directly. When this contextmanager is active, `A` will be temporarily patched to be\n+    equivalent to:\n+\n+    ```python {test=\"skip\" lint=\"skip\"}\n+    @stdlib_dc.dataclass\n+    class A:\n+        a: int = stdlib_dc.field(default=Field(repr=False), repr=False)\n+    ```\n+\n+    !!! note\n+        This is only applied to the bases of `cls`, and not `cls` itself. The reason is that the Pydantic\n+        dataclass decorator \"owns\" `cls` (in the previous example, `B`). As such, we instead modify the fields\n+        directly (in the previous example, we simply do `setattr(B, 'b', as_dataclass_field(pydantic_field))`).\n+\n+    !!! note\n+        This approach is far from ideal, and can probably be the source of unwanted side effects/race conditions.\n+        The previous implemented approach was mutating the `__annotations__` dict of `cls`, which is no longer a\n+        safe operation in Python 3.14+, and resulted in unexpected behavior with field ordering anyway.\n+    \"\"\"\n+    # A list of two-tuples, the first element being a reference to the\n+    # dataclass fields dictionary, the second element being a mapping between\n+    # the field names that were modified, and their original `Field`:\n+    original_fields_list: list[tuple[DcFields, DcFields]] = []\n+\n+    for base in cls.__mro__[1:]:\n+        dc_fields: dict[str, dataclasses.Field[Any]] = base.__dict__.get('__dataclass_fields__', {})\n+        dc_fields_with_pydantic_field_defaults = {\n+            field_name: field\n+            for field_name, field in dc_fields.items()\n+            if isinstance(field.default, FieldInfo)\n+            # Only do the patching if one of the affected attributes is set:\n+            and (field.default.kw_only or field.default.repr is not True)\n+        }\n+        if dc_fields_with_pydantic_field_defaults:\n+            original_fields_list.append((dc_fields, dc_fields_with_pydantic_field_defaults))\n+            for field_name, field in dc_fields_with_pydantic_field_defaults.items():\n+                default = cast(FieldInfo, field.default)\n+                # `dataclasses.Field` isn't documented as working with `copy.copy()`.\n+                # It is a class with `__slots__`, so should work (and we hope for the best):\n+                new_dc_field = copy.copy(field)\n+                if default.kw_only:\n+                    new_dc_field.kw_only = True\n+                if default.repr is not True:\n+                    new_dc_field.repr = default.repr\n+                dc_fields[field_name] = new_dc_field",
      "comment": "The issue is that the dataclasses module is doing roughly:\r\n\r\n```python\r\nfields: dict[str, Field] = {}\r\n\r\nfor b in cls.__mro__[-1:0:-1]:\r\n    base_fields = getattr(b, '__dataclass_fields__', None)\r\n    if base_fields is not None:\r\n        for f_name, f in base_fields.items():\r\n            fields[f_name] = f\r\n\r\n# Then fetch the annotations of the class under construction and build fields for it\r\n```\r\n\r\nI thought about patching the whole `__dataclass_fields__` attribute directly, without mutating the original dict, but I don't know which one is best. I think we can revisit if we ever get issues.",
      "comment_id": 2212331202,
      "user": "Viicos",
      "created_at": "2025-07-17T05:46:55Z",
      "url": "https://github.com/pydantic/pydantic/pull/12051#discussion_r2212331202"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12051,
      "file_path": "pydantic/_internal/_dataclasses.py",
      "line": 278,
      "side": "RIGHT",
      "diff_hunk": "@@ -203,3 +208,105 @@ def is_stdlib_dataclass(cls: type[Any], /) -> TypeIs[type[StandardDataclass]]:\n         `True` if the class is a stdlib dataclass, `False` otherwise.\n     \"\"\"\n     return '__dataclass_fields__' in cls.__dict__ and not hasattr(cls, '__pydantic_validator__')\n+\n+\n+def as_dataclass_field(pydantic_field: FieldInfo) -> dataclasses.Field[Any]:\n+    field_args: dict[str, Any] = {'default': pydantic_field}\n+\n+    if sys.version_info >= (3, 10) and pydantic_field.kw_only:\n+        field_args['kw_only'] = True\n+\n+    if pydantic_field.repr is not True:\n+        field_args['repr'] = pydantic_field.repr\n+\n+    return dataclasses.field(**field_args)\n+\n+\n+DcFields: TypeAlias = dict[str, dataclasses.Field[Any]]\n+\n+\n+@contextmanager\n+def patch_base_fields(cls: type[Any]) -> Generator[None]:\n+    \"\"\"Temporarily patch the stdlib dataclasses bases of `cls` if the Pydantic `Field()` function is used.\n+\n+    When creating a Pydantic dataclass, it is possible to inherit from stdlib dataclasses, where\n+    the Pydantic `Field()` function is used. To create this Pydantic dataclass, we first apply\n+    the stdlib `@dataclass` decorator on it. During the construction of the stdlib dataclass,\n+    the `kw_only` and `repr` field arguments need to be understood by the stdlib *during* the\n+    dataclass construction. To do so, we temporarily patch the fields dictionary of the affected\n+    bases.\n+\n+    For instance, with the following example:\n+\n+    ```python {test=\"skip\" lint=\"skip\"}\n+    import dataclasses as stdlib_dc\n+\n+    import pydantic\n+    import pydantic.dataclasses as pydantic_dc\n+\n+    @stdlib_dc.dataclass\n+    class A:\n+        a: int = pydantic.Field(repr=False)\n+\n+    # Notice that the `repr` attribute of the dataclass field is `True`:\n+    A.__dataclass_fields__['a']\n+    #> dataclass.Field(default=FieldInfo(repr=False), repr=True, ...)\n+\n+    @pydantic_dc.dataclass\n+    class B(A):\n+        b: int = pydantic.Field(repr=False)\n+    ```\n+\n+    When passing `B` to the stdlib `@dataclass` decorator, it will look for fields in the parent classes\n+    and reuse them directly. When this contextmanager is active, `A` will be temporarily patched to be\n+    equivalent to:\n+\n+    ```python {test=\"skip\" lint=\"skip\"}\n+    @stdlib_dc.dataclass\n+    class A:\n+        a: int = stdlib_dc.field(default=Field(repr=False), repr=False)\n+    ```\n+\n+    !!! note\n+        This is only applied to the bases of `cls`, and not `cls` itself. The reason is that the Pydantic\n+        dataclass decorator \"owns\" `cls` (in the previous example, `B`). As such, we instead modify the fields\n+        directly (in the previous example, we simply do `setattr(B, 'b', as_dataclass_field(pydantic_field))`).\n+\n+    !!! note\n+        This approach is far from ideal, and can probably be the source of unwanted side effects/race conditions.\n+        The previous implemented approach was mutating the `__annotations__` dict of `cls`, which is no longer a\n+        safe operation in Python 3.14+, and resulted in unexpected behavior with field ordering anyway.",
      "comment": "Yeah I think if we ever get issues about this, we could wrap the mutation in a threading lock (similar to what I've initially tried to do in https://github.com/pydantic/pydantic/pull/11851). For this to be an issue, a user would have to dynamically create Pydantic dataclasses in a multi-threaded environment, and have them subclassing a stdlib dataclass with at least one field using the Pydantic's `Field()` function which is quite unlikely to happen.",
      "comment_id": 2212339644,
      "user": "Viicos",
      "created_at": "2025-07-17T05:53:26Z",
      "url": "https://github.com/pydantic/pydantic/pull/12051#discussion_r2212339644"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11759,
      "file_path": "pydantic/_internal/_model_construction.py",
      "line": 588,
      "side": "RIGHT",
      "diff_hunk": "@@ -587,6 +586,27 @@ def complete_model_class(\n             and `raise_errors=True`.\n     \"\"\"\n     typevars_map = get_model_typevars_map(cls)\n+\n+    if not cls.__pydantic_fields_complete__:",
      "comment": "Was the change required to implement the hook?\r\n\r\nIn both situations, we have inconsistent behavior but this can only be easily fixed if/when we remove support for accessing incomplete `model_fields` (well we can also make it so that `collect_model_fields()` \u2014 currently lenient to unresolvable type hints \u2014 also returns the `NameError`s, but this is quite ugly).\r\n\r\nWhen a model with unresolvable forward references is defined:\r\n\r\n- On `main`, we call `collect_model_fields()`, and then go through the `GenerateSchema` process, which will end up calling `rebuild_model_fields()`:\r\n\r\n    https://github.com/pydantic/pydantic/blob/625dd4284b266c17f0b70d282f237dd3ee7ec9f2/pydantic/_internal/_generate_schema.py#L741-L749\r\n\r\n- On this branch, we call `collect_model_fields()` and then call `rebuild_model_fields()` here.\r\n\r\n(In both cases, fields collection happens twice).",
      "comment_id": 2046466779,
      "user": "Viicos",
      "created_at": "2025-04-16T09:08:54Z",
      "url": "https://github.com/pydantic/pydantic/pull/11759#discussion_r2046466779"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11759,
      "file_path": "pydantic/_internal/_model_construction.py",
      "line": 588,
      "side": "RIGHT",
      "diff_hunk": "@@ -587,6 +586,27 @@ def complete_model_class(\n             and `raise_errors=True`.\n     \"\"\"\n     typevars_map = get_model_typevars_map(cls)\n+\n+    if not cls.__pydantic_fields_complete__:",
      "comment": "@Viicos Not strictly necessary to implement the hook, but I want to guarantee that when the hook is called (and the complete boolean is set), the fields are complete as well (see first two paragraphs of the PR description).\r\n\r\nThe __pydantic_init_subclass__ description states that model_fields will be present (although not necessarily complete), so I think we need to keep separataly collecting the model fields quietly and rebuilding them loudly. We could possibly also have collect_model_fields behave quietly but return an extra list of names that raised NameErrors.\r\n\r\nLet me know if you'd like to see a change here or if this is acceptable.",
      "comment_id": 2047206101,
      "user": "DouweM",
      "created_at": "2025-04-16T15:36:01Z",
      "url": "https://github.com/pydantic/pydantic/pull/11759#discussion_r2047206101"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11759,
      "file_path": "pydantic/_internal/_model_construction.py",
      "line": 588,
      "side": "RIGHT",
      "diff_hunk": "@@ -587,6 +586,27 @@ def complete_model_class(\n             and `raise_errors=True`.\n     \"\"\"\n     typevars_map = get_model_typevars_map(cls)\n+\n+    if not cls.__pydantic_fields_complete__:",
      "comment": "> We now do the same on `ModelMetaclass.__new__`, to make sure that subclasses of incomplete superclasses don't incorrectly get marked as complete.\r\n\r\nHum, did you have any example where this happened? When we create the model fields for a subclass, we copy the parent `FieldInfo` instances, keeping the `_complete` property.",
      "comment_id": 2047469054,
      "user": "Viicos",
      "created_at": "2025-04-16T18:12:24Z",
      "url": "https://github.com/pydantic/pydantic/pull/11759#discussion_r2047469054"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11759,
      "file_path": "pydantic/_internal/_model_construction.py",
      "line": 588,
      "side": "RIGHT",
      "diff_hunk": "@@ -587,6 +586,27 @@ def complete_model_class(\n             and `raise_errors=True`.\n     \"\"\"\n     typevars_map = get_model_typevars_map(cls)\n+\n+    if not cls.__pydantic_fields_complete__:",
      "comment": "@Viicos This is what I was describing in https://github.com/pydantic/pydantic/issues/11453#issuecomment-2803435274, where I added `assert cls.__pydantic_fields_complete__` at the end of `complete_model_class` (after `__pydantic_complete__ = True` and it failed in one test with a super and submodel. Rebuilding the fields solved the issue, because `SubModel` can resolve the `'SubModel'` ref to itself. You mentioned there that that was expected but not ideal, so I thought I'd fix it.",
      "comment_id": 2047478795,
      "user": "DouweM",
      "created_at": "2025-04-16T18:19:06Z",
      "url": "https://github.com/pydantic/pydantic/pull/11759#discussion_r2047478795"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11759,
      "file_path": "pydantic/_internal/_model_construction.py",
      "line": 562,
      "side": "RIGHT",
      "diff_hunk": "@@ -562,9 +559,9 @@ def set_model_fields(\n def complete_model_class(\n     cls: type[BaseModel],\n     config_wrapper: ConfigWrapper,\n+    ns_resolver: NsResolver,",
      "comment": "Let's update the order in the docstring and also where `complete_model_class()` is called.",
      "comment_id": 2048493997,
      "user": "Viicos",
      "created_at": "2025-04-17T08:30:29Z",
      "url": "https://github.com/pydantic/pydantic/pull/11759#discussion_r2048493997"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11759,
      "file_path": "pydantic/_internal/_model_construction.py",
      "line": 589,
      "side": "RIGHT",
      "diff_hunk": "@@ -587,6 +584,27 @@ def complete_model_class(\n             and `raise_errors=True`.\n     \"\"\"\n     typevars_map = get_model_typevars_map(cls)\n+\n+    if not cls.__pydantic_fields_complete__:\n+        # Rebuild the model fields so we can get the NameError for the specific undefined annotation",
      "comment": "```suggestion\r\n        # Note: when coming from `ModelMetaclass.__new__()`, this results in fields being built twice.\r\n        # We do so a second time here so that we can get the `NameError` for the specific undefined annotation.\r\n        # Alternatively, we could let `GenerateSchema()` raise the error, but there are cases where incomplete\r\n        # fields are inherited in `collect_model_fields()` and can actually have their annotation resolved in the\r\n        # generate schema process. As we want to avoid having `__pydantic_fields_complete__` set to `False`\r\n        # when `__pydantic_complete__` is `True`, we rebuild here:\r\n```",
      "comment_id": 2048511273,
      "user": "Viicos",
      "created_at": "2025-04-17T08:41:25Z",
      "url": "https://github.com/pydantic/pydantic/pull/11759#discussion_r2048511273"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11991,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 263,
      "side": "RIGHT",
      "diff_hunk": "@@ -259,7 +260,13 @@ def collect_model_fields(  # noqa: C901\n \n     # https://docs.python.org/3/howto/annotations.html#accessing-the-annotations-dict-of-an-object-in-python-3-9-and-older\n     # annotations is only used for finding fields in parent classes\n-    annotations = cls.__dict__.get('__annotations__', {})\n+    if sys.version_info >= (3, 14):",
      "comment": "I'll try to move this logic into a reusable function",
      "comment_id": 2190208996,
      "user": "Viicos",
      "created_at": "2025-07-07T14:01:01Z",
      "url": "https://github.com/pydantic/pydantic/pull/11991#discussion_r2190208996"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11991,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 268,
      "side": "RIGHT",
      "diff_hunk": "@@ -259,7 +260,13 @@ def collect_model_fields(  # noqa: C901\n \n     # https://docs.python.org/3/howto/annotations.html#accessing-the-annotations-dict-of-an-object-in-python-3-9-and-older\n     # annotations is only used for finding fields in parent classes\n-    annotations = cls.__dict__.get('__annotations__', {})\n+    if sys.version_info >= (3, 14):\n+        from annotationlib import Format, get_annotations\n+\n+        annotations = get_annotations(cls, format=Format.FORWARDREF)\n+    else:\n+        annotations = cls.__dict__.get('__annotations__', {})",
      "comment": "Think there's a call to `_typing_extra.safe_get_annotations(cls)` still to be added here?\r\n\r\n```suggestion\r\n    annotations = _typing_extra.safe_get_annotations(cls)\r\n```",
      "comment_id": 2197049949,
      "user": "davidhewitt",
      "created_at": "2025-07-10T08:57:18Z",
      "url": "https://github.com/pydantic/pydantic/pull/11991#discussion_r2197049949"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 12008,
      "file_path": "pydantic/types.py",
      "line": 1532,
      "side": "RIGHT",
      "diff_hunk": "@@ -1530,7 +1530,7 @@ def __eq__(self, other: Any) -> bool:\n \n # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ SECRET TYPES ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n ",
      "comment": "```suggestion\r\n\r\n# The `Secret` class being conceptually immutable, make the type variable covariant:\r\n```",
      "comment_id": 2177759350,
      "user": "Viicos",
      "created_at": "2025-07-01T14:28:42Z",
      "url": "https://github.com/pydantic/pydantic/pull/12008#discussion_r2177759350"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11914,
      "file_path": "pydantic/_internal/_fields.py",
      "line": 285,
      "side": "RIGHT",
      "diff_hunk": "@@ -265,6 +282,20 @@ def collect_model_fields(  # noqa: C901\n             continue\n \n         assigned_value = getattr(cls, ann_name, PydanticUndefined)\n+        if (",
      "comment": "I think we can make this a bit more performant by skipping the checks if `assigned_values is PydanticUndefined`",
      "comment_id": 2143344719,
      "user": "DouweM",
      "created_at": "2025-06-12T18:00:55Z",
      "url": "https://github.com/pydantic/pydantic/pull/11914#discussion_r2143344719"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/main.py",
      "line": 688,
      "side": "LEFT",
      "diff_hunk": "@@ -671,30 +671,6 @@ def model_validate_strings(\n         __tracebackhide__ = True\n         return cls.__pydantic_validator__.validate_strings(obj, strict=strict, context=context)\n \n-    @classmethod\n-    def __get_pydantic_core_schema__(cls, source: type[BaseModel], handler: GetCoreSchemaHandler, /) -> CoreSchema:",
      "comment": "I dont think this is a good idea. This is definitely being relied on. Its not internal and also documented for customizing the schema.",
      "comment_id": 1847732698,
      "user": "MarkusSintonen",
      "created_at": "2024-11-19T06:50:48Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1847732698"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/main.py",
      "line": 688,
      "side": "LEFT",
      "diff_hunk": "@@ -671,30 +671,6 @@ def model_validate_strings(\n         __tracebackhide__ = True\n         return cls.__pydantic_validator__.validate_strings(obj, strict=strict, context=context)\n \n-    @classmethod\n-    def __get_pydantic_core_schema__(cls, source: type[BaseModel], handler: GetCoreSchemaHandler, /) -> CoreSchema:",
      "comment": "But the perf improvement could be maybe done so that the `__get_pydantic_core_schema__` can not be overriden but instead coming from model_config (with similar args). Users then have option to migrate into that. Then if its defined in model config the perf improvements are not applied. (Didnt fully follow why its causing issues here but maybe possible)",
      "comment_id": 1847824205,
      "user": "MarkusSintonen",
      "created_at": "2024-11-19T07:52:34Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1847824205"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_core_utils.py",
      "line": 70,
      "side": "RIGHT",
      "diff_hunk": "@@ -66,6 +67,7 @@ def is_list_like_schema_with_items_schema(\n     return schema['type'] in _LIST_LIKE_SCHEMA_WITH_ITEMS_TYPES\n \n \n+@lru_cache",
      "comment": "Should it be some weak cache like in generics side to avoid (dynamic cough cough) models being leaked.",
      "comment_id": 1847840249,
      "user": "MarkusSintonen",
      "created_at": "2024-11-19T07:56:38Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1847840249"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_core_utils.py",
      "line": 70,
      "side": "RIGHT",
      "diff_hunk": "@@ -66,6 +67,7 @@ def is_list_like_schema_with_items_schema(\n     return schema['type'] in _LIST_LIKE_SCHEMA_WITH_ITEMS_TYPES\n \n \n+@lru_cache",
      "comment": "Yeah, I currently went with the default maxsize here (128) to avoid memory leaks, but this can still hold references to types/classes that should be gc'd, and with a small application where you have less than 128 referenceable types, this will never reach the limit and thus keep a reference to all of them.\r\n\r\nIt's a bit annoying that the `functools` cache utilities are limited in that aspect. It would be great if we could define our own cache key (currently hash) and customize the internal cache implementation (currently a dict). The `cachetools` 3rd party lib states [it supports](https://cachetools.readthedocs.io/en/latest/#cachetools.cached) using a `WeakValueDictionary`.\r\n\r\nOn the K8S file, with the cache impl, `get_type_ref` takes 30ms/~7s, without it takes 100ms/~7s, so I think we can live without it. Alternatively, we could a class level cached property on Pydantic models so that we only compute the reference once, I can take a look. ",
      "comment_id": 1848279501,
      "user": "Viicos",
      "created_at": "2024-11-19T12:33:59Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848279501"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/main.py",
      "line": 688,
      "side": "LEFT",
      "diff_hunk": "@@ -671,30 +671,6 @@ def model_validate_strings(\n         __tracebackhide__ = True\n         return cls.__pydantic_validator__.validate_strings(obj, strict=strict, context=context)\n \n-    @classmethod\n-    def __get_pydantic_core_schema__(cls, source: type[BaseModel], handler: GetCoreSchemaHandler, /) -> CoreSchema:",
      "comment": "To be clear, this doesn't remove support for `__get_pydantic_core_schema__`. This is still handled by the added `_generate_schema_from_get_schema_method` method.\r\n\r\nUsers are still free to implement `__get_pydantic_core_schema__` on Pydantic models, however we provide no guarantees (and never did, see the _breaking changes concerns_ section in my original post) it will work flawlessly. ",
      "comment_id": 1848282518,
      "user": "Viicos",
      "created_at": "2024-11-19T12:36:05Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848282518"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/main.py",
      "line": 688,
      "side": "LEFT",
      "diff_hunk": "@@ -671,30 +671,6 @@ def model_validate_strings(\n         __tracebackhide__ = True\n         return cls.__pydantic_validator__.validate_strings(obj, strict=strict, context=context)\n \n-    @classmethod\n-    def __get_pydantic_core_schema__(cls, source: type[BaseModel], handler: GetCoreSchemaHandler, /) -> CoreSchema:",
      "comment": "Ah interesting. Will give this another review then. Didn't realize users could still implement support. Nice!",
      "comment_id": 1848312831,
      "user": "sydney-runkle",
      "created_at": "2024-11-19T12:56:44Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848312831"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 839,
      "side": "RIGHT",
      "diff_hunk": "@@ -861,6 +836,9 @@ def _get_first_two_args_or_any(self, obj: Any) -> tuple[Any, Any]:\n         return args[0], args[1]\n \n     def _generate_schema_inner(self, obj: Any) -> core_schema.CoreSchema:\n+        if _typing_extra.is_self(obj):\n+            obj = self._resolve_self_type(obj)\n+",
      "comment": "Just curious, why do we need to add this here now?",
      "comment_id": 1848385488,
      "user": "sydney-runkle",
      "created_at": "2024-11-19T13:39:27Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848385488"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 1724,
      "side": "RIGHT",
      "diff_hunk": "@@ -1734,6 +1712,16 @@ def _dataclass_schema(\n             if maybe_schema is not None:\n                 return maybe_schema\n \n+            schema = dataclass.__dict__.get('__pydantic_core_schema__')\n+            if schema is not None and not isinstance(schema, MockCoreSchema):\n+                schema = self._unpack_refs_defs(schema)\n+                ref = get_ref(schema)\n+                if ref:\n+                    self.defs.definitions[ref] = schema\n+                    return core_schema.definition_reference_schema(ref)\n+                else:\n+                    return schema",
      "comment": "Let's consolidate this shared pattern to avoid potential inconsistencies across models, dataclasses, etc",
      "comment_id": 1848387102,
      "user": "sydney-runkle",
      "created_at": "2024-11-19T13:40:25Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848387102"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 2037,
      "side": "RIGHT",
      "diff_hunk": "@@ -2032,11 +2020,12 @@ def _apply_annotations(\n         pydantic_js_annotation_functions: list[GetJsonSchemaFunction] = []\n \n         def inner_handler(obj: Any) -> CoreSchema:\n-            from_property = self._generate_schema_from_property(obj, source_type)\n-            if from_property is None:\n+            # TODO can obj be != source? if not, then just call self.generate_schema\n+            schema = self._generate_schema_from_get_schema_method(obj, source_type)\n+\n+            if schema is None:\n                 schema = self._generate_schema_inner(obj)",
      "comment": "Have you tried with the `self.generate_schema` approach? Seems like it would make more sense here...",
      "comment_id": 1848389752,
      "user": "sydney-runkle",
      "created_at": "2024-11-19T13:41:59Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848389752"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 627,
      "side": "RIGHT",
      "diff_hunk": "@@ -627,6 +618,23 @@ def _model_schema(self, cls: type[BaseModel]) -> core_schema.CoreSchema:\n             if maybe_schema is not None:\n                 return maybe_schema\n \n+            schema = cls.__dict__.get('__pydantic_core_schema__')\n+            if (\n+                schema is not None\n+                and not isinstance(schema, MockCoreSchema)\n+                # Due to the way generic classes are built, it's possible that an invalid schema may be temporarily\n+                # set on generic classes. Probably we could resolve this to ensure that we get proper schema caching\n+                # for generics, but for simplicity for now, we just always rebuild if the class has a generic origin:\n+                and not cls.__pydantic_generic_metadata__['origin']\n+            ):",
      "comment": "@MarkusSintonen did a good job at intuitively extracting some of this logic as follows:\r\n\r\n```py\r\ndef get_existing_core_schema(obj: Any) -> core_schema.CoreSchema | None:\r\n    # Only use the cached value from this _exact_ class; we don't want one from a parent class\r\n    # This is why we check `cls.__dict__` and don't use `cls.__pydantic_core_schema__` or similar.\r\n    if (\r\n        hasattr(obj, '__dict__')\r\n        and (existing_schema := obj.__dict__.get('__pydantic_core_schema__')) is not None\r\n        and not isinstance(existing_schema, MockCoreSchema)\r\n    ):\r\n        return existing_schema\r\n    return None\r\n```\r\n\r\nMaybe we could eagerly pull changes like that into this PR, given that https://github.com/pydantic/pydantic/pull/10655 isn't quite ready to merge yet?",
      "comment_id": 1848393876,
      "user": "sydney-runkle",
      "created_at": "2024-11-19T13:44:44Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848393876"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 873,
      "side": "LEFT",
      "diff_hunk": "@@ -783,25 +776,7 @@ def _generate_schema_from_property(self, obj: Any, source: Any) -> core_schema.C\n                     '`__get_validators__` is deprecated and will be removed, use `__get_pydantic_core_schema__` instead.',\n                     PydanticDeprecatedSince20,\n                 )\n-            schema = core_schema.chain_schema([core_schema.with_info_plain_validator_function(v) for v in validators()])\n-        else:\n-            # we have no existing schema information on the property, exit early so that we can go generate a schema\n-            return None\n-\n-        schema = self._unpack_refs_defs(schema)\n-\n-        if is_function_with_inner_schema(schema):\n-            ref = schema['schema'].pop('ref', None)  # pyright: ignore[reportCallIssue, reportArgumentType]\n-            if ref:\n-                schema['ref'] = ref\n-        else:\n-            ref = get_ref(schema)",
      "comment": "Seems like we lost this logic - is this needed anywhere?",
      "comment_id": 1848394960,
      "user": "sydney-runkle",
      "created_at": "2024-11-19T13:45:29Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848394960"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 839,
      "side": "RIGHT",
      "diff_hunk": "@@ -861,6 +836,9 @@ def _get_first_two_args_or_any(self, obj: Any) -> tuple[Any, Any]:\n         return args[0], args[1]\n \n     def _generate_schema_inner(self, obj: Any) -> core_schema.CoreSchema:\n+        if _typing_extra.is_self(obj):\n+            obj = self._resolve_self_type(obj)\n+",
      "comment": "This was present inside `_generate_schema_from_property` before, but actually I think it should come first. Whenever you call `generate_schema`, if we pass in `typing(_extensions).Self`, we need to resolve the type before trying to build the schema.\r\n\r\nI moved it at the top of `GenerateSchema.generate_schema`",
      "comment_id": 1848502818,
      "user": "Viicos",
      "created_at": "2024-11-19T14:47:35Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848502818"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 627,
      "side": "RIGHT",
      "diff_hunk": "@@ -627,6 +618,23 @@ def _model_schema(self, cls: type[BaseModel]) -> core_schema.CoreSchema:\n             if maybe_schema is not None:\n                 return maybe_schema\n \n+            schema = cls.__dict__.get('__pydantic_core_schema__')\n+            if (\n+                schema is not None\n+                and not isinstance(schema, MockCoreSchema)\n+                # Due to the way generic classes are built, it's possible that an invalid schema may be temporarily\n+                # set on generic classes. Probably we could resolve this to ensure that we get proper schema caching\n+                # for generics, but for simplicity for now, we just always rebuild if the class has a generic origin:\n+                and not cls.__pydantic_generic_metadata__['origin']\n+            ):",
      "comment": "I also need to check that `cls.__pydantic_generic_metadata__['origin']` is `None` for Pydantic models, so maybe it's best to keep the (small) duplication of code here.",
      "comment_id": 1848522677,
      "user": "Viicos",
      "created_at": "2024-11-19T14:58:26Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848522677"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 1724,
      "side": "RIGHT",
      "diff_hunk": "@@ -1734,6 +1712,16 @@ def _dataclass_schema(\n             if maybe_schema is not None:\n                 return maybe_schema\n \n+            schema = dataclass.__dict__.get('__pydantic_core_schema__')\n+            if schema is not None and not isinstance(schema, MockCoreSchema):\n+                schema = self._unpack_refs_defs(schema)\n+                ref = get_ref(schema)\n+                if ref:\n+                    self.defs.definitions[ref] = schema\n+                    return core_schema.definition_reference_schema(ref)\n+                else:\n+                    return schema",
      "comment": "This certainly should be in a shared pattern, but seems like https://github.com/pydantic/pydantic/pull/10655 does something similar already. Maybe it's best to have it implemented there when rebasing?",
      "comment_id": 1848525378,
      "user": "Viicos",
      "created_at": "2024-11-19T14:59:58Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848525378"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 1724,
      "side": "RIGHT",
      "diff_hunk": "@@ -1734,6 +1712,16 @@ def _dataclass_schema(\n             if maybe_schema is not None:\n                 return maybe_schema\n \n+            schema = dataclass.__dict__.get('__pydantic_core_schema__')\n+            if schema is not None and not isinstance(schema, MockCoreSchema):\n+                schema = self._unpack_refs_defs(schema)\n+                ref = get_ref(schema)\n+                if ref:\n+                    self.defs.definitions[ref] = schema\n+                    return core_schema.definition_reference_schema(ref)\n+                else:\n+                    return schema",
      "comment": "Hmm I'd rather have it shared now, then that refactor should look more simple in the long run? That PR is already big enough \ud83d\ude05 ",
      "comment_id": 1848547791,
      "user": "sydney-runkle",
      "created_at": "2024-11-19T15:12:54Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848547791"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 2037,
      "side": "RIGHT",
      "diff_hunk": "@@ -2032,11 +2020,12 @@ def _apply_annotations(\n         pydantic_js_annotation_functions: list[GetJsonSchemaFunction] = []\n \n         def inner_handler(obj: Any) -> CoreSchema:\n-            from_property = self._generate_schema_from_property(obj, source_type)\n-            if from_property is None:\n+            # TODO can obj be != source? if not, then just call self.generate_schema\n+            schema = self._generate_schema_from_get_schema_method(obj, source_type)\n+\n+            if schema is None:\n                 schema = self._generate_schema_inner(obj)",
      "comment": "Turns out there's some cases where `obj != source_type` :/",
      "comment_id": 1848712466,
      "user": "Viicos",
      "created_at": "2024-11-19T16:47:26Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848712466"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_core_utils.py",
      "line": 70,
      "side": "RIGHT",
      "diff_hunk": "@@ -66,6 +67,7 @@ def is_list_like_schema_with_items_schema(\n     return schema['type'] in _LIST_LIKE_SCHEMA_WITH_ITEMS_TYPES\n \n \n+@lru_cache",
      "comment": "It could be maybe simple as:\r\n\r\n```python\r\nclass _TypeRefCache(WeakKeyDictionary):\r\n    def __setitem__(self, key: type[Any], value: Any) -> None:\r\n        size = len(self)\r\n        if size >= 1000:\r\n            for remove_key in [*self.keys()][: size // 10]:  # Remove 10% of the cache (FIFO)\r\n                del self[remove_key]\r\n        super().__setitem__(key, value)\r\n\r\n\r\n_TYPE_REF_CACHE = _TypeRefCache()\r\n\r\n\r\ndef get_type_ref(type_: type[Any], args_override: tuple[type[Any], ...] | None = None) -> str:\r\n    \"\"\"....\"\"\"\r\n    if isinstance(type_, type) and not args_override:\r\n        if (cached := _TYPE_REF_CACHE.get(type_)) is not None:\r\n            return cached\r\n        type_ref = _get_type_ref(type_, args_override)\r\n        _TYPE_REF_CACHE[type_] = type_ref\r\n        return type_ref\r\n    else:\r\n        return _get_type_ref(type_, args_override)\r\n\r\n\r\ndef _get_type_ref(type_: type[Any], args_override: tuple[type[Any], ...] | None = None) -> str:\r\n    ... rest of stuff\r\n```",
      "comment_id": 1848837011,
      "user": "MarkusSintonen",
      "created_at": "2024-11-19T18:15:02Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848837011"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_core_utils.py",
      "line": 70,
      "side": "RIGHT",
      "diff_hunk": "@@ -66,6 +67,7 @@ def is_list_like_schema_with_items_schema(\n     return schema['type'] in _LIST_LIKE_SCHEMA_WITH_ITEMS_TYPES\n \n \n+@lru_cache",
      "comment": "A better API would be for each type to compute the ref, as currently `get_type_ref` is doing useless work as it needs to account for type alias types, dataclasses, etc. Instead, we should be able to decouple everything from this function. Postponing for now.",
      "comment_id": 1848965033,
      "user": "Viicos",
      "created_at": "2024-11-19T19:42:13Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1848965033"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 839,
      "side": "RIGHT",
      "diff_hunk": "@@ -861,6 +836,9 @@ def _get_first_two_args_or_any(self, obj: Any) -> tuple[Any, Any]:\n         return args[0], args[1]\n \n     def _generate_schema_inner(self, obj: Any) -> core_schema.CoreSchema:\n+        if _typing_extra.is_self(obj):\n+            obj = self._resolve_self_type(obj)\n+",
      "comment": "Oops, seems like moving it breaks things, it needs to be right after the `__get_pydantic_core_schema__` check, so I'll leave it here",
      "comment_id": 1850672364,
      "user": "Viicos",
      "created_at": "2024-11-20T16:51:04Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1850672364"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/main.py",
      "line": 697,
      "side": "RIGHT",
      "diff_hunk": "@@ -687,23 +687,17 @@ def model_validate_strings(\n \n     @classmethod\n     def __get_pydantic_core_schema__(cls, source: type[BaseModel], handler: GetCoreSchemaHandler, /) -> CoreSchema:\n-        \"\"\"Hook into generating the model's CoreSchema.\n-\n-        Args:\n-            source: The class we are generating a schema for.\n-                This will generally be the same as the `cls` argument if this is a classmethod.\n-            handler: A callable that calls into Pydantic's internal CoreSchema generation logic.\n-\n-        Returns:\n-            A `pydantic-core` `CoreSchema`.\n-        \"\"\"\n-        # Only use the cached value from this _exact_ class; we don't want one from a parent class\n-        # This is why we check `cls.__dict__` and don't use `cls.__pydantic_core_schema__` or similar.\n+        warnings.warn(\n+            'The `__get_pydantic_core_schema__` method of the `BaseModel` class is deprecated. If you are calling '\n+            '`super().__get_pydantic_core_schema__` when overriding the method on a Pydantic model, consider using '\n+            '`handler(source)` instead. However, note that overriding this method on models can lead to unexpected '\n+            'side effects.',\n+            PydanticDeprecatedSince211,\n+            stacklevel=2,\n+        )",
      "comment": "As discussed in person, let's add a comment that this warning is only omitted when calling super. I think we need to make it more clear what the consequences of this deprecation are.",
      "comment_id": 1914654183,
      "user": "sydney-runkle",
      "created_at": "2025-01-14T11:20:16Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1914654183"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 873,
      "side": "LEFT",
      "diff_hunk": "@@ -783,25 +776,7 @@ def _generate_schema_from_property(self, obj: Any, source: Any) -> core_schema.C\n                     '`__get_validators__` is deprecated and will be removed, use `__get_pydantic_core_schema__` instead.',\n                     PydanticDeprecatedSince20,\n                 )\n-            schema = core_schema.chain_schema([core_schema.with_info_plain_validator_function(v) for v in validators()])\n-        else:\n-            # we have no existing schema information on the property, exit early so that we can go generate a schema\n-            return None\n-\n-        schema = self._unpack_refs_defs(schema)\n-\n-        if is_function_with_inner_schema(schema):\n-            ref = schema['schema'].pop('ref', None)  # pyright: ignore[reportCallIssue, reportArgumentType]\n-            if ref:\n-                schema['ref'] = ref\n-        else:\n-            ref = get_ref(schema)",
      "comment": "Would it make sense to break this change out into a different PR?",
      "comment_id": 1914860077,
      "user": "sydney-runkle",
      "created_at": "2025-01-14T13:58:28Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1914860077"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 1830,
      "side": "RIGHT",
      "diff_hunk": "@@ -1817,6 +1819,16 @@ def _dataclass_schema(\n             if maybe_schema is not None:\n                 return maybe_schema\n \n+            schema = dataclass.__dict__.get('__pydantic_core_schema__')\n+            if schema is not None and not isinstance(schema, MockCoreSchema):\n+                if schema['type'] == 'definitions':\n+                    schema = self.defs.unpack_definitions(schema)\n+                ref = get_ref(schema)\n+                if ref:\n+                    return self.defs.create_definition_reference_schema(schema)\n+                else:\n+                    return schema",
      "comment": "Does it make sense to do this in a different PR as well?",
      "comment_id": 1914864884,
      "user": "sydney-runkle",
      "created_at": "2025-01-14T14:01:40Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1914864884"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 873,
      "side": "LEFT",
      "diff_hunk": "@@ -783,25 +776,7 @@ def _generate_schema_from_property(self, obj: Any, source: Any) -> core_schema.C\n                     '`__get_validators__` is deprecated and will be removed, use `__get_pydantic_core_schema__` instead.',\n                     PydanticDeprecatedSince20,\n                 )\n-            schema = core_schema.chain_schema([core_schema.with_info_plain_validator_function(v) for v in validators()])\n-        else:\n-            # we have no existing schema information on the property, exit early so that we can go generate a schema\n-            return None\n-\n-        schema = self._unpack_refs_defs(schema)\n-\n-        if is_function_with_inner_schema(schema):\n-            ref = schema['schema'].pop('ref', None)  # pyright: ignore[reportCallIssue, reportArgumentType]\n-            if ref:\n-                schema['ref'] = ref\n-        else:\n-            ref = get_ref(schema)",
      "comment": "iirc (but I'm not sure), I was able to remove it only thanks to the other changes. This won't clutter the git diff though, because it's just a removal. Probably by having a proper commit description when merging, I can add a note about this?",
      "comment_id": 1916202889,
      "user": "Viicos",
      "created_at": "2025-01-15T09:13:01Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1916202889"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 10863,
      "file_path": "pydantic/_internal/_generate_schema.py",
      "line": 1830,
      "side": "RIGHT",
      "diff_hunk": "@@ -1817,6 +1819,16 @@ def _dataclass_schema(\n             if maybe_schema is not None:\n                 return maybe_schema\n \n+            schema = dataclass.__dict__.get('__pydantic_core_schema__')\n+            if schema is not None and not isinstance(schema, MockCoreSchema):\n+                if schema['type'] == 'definitions':\n+                    schema = self.defs.unpack_definitions(schema)\n+                ref = get_ref(schema)\n+                if ref:\n+                    return self.defs.create_definition_reference_schema(schema)\n+                else:\n+                    return schema",
      "comment": "It has to be done together with the rest of the changes iirc, because in `pydantic/_internal/_dataclasses.py` we also have the `from_dunder_get_core_schema` logic which was removed",
      "comment_id": 1916214847,
      "user": "Viicos",
      "created_at": "2025-01-15T09:20:15Z",
      "url": "https://github.com/pydantic/pydantic/pull/10863#discussion_r1916214847"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11941,
      "file_path": "pydantic/types.py",
      "line": 3108,
      "side": "RIGHT",
      "diff_hunk": "@@ -3093,10 +3095,23 @@ def _convert_schema(self, original_schema: core_schema.CoreSchema) -> core_schem\n             if metadata is not None:\n                 tag = metadata.get('pydantic_internal_union_tag_key') or tag\n             if tag is None:\n-                raise PydanticUserError(\n-                    f'`Tag` not provided for choice {choice} used with `Discriminator`',\n-                    code='callable-discriminator-no-tag',\n-                )\n+                # `handler` is None when this method is called from `apply_discriminator()` (deferred discriminators)\n+                if handler is not None and choice['type'] == 'definition-ref':\n+                    # If choice was built from a PEP 695 type alias, try to resolve the def:\n+                    try:\n+                        choice = handler.resolve_ref_schema(choice)\n+                    except LookupError:\n+                        pass\n+                    else:\n+                        metadata = cast('CoreMetadata | None', choice.get('metadata'))\n+                        if metadata is not None:\n+                            tag = metadata.get('pydantic_internal_union_tag_key') or tag",
      "comment": "`tag` is known to be `None` here so we don't need the `or tag`",
      "comment_id": 2143351247,
      "user": "DouweM",
      "created_at": "2025-06-12T18:05:37Z",
      "url": "https://github.com/pydantic/pydantic/pull/11941#discussion_r2143351247"
    },
    {
      "repo": "pydantic/pydantic",
      "pr_number": 11902,
      "file_path": "pydantic/fields.py",
      "line": 598,
      "side": "RIGHT",
      "diff_hunk": "@@ -588,6 +588,15 @@ def _collect_metadata(kwargs: dict[str, Any]) -> list[Any]:\n             metadata.append(_fields.pydantic_general_metadata(**general_metadata))\n         return metadata\n \n+    def _copy(self) -> Self:\n+        copied = copy(self)\n+        for attr_name in ('metadata', '_attributes_set', '_qualifiers'):\n+            # Apply \"deep-copy\" behavior on collections attributes:\n+            value = getattr(copied, attr_name).copy()\n+            setattr(copied, attr_name, value)\n+\n+        return copied",
      "comment": "We can't define a custom `__copy__()`, because I couldn't find a way to delegate to `copy.copy()` and then apply the special case for `metadata`, `_attributes_set` and `_qualifiers`.\r\n\r\nThe following could still be done:\r\n\r\n```python\r\n    def __copy__(self) -> Self:\r\n        cls = type(self)\r\n        copied = cls()\r\n        for attr_name in cls.__slots__:\r\n            value = getattr(self, attr_name)\r\n            if attr_name in ('metadata', '_attributes_set', '_qualifiers'):\r\n                # Apply \"deep-copy\" behavior on collections attributes:\r\n                value = value.copy()\r\n            setattr(copied, attr_name, value)\r\n\r\n        return copied\r\n```\r\n\r\nBut this blows up on libraries (FastAPI/SQLModel) subclassing `FieldInfo` (not the first time this is causing issues..) as we don't know which extra attributes are defined on these classes.",
      "comment_id": 2103354317,
      "user": "Viicos",
      "created_at": "2025-05-22T20:31:22Z",
      "url": "https://github.com/pydantic/pydantic/pull/11902#discussion_r2103354317"
    }
  ]
}