{
  "repo": "encode/httpx",
  "scraped_at": "2026-02-03T10:43:59.358250",
  "stats": {
    "total_comments": 453,
    "filtered": {
      "not_python": 124,
      "too_short": 96,
      "no_diff_hunk": 2,
      "too_long": 4
    },
    "kept": 227
  },
  "examples": [
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "httpx/utils.py",
      "line": 111,
      "side": "RIGHT",
      "diff_hunk": "@@ -107,6 +107,14 @@ def get_netrc_login(host: str) -> typing.Optional[typing.Tuple[str, str, str]]:\n     return netrc_info.authenticators(host)  # type: ignore\n \n \n+def get_ssl_cert_file() -> typing.Optional[str]:\n+    for env_name in (\"REQUESTS_CA_BUNDLE\", \"SSL_CERT_FILE\", \"CURL_CA_BUNDLE\"):",
      "comment": "> We should check the three environment variables in the order above\r\n> `(SSL_CERT_FILE, REQUESTS_CA_BUNDLE, CURL_CA_BUNDLE)`,\r\n> as SSL_CERT_FILE is a PEP and a standard whereas the other are products of other projects.\r\n- @sethmlarson \thttps://github.com/encode/httpx/issues/306#issue-488260040\r\n\r\nThis also affects [the](https://github.com/encode/httpx/pull/307/files#diff-c73723c2d8a7c6dfecc80f229ebcef55R83) [docs](https://github.com/encode/httpx/pull/307/files#diff-c73723c2d8a7c6dfecc80f229ebcef55R88)",
      "comment_id": 320042951,
      "user": "StephenBrown2",
      "created_at": "2019-09-02T20:32:01Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r320042951"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_utils.py",
      "line": 121,
      "side": "RIGHT",
      "diff_hunk": "@@ -111,3 +116,19 @@ def test_parse_header_links(value, expected):\n \n     # Reset the logger so we don't have verbose output in all unit tests\n     logging.getLogger(\"httpx\").handlers = []\n+\n+\n+def test_get_ssl_cert_file():",
      "comment": "This should also test if all three are set and if none are valid files, and verify the order tested.",
      "comment_id": 320043132,
      "user": "StephenBrown2",
      "created_at": "2019-09-02T20:33:59Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r320043132"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "httpx/config.py",
      "line": 67,
      "side": "RIGHT",
      "diff_hunk": "@@ -61,6 +62,10 @@ def __init__(\n             verify = True\n             self._load_client_certs(ssl_context)\n \n+        if trust_env:\n+            if verify is True or verify is None:\n+                verify = get_ssl_cert_file()  # type: ignore",
      "comment": "This doesn't look quite right to me, but perhaps I've got myself in a muddle.\r\n\r\nIf verify is True, but `SSL_CERT_FILE` is not set, then `get_ssl_cert_file` will return `None`, which looks like a behavioral change from what we've got right now.",
      "comment_id": 320250534,
      "user": "lovelydinosaur",
      "created_at": "2019-09-03T12:43:53Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r320250534"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "httpx/config.py",
      "line": 67,
      "side": "RIGHT",
      "diff_hunk": "@@ -61,6 +62,10 @@ def __init__(\n             verify = True\n             self._load_client_certs(ssl_context)\n \n+        if trust_env:\n+            if verify is True or verify is None:\n+                verify = get_ssl_cert_file()  # type: ignore",
      "comment": "I also think we should *probably* inspect the environment at the point of calling `load_ssl_context`, rather than on `__init__`.",
      "comment_id": 320250946,
      "user": "lovelydinosaur",
      "created_at": "2019-09-03T12:44:49Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r320250946"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "httpx/utils.py",
      "line": 113,
      "side": "RIGHT",
      "diff_hunk": "@@ -107,6 +107,14 @@ def get_netrc_login(host: str) -> typing.Optional[typing.Tuple[str, str, str]]:\n     return netrc_info.authenticators(host)  # type: ignore\n \n \n+def get_ssl_cert_file() -> typing.Optional[str]:\n+    for env_name in (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"):\n+        ssl_file = Path(os.getenv(env_name, \"\"))\n+        if ssl_file and ssl_file.is_file():",
      "comment": "This won't work for `SSL_CERT_DIR`, for hopefully obvious reasons.",
      "comment_id": 320416523,
      "user": "StephenBrown2",
      "created_at": "2019-09-03T18:30:00Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r320416523"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "httpx/utils.py",
      "line": 110,
      "side": "RIGHT",
      "diff_hunk": "@@ -107,6 +107,16 @@ def get_netrc_login(host: str) -> typing.Optional[typing.Tuple[str, str, str]]:\n     return netrc_info.authenticators(host)  # type: ignore\n \n \n+def get_ssl_cert_file() -> typing.Optional[str]:",
      "comment": "Let's change the title of this since \"cert\" is what we use for client cert. Really this should be `get_ca_bundle_from_env()` or something like it?",
      "comment_id": 321404735,
      "user": "sethmlarson",
      "created_at": "2019-09-05T18:02:10Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r321404735"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 32,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +27,19 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(config):\n+    default_path = httpx.config.DEFAULT_CA_BUNDLE_PATH",
      "comment": "We should use a non-default and verify that it's loaded. I think there's a way to see how many certificates are loaded in an SSLContext?",
      "comment_id": 321405215,
      "user": "sethmlarson",
      "created_at": "2019-09-05T18:03:16Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r321405215"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 32,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +27,19 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(config):\n+    default_path = httpx.config.DEFAULT_CA_BUNDLE_PATH",
      "comment": "I couldn't understand this part. Could you give an example roughly?",
      "comment_id": 321487564,
      "user": "cansarigol",
      "created_at": "2019-09-05T21:18:25Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r321487564"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 32,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +27,19 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(config):\n+    default_path = httpx.config.DEFAULT_CA_BUNDLE_PATH",
      "comment": "Basically if we don't set any `SSL_CERT_...` environment variable we choose `httpx.config.DEFAULT_CA_BUNDLE_PATH` so we can't test the behavior of `SSL_CERT_...` using that path as our expected value because there's no way to tell if the environment variable worked or we just picked the default anyways.\r\n\r\nI suggest you use one of the auto-generated cert fixtures to test this functionality. :)",
      "comment_id": 321546711,
      "user": "sethmlarson",
      "created_at": "2019-09-06T01:34:35Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r321546711"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 32,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +27,19 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(config):\n+    default_path = httpx.config.DEFAULT_CA_BUNDLE_PATH",
      "comment": "thanks. in addition, added ssl_config.verify validation to the end of the test to make sure.",
      "comment_id": 321593551,
      "user": "cansarigol",
      "created_at": "2019-09-06T06:36:45Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r321593551"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "httpx/config.py",
      "line": 94,
      "side": "RIGHT",
      "diff_hunk": "@@ -90,6 +91,12 @@ def load_ssl_context(\n     ) -> ssl.SSLContext:\n         http_versions = HTTPVersionConfig() if http_versions is None else http_versions\n \n+        if self.trust_env:",
      "comment": "Can we move this section into the `load_ssl_context_verify()`? Since we're only doing the loading if we've got verify active anyways.\r\n\r\nAlso is there any harm in having `SSLConfig.verify` default to `True` in the constructor? It defaults to `True` on the client anyways.",
      "comment_id": 321714538,
      "user": "sethmlarson",
      "created_at": "2019-09-06T12:39:56Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r321714538"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "Verify that certs are loaded via `assert len(context.get_ca_certs) > 0`",
      "comment_id": 321715100,
      "user": "sethmlarson",
      "created_at": "2019-09-06T12:41:32Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r321715100"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "`get_ca_certs` returns empty if use `context.load_verify_locations(capath=str(ca_bundle_path))`. \r\nTo get a result, we should create an `SSLSocket` and call [getpeercert](https://docs.python.org/3/library/ssl.html#ssl.SSLSocket.getpeercert) like below\r\n\r\n```\r\nif config == \"SSL_CERT_DIR\":\r\n        HOST = \"example.org\"\r\n        PORT = 443\r\n        conn: ssl.SSLSocket = ssl_config.ssl_context.wrap_socket(\r\n            socket.socket(socket.AF_INET, socket.SOCK_STREAM), server_hostname=HOST\r\n        )\r\n        conn.connect((HOST, PORT))\r\n        conn.getpeercert()\r\n```\r\n",
      "comment_id": 321744962,
      "user": "cansarigol",
      "created_at": "2019-09-06T13:52:03Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r321744962"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "httpx/config.py",
      "line": 94,
      "side": "RIGHT",
      "diff_hunk": "@@ -90,6 +91,12 @@ def load_ssl_context(\n     ) -> ssl.SSLContext:\n         http_versions = HTTPVersionConfig() if http_versions is None else http_versions\n \n+        if self.trust_env:",
      "comment": "Did you mean `load_ssl_context_verify`? when `verify` active, `load_ssl_context_verify` is called.",
      "comment_id": 321748486,
      "user": "cansarigol",
      "created_at": "2019-09-06T13:59:49Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r321748486"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "Maybe we can use https_server.url.host and https_server.url.port to accomplish that. Then our certificate will verify as well :)",
      "comment_id": 321753686,
      "user": "sethmlarson",
      "created_at": "2019-09-06T14:11:41Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r321753686"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "I couldn't verify with `cert_pem_file` for `https_server.url`. Please help :)",
      "comment_id": 321870931,
      "user": "cansarigol",
      "created_at": "2019-09-06T19:04:19Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r321870931"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_utils.py",
      "line": 121,
      "side": "RIGHT",
      "diff_hunk": "@@ -111,3 +116,19 @@ def test_parse_header_links(value, expected):\n \n     # Reset the logger so we don't have verbose output in all unit tests\n     logging.getLogger(\"httpx\").handlers = []\n+\n+\n+def test_get_ssl_cert_file():",
      "comment": "I'd probably tend to be okay either way on this sort of thing.\r\nWe can't ever test every possible permutation, and test code does have it's own maintenance cost, too.",
      "comment_id": 322308585,
      "user": "lovelydinosaur",
      "created_at": "2019-09-09T15:30:03Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r322308585"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "httpx/utils.py",
      "line": 115,
      "side": "RIGHT",
      "diff_hunk": "@@ -107,6 +107,16 @@ def get_netrc_login(host: str) -> typing.Optional[typing.Tuple[str, str, str]]:\n     return netrc_info.authenticators(host)  # type: ignore\n \n \n+def get_ca_bundle_from_env() -> typing.Optional[str]:\n+    ssl_path = Path(os.getenv(\"SSL_CERT_FILE\", \"\"))\n+    if ssl_path and ssl_path.is_file():\n+        return str(ssl_path)\n+    ssl_path = Path(os.getenv(\"SSL_CERT_DIR\", \"\"))\n+    if ssl_path and ssl_path.is_dir():",
      "comment": "I don't think this is doing what we want: `bool(ssl_path)` is always going to be `True` because it refers to a `Path` object.\r\n\r\nAs a result, we'll probably end up using the current directory as the `SSL_CERT_DIR` in all cases. \ud83d\ude15 \r\n\r\nWe should probably instead write something like\u2026\r\n\r\n```python\r\nif \"SSL_CERT_DIR\" in os.environ:\r\n    ssl_path = Path(os.environ[\"SSL_CERT_DIR\"])\r\n    if ssl_path.is_dir():\r\n        return str(ssl_path)\r\n```\r\n\r\nand do the same kind of procesing for `SSL_CERT_FILE` above (although the bug wouldn't happen because the current directory is never a file).\r\n",
      "comment_id": 323458263,
      "user": "florimondmanca",
      "created_at": "2019-09-11T21:03:18Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r323458263"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "httpx/utils.py",
      "line": 115,
      "side": "RIGHT",
      "diff_hunk": "@@ -107,6 +107,16 @@ def get_netrc_login(host: str) -> typing.Optional[typing.Tuple[str, str, str]]:\n     return netrc_info.authenticators(host)  # type: ignore\n \n \n+def get_ca_bundle_from_env() -> typing.Optional[str]:\n+    ssl_path = Path(os.getenv(\"SSL_CERT_FILE\", \"\"))\n+    if ssl_path and ssl_path.is_file():\n+        return str(ssl_path)\n+    ssl_path = Path(os.getenv(\"SSL_CERT_DIR\", \"\"))\n+    if ssl_path and ssl_path.is_dir():",
      "comment": "(Trivia: I think this is typically a case where the Python 3.8 walrus operator would shine \ud83d\ude04)\r\n\r\n```python\r\nif (\r\n    ssl_cert_dir := os.getenv(\"SSL_CERT_DIR\") is not None\r\n    and (ssl_path := Path(ssl_cert_dir)).is_dir()\r\n):\r\n    return str(ssl_path)\r\n```",
      "comment_id": 323459451,
      "user": "florimondmanca",
      "created_at": "2019-09-11T21:06:27Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r323459451"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_utils.py",
      "line": 121,
      "side": "RIGHT",
      "diff_hunk": "@@ -111,3 +116,15 @@ def test_parse_header_links(value, expected):\n \n     # Reset the logger so we don't have verbose output in all unit tests\n     logging.getLogger(\"httpx\").handlers = []\n+\n+\n+def test_get_ssl_cert_file():",
      "comment": "I'd say let\u2019s add tests at the top here for the cases when `SSL_CERT_FILE` and `SSL_CERT_DIR` are not set. Ideally we should be able to catch the potential bugs I mention in my other comment. :)",
      "comment_id": 323460444,
      "user": "florimondmanca",
      "created_at": "2019-09-11T21:09:01Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r323460444"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "httpx/utils.py",
      "line": 115,
      "side": "RIGHT",
      "diff_hunk": "@@ -107,6 +107,16 @@ def get_netrc_login(host: str) -> typing.Optional[typing.Tuple[str, str, str]]:\n     return netrc_info.authenticators(host)  # type: ignore\n \n \n+def get_ca_bundle_from_env() -> typing.Optional[str]:\n+    ssl_path = Path(os.getenv(\"SSL_CERT_FILE\", \"\"))\n+    if ssl_path and ssl_path.is_file():\n+        return str(ssl_path)\n+    ssl_path = Path(os.getenv(\"SSL_CERT_DIR\", \"\"))\n+    if ssl_path and ssl_path.is_dir():",
      "comment": "I got it. `Path` always returns a `PosixPath` and never be `None`. I'm fixing thanks.",
      "comment_id": 323605716,
      "user": "cansarigol",
      "created_at": "2019-09-12T08:02:24Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r323605716"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "httpx/utils.py",
      "line": 115,
      "side": "RIGHT",
      "diff_hunk": "@@ -107,6 +107,16 @@ def get_netrc_login(host: str) -> typing.Optional[typing.Tuple[str, str, str]]:\n     return netrc_info.authenticators(host)  # type: ignore\n \n \n+def get_ca_bundle_from_env() -> typing.Optional[str]:\n+    ssl_path = Path(os.getenv(\"SSL_CERT_FILE\", \"\"))\n+    if ssl_path and ssl_path.is_file():\n+        return str(ssl_path)\n+    ssl_path = Path(os.getenv(\"SSL_CERT_DIR\", \"\"))\n+    if ssl_path and ssl_path.is_dir():",
      "comment": "> (Trivia: I think this is typically a case where the Python 3.8 walrus operator would shine \ud83d\ude04)\r\n> \r\n> ```python\r\n> if (\r\n>     ssl_cert_dir := os.getenv(\"SSL_CERT_DIR\") is not None\r\n>     and (ssl_path := Path(ssl_cert_dir)).is_dir()\r\n> ):\r\n>     return str(ssl_path)\r\n> ```\r\n\r\ndefinitely, this syntax is great \ud83d\ude80 ",
      "comment_id": 323620515,
      "user": "cansarigol",
      "created_at": "2019-09-12T08:37:50Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r323620515"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "Not yet, would be good to resolve this and maybe add a case for the default of certifi getting loaded. :)",
      "comment_id": 324024303,
      "user": "sethmlarson",
      "created_at": "2019-09-13T03:25:18Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r324024303"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "I'm trying to fix this like [cpython test_ssl](https://github.com/python/cpython/blob/7cad53e6b084435a220e6604010f1fa5778bd0b1/Lib/test/test_ssl.py#L1931). However, I haven't been able to verify the certificate yet.",
      "comment_id": 324054753,
      "user": "cansarigol",
      "created_at": "2019-09-13T06:47:35Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r324054753"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "@cansarigol Is there anything we can do to help unblock this?",
      "comment_id": 324460274,
      "user": "florimondmanca",
      "created_at": "2019-09-15T12:25:42Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r324460274"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "Would be great. Thanks.  I'm stuck about create a sslsocket because of ssl validation error. I don't know if it is related trustme scope",
      "comment_id": 324462839,
      "user": "cansarigol",
      "created_at": "2019-09-15T13:24:53Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r324462839"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "@cansarigol Can you share a traceback so we know what part is failing exactly? :) Thanks",
      "comment_id": 324465172,
      "user": "florimondmanca",
      "created_at": "2019-09-15T14:18:24Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r324465172"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "I'm very sorry that I didn't do anything but i will asap",
      "comment_id": 324579390,
      "user": "cansarigol",
      "created_at": "2019-09-16T09:28:17Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r324579390"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "This is blocked by #354, just gave it a spin myself. I think we should maybe merge this now?",
      "comment_id": 325815705,
      "user": "sethmlarson",
      "created_at": "2019-09-18T18:00:45Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r325815705"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "#354 is closed now, I tried changing the test to look like this right now:\r\n\r\n```python\r\n    os.environ[config] = (\r\n        ca_cert_pem_file\r\n        if config.endswith(\"_FILE\")\r\n        else str(Path(ca_cert_pem_file).parent)\r\n    )\r\n    ssl_config = httpx.SSLConfig(trust_env=True)\r\n    context = ssl_config.load_ssl_context()\r\n    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\r\n    assert context.check_hostname is True\r\n    assert ssl_config.verify == os.environ[config]\r\n\r\n    host = https_server.url.host\r\n    port = https_server.url.port\r\n    conn = socket.create_connection((host, port))\r\n    context.wrap_socket(conn, server_hostname=host)\r\n    assert len(context.get_ca_certs()) == 1\r\n```\r\n\r\nBut I'm still failing on the `SSL_CERT_DIR` test case and I don't know why, pretty annoying!",
      "comment_id": 325958024,
      "user": "sethmlarson",
      "created_at": "2019-09-19T01:35:30Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r325958024"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "I added a test to be able to compare with below traceback.\r\n\r\n```\r\ntests/test_config.py ...FSSL error in data received\r\nprotocol: <asyncio.sslproto.SSLProtocol object at 0x103c044a8>\r\ntransport: <_SelectorSocketTransport closing fd=19 read=idle write=<idle, bufsize=0>>\r\nTraceback (most recent call last):\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/sslproto.py\", line 526, in data_received\r\n    ssldata, appdata = self._sslpipe.feed_ssldata(data)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/sslproto.py\", line 189, in feed_ssldata\r\n    self._sslobj.do_handshake()\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\", line 763, in do_handshake\r\n    self._sslobj.do_handshake()\r\nssl.SSLError: [SSL: TLSV1_ALERT_UNKNOWN_CA] tlsv1 alert unknown ca (_ssl.c:1045)\r\n```",
      "comment_id": 326024810,
      "user": "cansarigol",
      "created_at": "2019-09-19T07:26:53Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r326024810"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 307,
      "file_path": "tests/test_config.py",
      "line": 40,
      "side": "RIGHT",
      "diff_hunk": "@@ -26,6 +28,18 @@ def test_load_ssl_config_verify_existing_file():\n     assert context.check_hostname is True\n \n \n+@pytest.mark.parametrize(\"config\", (\"SSL_CERT_FILE\", \"SSL_CERT_DIR\"))\n+def test_load_ssl_config_verify_env_file(cert_pem_file, config):\n+    os.environ[config] = (\n+        cert_pem_file if config.endswith(\"_FILE\") else str(Path(cert_pem_file).parent)\n+    )\n+    ssl_config = httpx.SSLConfig(trust_env=True)\n+    context = ssl_config.load_ssl_context()\n+    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n+    assert context.check_hostname is True\n+    assert ssl_config.verify == os.environ[config]",
      "comment": "Spoke with @florimondmanca and I think we're just going to skip the `SSL_CERT_DIR` case here and if we run into issues with it we'll fix them then. Until then this PR is good to go. Thank you so much @cansarigol for following this one all the way through. :)",
      "comment_id": 327178731,
      "user": "sethmlarson",
      "created_at": "2019-09-23T15:23:46Z",
      "url": "https://github.com/encode/httpx/pull/307#discussion_r327178731"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "tests/models/test_url.py",
      "line": 316,
      "side": "RIGHT",
      "diff_hunk": "@@ -312,49 +312,13 @@ def test_url_copywith_security():\n     \"\"\"\n     Prevent unexpected changes on URL after calling copy_with (CVE-2021-41945)\n     \"\"\"\n-    url = httpx.URL(\"https://u:p@[invalid!]//evilHost/path?t=w#tw\")\n-    original_scheme = url.scheme\n-    original_userinfo = url.userinfo\n-    original_netloc = url.netloc\n-    original_raw_path = url.raw_path\n-    original_query = url.query\n-    original_fragment = url.fragment\n-    url = url.copy_with()\n-    assert url.scheme == original_scheme\n-    assert url.userinfo == original_userinfo\n-    assert url.netloc == original_netloc\n-    assert url.raw_path == original_raw_path\n-    assert url.query == original_query\n-    assert url.fragment == original_fragment\n-\n-    url = httpx.URL(\"https://u:p@[invalid!]//evilHost/path?t=w#tw\")\n-    original_scheme = url.scheme\n-    original_netloc = url.netloc\n-    original_raw_path = url.raw_path\n-    original_query = url.query\n-    original_fragment = url.fragment\n-    url = url.copy_with(userinfo=b\"\")\n-    assert url.scheme == original_scheme\n-    assert url.userinfo == b\"\"\n-    assert url.netloc == original_netloc\n-    assert url.raw_path == original_raw_path\n-    assert url.query == original_query\n-    assert url.fragment == original_fragment\n+    with pytest.raises(httpx.InvalidURL):\n+        httpx.URL(\"https://u:p@[invalid!]//evilHost/path?t=w#tw\")",
      "comment": "Our test here is much simpler, since this URL no longer passes validation. \ud83d\udc4d",
      "comment_id": 885618832,
      "user": "lovelydinosaur",
      "created_at": "2022-05-31T13:11:00Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r885618832"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "tests/models/test_url.py",
      "line": 321,
      "side": "RIGHT",
      "diff_hunk": "@@ -312,49 +312,13 @@ def test_url_copywith_security():\n     \"\"\"\n     Prevent unexpected changes on URL after calling copy_with (CVE-2021-41945)\n     \"\"\"\n-    url = httpx.URL(\"https://u:p@[invalid!]//evilHost/path?t=w#tw\")\n-    original_scheme = url.scheme\n-    original_userinfo = url.userinfo\n-    original_netloc = url.netloc\n-    original_raw_path = url.raw_path\n-    original_query = url.query\n-    original_fragment = url.fragment\n-    url = url.copy_with()\n-    assert url.scheme == original_scheme\n-    assert url.userinfo == original_userinfo\n-    assert url.netloc == original_netloc\n-    assert url.raw_path == original_raw_path\n-    assert url.query == original_query\n-    assert url.fragment == original_fragment\n-\n-    url = httpx.URL(\"https://u:p@[invalid!]//evilHost/path?t=w#tw\")\n-    original_scheme = url.scheme\n-    original_netloc = url.netloc\n-    original_raw_path = url.raw_path\n-    original_query = url.query\n-    original_fragment = url.fragment\n-    url = url.copy_with(userinfo=b\"\")\n-    assert url.scheme == original_scheme\n-    assert url.userinfo == b\"\"\n-    assert url.netloc == original_netloc\n-    assert url.raw_path == original_raw_path\n-    assert url.query == original_query\n-    assert url.fragment == original_fragment\n+    with pytest.raises(httpx.InvalidURL):\n+        httpx.URL(\"https://u:p@[invalid!]//evilHost/path?t=w#tw\")\n \n     url = httpx.URL(\"https://example.com/path?t=w#tw\")\n-    original_userinfo = url.userinfo\n-    original_netloc = url.netloc\n-    original_raw_path = url.raw_path\n-    original_query = url.query\n-    original_fragment = url.fragment\n     bad = \"https://xxxx:xxxx@xxxxxxx/xxxxx/xxx?x=x#xxxxx\"\n-    url = url.copy_with(scheme=bad)\n-    assert url.scheme == bad\n-    assert url.userinfo == original_userinfo\n-    assert url.netloc == original_netloc\n-    assert url.raw_path == original_raw_path\n-    assert url.query == original_query\n-    assert url.fragment == original_fragment\n+    with pytest.raises(httpx.InvalidURL):\n+        url.copy_with(scheme=bad)",
      "comment": "Similarly, this scheme no longer validates, which is an improved behaviour.",
      "comment_id": 885619451,
      "user": "lovelydinosaur",
      "created_at": "2022-05-31T13:11:34Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r885619451"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "tests/test_asgi.py",
      "line": 119,
      "side": "RIGHT",
      "diff_hunk": "@@ -116,7 +116,7 @@ async def test_asgi_raw_path():\n         response = await client.get(url)\n \n     assert response.status_code == 200\n-    assert response.json() == {\"raw_path\": \"/user%40example.org\"}\n+    assert response.json() == {\"raw_path\": \"/user@example.org\"}",
      "comment": "This test changes, because of some improved behaviour. \"@\" should not be an auto-escaping character in the path.\r\n\r\nTry `https://www.example.com/some@path` in a browser, or see RFC sec 3.3...\r\n\r\nFrom https://datatracker.ietf.org/doc/html/rfc3986.html#section-3.3...\r\n\r\n> `pchar = unreserved / pct-encoded / sub-delims / \":\" / \"@\"`",
      "comment_id": 885623387,
      "user": "lovelydinosaur",
      "created_at": "2022-05-31T13:14:58Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r885623387"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "httpx/_urls.py",
      "line": 130,
      "side": "RIGHT",
      "diff_hunk": "@@ -73,76 +71,87 @@ class URL:\n     def __init__(\n         self, url: typing.Union[\"URL\", str] = \"\", **kwargs: typing.Any\n     ) -> None:\n+        if kwargs:\n+            allowed = {\n+                \"scheme\": str,\n+                \"username\": str,\n+                \"password\": str,\n+                \"userinfo\": bytes,\n+                \"host\": str,\n+                \"port\": int,\n+                \"netloc\": bytes,\n+                \"path\": str,\n+                \"query\": bytes,\n+                \"raw_path\": bytes,\n+                \"fragment\": str,\n+                \"params\": object,\n+            }\n+\n+            # Perform type checking for all supported keyword arguments.\n+            for key, value in kwargs.items():\n+                if key not in allowed:\n+                    message = f\"{key!r} is an invalid keyword argument for URL()\"\n+                    raise TypeError(message)\n+                if value is not None and not isinstance(value, allowed[key]):\n+                    expected = allowed[key].__name__\n+                    seen = type(value).__name__\n+                    message = f\"Argument {key!r} must be {expected} but got {seen}\"\n+                    raise TypeError(message)\n+                if isinstance(value, bytes):\n+                    kwargs[key] = value.decode(\"ascii\")\n+\n+            if \"raw_path\" in kwargs:\n+                kwargs[\"full_path\"] = kwargs.pop(\"raw_path\")\n+\n+            if \"params\" in kwargs:\n+                # Replace any \"params\" keyword with the raw \"query\" instead.\n+                #\n+                # Ensure that empty params use `kwargs[\"query\"] = None` rather\n+                # than `kwargs[\"query\"] = \"\"`, so that generated URLs do not\n+                # include an empty trailing \"?\".\n+                params = kwargs.pop(\"params\")\n+                kwargs[\"query\"] = None if not params else str(QueryParams(params))\n+\n         if isinstance(url, str):\n-            try:\n-                self._uri_reference = rfc3986.iri_reference(url).encode()\n-            except rfc3986.exceptions.InvalidAuthority as exc:\n-                raise InvalidURL(message=str(exc)) from None\n-\n-            if self.is_absolute_url:\n-                # We don't want to normalize relative URLs, since doing so\n-                # removes any leading `../` portion.\n-                self._uri_reference = self._uri_reference.normalize()\n+            self._uri_reference = urlparse(url, **kwargs)\n         elif isinstance(url, URL):\n-            self._uri_reference = url._uri_reference\n+            self._uri_reference = url._uri_reference.copy_with(**kwargs)\n         else:\n             raise TypeError(\n                 f\"Invalid type for url.  Expected str or httpx.URL, got {type(url)}: {url!r}\"\n             )\n \n-        # Perform port normalization, following the WHATWG spec for default ports.\n-        #\n-        # See:\n-        # * https://tools.ietf.org/html/rfc3986#section-3.2.3\n-        # * https://url.spec.whatwg.org/#url-miscellaneous\n-        # * https://url.spec.whatwg.org/#scheme-state\n-        default_port = {\n-            \"ftp\": \":21\",\n-            \"http\": \":80\",\n-            \"https\": \":443\",\n-            \"ws\": \":80\",\n-            \"wss\": \":443\",\n-        }.get(self._uri_reference.scheme, \"\")\n-        authority = self._uri_reference.authority or \"\"\n-        if default_port and authority.endswith(default_port):\n-            authority = authority[: -len(default_port)]\n-            self._uri_reference = self._uri_reference.copy_with(authority=authority)\n-\n-        if kwargs:\n-            self._uri_reference = self.copy_with(**kwargs)._uri_reference\n-\n     @property\n     def scheme(self) -> str:\n         \"\"\"\n         The URL scheme, such as \"http\", \"https\".\n         Always normalised to lowercase.\n         \"\"\"\n-        return self._uri_reference.scheme or \"\"\n+        return self._uri_reference.scheme",
      "comment": "Unlike with `rfc3986`, this value can no longer be `None`.\r\nIt's not needed, since an empty string is sufficient.\r\n\r\nSee also other cases below.",
      "comment_id": 886778198,
      "user": "lovelydinosaur",
      "created_at": "2022-06-01T13:01:22Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r886778198"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "httpx/_urls.py",
      "line": 336,
      "side": "RIGHT",
      "diff_hunk": "@@ -340,127 +333,7 @@ def copy_with(self, **kwargs: typing.Any) -> \"URL\":\n         url = httpx.URL(\"https://www.example.com\").copy_with(username=\"jo@gmail.com\", password=\"a secret\")\n         assert url == \"https://jo%40email.com:a%20secret@www.example.com\"\n         \"\"\"\n-        allowed = {\n-            \"scheme\": str,\n-            \"username\": str,\n-            \"password\": str,\n-            \"userinfo\": bytes,\n-            \"host\": str,\n-            \"port\": int,\n-            \"netloc\": bytes,\n-            \"path\": str,\n-            \"query\": bytes,\n-            \"raw_path\": bytes,\n-            \"fragment\": str,\n-            \"params\": object,\n-        }\n-\n-        # Step 1\n-        # ======\n-        #\n-        # Perform type checking for all supported keyword arguments.\n-        for key, value in kwargs.items():\n-            if key not in allowed:\n-                message = f\"{key!r} is an invalid keyword argument for copy_with()\"\n-                raise TypeError(message)\n-            if value is not None and not isinstance(value, allowed[key]):\n-                expected = allowed[key].__name__\n-                seen = type(value).__name__\n-                message = f\"Argument {key!r} must be {expected} but got {seen}\"\n-                raise TypeError(message)\n-\n-        # Step 2\n-        # ======\n-        #\n-        # Consolidate \"username\", \"password\", \"userinfo\", \"host\", \"port\" and \"netloc\"\n-        # into a single \"authority\" keyword, for `rfc3986`.\n-        if \"username\" in kwargs or \"password\" in kwargs:\n-            # Consolidate \"username\" and \"password\" into \"userinfo\".\n-            username = quote(kwargs.pop(\"username\", self.username) or \"\")\n-            password = quote(kwargs.pop(\"password\", self.password) or \"\")\n-            userinfo = f\"{username}:{password}\" if password else username\n-            kwargs[\"userinfo\"] = userinfo.encode(\"ascii\")\n-\n-        if \"host\" in kwargs or \"port\" in kwargs:\n-            # Consolidate \"host\" and \"port\" into \"netloc\".\n-            host = kwargs.pop(\"host\", self.host) or \"\"\n-            port = kwargs.pop(\"port\", self.port)\n-\n-            if host and \":\" in host and host[0] != \"[\":\n-                # IPv6 addresses need to be escaped within square brackets.\n-                host = f\"[{host}]\"\n-\n-            kwargs[\"netloc\"] = (\n-                f\"{host}:{port}\".encode(\"ascii\")\n-                if port is not None\n-                else host.encode(\"ascii\")\n-            )\n-\n-        if \"userinfo\" in kwargs or \"netloc\" in kwargs:\n-            # Consolidate \"userinfo\" and \"netloc\" into authority.\n-            userinfo = (kwargs.pop(\"userinfo\", self.userinfo) or b\"\").decode(\"ascii\")\n-            netloc = (kwargs.pop(\"netloc\", self.netloc) or b\"\").decode(\"ascii\")\n-            authority = f\"{userinfo}@{netloc}\" if userinfo else netloc\n-            kwargs[\"authority\"] = authority\n-\n-        # Step 3\n-        # ======\n-        #\n-        # Wrangle any \"path\", \"query\", \"raw_path\" and \"params\" keywords into\n-        # \"query\" and \"path\" keywords for `rfc3986`.\n-        if \"raw_path\" in kwargs:\n-            # If \"raw_path\" is included, then split it into \"path\" and \"query\" components.\n-            raw_path = kwargs.pop(\"raw_path\") or b\"\"\n-            path, has_query, query = raw_path.decode(\"ascii\").partition(\"?\")\n-            kwargs[\"path\"] = path\n-            kwargs[\"query\"] = query if has_query else None\n-\n-        else:\n-            if kwargs.get(\"path\") is not None:\n-                # Ensure `kwargs[\"path\"] = <url quoted str>` for `rfc3986`.\n-                kwargs[\"path\"] = quote(kwargs[\"path\"])\n-\n-            if kwargs.get(\"query\") is not None:\n-                # Ensure `kwargs[\"query\"] = <str>` for `rfc3986`.\n-                #\n-                # Note that `.copy_with(query=None)` and `.copy_with(query=b\"\")`\n-                # are subtly different. The `None` style will not include an empty\n-                # trailing \"?\" character.\n-                kwargs[\"query\"] = kwargs[\"query\"].decode(\"ascii\")\n-\n-            if \"params\" in kwargs:\n-                # Replace any \"params\" keyword with the raw \"query\" instead.\n-                #\n-                # Ensure that empty params use `kwargs[\"query\"] = None` rather\n-                # than `kwargs[\"query\"] = \"\"`, so that generated URLs do not\n-                # include an empty trailing \"?\".\n-                params = kwargs.pop(\"params\")\n-                kwargs[\"query\"] = None if not params else str(QueryParams(params))\n-\n-        # Step 4\n-        # ======\n-        #\n-        # Ensure any fragment component is quoted.\n-        if kwargs.get(\"fragment\") is not None:\n-            kwargs[\"fragment\"] = quote(kwargs[\"fragment\"])\n-\n-        # Step 5\n-        # ======\n-        #\n-        # At this point kwargs may include keys for \"scheme\", \"authority\", \"path\",\n-        # \"query\" and \"fragment\". Together these constitute the entire URL.\n-        #\n-        # See https://tools.ietf.org/html/rfc3986#section-3\n-        #\n-        #  foo://example.com:8042/over/there?name=ferret#nose\n-        #  \\_/   \\______________/\\_________/ \\_________/ \\__/\n-        #   |           |            |            |        |\n-        # scheme     authority       path        query   fragment\n-        new_url = URL(self)\n-        new_url._uri_reference = self._uri_reference.copy_with(**kwargs)\n-        if new_url.is_absolute_url:\n-            new_url._uri_reference = new_url._uri_reference.normalize()\n-        return URL(new_url)\n+        return URL(self, **kwargs)",
      "comment": "Note that our parameter checking moves into `__init__(...)` instead.",
      "comment_id": 886792776,
      "user": "lovelydinosaur",
      "created_at": "2022-06-01T13:15:17Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r886792776"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "httpx/_urls.py",
      "line": 362,
      "side": "RIGHT",
      "diff_hunk": "@@ -484,21 +357,9 @@ def join(self, url: URLTypes) -> \"URL\":\n         url = url.join(\"/new/path\")\n         assert url == \"https://www.example.com/new/path\"\n         \"\"\"\n-        if self.is_relative_url:\n-            # Workaround to handle relative URLs, which otherwise raise\n-            # rfc3986.exceptions.ResolutionError when used as an argument\n-            # in `.resolve_with`.\n-            return (\n-                self.copy_with(scheme=\"http\", host=\"example.com\")\n-                .join(url)\n-                .copy_with(scheme=None, host=None)\n-            )\n+        from urllib.parse import urljoin\n \n-        # We drop any fragment portion, because RFC 3986 strictly\n-        # treats URLs with a fragment portion as not being absolute URLs.\n-        base_uri = self._uri_reference.copy_with(fragment=None)\n-        relative_url = URL(url)\n-        return URL(relative_url._uri_reference.resolve_with(base_uri).unsplit())\n+        return URL(urljoin(str(self), str(URL(url))))",
      "comment": "We're just leaning on the stdlib's built-in implementation of `urljoin` now, but making sure to use our URL validation and normalisation first.",
      "comment_id": 886793608,
      "user": "lovelydinosaur",
      "created_at": "2022-06-01T13:16:04Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r886793608"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "httpx/_urls.py",
      "line": 101,
      "side": "RIGHT",
      "diff_hunk": "@@ -73,76 +71,87 @@ class URL:\n     def __init__(\n         self, url: typing.Union[\"URL\", str] = \"\", **kwargs: typing.Any\n     ) -> None:\n+        if kwargs:\n+            allowed = {\n+                \"scheme\": str,\n+                \"username\": str,\n+                \"password\": str,\n+                \"userinfo\": bytes,\n+                \"host\": str,\n+                \"port\": int,\n+                \"netloc\": bytes,\n+                \"path\": str,\n+                \"query\": bytes,\n+                \"raw_path\": bytes,\n+                \"fragment\": str,\n+                \"params\": object,\n+            }\n+\n+            # Perform type checking for all supported keyword arguments.\n+            for key, value in kwargs.items():\n+                if key not in allowed:\n+                    message = f\"{key!r} is an invalid keyword argument for URL()\"\n+                    raise TypeError(message)\n+                if value is not None and not isinstance(value, allowed[key]):\n+                    expected = allowed[key].__name__\n+                    seen = type(value).__name__\n+                    message = f\"Argument {key!r} must be {expected} but got {seen}\"\n+                    raise TypeError(message)\n+                if isinstance(value, bytes):\n+                    kwargs[key] = value.decode(\"ascii\")",
      "comment": "Our `urlparse` implementation uses strings everywhere. If `bytes` are provided, then coerce to an ascii string.\r\n\r\nThis is internal detail, but there are some interesting public API considerations that this work has prompted, tho going to leave those as follow-up.",
      "comment_id": 886796756,
      "user": "lovelydinosaur",
      "created_at": "2022-06-01T13:18:49Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r886796756"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "httpx/_urls.py",
      "line": 113,
      "side": "RIGHT",
      "diff_hunk": "@@ -73,76 +71,87 @@ class URL:\n     def __init__(\n         self, url: typing.Union[\"URL\", str] = \"\", **kwargs: typing.Any\n     ) -> None:\n+        if kwargs:\n+            allowed = {\n+                \"scheme\": str,\n+                \"username\": str,\n+                \"password\": str,\n+                \"userinfo\": bytes,\n+                \"host\": str,\n+                \"port\": int,\n+                \"netloc\": bytes,\n+                \"path\": str,\n+                \"query\": bytes,\n+                \"raw_path\": bytes,\n+                \"fragment\": str,\n+                \"params\": object,\n+            }\n+\n+            # Perform type checking for all supported keyword arguments.\n+            for key, value in kwargs.items():\n+                if key not in allowed:\n+                    message = f\"{key!r} is an invalid keyword argument for URL()\"\n+                    raise TypeError(message)\n+                if value is not None and not isinstance(value, allowed[key]):\n+                    expected = allowed[key].__name__\n+                    seen = type(value).__name__\n+                    message = f\"Argument {key!r} must be {expected} but got {seen}\"\n+                    raise TypeError(message)\n+                if isinstance(value, bytes):\n+                    kwargs[key] = value.decode(\"ascii\")\n+\n+            if \"raw_path\" in kwargs:\n+                kwargs[\"full_path\"] = kwargs.pop(\"raw_path\")\n+\n+            if \"params\" in kwargs:\n+                # Replace any \"params\" keyword with the raw \"query\" instead.\n+                #\n+                # Ensure that empty params use `kwargs[\"query\"] = None` rather\n+                # than `kwargs[\"query\"] = \"\"`, so that generated URLs do not\n+                # include an empty trailing \"?\".\n+                params = kwargs.pop(\"params\")\n+                kwargs[\"query\"] = None if not params else str(QueryParams(params))",
      "comment": "The \"params\" argument isn't used but the `urlparse` implementation, because the `QueryParams` model doesn't exist at that level of abstraction.",
      "comment_id": 886797472,
      "user": "lovelydinosaur",
      "created_at": "2022-06-01T13:19:32Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r886797472"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "httpx/_urlparse.py",
      "line": 57,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,435 @@\n+\"\"\"\n+An implementation of `urlparse` that provides URL validation and normalization\n+as described by RFC3986.\n+\n+We rely on this implementation rather than the one in Python's stdlib, because:\n+\n+* It provides more complete URL validation.\n+* It properly differentiates between an empty querystring and an absent querystring,\n+  to distinguish URLs with a trailing '?'.\n+* It handles scheme, hostname, port, and path normalization.\n+* It supports IDNA hostnames, normalizing them to their encoded form.\n+* The API supports passing individual components, as well as the complete URL string.\n+\n+Previously we relied on the excellent `rfc3986` package to handle URL parsing and\n+validation, but this module provides a simpler alternative, with less indirection\n+required.\n+\"\"\"\n+import ipaddress\n+import re\n+import typing\n+\n+import idna\n+\n+from ._exceptions import InvalidURL\n+\n+MAX_URL_LENGTH = 65536\n+\n+# https://datatracker.ietf.org/doc/html/rfc3986.html#section-2.3\n+UNRESERVED_CHARACTERS = (\n+    \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-._~\"\n+)\n+SUB_DELIMS = \"!$&'()*+,;=\"\n+\n+PERCENT_ENCODED_REGEX = re.compile(\"%[A-Fa-f0-9]{2}\")\n+\n+\n+# {scheme}:      (optional)\n+# //{authority}  (optional)\n+# {path}\n+# ?{query}       (optional)\n+# #{fragment}    (optional)\n+URL_REGEX = re.compile(\n+    (\n+        r\"(?:(?P<scheme>{scheme}):)?\"\n+        r\"(?://(?P<authority>{authority}))?\"\n+        r\"(?P<path>{path})\"\n+        r\"(?:\\?(?P<query>{query}))?\"\n+        r\"(?:#(?P<fragment>{fragment}))?\"\n+    ).format(\n+        scheme=\"([a-zA-Z][a-zA-Z0-9+.-]*)?\",\n+        authority=\"[^/?#]*\",\n+        path=\"[^?#]*\",\n+        query=\"[^#]*\",\n+        fragment=\".*\",\n+    )\n+)\n+",
      "comment": "I just want to point out, I love love LOVE using format strings to improve readability and maintainability of regex.",
      "comment_id": 906862566,
      "user": "xkortex",
      "created_at": "2022-06-26T19:39:48Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r906862566"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "httpx/_urls.py",
      "line": 384,
      "side": "RIGHT",
      "diff_hunk": "@@ -507,21 +365,33 @@ def __eq__(self, other: typing.Any) -> bool:\n         return isinstance(other, (URL, str)) and str(self) == str(URL(other))\n \n     def __str__(self) -> str:\n-        return self._uri_reference.unsplit()\n+        return str(self._uri_reference)\n \n     def __repr__(self) -> str:\n-        class_name = self.__class__.__name__\n-        url_str = str(self)\n-        if self._uri_reference.userinfo:\n-            # Mask any password component in the URL representation, to lower the\n-            # risk of unintended leakage, such as in debug information and logging.\n-            username = quote(self.username)\n-            url_str = (\n-                rfc3986.urlparse(url_str)\n-                .copy_with(userinfo=f\"{username}:[secure]\")\n-                .unsplit()\n-            )\n-        return f\"{class_name}({url_str!r})\"\n+        scheme, userinfo, host, port, path, query, fragment = self._uri_reference\n+\n+        if \":\" in userinfo:\n+            # Mask any password component.\n+            userinfo = f'{userinfo.split(\":\")[0]}:[secure]'\n+\n+        authority = \"\".join(\n+            [\n+                f\"{userinfo}@\" if userinfo else \"\",\n+                f\"[{host}]\" if \":\" in host else host,\n+                f\":{port}\" if port is not None else \"\",\n+            ]\n+        )\n+        url = \"\".join(",
      "comment": "Question: could this just be str(self._url_reference)? Just curious what the implications are of the different rendering methods are. I think it'd be more parsimonious to have a single URL->str but I could see this being a backwards-compat thing.",
      "comment_id": 906863406,
      "user": "xkortex",
      "created_at": "2022-06-26T19:48:46Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r906863406"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "httpx/_urls.py",
      "line": 384,
      "side": "RIGHT",
      "diff_hunk": "@@ -507,21 +365,33 @@ def __eq__(self, other: typing.Any) -> bool:\n         return isinstance(other, (URL, str)) and str(self) == str(URL(other))\n \n     def __str__(self) -> str:\n-        return self._uri_reference.unsplit()\n+        return str(self._uri_reference)\n \n     def __repr__(self) -> str:\n-        class_name = self.__class__.__name__\n-        url_str = str(self)\n-        if self._uri_reference.userinfo:\n-            # Mask any password component in the URL representation, to lower the\n-            # risk of unintended leakage, such as in debug information and logging.\n-            username = quote(self.username)\n-            url_str = (\n-                rfc3986.urlparse(url_str)\n-                .copy_with(userinfo=f\"{username}:[secure]\")\n-                .unsplit()\n-            )\n-        return f\"{class_name}({url_str!r})\"\n+        scheme, userinfo, host, port, path, query, fragment = self._uri_reference\n+\n+        if \":\" in userinfo:\n+            # Mask any password component.\n+            userinfo = f'{userinfo.split(\":\")[0]}:[secure]'\n+\n+        authority = \"\".join(\n+            [\n+                f\"{userinfo}@\" if userinfo else \"\",\n+                f\"[{host}]\" if \":\" in host else host,\n+                f\":{port}\" if port is not None else \"\",\n+            ]\n+        )\n+        url = \"\".join(",
      "comment": "Right now we're doing this here because we need to mask the password for `__repr__`, but not for the `__str__`.\r\n\r\nWe could perhaps simplify a little by having a `to_string(mask_password: bool)` method on the `ParseResult` class.\r\n",
      "comment_id": 907152909,
      "user": "lovelydinosaur",
      "created_at": "2022-06-27T09:06:03Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r907152909"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "httpx/_urls.py",
      "line": 384,
      "side": "RIGHT",
      "diff_hunk": "@@ -507,21 +365,33 @@ def __eq__(self, other: typing.Any) -> bool:\n         return isinstance(other, (URL, str)) and str(self) == str(URL(other))\n \n     def __str__(self) -> str:\n-        return self._uri_reference.unsplit()\n+        return str(self._uri_reference)\n \n     def __repr__(self) -> str:\n-        class_name = self.__class__.__name__\n-        url_str = str(self)\n-        if self._uri_reference.userinfo:\n-            # Mask any password component in the URL representation, to lower the\n-            # risk of unintended leakage, such as in debug information and logging.\n-            username = quote(self.username)\n-            url_str = (\n-                rfc3986.urlparse(url_str)\n-                .copy_with(userinfo=f\"{username}:[secure]\")\n-                .unsplit()\n-            )\n-        return f\"{class_name}({url_str!r})\"\n+        scheme, userinfo, host, port, path, query, fragment = self._uri_reference\n+\n+        if \":\" in userinfo:\n+            # Mask any password component.\n+            userinfo = f'{userinfo.split(\":\")[0]}:[secure]'\n+\n+        authority = \"\".join(\n+            [\n+                f\"{userinfo}@\" if userinfo else \"\",\n+                f\"[{host}]\" if \":\" in host else host,\n+                f\":{port}\" if port is not None else \"\",\n+            ]\n+        )\n+        url = \"\".join(",
      "comment": "Ohhhh right, because of this, right? https://datatracker.ietf.org/doc/html/rfc3986#section-3.2.1\r\n\r\n> We could perhaps simplify a little by having a to_string(mask_password: bool) method on the ParseResult class.\r\n\r\nThat also sounds reasonable, if it were my codebase, I'd prefer that. Not a big deal either way (obviously not my call here :) ). \r\n\r\n>  we need to mask the password for __repr__, but not for the __str__\r\n\r\nThis is indeed the current behavior of httpx, but boy does that bug me, that the `repr` of a user info string doesn't convert back to even a correct URL, let alone the equivalent URL.  \r\n```\r\nu = httpx.URL('http://user:hunter2@example.com')\r\nu\r\nOut[10]: URL('http://user:[secure]@example.com')\r\nstr(u)\r\nOut[11]: 'http://user:hunter2@example.com'\r\nhttpx.URL('http://user:[secure]@example.com')\r\nOut[12]: URL('http:')\r\n```\r\n\r\nI think it would be better if it didn't use square braces to elide the password, since that screws up later parses, but that's beyond the purview of this PR, so... `\u00af\\_(\u30c4)_/\u00af`  ",
      "comment_id": 907469214,
      "user": "xkortex",
      "created_at": "2022-06-27T14:41:37Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r907469214"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2252,
      "file_path": "httpx/_urls.py",
      "line": 384,
      "side": "RIGHT",
      "diff_hunk": "@@ -507,21 +365,33 @@ def __eq__(self, other: typing.Any) -> bool:\n         return isinstance(other, (URL, str)) and str(self) == str(URL(other))\n \n     def __str__(self) -> str:\n-        return self._uri_reference.unsplit()\n+        return str(self._uri_reference)\n \n     def __repr__(self) -> str:\n-        class_name = self.__class__.__name__\n-        url_str = str(self)\n-        if self._uri_reference.userinfo:\n-            # Mask any password component in the URL representation, to lower the\n-            # risk of unintended leakage, such as in debug information and logging.\n-            username = quote(self.username)\n-            url_str = (\n-                rfc3986.urlparse(url_str)\n-                .copy_with(userinfo=f\"{username}:[secure]\")\n-                .unsplit()\n-            )\n-        return f\"{class_name}({url_str!r})\"\n+        scheme, userinfo, host, port, path, query, fragment = self._uri_reference\n+\n+        if \":\" in userinfo:\n+            # Mask any password component.\n+            userinfo = f'{userinfo.split(\":\")[0]}:[secure]'\n+\n+        authority = \"\".join(\n+            [\n+                f\"{userinfo}@\" if userinfo else \"\",\n+                f\"[{host}]\" if \":\" in host else host,\n+                f\":{port}\" if port is not None else \"\",\n+            ]\n+        )\n+        url = \"\".join(",
      "comment": "> I think it would be better if it didn't use square braces to elide the password, since that screws up later parses, but that's beyond the purview of this PR\r\n\r\nHrm, yes, we could certainly reconsider that. As you say tho, we'd do so independently of this pull request.",
      "comment_id": 933312779,
      "user": "lovelydinosaur",
      "created_at": "2022-07-29T14:09:27Z",
      "url": "https://github.com/encode/httpx/pull/2252#discussion_r933312779"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "tests/test_multipart.py",
      "line": 100,
      "side": "RIGHT",
      "diff_hunk": "@@ -42,6 +42,64 @@ def test_multipart(value, output):\n     assert multipart[\"file\"] == [b\"<file content>\"]\n \n \n+@pytest.mark.parametrize(\n+    \"header\",\n+    [\n+        \"multipart/form-data; boundary=+++; charset=utf-8\",\n+        \"multipart/form-data; charset=utf-8; boundary=+++\",\n+        \"multipart/form-data; boundary=+++\",\n+        \"multipart/form-data; boundary=+++ ;\",\n+    ],\n+)\n+def test_multipart_explicit_boundary(header: str) -> None:\n+    client = httpx.Client(transport=httpx.MockTransport(echo_request_content))\n+\n+    files = {\"file\": io.BytesIO(b\"<file content>\")}\n+    headers = {\"content-type\": header}\n+    response = client.post(\"http://127.0.0.1:8000/\", files=files, headers=headers)\n+    assert response.status_code == 200\n+\n+    # We're using the cgi module to verify the behavior here, which is a\n+    # bit grungy, but sufficient just for our testing purposes.\n+    assert response.request.headers[\"Content-Type\"] == header\n+    content_length = response.request.headers[\"Content-Length\"]\n+    pdict: dict = {\n+        \"boundary\": b\"+++\",\n+        \"CONTENT-LENGTH\": content_length,\n+    }\n+    multipart = cgi.parse_multipart(io.BytesIO(response.content), pdict)\n+\n+    assert multipart[\"file\"] == [b\"<file content>\"]\n+\n+\n+@pytest.mark.parametrize(\n+    \"header\",\n+    [\n+        \"multipart/form-data; charset=utf-8\",\n+        \"multipart/form-data; charset=utf-8; \",\n+    ],\n+)\n+def test_multipart_header_without_boundary(header: str) -> None:\n+    client = httpx.Client(transport=httpx.MockTransport(echo_request_content))\n+\n+    files = {\"file\": io.BytesIO(b\"<file content>\")}\n+    headers = {\"content-type\": header}\n+    response = client.post(\"http://127.0.0.1:8000/\", files=files, headers=headers)\n+    assert response.status_code == 200\n+\n+    # We're using the cgi module to verify the behavior here, which is a\n+    # bit grungy, but sufficient just for our testing purposes.\n+    boundary = response.request.headers[\"Content-Type\"].split(\"boundary=\")[-1]\n+    content_length = response.request.headers[\"Content-Length\"]\n+    pdict: dict = {\n+        \"boundary\": boundary.encode(\"ascii\"),\n+        \"CONTENT-LENGTH\": content_length,\n+    }\n+    multipart = cgi.parse_multipart(io.BytesIO(response.content), pdict)\n+\n+    assert multipart[\"file\"] == [b\"<file content>\"]",
      "comment": "This test is fails on main/master as well, but I think it would be important to fix in this PR. What needs to happen is we need to create the random boundary and then insert that into the existing header. The issue is that there is currently no machinery / precedent for `encode_request()` modifying headers, so it would take a bit more refactoring to get working. Alternatively, we can raise an error if a user gives us a `content-type: multipart/form-data` without an explicit header?",
      "comment_id": 905240480,
      "user": "adriangb",
      "created_at": "2022-06-23T16:33:10Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r905240480"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_content.py",
      "line": 201,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,6 +198,7 @@ def encode_request(\n     files: Optional[RequestFiles] = None,\n     json: Optional[Any] = None,\n     boundary: Optional[bytes] = None,\n+    headers: Optional[Mapping[str, str]] = None,",
      "comment": "How about we keep things a little tighter here by passing `content_type: str = None` instead? That restricts the information we're passing around to the one thing we're actually interested in.",
      "comment_id": 905940496,
      "user": "lovelydinosaur",
      "created_at": "2022-06-24T10:35:58Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r905940496"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_multipart.py",
      "line": 30,
      "side": "RIGHT",
      "diff_hunk": "@@ -20,6 +20,16 @@\n )\n \n \n+def get_multipart_boundary_from_content_type(\n+    content_type: str,\n+) -> bytes:\n+    if \";\" in content_type:\n+        for section in content_type.split(\";\"):\n+            if section.strip().startswith(\"boundary=\"):\n+                return section.strip().split(\"boundary=\")[-1].encode(\"latin-1\")\n+    raise ValueError(\"Missing boundary in multipart/form-data content-type header\")",
      "comment": "Instead of raising `ValueError` we could just return `None` if the content type doesn't start with \"multipart/form-data\", or doesn't include a valid boundary.\r\n\r\n(Users can currently submit requests with `Content-Type` headers that don't properly match up to the data they include, so just being lax here seems okay to me.)",
      "comment_id": 905947972,
      "user": "lovelydinosaur",
      "created_at": "2022-06-24T10:47:18Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r905947972"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_content.py",
      "line": 161,
      "side": "RIGHT",
      "diff_hunk": "@@ -150,11 +151,21 @@ def encode_urlencoded_data(\n \n \n def encode_multipart_data(\n-    data: dict, files: RequestFiles, boundary: Optional[bytes] = None\n+    data: dict,\n+    files: RequestFiles,\n+    boundary: Optional[bytes] = None,\n+    headers: Optional[Mapping[str, str]] = None,\n ) -> Tuple[Dict[str, str], MultipartStream]:\n+    if headers and boundary is None and \"content-type\" in headers:\n+        content_type = headers[\"content-type\"]\n+        if not content_type.startswith(\"multipart/form-data\"):",
      "comment": "I think we could drop this case, as with [this comment](https://github.com/encode/httpx/pull/2278/files#r905947972).",
      "comment_id": 905948476,
      "user": "lovelydinosaur",
      "created_at": "2022-06-24T10:48:07Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r905948476"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_multipart.py",
      "line": 30,
      "side": "RIGHT",
      "diff_hunk": "@@ -20,6 +20,16 @@\n )\n \n \n+def get_multipart_boundary_from_content_type(\n+    content_type: str,\n+) -> bytes:\n+    if \";\" in content_type:\n+        for section in content_type.split(\";\"):\n+            if section.strip().startswith(\"boundary=\"):\n+                return section.strip().split(\"boundary=\")[-1].encode(\"latin-1\")\n+    raise ValueError(\"Missing boundary in multipart/form-data content-type header\")",
      "comment": "Note that since `content-type` gets set [via `setdefault`](https://github.com/encode/httpx/blob/aad60a4f123801e7ce0e02bc49138e7f0f9ca0a5/httpx/_models.py#L362). If it already exists, it won't be overwritten. So in the case where the user provided the `content-type` header but did not provide the multipart boundary we'd be sending out a request with no multipart boundary, which completely violates the spec and no server will be able to parse.",
      "comment_id": 906733887,
      "user": "adriangb",
      "created_at": "2022-06-25T23:17:15Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r906733887"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_multipart.py",
      "line": 30,
      "side": "RIGHT",
      "diff_hunk": "@@ -20,6 +20,16 @@\n )\n \n \n+def get_multipart_boundary_from_content_type(\n+    content_type: str,\n+) -> bytes:\n+    if \";\" in content_type:\n+        for section in content_type.split(\";\"):\n+            if section.strip().startswith(\"boundary=\"):\n+                return section.strip().split(\"boundary=\")[-1].encode(\"latin-1\")\n+    raise ValueError(\"Missing boundary in multipart/form-data content-type header\")",
      "comment": "> So in the case where the user provided the content-type header but did not provide the multipart boundary we'd be sending out a request with no multipart boundary, which completely violates the spec and no server will be able to parse.\r\n\r\nTrue. We could either hard-error in that case, or just ignore it and allow users to do that.\r\n\r\nThere is also a whole class of cases here where a user can set a `Content-Type` that doesn't match the encoding type they're using with `data=`/`files=`/`json=`. (Eg. they can set `Content-Type: application/json` on either form or multipart requests.) But that's probably okay.\r\n\r\n\r\n\r\n",
      "comment_id": 907177499,
      "user": "lovelydinosaur",
      "created_at": "2022-06-27T09:30:20Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r907177499"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_content.py",
      "line": 159,
      "side": "RIGHT",
      "diff_hunk": "@@ -150,11 +150,16 @@ def encode_urlencoded_data(\n \n \n def encode_multipart_data(\n-    data: dict, files: RequestFiles, boundary: Optional[bytes] = None\n+    data: dict,\n+    files: RequestFiles,\n+    boundary: Optional[bytes] = None,\n+    content_type: Optional[str] = None,\n ) -> Tuple[Dict[str, str], MultipartStream]:\n+    if content_type:\n+        boundary = get_multipart_boundary_from_content_type(content_type)",
      "comment": "Shouldn't we check that `boundary is None` before computing `boundary`? (In other words, what happens when `content_type` and `boundary` do not agree on the value to use for `boundary`?)",
      "comment_id": 945183299,
      "user": "jhominal",
      "created_at": "2022-08-13T19:44:33Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945183299"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_content.py",
      "line": 159,
      "side": "RIGHT",
      "diff_hunk": "@@ -150,11 +150,16 @@ def encode_urlencoded_data(\n \n \n def encode_multipart_data(\n-    data: dict, files: RequestFiles, boundary: Optional[bytes] = None\n+    data: dict,\n+    files: RequestFiles,\n+    boundary: Optional[bytes] = None,\n+    content_type: Optional[str] = None,\n ) -> Tuple[Dict[str, str], MultipartStream]:\n+    if content_type:\n+        boundary = get_multipart_boundary_from_content_type(content_type)",
      "comment": "We're the only ones ever making the call into this function and we never call it with a mismatch. If I add the error I would either have to (1) add a test just to check the error or (2) pragma: no cover it. I'll add a comment instead.",
      "comment_id": 945184522,
      "user": "adriangb",
      "created_at": "2022-08-13T20:00:32Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945184522"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_content.py",
      "line": 159,
      "side": "RIGHT",
      "diff_hunk": "@@ -150,11 +150,16 @@ def encode_urlencoded_data(\n \n \n def encode_multipart_data(\n-    data: dict, files: RequestFiles, boundary: Optional[bytes] = None\n+    data: dict,\n+    files: RequestFiles,\n+    boundary: Optional[bytes] = None,\n+    content_type: Optional[str] = None,\n ) -> Tuple[Dict[str, str], MultipartStream]:\n+    if content_type:\n+        boundary = get_multipart_boundary_from_content_type(content_type)",
      "comment": "Shouldn't the `get_multipart_boundary_from_content_type` call be made upstream? e.g. in httpx/_models.py?",
      "comment_id": 945184797,
      "user": "jhominal",
      "created_at": "2022-08-13T20:03:24Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945184797"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_models.py",
      "line": 341,
      "side": "RIGHT",
      "diff_hunk": "@@ -332,7 +332,13 @@ def __init__(\n             Cookies(cookies).set_cookie_header(self)\n \n         if stream is None:\n-            headers, stream = encode_request(content, data, files, json)\n+            headers, stream = encode_request(\n+                content=content,\n+                data=data,\n+                files=files,\n+                json=json,\n+                content_type=self.headers.get(\"content-type\"),\n+            )",
      "comment": "By the comment on the other thread, I mean, why not write:\r\n```suggestion\r\n            headers, stream = encode_request(\r\n                content=content,\r\n                data=data,\r\n                files=files,\r\n                json=json,\r\n                boundary= get_multipart_boundary_from_content_type(self.headers.get(\"content-type\")),\r\n            )\r\n```\r\n\r\nThat way, we do not have function signatures that have both a `boundary` and a `content_type` that could possibly have contradictory data?",
      "comment_id": 945184961,
      "user": "jhominal",
      "created_at": "2022-08-13T20:06:12Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945184961"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_models.py",
      "line": 341,
      "side": "RIGHT",
      "diff_hunk": "@@ -332,7 +332,13 @@ def __init__(\n             Cookies(cookies).set_cookie_header(self)\n \n         if stream is None:\n-            headers, stream = encode_request(content, data, files, json)\n+            headers, stream = encode_request(\n+                content=content,\n+                data=data,\n+                files=files,\n+                json=json,\n+                content_type=self.headers.get(\"content-type\"),\n+            )",
      "comment": "By which I mean, the `content_type` argument could be removed from `encode_request` and `encode_multipart_data`?",
      "comment_id": 945185034,
      "user": "jhominal",
      "created_at": "2022-08-13T20:07:03Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945185034"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_content.py",
      "line": 159,
      "side": "RIGHT",
      "diff_hunk": "@@ -150,11 +150,16 @@ def encode_urlencoded_data(\n \n \n def encode_multipart_data(\n-    data: dict, files: RequestFiles, boundary: Optional[bytes] = None\n+    data: dict,\n+    files: RequestFiles,\n+    boundary: Optional[bytes] = None,\n+    content_type: Optional[str] = None,\n ) -> Tuple[Dict[str, str], MultipartStream]:\n+    if content_type:\n+        boundary = get_multipart_boundary_from_content_type(content_type)",
      "comment": "I think _should_ would be a bit strong of a word, we certainly _could_ do that. I think the main reason for having it here is that `_models.py` doesn't know about multipart request or other encoding stuff, so it would be a bit of a violation of the layering that is currently set up to put something like `if content_type.startswith(\"multipart/form-data\")`: <do multipart specific stuff>`.",
      "comment_id": 945185173,
      "user": "adriangb",
      "created_at": "2022-08-13T20:08:37Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945185173"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_content.py",
      "line": 159,
      "side": "RIGHT",
      "diff_hunk": "@@ -150,11 +150,16 @@ def encode_urlencoded_data(\n \n \n def encode_multipart_data(\n-    data: dict, files: RequestFiles, boundary: Optional[bytes] = None\n+    data: dict,\n+    files: RequestFiles,\n+    boundary: Optional[bytes] = None,\n+    content_type: Optional[str] = None,\n ) -> Tuple[Dict[str, str], MultipartStream]:\n+    if content_type:\n+        boundary = get_multipart_boundary_from_content_type(content_type)",
      "comment": "No need to apologize for a good suggestion \ud83d\ude04 \r\nLike I said I'm open to it, but I do feel that it breaks a bit with the way abstractions are currently set up in the codebase",
      "comment_id": 945185588,
      "user": "adriangb",
      "created_at": "2022-08-13T20:13:18Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945185588"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_models.py",
      "line": 341,
      "side": "RIGHT",
      "diff_hunk": "@@ -332,7 +332,13 @@ def __init__(\n             Cookies(cookies).set_cookie_header(self)\n \n         if stream is None:\n-            headers, stream = encode_request(content, data, files, json)\n+            headers, stream = encode_request(\n+                content=content,\n+                data=data,\n+                files=files,\n+                json=json,\n+                content_type=self.headers.get(\"content-type\"),\n+            )",
      "comment": "Okay I liked it once I wrote it, I think given that `encode_request` already takes a `boundary` parameter (which only makes sense in the context of multipart requests) moving the call to where you are suggesting is not a big deal",
      "comment_id": 945185780,
      "user": "adriangb",
      "created_at": "2022-08-13T20:15:59Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945185780"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_models.py",
      "line": 341,
      "side": "RIGHT",
      "diff_hunk": "@@ -332,7 +332,13 @@ def __init__(\n             Cookies(cookies).set_cookie_header(self)\n \n         if stream is None:\n-            headers, stream = encode_request(content, data, files, json)\n+            headers, stream = encode_request(\n+                content=content,\n+                data=data,\n+                files=files,\n+                json=json,\n+                content_type=self.headers.get(\"content-type\"),\n+            )",
      "comment": "Yes, that kind of was my thought (if `encode_request` did not have `boundary` I would not have suggested that). Thank you for accepting my suggestion.\r\n\r\nI just wonder if you would also go also look at potentially reviewing the remaining changes in `httpx/_content.py`? I mean, these changes seem mostly vestigial to me (e.g. the `content_type` in `encode_request`, and the changes in `encode_multipart_data` are now purely of variable and formatting (and `boundary` is now a required argument)",
      "comment_id": 945186211,
      "user": "jhominal",
      "created_at": "2022-08-13T20:20:56Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945186211"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_multipart.py",
      "line": 31,
      "side": "RIGHT",
      "diff_hunk": "@@ -20,6 +20,18 @@\n )\n \n \n+def get_multipart_boundary_from_content_type(\n+    content_type: typing.Optional[str],\n+) -> typing.Optional[bytes]:\n+    if not content_type or not content_type.startswith(\"multipart/form-data\"):\n+        return None\n+    if \";\" in content_type:\n+        for section in content_type.split(\";\"):\n+            if section.strip().startswith(\"boundary=\"):\n+                return section.strip().split(\"boundary=\")[-1].encode(\"latin-1\")",
      "comment": "Is there any possibility that `boundary` could be quoted, with either simple or double quotes?",
      "comment_id": 945186645,
      "user": "jhominal",
      "created_at": "2022-08-13T20:26:29Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945186645"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_multipart.py",
      "line": 31,
      "side": "RIGHT",
      "diff_hunk": "@@ -20,6 +20,18 @@\n )\n \n \n+def get_multipart_boundary_from_content_type(\n+    content_type: typing.Optional[str],\n+) -> typing.Optional[bytes]:\n+    if not content_type or not content_type.startswith(\"multipart/form-data\"):\n+        return None\n+    if \";\" in content_type:\n+        for section in content_type.split(\";\"):\n+            if section.strip().startswith(\"boundary=\"):\n+                return section.strip().split(\"boundary=\")[-1].encode(\"latin-1\")",
      "comment": "[RFC 2046](https://www.rfc-editor.org/rfc/rfc2046#section-5.1.1) has examples where boundary is contained in quotes. Do we want to support that?",
      "comment_id": 945186942,
      "user": "jhominal",
      "created_at": "2022-08-13T20:30:19Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945186942"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_multipart.py",
      "line": 31,
      "side": "RIGHT",
      "diff_hunk": "@@ -20,6 +20,18 @@\n )\n \n \n+def get_multipart_boundary_from_content_type(\n+    content_type: typing.Optional[str],\n+) -> typing.Optional[bytes]:\n+    if not content_type or not content_type.startswith(\"multipart/form-data\"):\n+        return None\n+    if \";\" in content_type:\n+        for section in content_type.split(\";\"):\n+            if section.strip().startswith(\"boundary=\"):\n+                return section.strip().split(\"boundary=\")[-1].encode(\"latin-1\")",
      "comment": "Great catch! Not sure how you find these things but thank you",
      "comment_id": 945209881,
      "user": "adriangb",
      "created_at": "2022-08-13T23:56:04Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945209881"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_multipart.py",
      "line": 31,
      "side": "RIGHT",
      "diff_hunk": "@@ -20,6 +20,18 @@\n )\n \n \n+def get_multipart_boundary_from_content_type(\n+    content_type: typing.Optional[str],\n+) -> typing.Optional[bytes]:\n+    if not content_type or not content_type.startswith(\"multipart/form-data\"):\n+        return None\n+    if \";\" in content_type:\n+        for section in content_type.split(\";\"):\n+            if section.strip().startswith(\"boundary=\"):\n+                return section.strip().split(\"boundary=\")[-1].encode(\"latin-1\")",
      "comment": "After reviewing the grammar for boundary ([RFC 2046 Appendix A](https://www.rfc-editor.org/rfc/rfc2046#page-43), referencing [RFC 2045 \u00a75.1](https://www.rfc-editor.org/rfc/rfc2045#section-5.1), referencing [RFC 822 \u00a73.3](https://www.rfc-editor.org/rfc/rfc822#section-3.3) which has been replaced by [RFC 5322 \u00a73.2.4](https://www.rfc-editor.org/rfc/rfc5322#section-3.2.4)):\r\n\r\n1. The only quoting character that seems to be valid is the double quote `\"` (`'` is not valid for that usage);\r\n2. However, when the double quote is in use, any backslash `\\` will be part of a \"quoted pair\", meaning that it is semantically equivalent to the next character (`\\\\` => `\\`, `\\\"` => `\"`);\r\n3. However, there is a limitation on allowed characters in a boundary - none of the characters that would require a quoted pair escape are allowed in a boundary;\r\n\r\nIn other words:\r\n * We need to handle only `\"` for quoting;\r\n * We also need to decide what to do about quoted pairs:\r\n   * Either we write a simpler implementation that does not handle them, as all legal boundaries can be written without using quoted pairs;\r\n   * Or we go the extra mile of supporting quoted pairs;\r\n * What do we want to do about the fact that not all ascii characters are allowed as part of a boundary?",
      "comment_id": 945285489,
      "user": "jhominal",
      "created_at": "2022-08-14T12:50:56Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945285489"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_multipart.py",
      "line": 31,
      "side": "RIGHT",
      "diff_hunk": "@@ -20,6 +20,18 @@\n )\n \n \n+def get_multipart_boundary_from_content_type(\n+    content_type: typing.Optional[str],\n+) -> typing.Optional[bytes]:\n+    if not content_type or not content_type.startswith(\"multipart/form-data\"):\n+        return None\n+    if \";\" in content_type:\n+        for section in content_type.split(\";\"):\n+            if section.strip().startswith(\"boundary=\"):\n+                return section.strip().split(\"boundary=\")[-1].encode(\"latin-1\")",
      "comment": "I think we can go with the simpler implementation. I also don't think we need to handle non-valid characters, that'd be too much introspection ",
      "comment_id": 945291083,
      "user": "adriangb",
      "created_at": "2022-08-14T13:32:51Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945291083"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_multipart.py",
      "line": 31,
      "side": "RIGHT",
      "diff_hunk": "@@ -20,6 +20,18 @@\n )\n \n \n+def get_multipart_boundary_from_content_type(\n+    content_type: typing.Optional[str],\n+) -> typing.Optional[bytes]:\n+    if not content_type or not content_type.startswith(\"multipart/form-data\"):\n+        return None\n+    if \";\" in content_type:\n+        for section in content_type.split(\";\"):\n+            if section.strip().startswith(\"boundary=\"):\n+                return section.strip().split(\"boundary=\")[-1].encode(\"latin-1\")",
      "comment": "I just removed the `'` stripping, which I think now makes this able to parse any boundary except the ones with quoted pairs (valid but never necessary).",
      "comment_id": 945728832,
      "user": "adriangb",
      "created_at": "2022-08-15T13:22:20Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945728832"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "httpx/_multipart.py",
      "line": 33,
      "side": "RIGHT",
      "diff_hunk": "@@ -20,6 +20,20 @@\n )\n \n \n+def get_multipart_boundary_from_content_type(\n+    content_type: typing.Optional[bytes],\n+) -> typing.Optional[bytes]:\n+    if not content_type or not content_type.startswith(b\"multipart/form-data\"):\n+        return None\n+    # parse boundary according to\n+    # https://www.rfc-editor.org/rfc/rfc2046#section-5.1.1\n+    if b\";\" in content_type:\n+        for section in content_type.split(b\";\"):\n+            if section.strip().startswith(b\"boundary=\"):\n+                return section.strip().split(b\"boundary=\")[-1].strip(b'\"')",
      "comment": "```suggestion\r\n            if section.strip().lower().startswith(b\"boundary=\"):\r\n                return section.strip()[len(b\"boundary=\"):].strip(b'\"')\r\n```\r\n\r\nI am making this suggestion to solve two things I see as issues (you can argue that these are niche edge cases, but I think that the changes I suggest are reasonable) with the current implementation:\r\n\r\n 1. As indicated in [RFC 2045](https://www.rfc-editor.org/rfc/rfc2045#section-5.1), matching of attributes (of which `boundary` is one) is always case insensitive (thus `BOUNDARY=\"abcd\"` would also work) - so I have added a call to `lower()` on line 32;\r\n 2. The implementation with `split` will fail on a boundary that contains the `boundary=` substring. I think the intent is clearer if we write code that simply removes the prefix, and also reduces the number of potential edge cases;",
      "comment_id": 945822783,
      "user": "jhominal",
      "created_at": "2022-08-15T14:44:39Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r945822783"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2278,
      "file_path": "tests/test_multipart.py",
      "line": 94,
      "side": "RIGHT",
      "diff_hunk": "@@ -42,6 +42,58 @@ def test_multipart(value, output):\n     assert multipart[\"file\"] == [b\"<file content>\"]\n \n \n+@pytest.mark.parametrize(\n+    \"header\",\n+    [\n+        \"multipart/form-data; boundary=+++; charset=utf-8\",\n+        \"multipart/form-data; charset=utf-8; boundary=+++\",\n+        \"multipart/form-data; boundary=+++\",\n+        \"multipart/form-data; boundary=+++ ;\",\n+        'multipart/form-data; boundary=\"+++\"; charset=utf-8',\n+        'multipart/form-data; charset=utf-8; boundary=\"+++\"',\n+        'multipart/form-data; boundary=\"+++\"',\n+        'multipart/form-data; boundary=\"+++\" ;',\n+    ],\n+)\n+def test_multipart_explicit_boundary(header: str) -> None:\n+    client = httpx.Client(transport=httpx.MockTransport(echo_request_content))\n+\n+    files = {\"file\": io.BytesIO(b\"<file content>\")}\n+    headers = {\"content-type\": header}\n+    response = client.post(\"http://127.0.0.1:8000/\", files=files, headers=headers)\n+    assert response.status_code == 200\n+\n+    # We're using the cgi module to verify the behavior here, which is a\n+    # bit grungy, but sufficient just for our testing purposes.\n+    assert response.request.headers[\"Content-Type\"] == header\n+    content_length = response.request.headers[\"Content-Length\"]\n+    pdict: dict = {\n+        \"boundary\": b\"+++\",\n+        \"CONTENT-LENGTH\": content_length,\n+    }\n+    multipart = cgi.parse_multipart(io.BytesIO(response.content), pdict)\n+\n+    assert multipart[\"file\"] == [b\"<file content>\"]\n+\n+\n+@pytest.mark.parametrize(\n+    \"header\",\n+    [\n+        \"multipart/form-data; charset=utf-8\",\n+        \"multipart/form-data; charset=utf-8; \",\n+    ],\n+)\n+def test_multipart_header_without_boundary(header: str) -> None:\n+    client = httpx.Client(transport=httpx.MockTransport(echo_request_content))\n+\n+    files = {\"file\": io.BytesIO(b\"<file content>\")}\n+    headers = {\"content-type\": header}\n+    response = client.post(\"http://127.0.0.1:8000/\", files=files, headers=headers)\n+\n+    assert response.status_code == 200\n+    assert response.request.headers[\"Content-Type\"] == header",
      "comment": "@adriangb Shouldn't it provide autogenerated boundary in the header ? Seems like it causes this [issue](https://github.com/encode/httpx/issues/3522) ?",
      "comment_id": 1977589495,
      "user": "Anton-Shutik",
      "created_at": "2025-03-03T14:15:18Z",
      "url": "https://github.com/encode/httpx/pull/2278#discussion_r1977589495"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3371,
      "file_path": "tests/models/test_url.py",
      "line": 620,
      "side": "RIGHT",
      "diff_hunk": "@@ -614,10 +614,10 @@ def test_url_copywith_userinfo_subcomponents():\n     }\n     url = httpx.URL(\"https://example.org\")\n     new = url.copy_with(**copy_with_kwargs)\n-    assert str(new) == \"https://tom%40example.org:abc123%40%20%25@example.org\"\n+    assert str(new) == \"https://tom%40example.org:abc123%40%20%@example.org\"\n     assert new.username == \"tom@example.org\"\n     assert new.password == \"abc123@ %\"\n-    assert new.userinfo == b\"tom%40example.org:abc123%40%20%25\"\n+    assert new.userinfo == b\"tom%40example.org:abc123%40%20%\"",
      "comment": "This looks weird. I could be wrong. But should the userinfo field contain partial escapes? The trialing % sign change here seem odd. \r\n\r\n",
      "comment_id": 1895670033,
      "user": "elupus",
      "created_at": "2024-12-23T11:57:19Z",
      "url": "https://github.com/encode/httpx/pull/3371#discussion_r1895670033"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2911,
      "file_path": "httpx/_models.py",
      "line": 766,
      "side": "LEFT",
      "diff_hunk": "@@ -759,11 +758,7 @@ def raise_for_status(self) -> \"Response\":\n         raise HTTPStatusError(message, request=request, response=self)\n \n     def json(self, **kwargs: typing.Any) -> typing.Any:\n-        if self.charset_encoding is None and self.content and len(self.content) > 3:\n-            encoding = guess_json_utf(self.content)\n-            if encoding is not None:\n-                return jsonlib.loads(self.content.decode(encoding), **kwargs)\n-        return jsonlib.loads(self.text, **kwargs)",
      "comment": "Just a random thing I noticed looking through the code, not a problem I've seen in the wild: isn't using `self.text` like this this better than the new version when there's a non-utf charset?",
      "comment_id": 1890475281,
      "user": "alexmojaki",
      "created_at": "2024-12-18T15:56:52Z",
      "url": "https://github.com/encode/httpx/pull/2911#discussion_r1890475281"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3367,
      "file_path": "tests/test_content.py",
      "line": 7,
      "side": "RIGHT",
      "diff_hunk": "@@ -4,6 +4,7 @@\n import pytest\n \n import httpx\n+from httpx._content import encode_json",
      "comment": "I've just noticed this accidentally snuck in a private import.\r\n\r\n@BERRADA-Omar would you be up for refactoring these tests?\r\n\r\nWe can test this against public API using `httpx.Request()`. Eg...\r\n\r\n```python\r\ndata = {...}\r\nreq = httpx.Request(\"POST\", \"https://www.example.com/\", json=data)\r\nassert req.content == ...\r\nassert req.headers = ...\r\n```",
      "comment_id": 1829240738,
      "user": "lovelydinosaur",
      "created_at": "2024-11-05T12:08:10Z",
      "url": "https://github.com/encode/httpx/pull/3367#discussion_r1829240738"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3418,
      "file_path": "httpx/_config.py",
      "line": 34,
      "side": "RIGHT",
      "diff_hunk": "@@ -31,6 +31,14 @@ def create_ssl_context(verify: ssl.SSLContext | bool = True) -> ssl.SSLContext:\n         ssl_context.check_hostname = False\n         ssl_context.verify_mode = ssl.CERT_NONE\n         return ssl_context\n+    elif isinstance(verify, str):  # pagma: nocover",
      "comment": "```suggestion\r\n    elif isinstance(verify, str):  # pragma: nocover\r\n```",
      "comment_id": 1862031777,
      "user": "lovelydinosaur",
      "created_at": "2024-11-28T11:42:48Z",
      "url": "https://github.com/encode/httpx/pull/3418#discussion_r1862031777"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3387,
      "file_path": "httpx/_models.py",
      "line": 130,
      "side": "RIGHT",
      "diff_hunk": "@@ -72,6 +82,60 @@ def _normalize_header_value(value: str | bytes, encoding: str | None = None) ->\n     return value.encode(encoding or \"ascii\")\n \n \n+def _parse_content_type_charset(content_type: str) -> str | None:\n+    # We used to use `cgi.parse_header()` here, but `cgi` became a dead battery.\n+    # See: https://peps.python.org/pep-0594/#cgi\n+    msg = email.message.Message()\n+    msg[\"content-type\"] = content_type\n+    return msg.get_content_charset(failobj=None)\n+\n+\n+def _parse_header_links(value: str) -> list[dict[str, str]]:\n+    \"\"\"\n+    Returns a list of parsed link headers, for more info see:\n+    https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Link\n+    The generic syntax of those is:\n+    Link: < uri-reference >; param1=value1; param2=\"value2\"\n+    So for instance:\n+    Link; '<http:/.../front.jpeg>; type=\"image/jpeg\",<http://.../back.jpeg>;'\n+    would return\n+        [\n+            {\"url\": \"http:/.../front.jpeg\", \"type\": \"image/jpeg\"},\n+            {\"url\": \"http://.../back.jpeg\"},\n+        ]\n+    :param value: HTTP Link entity-header field\n+    :return: list of parsed link headers\n+    \"\"\"\n+    links: list[dict[str, str]] = []\n+    replace_chars = \" '\\\"\"\n+    value = value.strip(replace_chars)\n+    if not value:\n+        return links\n+    for val in re.split(\", *<\", value):\n+        try:\n+            url, params = val.split(\";\", 1)\n+        except ValueError:\n+            url, params = val, \"\"\n+        link = {\"url\": url.strip(\"<> '\\\"\")}\n+        for param in params.split(\";\"):\n+            try:\n+                key, value = param.split(\"=\")\n+            except ValueError:\n+                break\n+            link[key.strip(replace_chars)] = value.strip(replace_chars)\n+        links.append(link)\n+    return links\n+\n+\n+def _obfuscate_sensitive_headers(",
      "comment": "Is now a good time to review this? Eg does flask provide similar behaviour onto its headers data structures? Does Django?\n\n(Possibly too off topic??)",
      "comment_id": 1826205536,
      "user": "lovelydinosaur",
      "created_at": "2024-11-01T19:15:43Z",
      "url": "https://github.com/encode/httpx/pull/3387#discussion_r1826205536"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3387,
      "file_path": "httpx/_models.py",
      "line": 130,
      "side": "RIGHT",
      "diff_hunk": "@@ -72,6 +82,60 @@ def _normalize_header_value(value: str | bytes, encoding: str | None = None) ->\n     return value.encode(encoding or \"ascii\")\n \n \n+def _parse_content_type_charset(content_type: str) -> str | None:\n+    # We used to use `cgi.parse_header()` here, but `cgi` became a dead battery.\n+    # See: https://peps.python.org/pep-0594/#cgi\n+    msg = email.message.Message()\n+    msg[\"content-type\"] = content_type\n+    return msg.get_content_charset(failobj=None)\n+\n+\n+def _parse_header_links(value: str) -> list[dict[str, str]]:\n+    \"\"\"\n+    Returns a list of parsed link headers, for more info see:\n+    https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Link\n+    The generic syntax of those is:\n+    Link: < uri-reference >; param1=value1; param2=\"value2\"\n+    So for instance:\n+    Link; '<http:/.../front.jpeg>; type=\"image/jpeg\",<http://.../back.jpeg>;'\n+    would return\n+        [\n+            {\"url\": \"http:/.../front.jpeg\", \"type\": \"image/jpeg\"},\n+            {\"url\": \"http://.../back.jpeg\"},\n+        ]\n+    :param value: HTTP Link entity-header field\n+    :return: list of parsed link headers\n+    \"\"\"\n+    links: list[dict[str, str]] = []\n+    replace_chars = \" '\\\"\"\n+    value = value.strip(replace_chars)\n+    if not value:\n+        return links\n+    for val in re.split(\", *<\", value):\n+        try:\n+            url, params = val.split(\";\", 1)\n+        except ValueError:\n+            url, params = val, \"\"\n+        link = {\"url\": url.strip(\"<> '\\\"\")}\n+        for param in params.split(\";\"):\n+            try:\n+                key, value = param.split(\"=\")\n+            except ValueError:\n+                break\n+            link[key.strip(replace_chars)] = value.strip(replace_chars)\n+        links.append(link)\n+    return links\n+\n+\n+def _obfuscate_sensitive_headers(",
      "comment": "It seems that flask does not obfuscate header values for `repr` (see [werkzeug](https://github.com/pallets/werkzeug/blob/357681fc26dd46ec5b7c3c067732873f57db0bc8/src/werkzeug/datastructures/headers.py#L20))\r\n\r\n```python\r\n>>> from werkzeug.datastructures import Headers\r\n>>>\r\n>>> head = Headers({\"authorization\": \"s3kr3t\"})\r\n>>> head\r\nHeaders([('authorization', 's3kr3t')])\r\n>>> repr(head)\r\n\"Headers([('authorization', 's3kr3t')])\"\r\n```\r\n\r\nSame for Django (see [HttpHeaders ](https://github.com/django/django/blob/611bf6c2e2a1b4ab93273980c45150c099ab146d/django/http/request.py#L468) or [ResponseHeaders](https://github.com/django/django/blob/611bf6c2e2a1b4ab93273980c45150c099ab146d/django/http/response.py#L33))\r\n\r\n```python\r\n>>> from django.http.response import ResponseHeaders\r\n>>> head = ResponseHeaders({\"Authorization\": \"s3kr3t\"})\r\n>>> repr(head)\r\n\"{'Authorization': 's3kr3t'}\"\r\n```",
      "comment_id": 1826536279,
      "user": "RafaelWO",
      "created_at": "2024-11-02T09:45:25Z",
      "url": "https://github.com/encode/httpx/pull/3387#discussion_r1826536279"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3370,
      "file_path": "httpx/_api.py",
      "line": 94,
      "side": "LEFT",
      "diff_hunk": "@@ -80,18 +79,11 @@ def request(\n     * **auth** - *(optional)* An authentication class to use when sending the\n     request.\n     * **proxy** - *(optional)* A proxy URL where all the traffic should be routed.\n-    * **proxies** - *(optional)* A dictionary mapping proxy keys to proxy URLs.\n     * **timeout** - *(optional)* The timeout configuration to use when sending\n     the request.\n     * **follow_redirects** - *(optional)* Enables or disables HTTP redirects.\n-    * **verify** - *(optional)* SSL certificates (a.k.a CA bundle) used to\n-    verify the identity of requested hosts. Either `True` (default CA bundle),\n-    a path to an SSL certificate file, an `ssl.SSLContext`, or `False`\n-    (which will disable verification).\n-    * **cert** - *(optional)* An SSL certificate used by the requested host\n-    to authenticate the client. Either a path to an SSL certificate file, or\n-    two-tuple of (certificate file, key file), or a three-tuple of (certificate\n-    file, key file, password).",
      "comment": "Perhaps it's better to keep these with `*(deprecated)*` tag?",
      "comment_id": 1819083352,
      "user": "T-256",
      "created_at": "2024-10-28T13:43:33Z",
      "url": "https://github.com/encode/httpx/pull/3370#discussion_r1819083352"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3370,
      "file_path": "httpx/_transports/default.py",
      "line": 146,
      "side": "RIGHT",
      "diff_hunk": "@@ -124,20 +125,25 @@ def close(self) -> None:\n class HTTPTransport(BaseTransport):\n     def __init__(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        ssl_context: ssl.SSLContext | None = None,\n         http1: bool = True,\n         http2: bool = False,\n         limits: Limits = DEFAULT_LIMITS,\n-        trust_env: bool = True,\n         proxy: ProxyTypes | None = None,\n         uds: str | None = None,\n         local_address: str | None = None,\n         retries: int = 0,\n         socket_options: typing.Iterable[SOCKET_OPTION] | None = None,\n+        # Deprecated...\n+        verify: typing.Any = None,\n+        cert: typing.Any = None,\n     ) -> None:\n-        ssl_context = create_ssl_context(verify=verify, cert=cert, trust_env=trust_env)\n         proxy = Proxy(url=proxy) if isinstance(proxy, (str, URL)) else proxy\n+        if verify is not None or cert is not None:  # pragma: nocover\n+            # Deprecated...\n+            ssl_context = create_ssl_context(verify, cert)\n+        else:\n+            ssl_context = ssl_context or SSLContext()",
      "comment": "perhaps, raising error when used together?\r\n```python\r\nhttpx.get(\"https://example.com/\", verify=False, ssl_context=httpx..SSLContext())\r\n```",
      "comment_id": 1819097875,
      "user": "T-256",
      "created_at": "2024-10-28T13:52:11Z",
      "url": "https://github.com/encode/httpx/pull/3370#discussion_r1819097875"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3370,
      "file_path": "httpx/_transports/default.py",
      "line": 146,
      "side": "RIGHT",
      "diff_hunk": "@@ -124,20 +125,25 @@ def close(self) -> None:\n class HTTPTransport(BaseTransport):\n     def __init__(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        ssl_context: ssl.SSLContext | None = None,\n         http1: bool = True,\n         http2: bool = False,\n         limits: Limits = DEFAULT_LIMITS,\n-        trust_env: bool = True,\n         proxy: ProxyTypes | None = None,\n         uds: str | None = None,\n         local_address: str | None = None,\n         retries: int = 0,\n         socket_options: typing.Iterable[SOCKET_OPTION] | None = None,\n+        # Deprecated...\n+        verify: typing.Any = None,\n+        cert: typing.Any = None,\n     ) -> None:\n-        ssl_context = create_ssl_context(verify=verify, cert=cert, trust_env=trust_env)\n         proxy = Proxy(url=proxy) if isinstance(proxy, (str, URL)) else proxy\n+        if verify is not None or cert is not None:  # pragma: nocover\n+            # Deprecated...\n+            ssl_context = create_ssl_context(verify, cert)\n+        else:\n+            ssl_context = ssl_context or SSLContext()",
      "comment": "Okay yep... I'm going to retitle our `version-1.0` branch and will resolve there.",
      "comment_id": 1819146801,
      "user": "lovelydinosaur",
      "created_at": "2024-10-28T14:13:07Z",
      "url": "https://github.com/encode/httpx/pull/3370#discussion_r1819146801"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 51,
      "side": "RIGHT",
      "diff_hunk": "@@ -42,150 +40,102 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: typing.Optional[CertTypes] = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):\n     DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n \n-    def __init__(\n-        self,\n-        *,\n-        cert: typing.Optional[CertTypes] = None,\n+    def __new__(\n+        cls,\n+        protocol: ssl._SSLMethod = ssl.PROTOCOL_TLS_CLIENT,\n         verify: VerifyTypes = True,\n-        trust_env: bool = True,\n-        http2: bool = False,\n-    ) -> None:\n-        self.cert = cert\n-        self.verify = verify\n-        self.trust_env = trust_env\n-        self.http2 = http2\n-        self.ssl_context = self.load_ssl_context()\n+        cert: typing.Optional[CertTypes] = None,\n+    ) -> \"SSLContext\":",
      "comment": "I'm curious why we're overriding `__new__` instead of `__init__` here?",
      "comment_id": 1437601093,
      "user": "lovelydinosaur",
      "created_at": "2023-12-28T12:16:24Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1437601093"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 95,
      "side": "RIGHT",
      "diff_hunk": "@@ -42,150 +40,102 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: typing.Optional[CertTypes] = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):\n     DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n \n-    def __init__(\n-        self,\n-        *,\n-        cert: typing.Optional[CertTypes] = None,\n+    def __new__(\n+        cls,\n+        protocol: ssl._SSLMethod = ssl.PROTOCOL_TLS_CLIENT,\n         verify: VerifyTypes = True,\n-        trust_env: bool = True,\n-        http2: bool = False,\n-    ) -> None:\n-        self.cert = cert\n-        self.verify = verify\n-        self.trust_env = trust_env\n-        self.http2 = http2\n-        self.ssl_context = self.load_ssl_context()\n+        cert: typing.Optional[CertTypes] = None,\n+    ) -> \"SSLContext\":\n+        self = super().__new__(cls, protocol)\n+\n+        set_minimum_tls_version_1_2(self)\n+        self.options |= ssl.OP_NO_COMPRESSION\n+        self.set_ciphers(DEFAULT_CIPHERS)\n \n-    def load_ssl_context(self) -> ssl.SSLContext:\n         logger.debug(\n-            \"load_ssl_context verify=%r cert=%r trust_env=%r http2=%r\",\n-            self.verify,\n-            self.cert,\n-            self.trust_env,\n-            self.http2,\n+            \"load_ssl_context verify=%r cert=%r\",\n+            verify,\n+            cert,\n         )\n \n-        if self.verify:\n-            return self.load_ssl_context_verify()\n-        return self.load_ssl_context_no_verify()\n+        if verify:\n+            self.load_ssl_context_verify(cert, verify)\n+        else:\n+            self.load_ssl_context_no_verify(cert)\n+        return self\n \n-    def load_ssl_context_no_verify(self) -> ssl.SSLContext:\n+    def load_ssl_context_no_verify(\n+        self, cert: typing.Optional[CertTypes]\n+    ) -> ssl.SSLContext:\n         \"\"\"\n         Return an SSL context for unverified connections.\n         \"\"\"\n-        context = self._create_default_ssl_context()\n-        context.check_hostname = False\n-        context.verify_mode = ssl.CERT_NONE\n-        self._load_client_certs(context)\n-        return context\n+        self.check_hostname = False\n+        self.verify_mode = ssl.CERT_NONE\n+        self._load_client_certs(cert)\n+        return self\n \n-    def load_ssl_context_verify(self) -> ssl.SSLContext:\n+    def load_ssl_context_verify(\n+        self, cert: typing.Optional[CertTypes], verify: VerifyTypes\n+    ) -> None:\n         \"\"\"\n         Return an SSL context for verified connections.\n         \"\"\"\n-        if self.trust_env and self.verify is True:\n-            ca_bundle = get_ca_bundle_from_env()\n-            if ca_bundle is not None:\n-                self.verify = ca_bundle\n-\n-        if isinstance(self.verify, ssl.SSLContext):\n-            # Allow passing in our own SSLContext object that's pre-configured.\n-            context = self.verify\n-            self._load_client_certs(context)\n-            return context\n-        elif isinstance(self.verify, bool):\n+        if isinstance(verify, bool):\n             ca_bundle_path = self.DEFAULT_CA_BUNDLE_PATH\n-        elif Path(self.verify).exists():\n-            ca_bundle_path = Path(self.verify)\n+        elif Path(verify).exists():\n+            ca_bundle_path = Path(verify)\n         else:\n             raise IOError(\n                 \"Could not find a suitable TLS CA certificate bundle, \"\n-                \"invalid path: {}\".format(self.verify)\n+                \"invalid path: {}\".format(verify)\n             )",
      "comment": "We confuse the flow here by having this section of code separated from where `ca_bundle_path` is actually used. It'd be more clear if we pushed this block down to just before `if ca_bundle_path.is_file():`. ",
      "comment_id": 1437606317,
      "user": "lovelydinosaur",
      "created_at": "2023-12-28T12:25:23Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1437606317"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 95,
      "side": "RIGHT",
      "diff_hunk": "@@ -42,150 +40,102 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: typing.Optional[CertTypes] = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):\n     DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n \n-    def __init__(\n-        self,\n-        *,\n-        cert: typing.Optional[CertTypes] = None,\n+    def __new__(\n+        cls,\n+        protocol: ssl._SSLMethod = ssl.PROTOCOL_TLS_CLIENT,\n         verify: VerifyTypes = True,\n-        trust_env: bool = True,\n-        http2: bool = False,\n-    ) -> None:\n-        self.cert = cert\n-        self.verify = verify\n-        self.trust_env = trust_env\n-        self.http2 = http2\n-        self.ssl_context = self.load_ssl_context()\n+        cert: typing.Optional[CertTypes] = None,\n+    ) -> \"SSLContext\":\n+        self = super().__new__(cls, protocol)\n+\n+        set_minimum_tls_version_1_2(self)\n+        self.options |= ssl.OP_NO_COMPRESSION\n+        self.set_ciphers(DEFAULT_CIPHERS)\n \n-    def load_ssl_context(self) -> ssl.SSLContext:\n         logger.debug(\n-            \"load_ssl_context verify=%r cert=%r trust_env=%r http2=%r\",\n-            self.verify,\n-            self.cert,\n-            self.trust_env,\n-            self.http2,\n+            \"load_ssl_context verify=%r cert=%r\",\n+            verify,\n+            cert,\n         )\n \n-        if self.verify:\n-            return self.load_ssl_context_verify()\n-        return self.load_ssl_context_no_verify()\n+        if verify:\n+            self.load_ssl_context_verify(cert, verify)\n+        else:\n+            self.load_ssl_context_no_verify(cert)\n+        return self\n \n-    def load_ssl_context_no_verify(self) -> ssl.SSLContext:\n+    def load_ssl_context_no_verify(\n+        self, cert: typing.Optional[CertTypes]\n+    ) -> ssl.SSLContext:\n         \"\"\"\n         Return an SSL context for unverified connections.\n         \"\"\"\n-        context = self._create_default_ssl_context()\n-        context.check_hostname = False\n-        context.verify_mode = ssl.CERT_NONE\n-        self._load_client_certs(context)\n-        return context\n+        self.check_hostname = False\n+        self.verify_mode = ssl.CERT_NONE\n+        self._load_client_certs(cert)\n+        return self\n \n-    def load_ssl_context_verify(self) -> ssl.SSLContext:\n+    def load_ssl_context_verify(\n+        self, cert: typing.Optional[CertTypes], verify: VerifyTypes\n+    ) -> None:\n         \"\"\"\n         Return an SSL context for verified connections.\n         \"\"\"\n-        if self.trust_env and self.verify is True:\n-            ca_bundle = get_ca_bundle_from_env()\n-            if ca_bundle is not None:\n-                self.verify = ca_bundle\n-\n-        if isinstance(self.verify, ssl.SSLContext):\n-            # Allow passing in our own SSLContext object that's pre-configured.\n-            context = self.verify\n-            self._load_client_certs(context)\n-            return context\n-        elif isinstance(self.verify, bool):\n+        if isinstance(verify, bool):\n             ca_bundle_path = self.DEFAULT_CA_BUNDLE_PATH\n-        elif Path(self.verify).exists():\n-            ca_bundle_path = Path(self.verify)\n+        elif Path(verify).exists():\n+            ca_bundle_path = Path(verify)\n         else:\n             raise IOError(\n                 \"Could not find a suitable TLS CA certificate bundle, \"\n-                \"invalid path: {}\".format(self.verify)\n+                \"invalid path: {}\".format(verify)\n             )",
      "comment": "(Tho perhaps we address clean-ups separately to the main API behavioral changes here?)",
      "comment_id": 1437607038,
      "user": "lovelydinosaur",
      "created_at": "2023-12-28T12:26:46Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1437607038"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 51,
      "side": "RIGHT",
      "diff_hunk": "@@ -42,150 +40,102 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: typing.Optional[CertTypes] = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):\n     DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n \n-    def __init__(\n-        self,\n-        *,\n-        cert: typing.Optional[CertTypes] = None,\n+    def __new__(\n+        cls,\n+        protocol: ssl._SSLMethod = ssl.PROTOCOL_TLS_CLIENT,\n         verify: VerifyTypes = True,\n-        trust_env: bool = True,\n-        http2: bool = False,\n-    ) -> None:\n-        self.cert = cert\n-        self.verify = verify\n-        self.trust_env = trust_env\n-        self.http2 = http2\n-        self.ssl_context = self.load_ssl_context()\n+        cert: typing.Optional[CertTypes] = None,\n+    ) -> \"SSLContext\":",
      "comment": "Yes, it should definitely be in __init__. I believe I encountered some issues and have temporarily moved it to __new__ to see how it looks in general.",
      "comment_id": 1437608213,
      "user": "karpetrosyan",
      "created_at": "2023-12-28T12:28:59Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1437608213"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 95,
      "side": "RIGHT",
      "diff_hunk": "@@ -42,150 +40,102 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: typing.Optional[CertTypes] = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):\n     DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n \n-    def __init__(\n-        self,\n-        *,\n-        cert: typing.Optional[CertTypes] = None,\n+    def __new__(\n+        cls,\n+        protocol: ssl._SSLMethod = ssl.PROTOCOL_TLS_CLIENT,\n         verify: VerifyTypes = True,\n-        trust_env: bool = True,\n-        http2: bool = False,\n-    ) -> None:\n-        self.cert = cert\n-        self.verify = verify\n-        self.trust_env = trust_env\n-        self.http2 = http2\n-        self.ssl_context = self.load_ssl_context()\n+        cert: typing.Optional[CertTypes] = None,\n+    ) -> \"SSLContext\":\n+        self = super().__new__(cls, protocol)\n+\n+        set_minimum_tls_version_1_2(self)\n+        self.options |= ssl.OP_NO_COMPRESSION\n+        self.set_ciphers(DEFAULT_CIPHERS)\n \n-    def load_ssl_context(self) -> ssl.SSLContext:\n         logger.debug(\n-            \"load_ssl_context verify=%r cert=%r trust_env=%r http2=%r\",\n-            self.verify,\n-            self.cert,\n-            self.trust_env,\n-            self.http2,\n+            \"load_ssl_context verify=%r cert=%r\",\n+            verify,\n+            cert,\n         )\n \n-        if self.verify:\n-            return self.load_ssl_context_verify()\n-        return self.load_ssl_context_no_verify()\n+        if verify:\n+            self.load_ssl_context_verify(cert, verify)\n+        else:\n+            self.load_ssl_context_no_verify(cert)\n+        return self\n \n-    def load_ssl_context_no_verify(self) -> ssl.SSLContext:\n+    def load_ssl_context_no_verify(\n+        self, cert: typing.Optional[CertTypes]\n+    ) -> ssl.SSLContext:\n         \"\"\"\n         Return an SSL context for unverified connections.\n         \"\"\"\n-        context = self._create_default_ssl_context()\n-        context.check_hostname = False\n-        context.verify_mode = ssl.CERT_NONE\n-        self._load_client_certs(context)\n-        return context\n+        self.check_hostname = False\n+        self.verify_mode = ssl.CERT_NONE\n+        self._load_client_certs(cert)\n+        return self\n \n-    def load_ssl_context_verify(self) -> ssl.SSLContext:\n+    def load_ssl_context_verify(\n+        self, cert: typing.Optional[CertTypes], verify: VerifyTypes\n+    ) -> None:\n         \"\"\"\n         Return an SSL context for verified connections.\n         \"\"\"\n-        if self.trust_env and self.verify is True:\n-            ca_bundle = get_ca_bundle_from_env()\n-            if ca_bundle is not None:\n-                self.verify = ca_bundle\n-\n-        if isinstance(self.verify, ssl.SSLContext):\n-            # Allow passing in our own SSLContext object that's pre-configured.\n-            context = self.verify\n-            self._load_client_certs(context)\n-            return context\n-        elif isinstance(self.verify, bool):\n+        if isinstance(verify, bool):\n             ca_bundle_path = self.DEFAULT_CA_BUNDLE_PATH\n-        elif Path(self.verify).exists():\n-            ca_bundle_path = Path(self.verify)\n+        elif Path(verify).exists():\n+            ca_bundle_path = Path(verify)\n         else:\n             raise IOError(\n                 \"Could not find a suitable TLS CA certificate bundle, \"\n-                \"invalid path: {}\".format(self.verify)\n+                \"invalid path: {}\".format(verify)\n             )",
      "comment": "Separating them will make it easier to review this PR, which contains an important API change.\r\n",
      "comment_id": 1437611108,
      "user": "karpetrosyan",
      "created_at": "2023-12-28T12:34:38Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1437611108"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 95,
      "side": "RIGHT",
      "diff_hunk": "@@ -42,150 +40,102 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: typing.Optional[CertTypes] = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):\n     DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n \n-    def __init__(\n-        self,\n-        *,\n-        cert: typing.Optional[CertTypes] = None,\n+    def __new__(\n+        cls,\n+        protocol: ssl._SSLMethod = ssl.PROTOCOL_TLS_CLIENT,\n         verify: VerifyTypes = True,\n-        trust_env: bool = True,\n-        http2: bool = False,\n-    ) -> None:\n-        self.cert = cert\n-        self.verify = verify\n-        self.trust_env = trust_env\n-        self.http2 = http2\n-        self.ssl_context = self.load_ssl_context()\n+        cert: typing.Optional[CertTypes] = None,\n+    ) -> \"SSLContext\":\n+        self = super().__new__(cls, protocol)\n+\n+        set_minimum_tls_version_1_2(self)\n+        self.options |= ssl.OP_NO_COMPRESSION\n+        self.set_ciphers(DEFAULT_CIPHERS)\n \n-    def load_ssl_context(self) -> ssl.SSLContext:\n         logger.debug(\n-            \"load_ssl_context verify=%r cert=%r trust_env=%r http2=%r\",\n-            self.verify,\n-            self.cert,\n-            self.trust_env,\n-            self.http2,\n+            \"load_ssl_context verify=%r cert=%r\",\n+            verify,\n+            cert,\n         )\n \n-        if self.verify:\n-            return self.load_ssl_context_verify()\n-        return self.load_ssl_context_no_verify()\n+        if verify:\n+            self.load_ssl_context_verify(cert, verify)\n+        else:\n+            self.load_ssl_context_no_verify(cert)\n+        return self\n \n-    def load_ssl_context_no_verify(self) -> ssl.SSLContext:\n+    def load_ssl_context_no_verify(\n+        self, cert: typing.Optional[CertTypes]\n+    ) -> ssl.SSLContext:\n         \"\"\"\n         Return an SSL context for unverified connections.\n         \"\"\"\n-        context = self._create_default_ssl_context()\n-        context.check_hostname = False\n-        context.verify_mode = ssl.CERT_NONE\n-        self._load_client_certs(context)\n-        return context\n+        self.check_hostname = False\n+        self.verify_mode = ssl.CERT_NONE\n+        self._load_client_certs(cert)\n+        return self\n \n-    def load_ssl_context_verify(self) -> ssl.SSLContext:\n+    def load_ssl_context_verify(\n+        self, cert: typing.Optional[CertTypes], verify: VerifyTypes\n+    ) -> None:\n         \"\"\"\n         Return an SSL context for verified connections.\n         \"\"\"\n-        if self.trust_env and self.verify is True:\n-            ca_bundle = get_ca_bundle_from_env()\n-            if ca_bundle is not None:\n-                self.verify = ca_bundle\n-\n-        if isinstance(self.verify, ssl.SSLContext):\n-            # Allow passing in our own SSLContext object that's pre-configured.\n-            context = self.verify\n-            self._load_client_certs(context)\n-            return context\n-        elif isinstance(self.verify, bool):\n+        if isinstance(verify, bool):\n             ca_bundle_path = self.DEFAULT_CA_BUNDLE_PATH\n-        elif Path(self.verify).exists():\n-            ca_bundle_path = Path(self.verify)\n+        elif Path(verify).exists():\n+            ca_bundle_path = Path(verify)\n         else:\n             raise IOError(\n                 \"Could not find a suitable TLS CA certificate bundle, \"\n-                \"invalid path: {}\".format(self.verify)\n+                \"invalid path: {}\".format(verify)\n             )",
      "comment": "Another important question is whether we need to deprecate previous arguments or simply delete them.",
      "comment_id": 1437621343,
      "user": "karpetrosyan",
      "created_at": "2023-12-28T12:54:22Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1437621343"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 95,
      "side": "RIGHT",
      "diff_hunk": "@@ -42,150 +40,102 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: typing.Optional[CertTypes] = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):\n     DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n \n-    def __init__(\n-        self,\n-        *,\n-        cert: typing.Optional[CertTypes] = None,\n+    def __new__(\n+        cls,\n+        protocol: ssl._SSLMethod = ssl.PROTOCOL_TLS_CLIENT,\n         verify: VerifyTypes = True,\n-        trust_env: bool = True,\n-        http2: bool = False,\n-    ) -> None:\n-        self.cert = cert\n-        self.verify = verify\n-        self.trust_env = trust_env\n-        self.http2 = http2\n-        self.ssl_context = self.load_ssl_context()\n+        cert: typing.Optional[CertTypes] = None,\n+    ) -> \"SSLContext\":\n+        self = super().__new__(cls, protocol)\n+\n+        set_minimum_tls_version_1_2(self)\n+        self.options |= ssl.OP_NO_COMPRESSION\n+        self.set_ciphers(DEFAULT_CIPHERS)\n \n-    def load_ssl_context(self) -> ssl.SSLContext:\n         logger.debug(\n-            \"load_ssl_context verify=%r cert=%r trust_env=%r http2=%r\",\n-            self.verify,\n-            self.cert,\n-            self.trust_env,\n-            self.http2,\n+            \"load_ssl_context verify=%r cert=%r\",\n+            verify,\n+            cert,\n         )\n \n-        if self.verify:\n-            return self.load_ssl_context_verify()\n-        return self.load_ssl_context_no_verify()\n+        if verify:\n+            self.load_ssl_context_verify(cert, verify)\n+        else:\n+            self.load_ssl_context_no_verify(cert)\n+        return self\n \n-    def load_ssl_context_no_verify(self) -> ssl.SSLContext:\n+    def load_ssl_context_no_verify(\n+        self, cert: typing.Optional[CertTypes]\n+    ) -> ssl.SSLContext:\n         \"\"\"\n         Return an SSL context for unverified connections.\n         \"\"\"\n-        context = self._create_default_ssl_context()\n-        context.check_hostname = False\n-        context.verify_mode = ssl.CERT_NONE\n-        self._load_client_certs(context)\n-        return context\n+        self.check_hostname = False\n+        self.verify_mode = ssl.CERT_NONE\n+        self._load_client_certs(cert)\n+        return self\n \n-    def load_ssl_context_verify(self) -> ssl.SSLContext:\n+    def load_ssl_context_verify(\n+        self, cert: typing.Optional[CertTypes], verify: VerifyTypes\n+    ) -> None:\n         \"\"\"\n         Return an SSL context for verified connections.\n         \"\"\"\n-        if self.trust_env and self.verify is True:\n-            ca_bundle = get_ca_bundle_from_env()\n-            if ca_bundle is not None:\n-                self.verify = ca_bundle\n-\n-        if isinstance(self.verify, ssl.SSLContext):\n-            # Allow passing in our own SSLContext object that's pre-configured.\n-            context = self.verify\n-            self._load_client_certs(context)\n-            return context\n-        elif isinstance(self.verify, bool):\n+        if isinstance(verify, bool):\n             ca_bundle_path = self.DEFAULT_CA_BUNDLE_PATH\n-        elif Path(self.verify).exists():\n-            ca_bundle_path = Path(self.verify)\n+        elif Path(verify).exists():\n+            ca_bundle_path = Path(verify)\n         else:\n             raise IOError(\n                 \"Could not find a suitable TLS CA certificate bundle, \"\n-                \"invalid path: {}\".format(self.verify)\n+                \"invalid path: {}\".format(verify)\n             )",
      "comment": "> (Tho perhaps we address clean-ups separately to the main API behavioral changes here?)\r\n\r\nAgree with tom, you could add `ssl_context=` and `httpx.SSLContext` in current PR and decide to deprecate/remove in separated PR.",
      "comment_id": 1437656569,
      "user": "T-256",
      "created_at": "2023-12-28T13:10:24Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1437656569"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 143,
      "side": "RIGHT",
      "diff_hunk": "@@ -138,6 +134,14 @@ def _load_client_certs(self, cert: typing.Optional[CertTypes] = None) -> None:\n                     password=cert[2],  # type: ignore\n                 )\n \n+    def __new__(\n+        cls,\n+        protocol: ssl._SSLMethod = ssl.PROTOCOL_TLS_CLIENT,\n+        *args: typing.Any,\n+        **kwargs: typing.Any,\n+    ) -> \"SSLContext\":\n+        return super().__new__(cls, protocol, *args, **kwargs)",
      "comment": "We need this to avoid \"DeprecationWarning: ssl.SSLContext() without protocol argument is deprecated.\"",
      "comment_id": 1438067431,
      "user": "karpetrosyan",
      "created_at": "2023-12-29T07:24:28Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1438067431"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 69,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,151 +44,113 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):\n     DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n \n     def __init__(\n         self,\n-        *,\n-        cert: CertTypes | None = None,\n         verify: VerifyTypes = True,\n-        trust_env: bool = True,\n-        http2: bool = False,\n+        cert: CertTypes | None = None,\n     ) -> None:\n-        self.cert = cert\n         self.verify = verify\n-        self.trust_env = trust_env\n-        self.http2 = http2\n-        self.ssl_context = self.load_ssl_context()\n+        set_minimum_tls_version_1_2(self)\n+        self.options |= ssl.OP_NO_COMPRESSION\n+        self.set_ciphers(DEFAULT_CIPHERS)\n \n-    def load_ssl_context(self) -> ssl.SSLContext:\n         logger.debug(\n-            \"load_ssl_context verify=%r cert=%r trust_env=%r http2=%r\",\n-            self.verify,\n-            self.cert,\n-            self.trust_env,\n-            self.http2,\n+            \"load_ssl_context verify=%r cert=%r\",\n+            verify,\n+            cert,\n         )\n \n-        if self.verify:\n-            return self.load_ssl_context_verify()\n-        return self.load_ssl_context_no_verify()\n+        if verify:\n+            self.load_ssl_context_verify(cert, verify)\n+        else:\n+            self.load_ssl_context_no_verify(cert)",
      "comment": "since `verify` attribute is set to instance, I think we could mix these in one method:\r\n```py\r\ndef load_ssl_context(self, cert: typing.Optional[CertTypes]) -> None:\r\n    if not self.verify:\r\n        self.check_hostname = False\r\n        self.verify_mode = ssl.CERT_NONE\r\n        self._load_client_certs(cert)\r\n        return\r\n    if isinstance(self.verify, bool):\r\n        ca_bundle_path = self.DEFAULT_CA_BUNDLE_PATH\r\n    ...\r\n    ...\r\n\r\n```",
      "comment_id": 1771142229,
      "user": "T-256",
      "created_at": "2024-09-23T10:24:55Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1771142229"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 47,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,151 +44,113 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):",
      "comment": "If possible I'd like this not to subclass ssl.SSLContext, so we can use pyopenssl with http3",
      "comment_id": 1771217918,
      "user": "graingert",
      "created_at": "2024-09-23T11:16:07Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1771217918"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 47,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,151 +44,113 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):",
      "comment": "Ah, so...\r\n\r\nThe *type* required by the client methods should be `ssl.SSLContext`.\r\nFor example in correctly typecheck against this documented usage...\r\n\r\nhttps://github.com/encode/httpx/blob/998f445c83efb140b7e9ae05c993e8f36663cba2/docs/advanced/ssl.md?plain=1#L148-L149\r\n\r\nI think it's okay for us to have an `httpx.SSLContext()` subclass.",
      "comment_id": 1771332015,
      "user": "lovelydinosaur",
      "created_at": "2024-09-23T12:43:02Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1771332015"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 47,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,151 +44,113 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):",
      "comment": "I'd like to change the type required by the Client methods to a custom httpcore class that can wrap either an ssl.SSLContext or a pyopenssl SSLContext ",
      "comment_id": 1771393713,
      "user": "graingert",
      "created_at": "2024-09-23T13:12:01Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1771393713"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 47,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,151 +44,113 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):",
      "comment": "@graingert Interesting...\r\n\r\nCan we progress that separately by opening a design discussion in `httpcore` for adding `pyopenssl` support?\r\nI'd like to understand that individual part better without risking this PR getting sidetracked.",
      "comment_id": 1771466178,
      "user": "lovelydinosaur",
      "created_at": "2024-09-23T13:40:01Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1771466178"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 50,
      "side": "RIGHT",
      "diff_hunk": "@@ -49,8 +47,7 @@ def request(\n     proxy: ProxyTypes | None = None,\n     timeout: TimeoutTypes = DEFAULT_TIMEOUT_CONFIG,\n     follow_redirects: bool = False,\n-    verify: VerifyTypes = True,\n-    cert: CertTypes | None = None,\n+    ssl_context: typing.Optional[SSLContext] = None,",
      "comment": "We should be using `typing.Optional[ssl.SSLContext]` here. (Yes it's a bit subtle)",
      "comment_id": 1777467423,
      "user": "lovelydinosaur",
      "created_at": "2024-09-26T17:11:39Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1777467423"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "tests/test_config.py",
      "line": 26,
      "side": "RIGHT",
      "diff_hunk": "@@ -9,48 +9,46 @@\n \n \n def test_load_ssl_config():\n-    context = httpx.create_ssl_context()\n+    context = httpx.SSLContext()\n     assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n     assert context.check_hostname is True\n \n \n def test_load_ssl_config_verify_non_existing_path():\n     with pytest.raises(IOError):\n-        httpx.create_ssl_context(verify=\"/path/to/nowhere\")\n+        httpx.SSLContext(verify=\"/path/to/nowhere\")\n \n \n-def test_load_ssl_config_verify_existing_file():\n-    context = httpx.create_ssl_context(verify=certifi.where())\n-    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n-    assert context.check_hostname is True\n-\n+@pytest.mark.parametrize(\n+    \"trust_env, expected_keylog_filename\",\n+    [\n+        pytest.param(True, \"test\", id=\"With trasting env\"),\n+        pytest.param(False, None, id=\"Without trasting env\"),",
      "comment": "```suggestion\r\n        pytest.param(True, \"test\", id=\"With trusting env\"),\r\n        pytest.param(False, None, id=\"Without trusting env\"),\r\n```\r\n\r\n\ud83d\ude0e",
      "comment_id": 1787439662,
      "user": "lovelydinosaur",
      "created_at": "2024-10-04T09:29:07Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1787439662"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 51,
      "side": "RIGHT",
      "diff_hunk": "@@ -49,8 +48,7 @@ def request(\n     proxy: ProxyTypes | None = None,\n     timeout: TimeoutTypes = DEFAULT_TIMEOUT_CONFIG,\n     follow_redirects: bool = False,\n-    verify: VerifyTypes = True,\n-    cert: CertTypes | None = None,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "Do we need DEFAULT_SSL_CONTEXT instead of None?\r\nI can remember there are memory leak issues for high count instantiate of Client. Personally, I fixed this by using global ssl context varible used for all httpx.Client instances.\r\nref: https://github.com/encode/httpx/discussions/2785#discussioncomment-6539886",
      "comment_id": 1787817691,
      "user": "T-256",
      "created_at": "2024-10-04T14:34:58Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1787817691"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 51,
      "side": "RIGHT",
      "diff_hunk": "@@ -49,8 +48,7 @@ def request(\n     proxy: ProxyTypes | None = None,\n     timeout: TimeoutTypes = DEFAULT_TIMEOUT_CONFIG,\n     follow_redirects: bool = False,\n-    verify: VerifyTypes = True,\n-    cert: CertTypes | None = None,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "Let's add things incrementally, maybe it should be resolved in another PR?",
      "comment_id": 1787935057,
      "user": "karpetrosyan",
      "created_at": "2024-10-04T16:08:40Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1787935057"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 51,
      "side": "RIGHT",
      "diff_hunk": "@@ -49,8 +48,7 @@ def request(\n     proxy: ProxyTypes | None = None,\n     timeout: TimeoutTypes = DEFAULT_TIMEOUT_CONFIG,\n     follow_redirects: bool = False,\n-    verify: VerifyTypes = True,\n-    cert: CertTypes | None = None,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "(btw it's not blocking concern, we can do it by follow-up PR.)",
      "comment_id": 1787941707,
      "user": "T-256",
      "created_at": "2024-10-04T16:14:52Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1787941707"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 51,
      "side": "RIGHT",
      "diff_hunk": "@@ -49,8 +48,7 @@ def request(\n     proxy: ProxyTypes | None = None,\n     timeout: TimeoutTypes = DEFAULT_TIMEOUT_CONFIG,\n     follow_redirects: bool = False,\n-    verify: VerifyTypes = True,\n-    cert: CertTypes | None = None,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "Yes, please. I don't even remember a lot of things from this PR \ud83d\ude04\r\nOne year old PR is a bad practice... always!",
      "comment_id": 1787951248,
      "user": "karpetrosyan",
      "created_at": "2024-10-04T16:23:50Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1787951248"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 51,
      "side": "RIGHT",
      "diff_hunk": "@@ -49,8 +48,7 @@ def request(\n     proxy: ProxyTypes | None = None,\n     timeout: TimeoutTypes = DEFAULT_TIMEOUT_CONFIG,\n     follow_redirects: bool = False,\n-    verify: VerifyTypes = True,\n-    cert: CertTypes | None = None,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "We should use `None` here.\r\nWe should use with instantiating a singleton default when `None` is passed to the transport.\r\nTho we can deal with that as a follow-up.",
      "comment_id": 1787956942,
      "user": "lovelydinosaur",
      "created_at": "2024-10-04T16:29:05Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1787956942"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_client.py",
      "line": 691,
      "side": "RIGHT",
      "diff_hunk": "@@ -695,20 +683,18 @@ def __init__(\n \n     def _init_transport(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        ssl_context: typing.Optional[ssl.SSLContext],\n         http1: bool = True,\n         http2: bool = False,\n         limits: Limits = DEFAULT_LIMITS,\n-        transport: BaseTransport | None = None,\n         trust_env: bool = True,\n+        transport: typing.Optional[BaseTransport] = None,",
      "comment": "why this change? lets keep it consistent with others.",
      "comment_id": 1789284375,
      "user": "T-256",
      "created_at": "2024-10-06T22:47:39Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1789284375"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 70,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,151 +45,103 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):\n     DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n \n     def __init__(\n         self,\n-        *,\n-        cert: CertTypes | None = None,\n         verify: VerifyTypes = True,\n+        cert: CertTypes | None = None,\n         trust_env: bool = True,\n-        http2: bool = False,\n     ) -> None:\n-        self.cert = cert\n         self.verify = verify\n+        set_minimum_tls_version_1_2(self)\n+        self.options |= ssl.OP_NO_COMPRESSION\n+        self.set_ciphers(DEFAULT_CIPHERS)\n         self.trust_env = trust_env\n-        self.http2 = http2\n-        self.ssl_context = self.load_ssl_context()\n \n-    def load_ssl_context(self) -> ssl.SSLContext:\n+        keylogfile = os.environ.get(\"SSLKEYLOGFILE\")\n+        if keylogfile and self.trust_env:\n+            self.keylog_filename = keylogfile\n+\n         logger.debug(\n-            \"load_ssl_context verify=%r cert=%r trust_env=%r http2=%r\",\n-            self.verify,\n-            self.cert,\n-            self.trust_env,\n-            self.http2,\n+            \"load_ssl_context verify=%r cert=%r\",\n+            verify,\n+            cert,",
      "comment": "```suggestion\r\n            \"load_ssl_context verify=%r cert=%r trust_env=%r\",\r\n            verify,\r\n            cert,\r\n            trust_env,\r\n```",
      "comment_id": 1789288418,
      "user": "T-256",
      "created_at": "2024-10-06T23:00:08Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1789288418"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 57,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,151 +45,103 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):\n     DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n \n     def __init__(\n         self,\n-        *,\n-        cert: CertTypes | None = None,\n         verify: VerifyTypes = True,\n+        cert: CertTypes | None = None,\n         trust_env: bool = True,\n-        http2: bool = False,\n     ) -> None:\n-        self.cert = cert\n         self.verify = verify",
      "comment": "Since httpx.SSLContext is now subclass of ssl.SSLContext, let's make these fields private.",
      "comment_id": 1789289649,
      "user": "T-256",
      "created_at": "2024-10-06T23:04:29Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1789289649"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 136,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,151 +45,103 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):\n     DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n \n     def __init__(\n         self,\n-        *,\n-        cert: CertTypes | None = None,\n         verify: VerifyTypes = True,\n+        cert: CertTypes | None = None,\n         trust_env: bool = True,\n-        http2: bool = False,\n     ) -> None:\n-        self.cert = cert\n         self.verify = verify\n+        set_minimum_tls_version_1_2(self)\n+        self.options |= ssl.OP_NO_COMPRESSION\n+        self.set_ciphers(DEFAULT_CIPHERS)\n         self.trust_env = trust_env\n-        self.http2 = http2\n-        self.ssl_context = self.load_ssl_context()\n \n-    def load_ssl_context(self) -> ssl.SSLContext:\n+        keylogfile = os.environ.get(\"SSLKEYLOGFILE\")\n+        if keylogfile and self.trust_env:\n+            self.keylog_filename = keylogfile\n+\n         logger.debug(\n-            \"load_ssl_context verify=%r cert=%r trust_env=%r http2=%r\",\n-            self.verify,\n-            self.cert,\n-            self.trust_env,\n-            self.http2,\n+            \"load_ssl_context verify=%r cert=%r\",\n+            verify,\n+            cert,\n         )\n \n-        if self.verify:\n-            return self.load_ssl_context_verify()\n-        return self.load_ssl_context_no_verify()\n-\n-    def load_ssl_context_no_verify(self) -> ssl.SSLContext:\n-        \"\"\"\n-        Return an SSL context for unverified connections.\n-        \"\"\"\n-        context = self._create_default_ssl_context()\n-        context.check_hostname = False\n-        context.verify_mode = ssl.CERT_NONE\n-        self._load_client_certs(context)\n-        return context\n+        if not verify:\n+            self.check_hostname = False\n+            self.verify_mode = ssl.CERT_NONE\n+            self._load_client_certs(cert)\n+            return\n \n-    def load_ssl_context_verify(self) -> ssl.SSLContext:\n-        \"\"\"\n-        Return an SSL context for verified connections.\n-        \"\"\"\n-        if self.trust_env and self.verify is True:\n-            ca_bundle = get_ca_bundle_from_env()\n-            if ca_bundle is not None:\n-                self.verify = ca_bundle\n-\n-        if isinstance(self.verify, ssl.SSLContext):\n-            # Allow passing in our own SSLContext object that's pre-configured.\n-            context = self.verify\n-            self._load_client_certs(context)\n-            return context\n-        elif isinstance(self.verify, bool):\n+        if isinstance(verify, bool):\n             ca_bundle_path = self.DEFAULT_CA_BUNDLE_PATH\n-        elif Path(self.verify).exists():\n-            ca_bundle_path = Path(self.verify)\n+        elif Path(verify).exists():\n+            ca_bundle_path = Path(verify)\n         else:\n             raise IOError(\n                 \"Could not find a suitable TLS CA certificate bundle, \"\n-                \"invalid path: {}\".format(self.verify)\n+                \"invalid path: {}\".format(verify)\n             )\n \n-        context = self._create_default_ssl_context()\n-        context.verify_mode = ssl.CERT_REQUIRED\n-        context.check_hostname = True\n+        self.verify_mode = ssl.CERT_REQUIRED\n+        self.check_hostname = True\n \n         # Signal to server support for PHA in TLS 1.3. Raises an\n         # AttributeError if only read-only access is implemented.\n         try:\n-            context.post_handshake_auth = True\n+            self.post_handshake_auth = True\n         except AttributeError:  # pragma: no cover\n             pass\n \n         # Disable using 'commonName' for SSLContext.check_hostname\n         # when the 'subjectAltName' extension isn't available.\n         try:\n-            context.hostname_checks_common_name = False\n+            self.hostname_checks_common_name = False\n         except AttributeError:  # pragma: no cover\n             pass\n \n         if ca_bundle_path.is_file():\n             cafile = str(ca_bundle_path)\n             logger.debug(\"load_verify_locations cafile=%r\", cafile)\n-            context.load_verify_locations(cafile=cafile)\n+            self.load_verify_locations(cafile=cafile)\n         elif ca_bundle_path.is_dir():\n             capath = str(ca_bundle_path)\n             logger.debug(\"load_verify_locations capath=%r\", capath)\n-            context.load_verify_locations(capath=capath)\n+            self.load_verify_locations(capath=capath)\n \n-        self._load_client_certs(context)\n+        self._load_client_certs(cert)\n \n-        return context\n-\n-    def _create_default_ssl_context(self) -> ssl.SSLContext:\n+    def _load_client_certs(self, cert: typing.Optional[CertTypes] = None) -> None:\n         \"\"\"\n-        Creates the default SSLContext object that's used for both verified\n-        and unverified connections.\n+        Loads client certificates into our SSLContext object\n         \"\"\"\n-        context = ssl.SSLContext(ssl.PROTOCOL_TLS_CLIENT)\n-        set_minimum_tls_version_1_2(context)\n-        context.options |= ssl.OP_NO_COMPRESSION\n-        context.set_ciphers(DEFAULT_CIPHERS)\n-\n-        if ssl.HAS_ALPN:\n-            alpn_idents = [\"http/1.1\", \"h2\"] if self.http2 else [\"http/1.1\"]\n-            context.set_alpn_protocols(alpn_idents)\n+        if cert is not None:\n+            if isinstance(cert, str):\n+                self.load_cert_chain(certfile=cert)\n+            elif isinstance(cert, tuple) and len(cert) == 2:\n+                self.load_cert_chain(certfile=cert[0], keyfile=cert[1])\n+            elif isinstance(cert, tuple) and len(cert) == 3:\n+                self.load_cert_chain(\n+                    certfile=cert[0],\n+                    keyfile=cert[1],\n+                    password=cert[2],\n+                )\n \n-        keylogfile = os.environ.get(\"SSLKEYLOGFILE\")\n-        if keylogfile and self.trust_env:\n-            context.keylog_filename = keylogfile\n+    def __repr__(self) -> str:\n+        class_name = self.__class__.__name__\n \n-        return context\n+        return f\"{class_name}(verify={self.verify!r})\"",
      "comment": "```suggestion\r\n        return f\"{class_name}(verify={self.verify!r}, trust_env={self.trust_env!r})\"\r\n```",
      "comment_id": 1789290923,
      "user": "T-256",
      "created_at": "2024-10-06T23:08:18Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1789290923"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_transports/default.py",
      "line": 140,
      "side": "RIGHT",
      "diff_hunk": "@@ -136,8 +136,8 @@ def __init__(\n         retries: int = 0,\n         socket_options: typing.Iterable[SOCKET_OPTION] | None = None,\n     ) -> None:\n-        ssl_context = create_ssl_context(verify=verify, cert=cert, trust_env=trust_env)\n         proxy = Proxy(url=proxy) if isinstance(proxy, (str, URL)) else proxy\n+        ssl_context = ssl_context or SSLContext()",
      "comment": "```suggestion\r\n        ssl_context = ssl_context or SSLContext(trust_env=trust_env)\r\n```",
      "comment_id": 1789295895,
      "user": "T-256",
      "created_at": "2024-10-06T23:23:27Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1789295895"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_transports/default.py",
      "line": 279,
      "side": "RIGHT",
      "diff_hunk": "@@ -265,20 +265,18 @@ async def aclose(self) -> None:\n class AsyncHTTPTransport(AsyncBaseTransport):\n     def __init__(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        ssl_context: ssl.SSLContext | None = None,\n         http1: bool = True,\n         http2: bool = False,\n         limits: Limits = DEFAULT_LIMITS,\n-        trust_env: bool = True,\n         proxy: ProxyTypes | None = None,\n         uds: str | None = None,\n         local_address: str | None = None,\n         retries: int = 0,\n         socket_options: typing.Iterable[SOCKET_OPTION] | None = None,\n     ) -> None:\n-        ssl_context = create_ssl_context(verify=verify, cert=cert, trust_env=trust_env)\n         proxy = Proxy(url=proxy) if isinstance(proxy, (str, URL)) else proxy\n+        ssl_context = ssl_context or SSLContext()",
      "comment": "```suggestion\r\n        ssl_context = ssl_context or SSLContext(trust_env=trust_env)\r\n```",
      "comment_id": 1789296103,
      "user": "T-256",
      "created_at": "2024-10-06T23:24:09Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1789296103"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_client.py",
      "line": 686,
      "side": "RIGHT",
      "diff_hunk": "@@ -695,20 +683,18 @@ def __init__(\n \n     def _init_transport(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        ssl_context: typing.Optional[ssl.SSLContext],",
      "comment": "```suggestion\r\n        ssl_context: ssl.SSLContext | None = None,\r\n```",
      "comment_id": 1790216656,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:21:22Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790216656"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_client.py",
      "line": 707,
      "side": "RIGHT",
      "diff_hunk": "@@ -718,16 +704,14 @@ def _init_transport(\n     def _init_proxy_transport(\n         self,\n         proxy: Proxy,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "```suggestion\r\n        ssl_context: ssl.SSLContext | None = None,\r\n```",
      "comment_id": 1790218211,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:22:18Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790218211"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "tests/test_config.py",
      "line": 31,
      "side": "RIGHT",
      "diff_hunk": "@@ -9,48 +9,46 @@\n \n \n def test_load_ssl_config():\n-    context = httpx.create_ssl_context()\n+    context = httpx.SSLContext()\n     assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n     assert context.check_hostname is True\n \n \n def test_load_ssl_config_verify_non_existing_path():\n     with pytest.raises(IOError):\n-        httpx.create_ssl_context(verify=\"/path/to/nowhere\")\n+        httpx.SSLContext(verify=\"/path/to/nowhere\")\n \n \n-def test_load_ssl_config_verify_existing_file():\n-    context = httpx.create_ssl_context(verify=certifi.where())\n-    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n-    assert context.check_hostname is True\n-\n+@pytest.mark.parametrize(\n+    \"trust_env, expected_keylog_filename\",\n+    [\n+        pytest.param(True, \"test\", id=\"With trusting env\"),\n+        pytest.param(False, None, id=\"Without trusting env\"),\n+    ],\n+)\n+def test_load_ssl_with_keylog(\n+    monkeypatch: t.Any, trust_env: bool, expected_keylog_filename: t.Union[str, None]\n+) -> None:",
      "comment": "```suggestion\r\ndef test_load_ssl_with_keylog(\r\n    monkeypatch: typing.Any,\r\n    trust_env: bool,\r\n    expected_keylog_filename: typing.Union[str, None]\r\n) -> None:\r\n```",
      "comment_id": 1790224400,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:25:48Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790224400"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 51,
      "side": "RIGHT",
      "diff_hunk": "@@ -49,8 +48,7 @@ def request(\n     proxy: ProxyTypes | None = None,\n     timeout: TimeoutTypes = DEFAULT_TIMEOUT_CONFIG,\n     follow_redirects: bool = False,\n-    verify: VerifyTypes = True,\n-    cert: CertTypes | None = None,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "```suggestion\r\n    ssl_context: ssl.SSLContext | None = None,\r\n```",
      "comment_id": 1790225935,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:26:40Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790225935"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 135,
      "side": "RIGHT",
      "diff_hunk": "@@ -141,8 +132,7 @@ def stream(\n     proxy: ProxyTypes | None = None,\n     timeout: TimeoutTypes = DEFAULT_TIMEOUT_CONFIG,\n     follow_redirects: bool = False,\n-    verify: VerifyTypes = True,\n-    cert: CertTypes | None = None,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "```suggestion\r\n    ssl_context: ssl.SSLContext | None = None,\r\n```",
      "comment_id": 1790226408,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:26:57Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790226408"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 179,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,8 +176,7 @@ def get(\n     auth: AuthTypes | None = None,\n     proxy: ProxyTypes | None = None,\n     follow_redirects: bool = False,\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "```suggestion\r\n    ssl_context: ssl.SSLContext | None = None,\r\n```",
      "comment_id": 1790226941,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:27:14Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790226941"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 215,
      "side": "RIGHT",
      "diff_hunk": "@@ -225,8 +212,7 @@ def options(\n     auth: AuthTypes | None = None,\n     proxy: ProxyTypes | None = None,\n     follow_redirects: bool = False,\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "```suggestion\r\n    ssl_context: ssl.SSLContext | None = None,\r\n```",
      "comment_id": 1790227449,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:27:31Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790227449"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 251,
      "side": "RIGHT",
      "diff_hunk": "@@ -263,8 +248,7 @@ def head(\n     auth: AuthTypes | None = None,\n     proxy: ProxyTypes | None = None,\n     follow_redirects: bool = False,\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "```suggestion\r\n    ssl_context: ssl.SSLContext | None = None,\r\n```",
      "comment_id": 1790227923,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:27:47Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790227923"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 291,
      "side": "RIGHT",
      "diff_hunk": "@@ -305,8 +288,7 @@ def post(\n     auth: AuthTypes | None = None,\n     proxy: ProxyTypes | None = None,\n     follow_redirects: bool = False,\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "```suggestion\r\n    ssl_context: ssl.SSLContext | None = None,\r\n```",
      "comment_id": 1790228710,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:28:10Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790228710"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 332,
      "side": "RIGHT",
      "diff_hunk": "@@ -348,8 +329,7 @@ def put(\n     auth: AuthTypes | None = None,\n     proxy: ProxyTypes | None = None,\n     follow_redirects: bool = False,\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "```suggestion\r\n    ssl_context: ssl.SSLContext | None = None,\r\n```",
      "comment_id": 1790229202,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:28:25Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790229202"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 373,
      "side": "RIGHT",
      "diff_hunk": "@@ -391,8 +370,7 @@ def patch(\n     auth: AuthTypes | None = None,\n     proxy: ProxyTypes | None = None,\n     follow_redirects: bool = False,\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "```suggestion\r\n    ssl_context: ssl.SSLContext | None = None,\r\n```",
      "comment_id": 1790229610,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:28:41Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790229610"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_api.py",
      "line": 411,
      "side": "RIGHT",
      "diff_hunk": "@@ -430,9 +407,8 @@ def delete(\n     auth: AuthTypes | None = None,\n     proxy: ProxyTypes | None = None,\n     follow_redirects: bool = False,\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n     timeout: TimeoutTypes = DEFAULT_TIMEOUT_CONFIG,\n+    ssl_context: typing.Optional[ssl.SSLContext] = None,",
      "comment": "```suggestion\r\n    ssl_context: ssl.SSLContext | None = None,\r\n```",
      "comment_id": 1790230064,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:28:57Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790230064"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_client.py",
      "line": 691,
      "side": "RIGHT",
      "diff_hunk": "@@ -695,20 +683,18 @@ def __init__(\n \n     def _init_transport(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        ssl_context: typing.Optional[ssl.SSLContext],\n         http1: bool = True,\n         http2: bool = False,\n         limits: Limits = DEFAULT_LIMITS,\n-        transport: BaseTransport | None = None,\n         trust_env: bool = True,\n+        transport: typing.Optional[BaseTransport] = None,",
      "comment": "```suggestion\r\n        transport: BaseTransport | None = None,\r\n        trust_env: bool = True,\r\n```",
      "comment_id": 1790231357,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:29:40Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790231357"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_client.py",
      "line": 691,
      "side": "RIGHT",
      "diff_hunk": "@@ -695,20 +683,18 @@ def __init__(\n \n     def _init_transport(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        ssl_context: typing.Optional[ssl.SSLContext],\n         http1: bool = True,\n         http2: bool = False,\n         limits: Limits = DEFAULT_LIMITS,\n-        transport: BaseTransport | None = None,\n         trust_env: bool = True,\n+        transport: typing.Optional[BaseTransport] = None,",
      "comment": "```suggestion\r\n        transport: BaseTransport | None = None,\r\n        trust_env: bool = True,\r\n```",
      "comment_id": 1790234890,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:31:40Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790234890"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "tests/test_config.py",
      "line": 31,
      "side": "RIGHT",
      "diff_hunk": "@@ -9,48 +9,46 @@\n \n \n def test_load_ssl_config():\n-    context = httpx.create_ssl_context()\n+    context = httpx.SSLContext()\n     assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n     assert context.check_hostname is True\n \n \n def test_load_ssl_config_verify_non_existing_path():\n     with pytest.raises(IOError):\n-        httpx.create_ssl_context(verify=\"/path/to/nowhere\")\n+        httpx.SSLContext(verify=\"/path/to/nowhere\")\n \n \n-def test_load_ssl_config_verify_existing_file():\n-    context = httpx.create_ssl_context(verify=certifi.where())\n-    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n-    assert context.check_hostname is True\n-\n+@pytest.mark.parametrize(\n+    \"trust_env, expected_keylog_filename\",\n+    [\n+        pytest.param(True, \"test\", id=\"With trusting env\"),\n+        pytest.param(False, None, id=\"Without trusting env\"),\n+    ],\n+)\n+def test_load_ssl_with_keylog(\n+    monkeypatch: t.Any, trust_env: bool, expected_keylog_filename: t.Union[str, None]\n+) -> None:",
      "comment": "`typing.Union[str, None]` -> `str | None`\r\n\r\nIMO, we could also use add these type annotations in separated PR which includes annotating other tests?",
      "comment_id": 1790238999,
      "user": "T-256",
      "created_at": "2024-10-07T13:34:02Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790238999"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "tests/test_config.py",
      "line": 32,
      "side": "RIGHT",
      "diff_hunk": "@@ -9,48 +9,48 @@\n \n \n def test_load_ssl_config():\n-    context = httpx.create_ssl_context()\n+    context = httpx.SSLContext()\n     assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n     assert context.check_hostname is True\n \n \n def test_load_ssl_config_verify_non_existing_path():\n     with pytest.raises(IOError):\n-        httpx.create_ssl_context(verify=\"/path/to/nowhere\")\n+        httpx.SSLContext(verify=\"/path/to/nowhere\")\n \n \n-def test_load_ssl_config_verify_existing_file():\n-    context = httpx.create_ssl_context(verify=certifi.where())\n-    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n-    assert context.check_hostname is True\n-\n+@pytest.mark.parametrize(\n+    \"trust_env, expected_keylog_filename\",\n+    [\n+        pytest.param(True, \"test\", id=\"With trusting env\"),\n+        pytest.param(False, None, id=\"Without trusting env\"),\n+    ],\n+)\n+def test_load_ssl_with_keylog(\n+    monkeypatch: typing.Any,\n+    trust_env: bool,\n+    expected_keylog_filename: typing.Union[str, None]",
      "comment": "```suggestion\r\n    expected_keylog_filename: typing.Union[str, None],\r\n```",
      "comment_id": 1790250479,
      "user": "lovelydinosaur",
      "created_at": "2024-10-07T13:40:33Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1790250479"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "tests/test_config.py",
      "line": 36,
      "side": "RIGHT",
      "diff_hunk": "@@ -9,48 +9,48 @@\n \n \n def test_load_ssl_config():\n-    context = httpx.create_ssl_context()\n+    context = httpx.SSLContext()\n     assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n     assert context.check_hostname is True\n \n \n def test_load_ssl_config_verify_non_existing_path():\n     with pytest.raises(IOError):\n-        httpx.create_ssl_context(verify=\"/path/to/nowhere\")\n+        httpx.SSLContext(verify=\"/path/to/nowhere\")\n \n \n-def test_load_ssl_config_verify_existing_file():\n-    context = httpx.create_ssl_context(verify=certifi.where())\n-    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n-    assert context.check_hostname is True\n-\n+@pytest.mark.parametrize(\n+    \"trust_env, expected_keylog_filename\",\n+    [\n+        pytest.param(True, \"test\", id=\"With trusting env\"),\n+        pytest.param(False, None, id=\"Without trusting env\"),\n+    ],\n+)\n+def test_load_ssl_with_keylog(\n+    monkeypatch: typing.Any,\n+    trust_env: bool,\n+    expected_keylog_filename: typing.Union[str, None],\n+) -> None:\n+    monkeypatch.setenv(\"SSLKEYLOGFILE\", \"test\")\n+    context = httpx.SSLContext(trust_env=trust_env)\n+    assert context.keylog_filename == expected_keylog_filename",
      "comment": "```suggestion\r\ndef test_load_ssl_with_keylog(\r\n    monkeypatch: typing.Any,\r\n    expected_keylog_filename: typing.Union[str, None],\r\n) -> None:\r\n    monkeypatch.setenv(\"SSLKEYLOGFILE\", \"test\")\r\n    context = httpx.SSLContext()\r\n    assert context.keylog_filename == expected_keylog_filename\r\n```",
      "comment_id": 1791561015,
      "user": "lovelydinosaur",
      "created_at": "2024-10-08T09:45:45Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1791561015"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_client.py",
      "line": 673,
      "side": "LEFT",
      "diff_hunk": "@@ -664,25 +656,21 @@ def __init__(\n         proxy_map = self._get_proxy_map(proxy, allow_env_proxies)\n \n         self._transport = self._init_transport(\n-            verify=verify,\n-            cert=cert,\n+            ssl_context=ssl_context,\n             http1=http1,\n             http2=http2,\n             limits=limits,\n             transport=transport,\n-            trust_env=trust_env,",
      "comment": "This is in the right direction... dropping `trust_env` out of the `httpx.SSLContext()` API.",
      "comment_id": 1791568594,
      "user": "lovelydinosaur",
      "created_at": "2024-10-08T09:50:46Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1791568594"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "httpx/_config.py",
      "line": 64,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,151 +45,103 @@ class UnsetType:\n UNSET = UnsetType()\n \n \n-def create_ssl_context(\n-    cert: CertTypes | None = None,\n-    verify: VerifyTypes = True,\n-    trust_env: bool = True,\n-    http2: bool = False,\n-) -> ssl.SSLContext:\n-    return SSLConfig(\n-        cert=cert, verify=verify, trust_env=trust_env, http2=http2\n-    ).ssl_context\n-\n-\n-class SSLConfig:\n-    \"\"\"\n-    SSL Configuration.\n-    \"\"\"\n-\n+class SSLContext(ssl.SSLContext):\n     DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n \n     def __init__(\n         self,\n-        *,\n-        cert: CertTypes | None = None,\n         verify: VerifyTypes = True,\n+        cert: CertTypes | None = None,\n         trust_env: bool = True,\n-        http2: bool = False,\n     ) -> None:\n-        self.cert = cert\n         self.verify = verify\n+        set_minimum_tls_version_1_2(self)\n+        self.options |= ssl.OP_NO_COMPRESSION\n+        self.set_ciphers(DEFAULT_CIPHERS)\n         self.trust_env = trust_env\n-        self.http2 = http2\n-        self.ssl_context = self.load_ssl_context()\n \n-    def load_ssl_context(self) -> ssl.SSLContext:\n+        keylogfile = os.environ.get(\"SSLKEYLOGFILE\")\n+        if keylogfile and self.trust_env:",
      "comment": "Yes we're applying this unilaterally. (In line with `ssl.create_default_context()`, `urllib3`, and `requests`)",
      "comment_id": 1791571187,
      "user": "lovelydinosaur",
      "created_at": "2024-10-08T09:52:28Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1791571187"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3022,
      "file_path": "tests/test_config.py",
      "line": 28,
      "side": "RIGHT",
      "diff_hunk": "@@ -9,48 +9,40 @@\n \n \n def test_load_ssl_config():\n-    context = httpx.create_ssl_context()\n+    context = httpx.SSLContext()\n     assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n     assert context.check_hostname is True\n \n \n def test_load_ssl_config_verify_non_existing_path():\n     with pytest.raises(IOError):\n-        httpx.create_ssl_context(verify=\"/path/to/nowhere\")\n+        httpx.SSLContext(verify=\"/path/to/nowhere\")\n \n \n-def test_load_ssl_config_verify_existing_file():\n-    context = httpx.create_ssl_context(verify=certifi.where())\n-    assert context.verify_mode == ssl.VerifyMode.CERT_REQUIRED\n-    assert context.check_hostname is True\n+def test_load_ssl_with_keylog(\n+    monkeypatch: typing.Any,\n+    expected_keylog_filename: typing.Union[str, None],\n+) -> None:\n+    monkeypatch.setenv(\"SSLKEYLOGFILE\", \"test\")\n+    context = httpx.SSLContext()\n+    assert context.keylog_filename == expected_keylog_filename",
      "comment": "```suggestion\r\ndef test_load_ssl_with_keylog(monkeypatch: typing.Any) -> None:\r\n    monkeypatch.setenv(\"SSLKEYLOGFILE\", \"test\")\r\n    context = httpx.SSLContext()\r\n    assert context.keylog_filename == \"test\"\r\n```",
      "comment_id": 1791576267,
      "user": "lovelydinosaur",
      "created_at": "2024-10-08T09:55:50Z",
      "url": "https://github.com/encode/httpx/pull/3022#discussion_r1791576267"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3335,
      "file_path": "httpx/_config.py",
      "line": 49,
      "side": "LEFT",
      "diff_hunk": "@@ -46,92 +45,41 @@ class UnsetType:\n \n \n class SSLContext(ssl.SSLContext):\n-    DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())",
      "comment": "Let's keep it, avoid new `certifi.where()` call per instantization.",
      "comment_id": 1791986336,
      "user": "T-256",
      "created_at": "2024-10-08T14:25:39Z",
      "url": "https://github.com/encode/httpx/pull/3335#discussion_r1791986336"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3335,
      "file_path": "httpx/_config.py",
      "line": 56,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,92 +45,41 @@ class UnsetType:\n \n \n class SSLContext(ssl.SSLContext):\n-    DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n-\n     def __init__(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        verify: bool = True,\n     ) -> None:\n-        self.verify = verify\n-        set_minimum_tls_version_1_2(self)\n-        self.options |= ssl.OP_NO_COMPRESSION\n-        self.set_ciphers(DEFAULT_CIPHERS)\n-\n-        keylogfile = os.environ.get(\"SSLKEYLOGFILE\")\n-        if keylogfile:\n-            self.keylog_filename = keylogfile\n-\n-        logger.debug(\n-            \"load_ssl_context verify=%r cert=%r\",\n-            verify,\n-            cert,\n-        )\n+        super().__init__()\n+        self._verify = verify\n \n+        # Our SSL setup here is similar to the stdlib `ssl.create_default_context()`\n+        # implementation, except with `certifi` used for certificate verification.",
      "comment": "when `verify=False`, we actually don't load certifi. let's move this comment to down.",
      "comment_id": 1791997641,
      "user": "T-256",
      "created_at": "2024-10-08T14:31:02Z",
      "url": "https://github.com/encode/httpx/pull/3335#discussion_r1791997641"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3335,
      "file_path": "httpx/_config.py",
      "line": 77,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,92 +45,41 @@ class UnsetType:\n \n \n class SSLContext(ssl.SSLContext):\n-    DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n-\n     def __init__(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        verify: bool = True,\n     ) -> None:\n-        self.verify = verify\n-        set_minimum_tls_version_1_2(self)\n-        self.options |= ssl.OP_NO_COMPRESSION\n-        self.set_ciphers(DEFAULT_CIPHERS)\n-\n-        keylogfile = os.environ.get(\"SSLKEYLOGFILE\")\n-        if keylogfile:\n-            self.keylog_filename = keylogfile\n-\n-        logger.debug(\n-            \"load_ssl_context verify=%r cert=%r\",\n-            verify,\n-            cert,\n-        )\n+        super().__init__()\n+        self._verify = verify\n \n+        # Our SSL setup here is similar to the stdlib `ssl.create_default_context()`\n+        # implementation, except with `certifi` used for certificate verification.\n         if not verify:\n             self.check_hostname = False\n             self.verify_mode = ssl.CERT_NONE\n-            self._load_client_certs(cert)\n             return\n \n-        if isinstance(verify, bool):\n-            ca_bundle_path = self.DEFAULT_CA_BUNDLE_PATH\n-        elif Path(verify).exists():\n-            ca_bundle_path = Path(verify)\n-        else:\n-            raise IOError(\n-                \"Could not find a suitable TLS CA certificate bundle, \"\n-                \"invalid path: {}\".format(verify)\n-            )\n-\n         self.verify_mode = ssl.CERT_REQUIRED\n         self.check_hostname = True\n \n-        # Signal to server support for PHA in TLS 1.3. Raises an\n-        # AttributeError if only read-only access is implemented.\n-        try:\n-            self.post_handshake_auth = True\n-        except AttributeError:  # pragma: no cover\n-            pass\n-\n-        # Disable using 'commonName' for SSLContext.check_hostname\n-        # when the 'subjectAltName' extension isn't available.\n-        try:\n-            self.hostname_checks_common_name = False\n-        except AttributeError:  # pragma: no cover\n-            pass\n-\n-        if ca_bundle_path.is_file():\n-            cafile = str(ca_bundle_path)\n-            logger.debug(\"load_verify_locations cafile=%r\", cafile)\n-            self.load_verify_locations(cafile=cafile)\n-        elif ca_bundle_path.is_dir():\n-            capath = str(ca_bundle_path)\n-            logger.debug(\"load_verify_locations capath=%r\", capath)\n-            self.load_verify_locations(capath=capath)\n-\n-        self._load_client_certs(cert)\n-\n-    def _load_client_certs(self, cert: typing.Optional[CertTypes] = None) -> None:\n-        \"\"\"\n-        Loads client certificates into our SSLContext object\n-        \"\"\"\n-        if cert is not None:\n-            if isinstance(cert, str):\n-                self.load_cert_chain(certfile=cert)\n-            elif isinstance(cert, tuple) and len(cert) == 2:\n-                self.load_cert_chain(certfile=cert[0], keyfile=cert[1])\n-            elif isinstance(cert, tuple) and len(cert) == 3:\n-                self.load_cert_chain(\n-                    certfile=cert[0],\n-                    keyfile=cert[1],\n-                    password=cert[2],\n-                )\n+        # Use stricter verify flags where possible.\n+        if hasattr(ssl, \"VERIFY_X509_PARTIAL_CHAIN\"):  # pragma: nocover\n+            self.verify_flags |= ssl.VERIFY_X509_PARTIAL_CHAIN\n+        if hasattr(ssl, \"VERIFY_X509_STRICT\"):  # pragma: nocover\n+            self.verify_flags |= ssl.VERIFY_X509_STRICT\n+\n+        # Default to `certifi` for certificiate verification.\n+        self.load_verify_locations(cafile=certifi.where())\n+\n+        # OpenSSL keylog file support.\n+        if hasattr(self, \"keylog_filename\"):\n+            keylogfile = os.environ.get(\"SSLKEYLOGFILE\")\n+            if keylogfile and not sys.flags.ignore_environment:",
      "comment": "Do we need to document `sys.flags.ignore_environment` behavior at here?",
      "comment_id": 1792003687,
      "user": "T-256",
      "created_at": "2024-10-08T14:34:25Z",
      "url": "https://github.com/encode/httpx/pull/3335#discussion_r1792003687"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3335,
      "file_path": "httpx/_config.py",
      "line": 60,
      "side": "LEFT",
      "diff_hunk": "@@ -46,92 +45,41 @@ class UnsetType:\n \n \n class SSLContext(ssl.SSLContext):\n-    DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n-\n     def __init__(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        verify: bool = True,\n     ) -> None:\n-        self.verify = verify\n-        set_minimum_tls_version_1_2(self)\n-        self.options |= ssl.OP_NO_COMPRESSION\n-        self.set_ciphers(DEFAULT_CIPHERS)\n-",
      "comment": "We've been following `urllib3`'s lead on SSL, and have [some out of date defaults here](https://github.com/urllib3/urllib3/pull/2705).",
      "comment_id": 1794964425,
      "user": "lovelydinosaur",
      "created_at": "2024-10-10T08:29:07Z",
      "url": "https://github.com/encode/httpx/pull/3335#discussion_r1794964425"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3335,
      "file_path": "httpx/_config.py",
      "line": 49,
      "side": "LEFT",
      "diff_hunk": "@@ -46,92 +45,41 @@ class UnsetType:\n \n \n class SSLContext(ssl.SSLContext):\n-    DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())",
      "comment": "Calling `certifi.where()` at the point the certifi certificates are loaded seems reasonable to me.",
      "comment_id": 1795109143,
      "user": "lovelydinosaur",
      "created_at": "2024-10-10T10:05:43Z",
      "url": "https://github.com/encode/httpx/pull/3335#discussion_r1795109143"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3335,
      "file_path": "httpx/_config.py",
      "line": 102,
      "side": "LEFT",
      "diff_hunk": "@@ -46,92 +45,41 @@ class UnsetType:\n \n \n class SSLContext(ssl.SSLContext):\n-    DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n-\n     def __init__(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        verify: bool = True,\n     ) -> None:\n-        self.verify = verify\n-        set_minimum_tls_version_1_2(self)\n-        self.options |= ssl.OP_NO_COMPRESSION\n-        self.set_ciphers(DEFAULT_CIPHERS)\n-\n-        keylogfile = os.environ.get(\"SSLKEYLOGFILE\")\n-        if keylogfile:\n-            self.keylog_filename = keylogfile\n-\n-        logger.debug(\n-            \"load_ssl_context verify=%r cert=%r\",\n-            verify,\n-            cert,\n-        )\n+        super().__init__()\n+        self._verify = verify\n \n+        # Our SSL setup here is similar to the stdlib `ssl.create_default_context()`\n+        # implementation, except with `certifi` used for certificate verification.\n         if not verify:\n             self.check_hostname = False\n             self.verify_mode = ssl.CERT_NONE\n-            self._load_client_certs(cert)\n             return\n \n-        if isinstance(verify, bool):\n-            ca_bundle_path = self.DEFAULT_CA_BUNDLE_PATH\n-        elif Path(verify).exists():\n-            ca_bundle_path = Path(verify)\n-        else:\n-            raise IOError(\n-                \"Could not find a suitable TLS CA certificate bundle, \"\n-                \"invalid path: {}\".format(verify)\n-            )\n-\n         self.verify_mode = ssl.CERT_REQUIRED\n         self.check_hostname = True\n \n-        # Signal to server support for PHA in TLS 1.3. Raises an\n-        # AttributeError if only read-only access is implemented.\n-        try:\n-            self.post_handshake_auth = True\n-        except AttributeError:  # pragma: no cover\n-            pass\n-\n-        # Disable using 'commonName' for SSLContext.check_hostname\n-        # when the 'subjectAltName' extension isn't available.\n-        try:\n-            self.hostname_checks_common_name = False\n-        except AttributeError:  # pragma: no cover\n-            pass",
      "comment": "Ah... there's possibly useful context to talk through for both `post_handshake_auth`, and for `hostname_checks_common_name`. I'm going to suggest that we start by matching the `stdlib` behaviour, and have a design discussion review on the SSL settings prior to 1.0.\r\n\r\nUsing commonName fallback has been deprecated for some time...\r\n\r\n* https://stackoverflow.com/questions/43665243/invalid-self-signed-ssl-cert-subject-alternative-name-missing\r\n* https://github.com/encode/httpx/discussions/2978\r\n* https://github.com/encode/httpx/discussions/3125\r\n\r\nThis is not enforced in `ssl.create_default_context()`, and perhaps we don't need to either if the user is working with self-signed certs may be their responsibility.\r\n\r\nWrt. PHA, this was introduced in `urllib3` based on this ticket...\r\n\r\nhttps://github.com/urllib3/urllib3/issues/1634\r\n\r\nIt's not obvious to me that \"client cert authentication based on HTTP request parameters like method or path\" is desirable.",
      "comment_id": 1795147435,
      "user": "lovelydinosaur",
      "created_at": "2024-10-10T10:21:25Z",
      "url": "https://github.com/encode/httpx/pull/3335#discussion_r1795147435"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3335,
      "file_path": "httpx/_config.py",
      "line": 77,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,92 +45,41 @@ class UnsetType:\n \n \n class SSLContext(ssl.SSLContext):\n-    DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n-\n     def __init__(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        verify: bool = True,\n     ) -> None:\n-        self.verify = verify\n-        set_minimum_tls_version_1_2(self)\n-        self.options |= ssl.OP_NO_COMPRESSION\n-        self.set_ciphers(DEFAULT_CIPHERS)\n-\n-        keylogfile = os.environ.get(\"SSLKEYLOGFILE\")\n-        if keylogfile:\n-            self.keylog_filename = keylogfile\n-\n-        logger.debug(\n-            \"load_ssl_context verify=%r cert=%r\",\n-            verify,\n-            cert,\n-        )\n+        super().__init__()\n+        self._verify = verify\n \n+        # Our SSL setup here is similar to the stdlib `ssl.create_default_context()`\n+        # implementation, except with `certifi` used for certificate verification.\n         if not verify:\n             self.check_hostname = False\n             self.verify_mode = ssl.CERT_NONE\n-            self._load_client_certs(cert)\n             return\n \n-        if isinstance(verify, bool):\n-            ca_bundle_path = self.DEFAULT_CA_BUNDLE_PATH\n-        elif Path(verify).exists():\n-            ca_bundle_path = Path(verify)\n-        else:\n-            raise IOError(\n-                \"Could not find a suitable TLS CA certificate bundle, \"\n-                \"invalid path: {}\".format(verify)\n-            )\n-\n         self.verify_mode = ssl.CERT_REQUIRED\n         self.check_hostname = True\n \n-        # Signal to server support for PHA in TLS 1.3. Raises an\n-        # AttributeError if only read-only access is implemented.\n-        try:\n-            self.post_handshake_auth = True\n-        except AttributeError:  # pragma: no cover\n-            pass\n-\n-        # Disable using 'commonName' for SSLContext.check_hostname\n-        # when the 'subjectAltName' extension isn't available.\n-        try:\n-            self.hostname_checks_common_name = False\n-        except AttributeError:  # pragma: no cover\n-            pass\n-\n-        if ca_bundle_path.is_file():\n-            cafile = str(ca_bundle_path)\n-            logger.debug(\"load_verify_locations cafile=%r\", cafile)\n-            self.load_verify_locations(cafile=cafile)\n-        elif ca_bundle_path.is_dir():\n-            capath = str(ca_bundle_path)\n-            logger.debug(\"load_verify_locations capath=%r\", capath)\n-            self.load_verify_locations(capath=capath)\n-\n-        self._load_client_certs(cert)\n-\n-    def _load_client_certs(self, cert: typing.Optional[CertTypes] = None) -> None:\n-        \"\"\"\n-        Loads client certificates into our SSLContext object\n-        \"\"\"\n-        if cert is not None:\n-            if isinstance(cert, str):\n-                self.load_cert_chain(certfile=cert)\n-            elif isinstance(cert, tuple) and len(cert) == 2:\n-                self.load_cert_chain(certfile=cert[0], keyfile=cert[1])\n-            elif isinstance(cert, tuple) and len(cert) == 3:\n-                self.load_cert_chain(\n-                    certfile=cert[0],\n-                    keyfile=cert[1],\n-                    password=cert[2],\n-                )\n+        # Use stricter verify flags where possible.\n+        if hasattr(ssl, \"VERIFY_X509_PARTIAL_CHAIN\"):  # pragma: nocover\n+            self.verify_flags |= ssl.VERIFY_X509_PARTIAL_CHAIN\n+        if hasattr(ssl, \"VERIFY_X509_STRICT\"):  # pragma: nocover\n+            self.verify_flags |= ssl.VERIFY_X509_STRICT\n+\n+        # Default to `certifi` for certificiate verification.\n+        self.load_verify_locations(cafile=certifi.where())\n+\n+        # OpenSSL keylog file support.\n+        if hasattr(self, \"keylog_filename\"):\n+            keylogfile = os.environ.get(\"SSLKEYLOGFILE\")\n+            if keylogfile and not sys.flags.ignore_environment:",
      "comment": "Maybe. We're just following `stdlib` behavior here. Can take a final review on that once we've dealt with getting the API clean-up in.",
      "comment_id": 1795162041,
      "user": "lovelydinosaur",
      "created_at": "2024-10-10T10:30:10Z",
      "url": "https://github.com/encode/httpx/pull/3335#discussion_r1795162041"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3335,
      "file_path": "httpx/_config.py",
      "line": 29,
      "side": "RIGHT",
      "diff_hunk": "@@ -46,92 +22,41 @@ class UnsetType:\n \n \n class SSLContext(ssl.SSLContext):\n-    DEFAULT_CA_BUNDLE_PATH = Path(certifi.where())\n-\n     def __init__(\n         self,\n-        verify: VerifyTypes = True,\n-        cert: CertTypes | None = None,\n+        verify: bool = True,\n     ) -> None:\n-        self.verify = verify\n-        set_minimum_tls_version_1_2(self)\n-        self.options |= ssl.OP_NO_COMPRESSION\n-        self.set_ciphers(DEFAULT_CIPHERS)\n-\n-        keylogfile = os.environ.get(\"SSLKEYLOGFILE\")\n-        if keylogfile:\n-            self.keylog_filename = keylogfile\n-\n-        logger.debug(\n-            \"load_ssl_context verify=%r cert=%r\",\n-            verify,\n-            cert,\n-        )\n+        super().__init__()",
      "comment": "```suggestion\r\n        # ssl.SSLContext sets OP_NO_SSLv2, OP_NO_SSLv3, OP_NO_COMPRESSION,\r\n        # OP_CIPHER_SERVER_PREFERENCE, OP_SINGLE_DH_USE and OP_SINGLE_ECDH_USE\r\n        # by default. (from `ssl.create_default_context`)\r\n        super().__init__()\r\n```",
      "comment_id": 1795338325,
      "user": "T-256",
      "created_at": "2024-10-10T12:34:23Z",
      "url": "https://github.com/encode/httpx/pull/3335#discussion_r1795338325"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3050,
      "file_path": "httpx/_client.py",
      "line": 683,
      "side": "RIGHT",
      "diff_hunk": "@@ -682,7 +679,13 @@ def __init__(\n             if proxy:\n                 raise RuntimeError(\"Use either `proxy` or 'proxies', not both.\")\n \n-        allow_env_proxies = trust_env and app is None and transport is None\n+        if app:\n+            raise RuntimeError(",
      "comment": "I don't know what's deprecation policy but are you sure raise error here? isn't it breaking change for those using `app`?\r\n\r\nI'd recommend keep docs, type-hints and use warning instead. then we can schedule the removal version and mention it in warning message (?)",
      "comment_id": 1451676418,
      "user": "T-256",
      "created_at": "2024-01-14T07:53:50Z",
      "url": "https://github.com/encode/httpx/pull/3050#discussion_r1451676418"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3050,
      "file_path": "httpx/_client.py",
      "line": 683,
      "side": "RIGHT",
      "diff_hunk": "@@ -682,7 +679,13 @@ def __init__(\n             if proxy:\n                 raise RuntimeError(\"Use either `proxy` or 'proxies', not both.\")\n \n-        allow_env_proxies = trust_env and app is None and transport is None\n+        if app:\n+            raise RuntimeError(",
      "comment": "> I don't know what's deprecation policy but are you sure raise error here? isn't it breaking change for those using `app`?\r\n\r\nIt looks good to me if this breaking change is for 1.0. But do we want to keep these additional errors in 1.0?",
      "comment_id": 1451678340,
      "user": "T-256",
      "created_at": "2024-01-14T08:06:37Z",
      "url": "https://github.com/encode/httpx/pull/3050#discussion_r1451678340"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3050,
      "file_path": "httpx/_client.py",
      "line": 683,
      "side": "RIGHT",
      "diff_hunk": "@@ -682,7 +679,13 @@ def __init__(\n             if proxy:\n                 raise RuntimeError(\"Use either `proxy` or 'proxies', not both.\")\n \n-        allow_env_proxies = trust_env and app is None and transport is None\n+        if app:\n+            raise RuntimeError(",
      "comment": "> It looks good to me if this breaking change is for 1.0. But do we want to keep these additional errors in 1.0?\r\n\r\nSo...  we'll need to have consistency around this.\r\n\r\nOptions might be...\r\n\r\n* Include old argument styles for 1.0 with explicit errors, to aid migrations. Clean up later and drop the errors in a 1.1 release.\r\n* Don't include old argument styles.",
      "comment_id": 1452183188,
      "user": "lovelydinosaur",
      "created_at": "2024-01-15T10:20:51Z",
      "url": "https://github.com/encode/httpx/pull/3050#discussion_r1452183188"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3050,
      "file_path": "httpx/_client.py",
      "line": 683,
      "side": "RIGHT",
      "diff_hunk": "@@ -682,7 +679,13 @@ def __init__(\n             if proxy:\n                 raise RuntimeError(\"Use either `proxy` or 'proxies', not both.\")\n \n-        allow_env_proxies = trust_env and app is None and transport is None\n+        if app:\n+            raise RuntimeError(",
      "comment": "At there, I'm more fan of what done for `proxies`:\r\nhttps://github.com/encode/httpx/blob/419d3a9d80d0c4072f6cb58eeb306148ae89e2e9/httpx/_client.py#L676-L681\r\n\r\nSo, what I can suggest at here is:\r\n1. deprecate and mention scheduled removal if any (e.g. \"The 'proxies' argument is now deprecated and it will remove in v1.0.0\")\r\n2. minor/patch release\r\n3. clear all deprecations in major release",
      "comment_id": 1452230760,
      "user": "T-256",
      "created_at": "2024-01-15T10:58:47Z",
      "url": "https://github.com/encode/httpx/pull/3050#discussion_r1452230760"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3050,
      "file_path": "httpx/_client.py",
      "line": 683,
      "side": "RIGHT",
      "diff_hunk": "@@ -682,7 +679,13 @@ def __init__(\n             if proxy:\n                 raise RuntimeError(\"Use either `proxy` or 'proxies', not both.\")\n \n-        allow_env_proxies = trust_env and app is None and transport is None\n+        if app:\n+            raise RuntimeError(",
      "comment": "I think now is good time to discuss about deprecation policy, since there are few `1.0 proposal` PRs those trying to directly remove APIs without any deprecation.",
      "comment_id": 1452235919,
      "user": "T-256",
      "created_at": "2024-01-15T11:03:24Z",
      "url": "https://github.com/encode/httpx/pull/3050#discussion_r1452235919"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3050,
      "file_path": "httpx/_client.py",
      "line": 683,
      "side": "RIGHT",
      "diff_hunk": "@@ -682,7 +679,13 @@ def __init__(\n             if proxy:\n                 raise RuntimeError(\"Use either `proxy` or 'proxies', not both.\")\n \n-        allow_env_proxies = trust_env and app is None and transport is None\n+        if app:\n+            raise RuntimeError(",
      "comment": "https://github.com/encode/httpx/pull/3069 would be a good place for us to discuss how we'd like to approach this.",
      "comment_id": 1466121446,
      "user": "lovelydinosaur",
      "created_at": "2024-01-25T09:58:45Z",
      "url": "https://github.com/encode/httpx/pull/3050#discussion_r1466121446"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3050,
      "file_path": "httpx/_client.py",
      "line": 683,
      "side": "RIGHT",
      "diff_hunk": "@@ -682,7 +679,13 @@ def __init__(\n             if proxy:\n                 raise RuntimeError(\"Use either `proxy` or 'proxies', not both.\")\n \n-        allow_env_proxies = trust_env and app is None and transport is None\n+        if app:\n+            raise RuntimeError(",
      "comment": "Via #3071 and since v1.0 is major upgrade, I'm now more interested to directly drop instead of deprecation.\r\n",
      "comment_id": 1466369932,
      "user": "T-256",
      "created_at": "2024-01-25T13:19:15Z",
      "url": "https://github.com/encode/httpx/pull/3050#discussion_r1466369932"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3312,
      "file_path": "tests/test_utils.py",
      "line": 319,
      "side": "RIGHT",
      "diff_hunk": "@@ -300,6 +301,24 @@ def test_url_matches(pattern, url, expected):\n     assert pattern.matches(httpx.URL(url)) == expected\n \n \n+@pytest.mark.parametrize(\n+    [\"value\", \"expected\"],\n+    [\n+        (b\"value\", b\"value\"),\n+        (b\"success\", b\"success\"),\n+    ],\n+)\n+def test_normalize_header_value(value, expected):\n+    assert normalize_header_value(value) == expected\n+\n+\n+def test_normalize_header_incorrect_value():\n+    with pytest.raises(\n+        TypeError, match=f\"Header value must be str or bytes, not {type(None)}\"\n+    ):\n+        normalize_header_value(None)  # type: ignore",
      "comment": "Could we have these tests in `tests/client/test_headers.py` with the testing against `httpx.Header(...)` instead of against the internal API?",
      "comment_id": 1777193345,
      "user": "lovelydinosaur",
      "created_at": "2024-09-26T14:31:17Z",
      "url": "https://github.com/encode/httpx/pull/3312#discussion_r1777193345"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3250,
      "file_path": "httpx/_urlparse.py",
      "line": 163,
      "side": "RIGHT",
      "diff_hunk": "@@ -160,7 +160,12 @@ def urlparse(url: str = \"\", **kwargs: str | None) -> ParseResult:\n     # If a URL includes any ASCII control characters including \\t, \\r, \\n,\n     # then treat it as invalid.\n     if any(char.isascii() and not char.isprintable() for char in url):\n-        raise InvalidURL(\"Invalid non-printable ASCII character in URL\")\n+        char = [char for char in url if char.isascii() and not char.isprintable()][0]",
      "comment": "Could this be done lazily without materializing the list?",
      "comment_id": 1692499301,
      "user": "adriangb",
      "created_at": "2024-07-26T04:31:08Z",
      "url": "https://github.com/encode/httpx/pull/3250#discussion_r1692499301"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3250,
      "file_path": "httpx/_urlparse.py",
      "line": 215,
      "side": "RIGHT",
      "diff_hunk": "@@ -205,9 +210,15 @@ def urlparse(url: str = \"\", **kwargs: str | None) -> ParseResult:\n             # If a component includes any ASCII control characters including \\t, \\r, \\n,\n             # then treat it as invalid.\n             if any(char.isascii() and not char.isprintable() for char in value):\n-                raise InvalidURL(\n-                    f\"Invalid non-printable ASCII character in URL component '{key}'\"\n+                char = [\n+                    char for char in value if char.isascii() and not char.isprintable()\n+                ][0]",
      "comment": "Same here. This could be a small utility function as well (it's duplicated in 2 places, I'm okay keeping it duplicated).",
      "comment_id": 1692499591,
      "user": "adriangb",
      "created_at": "2024-07-26T04:31:43Z",
      "url": "https://github.com/encode/httpx/pull/3250#discussion_r1692499591"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3250,
      "file_path": "httpx/_urlparse.py",
      "line": 163,
      "side": "RIGHT",
      "diff_hunk": "@@ -160,7 +160,12 @@ def urlparse(url: str = \"\", **kwargs: str | None) -> ParseResult:\n     # If a URL includes any ASCII control characters including \\t, \\r, \\n,\n     # then treat it as invalid.\n     if any(char.isascii() and not char.isprintable() for char in url):\n-        raise InvalidURL(\"Invalid non-printable ASCII character in URL\")\n+        char = [char for char in url if char.isascii() and not char.isprintable()][0]",
      "comment": "It can be done lazily by materializing a generator yes. \u270c\ufe0f",
      "comment_id": 1692707828,
      "user": "lovelydinosaur",
      "created_at": "2024-07-26T08:35:24Z",
      "url": "https://github.com/encode/httpx/pull/3250#discussion_r1692707828"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3139,
      "file_path": "httpx/_decoders.py",
      "line": 167,
      "side": "RIGHT",
      "diff_hunk": "@@ -140,6 +140,41 @@ def flush(self) -> bytes:\n             raise DecodingError(str(exc)) from exc\n \n \n+class ZStandardDecoder(ContentDecoder):\n+    \"\"\"\n+    Handle 'zstd' RFC 8878 decoding.\n+\n+    Requires `pip install zstandard`.\n+    Can be installed as a dependency of httpx using `pip install httpx[zstd]`.\n+    \"\"\"\n+\n+    def __init__(self) -> None:\n+        if zstd is False:  # pragma: no cover\n+            raise ImportError(\n+                \"Using 'ZStandardDecoder', ...\"\n+                \"Make sure to install httpx using `pip install httpx[zstd]`.\"\n+            ) from None\n+\n+        self.decompressor = zstd.ZstdDecompressor().decompressobj()\n+\n+    def decode(self, data: bytes) -> bytes:\n+        try:\n+            data_parts = [self.decompressor.decompress(data)]\n+            while self.decompressor.eof and self.decompressor.unused_data:\n+                unused_data = self.decompressor.unused_data\n+                self.decompressor = zstd.ZstdDecompressor().decompressobj()\n+                data_parts.append(self.decompressor.decompress(unused_data))",
      "comment": "I may be wrong about this one. But wouldn't read_across_frames=True simplify this logic (since it will allow to read multiple frames)?",
      "comment_id": 1518812853,
      "user": "Zaczero",
      "created_at": "2024-03-10T10:19:09Z",
      "url": "https://github.com/encode/httpx/pull/3139#discussion_r1518812853"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3139,
      "file_path": "httpx/_compat.py",
      "line": 35,
      "side": "RIGHT",
      "diff_hunk": "@@ -17,6 +18,23 @@\n     except ImportError:\n         brotli = None\n \n+# Zstandard support is optional\n+try:\n+    import zstandard as zstd\n+except (AttributeError, ImportError, ValueError):  # Defensive:\n+    zstd = False\n+else:\n+    # The package 'zstandard' added the 'eof' property starting\n+    # in v0.18.0 which we require to ensure a complete and\n+    # valid zstd stream was fed into the ZstdDecoder.\n+    # See: https://github.com/urllib3/urllib3/pull/2624\n+    _zstd_version = tuple(\n+        map(int, re.search(r\"^([0-9]+)\\.([0-9]+)\", zstd.__version__).groups())  # type: ignore[union-attr]\n+    )\n+    if _zstd_version < (0, 18):  # Defensive:\n+        zstd = False",
      "comment": "This is just out of my curiosity, feel free to not answer it.\r\nWhy do we need this code if we already specify zstandard>=0.18.0, wouldn't package manager guarantee it already?",
      "comment_id": 1518813076,
      "user": "Zaczero",
      "created_at": "2024-03-10T10:20:32Z",
      "url": "https://github.com/encode/httpx/pull/3139#discussion_r1518813076"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3139,
      "file_path": "httpx/_compat.py",
      "line": 35,
      "side": "RIGHT",
      "diff_hunk": "@@ -17,6 +18,23 @@\n     except ImportError:\n         brotli = None\n \n+# Zstandard support is optional\n+try:\n+    import zstandard as zstd\n+except (AttributeError, ImportError, ValueError):  # Defensive:\n+    zstd = False\n+else:\n+    # The package 'zstandard' added the 'eof' property starting\n+    # in v0.18.0 which we require to ensure a complete and\n+    # valid zstd stream was fed into the ZstdDecoder.\n+    # See: https://github.com/urllib3/urllib3/pull/2624\n+    _zstd_version = tuple(\n+        map(int, re.search(r\"^([0-9]+)\\.([0-9]+)\", zstd.__version__).groups())  # type: ignore[union-attr]\n+    )\n+    if _zstd_version < (0, 18):  # Defensive:\n+        zstd = False",
      "comment": " zstandard is an optional install. So if your `requirements.txt` just has `httpx` and not `httpx[zstd]`, and you have `zstandard==[old version]` somehow, this would prevent breakage.",
      "comment_id": 1518815892,
      "user": "mbeijen",
      "created_at": "2024-03-10T10:30:56Z",
      "url": "https://github.com/encode/httpx/pull/3139#discussion_r1518815892"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3139,
      "file_path": "httpx/_decoders.py",
      "line": 165,
      "side": "RIGHT",
      "diff_hunk": "@@ -140,6 +140,43 @@ def flush(self) -> bytes:\n             raise DecodingError(str(exc)) from exc\n \n \n+class ZStandardDecoder(ContentDecoder):\n+    \"\"\"\n+    Handle 'zstd' RFC 8878 decoding.\n+\n+    Requires `pip install zstandard`.\n+    Can be installed as a dependency of httpx using `pip install httpx[zstd]`.\n+    \"\"\"\n+\n+    def __init__(self) -> None:\n+        if zstd is None:  # pragma: no cover\n+            raise ImportError(\n+                \"Using 'ZStandardDecoder', ...\"\n+                \"Make sure to install httpx using `pip install httpx[zstd]`.\"\n+            ) from None\n+\n+        self.decompressor = zstd.ZstdDecompressor().decompressobj()\n+\n+    def decode(self, data: bytes) -> bytes:\n+        assert zstd is not None\n+        output = io.BytesIO()\n+        try:\n+            output.write(self.decompressor.decompress(data))",
      "comment": "One less function call :slightly_smiling_face:\r\n\r\n```suggestion\r\n        try:\r\n            output = io.BytesIO(self.decompressor.decompress(data))\r\n```",
      "comment_id": 1518817642,
      "user": "Zaczero",
      "created_at": "2024-03-10T10:40:54Z",
      "url": "https://github.com/encode/httpx/pull/3139#discussion_r1518817642"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3139,
      "file_path": "httpx/_decoders.py",
      "line": 167,
      "side": "RIGHT",
      "diff_hunk": "@@ -140,6 +140,41 @@ def flush(self) -> bytes:\n             raise DecodingError(str(exc)) from exc\n \n \n+class ZStandardDecoder(ContentDecoder):\n+    \"\"\"\n+    Handle 'zstd' RFC 8878 decoding.\n+\n+    Requires `pip install zstandard`.\n+    Can be installed as a dependency of httpx using `pip install httpx[zstd]`.\n+    \"\"\"\n+\n+    def __init__(self) -> None:\n+        if zstd is False:  # pragma: no cover\n+            raise ImportError(\n+                \"Using 'ZStandardDecoder', ...\"\n+                \"Make sure to install httpx using `pip install httpx[zstd]`.\"\n+            ) from None\n+\n+        self.decompressor = zstd.ZstdDecompressor().decompressobj()\n+\n+    def decode(self, data: bytes) -> bytes:\n+        try:\n+            data_parts = [self.decompressor.decompress(data)]\n+            while self.decompressor.eof and self.decompressor.unused_data:\n+                unused_data = self.decompressor.unused_data\n+                self.decompressor = zstd.ZstdDecompressor().decompressobj()\n+                data_parts.append(self.decompressor.decompress(unused_data))",
      "comment": "I'm not exactly sure what happens, but if I try to use `read_across_frames` I get decoding errors. Also, please note I've copied this logic from urllib3 so it is \"Best Practice\" :-) or at least proven to be working.\r\n\r\nI would be open for suggestions of course!",
      "comment_id": 1518821040,
      "user": "mbeijen",
      "created_at": "2024-03-10T10:59:41Z",
      "url": "https://github.com/encode/httpx/pull/3139#discussion_r1518821040"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3139,
      "file_path": "httpx/_compat.py",
      "line": 38,
      "side": "RIGHT",
      "diff_hunk": "@@ -17,6 +20,24 @@\n     except ImportError:\n         brotli = None\n \n+# Zstandard support is optional\n+zstd: Optional[ModuleType] = None\n+try:\n+    import zstandard as zstd\n+except (AttributeError, ImportError, ValueError):  # Defensive:\n+    zstd = None\n+else:\n+    # The package 'zstandard' added the 'eof' property starting\n+    # in v0.18.0 which we require to ensure a complete and\n+    # valid zstd stream was fed into the ZstdDecoder.\n+    # See: https://github.com/urllib3/urllib3/pull/2624\n+    _zstd_version = tuple(\n+        map(int, re.search(r\"^([0-9]+)\\.([0-9]+)\", zstd.__version__).groups())  # type: ignore[union-attr]\n+    )\n+    if _zstd_version < (0, 18):  # Defensive:\n+        zstd = None",
      "comment": "This might be overly defensive? Can we pin >= 0.18 in the requirements instead?",
      "comment_id": 1524997549,
      "user": "lovelydinosaur",
      "created_at": "2024-03-14T14:38:46Z",
      "url": "https://github.com/encode/httpx/pull/3139#discussion_r1524997549"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3139,
      "file_path": "httpx/_compat.py",
      "line": 38,
      "side": "RIGHT",
      "diff_hunk": "@@ -17,6 +20,24 @@\n     except ImportError:\n         brotli = None\n \n+# Zstandard support is optional\n+zstd: Optional[ModuleType] = None\n+try:\n+    import zstandard as zstd\n+except (AttributeError, ImportError, ValueError):  # Defensive:\n+    zstd = None\n+else:\n+    # The package 'zstandard' added the 'eof' property starting\n+    # in v0.18.0 which we require to ensure a complete and\n+    # valid zstd stream was fed into the ZstdDecoder.\n+    # See: https://github.com/urllib3/urllib3/pull/2624\n+    _zstd_version = tuple(\n+        map(int, re.search(r\"^([0-9]+)\\.([0-9]+)\", zstd.__version__).groups())  # type: ignore[union-attr]\n+    )\n+    if _zstd_version < (0, 18):  # Defensive:\n+        zstd = None",
      "comment": "I've asked a similar question already and got this answer:\r\n\r\nhttps://github.com/encode/httpx/pull/3139#discussion_r1518815892\r\n\r\n> zstandard is an optional install. So if your `requirements.txt` just has `httpx` and not `httpx[zstd]`, and you have `zstandard==[old version]` somehow, this would prevent breakage.\r\n\r\nBasically the idea is that the optional dependency pin is optional and does not guarantee that the given dependency version will be installed. This check would only be redundant if we made zstandard a hard dependency (one not requiring httpx[zstandard]).\r\n\r\nThe same check [exists](https://github.com/urllib3/urllib3/blob/733f638a2faa02b4ff8a9f3b5668949d39396b8b/src/urllib3/response.py#L28-L43) in urllib3.\r\n\r\nPersonally, I +1 the extra safety at the cost of minimal startup delay. :slightly_smiling_face: ",
      "comment_id": 1525232707,
      "user": "Zaczero",
      "created_at": "2024-03-14T17:07:51Z",
      "url": "https://github.com/encode/httpx/pull/3139#discussion_r1525232707"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3139,
      "file_path": "httpx/_compat.py",
      "line": 38,
      "side": "RIGHT",
      "diff_hunk": "@@ -17,6 +20,24 @@\n     except ImportError:\n         brotli = None\n \n+# Zstandard support is optional\n+zstd: Optional[ModuleType] = None\n+try:\n+    import zstandard as zstd\n+except (AttributeError, ImportError, ValueError):  # Defensive:\n+    zstd = None\n+else:\n+    # The package 'zstandard' added the 'eof' property starting\n+    # in v0.18.0 which we require to ensure a complete and\n+    # valid zstd stream was fed into the ZstdDecoder.\n+    # See: https://github.com/urllib3/urllib3/pull/2624\n+    _zstd_version = tuple(\n+        map(int, re.search(r\"^([0-9]+)\\.([0-9]+)\", zstd.__version__).groups())  # type: ignore[union-attr]\n+    )\n+    if _zstd_version < (0, 18):  # Defensive:\n+        zstd = None",
      "comment": "Okay yep. Main thing is coverage needs addressing.",
      "comment_id": 1525274642,
      "user": "lovelydinosaur",
      "created_at": "2024-03-14T17:39:31Z",
      "url": "https://github.com/encode/httpx/pull/3139#discussion_r1525274642"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3245,
      "file_path": "httpx/_api.py",
      "line": 23,
      "side": "RIGHT",
      "diff_hunk": "@@ -18,9 +18,9 @@\n     RequestData,\n     RequestFiles,\n     TimeoutTypes,\n-    URLTypes,\n     VerifyTypes,\n )\n+from ._urls import URL",
      "comment": "I'd only use that if it was required to avoid a cyclical dependency.",
      "comment_id": 1688184272,
      "user": "lovelydinosaur",
      "created_at": "2024-07-23T14:36:53Z",
      "url": "https://github.com/encode/httpx/pull/3245#discussion_r1688184272"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3064,
      "file_path": "tests/test_utils.py",
      "line": 242,
      "side": "RIGHT",
      "diff_hunk": "@@ -234,21 +233,39 @@ def test_not_same_origin():\n \n \n def test_is_https_redirect():\n-    url = httpx.URL(\"http://example.com\")\n-    location = httpx.URL(\"https://example.com\")\n-    assert is_https_redirect(url, location)\n+    url = httpx.URL(\"https://example.com\")\n+    request = httpx.Request(\n+        \"GET\", \"http://example.com\", headers={\"Authorization\": \"empty\"}\n+    )\n+\n+    client = httpx.Client()\n+    headers = client._redirect_headers(request, url, \"GET\")",
      "comment": "Hrm. Is there a way around that allows us to test this against public API?",
      "comment_id": 1453218472,
      "user": "lovelydinosaur",
      "created_at": "2024-01-16T10:19:53Z",
      "url": "https://github.com/encode/httpx/pull/3064#discussion_r1453218472"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3064,
      "file_path": "tests/test_utils.py",
      "line": 242,
      "side": "RIGHT",
      "diff_hunk": "@@ -234,21 +233,39 @@ def test_not_same_origin():\n \n \n def test_is_https_redirect():\n-    url = httpx.URL(\"http://example.com\")\n-    location = httpx.URL(\"https://example.com\")\n-    assert is_https_redirect(url, location)\n+    url = httpx.URL(\"https://example.com\")\n+    request = httpx.Request(\n+        \"GET\", \"http://example.com\", headers={\"Authorization\": \"empty\"}\n+    )\n+\n+    client = httpx.Client()\n+    headers = client._redirect_headers(request, url, \"GET\")",
      "comment": "Might be that we're okay with leaning on implementation details a little bit, certainly not a terrible trade-off to make. (I think we already have some instances of this in our test cases right?)",
      "comment_id": 1453220170,
      "user": "lovelydinosaur",
      "created_at": "2024-01-16T10:21:13Z",
      "url": "https://github.com/encode/httpx/pull/3064#discussion_r1453220170"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3064,
      "file_path": "tests/test_utils.py",
      "line": 242,
      "side": "RIGHT",
      "diff_hunk": "@@ -234,21 +233,39 @@ def test_not_same_origin():\n \n \n def test_is_https_redirect():\n-    url = httpx.URL(\"http://example.com\")\n-    location = httpx.URL(\"https://example.com\")\n-    assert is_https_redirect(url, location)\n+    url = httpx.URL(\"https://example.com\")\n+    request = httpx.Request(\n+        \"GET\", \"http://example.com\", headers={\"Authorization\": \"empty\"}\n+    )\n+\n+    client = httpx.Client()\n+    headers = client._redirect_headers(request, url, \"GET\")",
      "comment": "Also, we already use private-accessors in another test:\r\nhttps://github.com/encode/httpx/blob/4f6edf36e93fd9f83ff95b065718fd6bd0c4d3c5/tests/client/test_proxies.py#L333-L338",
      "comment_id": 1453483159,
      "user": "T-256",
      "created_at": "2024-01-16T14:11:05Z",
      "url": "https://github.com/encode/httpx/pull/3064#discussion_r1453483159"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 1574,
      "file_path": "httpx/_client.py",
      "line": 736,
      "side": "RIGHT",
      "diff_hunk": "@@ -731,6 +731,14 @@ def request(\n \n         [0]: /advanced/#merging-of-configuration\n         \"\"\"\n+        if cookies is not None:\n+            message = (\n+                \"Setting per-request cookies=... is being deprecated, because \"",
      "comment": "This would be better as\r\n```suggestion\r\n                \"Setting per-request cookies=<...> is being deprecated, because \"\r\n```\r\nfor better language flow, I think (and similar to the `content=<...>` message in https://github.com/encode/httpx/pull/1573/files#diff-361c5daf6e5401b987414c619d003a20ea88f74fe9da50cbb2da72c337aeb290R152)",
      "comment_id": 613343499,
      "user": "StephenBrown2",
      "created_at": "2021-04-14T15:18:40Z",
      "url": "https://github.com/encode/httpx/pull/1574#discussion_r613343499"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3045,
      "file_path": "httpx/_auth.py",
      "line": 285,
      "side": "RIGHT",
      "diff_hunk": "@@ -280,7 +280,7 @@ def digest(data: bytes) -> bytes:\n \n         qop = self._resolve_qop(challenge.qop, request=request)\n         if qop is None:\n-            digest_data = [HA1, challenge.nonce, HA2]\n+            digest_data = [challenge.nonce, HA2]\n         else:\n             digest_data = [challenge.nonce, nc_value, cnonce, qop, HA2]",
      "comment": "Looking at the curl code, seems like this change should be the other way around(?)...\r\n\r\n```python\r\n        if qop is None:\r\n            digest_data = [HA1, challenge.nonce, HA2]\r\n        else:\r\n            digest_data = [HA1, challenge.nonce, nc_value, cnonce, qop, HA2]\r\n```\r\n\r\nAnd then...\r\n\r\n```python\r\n        format_args = {\r\n            \"username\": self._username,\r\n            \"realm\": challenge.realm,\r\n            \"nonce\": challenge.nonce,\r\n            \"uri\": path,\r\n            \"response\": digest(key_digest),\r\n            \"algorithm\": challenge.algorithm.encode(),\r\n        }\r\n```",
      "comment_id": 1444454071,
      "user": "lovelydinosaur",
      "created_at": "2024-01-08T11:01:34Z",
      "url": "https://github.com/encode/httpx/pull/3045#discussion_r1444454071"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3045,
      "file_path": "httpx/_auth.py",
      "line": 285,
      "side": "RIGHT",
      "diff_hunk": "@@ -280,7 +280,7 @@ def digest(data: bytes) -> bytes:\n \n         qop = self._resolve_qop(challenge.qop, request=request)\n         if qop is None:\n-            digest_data = [HA1, challenge.nonce, HA2]\n+            digest_data = [challenge.nonce, HA2]\n         else:\n             digest_data = [challenge.nonce, nc_value, cnonce, qop, HA2]",
      "comment": "Yeah, initially I wanted to avoid touching the other branch (so I don't break it accidentally), but I agree the curl way is more readable. I also add the comments.",
      "comment_id": 1444577834,
      "user": "the-ress",
      "created_at": "2024-01-08T12:50:09Z",
      "url": "https://github.com/encode/httpx/pull/3045#discussion_r1444577834"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3045,
      "file_path": "tests/test_auth.py",
      "line": 242,
      "side": "RIGHT",
      "diff_hunk": "@@ -140,3 +140,168 @@ def test_digest_auth_setting_cookie_in_request():\n     )\n     with pytest.raises(StopIteration):\n         flow.send(response)\n+\n+\n+def test_digest_auth_rfc_2069():\n+    # Example from https://datatracker.ietf.org/doc/html/rfc2069#section-2.4\n+    # with corrected response from https://www.rfc-editor.org/errata/eid749\n+\n+    auth = httpx.DigestAuth(username=\"Mufasa\", password=\"CircleOfLife\")\n+    request = httpx.Request(\"GET\", \"https://www.example.com/dir/index.html\")\n+\n+    # The initial request should not include an auth header.\n+    flow = auth.sync_auth_flow(request)\n+    request = next(flow)\n+    assert \"Authorization\" not in request.headers\n+\n+    # If a 401 response is returned, then a digest auth request is made.\n+    headers = {\n+        \"WWW-Authenticate\": (\n+            'Digest realm=\"testrealm@host.com\", '\n+            'nonce=\"dcd98b7102dd2f0e8b11d0f600bfb0c093\", '\n+            'opaque=\"5ccc069c403ebaf9f0171e9517f40e41\"'\n+        )\n+    }\n+    response = httpx.Response(\n+        content=b\"Auth required\", status_code=401, headers=headers, request=request\n+    )\n+    request = flow.send(response)\n+    assert request.headers[\"Authorization\"].startswith(\"Digest\")\n+    assert 'username=\"Mufasa\"' in request.headers[\"Authorization\"]\n+    assert 'realm=\"testrealm@host.com\"' in request.headers[\"Authorization\"]\n+    assert (\n+        'nonce=\"dcd98b7102dd2f0e8b11d0f600bfb0c093\"' in request.headers[\"Authorization\"]\n+    )\n+    assert 'uri=\"/dir/index.html\"' in request.headers[\"Authorization\"]\n+    assert (\n+        'opaque=\"5ccc069c403ebaf9f0171e9517f40e41\"' in request.headers[\"Authorization\"]\n+    )\n+    assert (\n+        'response=\"1949323746fe6a43ef61f9606e7febea\"'\n+        in request.headers[\"Authorization\"]\n+    )\n+\n+    # No other requests are made.\n+    response = httpx.Response(content=b\"Hello, world!\", status_code=200)\n+    with pytest.raises(StopIteration):\n+        flow.send(response)\n+\n+\n+def test_digest_auth_rfc_7616_md5(monkeypatch):\n+    # Example from https://datatracker.ietf.org/doc/html/rfc7616#section-3.9.1\n+\n+    def mock_get_client_nonce(nonce_count: int, nonce: bytes) -> bytes:\n+        return \"f2/wE4q74E6zIJEtWaHKaf5wv/H5QzzpXusqGemxURZJ\".encode()\n+\n+    auth = httpx.DigestAuth(username=\"Mufasa\", password=\"Circle of Life\")\n+    monkeypatch.setattr(auth, \"_get_client_nonce\", mock_get_client_nonce)\n+\n+    request = httpx.Request(\"GET\", \"https://www.example.com/dir/index.html\")\n+\n+    # The initial request should not include an auth header.\n+    flow = auth.sync_auth_flow(request)\n+    request = next(flow)\n+    assert \"Authorization\" not in request.headers\n+\n+    # If a 401 response is returned, then a digest auth request is made.\n+    headers = {\n+        \"WWW-Authenticate\": (\n+            'Digest realm=\"http-auth@example.org\", '\n+            'qop=\"auth, auth-int\", '\n+            \"algorithm=MD5, \"\n+            'nonce=\"7ypf/xlj9XXwfDPEoM4URrv/xwf94BcCAzFZH4GiTo0v\", '\n+            'opaque=\"FQhe/qaU925kfnzjCev0ciny7QMkPqMAFRtzCUYo5tdS\"'\n+        )\n+    }\n+    response = httpx.Response(\n+        content=b\"Auth required\", status_code=401, headers=headers, request=request\n+    )\n+    request = flow.send(response)\n+    assert request.headers[\"Authorization\"].startswith(\"Digest\")\n+    assert 'username=\"Mufasa\"' in request.headers[\"Authorization\"]\n+    assert 'realm=\"http-auth@example.org\"' in request.headers[\"Authorization\"]\n+    assert 'uri=\"/dir/index.html\"' in request.headers[\"Authorization\"]\n+    assert \"algorithm=MD5\" in request.headers[\"Authorization\"]\n+    assert (\n+        'nonce=\"7ypf/xlj9XXwfDPEoM4URrv/xwf94BcCAzFZH4GiTo0v\"'\n+        in request.headers[\"Authorization\"]\n+    )\n+    assert \"nc=00000001\" in request.headers[\"Authorization\"]\n+    assert (\n+        'cnonce=\"f2/wE4q74E6zIJEtWaHKaf5wv/H5QzzpXusqGemxURZJ\"'\n+        in request.headers[\"Authorization\"]\n+    )\n+    assert \"qop=auth\" in request.headers[\"Authorization\"]\n+    assert (\n+        'opaque=\"FQhe/qaU925kfnzjCev0ciny7QMkPqMAFRtzCUYo5tdS\"'\n+        in request.headers[\"Authorization\"]\n+    )\n+    assert (\n+        'response=\"8ca523f5e9506fed4657c9700eebdbec\"'\n+        in request.headers[\"Authorization\"]\n+    )",
      "comment": "These tests are fantastic, thanks!\r\n\r\nAre we able to do a literal `assert request.headers[\"Authorization\"] == ...` test here or is the ordering that we're returning different to the example in the RFC?",
      "comment_id": 1445998305,
      "user": "lovelydinosaur",
      "created_at": "2024-01-09T11:56:24Z",
      "url": "https://github.com/encode/httpx/pull/3045#discussion_r1445998305"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3045,
      "file_path": "tests/test_auth.py",
      "line": 242,
      "side": "RIGHT",
      "diff_hunk": "@@ -140,3 +140,168 @@ def test_digest_auth_setting_cookie_in_request():\n     )\n     with pytest.raises(StopIteration):\n         flow.send(response)\n+\n+\n+def test_digest_auth_rfc_2069():\n+    # Example from https://datatracker.ietf.org/doc/html/rfc2069#section-2.4\n+    # with corrected response from https://www.rfc-editor.org/errata/eid749\n+\n+    auth = httpx.DigestAuth(username=\"Mufasa\", password=\"CircleOfLife\")\n+    request = httpx.Request(\"GET\", \"https://www.example.com/dir/index.html\")\n+\n+    # The initial request should not include an auth header.\n+    flow = auth.sync_auth_flow(request)\n+    request = next(flow)\n+    assert \"Authorization\" not in request.headers\n+\n+    # If a 401 response is returned, then a digest auth request is made.\n+    headers = {\n+        \"WWW-Authenticate\": (\n+            'Digest realm=\"testrealm@host.com\", '\n+            'nonce=\"dcd98b7102dd2f0e8b11d0f600bfb0c093\", '\n+            'opaque=\"5ccc069c403ebaf9f0171e9517f40e41\"'\n+        )\n+    }\n+    response = httpx.Response(\n+        content=b\"Auth required\", status_code=401, headers=headers, request=request\n+    )\n+    request = flow.send(response)\n+    assert request.headers[\"Authorization\"].startswith(\"Digest\")\n+    assert 'username=\"Mufasa\"' in request.headers[\"Authorization\"]\n+    assert 'realm=\"testrealm@host.com\"' in request.headers[\"Authorization\"]\n+    assert (\n+        'nonce=\"dcd98b7102dd2f0e8b11d0f600bfb0c093\"' in request.headers[\"Authorization\"]\n+    )\n+    assert 'uri=\"/dir/index.html\"' in request.headers[\"Authorization\"]\n+    assert (\n+        'opaque=\"5ccc069c403ebaf9f0171e9517f40e41\"' in request.headers[\"Authorization\"]\n+    )\n+    assert (\n+        'response=\"1949323746fe6a43ef61f9606e7febea\"'\n+        in request.headers[\"Authorization\"]\n+    )\n+\n+    # No other requests are made.\n+    response = httpx.Response(content=b\"Hello, world!\", status_code=200)\n+    with pytest.raises(StopIteration):\n+        flow.send(response)\n+\n+\n+def test_digest_auth_rfc_7616_md5(monkeypatch):\n+    # Example from https://datatracker.ietf.org/doc/html/rfc7616#section-3.9.1\n+\n+    def mock_get_client_nonce(nonce_count: int, nonce: bytes) -> bytes:\n+        return \"f2/wE4q74E6zIJEtWaHKaf5wv/H5QzzpXusqGemxURZJ\".encode()\n+\n+    auth = httpx.DigestAuth(username=\"Mufasa\", password=\"Circle of Life\")\n+    monkeypatch.setattr(auth, \"_get_client_nonce\", mock_get_client_nonce)\n+\n+    request = httpx.Request(\"GET\", \"https://www.example.com/dir/index.html\")\n+\n+    # The initial request should not include an auth header.\n+    flow = auth.sync_auth_flow(request)\n+    request = next(flow)\n+    assert \"Authorization\" not in request.headers\n+\n+    # If a 401 response is returned, then a digest auth request is made.\n+    headers = {\n+        \"WWW-Authenticate\": (\n+            'Digest realm=\"http-auth@example.org\", '\n+            'qop=\"auth, auth-int\", '\n+            \"algorithm=MD5, \"\n+            'nonce=\"7ypf/xlj9XXwfDPEoM4URrv/xwf94BcCAzFZH4GiTo0v\", '\n+            'opaque=\"FQhe/qaU925kfnzjCev0ciny7QMkPqMAFRtzCUYo5tdS\"'\n+        )\n+    }\n+    response = httpx.Response(\n+        content=b\"Auth required\", status_code=401, headers=headers, request=request\n+    )\n+    request = flow.send(response)\n+    assert request.headers[\"Authorization\"].startswith(\"Digest\")\n+    assert 'username=\"Mufasa\"' in request.headers[\"Authorization\"]\n+    assert 'realm=\"http-auth@example.org\"' in request.headers[\"Authorization\"]\n+    assert 'uri=\"/dir/index.html\"' in request.headers[\"Authorization\"]\n+    assert \"algorithm=MD5\" in request.headers[\"Authorization\"]\n+    assert (\n+        'nonce=\"7ypf/xlj9XXwfDPEoM4URrv/xwf94BcCAzFZH4GiTo0v\"'\n+        in request.headers[\"Authorization\"]\n+    )\n+    assert \"nc=00000001\" in request.headers[\"Authorization\"]\n+    assert (\n+        'cnonce=\"f2/wE4q74E6zIJEtWaHKaf5wv/H5QzzpXusqGemxURZJ\"'\n+        in request.headers[\"Authorization\"]\n+    )\n+    assert \"qop=auth\" in request.headers[\"Authorization\"]\n+    assert (\n+        'opaque=\"FQhe/qaU925kfnzjCev0ciny7QMkPqMAFRtzCUYo5tdS\"'\n+        in request.headers[\"Authorization\"]\n+    )\n+    assert (\n+        'response=\"8ca523f5e9506fed4657c9700eebdbec\"'\n+        in request.headers[\"Authorization\"]\n+    )",
      "comment": "I wouldn't want to depend on the exact order since it'd make the test more fragile with little benefit.",
      "comment_id": 1446681951,
      "user": "the-ress",
      "created_at": "2024-01-09T22:21:31Z",
      "url": "https://github.com/encode/httpx/pull/3045#discussion_r1446681951"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3042,
      "file_path": "httpx/_client.py",
      "line": 1316,
      "side": "RIGHT",
      "diff_hunk": "@@ -1311,6 +1313,8 @@ class AsyncClient(BaseClient):\n     An asynchronous HTTP client, with connection pooling, HTTP/2, redirects,\n     cookie persistence, etc.\n \n+    It can be shared between threads.",
      "comment": "```suggestion\r\n    It can be shared between tasks.\r\n```",
      "comment_id": 1442512639,
      "user": "karpetrosyan",
      "created_at": "2024-01-05T05:41:11Z",
      "url": "https://github.com/encode/httpx/pull/3042#discussion_r1442512639"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 3042,
      "file_path": "httpx/_client.py",
      "line": 1552,
      "side": "RIGHT",
      "diff_hunk": "@@ -1544,6 +1548,15 @@ async def request(\n \n         [0]: /advanced/#merging-of-configuration\n         \"\"\"\n+\n+        if cookies is not None:",
      "comment": "```suggestion\r\n        if cookies is not None:  # pragma: no cover\r\n```",
      "comment_id": 1442513863,
      "user": "karpetrosyan",
      "created_at": "2024-01-05T05:44:18Z",
      "url": "https://github.com/encode/httpx/pull/3042#discussion_r1442513863"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_urlparse.py",
      "line": 454,
      "side": "RIGHT",
      "diff_hunk": "@@ -449,6 +448,32 @@ def quote(string: str, safe: str = \"/\") -> str:\n     )\n \n \n+def quote(string: str, safe: str = \"/\") -> str:\n+    \"\"\"\n+    Use percent-encoding to quote a string, omitting existing '%xx' escape sequences.\n+    \"\"\"",
      "comment": "@tomchristie - perhaps this could do with some code comments?\r\n\r\nAn example of what we're ending up with here is...\r\n\r\n```python\r\ninput = \"abc%20de f\"\r\noutput = \"\".join([percent_encoded(\"abc\"), \"%20\", percent_encoded(\"de f\")])\r\nassert quote(input) == output",
      "comment_id": 1420326415,
      "user": "lovelydinosaur",
      "created_at": "2023-12-08T11:44:52Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1420326415"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_urlparse.py",
      "line": 497,
      "side": "RIGHT",
      "diff_hunk": "@@ -464,4 +489,9 @@ def urlencode(items: typing.List[typing.Tuple[str, str]]) -> str:\n     - https://github.com/encode/httpx/issues/2721\n     - https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlencode\n     \"\"\"\n-    return \"&\".join([quote(k, safe=\"\") + \"=\" + quote(v, safe=\"\") for k, v in items])\n+    return \"&\".join(\n+        [\n+            percent_encoded(k, safe=\"\") + \"=\" + percent_encoded(v, safe=\"\")\n+            for k, v in items\n+        ]\n+    )",
      "comment": "Comment to the gallery...\r\n\r\nWe've switch from `quote` to `percent_encoded` here, because we *always* want to percent encode items that are being provided as form inputs, with `params = {}`.\r\n",
      "comment_id": 1420329649,
      "user": "lovelydinosaur",
      "created_at": "2023-12-08T11:48:11Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1420329649"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_urlparse.py",
      "line": 454,
      "side": "RIGHT",
      "diff_hunk": "@@ -449,6 +448,32 @@ def quote(string: str, safe: str = \"/\") -> str:\n     )\n \n \n+def quote(string: str, safe: str = \"/\") -> str:\n+    \"\"\"\n+    Use percent-encoding to quote a string, omitting existing '%xx' escape sequences.\n+    \"\"\"",
      "comment": "I see code comments more difficult to read than that simple straightforward description.\r\nPerhaps `safe` parameter needs more info here(?)",
      "comment_id": 1421693032,
      "user": "T-256",
      "created_at": "2023-12-10T06:35:15Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1421693032"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_urlparse.py",
      "line": 443,
      "side": "RIGHT",
      "diff_hunk": "@@ -432,13 +432,12 @@ def is_safe(string: str, safe: str = \"/\") -> bool:\n         if char not in NON_ESCAPED_CHARS:\n             return False\n \n-    # Any '%' characters must be valid '%xx' escape sequences.\n-    return string.count(\"%\") == len(PERCENT_ENCODED_REGEX.findall(string))\n+    return True\n \n \n-def quote(string: str, safe: str = \"/\") -> str:\n+def percent_encoded(string: str, safe: str = \"/\") -> str:\n     \"\"\"\n-    Use percent-encoding to quote a string if required.\n+    Use percent-encoding to quote a string.\n     \"\"\"\n     if is_safe(string, safe=safe):\n         return string",
      "comment": "I suggest use minimal filtering instead of separated one-time function.\r\n```py\r\n    if all(char in NON_ESCAPED_CHARS for char in string):\r\n        return string\r\n```\r\n\r\nI also noticed `NON_ESCAPED_CHARS` name in `is_safe` function has different value than it is in `percent_encoded`.",
      "comment_id": 1421693601,
      "user": "T-256",
      "created_at": "2023-12-10T06:41:37Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1421693601"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_urlparse.py",
      "line": 474,
      "side": "RIGHT",
      "diff_hunk": "@@ -449,6 +448,32 @@ def quote(string: str, safe: str = \"/\") -> str:\n     )\n \n \n+def quote(string: str, safe: str = \"/\") -> str:\n+    \"\"\"\n+    Use percent-encoding to quote a string, omitting existing '%xx' escape sequences.\n+    \"\"\"\n+    parts = []\n+    current_position = 0\n+    for match in re.finditer(PERCENT_ENCODED_REGEX, string):\n+        start_position, end_position = match.start(), match.end()\n+        matched_text = match.group(0)\n+        # Add any text up to the '%xx' escape sequence.\n+        if start_position != current_position:\n+            leading_text = string[current_position:start_position]\n+            parts.append(percent_encoded(leading_text, safe=safe))\n+\n+        # Add the '%xx' escape sequence.\n+        parts.append(matched_text)\n+        current_position = end_position\n+\n+    # Add any text after the final '%xx' escape sequence.\n+    if current_position != len(string):\n+        trailing_text = string[current_position:]\n+        parts.append(percent_encoded(trailing_text, safe=safe))\n+\n+    return \"\".join(parts)",
      "comment": "`parts` could be string. `parts +=` instead of `parts.append`",
      "comment_id": 1421694231,
      "user": "T-256",
      "created_at": "2023-12-10T06:48:27Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1421694231"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_urlparse.py",
      "line": 443,
      "side": "RIGHT",
      "diff_hunk": "@@ -432,13 +432,12 @@ def is_safe(string: str, safe: str = \"/\") -> bool:\n         if char not in NON_ESCAPED_CHARS:\n             return False\n \n-    # Any '%' characters must be valid '%xx' escape sequences.\n-    return string.count(\"%\") == len(PERCENT_ENCODED_REGEX.findall(string))\n+    return True\n \n \n-def quote(string: str, safe: str = \"/\") -> str:\n+def percent_encoded(string: str, safe: str = \"/\") -> str:\n     \"\"\"\n-    Use percent-encoding to quote a string if required.\n+    Use percent-encoding to quote a string.\n     \"\"\"\n     if is_safe(string, safe=safe):\n         return string",
      "comment": "Sure. I'd like to treat performance improvements separately to this.\r\nI'll followup with some further work once we've got the behavioural changes in.",
      "comment_id": 1422158955,
      "user": "lovelydinosaur",
      "created_at": "2023-12-11T09:21:54Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1422158955"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_urlparse.py",
      "line": 474,
      "side": "RIGHT",
      "diff_hunk": "@@ -449,6 +448,32 @@ def quote(string: str, safe: str = \"/\") -> str:\n     )\n \n \n+def quote(string: str, safe: str = \"/\") -> str:\n+    \"\"\"\n+    Use percent-encoding to quote a string, omitting existing '%xx' escape sequences.\n+    \"\"\"\n+    parts = []\n+    current_position = 0\n+    for match in re.finditer(PERCENT_ENCODED_REGEX, string):\n+        start_position, end_position = match.start(), match.end()\n+        matched_text = match.group(0)\n+        # Add any text up to the '%xx' escape sequence.\n+        if start_position != current_position:\n+            leading_text = string[current_position:start_position]\n+            parts.append(percent_encoded(leading_text, safe=safe))\n+\n+        # Add the '%xx' escape sequence.\n+        parts.append(matched_text)\n+        current_position = end_position\n+\n+    # Add any text after the final '%xx' escape sequence.\n+    if current_position != len(string):\n+        trailing_text = string[current_position:]\n+        parts.append(percent_encoded(trailing_text, safe=safe))\n+\n+    return \"\".join(parts)",
      "comment": "It could, yes. I've gone with this pattern because in the past we've seen performance issues with the `+=` pattern, that a `.append() ... \"\".join()` pattern resolves. Might not be the case in this context, since we've got strict limits on the allowable string lengths in URLs. But... let's handle any performance related considerations separately to the behavioural fixes.",
      "comment_id": 1422164211,
      "user": "lovelydinosaur",
      "created_at": "2023-12-11T09:25:09Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1422164211"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_transports/asgi.py",
      "line": 3,
      "side": "LEFT",
      "diff_hunk": "@@ -1,7 +1,5 @@\n import typing\n \n-import sniffio",
      "comment": "`_utils.py` also imports sniffio as top-level.\r\nCould we consider add httpcore's [`current_async_library`](https://github.com/encode/httpcore/blob/2fcd062df71555cc7de55774c6dc137551eb8692/httpcore/_synchronization.py#L21) in httpx?",
      "comment_id": 1423025866,
      "user": "T-256",
      "created_at": "2023-12-11T19:27:01Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1423025866"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_urlparse.py",
      "line": 264,
      "side": "RIGHT",
      "diff_hunk": "@@ -263,7 +263,7 @@ def urlparse(url: str = \"\", **kwargs: typing.Optional[str]) -> ParseResult:\n     # We also exclude '/' because it is more robust to replace it with a percent\n     # encoding despite it not being a requirement of the spec.",
      "comment": "Doesn't this comment become incorrect with this change?",
      "comment_id": 1424884213,
      "user": "jkseppan",
      "created_at": "2023-12-13T06:01:36Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1424884213"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_urlparse.py",
      "line": 449,
      "side": "RIGHT",
      "diff_hunk": "@@ -449,6 +446,39 @@ def quote(string: str, safe: str = \"/\") -> str:\n     )\n \n \n+def quote(string: str, safe: str = \"/\") -> str:",
      "comment": "I believe we should also add unit tests for these functions, rather than simply testing them with `httpx.URL`. \r\nThis would be a more robust approach, in my opinion.\r\n",
      "comment_id": 1425186493,
      "user": "karpetrosyan",
      "created_at": "2023-12-13T10:55:47Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1425186493"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_urlparse.py",
      "line": 449,
      "side": "RIGHT",
      "diff_hunk": "@@ -449,6 +446,39 @@ def quote(string: str, safe: str = \"/\") -> str:\n     )\n \n \n+def quote(string: str, safe: str = \"/\") -> str:",
      "comment": "IMO current approach is fine.\r\n\r\n> This is clearly a code-smell, because our test cases ought to be tests against our public API, rather than testing implementation details. Perhaps there's some cases where it's a necessary hack, but... perhaps not?\r\n\r\n\r\nfrom https://github.com/encode/httpx/issues/2492#issue-1478857204",
      "comment_id": 1425847949,
      "user": "T-256",
      "created_at": "2023-12-13T20:23:49Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1425847949"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_urlparse.py",
      "line": 449,
      "side": "RIGHT",
      "diff_hunk": "@@ -449,6 +446,39 @@ def quote(string: str, safe: str = \"/\") -> str:\n     )\n \n \n+def quote(string: str, safe: str = \"/\") -> str:",
      "comment": "I agree testing the public API should be sufficient unless something private is particularly expensive to test via the public API.",
      "comment_id": 1426015469,
      "user": "zanieb",
      "created_at": "2023-12-14T00:20:26Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1426015469"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2990,
      "file_path": "httpx/_urlparse.py",
      "line": 449,
      "side": "RIGHT",
      "diff_hunk": "@@ -449,6 +446,39 @@ def quote(string: str, safe: str = \"/\") -> str:\n     )\n \n \n+def quote(string: str, safe: str = \"/\") -> str:",
      "comment": "It's a matter of preference, but if we encounter regression in our `httpx.URL` tests, we will go through these functions and find the method that isn't working properly, which is why unit tests are useful.",
      "comment_id": 1426181241,
      "user": "karpetrosyan",
      "created_at": "2023-12-14T05:14:41Z",
      "url": "https://github.com/encode/httpx/pull/2990#discussion_r1426181241"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2998,
      "file_path": "tests/test_decoders.py",
      "line": 278,
      "side": "RIGHT",
      "diff_hunk": "@@ -262,6 +273,11 @@ def test_line_decoder_crnl():\n     assert list(response.iter_lines()) == [\"12345\", \"foo bar baz\"]\n \n \n+@pytest.mark.parametrize([\"text\", \"expected\"], [(\"\", [])])\n+def test_line_decoding_edge_cases(text: str, expected: typing.List[str]) -> None:\n+    assert httpx._decoders.LineDecoder().decode(text) == expected",
      "comment": "This was the only way I could figure out how to cover an empty input to `LineDecoder.decode`.",
      "comment_id": 1422619715,
      "user": "jamesbraza",
      "created_at": "2023-12-11T15:08:15Z",
      "url": "https://github.com/encode/httpx/pull/2998#discussion_r1422619715"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2879,
      "file_path": "httpx/_transports/default.py",
      "line": 52,
      "side": "RIGHT",
      "diff_hunk": "@@ -47,7 +49,7 @@\n     WriteTimeout,\n )\n from .._models import Request, Response\n-from .._types import AsyncByteStream, CertTypes, SyncByteStream, VerifyTypes\n+from .._types import AsyncByteStream, CertTypes, ProxyTypes, SyncByteStream, VerifyTypes",
      "comment": "```suggestion\r\nfrom .._types import AsyncByteStream, CertTypes, ProxyTypes, SyncByteStream, VerifyTypes\r\nfrom .._urls import URL\r\n```",
      "comment_id": 1353991206,
      "user": "T-256",
      "created_at": "2023-10-11T04:16:34Z",
      "url": "https://github.com/encode/httpx/pull/2879#discussion_r1353991206"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2879,
      "file_path": "httpx/_types.py",
      "line": 82,
      "side": "RIGHT",
      "diff_hunk": "@@ -78,7 +78,8 @@\n     Tuple[Optional[float], Optional[float], Optional[float], Optional[float]],\n     \"Timeout\",\n ]\n-ProxiesTypes = Union[URLTypes, \"Proxy\", Dict[URLTypes, Union[None, URLTypes, \"Proxy\"]]]\n+ProxyTypes = Union[URLTypes, \"Proxy\"]\n+ProxiesTypes = Union[URLTypes, ProxyTypes, Dict[URLTypes, Union[None, ProxyTypes]]]",
      "comment": "```suggestion\r\nProxiesTypes = Union[ProxyTypes, Dict[URLTypes, Union[None, ProxyTypes]]]\r\n```",
      "comment_id": 1356443220,
      "user": "karpetrosyan",
      "created_at": "2023-10-12T08:03:28Z",
      "url": "https://github.com/encode/httpx/pull/2879#discussion_r1356443220"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2723,
      "file_path": "httpx/_urlparse.py",
      "line": 267,
      "side": "RIGHT",
      "diff_hunk": "@@ -260,8 +260,11 @@ def urlparse(url: str = \"\", **kwargs: typing.Optional[str]) -> ParseResult:\n     # For 'path' we need to drop ? and # from the GEN_DELIMS set.\n     parsed_path: str = quote(path, safe=SUB_DELIMS + \":/[]@\")\n     # For 'query' we need to drop '#' from the GEN_DELIMS set.\n+    # We also exclude '/' because it is more robust to replace it with a percent\n+    # encoding despite it not being a requirement of the spec and include '%' to\n+    # prevent duplicate encoding of previously quoted items.\n     parsed_query: typing.Optional[str] = (\n-        None if query is None else quote(query, safe=SUB_DELIMS + \":/?[]@\")\n+        None if query is None else quote(query, safe=SUB_DELIMS + \":?[]@%\")",
      "comment": "I was surprised that I needed to include `%` but it was needed to to prevent spaces converted to `%20` from being changed to `%2520` in tests.",
      "comment_id": 1207129278,
      "user": "zanieb",
      "created_at": "2023-05-26T17:39:17Z",
      "url": "https://github.com/encode/httpx/pull/2723#discussion_r1207129278"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2723,
      "file_path": "httpx/_urlparse.py",
      "line": 267,
      "side": "RIGHT",
      "diff_hunk": "@@ -260,8 +260,11 @@ def urlparse(url: str = \"\", **kwargs: typing.Optional[str]) -> ParseResult:\n     # For 'path' we need to drop ? and # from the GEN_DELIMS set.\n     parsed_path: str = quote(path, safe=SUB_DELIMS + \":/[]@\")\n     # For 'query' we need to drop '#' from the GEN_DELIMS set.\n+    # We also exclude '/' because it is more robust to replace it with a percent\n+    # encoding despite it not being a requirement of the spec and include '%' to\n+    # prevent duplicate encoding of previously quoted items.\n     parsed_query: typing.Optional[str] = (\n-        None if query is None else quote(query, safe=SUB_DELIMS + \":/?[]@\")\n+        None if query is None else quote(query, safe=SUB_DELIMS + \":?[]@%\")",
      "comment": "Let me know if there's additional test coverage that would make sense for this or if we've revealed another issue.",
      "comment_id": 1207129907,
      "user": "zanieb",
      "created_at": "2023-05-26T17:39:50Z",
      "url": "https://github.com/encode/httpx/pull/2723#discussion_r1207129907"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2723,
      "file_path": "httpx/_urlparse.py",
      "line": 267,
      "side": "RIGHT",
      "diff_hunk": "@@ -260,8 +260,11 @@ def urlparse(url: str = \"\", **kwargs: typing.Optional[str]) -> ParseResult:\n     # For 'path' we need to drop ? and # from the GEN_DELIMS set.\n     parsed_path: str = quote(path, safe=SUB_DELIMS + \":/[]@\")\n     # For 'query' we need to drop '#' from the GEN_DELIMS set.\n+    # We also exclude '/' because it is more robust to replace it with a percent\n+    # encoding despite it not being a requirement of the spec and include '%' to\n+    # prevent duplicate encoding of previously quoted items.\n     parsed_query: typing.Optional[str] = (\n-        None if query is None else quote(query, safe=SUB_DELIMS + \":/?[]@\")\n+        None if query is None else quote(query, safe=SUB_DELIMS + \":?[]@%\")",
      "comment": "I'll rephrase: Can you drop that bit from this pull request? It seems unrelated so it'd make sense to consider it separately.",
      "comment_id": 1207742623,
      "user": "lovelydinosaur",
      "created_at": "2023-05-27T07:09:05Z",
      "url": "https://github.com/encode/httpx/pull/2723#discussion_r1207742623"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2723,
      "file_path": "httpx/_urlparse.py",
      "line": 267,
      "side": "RIGHT",
      "diff_hunk": "@@ -260,8 +260,11 @@ def urlparse(url: str = \"\", **kwargs: typing.Optional[str]) -> ParseResult:\n     # For 'path' we need to drop ? and # from the GEN_DELIMS set.\n     parsed_path: str = quote(path, safe=SUB_DELIMS + \":/[]@\")\n     # For 'query' we need to drop '#' from the GEN_DELIMS set.\n+    # We also exclude '/' because it is more robust to replace it with a percent\n+    # encoding despite it not being a requirement of the spec and include '%' to\n+    # prevent duplicate encoding of previously quoted items.\n     parsed_query: typing.Optional[str] = (\n-        None if query is None else quote(query, safe=SUB_DELIMS + \":/?[]@\")\n+        None if query is None else quote(query, safe=SUB_DELIMS + \":?[]@%\")",
      "comment": "Yeah I can but then the _other_ change will make the tests fail i.e. this pull request will introduce a incorrect behavior. I don't understand why yet. I'll adjust my commit so you can see it in CI.",
      "comment_id": 1209579869,
      "user": "zanieb",
      "created_at": "2023-05-29T22:40:17Z",
      "url": "https://github.com/encode/httpx/pull/2723#discussion_r1209579869"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2723,
      "file_path": "httpx/_urlparse.py",
      "line": 267,
      "side": "RIGHT",
      "diff_hunk": "@@ -260,8 +260,11 @@ def urlparse(url: str = \"\", **kwargs: typing.Optional[str]) -> ParseResult:\n     # For 'path' we need to drop ? and # from the GEN_DELIMS set.\n     parsed_path: str = quote(path, safe=SUB_DELIMS + \":/[]@\")\n     # For 'query' we need to drop '#' from the GEN_DELIMS set.\n+    # We also exclude '/' because it is more robust to replace it with a percent\n+    # encoding despite it not being a requirement of the spec and include '%' to\n+    # prevent duplicate encoding of previously quoted items.\n     parsed_query: typing.Optional[str] = (\n-        None if query is None else quote(query, safe=SUB_DELIMS + \":/?[]@\")\n+        None if query is None else quote(query, safe=SUB_DELIMS + \":?[]@%\")",
      "comment": "> I can but then the other change will make the tests fail i.e. this pull request will introduce a incorrect behavior.\r\n\r\nOkay. That would be worthwhile, we can review from there.",
      "comment_id": 1219265789,
      "user": "lovelydinosaur",
      "created_at": "2023-06-06T09:21:42Z",
      "url": "https://github.com/encode/httpx/pull/2723#discussion_r1219265789"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2723,
      "file_path": "httpx/_urlparse.py",
      "line": 266,
      "side": "RIGHT",
      "diff_hunk": "@@ -260,8 +260,10 @@ def urlparse(url: str = \"\", **kwargs: typing.Optional[str]) -> ParseResult:\n     # For 'path' we need to drop ? and # from the GEN_DELIMS set.\n     parsed_path: str = quote(path, safe=SUB_DELIMS + \":/[]@\")\n     # For 'query' we need to drop '#' from the GEN_DELIMS set.\n+    # We also exclude '/' because it is more robust to replace it with a percent\n+    # encoding despite it not being a requirement of the spec.\n     parsed_query: typing.Optional[str] = (\n-        None if query is None else quote(query, safe=SUB_DELIMS + \":/?[]@\")\n+        None if query is None else quote(query, safe=SUB_DELIMS + \":?[]@\")",
      "comment": "This change was unnecessary. The fix was the changes below. We dont need to change an already encoded query to encode slashes. We do need to handle it when passed in as separate parameter.",
      "comment_id": 1414362854,
      "user": "elupus",
      "created_at": "2023-12-04T19:10:14Z",
      "url": "https://github.com/encode/httpx/pull/2723#discussion_r1414362854"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2909,
      "file_path": "httpx/_multipart.py",
      "line": 202,
      "side": "RIGHT",
      "diff_hunk": "@@ -200,7 +199,7 @@ def __init__(\n         boundary: typing.Optional[bytes] = None,\n     ) -> None:\n         if boundary is None:\n-            boundary = binascii.hexlify(os.urandom(16))\n+            boundary = ''.join([f'{byte:02x}' for byte in(os.urandom(16)])",
      "comment": "Oh, I see python 2 user \ud83d\ude04 \r\n```suggestion\r\n            boundary = os.urandom(16).hex()\r\n```",
      "comment_id": 1376184439,
      "user": "T-256",
      "created_at": "2023-10-30T13:03:24Z",
      "url": "https://github.com/encode/httpx/pull/2909#discussion_r1376184439"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2854,
      "file_path": "httpx/_config.py",
      "line": 135,
      "side": "LEFT",
      "diff_hunk": "@@ -128,11 +127,10 @@ def load_ssl_context_verify(self) -> ssl.SSLContext:\n \n         # Signal to server support for PHA in TLS 1.3. Raises an\n         # AttributeError if only read-only access is implemented.\n-        if sys.version_info >= (3, 8):  # pragma: no cover\n-            try:\n-                context.post_handshake_auth = True\n-            except AttributeError:  # pragma: no cover\n-                pass",
      "comment": "Python 3.7 no longer supported https://github.com/encode/httpx/pull/2813",
      "comment_id": 1330177340,
      "user": "T-256",
      "created_at": "2023-09-19T13:58:04Z",
      "url": "https://github.com/encode/httpx/pull/2854#discussion_r1330177340"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2854,
      "file_path": "httpx/_config.py",
      "line": 135,
      "side": "LEFT",
      "diff_hunk": "@@ -128,11 +127,10 @@ def load_ssl_context_verify(self) -> ssl.SSLContext:\n \n         # Signal to server support for PHA in TLS 1.3. Raises an\n         # AttributeError if only read-only access is implemented.\n-        if sys.version_info >= (3, 8):  # pragma: no cover\n-            try:\n-                context.post_handshake_auth = True\n-            except AttributeError:  # pragma: no cover\n-                pass",
      "comment": "Yep, with 3.8+, the condition `sys.version_info >= (3, 8)` is always true.",
      "comment_id": 1330191242,
      "user": "hugovk",
      "created_at": "2023-09-19T14:05:37Z",
      "url": "https://github.com/encode/httpx/pull/2854#discussion_r1330191242"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2852,
      "file_path": "tests/models/test_responses.py",
      "line": 311,
      "side": "RIGHT",
      "diff_hunk": "@@ -298,6 +298,22 @@ def test_response_force_encoding():\n     assert response.encoding == \"iso-8859-1\"\n \n \n+def test_response_force_encoding_after_text_accessed():\n+    response = httpx.Response(\n+        200,\n+        content=b\"Hello, world!\",\n+    )\n+    assert response.status_code == 200\n+    assert response.reason_phrase == \"OK\"\n+    assert response.text == \"Hello, world!\"\n+    assert response.encoding == \"utf-8\"\n+\n+    response.encoding = \"UTF8\"",
      "comment": "I'd expect the `ValueError` to be raised here. I don't think we need the conditional \"don't raise if the encoding is being set but the resulting codec won't change\".\n\nSimplicity over complexity where possible.",
      "comment_id": 1328064919,
      "user": "lovelydinosaur",
      "created_at": "2023-09-17T08:52:20Z",
      "url": "https://github.com/encode/httpx/pull/2852#discussion_r1328064919"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2716,
      "file_path": "httpx/_transports/default.py",
      "line": 31,
      "side": "RIGHT",
      "diff_hunk": "@@ -28,6 +28,7 @@\n from types import TracebackType\n \n import httpcore\n+from httpcore.backends.base import SOCKET_OPTION",
      "comment": "Let's not import that type definition, it's not documented public API.\r\n\r\nIt's be okay to instead define the socket option types here.\r\n\r\n```python\r\nSOCKET_OPTION = typing.Union[\r\n    typing.Tuple[int, int, int],\r\n    typing.Tuple[int, int, typing.Union[bytes, bytearray]],\r\n    typing.Tuple[int, int, None, int],\r\n]\r\n```",
      "comment_id": 1203667142,
      "user": "lovelydinosaur",
      "created_at": "2023-05-24T08:14:28Z",
      "url": "https://github.com/encode/httpx/pull/2716#discussion_r1203667142"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2669,
      "file_path": "tests/test_asgi.py",
      "line": 6,
      "side": "RIGHT",
      "diff_hunk": "@@ -3,6 +3,7 @@\n import pytest\n \n import httpx\n+from httpx._transports.asgi import ASGITransport",
      "comment": "We don't need the import from private API space here.\r\nWe can use `httpx.ASGITransport`, same as the other tests.",
      "comment_id": 1172572391,
      "user": "lovelydinosaur",
      "created_at": "2023-04-20T13:14:57Z",
      "url": "https://github.com/encode/httpx/pull/2669#discussion_r1172572391"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2669,
      "file_path": "tests/test_asgi.py",
      "line": 203,
      "side": "RIGHT",
      "diff_hunk": "@@ -191,3 +192,12 @@ async def read_body(scope, receive, send):\n \n     assert response.status_code == 200\n     assert disconnect\n+\n+\n+@pytest.mark.anyio\n+async def test_asgi_exc_no_raise():\n+    transport = ASGITransport(app=raise_exc, raise_app_exceptions=False)\n+    async with httpx.AsyncClient(app=raise_exc, transport=transport) as client:\n+        response = await client.get(\"http://www.example.org/\")\n+\n+        assert response.status_code == 500",
      "comment": "What's the behaviour of this test before the code change?",
      "comment_id": 1172573305,
      "user": "lovelydinosaur",
      "created_at": "2023-04-20T13:15:40Z",
      "url": "https://github.com/encode/httpx/pull/2669#discussion_r1172573305"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2669,
      "file_path": "tests/test_asgi.py",
      "line": 200,
      "side": "RIGHT",
      "diff_hunk": "@@ -191,3 +192,12 @@ async def read_body(scope, receive, send):\n \n     assert response.status_code == 200\n     assert disconnect\n+\n+\n+@pytest.mark.anyio\n+async def test_asgi_exc_no_raise():\n+    transport = ASGITransport(app=raise_exc, raise_app_exceptions=False)\n+    async with httpx.AsyncClient(app=raise_exc, transport=transport) as client:",
      "comment": "Since we're specifying `transport=...` the `app=...` parameter is redundant.\r\n\r\n```suggestion\r\n    async with httpx.AsyncClient(transport=transport) as client:\r\n```",
      "comment_id": 1172575027,
      "user": "lovelydinosaur",
      "created_at": "2023-04-20T13:16:42Z",
      "url": "https://github.com/encode/httpx/pull/2669#discussion_r1172575027"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2669,
      "file_path": "tests/test_asgi.py",
      "line": 203,
      "side": "RIGHT",
      "diff_hunk": "@@ -191,3 +192,12 @@ async def read_body(scope, receive, send):\n \n     assert response.status_code == 200\n     assert disconnect\n+\n+\n+@pytest.mark.anyio\n+async def test_asgi_exc_no_raise():\n+    transport = ASGITransport(app=raise_exc, raise_app_exceptions=False)\n+    async with httpx.AsyncClient(app=raise_exc, transport=transport) as client:\n+        response = await client.get(\"http://www.example.org/\")\n+\n+        assert response.status_code == 500",
      "comment": "Test failed with `RuntimeError` being raised from `raise_exc`",
      "comment_id": 1172689472,
      "user": "Nnonexistent",
      "created_at": "2023-04-20T14:32:59Z",
      "url": "https://github.com/encode/httpx/pull/2669#discussion_r1172689472"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2680,
      "file_path": "httpx/_utils.py",
      "line": 467,
      "side": "RIGHT",
      "diff_hunk": "@@ -464,14 +464,14 @@ def __eq__(self, other: typing.Any) -> bool:\n def is_ipv4_hostname(hostname: str) -> bool:\n     try:\n         ipaddress.IPv4Address(hostname.split(\"/\")[0])\n-    except:\n+    except ValueError:",
      "comment": "Not sure if an IndexError is required too.\r\nMaybe we can replace it with `except Exception`.",
      "comment_id": 1176504865,
      "user": "aminalaee",
      "created_at": "2023-04-25T13:16:56Z",
      "url": "https://github.com/encode/httpx/pull/2680#discussion_r1176504865"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2680,
      "file_path": "httpx/_utils.py",
      "line": 467,
      "side": "RIGHT",
      "diff_hunk": "@@ -464,14 +464,14 @@ def __eq__(self, other: typing.Any) -> bool:\n def is_ipv4_hostname(hostname: str) -> bool:\n     try:\n         ipaddress.IPv4Address(hostname.split(\"/\")[0])\n-    except:\n+    except ValueError:",
      "comment": "Technically speaking `except Exception` would guarantee the same behaviour?",
      "comment_id": 1176696378,
      "user": "michaeloliverx",
      "created_at": "2023-04-25T15:32:49Z",
      "url": "https://github.com/encode/httpx/pull/2680#discussion_r1176696378"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2680,
      "file_path": "httpx/_utils.py",
      "line": 467,
      "side": "RIGHT",
      "diff_hunk": "@@ -464,14 +464,14 @@ def __eq__(self, other: typing.Any) -> bool:\n def is_ipv4_hostname(hostname: str) -> bool:\n     try:\n         ipaddress.IPv4Address(hostname.split(\"/\")[0])\n-    except:\n+    except ValueError:",
      "comment": "Yeah, and the only reason we allowed this was because of the ruff issue. Flake8 would have caught this too.",
      "comment_id": 1176767295,
      "user": "aminalaee",
      "created_at": "2023-04-25T16:29:46Z",
      "url": "https://github.com/encode/httpx/pull/2680#discussion_r1176767295"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2570,
      "file_path": "tests/test_decoders.py",
      "line": 335,
      "side": "LEFT",
      "diff_hunk": "@@ -214,125 +213,55 @@ async def iterator() -> typing.AsyncIterator[bytes]:\n \n \n def test_text_decoder_empty_cases():\n-    decoder = TextDecoder()\n-    assert decoder.flush() == \"\"\n+    response = httpx.Response(200, content=b\"\")\n+    assert response.text == \"\"\n \n-    decoder = TextDecoder()\n-    assert decoder.decode(b\"\") == \"\"\n-    assert decoder.flush() == \"\"\n+    response = httpx.Response(200, content=[b\"\"])\n+    response.read()\n+    assert response.text == \"\"\n \n \n def test_line_decoder_nl():\n-    decoder = LineDecoder()\n-    assert decoder.decode(\"\") == []\n-    assert decoder.decode(\"a\\n\\nb\\nc\") == [\"a\\n\", \"\\n\", \"b\\n\"]\n-    assert decoder.flush() == [\"c\"]\n+    response = httpx.Response(200, content=[b\"\"])\n+    assert list(response.iter_lines()) == []\n \n-    decoder = LineDecoder()\n-    assert decoder.decode(\"\") == []\n-    assert decoder.decode(\"a\\n\\nb\\nc\\n\") == [\"a\\n\", \"\\n\", \"b\\n\", \"c\\n\"]\n-    assert decoder.flush() == []\n+    response = httpx.Response(200, content=[b\"\", b\"a\\n\\nb\\nc\"])\n+    assert list(response.iter_lines()) == [\"a\\n\", \"\\n\", \"b\\n\", \"c\"]\n \n     # Issue #1033\n-    decoder = LineDecoder()\n-    assert decoder.decode(\"\") == []\n-    assert decoder.decode(\"12345\\n\") == [\"12345\\n\"]\n-    assert decoder.decode(\"foo \") == []\n-    assert decoder.decode(\"bar \") == []\n-    assert decoder.decode(\"baz\\n\") == [\"foo bar baz\\n\"]\n-    assert decoder.flush() == []\n+    response = httpx.Response(\n+        200, content=[b\"\", b\"12345\\n\", b\"foo \", b\"bar \", b\"baz\\n\"]\n+    )\n+    assert list(response.iter_lines()) == [\"12345\\n\", \"foo bar baz\\n\"]\n \n \n def test_line_decoder_cr():\n-    decoder = LineDecoder()\n-    assert decoder.decode(\"\") == []\n-    assert decoder.decode(\"a\\r\\rb\\rc\") == [\"a\\n\", \"\\n\", \"b\\n\"]\n-    assert decoder.flush() == [\"c\"]\n+    response = httpx.Response(200, content=[b\"\", b\"a\\r\\rb\\rc\"])\n+    assert list(response.iter_lines()) == [\"a\\n\", \"\\n\", \"b\\n\", \"c\"]\n \n-    decoder = LineDecoder()\n-    assert decoder.decode(\"\") == []\n-    assert decoder.decode(\"a\\r\\rb\\rc\\r\") == [\"a\\n\", \"\\n\", \"b\\n\"]\n-    assert decoder.flush() == [\"c\\n\"]\n+    response = httpx.Response(200, content=[b\"\", b\"a\\r\\rb\\rc\\r\"])\n+    assert list(response.iter_lines()) == [\"a\\n\", \"\\n\", \"b\\n\", \"c\\n\"]\n \n     # Issue #1033\n-    decoder = LineDecoder()\n-    assert decoder.decode(\"\") == []\n-    assert decoder.decode(\"12345\\r\") == []\n-    assert decoder.decode(\"foo \") == [\"12345\\n\"]\n-    assert decoder.decode(\"bar \") == []\n-    assert decoder.decode(\"baz\\r\") == []\n-    assert decoder.flush() == [\"foo bar baz\\n\"]\n+    response = httpx.Response(\n+        200, content=[b\"\", b\"12345\\r\", b\"foo \", b\"bar \", b\"baz\\r\"]\n+    )\n+    assert list(response.iter_lines()) == [\"12345\\n\", \"foo bar baz\\n\"]\n \n \n def test_line_decoder_crnl():\n-    decoder = LineDecoder()\n-    assert decoder.decode(\"\") == []\n-    assert decoder.decode(\"a\\r\\n\\r\\nb\\r\\nc\") == [\"a\\n\", \"\\n\", \"b\\n\"]\n-    assert decoder.flush() == [\"c\"]\n-\n-    decoder = LineDecoder()\n-    assert decoder.decode(\"\") == []\n-    assert decoder.decode(\"a\\r\\n\\r\\nb\\r\\nc\\r\\n\") == [\"a\\n\", \"\\n\", \"b\\n\", \"c\\n\"]\n-    assert decoder.flush() == []\n-\n-    decoder = LineDecoder()\n-    assert decoder.decode(\"\") == []\n-    assert decoder.decode(\"a\\r\") == []\n-    assert decoder.decode(\"\\n\\r\\nb\\r\\nc\") == [\"a\\n\", \"\\n\", \"b\\n\"]\n-    assert decoder.flush() == [\"c\"]\n+    response = httpx.Response(200, content=[b\"\", b\"a\\r\\n\\r\\nb\\r\\nc\"])\n+    assert list(response.iter_lines()) == [\"a\\n\", \"\\n\", \"b\\n\", \"c\"]\n+\n+    response = httpx.Response(200, content=[b\"\", b\"a\\r\\n\\r\\nb\\r\\nc\\r\\n\"])\n+    assert list(response.iter_lines()) == [\"a\\n\", \"\\n\", \"b\\n\", \"c\\n\"]\n+\n+    response = httpx.Response(200, content=[b\"\", b\"a\\r\", b\"\\n\\r\\nb\\r\\nc\"])\n+    assert list(response.iter_lines()) == [\"a\\n\", \"\\n\", \"b\\n\", \"c\"]\n \n     # Issue #1033\n-    decoder = LineDecoder()\n-    assert decoder.decode(\"\") == []\n-    assert decoder.decode(\"12345\\r\\n\") == [\"12345\\n\"]\n-    assert decoder.decode(\"foo \") == []\n-    assert decoder.decode(\"bar \") == []\n-    assert decoder.decode(\"baz\\r\\n\") == [\"foo bar baz\\n\"]\n-    assert decoder.flush() == []\n-\n-\n-def test_byte_chunker():\n-    decoder = ByteChunker()\n-    assert decoder.decode(b\"1234567\") == [b\"1234567\"]\n-    assert decoder.decode(b\"89\") == [b\"89\"]\n-    assert decoder.flush() == []\n-\n-    decoder = ByteChunker(chunk_size=3)\n-    assert decoder.decode(b\"1234567\") == [b\"123\", b\"456\"]\n-    assert decoder.decode(b\"89\") == [b\"789\"]\n-    assert decoder.flush() == []\n-\n-    decoder = ByteChunker(chunk_size=3)\n-    assert decoder.decode(b\"123456\") == [b\"123\", b\"456\"]\n-    assert decoder.decode(b\"789\") == [b\"789\"]\n-    assert decoder.flush() == []\n-\n-    decoder = ByteChunker(chunk_size=3)\n-    assert decoder.decode(b\"123456\") == [b\"123\", b\"456\"]\n-    assert decoder.decode(b\"78\") == []\n-    assert decoder.flush() == [b\"78\"]\n-\n-\n-def test_text_chunker():\n-    decoder = TextChunker()\n-    assert decoder.decode(\"1234567\") == [\"1234567\"]\n-    assert decoder.decode(\"89\") == [\"89\"]\n-    assert decoder.flush() == []\n-\n-    decoder = TextChunker(chunk_size=3)\n-    assert decoder.decode(\"1234567\") == [\"123\", \"456\"]\n-    assert decoder.decode(\"89\") == [\"789\"]\n-    assert decoder.flush() == []\n-\n-    decoder = TextChunker(chunk_size=3)\n-    assert decoder.decode(\"123456\") == [\"123\", \"456\"]\n-    assert decoder.decode(\"789\") == [\"789\"]\n-    assert decoder.flush() == []\n-\n-    decoder = TextChunker(chunk_size=3)\n-    assert decoder.decode(\"123456\") == [\"123\", \"456\"]\n-    assert decoder.decode(\"78\") == []\n-    assert decoder.flush() == [\"78\"]",
      "comment": "Most of these cases we actually already well covered in `test_responses.py`, so I figured I'd expand those a bit to match coverage, and drop these.",
      "comment_id": 1096597170,
      "user": "florimondmanca",
      "created_at": "2023-02-04T23:07:37Z",
      "url": "https://github.com/encode/httpx/pull/2570#discussion_r1096597170"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2648,
      "file_path": "tests/client/test_async_client.py",
      "line": 87,
      "side": "RIGHT",
      "diff_hunk": "@@ -84,7 +84,7 @@ async def test_access_content_stream_response(server):\n \n     assert response.status_code == 200\n     with pytest.raises(httpx.ResponseNotRead):\n-        response.content\n+        response.content  # noqa: B018",
      "comment": "It's on the rules page: https://beta.ruff.rs/docs/rules/#flake8-bugbear-b\r\n\r\nShould I add a comment here or ignore it globally?",
      "comment_id": 1158258821,
      "user": "Kludex",
      "created_at": "2023-04-05T09:22:34Z",
      "url": "https://github.com/encode/httpx/pull/2648#discussion_r1158258821"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2547,
      "file_path": "httpx/_client.py",
      "line": 1013,
      "side": "RIGHT",
      "diff_hunk": "@@ -1010,10 +1010,13 @@ def _send_single_request(self, request: Request) -> Response:\n         self.cookies.extract_cookies(response)\n         response.default_encoding = self._default_encoding\n \n-        status = f\"{response.status_code} {response.reason_phrase}\"\n-        response_line = f\"{response.http_version} {status}\"\n-        logger.debug(\n-            'HTTP Request: %s %s \"%s\"', request.method, request.url, response_line\n+        logger.info(",
      "comment": "Based on the other python packages, I don't recall any other python client having an INFO log message level. :thinking: ",
      "comment_id": 1141706645,
      "user": "Kludex",
      "created_at": "2023-03-20T07:17:57Z",
      "url": "https://github.com/encode/httpx/pull/2547#discussion_r1141706645"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2547,
      "file_path": "httpx/_client.py",
      "line": 1013,
      "side": "RIGHT",
      "diff_hunk": "@@ -1010,10 +1010,13 @@ def _send_single_request(self, request: Request) -> Response:\n         self.cookies.extract_cookies(response)\n         response.default_encoding = self._default_encoding\n \n-        status = f\"{response.status_code} {response.reason_phrase}\"\n-        response_line = f\"{response.http_version} {status}\"\n-        logger.debug(\n-            'HTTP Request: %s %s \"%s\"', request.method, request.url, response_line\n+        logger.info(",
      "comment": "It could yes, though it's less useful to have logging if everything is at the same level.\r\nI like the different \"show me nothing\", \"show me the requests\", \"show me the debug\" lighting levels.\r\n\r\n(Similar: gunicorn, uvicorn using INFO for requests, and DEBUG for other stuffs)",
      "comment_id": 1141930995,
      "user": "lovelydinosaur",
      "created_at": "2023-03-20T10:45:16Z",
      "url": "https://github.com/encode/httpx/pull/2547#discussion_r1141930995"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "tests/models/test_responses.py",
      "line": 642,
      "side": "RIGHT",
      "diff_hunk": "@@ -639,7 +639,7 @@ def test_iter_lines():\n         content=b\"Hello,\\nworld!\",\n     )\n     content = [line for line in response.iter_lines()]\n-    assert content == [\"Hello,\\n\", \"world!\"]\n+    assert content == [\"Hello,\", \"world!\"]",
      "comment": "These test changes show that currently this PR introduces a behavior change. I assume we don't want behavior to change, i.e. for `\\n` to stay in the yielded lines? Does that mean relying on `splitlines(keep_ends=True)`... ?",
      "comment_id": 1014794251,
      "user": "florimondmanca",
      "created_at": "2022-11-06T09:13:57Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1014794251"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "tests/models/test_responses.py",
      "line": 642,
      "side": "RIGHT",
      "diff_hunk": "@@ -639,7 +639,7 @@ def test_iter_lines():\n         content=b\"Hello,\\nworld!\",\n     )\n     content = [line for line in response.iter_lines()]\n-    assert content == [\"Hello,\\n\", \"world!\"]\n+    assert content == [\"Hello,\", \"world!\"]",
      "comment": "Oh, I didn't realise there was a `keepends` flag, let me rework the patch with that. ",
      "comment_id": 1027299829,
      "user": "giannitedesco",
      "created_at": "2022-11-20T14:30:48Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1027299829"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "tests/models/test_responses.py",
      "line": 642,
      "side": "RIGHT",
      "diff_hunk": "@@ -639,7 +639,7 @@ def test_iter_lines():\n         content=b\"Hello,\\nworld!\",\n     )\n     content = [line for line in response.iter_lines()]\n-    assert content == [\"Hello,\\n\", \"world!\"]\n+    assert content == [\"Hello,\", \"world!\"]",
      "comment": "Right, the issue is that `keepends` ~converts~ doesn't convert them all to `\\n`",
      "comment_id": 1027510876,
      "user": "giannitedesco",
      "created_at": "2022-11-21T03:23:35Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1027510876"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 286,
      "side": "RIGHT",
      "diff_hunk": "@@ -267,57 +267,23 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        if self.buffer:\n+            text = self.buffer + text\n+\n+        if not text:\n+            return []\n+\n+        lines = text.splitlines(True)\n+        if text.endswith(\"\\n\"):\n+            self.buffer = \"\"\n+        else:\n+            remainder = lines.pop()\n+            self.buffer = remainder\n \n         return lines\n \n     def flush(self) -> typing.List[str]:\n-        if self.buffer.endswith(\"\\r\"):\n-            # Handle the case where we had a trailing '\\r', which could have\n-            # been a '\\r\\n' pair.\n-            lines = [self.buffer[:-1] + \"\\n\"]\n-        elif self.buffer:\n-            lines = [self.buffer]\n-        else:\n-            lines = []\n+        lines = self.buffer.splitlines(True)",
      "comment": "I guess we'll want to drop the `True` here, given review comments.",
      "comment_id": 1044351555,
      "user": "lovelydinosaur",
      "created_at": "2022-12-09T11:18:54Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1044351555"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 276,
      "side": "RIGHT",
      "diff_hunk": "@@ -267,57 +267,23 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        if self.buffer:\n+            text = self.buffer + text\n+\n+        if not text:\n+            return []\n+\n+        lines = text.splitlines(True)",
      "comment": "I guess we'll want to drop the `True` here, given review comments.",
      "comment_id": 1044351913,
      "user": "lovelydinosaur",
      "created_at": "2022-12-09T11:19:22Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1044351913"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 277,
      "side": "RIGHT",
      "diff_hunk": "@@ -267,57 +267,23 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        if self.buffer:\n+            text = self.buffer + text\n+\n+        if not text:\n+            return []\n+\n+        lines = text.splitlines(True)\n+        if text.endswith(\"\\n\"):",
      "comment": "I *think* this would then be something like...\r\n\r\n```python\r\nlastline = lines[-1]\r\nif lastline and text and lastline[-1] != text[-1]:\r\n    # The final line ends with a different character to the input\r\n    # text, so it must have ended in a newline.\r\n    ...\r\nelse:\r\n    #\u00a0The final line *didn't* end with a newline, so push it back\r\n    # into the buffer.\r\n    ...\r\n```",
      "comment_id": 1044355428,
      "user": "lovelydinosaur",
      "created_at": "2022-12-09T11:24:02Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1044355428"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 272,
      "side": "RIGHT",
      "diff_hunk": "@@ -266,57 +266,23 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        if self.buffer:\n+            text = self.buffer + text\n+\n+        if text.endswith(\"\\r\"):",
      "comment": "`splitlines()` will teat a trailing `\"\\r\"` as a newline because it is designed around the assumption that that input is the whole string.. in the case of the line decoder, when a trailing `\"\\r\"` is received, we need to buffer it up in case the next character in the input stream is an `\"\\n\"` (ie. it was part of an interrupted `\"\\r\\n\"` sequence)",
      "comment_id": 1045052360,
      "user": "giannitedesco",
      "created_at": "2022-12-10T10:10:21Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1045052360"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 272,
      "side": "RIGHT",
      "diff_hunk": "@@ -266,57 +266,23 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        if self.buffer:\n+            text = self.buffer + text\n+\n+        if text.endswith(\"\\r\"):",
      "comment": "well, if we go with this version then it needs a comment :)",
      "comment_id": 1045052847,
      "user": "giannitedesco",
      "created_at": "2022-12-10T10:11:49Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1045052847"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 278,
      "side": "RIGHT",
      "diff_hunk": "@@ -267,57 +267,23 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        if self.buffer:\n+            text = self.buffer + text\n+\n+        if text.endswith(\"\\r\"):\n+            self.buffer = text\n+            return []\n+\n+        lines = text.splitlines()\n+        if text.endswith(\"\\n\") or not lines:",
      "comment": "The `if text.endswith(\"\\n\")` doesn't seems sufficient to me.\r\n\r\nOther newline endings [are also available](https://docs.python.org/3/library/stdtypes.html#str.splitlines).\r\n\r\nI'd assume that our test cases aren't covering this sufficiently.",
      "comment_id": 1045653671,
      "user": "lovelydinosaur",
      "created_at": "2022-12-12T10:32:26Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1045653671"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 272,
      "side": "RIGHT",
      "diff_hunk": "@@ -266,57 +266,23 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        if self.buffer:\n+            text = self.buffer + text\n+\n+        if text.endswith(\"\\r\"):",
      "comment": "Gotcha. Yes a comment would be good. I assume that `\"\\r\\n\"` is the *only* two-character newline sequence, right?",
      "comment_id": 1045679676,
      "user": "lovelydinosaur",
      "created_at": "2022-12-12T10:57:22Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1045679676"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 278,
      "side": "RIGHT",
      "diff_hunk": "@@ -267,57 +267,23 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        if self.buffer:\n+            text = self.buffer + text\n+\n+        if text.endswith(\"\\r\"):\n+            self.buffer = text\n+            return []\n+\n+        lines = text.splitlines()\n+        if text.endswith(\"\\n\") or not lines:",
      "comment": "The behaviour when using any of the other \"funny money\" line-endings is not really incorrect output, but that trailing lines will be delayed until the subsequent call or until finalization when one or two lines will be returned.",
      "comment_id": 1045694536,
      "user": "giannitedesco",
      "created_at": "2022-12-12T11:13:20Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1045694536"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 278,
      "side": "RIGHT",
      "diff_hunk": "@@ -267,57 +267,23 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        if self.buffer:\n+            text = self.buffer + text\n+\n+        if text.endswith(\"\\r\"):\n+            self.buffer = text\n+            return []\n+\n+        lines = text.splitlines()\n+        if text.endswith(\"\\n\") or not lines:",
      "comment": "Well, unless you consider splitting on those other line endings is, itself, as a bug/unintended. (I had no idea, fwiw)",
      "comment_id": 1045695695,
      "user": "giannitedesco",
      "created_at": "2022-12-12T11:14:38Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1045695695"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 283,
      "side": "RIGHT",
      "diff_hunk": "@@ -267,57 +267,23 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        if self.buffer:\n+            text = self.buffer + text\n+\n+        if text.endswith(\"\\r\"):\n+            self.buffer = text\n+            return []\n+\n+        lines = text.splitlines()\n+        if text.endswith(\"\\n\") or not lines:\n+            self.buffer = \"\"\n+        else:\n+            self.buffer = lines.pop()\n \n         return lines",
      "comment": "```suggestion\r\n        # See https://docs.python.org/3/library/stdtypes.html#str.splitlines\r\n        NEWLINE_CHARS = \"\\n\\r\\x0b\\x0c\\x1c\\x1d\\x1e\\x85\\u2028\\u2029\"\r\n\r\n        if self.buffer:\r\n            # If we have some buffered text from the previous pass,\r\n            # then we include it before handling the input.\r\n            text = self.buffer + text\r\n            self.buffer = \"\"\r\n\r\n        if not text:\r\n            return []\r\n        elif text[-1] == \"\\r\":\r\n            # If the last character is \"\\r\", then we might be about to see \"\\r\\n\"\r\n            # newline seperator. We buffer the text input and return.\r\n            self.buffer = text\r\n            return []\r\n        elif text[-1] in NEWLINE_CHARS:\r\n            # If the last character is a newline separator then we can simply split\r\n            # the text into lines and return them. There is no remaining portion\r\n            # to be dealt with on the next pass.\r\n            return text.splitlines()\r\n        else:\r\n            # If the last character is not a newline seperator, then the final portion\r\n            # from `splitlines()` is incomplete and needs to be buffered for the next\r\n            # pass.\r\n            lines = text.splitlines()\r\n            self.buffer = lines.pop()\r\n            return lines\r\n```",
      "comment_id": 1050940196,
      "user": "lovelydinosaur",
      "created_at": "2022-12-16T16:30:16Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1050940196"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 276,
      "side": "RIGHT",
      "diff_hunk": "@@ -267,57 +267,34 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        # See https://docs.python.org/3/library/stdtypes.html#str.splitlines\n+        NEWLINE_CHARS = \"\\n\\r\\x0b\\x0c\\x1c\\x1d\\x1e\\x85\\u2028\\u2029\"\n+\n+        if self.buffer:\n+            # If we have some buffered text from the previous pass,\n+            # then we include it before handling the input.\n+            text = self.buffer + text",
      "comment": "Please correct me if I'm wrong, but it seems like if we do the following:\r\n\r\n```python\r\nfor i in range(N):\r\n    decoder.decode(\"a\")\r\n```\r\n\r\nthen we will have N string concatenations here (e.g. N string concatenations gives us O(N**2)). I'm curious if there any way to avoid it?\r\n\r\nE.g. may be we can use a `list` as a buffer, and do `''.join(buffer)` (it's O(N)) when newline is coming?",
      "comment_id": 1066603902,
      "user": "cdeler",
      "created_at": "2023-01-11T06:07:22Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1066603902"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 276,
      "side": "RIGHT",
      "diff_hunk": "@@ -267,57 +267,34 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        # See https://docs.python.org/3/library/stdtypes.html#str.splitlines\n+        NEWLINE_CHARS = \"\\n\\r\\x0b\\x0c\\x1c\\x1d\\x1e\\x85\\u2028\\u2029\"\n+\n+        if self.buffer:\n+            # If we have some buffered text from the previous pass,\n+            # then we include it before handling the input.\n+            text = self.buffer + text",
      "comment": "Well observed.\r\n\r\nThis will run slowly...\r\n\r\n```python\r\nclass LineDecoder:\r\n    \"\"\"\r\n    Handles incrementally reading lines from text.\r\n    Uses universal line decoding, supporting any of `\\n`, `\\r`, or `\\r\\n`\r\n    as line endings, normalizing to `\\n`.\r\n    \"\"\"\r\n\r\n    def __init__(self):\r\n        self.buffer = \"\"\r\n\r\n    def decode(self, text):\r\n        # See https://docs.python.org/3/library/stdtypes.html#str.splitlines\r\n        NEWLINE_CHARS = \"\\n\\r\\x0b\\x0c\\x1c\\x1d\\x1e\\x85\\u2028\\u2029\"\r\n\r\n        if self.buffer:\r\n            # If we have some buffered text from the previous pass,\r\n            # then we include it before handling the input.\r\n            text = self.buffer + text\r\n            self.buffer = \"\"\r\n\r\n        if not text:\r\n            return []\r\n\r\n        lines = text.splitlines()\r\n\r\n        if text[-1] == \"\\r\":\r\n            # If the last character is \"\\r\", then we might be on the boundary of\r\n            # a \"\\r\\n\" sequence. We reassemble and buffer the final portion of the input.\r\n            self.buffer = lines.pop() + \"\\r\"\r\n        elif text[-1] not in NEWLINE_CHARS:\r\n            # If the last character is not a newline seperator, then the final portion\r\n            # from `splitlines()` is incomplete and needs to be buffered for the next\r\n            # pass.\r\n            self.buffer = lines.pop()\r\n\r\n        return lines\r\n\r\n    def flush(self):\r\n        lines = self.buffer.splitlines()\r\n        self.buffer = \"\"\r\n        return lines\r\n\r\n\r\nl = LineDecoder()\r\nfor i in range(100_000):\r\n    l.decode(\"a\")\r\nl.flush()\r\n```",
      "comment_id": 1066796498,
      "user": "lovelydinosaur",
      "created_at": "2023-01-11T10:00:50Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1066796498"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 276,
      "side": "RIGHT",
      "diff_hunk": "@@ -267,57 +267,34 @@ def __init__(self) -> None:\n         self.buffer = \"\"\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        # See https://docs.python.org/3/library/stdtypes.html#str.splitlines\n+        NEWLINE_CHARS = \"\\n\\r\\x0b\\x0c\\x1c\\x1d\\x1e\\x85\\u2028\\u2029\"\n+\n+        if self.buffer:\n+            # If we have some buffered text from the previous pass,\n+            # then we include it before handling the input.\n+            text = self.buffer + text",
      "comment": "I feel we should re-write the `flush(...)`\r\n\r\n```diff\r\n    def flush(self) -> typing.List[str]:\r\n        if self.buffer or self.trailing_cr:\r\n-            return [\"\".join(self.buffer)]\r\n+            result = [\"\".join(self.buffer)]\r\n+            self.buffer = []\r\n+            return result\r\n        return []\r\n```",
      "comment_id": 1067360513,
      "user": "cdeler",
      "created_at": "2023-01-11T19:04:30Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1067360513"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2423,
      "file_path": "httpx/_decoders.py",
      "line": 311,
      "side": "RIGHT",
      "diff_hunk": "@@ -259,67 +259,56 @@ class LineDecoder:\n     \"\"\"\n     Handles incrementally reading lines from text.\n \n-    Uses universal line decoding, supporting any of `\\n`, `\\r`, or `\\r\\n`\n-    as line endings, normalizing to `\\n`.\n+    Has the same behaviour as the stdllib splitlines, but handling the input iteratively.\n     \"\"\"\n \n     def __init__(self) -> None:\n-        self.buffer = \"\"\n+        self.buffer: typing.List[str] = []\n+        self.trailing_cr: bool = False\n \n     def decode(self, text: str) -> typing.List[str]:\n-        lines = []\n-\n-        if text and self.buffer and self.buffer[-1] == \"\\r\":\n-            if text.startswith(\"\\n\"):\n-                # Handle the case where we have an \"\\r\\n\" split across\n-                # our previous input, and our new chunk.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-                text = text[1:]\n-            else:\n-                # Handle the case where we have \"\\r\" at the end of our\n-                # previous input.\n-                lines.append(self.buffer[:-1] + \"\\n\")\n-                self.buffer = \"\"\n-\n-        while text:\n-            num_chars = len(text)\n-            for idx in range(num_chars):\n-                char = text[idx]\n-                next_char = None if idx + 1 == num_chars else text[idx + 1]\n-                if char == \"\\n\":\n-                    lines.append(self.buffer + text[: idx + 1])\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif char == \"\\r\" and next_char == \"\\n\":\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 2 :]\n-                    break\n-                elif char == \"\\r\" and next_char is not None:\n-                    lines.append(self.buffer + text[:idx] + \"\\n\")\n-                    self.buffer = \"\"\n-                    text = text[idx + 1 :]\n-                    break\n-                elif next_char is None:\n-                    self.buffer += text\n-                    text = \"\"\n-                    break\n+        # See https://docs.python.org/3/library/stdtypes.html#str.splitlines\n+        NEWLINE_CHARS = \"\\n\\r\\x0b\\x0c\\x1c\\x1d\\x1e\\x85\\u2028\\u2029\"\n+\n+        # We always push a trailing `\\r` into the next decode iteration.\n+        if self.trailing_cr:\n+            text = \"\\r\" + text\n+            self.trailing_cr = False\n+        if text.endswith(\"\\r\"):\n+            self.trailing_cr = True\n+            text = text[:-1]\n+\n+        if not text:\n+            return []\n+\n+        trailing_newline = text[-1] in NEWLINE_CHARS\n+        lines = text.splitlines()\n+\n+        if len(lines) == 1 and not trailing_newline:\n+            # No new lines, buffer the input and continue.\n+            self.buffer.append(lines[0])\n+            return []\n+\n+        if self.buffer:\n+            # Include any existing buffer in the first portion of the\n+            # splitlines result.\n+            lines = [\"\".join(self.buffer) + lines[0]] + lines[1:]\n+            self.buffer = []\n+\n+        if not trailing_newline:\n+            # If the last segment of splitlines is not newline terminated,\n+            # then drop it from our output and start a new buffer.\n+            self.buffer = [lines.pop()]\n \n         return lines\n \n     def flush(self) -> typing.List[str]:\n-        if self.buffer.endswith(\"\\r\"):\n-            # Handle the case where we had a trailing '\\r', which could have\n-            # been a '\\r\\n' pair.\n-            lines = [self.buffer[:-1] + \"\\n\"]\n-        elif self.buffer:\n-            lines = [self.buffer]\n-        else:\n-            lines = []\n-        self.buffer = \"\"\n-        return lines\n+        if self.buffer or self.trailing_cr:\n+            lines = [\"\".join(self.buffer)]\n+            self.buffer = []\n+            self.trailing_cr = False\n+            return lines\n+        return []",
      "comment": "```suggestion\r\n        if not self.buffer and not self.trailing_cr:\r\n            return []\r\n            \r\n        lines = [\"\".join(self.buffer)]\r\n        self.buffer = []\r\n        self.trailing_cr = False\r\n        return lines\r\n```",
      "comment_id": 1068912857,
      "user": "cdeler",
      "created_at": "2023-01-13T04:24:11Z",
      "url": "https://github.com/encode/httpx/pull/2423#discussion_r1068912857"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2572,
      "file_path": "httpx/_urlparse.py",
      "line": 208,
      "side": "LEFT",
      "diff_hunk": "@@ -195,18 +195,6 @@ def urlparse(url: str = \"\", **kwargs: typing.Optional[str]) -> ParseResult:\n     # -------------------------------------------------------------\n \n     for key, value in kwargs.items():\n-        if key not in (\n-            \"scheme\",\n-            \"authority\",\n-            \"path\",\n-            \"query\",\n-            \"fragment\",\n-            \"userinfo\",\n-            \"host\",\n-            \"port\",\n-        ):\n-            raise TypeError(f\"'{key}' is an invalid keyword argument for urlparse()\")",
      "comment": "We were already doing this check in `URL.__init__()`, so in the wild it would indeed be redundant as we use `httpx.URL()`, so I dropped this check.",
      "comment_id": 1096670353,
      "user": "florimondmanca",
      "created_at": "2023-02-05T11:44:24Z",
      "url": "https://github.com/encode/httpx/pull/2572#discussion_r1096670353"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2571,
      "file_path": "tests/test_exceptions.py",
      "line": 63,
      "side": "LEFT",
      "diff_hunk": "@@ -16,66 +14,39 @@ def test_httpcore_all_exceptions_mapped() -> None:\n     All exception classes exposed by HTTPCore are properly mapped to an HTTPX-specific\n     exception class.\n     \"\"\"\n-    not_mapped = [\n-        value\n-        for name, value in vars(httpcore).items()\n+    expected_mapped_httpcore_exceptions = {\n+        value.__name__\n+        for _, value in vars(httpcore).items()\n         if isinstance(value, type)\n         and issubclass(value, Exception)\n-        and value not in HTTPCORE_EXC_MAP\n         and value is not httpcore.ConnectionNotAvailable\n-    ]\n+    }\n \n-    if not_mapped:  # pragma: no cover\n-        pytest.fail(f\"Unmapped httpcore exceptions: {not_mapped}\")\n+    httpx_exceptions = {\n+        value.__name__\n+        for _, value in vars(httpx).items()\n+        if isinstance(value, type) and issubclass(value, Exception)\n+    }\n \n+    unmapped_exceptions = expected_mapped_httpcore_exceptions - httpx_exceptions\n \n-def test_httpcore_exception_mapping(server: \"TestServer\") -> None:\n-    \"\"\"\n-    HTTPCore exception mapping works as expected.\n-    \"\"\"\n-\n-    def connect_failed(*args, **kwargs):\n-        raise httpcore.ConnectError()\n-\n-    class TimeoutStream:\n-        def __iter__(self):\n-            raise httpcore.ReadTimeout()\n-\n-        def close(self):\n-            pass\n-\n-    with mock.patch(\n-        \"httpcore.ConnectionPool.handle_request\", side_effect=connect_failed\n-    ):\n-        with pytest.raises(httpx.ConnectError):\n-            httpx.get(server.url)\n+    if unmapped_exceptions:  # pragma: no cover\n+        pytest.fail(f\"Unmapped httpcore exceptions: {unmapped_exceptions}\")\n \n-    with mock.patch(\n-        \"httpcore.ConnectionPool.handle_request\",\n-        return_value=httpcore.Response(\n-            200, headers=[], content=TimeoutStream(), extensions={}\n-        ),\n-    ):\n-        with pytest.raises(httpx.ReadTimeout):\n-            httpx.get(server.url)\n \n-\n-def test_httpx_exceptions_exposed() -> None:",
      "comment": "The purpose of this test was to verify that we don't leave any exception class defined in `httpx/_exceptions.py` out of `httpx/__init__.py`.\r\n\r\nAs such, it's impossible to perform without reaching to `httpx._exceptions`.\r\n\r\nBut I also thought it wasn't very useful after all, so I am dropping it in this PR.",
      "comment_id": 1096665736,
      "user": "florimondmanca",
      "created_at": "2023-02-05T11:12:07Z",
      "url": "https://github.com/encode/httpx/pull/2571#discussion_r1096665736"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2535,
      "file_path": "httpx/_auth.py",
      "line": 155,
      "side": "RIGHT",
      "diff_hunk": "@@ -141,6 +142,34 @@ def _build_auth_header(\n         return f\"Basic {token}\"\n \n \n+class NetRCAuth(Auth):\n+    \"\"\"\n+    Use a 'netrc' file to lookup basic auth credentials based on the url host.\n+    \"\"\"\n+\n+    def __init__(self, file: typing.Optional[str]):\n+        self._netrc_info = netrc.netrc(file)\n+\n+    def auth_flow(self, request: Request) -> typing.Generator[Request, Response, None]:\n+        auth_info = self._netrc_info.authenticators(request.url.host)\n+        if auth_info is None or auth_info[2] is None:",
      "comment": "I'm sorry, may I ask you why you are checking the password for `None`?",
      "comment_id": 1066615132,
      "user": "cdeler",
      "created_at": "2023-01-11T06:26:56Z",
      "url": "https://github.com/encode/httpx/pull/2535#discussion_r1066615132"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2535,
      "file_path": "httpx/_auth.py",
      "line": 155,
      "side": "RIGHT",
      "diff_hunk": "@@ -141,6 +142,34 @@ def _build_auth_header(\n         return f\"Basic {token}\"\n \n \n+class NetRCAuth(Auth):\n+    \"\"\"\n+    Use a 'netrc' file to lookup basic auth credentials based on the url host.\n+    \"\"\"\n+\n+    def __init__(self, file: typing.Optional[str]):\n+        self._netrc_info = netrc.netrc(file)\n+\n+    def auth_flow(self, request: Request) -> typing.Generator[Request, Response, None]:\n+        auth_info = self._netrc_info.authenticators(request.url.host)\n+        if auth_info is None or auth_info[2] is None:",
      "comment": "I'm asking since previously you were checking \r\n```python\r\nif credentials is not None:\r\n    ...\r\n```\r\n\r\nand python documentation says ([link](https://docs.python.org/3/library/netrc.html#netrc.netrc.authenticators)) that \r\n> If the netrc file did not contain an entry for the given host, return the tuple associated with the \u2018default\u2019 entry. If neither matching host nor default entry is available, return None.\r\n\r\n",
      "comment_id": 1066617055,
      "user": "cdeler",
      "created_at": "2023-01-11T06:28:42Z",
      "url": "https://github.com/encode/httpx/pull/2535#discussion_r1066617055"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2535,
      "file_path": "httpx/_auth.py",
      "line": 155,
      "side": "RIGHT",
      "diff_hunk": "@@ -141,6 +142,34 @@ def _build_auth_header(\n         return f\"Basic {token}\"\n \n \n+class NetRCAuth(Auth):\n+    \"\"\"\n+    Use a 'netrc' file to lookup basic auth credentials based on the url host.\n+    \"\"\"\n+\n+    def __init__(self, file: typing.Optional[str]):\n+        self._netrc_info = netrc.netrc(file)\n+\n+    def auth_flow(self, request: Request) -> typing.Generator[Request, Response, None]:\n+        auth_info = self._netrc_info.authenticators(request.url.host)\n+        if auth_info is None or auth_info[2] is None:",
      "comment": "Thanks @cdeler.\r\n\r\nThe simple version of \"why\" is because I was blindly following our previous implementation details here.\r\n\r\nI've had a look into it, and I don't think the password can be `None` here, but I think it can be the empty string. It looks to me like Python 3.11+ will allow the empty string for a missing password field in the `netrc` file, and the previous versions will raise a parse error for missing passwords.\r\n\r\nI think the robust thing to do here would be...\r\n\r\n```python\r\nif auth_info is None or not auth_info[2]:\r\n```",
      "comment_id": 1066942807,
      "user": "lovelydinosaur",
      "created_at": "2023-01-11T12:38:35Z",
      "url": "https://github.com/encode/httpx/pull/2535#discussion_r1066942807"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2535,
      "file_path": "httpx/_auth.py",
      "line": 155,
      "side": "RIGHT",
      "diff_hunk": "@@ -141,6 +142,34 @@ def _build_auth_header(\n         return f\"Basic {token}\"\n \n \n+class NetRCAuth(Auth):\n+    \"\"\"\n+    Use a 'netrc' file to lookup basic auth credentials based on the url host.\n+    \"\"\"\n+\n+    def __init__(self, file: typing.Optional[str]):\n+        self._netrc_info = netrc.netrc(file)\n+\n+    def auth_flow(self, request: Request) -> typing.Generator[Request, Response, None]:\n+        auth_info = self._netrc_info.authenticators(request.url.host)\n+        if auth_info is None or auth_info[2] is None:",
      "comment": "```suggestion\r\n        if auth_info is None or not auth_info[2]:\r\n```",
      "comment_id": 1066943032,
      "user": "lovelydinosaur",
      "created_at": "2023-01-11T12:38:49Z",
      "url": "https://github.com/encode/httpx/pull/2535#discussion_r1066943032"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2535,
      "file_path": "httpx/_auth.py",
      "line": 155,
      "side": "RIGHT",
      "diff_hunk": "@@ -141,6 +142,34 @@ def _build_auth_header(\n         return f\"Basic {token}\"\n \n \n+class NetRCAuth(Auth):\n+    \"\"\"\n+    Use a 'netrc' file to lookup basic auth credentials based on the url host.\n+    \"\"\"\n+\n+    def __init__(self, file: typing.Optional[str]):\n+        self._netrc_info = netrc.netrc(file)\n+\n+    def auth_flow(self, request: Request) -> typing.Generator[Request, Response, None]:\n+        auth_info = self._netrc_info.authenticators(request.url.host)\n+        if auth_info is None or auth_info[2] is None:",
      "comment": "Demo'ing the behaviour of Python `netrc` with an empty password entry...\r\n\r\n```python\r\nimport netrc\r\nimport tempfile\r\n\r\n\r\nwith tempfile.NamedTemporaryFile(delete=False) as t:\r\n    t.write(b\"machine example.com\\nlogin user\\n\")\r\n    t.close()\r\n    n = netrc.netrc(t.name)\r\n    print(n.authenticators(\"example.com\"))\r\n```\r\n\r\nPython 3.11:\r\n\r\n```shell\r\n$ python3.11 ./example.py \r\n('user', '', '')\r\n```\r\n\r\nPython 3.10:\r\n\r\n```shell\r\n$ python3.10 ./example.py \r\nTraceback (most recent call last):\r\n  File \"/Users/tomchristie/Temp/./example.py\", line 8, in <module>\r\n    n = netrc.netrc(t.name)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/netrc.py\", line 31, in __init__\r\n    self._parse(file, fp, default_netrc)\r\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/netrc.py\", line 82, in _parse\r\n    raise NetrcParseError(\r\nnetrc.NetrcParseError: malformed machine entry example.com terminated by '' (/var/folders/8s/dk9369g11yzdnsfkvbtljcjm0000gn/T/tmpipnocc0x, line 3)\r\n```",
      "comment_id": 1066955362,
      "user": "lovelydinosaur",
      "created_at": "2023-01-11T12:52:11Z",
      "url": "https://github.com/encode/httpx/pull/2535#discussion_r1066955362"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2523,
      "file_path": "tests/models/test_queryparams.py",
      "line": 91,
      "side": "RIGHT",
      "diff_hunk": "@@ -87,6 +87,11 @@ def test_empty_query_params():\n     assert str(q) == \"a=\"\n \n \n+def test_invalid_query_params():\n+    with pytest.raises(TypeError):",
      "comment": "Seems nice to ensure that the formatted message is correct\r\n```suggestion\r\n    with pytest.raises(TypeError, match=r\"Expected str, int, float, bool, or None\\. Got 'bytes'\\.\"):\r\n```",
      "comment_id": 1059507467,
      "user": "zanieb",
      "created_at": "2022-12-30T20:01:02Z",
      "url": "https://github.com/encode/httpx/pull/2523#discussion_r1059507467"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2523,
      "file_path": "tests/models/test_queryparams.py",
      "line": 92,
      "side": "RIGHT",
      "diff_hunk": "@@ -89,7 +89,7 @@ def test_empty_query_params():\n \n def test_invalid_query_params():\n     with pytest.raises(\n-        TypeError, match=r\"Expected str, int, float, bool, or None\\. Got 'bytes'\\.\"\n+        TypeError, match=r\"Expected str, int, float, bool, or None. Got 'bytes'.\"",
      "comment": "You don't need the `r` if you aren't escaping the periods \u2014 this is doing a `re.search` so technically the `.` will be a wildcard but \ud83e\udd37\u200d\u2640\ufe0f it's not likely to cause you any problems. You could use `re.escape` if you really wanted to be correct.",
      "comment_id": 1059518254,
      "user": "zanieb",
      "created_at": "2022-12-30T20:58:04Z",
      "url": "https://github.com/encode/httpx/pull/2523#discussion_r1059518254"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2512,
      "file_path": "tests/client/test_auth.py",
      "line": 155,
      "side": "RIGHT",
      "diff_hunk": "@@ -152,7 +152,7 @@ async def async_auth_flow(\n         yield request\n \n \n-@pytest.mark.asyncio\n+@pytest.mark.anyio",
      "comment": "is there a reason these were not marked `@pytest.mark.usefixtures(\"async_environment\")` ?",
      "comment_id": 1053443351,
      "user": "graingert",
      "created_at": "2022-12-20T15:27:14Z",
      "url": "https://github.com/encode/httpx/pull/2512#discussion_r1053443351"
    },
    {
      "repo": "encode/httpx",
      "pr_number": 2512,
      "file_path": "tests/client/test_auth.py",
      "line": 155,
      "side": "RIGHT",
      "diff_hunk": "@@ -152,7 +152,7 @@ async def async_auth_flow(\n         yield request\n \n \n-@pytest.mark.asyncio\n+@pytest.mark.anyio",
      "comment": "ah some of these tests used `asyncio.Lock` so only worked on asyncio. I changed it to `anyio.Lock` and they pass on trio or asyncio now",
      "comment_id": 1055414437,
      "user": "graingert",
      "created_at": "2022-12-22T12:35:16Z",
      "url": "https://github.com/encode/httpx/pull/2512#discussion_r1055414437"
    }
  ]
}