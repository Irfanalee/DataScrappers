{
  "repo": "astral-sh/ruff",
  "scraped_at": "2026-02-03T10:47:30.917041",
  "stats": {
    "total_comments": 950,
    "filtered": {
      "not_python": 730,
      "skip_pattern:nit:": 6,
      "too_short": 116,
      "no_diff_hunk": 41,
      "too_long": 16,
      "skip_pattern:nice!": 1
    },
    "kept": 40
  },
  "examples": [
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22943,
      "file_path": "scripts/conformance.py",
      "line": 465,
      "side": "RIGHT",
      "diff_hunk": "@@ -462,6 +462,7 @@ def collect_ty_diagnostics(\n             f\"--python-version={python_version}\",\n             \"--output-format=gitlab\",\n             \"--ignore=assert-type-unspellable-subtype\",\n+            \"--error=invalid-legacy-positional-parameter\",",
      "comment": "this is necessary because I made the default severity of the lint `Level::Warn` rather than `Level::Error` (since it won't fail at runtime)",
      "comment_id": 2741872858,
      "user": "AlexWaygood",
      "created_at": "2026-01-29T14:15:48Z",
      "url": "https://github.com/astral-sh/ruff/pull/22943#discussion_r2741872858"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22943,
      "file_path": "scripts/conformance.py",
      "line": 465,
      "side": "RIGHT",
      "diff_hunk": "@@ -462,6 +462,7 @@ def collect_ty_diagnostics(\n             f\"--python-version={python_version}\",\n             \"--output-format=gitlab\",\n             \"--ignore=assert-type-unspellable-subtype\",\n+            \"--error=invalid-legacy-positional-parameter\",",
      "comment": "I feel like we should set up our conformance suite integration such that warnings count as errors for conformance suite purposes in general.",
      "comment_id": 2748483779,
      "user": "carljm",
      "created_at": "2026-01-30T23:59:41Z",
      "url": "https://github.com/astral-sh/ruff/pull/22943#discussion_r2748483779"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22943,
      "file_path": "scripts/conformance.py",
      "line": 465,
      "side": "RIGHT",
      "diff_hunk": "@@ -462,6 +462,7 @@ def collect_ty_diagnostics(\n             f\"--python-version={python_version}\",\n             \"--output-format=gitlab\",\n             \"--ignore=assert-type-unspellable-subtype\",\n+            \"--error=invalid-legacy-positional-parameter\",",
      "comment": "For example, the number of false positives we report might go up due to some `unused-ignore-comment` diagnostics on comments in the spec that aren't meant to be suppression comments at all, such as https://github.com/python/typing/blob/08f929ba70397b5c898a55bbb73c8b4e2e8e4fbb/conformance/tests/directives_type_ignore_file1.py#L11. (Related: https://github.com/astral-sh/ty/issues/881.)",
      "comment_id": 2749311445,
      "user": "AlexWaygood",
      "created_at": "2026-01-31T10:04:33Z",
      "url": "https://github.com/astral-sh/ruff/pull/22943#discussion_r2749311445"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 21369,
      "file_path": "crates/ruff_python_formatter/resources/test/fixtures/ruff/parentheses/call_chains.py",
      "line": 266,
      "side": "RIGHT",
      "diff_hunk": "@@ -216,3 +216,57 @@\n     .baz()\n )\n \n+# Note in preview we split at `pl` which some\n+# folks may dislike. (Similarly with common\n+# `np` and `pd` invocations).\n+\n+expr = (\n+    pl.scan_parquet(\"/data/pypi-parquet/*.parquet\")\n+    .filter(\n+        [\n+            pl.col(\"path\").str.contains(\n+                r\"\\.(asm|c|cc|cpp|cxx|h|hpp|rs|[Ff][0-9]{0,2}(?:or)?|go)$\"\n+            ),\n+            ~pl.col(\"path\").str.contains(r\"(^|/)test(|s|ing)\"),\n+            ~pl.col(\"path\").str.contains(\"/site-packages/\", literal=True),\n+        ]\n+    )\n+    .with_columns(\n+        month=pl.col(\"uploaded_on\").dt.truncate(\"1mo\"),\n+        ext=pl.col(\"path\")\n+        .str.extract(pattern=r\"\\.([a-z0-9]+)$\", group_index=1)\n+        .str.replace_all(pattern=r\"cxx|cpp|cc|c|hpp|h\", value=\"C/C++\")\n+        .str.replace_all(pattern=\"^f.*$\", value=\"Fortran\")\n+        .str.replace(\"rs\", \"Rust\", literal=True)\n+        .str.replace(\"go\", \"Go\", literal=True)\n+        .str.replace(\"asm\", \"Assembly\", literal=True)\n+        .replace({\"\": None}),\n+    )\n+    .group_by([\"month\", \"ext\"])\n+    .agg(project_count=pl.col(\"project_name\").n_unique())\n+    .drop_nulls([\"ext\"])\n+    .sort([\"month\", \"project_count\"], descending=True)\n+)\n+\n+def indentation_matching_for_loop_in_preview():\n+    if make_this:\n+        if more_nested_because_line_length:\n+            identical_hidden_layer_sizes = all(",
      "comment": "Variable identical_hidden_layer_sizes is not used.\n```suggestion\n            all(\n```",
      "comment_id": 2615739046,
      "user": "Copilot",
      "created_at": "2025-12-12T22:26:47Z",
      "url": "https://github.com/astral-sh/ruff/pull/21369#discussion_r2615739046"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 21369,
      "file_path": "crates/ruff_python_formatter/resources/test/fixtures/ruff/parentheses/call_chains.py",
      "line": 221,
      "side": "RIGHT",
      "diff_hunk": "@@ -216,3 +216,57 @@\n     .baz()\n )\n \n+# Note in preview we split at `pl` which some\n+# folks may dislike. (Similarly with common\n+# `np` and `pd` invocations).",
      "comment": "It might be worth explaining why we do it regardless. I'm sure it will come up in a future issue and I would much appreciate if I came across a comment in code (or test) explaining why we do split after `np`",
      "comment_id": 2618339047,
      "user": "MichaReiser",
      "created_at": "2025-12-15T07:46:41Z",
      "url": "https://github.com/astral-sh/ruff/pull/21369#discussion_r2618339047"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 385,
      "side": "RIGHT",
      "diff_hunk": "@@ -327,6 +380,10 @@ def collect_expected_diagnostics(test_files: Sequence[Path]) -> list[Diagnostic]\n                         ),\n                         source=Source.EXPECTED,\n                         optional=error.group(\"optional\") is not None,\n+                        tag=f\"{file.name}:{error.group('tag')}\"\n+                        if error.group(\"tag\")\n+                        else None,",
      "comment": "Ruff doesn't do a good job right now at formatting nested if-else expressions. But we can help it a bit to make this more readable by adding parentheses\r\n```suggestion\r\n                        tag=(\r\n                        \tf\"{file.name}:{error.group('tag')}\"\r\n                        \tif error.group(\"tag\")\r\n                        \telse None\r\n                      \t),\r\n```",
      "comment_id": 2712875649,
      "user": "MichaReiser",
      "created_at": "2026-01-21T14:40:17Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2712875649"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 471,
      "side": "RIGHT",
      "diff_hunk": "@@ -366,59 +423,77 @@ def collect_ty_diagnostics(\n     ]\n \n \n-def group_diagnostics_by_key(\n-    old: list[Diagnostic], new: list[Diagnostic], expected: list[Diagnostic]\n+def group_diagnostics_by_key_or_tag(\n+    old: list[Diagnostic],\n+    new: list[Diagnostic],\n+    expected: list[Diagnostic],\n ) -> list[GroupedDiagnostics]:\n+    # propagate tags from expected diagnostics to old and new diagnostics\n+    tagged_lines = {\n+        (d.location.path.name, d.location.positions.begin.line): d.tag\n+        for d in expected\n+        if d.tag is not None\n+    }\n+\n+    for diag in old:\n+        diag.tag = tagged_lines.get(\n+            (diag.location.path.name, diag.location.positions.begin.line), None\n+        )\n+\n+    for diag in new:\n+        diag.tag = tagged_lines.get(\n+            (diag.location.path.name, diag.location.positions.begin.line), None\n+        )\n+\n     diagnostics = [\n         *old,\n         *new,\n         *expected,\n     ]\n \n-    sorted_diagnostics = sorted(diagnostics, key=attrgetter(\"key\"))\n-\n-    grouped = []\n-    for key, group in groupby(sorted_diagnostics, key=attrgetter(\"key\")):\n+    # group diagnostics either by a path and a line or a path and a tag\n+    diagnostics = sorted(diagnostics, key=attrgetter(\"key\"))\n+    grouped_diagnostics = []\n+    for key, group in groupby(diagnostics, key=attrgetter(\"key\")):\n         group = list(group)\n-        sources: Source = reduce(or_, (diag.source for diag in group))\n-        grouped.append(\n-            GroupedDiagnostics(\n-                key=key,\n-                sources=sources,\n-                old=next(filter(lambda diag: diag.source == Source.OLD, group), None),\n-                new=next(filter(lambda diag: diag.source == Source.NEW, group), None),\n-                expected=next(\n-                    filter(lambda diag: diag.source == Source.EXPECTED, group), None\n-                ),\n-            )\n+        old_group = list(filter(lambda diag: diag.source == Source.OLD, group))\n+        new_group = list(filter(lambda diag: diag.source == Source.NEW, group))\n+        expected_group = list(\n+            filter(lambda diag: diag.source == Source.EXPECTED, group)\n+        )\n+\n+        grouped = GroupedDiagnostics(\n+            key=key,\n+            sources={d.source for d in group},\n+            old=old_group,\n+            new=new_group,\n+            expected=expected_group,\n         )",
      "comment": "Nit: I would use a regular loop here to avoid iterating `diagnostics` multiple times and also because I find it slightly more readable. But maybe that's the Rust dev in me.\r\n\r\n```py\r\n\t\t\t\told_diagnostics: list[Diagnostic] = []\r\n        new_diagnostics: list[Diagnostic] = []\r\n        expected_diagnostics: list[Diagnostic] = []\r\n        sources: set[Source] = set()\r\n\r\n        for diag in group:\r\n            sources.add(diag.source)\r\n            match diag.source:\r\n                case Source.OLD:\r\n                    old_diagnostics.append(diag)\r\n                case Source.NEW:\r\n                    new_diagnostics.append(diag)\r\n                case Source.EXPECTED:\r\n                    expected_diagnostics.append(diag)\r\n\r\n        grouped = GroupedDiagnostics(\r\n            key=key,\r\n            sources=sources,\r\n            old=old_diagnostics,\r\n            new=new_diagnostics,\r\n            expected=expected_diagnostics,\r\n        )\r\n```",
      "comment_id": 2712882781,
      "user": "MichaReiser",
      "created_at": "2026-01-21T14:41:54Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2712882781"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 482,
      "side": "RIGHT",
      "diff_hunk": "@@ -366,59 +423,77 @@ def collect_ty_diagnostics(\n     ]\n \n \n-def group_diagnostics_by_key(\n-    old: list[Diagnostic], new: list[Diagnostic], expected: list[Diagnostic]\n+def group_diagnostics_by_key_or_tag(\n+    old: list[Diagnostic],\n+    new: list[Diagnostic],\n+    expected: list[Diagnostic],\n ) -> list[GroupedDiagnostics]:\n+    # propagate tags from expected diagnostics to old and new diagnostics\n+    tagged_lines = {\n+        (d.location.path.name, d.location.positions.begin.line): d.tag\n+        for d in expected\n+        if d.tag is not None\n+    }\n+\n+    for diag in old:\n+        diag.tag = tagged_lines.get(\n+            (diag.location.path.name, diag.location.positions.begin.line), None\n+        )\n+\n+    for diag in new:\n+        diag.tag = tagged_lines.get(\n+            (diag.location.path.name, diag.location.positions.begin.line), None\n+        )\n+\n     diagnostics = [\n         *old,\n         *new,\n         *expected,\n     ]\n \n-    sorted_diagnostics = sorted(diagnostics, key=attrgetter(\"key\"))\n-\n-    grouped = []\n-    for key, group in groupby(sorted_diagnostics, key=attrgetter(\"key\")):\n+    # group diagnostics either by a path and a line or a path and a tag\n+    diagnostics = sorted(diagnostics, key=attrgetter(\"key\"))\n+    grouped_diagnostics = []\n+    for key, group in groupby(diagnostics, key=attrgetter(\"key\")):\n         group = list(group)\n-        sources: Source = reduce(or_, (diag.source for diag in group))\n-        grouped.append(\n-            GroupedDiagnostics(\n-                key=key,\n-                sources=sources,\n-                old=next(filter(lambda diag: diag.source == Source.OLD, group), None),\n-                new=next(filter(lambda diag: diag.source == Source.NEW, group), None),\n-                expected=next(\n-                    filter(lambda diag: diag.source == Source.EXPECTED, group), None\n-                ),\n-            )\n+        old_group = list(filter(lambda diag: diag.source == Source.OLD, group))\n+        new_group = list(filter(lambda diag: diag.source == Source.NEW, group))\n+        expected_group = list(\n+            filter(lambda diag: diag.source == Source.EXPECTED, group)\n+        )\n+\n+        grouped = GroupedDiagnostics(\n+            key=key,\n+            sources={d.source for d in group},\n+            old=old_group,\n+            new=new_group,\n+            expected=expected_group,\n         )\n+        grouped_diagnostics.append(grouped)\n \n-    return grouped\n+    return grouped_diagnostics\n \n \n def compute_stats(\n     grouped_diagnostics: list[GroupedDiagnostics],\n     source: Source,\n ) -> Statistics:\n     if source == source.EXPECTED:\n-        # ty currently raises a false positive here due to incomplete enum.Flag support\n-        # see https://github.com/astral-sh/ty/issues/876\n-        num_errors = sum(\n-            1\n-            for g in grouped_diagnostics\n-            if source.EXPECTED in g.sources  # ty:ignore[unsupported-operator]\n-        )\n+        num_errors = sum(1 for g in grouped_diagnostics if source.EXPECTED in g.sources)",
      "comment": "It's a bit tricky to say what `num_errors` means in the presence of `E[tag+]` and `E?` where a single expected tag can have multiple errors and some errors are entirely optional. \r\n\r\nBut it also seems that we never call `compute_stats` with `Source::Expected`. \r\n\r\nShould we remove this code and make `compute_stats` take a boolean argument instead (new_diagnostics)?",
      "comment_id": 2712891753,
      "user": "MichaReiser",
      "created_at": "2026-01-21T14:44:00Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2712891753"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 430,
      "side": "RIGHT",
      "diff_hunk": "@@ -366,59 +423,77 @@ def collect_ty_diagnostics(\n     ]\n \n \n-def group_diagnostics_by_key(\n-    old: list[Diagnostic], new: list[Diagnostic], expected: list[Diagnostic]\n+def group_diagnostics_by_key_or_tag(\n+    old: list[Diagnostic],\n+    new: list[Diagnostic],\n+    expected: list[Diagnostic],\n ) -> list[GroupedDiagnostics]:",
      "comment": "GitHub doesn't really allow me to comment on that line but you could simplify your code a good amount by removing `None` from `old`, `new` and `expected`. Unless I miss a place where you create a `GroupedDiagnostics` instance where those fields are `None`",
      "comment_id": 2712920374,
      "user": "MichaReiser",
      "created_at": "2026-01-21T14:50:32Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2712920374"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 278,
      "side": "RIGHT",
      "diff_hunk": "@@ -241,17 +238,76 @@ def change(self) -> Change:\n \n     @property\n     def optional(self) -> bool:\n-        return self.expected is not None and self.expected.optional\n+        return bool(self.expected) and all(\n+            diagnostic.optional for diagnostic in self.expected\n+        )\n+\n+    @property\n+    def multi(self) -> bool:\n+        return bool(self.expected) and all(\n+            diagnostic.multi for diagnostic in self.expected\n+        )\n+\n+    def diagnostics_by_source(self, source: Source) -> list[Diagnostic]:\n+        match source:\n+            case Source.NEW:\n+                return self.new or []\n+            case Source.OLD:\n+                return self.old or []\n+            case Source.EXPECTED:\n+                return self.expected or []\n+            case _:\n+                raise ValueError(f\"Invalid source: {source}\")\n+\n+    def classify(self, source: Source) -> Classification:\n+        if source in self.sources and Source.EXPECTED in self.sources:\n+            assert self.expected is not None\n+            distinct_lines = len(\n+                {\n+                    diagnostic.location.positions.begin.line\n+                    for diagnostic in self.diagnostics_by_source(source)\n+                }\n+            )\n+            expected_max = len(self.expected) if self.multi else 1\n+\n+            if 1 <= distinct_lines <= expected_max:\n+                return Classification.TRUE_POSITIVE\n+            else:\n+                return Classification.FALSE_POSITIVE\n+\n+        elif source in self.sources and Source.EXPECTED not in self.sources:",
      "comment": "```suggestion\r\n        elif source in self.sources:\r\n```\r\n\r\nI believe the second part is implicitly given by not taking the first if branch\r\n\r\nIt might also be more readable if you nested the conditions like so:\r\n\r\n```py\r\nif source in self.sources:\r\n\tif Source.EXPECTED in self.sources:\r\n\t\tdistinct_lines = ... \r\n\r\n\telse:\r\n\t\treturn Classification.FalsePositive\r\n\r\nelif Source.EXPECTED in self.sources:\r\n\treturn Classification.FALSE_NEGATIVE\r\n\r\nelse: \r\n\treturn Classification.TRUE_NEGATIVE\t\r\n```",
      "comment_id": 2712931785,
      "user": "MichaReiser",
      "created_at": "2026-01-21T14:53:15Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2712931785"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 273,
      "side": "RIGHT",
      "diff_hunk": "@@ -241,17 +238,76 @@ def change(self) -> Change:\n \n     @property\n     def optional(self) -> bool:\n-        return self.expected is not None and self.expected.optional\n+        return bool(self.expected) and all(\n+            diagnostic.optional for diagnostic in self.expected\n+        )\n+\n+    @property\n+    def multi(self) -> bool:\n+        return bool(self.expected) and all(\n+            diagnostic.multi for diagnostic in self.expected\n+        )\n+\n+    def diagnostics_by_source(self, source: Source) -> list[Diagnostic]:\n+        match source:\n+            case Source.NEW:\n+                return self.new or []\n+            case Source.OLD:\n+                return self.old or []\n+            case Source.EXPECTED:\n+                return self.expected or []\n+            case _:\n+                raise ValueError(f\"Invalid source: {source}\")\n+\n+    def classify(self, source: Source) -> Classification:\n+        if source in self.sources and Source.EXPECTED in self.sources:\n+            assert self.expected is not None\n+            distinct_lines = len(\n+                {\n+                    diagnostic.location.positions.begin.line\n+                    for diagnostic in self.diagnostics_by_source(source)\n+                }\n+            )\n+            expected_max = len(self.expected) if self.multi else 1\n+\n+            if 1 <= distinct_lines <= expected_max:",
      "comment": "I can see how classifying too many diagnostics as false positives can be a bit confusing but I think it's the right thing. There's at least one false positive. \r\n\r\nIt might be better to count them as both a true positive and false positive, but I suspect that this doesn't play well with how we use those numbers later on.",
      "comment_id": 2712936781,
      "user": "MichaReiser",
      "created_at": "2026-01-21T14:54:28Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2712936781"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 273,
      "side": "RIGHT",
      "diff_hunk": "@@ -241,17 +238,76 @@ def change(self) -> Change:\n \n     @property\n     def optional(self) -> bool:\n-        return self.expected is not None and self.expected.optional\n+        return bool(self.expected) and all(\n+            diagnostic.optional for diagnostic in self.expected\n+        )\n+\n+    @property\n+    def multi(self) -> bool:\n+        return bool(self.expected) and all(\n+            diagnostic.multi for diagnostic in self.expected\n+        )\n+\n+    def diagnostics_by_source(self, source: Source) -> list[Diagnostic]:\n+        match source:\n+            case Source.NEW:\n+                return self.new or []\n+            case Source.OLD:\n+                return self.old or []\n+            case Source.EXPECTED:\n+                return self.expected or []\n+            case _:\n+                raise ValueError(f\"Invalid source: {source}\")\n+\n+    def classify(self, source: Source) -> Classification:\n+        if source in self.sources and Source.EXPECTED in self.sources:\n+            assert self.expected is not None\n+            distinct_lines = len(\n+                {\n+                    diagnostic.location.positions.begin.line\n+                    for diagnostic in self.diagnostics_by_source(source)\n+                }\n+            )\n+            expected_max = len(self.expected) if self.multi else 1\n+\n+            if 1 <= distinct_lines <= expected_max:",
      "comment": "Makes sense. One advantage of grouping them like this is that you'll be able to see why an error that appears to match a line in the conformance suite is a false positive if another line with the same tag has a diagnostic.",
      "comment_id": 2714696511,
      "user": "WillDuke",
      "created_at": "2026-01-21T23:24:01Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2714696511"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 265,
      "side": "RIGHT",
      "diff_hunk": "@@ -241,17 +238,79 @@ def change(self) -> Change:\n \n     @property\n     def optional(self) -> bool:\n-        return self.expected is not None and self.expected.optional\n+        return bool(self.expected) and all(\n+            diagnostic.optional for diagnostic in self.expected\n+        )\n+\n+    @property\n+    def multi(self) -> bool:\n+        return bool(self.expected) and all(\n+            diagnostic.multi for diagnostic in self.expected\n+        )\n+\n+    def diagnostics_by_source(self, source: Source) -> list[Diagnostic]:\n+        match source:\n+            case Source.NEW:\n+                return self.new\n+            case Source.OLD:\n+                return self.old\n+            case Source.EXPECTED:\n+                return self.expected\n+            case _:\n+                raise ValueError(f\"Invalid source: {source}\")\n+\n+    def classify(self, source: Source) -> Classification:\n+        if source in self.sources:\n+            if Source.EXPECTED in self.sources:\n+                assert self.expected is not None",
      "comment": "I'm surprised that ty doesn't catch this but `self.expected` should never be `None` here",
      "comment_id": 2715756019,
      "user": "MichaReiser",
      "created_at": "2026-01-22T08:05:02Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2715756019"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 260,
      "side": "RIGHT",
      "diff_hunk": "@@ -241,17 +238,79 @@ def change(self) -> Change:\n \n     @property\n     def optional(self) -> bool:\n-        return self.expected is not None and self.expected.optional\n+        return bool(self.expected) and all(\n+            diagnostic.optional for diagnostic in self.expected\n+        )\n+\n+    @property\n+    def multi(self) -> bool:\n+        return bool(self.expected) and all(\n+            diagnostic.multi for diagnostic in self.expected\n+        )\n+\n+    def diagnostics_by_source(self, source: Source) -> list[Diagnostic]:\n+        match source:\n+            case Source.NEW:\n+                return self.new\n+            case Source.OLD:\n+                return self.old\n+            case Source.EXPECTED:\n+                return self.expected\n+            case _:\n+                raise ValueError(f\"Invalid source: {source}\")",
      "comment": "I'm surprised that this last `case` is needed here? Does ty complain without it?",
      "comment_id": 2715758499,
      "user": "MichaReiser",
      "created_at": "2026-01-22T08:05:55Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2715758499"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 487,
      "side": "RIGHT",
      "diff_hunk": "@@ -366,64 +423,88 @@ def collect_ty_diagnostics(\n     ]\n \n \n-def group_diagnostics_by_key(\n-    old: list[Diagnostic], new: list[Diagnostic], expected: list[Diagnostic]\n+def group_diagnostics_by_key_or_tag(\n+    old: list[Diagnostic],\n+    new: list[Diagnostic],\n+    expected: list[Diagnostic],\n ) -> list[GroupedDiagnostics]:\n+    # propagate tags from expected diagnostics to old and new diagnostics\n+    tagged_lines = {\n+        (d.location.path.name, d.location.positions.begin.line): d.tag\n+        for d in expected\n+        if d.tag is not None\n+    }\n+\n+    for diag in old:\n+        diag.tag = tagged_lines.get(\n+            (diag.location.path.name, diag.location.positions.begin.line), None\n+        )\n+\n+    for diag in new:\n+        diag.tag = tagged_lines.get(\n+            (diag.location.path.name, diag.location.positions.begin.line), None\n+        )\n+\n     diagnostics = [\n         *old,\n         *new,\n         *expected,\n     ]\n \n-    sorted_diagnostics = sorted(diagnostics, key=attrgetter(\"key\"))\n-\n-    grouped = []\n-    for key, group in groupby(sorted_diagnostics, key=attrgetter(\"key\")):\n-        group = list(group)\n-        sources: Source = reduce(or_, (diag.source for diag in group))\n-        grouped.append(\n-            GroupedDiagnostics(\n-                key=key,\n-                sources=sources,\n-                old=next(filter(lambda diag: diag.source == Source.OLD, group), None),\n-                new=next(filter(lambda diag: diag.source == Source.NEW, group), None),\n-                expected=next(\n-                    filter(lambda diag: diag.source == Source.EXPECTED, group), None\n-                ),\n-            )\n+    # group diagnostics by a key which may be a path and a line or a path and a tag\n+    diagnostics = sorted(diagnostics, key=attrgetter(\"key\"))\n+    grouped_diagnostics = []\n+    for key, group in groupby(diagnostics, key=attrgetter(\"key\")):\n+        old_diagnostics: list[Diagnostic] = []\n+        new_diagnostics: list[Diagnostic] = []\n+        expected_diagnostics: list[Diagnostic] = []\n+        sources: set[Source] = set()\n+\n+        for diag in group:\n+            sources.add(diag.source)\n+            match diag.source:\n+                case Source.OLD:\n+                    old_diagnostics.append(diag)\n+                case Source.NEW:\n+                    new_diagnostics.append(diag)\n+                case Source.EXPECTED:\n+                    expected_diagnostics.append(diag)\n+\n+        grouped = GroupedDiagnostics(\n+            key=key,\n+            sources=sources,\n+            old=old_diagnostics,\n+            new=new_diagnostics,\n+            expected=expected_diagnostics,\n         )\n+        grouped_diagnostics.append(grouped)\n \n-    return grouped\n+    return grouped_diagnostics\n \n \n def compute_stats(\n     grouped_diagnostics: list[GroupedDiagnostics],\n-    source: Source,\n+    ty_version: Literal[\"new\", \"old\"],",
      "comment": "This is nice. Does Python allow us to define a union over `Source.NEW | Source.OLD` or is this something Python doesn't support?",
      "comment_id": 2715761401,
      "user": "MichaReiser",
      "created_at": "2026-01-22T08:06:50Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2715761401"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 487,
      "side": "RIGHT",
      "diff_hunk": "@@ -366,64 +423,88 @@ def collect_ty_diagnostics(\n     ]\n \n \n-def group_diagnostics_by_key(\n-    old: list[Diagnostic], new: list[Diagnostic], expected: list[Diagnostic]\n+def group_diagnostics_by_key_or_tag(\n+    old: list[Diagnostic],\n+    new: list[Diagnostic],\n+    expected: list[Diagnostic],\n ) -> list[GroupedDiagnostics]:\n+    # propagate tags from expected diagnostics to old and new diagnostics\n+    tagged_lines = {\n+        (d.location.path.name, d.location.positions.begin.line): d.tag\n+        for d in expected\n+        if d.tag is not None\n+    }\n+\n+    for diag in old:\n+        diag.tag = tagged_lines.get(\n+            (diag.location.path.name, diag.location.positions.begin.line), None\n+        )\n+\n+    for diag in new:\n+        diag.tag = tagged_lines.get(\n+            (diag.location.path.name, diag.location.positions.begin.line), None\n+        )\n+\n     diagnostics = [\n         *old,\n         *new,\n         *expected,\n     ]\n \n-    sorted_diagnostics = sorted(diagnostics, key=attrgetter(\"key\"))\n-\n-    grouped = []\n-    for key, group in groupby(sorted_diagnostics, key=attrgetter(\"key\")):\n-        group = list(group)\n-        sources: Source = reduce(or_, (diag.source for diag in group))\n-        grouped.append(\n-            GroupedDiagnostics(\n-                key=key,\n-                sources=sources,\n-                old=next(filter(lambda diag: diag.source == Source.OLD, group), None),\n-                new=next(filter(lambda diag: diag.source == Source.NEW, group), None),\n-                expected=next(\n-                    filter(lambda diag: diag.source == Source.EXPECTED, group), None\n-                ),\n-            )\n+    # group diagnostics by a key which may be a path and a line or a path and a tag\n+    diagnostics = sorted(diagnostics, key=attrgetter(\"key\"))\n+    grouped_diagnostics = []\n+    for key, group in groupby(diagnostics, key=attrgetter(\"key\")):\n+        old_diagnostics: list[Diagnostic] = []\n+        new_diagnostics: list[Diagnostic] = []\n+        expected_diagnostics: list[Diagnostic] = []\n+        sources: set[Source] = set()\n+\n+        for diag in group:\n+            sources.add(diag.source)\n+            match diag.source:\n+                case Source.OLD:\n+                    old_diagnostics.append(diag)\n+                case Source.NEW:\n+                    new_diagnostics.append(diag)\n+                case Source.EXPECTED:\n+                    expected_diagnostics.append(diag)\n+\n+        grouped = GroupedDiagnostics(\n+            key=key,\n+            sources=sources,\n+            old=old_diagnostics,\n+            new=new_diagnostics,\n+            expected=expected_diagnostics,\n         )\n+        grouped_diagnostics.append(grouped)\n \n-    return grouped\n+    return grouped_diagnostics\n \n \n def compute_stats(\n     grouped_diagnostics: list[GroupedDiagnostics],\n-    source: Source,\n+    ty_version: Literal[\"new\", \"old\"],",
      "comment": "I tried the same thing, but unfortunately it does not!",
      "comment_id": 2718728396,
      "user": "WillDuke",
      "created_at": "2026-01-22T21:37:33Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2718728396"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 260,
      "side": "RIGHT",
      "diff_hunk": "@@ -241,17 +238,79 @@ def change(self) -> Change:\n \n     @property\n     def optional(self) -> bool:\n-        return self.expected is not None and self.expected.optional\n+        return bool(self.expected) and all(\n+            diagnostic.optional for diagnostic in self.expected\n+        )\n+\n+    @property\n+    def multi(self) -> bool:\n+        return bool(self.expected) and all(\n+            diagnostic.multi for diagnostic in self.expected\n+        )\n+\n+    def diagnostics_by_source(self, source: Source) -> list[Diagnostic]:\n+        match source:\n+            case Source.NEW:\n+                return self.new\n+            case Source.OLD:\n+                return self.old\n+            case Source.EXPECTED:\n+                return self.expected\n+            case _:\n+                raise ValueError(f\"Invalid source: {source}\")",
      "comment": "Just defensive programming while I was writing this!",
      "comment_id": 2718740704,
      "user": "WillDuke",
      "created_at": "2026-01-22T21:41:08Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2718740704"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 107,
      "side": "RIGHT",
      "diff_hunk": "@@ -105,6 +103,15 @@ def into_title(self) -> str:\n                 return \"True positives removed\"\n \n \n+@dataclass(kw_only=True, slots=True)\n+class Evaluation:",
      "comment": "This class feels pretty heavy only to support the case where one group has both true and false positives. \r\n\r\nI was wondering if we could change `classify` to return an iterable of `(Classification, int)` instead. Most groups return exactly one, with the exception of the `many` case where ty emits too many diagnostics, in which case we return two.",
      "comment_id": 2721493099,
      "user": "MichaReiser",
      "created_at": "2026-01-23T14:43:12Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2721493099"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22746,
      "file_path": "scripts/conformance.py",
      "line": 107,
      "side": "RIGHT",
      "diff_hunk": "@@ -105,6 +103,15 @@ def into_title(self) -> str:\n                 return \"True positives removed\"\n \n \n+@dataclass(kw_only=True, slots=True)\n+class Evaluation:",
      "comment": "With the last set of changes, we now count the diagnostics individually. So if ty emits 5 diagnostics on the same line where a \"# E\" is present, we're counting them all as true positives. Similarly, if ty raises 3 diagnostics on one line of a tagged group (no '+') and 1 on each of the other lines, we count the 3 diagnostics as true positives and the remainder as false positives. \n\nHappy to keep iterating on it though if this doesn't make sense. ",
      "comment_id": 2723118794,
      "user": "WillDuke",
      "created_at": "2026-01-23T22:54:13Z",
      "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2723118794"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22234,
      "file_path": "crates/ruff_linter/resources/test/fixtures/refurb/FURB180.py",
      "line": 92,
      "side": "RIGHT",
      "diff_hunk": "@@ -56,3 +56,37 @@ def foo(self): pass\n class A7(B0, abc.ABC, B1):\n     @abstractmethod\n     def foo(self): pass\n+\n+\n+# Regression tests for https://github.com/astral-sh/ruff/issues/17162\n+class A8(abc.ABC, metaclass=ABCMeta):  # FURB180\n+    @abstractmethod\n+    def foo(self):\n+        pass\n+\n+\n+def a9():\n+    from abc import ABC\n+\n+    class A9(ABC, metaclass=ABCMeta):  # FURB180\n+        @abstractmethod\n+        def foo(self):\n+            pass\n+\n+\n+def a10():\n+    from abc import ABC as ABCAlternativeName\n+\n+    class A10(ABCAlternativeName, metaclass=ABCMeta):  # FURB180\n+        @abstractmethod\n+        def foo(self):\n+            pass\n+\n+\n+class MyMetaClass(abc.ABC): ...\n+\n+\n+class A11(MyMetaClass, metaclass=ABCMeta):  # FURB180\n+    @abstractmethod\n+    def foo(self):\n+        pass",
      "comment": "Could you add a test case for the unsafe comment deletion? I think something like this example would work well:\n\n```py\nclass C(\n    other_kwarg=1,\n    # comment\n    metaclass=abc.ABCMeta,\n):\n    pass\n```",
      "comment_id": 2699959682,
      "user": "ntBre",
      "created_at": "2026-01-16T21:02:50Z",
      "url": "https://github.com/astral-sh/ruff/pull/22234#discussion_r2699959682"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22234,
      "file_path": "crates/ruff_linter/resources/test/fixtures/refurb/FURB180.py",
      "line": 92,
      "side": "RIGHT",
      "diff_hunk": "@@ -56,3 +56,37 @@ def foo(self): pass\n class A7(B0, abc.ABC, B1):\n     @abstractmethod\n     def foo(self): pass\n+\n+\n+# Regression tests for https://github.com/astral-sh/ruff/issues/17162\n+class A8(abc.ABC, metaclass=ABCMeta):  # FURB180\n+    @abstractmethod\n+    def foo(self):\n+        pass\n+\n+\n+def a9():\n+    from abc import ABC\n+\n+    class A9(ABC, metaclass=ABCMeta):  # FURB180\n+        @abstractmethod\n+        def foo(self):\n+            pass\n+\n+\n+def a10():\n+    from abc import ABC as ABCAlternativeName\n+\n+    class A10(ABCAlternativeName, metaclass=ABCMeta):  # FURB180\n+        @abstractmethod\n+        def foo(self):\n+            pass\n+\n+\n+class MyMetaClass(abc.ABC): ...\n+\n+\n+class A11(MyMetaClass, metaclass=ABCMeta):  # FURB180\n+    @abstractmethod\n+    def foo(self):\n+        pass",
      "comment": "Sure, the test case was added: https://github.com/astral-sh/ruff/pull/22234/changes/9c429186ed3eb060415d1b67f4c5ae96ad64722b",
      "comment_id": 2700644360,
      "user": "akawd",
      "created_at": "2026-01-17T05:03:33Z",
      "url": "https://github.com/astral-sh/ruff/pull/22234#discussion_r2700644360"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22320,
      "file_path": "crates/ruff_linter/resources/test/fixtures/pyupgrade/UP045_py39.py",
      "line": 15,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,15 @@\n+\"\"\"\n+Regression test for https://github.com/astral-sh/ruff/issues/20096\n+\"\"\"\n+\n+from __future__ import annotations\n+\n+from typing import Optional, cast, TypeAlias\n+\n+\n+x: Optional[str]             # UP045\n+x: \"Optional[str]\"           # UP045\n+cast(\"Optional[str]\", None)  # UP045\n+cast(Optional[str], None)    # okay, str | None is a runtime error\n+x: TypeAlias = \"Optional[str]\"  # UP045\n+x: TypeAlias = Optional[str]  # okay",
      "comment": "Can we add some tests for \"Complex\" string annotations (an annotation that uses implicit string concatenation). ",
      "comment_id": 2661017993,
      "user": "MichaReiser",
      "created_at": "2026-01-05T10:28:32Z",
      "url": "https://github.com/astral-sh/ruff/pull/22320#discussion_r2661017993"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22320,
      "file_path": "crates/ruff_linter/resources/test/fixtures/pyupgrade/UP045_py39.py",
      "line": 15,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,15 @@\n+\"\"\"\n+Regression test for https://github.com/astral-sh/ruff/issues/20096\n+\"\"\"\n+\n+from __future__ import annotations\n+\n+from typing import Optional, cast, TypeAlias\n+\n+\n+x: Optional[str]             # UP045\n+x: \"Optional[str]\"           # UP045\n+cast(\"Optional[str]\", None)  # UP045\n+cast(Optional[str], None)    # okay, str | None is a runtime error\n+x: TypeAlias = \"Optional[str]\"  # UP045\n+x: TypeAlias = Optional[str]  # okay",
      "comment": "Interestingly, the complex cases don't emit diagnostics even with my change. Claude thinks this is a bug, but I'll have to dig into it a bit more.\n\nty also emits an [implicit-concatenated-string-type-annotation](https://docs.astral.sh/ty/reference/rules/#implicit-concatenated-string-type-annotation) diagnostic on the new test cases, so I could possibly just replace `in_string_type_definition` with `in_simple_string_type_definition` if we want to filter out the complex cases intentionally.",
      "comment_id": 2684195946,
      "user": "ntBre",
      "created_at": "2026-01-12T23:07:35Z",
      "url": "https://github.com/astral-sh/ruff/pull/22320#discussion_r2684195946"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22320,
      "file_path": "crates/ruff_linter/resources/test/fixtures/pyupgrade/UP045_py39.py",
      "line": 15,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,15 @@\n+\"\"\"\n+Regression test for https://github.com/astral-sh/ruff/issues/20096\n+\"\"\"\n+\n+from __future__ import annotations\n+\n+from typing import Optional, cast, TypeAlias\n+\n+\n+x: Optional[str]             # UP045\n+x: \"Optional[str]\"           # UP045\n+cast(\"Optional[str]\", None)  # UP045\n+cast(Optional[str], None)    # okay, str | None is a runtime error\n+x: TypeAlias = \"Optional[str]\"  # UP045\n+x: TypeAlias = Optional[str]  # okay",
      "comment": "Yeah, this is a bit surprising. Let me know if you want me to take a closer look",
      "comment_id": 2711917554,
      "user": "MichaReiser",
      "created_at": "2026-01-21T10:23:07Z",
      "url": "https://github.com/astral-sh/ruff/pull/22320#discussion_r2711917554"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22320,
      "file_path": "crates/ruff_linter/resources/test/fixtures/pyupgrade/UP045_py39.py",
      "line": 15,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,15 @@\n+\"\"\"\n+Regression test for https://github.com/astral-sh/ruff/issues/20096\n+\"\"\"\n+\n+from __future__ import annotations\n+\n+from typing import Optional, cast, TypeAlias\n+\n+\n+x: Optional[str]             # UP045\n+x: \"Optional[str]\"           # UP045\n+cast(\"Optional[str]\", None)  # UP045\n+cast(Optional[str], None)    # okay, str | None is a runtime error\n+x: TypeAlias = \"Optional[str]\"  # UP045\n+x: TypeAlias = Optional[str]  # okay",
      "comment": "I think I'll just close this for now, unless you think it's worth landing without looking into the (arguably separate) issue with concatenated annotations. This is a pretty niche issue in any case.",
      "comment_id": 2713264436,
      "user": "ntBre",
      "created_at": "2026-01-21T16:06:15Z",
      "url": "https://github.com/astral-sh/ruff/pull/22320#discussion_r2713264436"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22320,
      "file_path": "crates/ruff_linter/resources/test/fixtures/pyupgrade/UP045_py39.py",
      "line": 15,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,15 @@\n+\"\"\"\n+Regression test for https://github.com/astral-sh/ruff/issues/20096\n+\"\"\"\n+\n+from __future__ import annotations\n+\n+from typing import Optional, cast, TypeAlias\n+\n+\n+x: Optional[str]             # UP045\n+x: \"Optional[str]\"           # UP045\n+cast(\"Optional[str]\", None)  # UP045\n+cast(Optional[str], None)    # okay, str | None is a runtime error\n+x: TypeAlias = \"Optional[str]\"  # UP045\n+x: TypeAlias = Optional[str]  # okay",
      "comment": "What you have here seems better than what we had before and should cover the majority of stringified type annotations",
      "comment_id": 2715700468,
      "user": "MichaReiser",
      "created_at": "2026-01-22T07:45:36Z",
      "url": "https://github.com/astral-sh/ruff/pull/22320#discussion_r2715700468"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22320,
      "file_path": "crates/ruff_linter/resources/test/fixtures/pyupgrade/UP045_py39.py",
      "line": 17,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,35 @@\n+\"\"\"\n+Regression test for https://github.com/astral-sh/ruff/issues/20096\n+\"\"\"\n+\n+from __future__ import annotations\n+\n+from typing import Optional, cast, TypeAlias\n+\n+\n+x: Optional[str]             # UP045\n+x: \"Optional[str]\"           # UP045\n+cast(\"Optional[str]\", None)  # UP045\n+cast(Optional[str], None)    # okay, str | None is a runtime error\n+x: TypeAlias = \"Optional[str]\"  # UP045\n+x: TypeAlias = Optional[str]  # okay\n+\n+# complex (implicitly concatenated) annotations",
      "comment": "Let's add a TODO comment here to make it clear, that the rule isn't currently handling implicitly concatenated strings.",
      "comment_id": 2715701759,
      "user": "MichaReiser",
      "created_at": "2026-01-22T07:46:04Z",
      "url": "https://github.com/astral-sh/ruff/pull/22320#discussion_r2715701759"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22320,
      "file_path": "crates/ruff_linter/resources/test/fixtures/pyupgrade/UP045_py39.py",
      "line": 15,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,15 @@\n+\"\"\"\n+Regression test for https://github.com/astral-sh/ruff/issues/20096\n+\"\"\"\n+\n+from __future__ import annotations\n+\n+from typing import Optional, cast, TypeAlias\n+\n+\n+x: Optional[str]             # UP045\n+x: \"Optional[str]\"           # UP045\n+cast(\"Optional[str]\", None)  # UP045\n+cast(Optional[str], None)    # okay, str | None is a runtime error\n+x: TypeAlias = \"Optional[str]\"  # UP045\n+x: TypeAlias = Optional[str]  # okay",
      "comment": "Sorry, I only just realized that my comment probably made it sound like I had left a bug in the PR. When Claude and I looked into it, the bug appears to be upstream of the rule itself in our complex string annotation parsing, or at least in how that parsing interacts with our semantic model. I think the rule itself is behaving correctly with the annotations it's asked to check.\r\n\r\nThanks for taking another look!",
      "comment_id": 2717344978,
      "user": "ntBre",
      "created_at": "2026-01-22T15:14:30Z",
      "url": "https://github.com/astral-sh/ruff/pull/22320#discussion_r2717344978"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22798,
      "file_path": "crates/ruff_linter/resources/test/fixtures/flake8_pyi/PYI034.py",
      "line": 330,
      "side": "RIGHT",
      "diff_hunk": "@@ -323,6 +323,13 @@ def __iadd__(self, other: \"UsesStringizedAnnotations\") -> \"typing.Self\":\n         return self\n \n \n+class UsesStringizedForwardReferences:\n+    def __new__(cls) -> \"UsesStringizedForwardReferences\": ...       # PYI034\n+    def __enter__(self) -> \"UsesStringizedForwardReferences\": ...    # PYI034\n+    async def __aenter__(self) -> \"UsesStringizedForwardReferences\": ...  # PYI034\n+    def __iadd__(self, other) -> \"UsesStringizedForwardReferences\": ...  # PYI034",
      "comment": "nit: could you possibly move this to the end of the fixture file? It's very hard to review the diff to the snapshot when all the line numbers change \ud83d\ude06",
      "comment_id": 2716597174,
      "user": "AlexWaygood",
      "created_at": "2026-01-22T11:55:47Z",
      "url": "https://github.com/astral-sh/ruff/pull/22798#discussion_r2716597174"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 21110,
      "file_path": "crates/ruff_python_formatter/resources/test/fixtures/ruff/newlines.py",
      "line": 374,
      "side": "RIGHT",
      "diff_hunk": "@@ -335,3 +335,40 @@ def overload4():\n     # trailing comment\n \n def overload4(a: int): ...\n+\n+\n+# In preview, we preserve these newlines at the start of functions:\n+def preserved1():\n+\n+    return 1\n+\n+def preserved2():\n+\n+    pass\n+\n+\n+# But we still discard these newlines:\n+def removed1():\n+\n+    \"Docstring\"\n+\n+    return 1\n+\n+\n+def removed2():\n+\n+    # Comment\n+\n+    return 1\n+\n+\n+def removed3():\n+\n+    ...\n+\n+\n+# And we discard empty lines after the first:\n+def partially_preserved1():\n+\n+\n+    return 1",
      "comment": "Can we add more tests to this, specifically tests including comments or cases where the first element is a function on its own?",
      "comment_id": 2473686964,
      "user": "MichaReiser",
      "created_at": "2025-10-29T15:07:52Z",
      "url": "https://github.com/astral-sh/ruff/pull/21110#discussion_r2473686964"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22671,
      "file_path": "scripts/conformance.py",
      "line": 300,
      "side": "RIGHT",
      "diff_hunk": "@@ -297,8 +297,12 @@ def total(self) -> int:\n \n def collect_expected_diagnostics(path: Path) -> list[Diagnostic]:\n     diagnostics: list[Diagnostic] = []\n-    for file in path.resolve().rglob(\"*.py\"):\n-        for idx, line in enumerate(file.read_text().splitlines(), 1):\n+    for entry in path.iterdir():",
      "comment": "I'm surprised that Python's globbing doesn't support multiple extensions, e.g. `.{py,pyi}`",
      "comment_id": 2702308348,
      "user": "MichaReiser",
      "created_at": "2026-01-18T10:45:52Z",
      "url": "https://github.com/astral-sh/ruff/pull/22671#discussion_r2702308348"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22671,
      "file_path": "scripts/conformance.py",
      "line": 303,
      "side": "RIGHT",
      "diff_hunk": "@@ -297,8 +297,12 @@ def total(self) -> int:\n \n def collect_expected_diagnostics(path: Path) -> list[Diagnostic]:\n     diagnostics: list[Diagnostic] = []\n-    for file in path.resolve().rglob(\"*.py\"):\n-        for idx, line in enumerate(file.read_text().splitlines(), 1):\n+    for entry in path.iterdir():\n+        if not entry.is_file():\n+            continue\n+        if entry.suffix not in {\".py\", \".pyi\"}:",
      "comment": "Should we skip files starting with an `_`? I assume it's not strictly necessary, since they never contain any comments matching the error pattern but it feels unnecessary",
      "comment_id": 2702309581,
      "user": "MichaReiser",
      "created_at": "2026-01-18T10:47:07Z",
      "url": "https://github.com/astral-sh/ruff/pull/22671#discussion_r2702309581"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22671,
      "file_path": "scripts/conformance.py",
      "line": 355,
      "side": "RIGHT",
      "diff_hunk": "@@ -345,7 +349,11 @@ def collect_ty_diagnostics(\n             f\"--python-version={python_version}\",\n             \"--output-format=gitlab\",\n             \"--exit-zero\",\n-            tests_path,\n+            *(\n+                str(path)\n+                for path in Path(tests_path).iterdir()\n+                if path.suffix in {\".py\", \".pyi\"} and not path.name.startswith(\"_\")",
      "comment": "Should we create a helper method that, given a path, returns whether this is a conformance test file?",
      "comment_id": 2702310372,
      "user": "MichaReiser",
      "created_at": "2026-01-18T10:47:47Z",
      "url": "https://github.com/astral-sh/ruff/pull/22671#discussion_r2702310372"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22647,
      "file_path": "scripts/conformance.py",
      "line": 118,
      "side": "RIGHT",
      "diff_hunk": "@@ -101,6 +103,21 @@ def into_title(self) -> str:\n                 return \"True positives removed\"\n \n \n+class Change(StrEnum):\n+    ADDED = auto()\n+    REMOVED = auto()\n+    UNCHANGED = auto()\n+\n+    def into_title(self) -> str:\n+        match self:\n+            case Change.ADDED:\n+                return \"Added (Optional)\"\n+            case Change.REMOVED:\n+                return \"Removed (Optional)\"\n+            case Change.UNCHANGED:\n+                return \"Unchanged (Optional)\"",
      "comment": "```suggestion\r\n                return \"Optional Diagnostics Added\"\r\n            case Change.REMOVED:\r\n                return \"Optional Diagnostics Removed\"\r\n            case Change.UNCHANGED:\r\n                return \"Optional Diagnostics Unchanged\"\r\n```",
      "comment_id": 2701042575,
      "user": "AlexWaygood",
      "created_at": "2026-01-17T12:23:32Z",
      "url": "https://github.com/astral-sh/ruff/pull/22647#discussion_r2701042575"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22647,
      "file_path": "scripts/conformance.py",
      "line": 156,
      "side": "RIGHT",
      "diff_hunk": "@@ -136,8 +153,11 @@ class Diagnostic:\n     fingerprint: str | None\n     location: Location\n     source: Source\n+    optional: bool",
      "comment": "It doesn't need to be in this PR, but it might be good if we could add some docs for the fields on this class at some point. `optional` is fairly clear, but I'd have to study the script a bit to figure out what e.g. `fingerprint` is \ud83d\ude04",
      "comment_id": 2701043523,
      "user": "AlexWaygood",
      "created_at": "2026-01-17T12:24:34Z",
      "url": "https://github.com/astral-sh/ruff/pull/22647#discussion_r2701043523"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22647,
      "file_path": "scripts/conformance.py",
      "line": 452,
      "side": "RIGHT",
      "diff_hunk": "@@ -397,13 +431,25 @@ def render_grouped_diagnostics(\n     format: Literal[\"diff\", \"github\"] = \"diff\",\n ) -> str:\n     if changed_only:\n-        grouped = [diag for diag in grouped if diag.changed]\n+        grouped = [\n+            diag for diag in grouped if diag.change in (Change.ADDED, Change.REMOVED)\n+        ]\n \n-    sorted_by_class = sorted(\n-        grouped,\n+    g1, g2 = tee(grouped)\n+    required, optional = (\n+        filterfalse(attrgetter(\"optional\"), g1),\n+        filter(attrgetter(\"optional\"), g2),\n+    )\n+    required = sorted(\n+        required,\n         key=attrgetter(\"classification\"),\n         reverse=True,\n     )\n+    optional = sorted(\n+        optional,\n+        key=attrgetter(\"change\"),\n+        reverse=True,\n+    )",
      "comment": "I think in this case, you can do this in a slightly more readable way without the `tee` ;)\r\n\r\nWhat about something like\r\n\r\n```diff\r\ndiff --git a/scripts/conformance.py b/scripts/conformance.py\r\nindex f8e7124d8a..383c5eb6bf 100644\r\n--- a/scripts/conformance.py\r\n+++ b/scripts/conformance.py\r\n@@ -435,19 +435,17 @@ def render_grouped_diagnostics(\r\n             diag for diag in grouped if diag.change in (Change.ADDED, Change.REMOVED)\r\n         ]\r\n \r\n-    g1, g2 = tee(grouped)\r\n-    required, optional = (\r\n-        filterfalse(attrgetter(\"optional\"), g1),\r\n-        filter(attrgetter(\"optional\"), g2),\r\n-    )\r\n-    required = sorted(\r\n-        required,\r\n-        key=attrgetter(\"classification\"),\r\n+    get_change = attrgetter(\"change\")\r\n+    get_classification = attrgetter(\"classification\")\r\n+\r\n+    optional_diagnostics = sorted(\r\n+        (diag for diag in grouped if diag.optional),\r\n+        key=get_change,\r\n         reverse=True,\r\n     )\r\n-    optional = sorted(\r\n-        optional,\r\n-        key=attrgetter(\"change\"),\r\n+    required_diagnostics = sorted(\r\n+        (diag for diag in grouped if not diag.optional),\r\n+        key=get_classification,\r\n         reverse=True,\r\n     )\r\n \r\n@@ -466,8 +464,8 @@ def render_grouped_diagnostics(\r\n \r\n     lines = []\r\n     for group, diagnostics in chain(\r\n-        groupby(required, key=attrgetter(\"classification\")),\r\n-        groupby(optional, key=attrgetter(\"change\")),\r\n+        groupby(required_diagnostics, key=get_classification),\r\n+        groupby(optional_diagnostics, key=get_change),\r\n     ):\r\n         lines.append(f\"### {group.into_title()}\")\r\n         lines.extend([\"\", \"<details>\", \"\"])\r\n```",
      "comment_id": 2701049489,
      "user": "AlexWaygood",
      "created_at": "2026-01-17T12:30:40Z",
      "url": "https://github.com/astral-sh/ruff/pull/22647#discussion_r2701049489"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22647,
      "file_path": "scripts/conformance.py",
      "line": 156,
      "side": "RIGHT",
      "diff_hunk": "@@ -136,8 +153,11 @@ class Diagnostic:\n     fingerprint: str | None\n     location: Location\n     source: Source\n+    optional: bool",
      "comment": "Makes sense. Regarding the fingerprint, I'm just preserving the data returned from `ty` in the gitlab output. I assume it provides a unique identifier for that diagnostic, but I don't actually know! Maybe it would be best to drop it since it is not used.",
      "comment_id": 2701064831,
      "user": "WillDuke",
      "created_at": "2026-01-17T12:45:05Z",
      "url": "https://github.com/astral-sh/ruff/pull/22647#discussion_r2701064831"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22114,
      "file_path": "crates/ruff_linter/resources/test/fixtures/ruff/RUF068.py",
      "line": 23,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,34 @@\n+import typing\n+\n+\n+class A: ...\n+\n+\n+class B: ...\n+\n+\n+# Good\n+__all__ = \"A\" + \"B\"\n+__all__: list[str] = [\"A\", \"B\"]\n+__all__: typing.Any = (\"A\", \"B\")\n+__all__ = [\"A\", \"B\"]\n+__all__ += [\"A\", \"B\"]\n+__all__.extend([\"A\", \"B\"])\n+\n+# Bad\n+__all__: list[str] = [\"A\", \"B\", \"A\"]\n+__all__: typing.Any = (\"A\", \"B\", \"B\")\n+__all__ = [\"A\", \"A\", \"B\"]\n+__all__ = [\"A\", \"B\", \"A\"]\n+__all__ = [\"A\", \"A\", \"B\", \"B\"]",
      "comment": "Let's throw in one multi-line case without comments.",
      "comment_id": 2656479847,
      "user": "ntBre",
      "created_at": "2026-01-01T16:38:35Z",
      "url": "https://github.com/astral-sh/ruff/pull/22114#discussion_r2656479847"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22114,
      "file_path": "crates/ruff_linter/resources/test/fixtures/ruff/RUF069.py",
      "line": 32,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,33 @@\n+import typing\n+\n+\n+class A: ...\n+\n+\n+class B: ...\n+\n+\n+# Good\n+__all__ = \"A\" + \"B\"\n+__all__: list[str] = [\"A\", \"B\"]\n+__all__: typing.Any = (\"A\", \"B\")\n+__all__ = [\"A\", \"B\"]\n+__all__ += [\"A\", \"B\"]\n+__all__.extend([\"A\", \"B\"])\n+\n+# Bad\n+__all__: list[str] = [\"A\", \"B\", \"A\"]\n+__all__: typing.Any = (\"A\", \"B\", \"B\")\n+__all__ = [\"A\", \"B\", \"A\"]\n+__all__ = [\"A\", \"A\", \"B\", \"B\"]\n+__all__ += [\"B\", \"B\"]\n+__all__.extend([\"B\", \"B\"])\n+\n+# Bad, unsafe\n+__all__ = [\n+    \"A\",\n+    \"A\",\n+    \"B\",\n+    # Comment\n+    \"B\",",
      "comment": "Can we add an end-of-line comment too? And maybe one after the deleted element, just to check which comments get deleted.\n\n\n```suggestion\n    \"B\",  # 2\n    # 3\n```",
      "comment_id": 2683974284,
      "user": "ntBre",
      "created_at": "2026-01-12T21:31:27Z",
      "url": "https://github.com/astral-sh/ruff/pull/22114#discussion_r2683974284"
    },
    {
      "repo": "astral-sh/ruff",
      "pr_number": 22114,
      "file_path": "crates/ruff_linter/resources/test/fixtures/ruff/RUF069.py",
      "line": 15,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,41 @@\n+import typing\n+\n+\n+class A: ...\n+\n+\n+class B: ...\n+\n+\n+# Good\n+__all__ = \"A\" + \"B\"\n+__all__: list[str] = [\"A\", \"B\"]\n+__all__: typing.Any = (\"A\", \"B\")\n+__all__ = [\"A\", \"B\"]\n+__all__ = [A, \"A\", \"B\"]",
      "comment": "I think this is actually what I meant in https://github.com/astral-sh/ruff/pull/22114#discussion_r2656477043:\n\n\n```suggestion\n__all__ = [A, \"B\", \"B\"]\n```\n\nSorry for being quite pedantic, I just want to have one test case for the `continue` vs `return` choice.",
      "comment_id": 2699643146,
      "user": "ntBre",
      "created_at": "2026-01-16T19:01:58Z",
      "url": "https://github.com/astral-sh/ruff/pull/22114#discussion_r2699643146"
    }
  ]
}