{
  "repo": "psf/requests",
  "scraped_at": "2026-02-03T10:40:19.678085",
  "stats": {
    "total_comments": 267,
    "filtered": {
      "not_python": 62,
      "too_short": 59,
      "no_diff_hunk": 1,
      "too_long": 1,
      "skip_pattern:thank you": 1,
      "skip_pattern:nit:": 1
    },
    "kept": 142
  },
  "examples": [
    {
      "repo": "psf/requests",
      "pr_number": 6724,
      "file_path": "src/requests/adapters.py",
      "line": 113,
      "side": "RIGHT",
      "diff_hunk": "@@ -90,13 +98,19 @@ def _urllib3_request_context(\n     parsed_request_url = urlparse(request.url)\n     scheme = parsed_request_url.scheme.lower()\n     port = parsed_request_url.port\n+\n+    # Determine if we have and should use our default SSLContext\n+    # to optimize performance on standard requests.\n     poolmanager_kwargs = getattr(poolmanager, \"connection_pool_kw\", {})\n     has_poolmanager_ssl_context = poolmanager_kwargs.get(\"ssl_context\")\n+    should_use_default_ssl_context = (\n+        _preloaded_ssl_context is not None and not has_poolmanager_ssl_context\n+    )\n \n     cert_reqs = \"CERT_REQUIRED\"\n     if verify is False:\n         cert_reqs = \"CERT_NONE\"\n-    elif verify is True and not has_poolmanager_ssl_context:\n+    elif verify is True and should_use_default_ssl_context:",
      "comment": "Missed this earlier but do we need any logic for verify=True without a condition here? ",
      "comment_id": 1617854876,
      "user": "sigmavirus24",
      "created_at": "2024-05-28T20:27:08Z",
      "url": "https://github.com/psf/requests/pull/6724#discussion_r1617854876"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6724,
      "file_path": "src/requests/adapters.py",
      "line": 113,
      "side": "RIGHT",
      "diff_hunk": "@@ -90,13 +98,19 @@ def _urllib3_request_context(\n     parsed_request_url = urlparse(request.url)\n     scheme = parsed_request_url.scheme.lower()\n     port = parsed_request_url.port\n+\n+    # Determine if we have and should use our default SSLContext\n+    # to optimize performance on standard requests.\n     poolmanager_kwargs = getattr(poolmanager, \"connection_pool_kw\", {})\n     has_poolmanager_ssl_context = poolmanager_kwargs.get(\"ssl_context\")\n+    should_use_default_ssl_context = (\n+        _preloaded_ssl_context is not None and not has_poolmanager_ssl_context\n+    )\n \n     cert_reqs = \"CERT_REQUIRED\"\n     if verify is False:\n         cert_reqs = \"CERT_NONE\"\n-    elif verify is True and not has_poolmanager_ssl_context:\n+    elif verify is True and should_use_default_ssl_context:",
      "comment": "Are you asking about the behavior if `verify is True` but `should_use_default_ssl_context` is False? This was a no-op prior to #6655 which fellback to letting the SSLContext be created when fetching the connection from the pool. [`_ssl_wrap_socket_and_match_hostname`](https://github.com/urllib3/urllib3/blob/b07a669bd970d69847801148286b726f0570b625/src/urllib3/connection.py#L755-L765) handles this for us, so I don't know if there's any additional concern from our previous behavior unless I'm missing part of the question.",
      "comment_id": 1617955993,
      "user": "nateprewitt",
      "created_at": "2024-05-28T22:28:51Z",
      "url": "https://github.com/psf/requests/pull/6724#discussion_r1617955993"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6724,
      "file_path": "src/requests/adapters.py",
      "line": 113,
      "side": "RIGHT",
      "diff_hunk": "@@ -90,13 +98,19 @@ def _urllib3_request_context(\n     parsed_request_url = urlparse(request.url)\n     scheme = parsed_request_url.scheme.lower()\n     port = parsed_request_url.port\n+\n+    # Determine if we have and should use our default SSLContext\n+    # to optimize performance on standard requests.\n     poolmanager_kwargs = getattr(poolmanager, \"connection_pool_kw\", {})\n     has_poolmanager_ssl_context = poolmanager_kwargs.get(\"ssl_context\")\n+    should_use_default_ssl_context = (\n+        _preloaded_ssl_context is not None and not has_poolmanager_ssl_context\n+    )\n \n     cert_reqs = \"CERT_REQUIRED\"\n     if verify is False:\n         cert_reqs = \"CERT_NONE\"\n-    elif verify is True and not has_poolmanager_ssl_context:\n+    elif verify is True and should_use_default_ssl_context:",
      "comment": "Makes sense. I've a terrible headache so just looking at the branches and concerned about missing something is all. ",
      "comment_id": 1618008653,
      "user": "sigmavirus24",
      "created_at": "2024-05-28T23:58:29Z",
      "url": "https://github.com/psf/requests/pull/6724#discussion_r1618008653"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6724,
      "file_path": "src/requests/adapters.py",
      "line": 113,
      "side": "RIGHT",
      "diff_hunk": "@@ -90,13 +98,19 @@ def _urllib3_request_context(\n     parsed_request_url = urlparse(request.url)\n     scheme = parsed_request_url.scheme.lower()\n     port = parsed_request_url.port\n+\n+    # Determine if we have and should use our default SSLContext\n+    # to optimize performance on standard requests.\n     poolmanager_kwargs = getattr(poolmanager, \"connection_pool_kw\", {})\n     has_poolmanager_ssl_context = poolmanager_kwargs.get(\"ssl_context\")\n+    should_use_default_ssl_context = (\n+        _preloaded_ssl_context is not None and not has_poolmanager_ssl_context\n+    )\n \n     cert_reqs = \"CERT_REQUIRED\"\n     if verify is False:\n         cert_reqs = \"CERT_NONE\"\n-    elif verify is True and not has_poolmanager_ssl_context:\n+    elif verify is True and should_use_default_ssl_context:",
      "comment": "Nope, that's a good call out. I'll give it one more look before merging but I think we're ok for that case.",
      "comment_id": 1618009506,
      "user": "nateprewitt",
      "created_at": "2024-05-29T00:00:07Z",
      "url": "https://github.com/psf/requests/pull/6724#discussion_r1618009506"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6724,
      "file_path": "src/requests/adapters.py",
      "line": 113,
      "side": "RIGHT",
      "diff_hunk": "@@ -90,13 +98,19 @@ def _urllib3_request_context(\n     parsed_request_url = urlparse(request.url)\n     scheme = parsed_request_url.scheme.lower()\n     port = parsed_request_url.port\n+\n+    # Determine if we have and should use our default SSLContext\n+    # to optimize performance on standard requests.\n     poolmanager_kwargs = getattr(poolmanager, \"connection_pool_kw\", {})\n     has_poolmanager_ssl_context = poolmanager_kwargs.get(\"ssl_context\")\n+    should_use_default_ssl_context = (\n+        _preloaded_ssl_context is not None and not has_poolmanager_ssl_context\n+    )\n \n     cert_reqs = \"CERT_REQUIRED\"\n     if verify is False:\n         cert_reqs = \"CERT_NONE\"\n-    elif verify is True and not has_poolmanager_ssl_context:\n+    elif verify is True and should_use_default_ssl_context:",
      "comment": "Oh, looking again, not on a phone, and without a migraine, I see the `cert_reqs = \"CERT_REQUIRED\"` line on L110 that I clearly wrote, and which is what I was thinking we may want to be concerned about. So, I'm not nearly as worried.",
      "comment_id": 1619000165,
      "user": "sigmavirus24",
      "created_at": "2024-05-29T14:31:10Z",
      "url": "https://github.com/psf/requests/pull/6724#discussion_r1619000165"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6724,
      "file_path": "src/requests/adapters.py",
      "line": 116,
      "side": "RIGHT",
      "diff_hunk": "@@ -90,13 +98,19 @@ def _urllib3_request_context(\n     parsed_request_url = urlparse(request.url)\n     scheme = parsed_request_url.scheme.lower()\n     port = parsed_request_url.port\n+\n+    # Determine if we have and should use our default SSLContext\n+    # to optimize performance on standard requests.\n     poolmanager_kwargs = getattr(poolmanager, \"connection_pool_kw\", {})\n     has_poolmanager_ssl_context = poolmanager_kwargs.get(\"ssl_context\")\n+    should_use_default_ssl_context = (\n+        _preloaded_ssl_context is not None and not has_poolmanager_ssl_context\n+    )\n \n     cert_reqs = \"CERT_REQUIRED\"\n     if verify is False:\n         cert_reqs = \"CERT_NONE\"\n-    elif verify is True and not has_poolmanager_ssl_context:\n+    elif verify is True and should_use_default_ssl_context:\n         pool_kwargs[\"ssl_context\"] = _preloaded_ssl_context\n     elif isinstance(verify, str):\n         if not os.path.isdir(verify):",
      "comment": "Looking at this again with something of a performance mindset, do we want to cache somehow lookups to `isdir`? I'm not sure this hurts us at all, but just thinking about things that could slow us down in certain cases now. (Not for this pull request, just putting it out there)",
      "comment_id": 1619003075,
      "user": "sigmavirus24",
      "created_at": "2024-05-29T14:32:37Z",
      "url": "https://github.com/psf/requests/pull/6724#discussion_r1619003075"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6724,
      "file_path": "src/requests/adapters.py",
      "line": 116,
      "side": "RIGHT",
      "diff_hunk": "@@ -90,13 +98,19 @@ def _urllib3_request_context(\n     parsed_request_url = urlparse(request.url)\n     scheme = parsed_request_url.scheme.lower()\n     port = parsed_request_url.port\n+\n+    # Determine if we have and should use our default SSLContext\n+    # to optimize performance on standard requests.\n     poolmanager_kwargs = getattr(poolmanager, \"connection_pool_kw\", {})\n     has_poolmanager_ssl_context = poolmanager_kwargs.get(\"ssl_context\")\n+    should_use_default_ssl_context = (\n+        _preloaded_ssl_context is not None and not has_poolmanager_ssl_context\n+    )\n \n     cert_reqs = \"CERT_REQUIRED\"\n     if verify is False:\n         cert_reqs = \"CERT_NONE\"\n-    elif verify is True and not has_poolmanager_ssl_context:\n+    elif verify is True and should_use_default_ssl_context:\n         pool_kwargs[\"ssl_context\"] = _preloaded_ssl_context\n     elif isinstance(verify, str):\n         if not os.path.isdir(verify):",
      "comment": "That seems like a reasonable optimization, I guess we'd need to check how much time we're actually spending on the dir check. I assume we'll get feedback if we have cases where this is a bottleneck.",
      "comment_id": 1619084935,
      "user": "nateprewitt",
      "created_at": "2024-05-29T15:23:20Z",
      "url": "https://github.com/psf/requests/pull/6724#discussion_r1619084935"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6667,
      "file_path": "src/requests/adapters.py",
      "line": 294,
      "side": "LEFT",
      "diff_hunk": "@@ -284,27 +284,26 @@ def cert_verify(self, conn, url, verify, cert):\n         :param cert: The SSL certificate to verify.\n         \"\"\"\n         if url.lower().startswith(\"https\") and verify:\n-            cert_loc = None\n+            conn.cert_reqs = \"CERT_REQUIRED\"\n \n-            # Allow self-specified cert location.\n+            # Only load the CA certificates if 'verify' is a string indicating the CA bundle to use.\n+            # Otherwise, if verify is a boolean, we don't load anything since\n+            # the connection will be using a context with the default certificates already loaded,\n+            # and this avoids a call to the slow load_verify_locations()\n             if verify is not True:\n+                # `verify` must be a str with a path then\n                 cert_loc = verify\n \n-            if not cert_loc:\n-                cert_loc = extract_zipped_paths(DEFAULT_CA_BUNDLE_PATH)",
      "comment": "This is actually critical behavior you're removing ",
      "comment_id": 1533138744,
      "user": "sigmavirus24",
      "created_at": "2024-03-21T01:45:42Z",
      "url": "https://github.com/psf/requests/pull/6667#discussion_r1533138744"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6667,
      "file_path": "src/requests/adapters.py",
      "line": 294,
      "side": "LEFT",
      "diff_hunk": "@@ -284,27 +284,26 @@ def cert_verify(self, conn, url, verify, cert):\n         :param cert: The SSL certificate to verify.\n         \"\"\"\n         if url.lower().startswith(\"https\") and verify:\n-            cert_loc = None\n+            conn.cert_reqs = \"CERT_REQUIRED\"\n \n-            # Allow self-specified cert location.\n+            # Only load the CA certificates if 'verify' is a string indicating the CA bundle to use.\n+            # Otherwise, if verify is a boolean, we don't load anything since\n+            # the connection will be using a context with the default certificates already loaded,\n+            # and this avoids a call to the slow load_verify_locations()\n             if verify is not True:\n+                # `verify` must be a str with a path then\n                 cert_loc = verify\n \n-            if not cert_loc:\n-                cert_loc = extract_zipped_paths(DEFAULT_CA_BUNDLE_PATH)",
      "comment": "Thanks for the catch, I had to adapt the patch quite a bit from what we're using right now and that inconsistency slipped by.\r\n\r\nI pushed a change to explicitly use `DEFAULT_CA_BUNDLE_PATH` when `verify=True`. This is done by creating a module-level `SSLContext` with that bundle already loaded, and instructing the connection pool to use that context when no custom bundle is specified. Since the server's cert is verified using the CA certificates loaded in the `SSLContext` used in the request, this should work.\r\n\r\nAgain, the goal is to avoid setting `ca_certs` or `ca_cert_dir` in the most common use case as it triggers another (in this case redundant) call to `load_verify_locations()` by urllib3:\r\n\r\n```py\r\nif ca_certs or ca_cert_dir or ca_cert_data:\r\n        try:\r\n            context.load_verify_locations(ca_certs, ca_cert_dir, ca_cert_data)\r\n```\r\n\r\nSince `DEFAULT_CA_BUNDLE_PATH` is sugar for `certifi.where()`, which in turn always returns the path to a single bundle file, I decided to skip checking for `os.path.isdir()` because it should always be False. If you're not comfortable with this please let me know and I'll change it.\r\n\r\nI also changed `_urllib3_request_context()` slightly to handle the case where `verify` is a path to a dir instead to a single file, as we should set `ca_cert_dir` instead of `ca_certs` in that case. I believe this is now fully redundant with the corresponding logic in `cert_verify()`.\r\n\r\nI tried to write corresponding tests to verify that the `SSLContext`s used in different scenarios have the correct certificates loaded, but I couldn't find a way to access such low-level information about a request in the exposed classes. If it's possible, please give me a few pointers and I'll be glad to expand the test suite.",
      "comment_id": 1533587993,
      "user": "agubelu",
      "created_at": "2024-03-21T10:14:37Z",
      "url": "https://github.com/psf/requests/pull/6667#discussion_r1533587993"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6655,
      "file_path": "src/requests/adapters.py",
      "line": 66,
      "side": "RIGHT",
      "diff_hunk": "@@ -61,12 +62,38 @@ def SOCKSProxyManager(*args, **kwargs):\n         raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n \n \n+if typing.TYPE_CHECKING:\n+    from .models import PreparedRequest",
      "comment": "Not against this, but I think this is the first time we're introducing typing into Requests. I'm curious if we want to start that or push it into typeshed since this will be precedent for future inline typing?",
      "comment_id": 1515206804,
      "user": "nateprewitt",
      "created_at": "2024-03-06T21:56:23Z",
      "url": "https://github.com/psf/requests/pull/6655#discussion_r1515206804"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6655,
      "file_path": "tests/test_requests.py",
      "line": 2836,
      "side": "RIGHT",
      "diff_hunk": "@@ -2828,6 +2828,13 @@ def test_status_code_425(self):\n         assert r5 == 425\n         assert r6 == 425\n \n+    def test_different_connection_pool_for_tls_settings(self):\n+        s = requests.Session()\n+        r1 = s.get(\"https://invalid.badssl.com\", verify=False)\n+        assert r1.status_code == 421\n+        with pytest.raises(requests.exceptions.SSLError):\n+            s.get(\"https://invalid.badssl.com\")",
      "comment": "There may not be a better way to test this but I don't know if we have other tests that require contacting a live site with TLS disabled. That may have some durability issues and means we're going to take the first response we get back. Probably minor, but figured I'd call it out.",
      "comment_id": 1518892861,
      "user": "nateprewitt",
      "created_at": "2024-03-10T16:33:36Z",
      "url": "https://github.com/psf/requests/pull/6655#discussion_r1518892861"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6655,
      "file_path": "src/requests/adapters.py",
      "line": 66,
      "side": "RIGHT",
      "diff_hunk": "@@ -61,12 +62,38 @@ def SOCKSProxyManager(*args, **kwargs):\n         raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n \n \n+if typing.TYPE_CHECKING:\n+    from .models import PreparedRequest",
      "comment": "This is for a private method (that I fully anticipate people abusing) but we're not advertising things are typed and so it's not something I'm concerned with. ",
      "comment_id": 1518900181,
      "user": "sigmavirus24",
      "created_at": "2024-03-10T17:11:39Z",
      "url": "https://github.com/psf/requests/pull/6655#discussion_r1518900181"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6655,
      "file_path": "tests/test_requests.py",
      "line": 2836,
      "side": "RIGHT",
      "diff_hunk": "@@ -2828,6 +2828,13 @@ def test_status_code_425(self):\n         assert r5 == 425\n         assert r6 == 425\n \n+    def test_different_connection_pool_for_tls_settings(self):\n+        s = requests.Session()\n+        r1 = s.get(\"https://invalid.badssl.com\", verify=False)\n+        assert r1.status_code == 421\n+        with pytest.raises(requests.exceptions.SSLError):\n+            s.get(\"https://invalid.badssl.com\")",
      "comment": "There are many alternatives here, but those are all significantly more effort and this shows the behaviour is fixed before and after handily. I'm sure Linux folks will get pissed but I'm not as bothered about finding time later to do this a different way after we have fixed this",
      "comment_id": 1518900465,
      "user": "sigmavirus24",
      "created_at": "2024-03-10T17:12:49Z",
      "url": "https://github.com/psf/requests/pull/6655#discussion_r1518900465"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6655,
      "file_path": "tests/test_requests.py",
      "line": 2836,
      "side": "RIGHT",
      "diff_hunk": "@@ -2828,6 +2828,13 @@ def test_status_code_425(self):\n         assert r5 == 425\n         assert r6 == 425\n \n+    def test_different_connection_pool_for_tls_settings(self):\n+        s = requests.Session()\n+        r1 = s.get(\"https://invalid.badssl.com\", verify=False)\n+        assert r1.status_code == 421\n+        with pytest.raises(requests.exceptions.SSLError):\n+            s.get(\"https://invalid.badssl.com\")",
      "comment": "I'll try to prioritize better (offline) tests soon",
      "comment_id": 1519559679,
      "user": "sigmavirus24",
      "created_at": "2024-03-11T11:21:54Z",
      "url": "https://github.com/psf/requests/pull/6655#discussion_r1519559679"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6767,
      "file_path": "src/requests/adapters.py",
      "line": 92,
      "side": "RIGHT",
      "diff_hunk": "@@ -99,19 +85,9 @@ def _urllib3_request_context(\n     scheme = parsed_request_url.scheme.lower()\n     port = parsed_request_url.port\n \n-    # Determine if we have and should use our default SSLContext\n-    # to optimize performance on standard requests.\n-    poolmanager_kwargs = getattr(poolmanager, \"connection_pool_kw\", {})\n-    has_poolmanager_ssl_context = poolmanager_kwargs.get(\"ssl_context\")\n-    should_use_default_ssl_context = (\n-        _preloaded_ssl_context is not None and not has_poolmanager_ssl_context\n-    )\n-\n     cert_reqs = \"CERT_REQUIRED\"\n     if verify is False:\n         cert_reqs = \"CERT_NONE\"\n-    elif verify is True and should_use_default_ssl_context:\n-        pool_kwargs[\"ssl_context\"] = _preloaded_ssl_context\n     elif isinstance(verify, str):\n         if not os.path.isdir(verify):",
      "comment": "This is one piece I left in place from #6667. We were unilaterally considering any `verify` string to be `ca_certs` instead of detecting if it was a directory. That seems like a miss from #6655 unless I'm missing something?",
      "comment_id": 1683276287,
      "user": "nateprewitt",
      "created_at": "2024-07-18T18:02:54Z",
      "url": "https://github.com/psf/requests/pull/6767#discussion_r1683276287"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6757,
      "file_path": "src/requests/compat.py",
      "line": 19,
      "side": "RIGHT",
      "diff_hunk": "@@ -10,6 +10,14 @@\n import importlib\n import sys\n \n+# -------\n+# urllib3\n+# -------\n+from urllib3 import __version__ as urllib3_version\n+\n+# Detect which major version of urllib3 is being used.\n+is_urllib3_2 = urllib3_version.split('.')[0] == 2",
      "comment": "I believe this is a string, not an integer. Also, should do a >= check instead of equals.",
      "comment_id": 1683193453,
      "user": "sethmlarson",
      "created_at": "2024-07-18T16:49:44Z",
      "url": "https://github.com/psf/requests/pull/6757#discussion_r1683193453"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6757,
      "file_path": "src/requests/compat.py",
      "line": 19,
      "side": "RIGHT",
      "diff_hunk": "@@ -10,6 +10,14 @@\n import importlib\n import sys\n \n+# -------\n+# urllib3\n+# -------\n+from urllib3 import __version__ as urllib3_version\n+\n+# Detect which major version of urllib3 is being used.\n+is_urllib3_2 = urllib3_version.split('.')[0] == 2",
      "comment": "Good catch on the `int`. For the equivalence, I don't know if `>=` is what we want if this is specifically scoping the 2.x major version. In the same way I wouldn't want an `is_py3` to include Python 4.x. We could do something like `is_gt_urllib3_1` but that seems like it may be premature forwards-compatibility?\r\n\r\nRight now our dependencies are scoped at `urllib3<3` and if we add this check to any other behaviors, I'd rather they stay scoped to the major version. That will let tests fail if we major version again and we can make an informed decision at that point when adding support. Otherwise, we may unintentionally carry forward behaviors that are subtly wrong.\r\n\r\nI can see similar risks with both sides, so not a hill I'm going to die on, but that was my initial thought process.",
      "comment_id": 1683204168,
      "user": "nateprewitt",
      "created_at": "2024-07-18T16:58:58Z",
      "url": "https://github.com/psf/requests/pull/6757#discussion_r1683204168"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6757,
      "file_path": "src/requests/compat.py",
      "line": 19,
      "side": "RIGHT",
      "diff_hunk": "@@ -10,6 +10,14 @@\n import importlib\n import sys\n \n+# -------\n+# urllib3\n+# -------\n+from urllib3 import __version__ as urllib3_version\n+\n+# Detect which major version of urllib3 is being used.\n+is_urllib3_2 = urllib3_version.split('.')[0] == 2",
      "comment": "I've changed the check from checking for urllib3 2.x to check for 1.x. That leaves us open to forward compatibility without the confusing behavior with `is_urllib3_2` including newer major versions.",
      "comment_id": 1695374605,
      "user": "nateprewitt",
      "created_at": "2024-07-29T14:49:41Z",
      "url": "https://github.com/psf/requests/pull/6757#discussion_r1695374605"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6963,
      "file_path": "src/requests/utils.py",
      "line": 240,
      "side": "RIGHT",
      "diff_hunk": "@@ -236,16 +236,8 @@ def get_netrc_auth(url, raise_errors=False):\n             return\n \n         ri = urlparse(url)\n-\n-        # Strip port numbers from netloc. This weird `if...encode`` dance is\n-        # used for Python 3.2, which doesn't support unicode literals.\n-        splitstr = b\":\"\n-        if isinstance(url, str):\n-            splitstr = splitstr.decode(\"ascii\")\n-        host = ri.netloc.split(splitstr)[0]\n-\n         try:\n-            _netrc = netrc(netrc_path).authenticators(host)\n+            _netrc = netrc(netrc_path).authenticators(ri.hostname)",
      "comment": "This is fixed now in main: https://github.com/psf/requests/commit/96ba401c1296ab1dda74a2365ef36d88f7d144ef",
      "comment_id": 2128118428,
      "user": "danigm",
      "created_at": "2025-06-05T07:12:17Z",
      "url": "https://github.com/psf/requests/pull/6963#discussion_r2128118428"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6951,
      "file_path": "docs/conf.py",
      "line": 61,
      "side": "RIGHT",
      "diff_hunk": "@@ -58,7 +58,7 @@\n \n # General information about the project.\n project = u\"Requests\"\n-copyright = u'MMXVIX. A <a href=\"https://kenreitz.org/projects\">Kenneth Reitz</a> Project'\n+copyright = u'MMXVIX. A <a href=\"https://kennethreitz.org/software/\">Kenneth Reitz</a> Project'",
      "comment": "```suggestion\r\ncopyright = u'MMXVIX. A Kenneth Reitz Project'\r\n```",
      "comment_id": 2101041830,
      "user": "nateprewitt",
      "created_at": "2025-05-21T19:45:04Z",
      "url": "https://github.com/psf/requests/pull/6951#discussion_r2101041830"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6710,
      "file_path": "src/requests/adapters.py",
      "line": 417,
      "side": "RIGHT",
      "diff_hunk": "@@ -404,7 +414,10 @@ def _get_connection(self, request, verify, proxies=None, cert=None):\n         return conn\n \n     def get_connection(self, url, proxies=None):\n-        \"\"\"Returns a urllib3 connection for the given URL. This should not be\n+        \"\"\"DEPRECATED: Users should move to `get_connection_with_tls_context`",
      "comment": "If this method is deprecated shall we start emitting `DeprecationWarning`?",
      "comment_id": 1608603801,
      "user": "sethmlarson",
      "created_at": "2024-05-21T16:12:52Z",
      "url": "https://github.com/psf/requests/pull/6710#discussion_r1608603801"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6710,
      "file_path": "src/requests/adapters.py",
      "line": 417,
      "side": "RIGHT",
      "diff_hunk": "@@ -404,7 +414,10 @@ def _get_connection(self, request, verify, proxies=None, cert=None):\n         return conn\n \n     def get_connection(self, url, proxies=None):\n-        \"\"\"Returns a urllib3 connection for the given URL. This should not be\n+        \"\"\"DEPRECATED: Users should move to `get_connection_with_tls_context`",
      "comment": "I thought about that but it's not reachable in any of our code anymore and if someone is using a custom implementation it won't have the warning.\n\nHappy to be wrong if I'm missing something but it seems like it will just be dead code on arrival.",
      "comment_id": 1608609666,
      "user": "nateprewitt",
      "created_at": "2024-05-21T16:17:36Z",
      "url": "https://github.com/psf/requests/pull/6710#discussion_r1608609666"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6710,
      "file_path": "src/requests/adapters.py",
      "line": 417,
      "side": "RIGHT",
      "diff_hunk": "@@ -404,7 +414,10 @@ def _get_connection(self, request, verify, proxies=None, cert=None):\n         return conn\n \n     def get_connection(self, url, proxies=None):\n-        \"\"\"Returns a urllib3 connection for the given URL. This should not be\n+        \"\"\"DEPRECATED: Users should move to `get_connection_with_tls_context`",
      "comment": "I guess it's better to be safe, this should be addressed in 92075b330a30b9883f466a43d3f7566ab849f91b.",
      "comment_id": 1608624860,
      "user": "nateprewitt",
      "created_at": "2024-05-21T16:29:48Z",
      "url": "https://github.com/psf/requests/pull/6710#discussion_r1608624860"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6702,
      "file_path": "src/requests/compat.py",
      "line": 21,
      "side": "RIGHT",
      "diff_hunk": "@@ -7,13 +7,28 @@\n compatibility until the next major version.\n \"\"\"\n \n-try:\n-    import chardet\n-except ImportError:\n-    import charset_normalizer as chardet\n-\n+import importlib\n import sys\n \n+# -------------------\n+# Character Detection\n+# -------------------\n+\n+\n+def _resolve_char_detection():\n+    \"\"\"Find supported character detection libraries.\"\"\"\n+    chardet = None\n+    for lib in (\"chardet\", \"charset_normalizer\"):",
      "comment": "While this keeps the logic of the earlier code, I think that the library which is required on should be tried first. https://github.com/psf/requests/pull/6714 addresses this.",
      "comment_id": 1609492798,
      "user": "nijel",
      "created_at": "2024-05-22T08:08:55Z",
      "url": "https://github.com/psf/requests/pull/6702#discussion_r1609492798"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6644,
      "file_path": "tests/test_adapters.py",
      "line": 6,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,7 @@\n+import requests.adapters\n+\n+\n+def test_request_url_trims_leading_path_separators():\n+    \"\"\"See also https://github.com/psf/requests/issues/6643.\"\"\"\n+    a = request.adapters.HTTPAdapter()",
      "comment": "```suggestion\n    a = requests.adapters.HTTPAdapter()\n```",
      "comment_id": 1498532708,
      "user": "sigmavirus24",
      "created_at": "2024-02-22T02:17:57Z",
      "url": "https://github.com/psf/requests/pull/6644#discussion_r1498532708"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6644,
      "file_path": "tests/test_adapters.py",
      "line": 7,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,7 @@\n+import requests.adapters\n+\n+\n+def test_request_url_trims_leading_path_separators():\n+    \"\"\"See also https://github.com/psf/requests/issues/6643.\"\"\"\n+    a = requests.adapters.HTTPAdapter()\n+    assert \"/v:h\" == a.request_url(\"http://127.0.0.1:10000//v:h\")",
      "comment": "```suggestion\n    assert \"/v:h\" == a.request_url(\"http://127.0.0.1:10000//v:h\", {})\n```",
      "comment_id": 1498534695,
      "user": "sigmavirus24",
      "created_at": "2024-02-22T02:21:39Z",
      "url": "https://github.com/psf/requests/pull/6644#discussion_r1498534695"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6644,
      "file_path": "tests/test_adapters.py",
      "line": 7,
      "side": "RIGHT",
      "diff_hunk": "@@ -0,0 +1,7 @@\n+import requests.adapters\n+\n+\n+def test_request_url_trims_leading_path_separators():\n+    \"\"\"See also https://github.com/psf/requests/issues/6643.\"\"\"\n+    a = requests.adapters.HTTPAdapter()\n+    assert \"/v:h\" == a.request_url(\"http://127.0.0.1:10000//v:h\", {})",
      "comment": "```suggestion\n    p = requests.Request(method=\"GET\", url=\"http://127.0.0.1:10000//v:h\").prepare()\n    assert \"/v:h\" == a.request_url(p, {})\n```",
      "comment_id": 1498539954,
      "user": "sigmavirus24",
      "created_at": "2024-02-22T02:31:51Z",
      "url": "https://github.com/psf/requests/pull/6644#discussion_r1498539954"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6644,
      "file_path": "src/requests/adapters.py",
      "line": 393,
      "side": "RIGHT",
      "diff_hunk": "@@ -389,7 +390,7 @@ def request_url(self, request, proxies):\n             proxy_scheme = urlparse(proxy).scheme.lower()\n             using_socks_proxy = proxy_scheme.startswith(\"socks\")\n \n-        url = request.path_url\n+        url = re.sub(\"^/+\", \"/\", request.path_url)",
      "comment": "As mentioned on https://github.com/urllib3/urllib3/issues/3352 this could also be\r\n\r\n```python\r\nurl = f\"/{request.path_url.lstrip('/')}\"\r\n```\r\n\r\nI could benchmark these but I don't particularly care what the implementation is. I just threw this together to show that it can be fixed",
      "comment_id": 1499181040,
      "user": "sigmavirus24",
      "created_at": "2024-02-22T12:39:14Z",
      "url": "https://github.com/psf/requests/pull/6644#discussion_r1499181040"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6644,
      "file_path": "src/requests/adapters.py",
      "line": 393,
      "side": "RIGHT",
      "diff_hunk": "@@ -389,7 +390,7 @@ def request_url(self, request, proxies):\n             proxy_scheme = urlparse(proxy).scheme.lower()\n             using_socks_proxy = proxy_scheme.startswith(\"socks\")\n \n-        url = request.path_url\n+        url = re.sub(\"^/+\", \"/\", request.path_url)",
      "comment": "It looks like the f-string (Python 3.9-3.12 tested) is ~4x faster but we're talking on the scale of nanoseconds so it's basically moot. I'd vote the f-string for readability, but don't have a strong opinion.",
      "comment_id": 1499501563,
      "user": "nateprewitt",
      "created_at": "2024-02-22T16:10:48Z",
      "url": "https://github.com/psf/requests/pull/6644#discussion_r1499501563"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6644,
      "file_path": "src/requests/adapters.py",
      "line": 393,
      "side": "RIGHT",
      "diff_hunk": "@@ -389,7 +390,7 @@ def request_url(self, request, proxies):\n             proxy_scheme = urlparse(proxy).scheme.lower()\n             using_socks_proxy = proxy_scheme.startswith(\"socks\")\n \n-        url = request.path_url\n+        url = re.sub(\"^/+\", \"/\", request.path_url)",
      "comment": "Yeah, I'm also happy to shove this into a branch too like \n\n```python\nif path.startswith('//'):\n```\n\nTo make it clearer that we only care about the separator being repeated. What I want is clarity in the reader as to why we're doing this. My old school brain things the regexp is clearer and the f-string looks sus but  that's just my opinion and I'm not holding it closely ",
      "comment_id": 1499711431,
      "user": "sigmavirus24",
      "created_at": "2024-02-22T18:22:38Z",
      "url": "https://github.com/psf/requests/pull/6644#discussion_r1499711431"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6589,
      "file_path": "src/requests/utils.py",
      "line": 137,
      "side": "RIGHT",
      "diff_hunk": "@@ -134,7 +134,10 @@ def super_len(o):\n     total_length = None\n     current_position = 0\n \n-    if hasattr(o, \"__len__\"):\n+    if isinstance(o, str):",
      "comment": "More simply this can be an if without changing the following conditions and just set `o = o.encode(...)` in the block then let the rest of the logic work. As it will hit another condition which will get it's length",
      "comment_id": 1409296382,
      "user": "sigmavirus24",
      "created_at": "2023-11-29T13:38:39Z",
      "url": "https://github.com/psf/requests/pull/6589#discussion_r1409296382"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6589,
      "file_path": "src/requests/utils.py",
      "line": 137,
      "side": "RIGHT",
      "diff_hunk": "@@ -134,7 +134,10 @@ def super_len(o):\n     total_length = None\n     current_position = 0\n \n-    if hasattr(o, \"__len__\"):\n+    if isinstance(o, str):",
      "comment": "Sounds fine to me. My usual workflow would be to rewrite my commit and do a force push to my branch (in my fork). Is this ok or would you prefer a separate commit for the change?",
      "comment_id": 1409321632,
      "user": "bruceadams",
      "created_at": "2023-11-29T13:57:59Z",
      "url": "https://github.com/psf/requests/pull/6589#discussion_r1409321632"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6562,
      "file_path": "src/requests/packages.py",
      "line": 26,
      "side": "LEFT",
      "diff_hunk": "@@ -23,6 +23,5 @@\n target = chardet.__name__\n for mod in list(sys.modules):\n     if mod == target or mod.startswith(f\"{target}.\"):\n-        target = target.replace(target, \"chardet\")",
      "comment": "This is unfortunately necessary. This is necessary to support charset-normalizer. The idea here is to import charset if it's installed instead of chardet from this location for users.\r\n\r\nThis is why we look at `chardet.__name__` (to determine which is most important: https://github.com/psf/requests/blob/839a8edec37c81a18ac8332cfbd44f44e1ae6206/src/requests/packages.py#L8 )\r\n\r\nSo what we need to do is determine how we want to handle this appropriately.\r\n\r\nThe idea is that we have two values:\r\n\r\n```py\r\ntarget = \"chardet\"\r\ntarget = \"charset_normalizer\"\r\n```\r\n\r\nIn the former case if `mod.startswith(\"chardet.\")` then we will be replacing `chardet` with `chardet`. In the latter case, we'd want to replace `charset_normalizer` with `chardet`.",
      "comment_id": 1377461842,
      "user": "sigmavirus24",
      "created_at": "2023-10-31T11:48:59Z",
      "url": "https://github.com/psf/requests/pull/6562#discussion_r1377461842"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6562,
      "file_path": "src/requests/packages.py",
      "line": 26,
      "side": "LEFT",
      "diff_hunk": "@@ -23,6 +23,5 @@\n target = chardet.__name__\n for mod in list(sys.modules):\n     if mod == target or mod.startswith(f\"{target}.\"):\n-        target = target.replace(target, \"chardet\")",
      "comment": "Got it, but still the for loop seems necessary. It'll just be mapping the last package of chardet modules to chardet package of requests. \r\n\r\nIf that is the expected behaviour then we can just assign the last package without running the for loop. ",
      "comment_id": 1377593896,
      "user": "amkarn258",
      "created_at": "2023-10-31T13:33:00Z",
      "url": "https://github.com/psf/requests/pull/6562#discussion_r1377593896"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6562,
      "file_path": "src/requests/packages.py",
      "line": 26,
      "side": "LEFT",
      "diff_hunk": "@@ -23,6 +23,5 @@\n target = chardet.__name__\n for mod in list(sys.modules):\n     if mod == target or mod.startswith(f\"{target}.\"):\n-        target = target.replace(target, \"chardet\")",
      "comment": "So I'm talking about the intent behind the line, there's obviously a bug in it. And I was trying to leave that as something for you to see for yourself.\n\nThe reality is that what we want is \n\n```py\nsys.modules[f\"requests.packages.{mod}\"] = sys.modules[mod]\nmod = mod.replace(target, \"chardet\")\nsys.modules[f\"requests.packages.{mod}\"] = sys.modules[mod]\n```\n\nBecause we may as well add charset normalizer in there but also, we want backwards compatibility with chardet\n\nSo it's a tiny bit obvious bug and we'd like the intended behavior fixed",
      "comment_id": 1377658476,
      "user": "sigmavirus24",
      "created_at": "2023-10-31T14:13:28Z",
      "url": "https://github.com/psf/requests/pull/6562#discussion_r1377658476"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6562,
      "file_path": "src/requests/packages.py",
      "line": 26,
      "side": "LEFT",
      "diff_hunk": "@@ -23,6 +23,5 @@\n target = chardet.__name__\n for mod in list(sys.modules):\n     if mod == target or mod.startswith(f\"{target}.\"):\n-        target = target.replace(target, \"chardet\")",
      "comment": "```\r\nsys.modules[f\"requests.packages.{mod}\"]` = sys.modules[mod]\r\nmod = mod.replace(target, \"chardet\")\r\nsys.modules[f\"requests.packages.{mod}\"] = sys.modules[mod]\r\n```\r\n\r\nDoesn't make sense, since then the mod will itself change to chardet and will throw a keyerror. \r\n\r\nHave added the support for both chardet and charset_normalizer in the latest commit, with this change - \r\n\r\n```\r\nsys.modules[f\"requests.packages.{mod}\"] = sys.modules[mod]\r\ntarget = target.replace(target, \"chardet\")\r\nsys.modules[f\"requests.packages.{target}\"] = sys.modules[mod]\r\n```\r\n",
      "comment_id": 1377751368,
      "user": "amkarn258",
      "created_at": "2023-10-31T15:10:40Z",
      "url": "https://github.com/psf/requests/pull/6562#discussion_r1377751368"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6562,
      "file_path": "src/requests/packages.py",
      "line": 26,
      "side": "LEFT",
      "diff_hunk": "@@ -23,6 +23,5 @@\n target = chardet.__name__\n for mod in list(sys.modules):\n     if mod == target or mod.startswith(f\"{target}.\"):\n-        target = target.replace(target, \"chardet\")",
      "comment": "Correct, it won't find the module, but it's still very wrong to do `target.replace(target, \"chardet\")`",
      "comment_id": 1377897436,
      "user": "sigmavirus24",
      "created_at": "2023-10-31T16:51:45Z",
      "url": "https://github.com/psf/requests/pull/6562#discussion_r1377897436"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6562,
      "file_path": "src/requests/packages.py",
      "line": 28,
      "side": "RIGHT",
      "diff_hunk": "@@ -23,6 +23,7 @@\n target = chardet.__name__\n for mod in list(sys.modules):\n     if mod == target or mod.startswith(f\"{target}.\"):\n+        sys.modules[f\"requests.packages.{mod}\"] = sys.modules[mod]\n         target = target.replace(target, \"chardet\")\n         sys.modules[f\"requests.packages.{target}\"] = sys.modules[mod]",
      "comment": "```suggestion\r\n        imported_mod = sys.modules[mod]\r\n        sys.modules[f\"requests.packages.{mod}\"] = imported_mod\r\n        mod = mod.replace(target, \"chardet\")\r\n        sys.modules[f\"requests.packages.{mod}\"] = imported_mod\r\n```\r\n",
      "comment_id": 1377900725,
      "user": "sigmavirus24",
      "created_at": "2023-10-31T16:54:08Z",
      "url": "https://github.com/psf/requests/pull/6562#discussion_r1377900725"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6529,
      "file_path": "src/requests/models.py",
      "line": 948,
      "side": "RIGHT",
      "diff_hunk": "@@ -945,7 +945,7 @@ def text(self):\n         return content\n \n     def json(self, **kwargs):\n-        r\"\"\"Returns the json-encoded content of a response, if any.\n+        r\"\"\"Returns the json-decoded dict of a response, if any.",
      "comment": "```suggestion\n        r\"\"\"Decodes the JSON response body (if any) as a Python object.\n\n           This may return a dictionary, list, etc. depending on what is in the response.\n```\n",
      "comment_id": 1950711358,
      "user": "sigmavirus24",
      "created_at": "2025-02-11T11:55:52Z",
      "url": "https://github.com/psf/requests/pull/6529#discussion_r1950711358"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6529,
      "file_path": "src/requests/models.py",
      "line": 948,
      "side": "RIGHT",
      "diff_hunk": "@@ -945,7 +945,8 @@ def text(self):\n         return content\n \n     def json(self, **kwargs):\n-        r\"\"\"Returns the json-encoded content of a response, if any.\n+        r\"\"\"Decodes the JSON response body (if any) as a Python object.",
      "comment": "```suggestion\n        r\"\"\"Decodes the JSON response body (if any) as a Python object.\n\n```\n",
      "comment_id": 1952510987,
      "user": "sigmavirus24",
      "created_at": "2025-02-12T11:57:20Z",
      "url": "https://github.com/psf/requests/pull/6529#discussion_r1952510987"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6448,
      "file_path": "setup.py",
      "line": 68,
      "side": "RIGHT",
      "diff_hunk": "@@ -65,7 +65,7 @@ def run_tests(self):\n     \"certifi>=2017.4.17\",\n ]\n test_requirements = [\n-    \"pytest-httpbin==0.0.7\",\n+    \"pytest-httpbin==2.0.0rc1\",",
      "comment": "```suggestion\r\n    \"pytest-httpbin==2.0.0rc2\",\r\n```",
      "comment_id": 1187828270,
      "user": "graingert",
      "created_at": "2023-05-08T19:47:43Z",
      "url": "https://github.com/psf/requests/pull/6448#discussion_r1187828270"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "requests/exceptions.py",
      "line": 45,
      "side": "RIGHT",
      "diff_hunk": "@@ -33,6 +33,9 @@ class InvalidJSONError(RequestException):\n \n class JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\n     \"\"\"Couldn't decode the text into json\"\"\"\n+    def __init__(self, *args, **kwargs):\n+        CompatJSONDecodeError.__init__(self, *args)\n+        InvalidJSONError.__init__(self, *self.args, **kwargs)",
      "comment": "Can we add comments here explaining why:\r\n\r\n1. We're using super old Python 2.5 methods of calling parent `__init__` methods\r\n2. We're calling the `__init__`s in this particular order - presuming the order matters\r\n3. This fixes the issue of `.doc` ending up in the message/default `__repr__`",
      "comment_id": 780674790,
      "user": "sigmavirus24",
      "created_at": "2022-01-08T14:42:14Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r780674790"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "requests/exceptions.py",
      "line": 37,
      "side": "RIGHT",
      "diff_hunk": "@@ -33,6 +33,9 @@ class InvalidJSONError(RequestException):\n \n class JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\n     \"\"\"Couldn't decode the text into json\"\"\"\n+    def __init__(self, *args, **kwargs):",
      "comment": "Can we add an empty line prior to the `__init__` here? That's already the style of this sub-module if not the entirety of `requests`",
      "comment_id": 780674982,
      "user": "sigmavirus24",
      "created_at": "2022-01-08T14:44:32Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r780674982"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "requests/exceptions.py",
      "line": 42,
      "side": "RIGHT",
      "diff_hunk": "@@ -34,6 +34,16 @@ class InvalidJSONError(RequestException):\n class JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\n     \"\"\"Couldn't decode the text into json\"\"\"\n \n+    def __init__(self, *args, **kwargs):\n+        \"\"\"\n+        Construct the JSONDecodeError instance first with all\n+        args. Then use it's args to construct the IOError so that\n+        the json specific args aren't used as IOError specific args\n+        and the error message that JSONDecodeError builds is preserved",
      "comment": "nit; This might be phrased \"[...] the error message from JSONDecodeError is preserved.\"\r\n\r\nAlso note the missing period in the current sentence.",
      "comment_id": 781581198,
      "user": "nateprewitt",
      "created_at": "2022-01-10T21:47:23Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r781581198"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "tests/test_requests.py",
      "line": 2590,
      "side": "RIGHT",
      "diff_hunk": "@@ -2585,5 +2585,11 @@ def test_post_json_nan(self, httpbin):\n \n     def test_json_decode_compatibility(self, httpbin):\n         r = requests.get(httpbin('bytes/20'))\n-        with pytest.raises(requests.exceptions.JSONDecodeError):\n+        data = r.text\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n             r.json()\n+        assert isinstance(excinfo.value, RequestException)",
      "comment": "Do we need to use `.value` in these assertions? Just `excinfo` should be sufficient and that's how the typical user will probably interact with them.",
      "comment_id": 781592203,
      "user": "nateprewitt",
      "created_at": "2022-01-10T21:57:30Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r781592203"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "tests/test_requests.py",
      "line": 2594,
      "side": "RIGHT",
      "diff_hunk": "@@ -2585,5 +2585,11 @@ def test_post_json_nan(self, httpbin):\n \n     def test_json_decode_compatibility(self, httpbin):\n         r = requests.get(httpbin('bytes/20'))\n-        with pytest.raises(requests.exceptions.JSONDecodeError):\n+        data = r.text\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n             r.json()\n+        assert isinstance(excinfo.value, RequestException)\n+        assert isinstance(excinfo.value, JSONDecodeError)\n+        assert data not in str(excinfo.value)\n+        if is_py3:",
      "comment": "Also somewhat of a nit. It may be better to just make this its own test with a `@unittest.skipIf(not is_py3)` at the top.\r\n\r\ne.g.\r\n\r\n```python\r\n@unittest.skipIf(not is_py3)\r\ndef test_json_decode_persists_doc_attr(self, httpbin):\r\n    r = requests.get(httpbin('bytes/20'))\r\n    with pytest.raises(requests.exceptions.JSONDecodeError) as e:\r\n        r.json()\r\n    assert e.doc == r.text\r\n```\r\n        \r\n",
      "comment_id": 781595242,
      "user": "nateprewitt",
      "created_at": "2022-01-10T22:00:15Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r781595242"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "tests/test_requests.py",
      "line": 2594,
      "side": "RIGHT",
      "diff_hunk": "@@ -2585,5 +2585,11 @@ def test_post_json_nan(self, httpbin):\n \n     def test_json_decode_compatibility(self, httpbin):\n         r = requests.get(httpbin('bytes/20'))\n-        with pytest.raises(requests.exceptions.JSONDecodeError):\n+        data = r.text\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n             r.json()\n+        assert isinstance(excinfo.value, RequestException)\n+        assert isinstance(excinfo.value, JSONDecodeError)\n+        assert data not in str(excinfo.value)\n+        if is_py3:",
      "comment": "don't we want to test that the py2 object is also what we expect? Or if we don't can i can make it py3 only?",
      "comment_id": 781656546,
      "user": "chyzzqo2",
      "created_at": "2022-01-10T23:41:24Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r781656546"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "tests/test_requests.py",
      "line": 2590,
      "side": "RIGHT",
      "diff_hunk": "@@ -2585,5 +2585,11 @@ def test_post_json_nan(self, httpbin):\n \n     def test_json_decode_compatibility(self, httpbin):\n         r = requests.get(httpbin('bytes/20'))\n-        with pytest.raises(requests.exceptions.JSONDecodeError):\n+        data = r.text\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n             r.json()\n+        assert isinstance(excinfo.value, RequestException)",
      "comment": "excinfo is a pytest thing that wraps the actual exception, i think we have to look at value to get the original object",
      "comment_id": 781658238,
      "user": "chyzzqo2",
      "created_at": "2022-01-10T23:45:42Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r781658238"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "tests/test_requests.py",
      "line": 2594,
      "side": "RIGHT",
      "diff_hunk": "@@ -2585,5 +2585,11 @@ def test_post_json_nan(self, httpbin):\n \n     def test_json_decode_compatibility(self, httpbin):\n         r = requests.get(httpbin('bytes/20'))\n-        with pytest.raises(requests.exceptions.JSONDecodeError):\n+        data = r.text\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n             r.json()\n+        assert isinstance(excinfo.value, RequestException)\n+        assert isinstance(excinfo.value, JSONDecodeError)\n+        assert data not in str(excinfo.value)\n+        if is_py3:",
      "comment": "The original test doesn't assert anything about Python 2 either. So we don't lose anything with this change. I suppose we could assert doc _isn't_ on the Python 2 exception but I'm not sure how meaningful that is.\n\nEdit: to be clear I'm proposing two tests. The one you have and moving the Python 3 specifics to its own test.",
      "comment_id": 781659079,
      "user": "nateprewitt",
      "created_at": "2022-01-10T23:48:06Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r781659079"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "tests/test_requests.py",
      "line": 2594,
      "side": "RIGHT",
      "diff_hunk": "@@ -2585,5 +2585,11 @@ def test_post_json_nan(self, httpbin):\n \n     def test_json_decode_compatibility(self, httpbin):\n         r = requests.get(httpbin('bytes/20'))\n-        with pytest.raises(requests.exceptions.JSONDecodeError):\n+        data = r.text\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n             r.json()\n+        assert isinstance(excinfo.value, RequestException)\n+        assert isinstance(excinfo.value, JSONDecodeError)\n+        assert data not in str(excinfo.value)\n+        if is_py3:",
      "comment": "ok, i think i updated it with what you had in mind.",
      "comment_id": 781684776,
      "user": "chyzzqo2",
      "created_at": "2022-01-11T00:58:10Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r781684776"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "requests/exceptions.py",
      "line": 42,
      "side": "RIGHT",
      "diff_hunk": "@@ -34,6 +34,16 @@ class InvalidJSONError(RequestException):\n class JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\n     \"\"\"Couldn't decode the text into json\"\"\"\n \n+    def __init__(self, *args, **kwargs):\n+        \"\"\"\n+        Construct the JSONDecodeError instance first with all\n+        args. Then use it's args to construct the IOError so that\n+        the json specific args aren't used as IOError specific args\n+        and the error message from JSONDecodeError is preserved",
      "comment": "I think the last sentence still needs a period at the end.",
      "comment_id": 782303428,
      "user": "nateprewitt",
      "created_at": "2022-01-11T16:11:57Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r782303428"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "tests/test_requests.py",
      "line": 2601,
      "side": "RIGHT",
      "diff_hunk": "@@ -2585,5 +2585,18 @@ def test_post_json_nan(self, httpbin):\n \n     def test_json_decode_compatibility(self, httpbin):\n         r = requests.get(httpbin('bytes/20'))\n-        with pytest.raises(requests.exceptions.JSONDecodeError):\n+        data = r.text\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n             r.json()\n+        assert isinstance(excinfo.value, RequestException)\n+        assert isinstance(excinfo.value, JSONDecodeError)\n+        assert data not in str(excinfo.value)\n+\n+    @pytest.mark.skipif(not is_py3, reason=\"doc attribute is only present on py3\")\n+    def test_json_decode_persists_doc_attr(self, httpbin):\n+        r = requests.get(httpbin('bytes/20'))\n+        data = r.text\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n+            r.json()\n+        assert data not in str(excinfo.value)",
      "comment": "We probably don't need to reassert this since it's already handled in the test above.",
      "comment_id": 782304038,
      "user": "nateprewitt",
      "created_at": "2022-01-11T16:12:37Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r782304038"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "tests/test_requests.py",
      "line": 2598,
      "side": "RIGHT",
      "diff_hunk": "@@ -2585,5 +2585,18 @@ def test_post_json_nan(self, httpbin):\n \n     def test_json_decode_compatibility(self, httpbin):\n         r = requests.get(httpbin('bytes/20'))\n-        with pytest.raises(requests.exceptions.JSONDecodeError):\n+        data = r.text\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n             r.json()\n+        assert isinstance(excinfo.value, RequestException)\n+        assert isinstance(excinfo.value, JSONDecodeError)\n+        assert data not in str(excinfo.value)\n+\n+    @pytest.mark.skipif(not is_py3, reason=\"doc attribute is only present on py3\")\n+    def test_json_decode_persists_doc_attr(self, httpbin):\n+        r = requests.get(httpbin('bytes/20'))\n+        data = r.text",
      "comment": "nit; since we're only using this once we can probably just use r.text in the final assertion as shown in the original proposal.",
      "comment_id": 782312495,
      "user": "nateprewitt",
      "created_at": "2022-01-11T16:21:42Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r782312495"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6036,
      "file_path": "tests/test_requests.py",
      "line": 2601,
      "side": "RIGHT",
      "diff_hunk": "@@ -2585,5 +2585,18 @@ def test_post_json_nan(self, httpbin):\n \n     def test_json_decode_compatibility(self, httpbin):\n         r = requests.get(httpbin('bytes/20'))\n-        with pytest.raises(requests.exceptions.JSONDecodeError):\n+        data = r.text\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n             r.json()\n+        assert isinstance(excinfo.value, RequestException)\n+        assert isinstance(excinfo.value, JSONDecodeError)\n+        assert data not in str(excinfo.value)\n+\n+    @pytest.mark.skipif(not is_py3, reason=\"doc attribute is only present on py3\")\n+    def test_json_decode_persists_doc_attr(self, httpbin):\n+        r = requests.get(httpbin('bytes/20'))\n+        data = r.text\n+        with pytest.raises(requests.exceptions.JSONDecodeError) as excinfo:\n+            r.json()\n+        assert data not in str(excinfo.value)",
      "comment": "I liked having both in the same test, assures us that we are testing with the right string. but i'll take it out.",
      "comment_id": 782337397,
      "user": "chyzzqo2",
      "created_at": "2022-01-11T16:43:54Z",
      "url": "https://github.com/psf/requests/pull/6036#discussion_r782337397"
    },
    {
      "repo": "psf/requests",
      "pr_number": 4766,
      "file_path": "tests/test_requests.py",
      "line": 883,
      "side": "RIGHT",
      "diff_hunk": "@@ -875,11 +875,12 @@ def test_form_encoded_post_query_multivalued_element(self, httpbin):\n         assert prep.body == 'test=foo&test=baz'\n \n     def test_different_encodings_dont_break_post(self, httpbin):\n-        r = requests.post(httpbin('post'),\n-            data={'stuff': json.dumps({'a': 123})},\n-            params={'blah': 'asdf1234'},\n-            files={'file': ('test_requests.py', open(__file__, 'rb'))})\n-        assert r.status_code == 200\n+        with open(__file__, 'rb') as f:\n+            r = requests.post(httpbin('post'),\n+                data={'stuff': json.dumps({'a': 123})},\n+                params={'blah': 'asdf1234'},\n+                files={'file': ('test_requests.py', f)})\n+            assert r.status_code == 200",
      "comment": "Let\u2019s pull the `assert` out to the same indentation level as `with`.",
      "comment_id": 209787773,
      "user": "nateprewitt",
      "created_at": "2018-08-13T23:14:55Z",
      "url": "https://github.com/psf/requests/pull/4766#discussion_r209787773"
    },
    {
      "repo": "psf/requests",
      "pr_number": 4766,
      "file_path": "tests/test_requests.py",
      "line": 912,
      "side": "RIGHT",
      "diff_hunk": "@@ -889,37 +890,41 @@ def test_different_encodings_dont_break_post(self, httpbin):\n             {'stuff': 'elixr'.encode('utf-8')},\n         ))\n     def test_unicode_multipart_post(self, httpbin, data):\n-        r = requests.post(httpbin('post'),\n-            data=data,\n-            files={'file': ('test_requests.py', open(__file__, 'rb'))})\n-        assert r.status_code == 200\n+        with open(__file__, 'rb') as f:\n+            r = requests.post(httpbin('post'),\n+                data=data,\n+                files={'file': ('test_requests.py', f)})\n+            assert r.status_code == 200\n \n     def test_unicode_multipart_post_fieldnames(self, httpbin):\n         filename = os.path.splitext(__file__)[0] + '.py'\n-        r = requests.Request(\n-            method='POST', url=httpbin('post'),\n-            data={'stuff'.encode('utf-8'): 'elixr'},\n-            files={'file': ('test_requests.py', open(filename, 'rb'))})\n-        prep = r.prepare()\n-        assert b'name=\"stuff\"' in prep.body\n-        assert b'name=\"b\\'stuff\\'\"' not in prep.body\n+        with open(filename, 'rb') as f:\n+            r = requests.Request(\n+                method='POST', url=httpbin('post'),\n+                data={'stuff'.encode('utf-8'): 'elixr'},\n+                files={'file': ('test_requests.py', f)})\n+            prep = r.prepare()\n+            assert b'name=\"stuff\"' in prep.body\n+            assert b'name=\"b\\'stuff\\'\"' not in prep.body\n \n     def test_unicode_method_name(self, httpbin):\n-        files = {'file': open(__file__, 'rb')}\n-        r = requests.request(\n-            method=u('POST'), url=httpbin('post'), files=files)\n-        assert r.status_code == 200\n+        with open(__file__, 'rb') as f:\n+            files = {'file': f}",
      "comment": "Let's just pass this directly to the `files` parameter.",
      "comment_id": 221472175,
      "user": "nateprewitt",
      "created_at": "2018-09-30T20:23:42Z",
      "url": "https://github.com/psf/requests/pull/4766#discussion_r221472175"
    },
    {
      "repo": "psf/requests",
      "pr_number": 4766,
      "file_path": "tests/test_requests.py",
      "line": 907,
      "side": "RIGHT",
      "diff_hunk": "@@ -889,37 +890,41 @@ def test_different_encodings_dont_break_post(self, httpbin):\n             {'stuff': 'elixr'.encode('utf-8')},\n         ))\n     def test_unicode_multipart_post(self, httpbin, data):\n-        r = requests.post(httpbin('post'),\n-            data=data,\n-            files={'file': ('test_requests.py', open(__file__, 'rb'))})\n-        assert r.status_code == 200\n+        with open(__file__, 'rb') as f:\n+            r = requests.post(httpbin('post'),\n+                data=data,\n+                files={'file': ('test_requests.py', f)})\n+            assert r.status_code == 200\n \n     def test_unicode_multipart_post_fieldnames(self, httpbin):\n         filename = os.path.splitext(__file__)[0] + '.py'\n-        r = requests.Request(\n-            method='POST', url=httpbin('post'),\n-            data={'stuff'.encode('utf-8'): 'elixr'},\n-            files={'file': ('test_requests.py', open(filename, 'rb'))})\n-        prep = r.prepare()\n-        assert b'name=\"stuff\"' in prep.body\n-        assert b'name=\"b\\'stuff\\'\"' not in prep.body\n+        with open(filename, 'rb') as f:\n+            r = requests.Request(\n+                method='POST', url=httpbin('post'),\n+                data={'stuff'.encode('utf-8'): 'elixr'},\n+                files={'file': ('test_requests.py', f)})\n+            prep = r.prepare()\n+            assert b'name=\"stuff\"' in prep.body",
      "comment": "These asserts can be done at the same indentation as the `with` block.",
      "comment_id": 221472224,
      "user": "nateprewitt",
      "created_at": "2018-09-30T20:25:23Z",
      "url": "https://github.com/psf/requests/pull/4766#discussion_r221472224"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "requests/sessions.py",
      "line": 41,
      "side": "RIGHT",
      "diff_hunk": "@@ -39,10 +39,7 @@\n \n # Preferred clock, based on which one is more accurate on a given system.\n if sys.platform == 'win32':",
      "comment": "Since we're now Python 3.7+ I wonder if we can start using `time.perf_counter` everywhere? Might need to do more research into why Windows was given only perf_counter/clock instead of `time.time()`",
      "comment_id": 833410951,
      "user": "sethmlarson",
      "created_at": "2022-03-23T15:32:31Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r833410951"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "setup.py",
      "line": 111,
      "side": "LEFT",
      "diff_hunk": "@@ -108,7 +102,6 @@ def run_tests(self):\n     extras_require={\n         'security': [],\n         'socks': ['PySocks>=1.5.6, !=1.5.7'],\n-        'socks:sys_platform == \"win32\" and python_version == \"2.7\"': ['win_inet_pton'],",
      "comment": "[Finally free...](https://pypi.org/project/win-inet-pton) :smiling_face_with_tear:",
      "comment_id": 833413598,
      "user": "sethmlarson",
      "created_at": "2022-03-23T15:34:32Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r833413598"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "tests/compat.py",
      "line": 15,
      "side": "RIGHT",
      "diff_hunk": "@@ -13,9 +10,5 @@\n except ImportError:\n     cStringIO = None\n \n-if is_py3:\n-    def u(s):\n-        return s\n-else:\n-    def u(s):\n-        return s.decode('unicode-escape')\n+def u(s):",
      "comment": "Should we go through and remove all uses of `u(...)` in the tests to simplify them?",
      "comment_id": 833414757,
      "user": "sethmlarson",
      "created_at": "2022-03-23T15:35:27Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r833414757"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "tests/test_requests.py",
      "line": 846,
      "side": "RIGHT",
      "diff_hunk": "@@ -844,7 +843,7 @@ def test_conflicting_post_params(self, httpbin):\n             with pytest.raises(ValueError):\n                 requests.post(url, data='[{\"some\": \"data\"}]', files={'some': f})\n             with pytest.raises(ValueError):\n-                requests.post(url, data=u('[{\"some\": \"data\"}]'), files={'some': f})\n+                requests.post(url, data=u'[{\"some\": \"data\"}]', files={'some': f})",
      "comment": "No we don't, I have a separate linting PR that removes these lines entirely since they're redundant. I can move that into this one.",
      "comment_id": 833421896,
      "user": "nateprewitt",
      "created_at": "2022-03-23T15:41:49Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r833421896"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "tests/compat.py",
      "line": 15,
      "side": "RIGHT",
      "diff_hunk": "@@ -13,9 +10,5 @@\n except ImportError:\n     cStringIO = None\n \n-if is_py3:\n-    def u(s):\n-        return s\n-else:\n-    def u(s):\n-        return s.decode('unicode-escape')\n+def u(s):",
      "comment": "I left the definition in case it's in use externally, but yes, it should be removed from all of our tests. I'll do a second pass if I missed some.",
      "comment_id": 833422816,
      "user": "nateprewitt",
      "created_at": "2022-03-23T15:42:39Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r833422816"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "requests/sessions.py",
      "line": 41,
      "side": "RIGHT",
      "diff_hunk": "@@ -39,10 +39,7 @@\n \n # Preferred clock, based on which one is more accurate on a given system.\n if sys.platform == 'win32':",
      "comment": "It was a performance issue for Windows where the clock wasn't granular enough for CI to pass on Appveyor (#3988). I can take a look at standardizing everything onto perf_counter but that's probably a separate deep dive.",
      "comment_id": 833422938,
      "user": "nateprewitt",
      "created_at": "2022-03-23T15:42:44Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r833422938"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "tests/test_requests.py",
      "line": 846,
      "side": "RIGHT",
      "diff_hunk": "@@ -844,7 +843,7 @@ def test_conflicting_post_params(self, httpbin):\n             with pytest.raises(ValueError):\n                 requests.post(url, data='[{\"some\": \"data\"}]', files={'some': f})\n             with pytest.raises(ValueError):\n-                requests.post(url, data=u('[{\"some\": \"data\"}]'), files={'some': f})\n+                requests.post(url, data=u'[{\"some\": \"data\"}]', files={'some': f})",
      "comment": "`pyupgrade **/*.py --py37-plus` will deal with a bunch of `u''`s and other stuff.",
      "comment_id": 833439166,
      "user": "hugovk",
      "created_at": "2022-03-23T15:56:05Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r833439166"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "tests/test_requests.py",
      "line": 846,
      "side": "RIGHT",
      "diff_hunk": "@@ -844,7 +843,7 @@ def test_conflicting_post_params(self, httpbin):\n             with pytest.raises(ValueError):\n                 requests.post(url, data='[{\"some\": \"data\"}]', files={'some': f})\n             with pytest.raises(ValueError):\n-                requests.post(url, data=u('[{\"some\": \"data\"}]'), files={'some': f})\n+                requests.post(url, data=u'[{\"some\": \"data\"}]', files={'some': f})",
      "comment": "Yep, that's what's in the linting commit currently. Unfortunately, it just makes the two declarations identical so it will still require manual removal in one of the PRs.",
      "comment_id": 833449625,
      "user": "nateprewitt",
      "created_at": "2022-03-23T16:04:19Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r833449625"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "tests/compat.py",
      "line": 15,
      "side": "RIGHT",
      "diff_hunk": "@@ -13,9 +10,5 @@\n except ImportError:\n     cStringIO = None\n \n-if is_py3:\n-    def u(s):\n-        return s\n-else:\n-    def u(s):\n-        return s.decode('unicode-escape')\n+def u(s):",
      "comment": "Perhaps add a deprecation warning for any external use?",
      "comment_id": 833454405,
      "user": "hugovk",
      "created_at": "2022-03-23T16:08:55Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r833454405"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "setup.py",
      "line": 23,
      "side": "RIGHT",
      "diff_hunk": "@@ -8,7 +7,32 @@\n from setuptools import setup\n from setuptools.command.test import test as TestCommand\n \n-here = os.path.abspath(os.path.dirname(__file__))\n+\n+CURRENT_PYTHON = sys.version_info[:2]\n+REQUIRED_PYTHON = (3, 7)\n+\n+if CURRENT_PYTHON < REQUIRED_PYTHON:\n+    sys.stderr.write(\n+        \"\"\"\n+==========================\n+Unsupported Python version\n+==========================\n+This version of Requests requires Python {}.{}, but you're trying to\n+install it on Python {}.{}.\n+This may be because you are using a version of pip that doesn't\n+understand the python_requires classifier. Make sure you",
      "comment": "We discussed this in the urllib3 Discord with @nateprewitt and @graingert and figured out that this series of steps isn't always going to solve the problem because pip *also* dropped Python versions over time.\r\n\r\nThere were a few solutions proposed:\r\n- Keep the current message\r\n- Always recommend installing pip<21 (last version that supported Python 2 and 3.5)\r\n- Recommend installing [pip-with-requires-python](https://pypi.org/project/pip-with-requires-python)\r\n- Not give a recommendation on *how* to upgrade pip and setuptools?\r\n\r\nI also raised the point of recommending users upgrade pip/setuptools would likely break OS installations.",
      "comment_id": 834551612,
      "user": "sethmlarson",
      "created_at": "2022-03-24T17:20:47Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r834551612"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "setup.py",
      "line": 23,
      "side": "RIGHT",
      "diff_hunk": "@@ -8,7 +7,32 @@\n from setuptools import setup\n from setuptools.command.test import test as TestCommand\n \n-here = os.path.abspath(os.path.dirname(__file__))\n+\n+CURRENT_PYTHON = sys.version_info[:2]\n+REQUIRED_PYTHON = (3, 7)\n+\n+if CURRENT_PYTHON < REQUIRED_PYTHON:\n+    sys.stderr.write(\n+        \"\"\"\n+==========================\n+Unsupported Python version\n+==========================\n+This version of Requests requires Python {}.{}, but you're trying to\n+install it on Python {}.{}.\n+This may be because you are using a version of pip that doesn't\n+understand the python_requires classifier. Make sure you",
      "comment": "I think `pip-with-requires-python` is likely the safest option. Alternatively, we'd vend the requires values from the package in our setup.py and compose the install message from those values as @graingert suggested. That avoids any risk for Python 3.4 users who still comprise a significant number of downloads.",
      "comment_id": 834561046,
      "user": "nateprewitt",
      "created_at": "2022-03-24T17:31:20Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r834561046"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "setup.py",
      "line": 23,
      "side": "RIGHT",
      "diff_hunk": "@@ -8,7 +7,32 @@\n from setuptools import setup\n from setuptools.command.test import test as TestCommand\n \n-here = os.path.abspath(os.path.dirname(__file__))\n+\n+CURRENT_PYTHON = sys.version_info[:2]\n+REQUIRED_PYTHON = (3, 7)\n+\n+if CURRENT_PYTHON < REQUIRED_PYTHON:\n+    sys.stderr.write(\n+        \"\"\"\n+==========================\n+Unsupported Python version\n+==========================\n+This version of Requests requires Python {}.{}, but you're trying to\n+install it on Python {}.{}.\n+This may be because you are using a version of pip that doesn't\n+understand the python_requires classifier. Make sure you",
      "comment": "@pradyunsg Noted that new Python versions come with a \"good\" pip version out of the box. Maybe our strategy should be to instruct the user to either pin to <2.28 or upgrade to at least Python 3.7 (since they'll need that version to install Requests anyways) and then we don't need to mention pip/setuptools at all.",
      "comment_id": 834612265,
      "user": "sethmlarson",
      "created_at": "2022-03-24T18:32:48Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r834612265"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "setup.py",
      "line": 23,
      "side": "RIGHT",
      "diff_hunk": "@@ -8,7 +7,32 @@\n from setuptools import setup\n from setuptools.command.test import test as TestCommand\n \n-here = os.path.abspath(os.path.dirname(__file__))\n+\n+CURRENT_PYTHON = sys.version_info[:2]\n+REQUIRED_PYTHON = (3, 7)\n+\n+if CURRENT_PYTHON < REQUIRED_PYTHON:\n+    sys.stderr.write(\n+        \"\"\"\n+==========================\n+Unsupported Python version\n+==========================\n+This version of Requests requires Python {}.{}, but you're trying to\n+install it on Python {}.{}.\n+This may be because you are using a version of pip that doesn't\n+understand the python_requires classifier. Make sure you",
      "comment": "I went ahead and [ripped out the whole of touching pip versions](https://github.com/psf/requests/pull/6091/commits/febcd5199c278d99232124e22b3ab2d912b7cc16) after further discussion. If users want to upgrade their pip, that's something they can manage, otherwise the simplest option is to upgrade their Python version which will provide this automatically.\r\n\r\nOther users are free to pin to older supported versions as discussed in the original deprecation announcement.",
      "comment_id": 834679845,
      "user": "nateprewitt",
      "created_at": "2022-03-24T20:03:49Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r834679845"
    },
    {
      "repo": "psf/requests",
      "pr_number": 6091,
      "file_path": "setup.py",
      "line": 26,
      "side": "RIGHT",
      "diff_hunk": "@@ -17,17 +17,13 @@\n ==========================\n Unsupported Python version\n ==========================\n-This version of Requests requires Python {}.{}, but you're trying to\n-install it on Python {}.{}.\n-This may be because you are using a version of pip that doesn't\n-understand the python_requires classifier. Make sure you\n-have pip >= 9.0 and setuptools >= 24.2, then try again:\n-    $ python -m pip install --upgrade pip setuptools\n-    $ python -m pip install requests\n-This will install the latest version of Requests which works on your\n-version of Python. If you can't upgrade your pip (or Python), request\n-an older version of Requests:\n-    $ python -m pip install \"requests<2.28\"\n+This version of Requests requires at least Python {}.{}, but\n+you're trying to install it on Python {}.{}. To resolve this,\n+consider upgrading to a supported Python version.\n+\n+If you can't upgrade your Python version, you'll need to\n+pin to an older version of Requests:\n+    python -m pip install \"requests<2.28\"",
      "comment": "```suggestion\r\npin to an older version of Requests (<2.28).\r\n```\r\n\r\nLet's just go all the way here. :P",
      "comment_id": 834692016,
      "user": "pradyunsg",
      "created_at": "2022-03-24T20:18:55Z",
      "url": "https://github.com/psf/requests/pull/6091#discussion_r834692016"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5917,
      "file_path": "requests/utils.py",
      "line": 974,
      "side": "RIGHT",
      "diff_hunk": "@@ -932,15 +933,22 @@ def prepend_scheme_if_needed(url, new_scheme):\n \n     :rtype: str\n     \"\"\"\n-    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)\n+    parsed = parse_url(url)\n+    scheme, auth, host, port, path, query, fragment = parsed\n \n-    # urlparse is a finicky beast, and sometimes decides that there isn't a\n-    # netloc present. Assume that it's being over-cautious, and switch netloc\n-    # and path if urlparse decided there was no netloc.\n+    # urlparse and parse_url determine that there isn't a netloc present in some\n+    # urls. We've chosen to assume parsing is being over-cautious, and switch\n+    # the netloc and path. This is maintained for backwards compatibility.\n+    netloc = parsed.netloc",
      "comment": "Uhhh, what? This doesn't make any sense to me, is this something that's only needed for `urlparse`?",
      "comment_id": 761620552,
      "user": "sethmlarson",
      "created_at": "2021-12-03T03:18:15Z",
      "url": "https://github.com/psf/requests/pull/5917#discussion_r761620552"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5917,
      "file_path": "requests/utils.py",
      "line": 974,
      "side": "RIGHT",
      "diff_hunk": "@@ -932,15 +933,22 @@ def prepend_scheme_if_needed(url, new_scheme):\n \n     :rtype: str\n     \"\"\"\n-    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)\n+    parsed = parse_url(url)\n+    scheme, auth, host, port, path, query, fragment = parsed\n \n-    # urlparse is a finicky beast, and sometimes decides that there isn't a\n-    # netloc present. Assume that it's being over-cautious, and switch netloc\n-    # and path if urlparse decided there was no netloc.\n+    # urlparse and parse_url determine that there isn't a netloc present in some\n+    # urls. We've chosen to assume parsing is being over-cautious, and switch\n+    # the netloc and path. This is maintained for backwards compatibility.\n+    netloc = parsed.netloc",
      "comment": "Yeah, this is only a quirk for `urlparse`. I'd thought I repro'd with `parse_url` initially, but I'm unable to now.\r\n\r\nI'll reword the whole comment for clarity. I'm not confident the test suite covers all of the initial issue though. I think I'm still in favor of leaving the swap in place as a fallback for anything we're missing.",
      "comment_id": 763565145,
      "user": "nateprewitt",
      "created_at": "2021-12-07T01:46:39Z",
      "url": "https://github.com/psf/requests/pull/5917#discussion_r763565145"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5917,
      "file_path": "requests/utils.py",
      "line": 974,
      "side": "RIGHT",
      "diff_hunk": "@@ -932,15 +933,22 @@ def prepend_scheme_if_needed(url, new_scheme):\n \n     :rtype: str\n     \"\"\"\n-    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)\n+    parsed = parse_url(url)\n+    scheme, auth, host, port, path, query, fragment = parsed\n \n-    # urlparse is a finicky beast, and sometimes decides that there isn't a\n-    # netloc present. Assume that it's being over-cautious, and switch netloc\n-    # and path if urlparse decided there was no netloc.\n+    # urlparse and parse_url determine that there isn't a netloc present in some\n+    # urls. We've chosen to assume parsing is being over-cautious, and switch\n+    # the netloc and path. This is maintained for backwards compatibility.\n+    netloc = parsed.netloc",
      "comment": "@sethmlarson I've reworded things to be a bit clearer.",
      "comment_id": 776146587,
      "user": "nateprewitt",
      "created_at": "2021-12-29T04:13:20Z",
      "url": "https://github.com/psf/requests/pull/5917#discussion_r776146587"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5894,
      "file_path": "requests/sessions.py",
      "line": 636,
      "side": "LEFT",
      "diff_hunk": "@@ -633,7 +633,8 @@ def send(self, request, **kwargs):\n         kwargs.setdefault('stream', self.stream)\n         kwargs.setdefault('verify', self.verify)\n         kwargs.setdefault('cert', self.cert)\n-        kwargs.setdefault('proxies', self.rebuild_proxies(request, self.proxies))",
      "comment": "@sigmavirus24 this change is needed because without it we are calling to re-build proxies from the environment even when proxies have been set/provided. \r\n\r\nIn one use test case I have setup - the time to \"retrieve\" a cached connection (using the cache control adapter) 10,000 times goes from 9.741 seconds and 25212240 function calls to 9902240 function calls & 6.169 seconds after applying this change. ",
      "comment_id": 678786441,
      "user": "dbaxa",
      "created_at": "2021-07-29T02:59:31Z",
      "url": "https://github.com/psf/requests/pull/5894#discussion_r678786441"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5894,
      "file_path": "requests/sessions.py",
      "line": 293,
      "side": "RIGHT",
      "diff_hunk": "@@ -289,7 +289,9 @@ def rebuild_proxies(self, prepared_request, proxies):\n         new_proxies = proxies.copy()\n         no_proxy = proxies.get('no_proxy')\n \n-        bypass_proxy = should_bypass_proxies(url, no_proxy=no_proxy)\n+        bypass_proxy = False\n+        if self.trust_env:",
      "comment": "@omermizr  / @sigmavirus24 / @nateprewitt   - this change fixes the performance regression of #5891 but does not fix #5888. IMHO fixing #5888 is something that you might do by checking if a proxy has been selected as if one has not been selected you likely would not want to leak proxy credentials. Of course it might be easier to suggest that we do not explicitly support setting `Proxy-Authorization` as a header and that users must specify proxy credentials in the proxy url.",
      "comment_id": 679537744,
      "user": "dbaxa",
      "created_at": "2021-07-29T22:59:55Z",
      "url": "https://github.com/psf/requests/pull/5894#discussion_r679537744"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5894,
      "file_path": "requests/sessions.py",
      "line": 295,
      "side": "RIGHT",
      "diff_hunk": "@@ -289,7 +289,9 @@ def rebuild_proxies(self, prepared_request, proxies):\n         new_proxies = proxies.copy()\n         no_proxy = proxies.get('no_proxy')\n \n-        bypass_proxy = should_bypass_proxies(url, no_proxy=no_proxy)\n+        bypass_proxy = False\n+        if self.trust_env:\n+            bypass_proxy = should_bypass_proxies(url, no_proxy=no_proxy)\n         if self.trust_env and not bypass_proxy:",
      "comment": "Looking at the new change, I don't have an issue with the general idea. This seems like a performance improvement for rebuild_proxies, regardless of the outcome for #5888. Stylistically, I'd like to simplify the logic here a bit more though. Something along the lines of this would be preferred:\r\n\r\n```suggestion\r\n        if self.trust_env and not should_bypass_proxies(url, no_proxy=no_proxy):\r\n```\r\n\r\n@omermizr I don't want to volunteer you but if you have a moment, would you mind confirming this PR resolves your issue in #5891?",
      "comment_id": 687377459,
      "user": "nateprewitt",
      "created_at": "2021-08-12T04:24:39Z",
      "url": "https://github.com/psf/requests/pull/5894#discussion_r687377459"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5894,
      "file_path": "requests/sessions.py",
      "line": 295,
      "side": "RIGHT",
      "diff_hunk": "@@ -289,7 +289,9 @@ def rebuild_proxies(self, prepared_request, proxies):\n         new_proxies = proxies.copy()\n         no_proxy = proxies.get('no_proxy')\n \n-        bypass_proxy = should_bypass_proxies(url, no_proxy=no_proxy)\n+        bypass_proxy = False\n+        if self.trust_env:\n+            bypass_proxy = should_bypass_proxies(url, no_proxy=no_proxy)\n         if self.trust_env and not bypass_proxy:",
      "comment": "@nateprewitt While this is probably a good change, unless I'm missing something it doesn't resolve the issue - when 'trust_env' is set to True (which is the default), this changes nothing. \nMore specifically to my use case - I have no control over how the third party package I'm using creates the session, and it uses the default value for 'trust_env' (like most usages). ",
      "comment_id": 689175728,
      "user": "omermizr",
      "created_at": "2021-08-16T01:02:39Z",
      "url": "https://github.com/psf/requests/pull/5894#discussion_r689175728"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5391,
      "file_path": "requests/adapters.py",
      "line": 463,
      "side": "RIGHT",
      "diff_hunk": "@@ -459,7 +459,8 @@ def send(self, request, stream=False, timeout=None, verify=True, cert=None, prox\n                 try:\n                     low_conn.putrequest(request.method,\n                                         url,\n-                                        skip_accept_encoding=True)\n+                                        skip_accept_encoding=True,\n+                                        skip_host='Host' in request.headers)",
      "comment": "That's good, this appears to be the same way that the same situation is handled in the urllib3 code itself: https://github.com/urllib3/urllib3/blob/74d6be1ab66cef44c0f479c24b0fc1756a8fe4e9/src/urllib3/connection.py#L243-L246",
      "comment_id": 523465475,
      "user": "AaronRobson",
      "created_at": "2020-11-14T21:30:07Z",
      "url": "https://github.com/psf/requests/pull/5391#discussion_r523465475"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5924,
      "file_path": "requests/sessions.py",
      "line": 623,
      "side": "RIGHT",
      "diff_hunk": "@@ -633,7 +620,10 @@ def send(self, request, **kwargs):\n         kwargs.setdefault('stream', self.stream)\n         kwargs.setdefault('verify', self.verify)\n         kwargs.setdefault('cert', self.cert)\n-        kwargs.setdefault('proxies', self.rebuild_proxies(request, self.proxies))\n+        if 'proxies' not in kwargs:",
      "comment": "This change should actually fix the performance regression in most cases (`Session.request` - which I assume is the most common flow - always sets `proxies` on `kwargs`).",
      "comment_id": 701262009,
      "user": "omermizr",
      "created_at": "2021-09-02T16:52:25Z",
      "url": "https://github.com/psf/requests/pull/5924#discussion_r701262009"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5924,
      "file_path": "requests/sessions.py",
      "line": 624,
      "side": "RIGHT",
      "diff_hunk": "@@ -633,7 +620,10 @@ def send(self, request, **kwargs):\n         kwargs.setdefault('stream', self.stream)\n         kwargs.setdefault('verify', self.verify)\n         kwargs.setdefault('cert', self.cert)\n-        kwargs.setdefault('proxies', self.rebuild_proxies(request, self.proxies))\n+        if 'proxies' not in kwargs:\n+            kwargs['proxies'] = resolve_proxies(",
      "comment": "So now we're:\r\n1. No longer stripping the proxy-auth header. Sounds right to me.\r\n2. No longer setting the proxy-auth header at all. Is this the desired behavior? What if someone uses a proxy and passes the username + password in the url? (though I'm not sure if that flow is supported or not)",
      "comment_id": 701265200,
      "user": "omermizr",
      "created_at": "2021-09-02T16:56:54Z",
      "url": "https://github.com/psf/requests/pull/5924#discussion_r701265200"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5924,
      "file_path": "requests/utils.py",
      "line": 850,
      "side": "RIGHT",
      "diff_hunk": "@@ -830,6 +830,34 @@ def select_proxy(url, proxies):\n     return proxy\n \n \n+def resolve_proxies(request, proxies, trust_env=True):\n+    \"\"\"This method takes proxy information from a request and configuration\n+    input to resolve a mapping of target proxies. This will consider settings\n+    such a NO_PROXY to strip proxy configurations.\n+\n+    :param request: Request or PreparedRequest\n+    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n+    :param trust_env: Boolean declaring whether to trust environment configs\n+\n+    :rtype: dict\n+    \"\"\"\n+    proxies = proxies if proxies is not None else {}\n+    url = request.url\n+    scheme = urlparse(url).scheme\n+    no_proxy = proxies.get('no_proxy')\n+    new_proxies = proxies.copy()\n+\n+    bypass_proxy = should_bypass_proxies(url, no_proxy=no_proxy)",
      "comment": "Didn't we want to unify 850 and 851 so we don't call `should_bypass_proxies` if `trust_env` is `False`?",
      "comment_id": 701266063,
      "user": "omermizr",
      "created_at": "2021-09-02T16:58:04Z",
      "url": "https://github.com/psf/requests/pull/5924#discussion_r701266063"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5924,
      "file_path": "requests/sessions.py",
      "line": 624,
      "side": "RIGHT",
      "diff_hunk": "@@ -633,7 +620,10 @@ def send(self, request, **kwargs):\n         kwargs.setdefault('stream', self.stream)\n         kwargs.setdefault('verify', self.verify)\n         kwargs.setdefault('cert', self.cert)\n-        kwargs.setdefault('proxies', self.rebuild_proxies(request, self.proxies))\n+        if 'proxies' not in kwargs:\n+            kwargs['proxies'] = resolve_proxies(",
      "comment": "For 2.) we were never doing that before this change and I don't think that was an intended byproduct. We should still support our normal proxy auth flows that were available prior to #5681.",
      "comment_id": 701276964,
      "user": "nateprewitt",
      "created_at": "2021-09-02T17:13:41Z",
      "url": "https://github.com/psf/requests/pull/5924#discussion_r701276964"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5924,
      "file_path": "requests/utils.py",
      "line": 850,
      "side": "RIGHT",
      "diff_hunk": "@@ -830,6 +830,34 @@ def select_proxy(url, proxies):\n     return proxy\n \n \n+def resolve_proxies(request, proxies, trust_env=True):\n+    \"\"\"This method takes proxy information from a request and configuration\n+    input to resolve a mapping of target proxies. This will consider settings\n+    such a NO_PROXY to strip proxy configurations.\n+\n+    :param request: Request or PreparedRequest\n+    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs\n+    :param trust_env: Boolean declaring whether to trust environment configs\n+\n+    :rtype: dict\n+    \"\"\"\n+    proxies = proxies if proxies is not None else {}\n+    url = request.url\n+    scheme = urlparse(url).scheme\n+    no_proxy = proxies.get('no_proxy')\n+    new_proxies = proxies.copy()\n+\n+    bypass_proxy = should_bypass_proxies(url, no_proxy=no_proxy)",
      "comment": "We do, I was going to have @dbaxa rebase their change onto whatever we merge so they can still have a commit in the repo.",
      "comment_id": 701277868,
      "user": "nateprewitt",
      "created_at": "2021-09-02T17:14:52Z",
      "url": "https://github.com/psf/requests/pull/5924#discussion_r701277868"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5924,
      "file_path": "requests/sessions.py",
      "line": 623,
      "side": "RIGHT",
      "diff_hunk": "@@ -633,7 +620,10 @@ def send(self, request, **kwargs):\n         kwargs.setdefault('stream', self.stream)\n         kwargs.setdefault('verify', self.verify)\n         kwargs.setdefault('cert', self.cert)\n-        kwargs.setdefault('proxies', self.rebuild_proxies(request, self.proxies))\n+        if 'proxies' not in kwargs:",
      "comment": "Yep, I think `proxies` will be the escape hatch when performance is a concern here :)",
      "comment_id": 701278739,
      "user": "nateprewitt",
      "created_at": "2021-09-02T17:16:02Z",
      "url": "https://github.com/psf/requests/pull/5924#discussion_r701278739"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5707,
      "file_path": "requests/utils.py",
      "line": 268,
      "side": "RIGHT",
      "diff_hunk": "@@ -256,13 +256,28 @@ def extract_zipped_paths(path):\n \n     # we have a valid zip archive and a valid member of that archive\n     tmp = tempfile.gettempdir()\n-    extracted_path = os.path.join(tmp, *member.split('/'))\n+    extracted_path = os.path.join(tmp, member.split('/')[-1])\n     if not os.path.exists(extracted_path):\n-        extracted_path = zip_file.extract(member, path=tmp)\n-\n+        # use read + write to avoid the creating nested folders, we only want the file, avoids mkdir racing condition\n+        with atomic_open(extracted_path) as file_handler:\n+            file_handler.write(zip_file.read(member))\n     return extracted_path\n \n \n+@contextlib.contextmanager\n+def atomic_open(filename):",
      "comment": "Just to handle a further race condition that can happen between opening and writing the file.",
      "comment_id": 548761782,
      "user": "gaborbernat",
      "created_at": "2020-12-24T23:18:20Z",
      "url": "https://github.com/psf/requests/pull/5707#discussion_r548761782"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/compat.py",
      "line": 34,
      "side": "LEFT",
      "diff_hunk": "@@ -25,10 +26,6 @@\n #: Python 3.x?\n is_py3 = (_ver[0] == 3)\n \n-try:\n-    import simplejson as json\n-except ImportError:\n-    import json",
      "comment": "This is backwards incompatible and needs to be reverted",
      "comment_id": 664037480,
      "user": "sigmavirus24",
      "created_at": "2021-07-05T16:19:59Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r664037480"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/exceptions.py",
      "line": 42,
      "side": "RIGHT",
      "diff_hunk": "@@ -25,6 +35,10 @@ def __init__(self, *args, **kwargs):\n         super(RequestException, self).__init__(*args, **kwargs)\n \n \n+class JSONDecodeError(StandardJSONDecodeError, SimpleJSONDecodeError):\n+    \"\"\"Couldn't decode the text into json\"\"\"\n+\n+\n class InvalidJSONError(RequestException):",
      "comment": "I forgot we had this exception, where do we use it? Should we sub-class this in `JSONDecodeError` as well?",
      "comment_id": 664037858,
      "user": "sigmavirus24",
      "created_at": "2021-07-05T16:20:44Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r664037858"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/models.py",
      "line": 893,
      "side": "RIGHT",
      "diff_hunk": "@@ -882,12 +890,8 @@ def json(self, **kwargs):\n         r\"\"\"Returns the json-encoded content of a response, if any.\n \n         :param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n-        :raises simplejson.JSONDecodeError: If the response body does not\n-            contain valid json and simplejson is installed.\n-        :raises json.JSONDecodeError: If the response body does not contain\n-            valid json and simplejson is not installed on Python 3.\n-        :raises ValueError: If the response body does not contain valid\n-            json and simplejson is not installed on Python 2.        \n+        :raises requests.JSONDecodeError: If the response body does not",
      "comment": "Please document this as `requests.exceptions.JSONDecodeError`. Eventually I desperately want to stop importing every exception class into `requests/__init__.py`",
      "comment_id": 664039064,
      "user": "sigmavirus24",
      "created_at": "2021-07-05T16:23:21Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r664039064"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/models.py",
      "line": 920,
      "side": "RIGHT",
      "diff_hunk": "@@ -907,7 +911,13 @@ def json(self, **kwargs):\n                     # and the server didn't bother to tell us what codec *was*\n                     # used.\n                     pass\n-        return complexjson.loads(self.text, **kwargs)\n+\n+        try:\n+            return json.loads(self.text, **kwargs)\n+        except json.JSONDecodeError as e:\n+            # Catch JSON-related errors and raise as requests.JSONDecodeError\n+            # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n+            raise JSONDecodeError(e.msg, e.doc, e.pos)",
      "comment": "We should probably preserve the original exception instance in this as well and proxy attributes down to it. That way folks can find the original exception. I'm not certain `simplejson` and `json` have the same exception attributes with the same meaning",
      "comment_id": 664039537,
      "user": "sigmavirus24",
      "created_at": "2021-07-05T16:24:32Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r664039537"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/exceptions.py",
      "line": 42,
      "side": "RIGHT",
      "diff_hunk": "@@ -25,6 +35,10 @@ def __init__(self, *args, **kwargs):\n         super(RequestException, self).__init__(*args, **kwargs)\n \n \n+class JSONDecodeError(StandardJSONDecodeError, SimpleJSONDecodeError):\n+    \"\"\"Couldn't decode the text into json\"\"\"\n+\n+\n class InvalidJSONError(RequestException):",
      "comment": "I added this exception to sub-class both `JSONDecodeError`s",
      "comment_id": 664043187,
      "user": "steveberdy",
      "created_at": "2021-07-05T16:32:45Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r664043187"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/exceptions.py",
      "line": 42,
      "side": "RIGHT",
      "diff_hunk": "@@ -25,6 +35,10 @@ def __init__(self, *args, **kwargs):\n         super(RequestException, self).__init__(*args, **kwargs)\n \n \n+class JSONDecodeError(StandardJSONDecodeError, SimpleJSONDecodeError):\n+    \"\"\"Couldn't decode the text into json\"\"\"\n+\n+\n class InvalidJSONError(RequestException):",
      "comment": "I'm talking about the `InvalidJSONError` exception here (the line I commented on)",
      "comment_id": 664949709,
      "user": "sigmavirus24",
      "created_at": "2021-07-07T00:02:39Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r664949709"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/compat.py",
      "line": 36,
      "side": "RIGHT",
      "diff_hunk": "@@ -33,6 +33,7 @@\n except ImportError:\n     import json\n \n+",
      "comment": "These spacing changes aren't really related to the current PR, can we remove them.",
      "comment_id": 667094313,
      "user": "nateprewitt",
      "created_at": "2021-07-09T17:05:30Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r667094313"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/exceptions.py",
      "line": 38,
      "side": "RIGHT",
      "diff_hunk": "@@ -25,6 +35,10 @@ def __init__(self, *args, **kwargs):\n         super(RequestException, self).__init__(*args, **kwargs)\n \n \n+class JSONDecodeError(StandardJSONDecodeError, SimpleJSONDecodeError):",
      "comment": "Our custom exceptions in Requests should ideally fall under a catch-all parent exception, `RequestException`. That allows users to catch everything thrown by Requests.",
      "comment_id": 667095839,
      "user": "nateprewitt",
      "created_at": "2021-07-09T17:08:32Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r667095839"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/exceptions.py",
      "line": 42,
      "side": "RIGHT",
      "diff_hunk": "@@ -25,6 +35,10 @@ def __init__(self, *args, **kwargs):\n         super(RequestException, self).__init__(*args, **kwargs)\n \n \n+class JSONDecodeError(StandardJSONDecodeError, SimpleJSONDecodeError):\n+    \"\"\"Couldn't decode the text into json\"\"\"\n+\n+\n class InvalidJSONError(RequestException):",
      "comment": "I think we're still waiting on a response here, @steveberdy.",
      "comment_id": 667096117,
      "user": "nateprewitt",
      "created_at": "2021-07-09T17:09:04Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r667096117"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/models.py",
      "line": 920,
      "side": "RIGHT",
      "diff_hunk": "@@ -907,7 +911,13 @@ def json(self, **kwargs):\n                     # and the server didn't bother to tell us what codec *was*\n                     # used.\n                     pass\n-        return complexjson.loads(self.text, **kwargs)\n+\n+        try:\n+            return json.loads(self.text, **kwargs)\n+        except json.JSONDecodeError as e:\n+            # Catch JSON-related errors and raise as requests.JSONDecodeError\n+            # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n+            raise JSONDecodeError(e.msg, e.doc, e.pos)",
      "comment": "I'm not sure I'm following how this will work in the Python 2 `json` case. Where is `ValueError` being handled?",
      "comment_id": 667104578,
      "user": "nateprewitt",
      "created_at": "2021-07-09T17:24:48Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r667104578"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/models.py",
      "line": 920,
      "side": "RIGHT",
      "diff_hunk": "@@ -907,7 +911,13 @@ def json(self, **kwargs):\n                     # and the server didn't bother to tell us what codec *was*\n                     # used.\n                     pass\n-        return complexjson.loads(self.text, **kwargs)\n+\n+        try:\n+            return json.loads(self.text, **kwargs)\n+        except json.JSONDecodeError as e:\n+            # Catch JSON-related errors and raise as requests.JSONDecodeError\n+            # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n+            raise JSONDecodeError(e.msg, e.doc, e.pos)",
      "comment": "https://github.com/psf/requests/pull/5856/checks?check_run_id=3031103164 Yeah, this is broken. We need to be able to handle this a different way.",
      "comment_id": 667105634,
      "user": "nateprewitt",
      "created_at": "2021-07-09T17:26:43Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r667105634"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/models.py",
      "line": 920,
      "side": "RIGHT",
      "diff_hunk": "@@ -907,7 +911,13 @@ def json(self, **kwargs):\n                     # and the server didn't bother to tell us what codec *was*\n                     # used.\n                     pass\n-        return complexjson.loads(self.text, **kwargs)\n+\n+        try:\n+            return json.loads(self.text, **kwargs)\n+        except json.JSONDecodeError as e:\n+            # Catch JSON-related errors and raise as requests.JSONDecodeError\n+            # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n+            raise JSONDecodeError(e.msg, e.doc, e.pos)",
      "comment": "I see your last comment was made outside of this thread, @steveberdy. To clarify, while `json.JSONDecodeError` does inherit from `ValueError`, it's not going to work in this case. The exception doesn't exist in Python 2, so we fall over with an attribute error when handling the exception. You'll need to take another approach to handle this.",
      "comment_id": 667121799,
      "user": "nateprewitt",
      "created_at": "2021-07-09T17:56:48Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r667121799"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/exceptions.py",
      "line": 42,
      "side": "RIGHT",
      "diff_hunk": "@@ -25,6 +35,10 @@ def __init__(self, *args, **kwargs):\n         super(RequestException, self).__init__(*args, **kwargs)\n \n \n+class JSONDecodeError(StandardJSONDecodeError, SimpleJSONDecodeError):\n+    \"\"\"Couldn't decode the text into json\"\"\"\n+\n+\n class InvalidJSONError(RequestException):",
      "comment": "Yes, I can subclass that in `JSONDecodeError` as well.",
      "comment_id": 668015646,
      "user": "steveberdy",
      "created_at": "2021-07-12T15:07:16Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r668015646"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/models.py",
      "line": 918,
      "side": "RIGHT",
      "diff_hunk": "@@ -907,7 +905,16 @@ def json(self, **kwargs):\n                     # and the server didn't bother to tell us what codec *was*\n                     # used.\n                     pass\n-        return complexjson.loads(self.text, **kwargs)\n+\n+        try:\n+            return complexjson.loads(self.text, **kwargs)\n+        except JSONDecodeError as e:\n+            # Catch JSON-related errors and raise as requests.JSONDecodeError\n+            # This aliases json.JSONDecodeError and simplejson.JSONDecodeError\n+            if is_py2: # e is a ValueError\n+                raise RequestsJSONDecodeError()\n+            else:\n+                raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n ",
      "comment": "Giving the user 0 useful information is unacceptable. Why can't we use `e.message` there?\r\n\r\n```py\r\nPython 2.7.18 (default, May 19 2021, 00:00:00)\r\n[GCC 11.1.1 20210428 (Red Hat 11.1.1-1)] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import json\r\n>>> try:\r\n...   json.loads(\"foo\")\r\n... except ValueError as ve:\r\n...   pass\r\n...\r\n>>> dir(ve)\r\n['__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__getitem__', '__getslice__', '__hash__', '__init__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', 'args', 'message']\r\n>>> ve.message\r\n'No JSON object could be decoded'\r\n>>> ve.args\r\n('No JSON object could be decoded',)\r\n>>>\r\n```",
      "comment_id": 669195075,
      "user": "sigmavirus24",
      "created_at": "2021-07-14T00:25:15Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r669195075"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/compat.py",
      "line": 31,
      "side": "RIGHT",
      "diff_hunk": "@@ -28,8 +28,10 @@\n #: Python 3.x?\n is_py3 = (_ver[0] == 3)\n \n+has_simplejson = False",
      "comment": "It doesn't look like we use this anywhere except to declare the exceptions. We're already setting either dependency to be imported under the `json` namespace. Can we not just do `from json import JSONDecodeError` under the py3 section and have it automatically resolve? Perhaps adding a short comment above the import saying it's using simplejson or json depending on what was resolved?",
      "comment_id": 669741494,
      "user": "nateprewitt",
      "created_at": "2021-07-14T15:49:47Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r669741494"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/exceptions.py",
      "line": 11,
      "side": "RIGHT",
      "diff_hunk": "@@ -8,6 +8,16 @@\n \"\"\"\n from urllib3.exceptions import HTTPError as BaseHTTPError\n \n+try:",
      "comment": "We have logic for which simplejson/json exceptions we're using spread across a few places now. Is there a compelling reason not to simply import JSONDecodeError from compat since it's already been resolved and supplying it as a single parent class?",
      "comment_id": 671444604,
      "user": "nateprewitt",
      "created_at": "2021-07-16T18:18:17Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r671444604"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/exceptions.py",
      "line": 11,
      "side": "RIGHT",
      "diff_hunk": "@@ -8,6 +8,16 @@\n \"\"\"\n from urllib3.exceptions import HTTPError as BaseHTTPError\n \n+try:",
      "comment": "@nateprewitt We want to know which properties the `JSONDecodeError` has, since it may have different properties depending on compatibility. That requires an extra check on import.",
      "comment_id": 673240914,
      "user": "steveberdy",
      "created_at": "2021-07-20T15:40:55Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r673240914"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/exceptions.py",
      "line": 11,
      "side": "RIGHT",
      "diff_hunk": "@@ -8,6 +8,16 @@\n \"\"\"\n from urllib3.exceptions import HTTPError as BaseHTTPError\n \n+try:",
      "comment": "@steveberdy I'm not sure I'm following, could you clarify which properties you're referring to? We have 3 parent classes that we'd ever use in our environment, `json.JSONDecodeError`, `simplejson.JSONDecodeError`, and `ValueError`. Only one of those can be relevant in a given execution of Requests.\r\n\r\nWhat I was asking about was if we did:\r\n\r\n```python\r\nfrom .compat import JSONDecodeError as CompatJSONDecodeError\r\n\r\n[...]\r\n\r\nclass JSONDecodeError(InvalidJSONError, CompatJSONDecodeError):\r\n```\r\n\r\nWe've already resolved these values once in compat, so I wanted to know why we're doing it again here.",
      "comment_id": 673356731,
      "user": "nateprewitt",
      "created_at": "2021-07-20T17:53:17Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r673356731"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/exceptions.py",
      "line": 11,
      "side": "RIGHT",
      "diff_hunk": "@@ -8,6 +8,16 @@\n \"\"\"\n from urllib3.exceptions import HTTPError as BaseHTTPError\n \n+try:",
      "comment": "@nateprewitt For Python 3, in the `compat.py` file itself, reference to the `json` package directly, whether aliased as `json` or actually the `json` package itself, would always look for the `json` package rather than whatever was aliased as it. So, just in the `compat.py` file itself, I used the check. From all other scripts that have `from .compat import json`, however, it works as expected.",
      "comment_id": 673381345,
      "user": "steveberdy",
      "created_at": "2021-07-20T18:30:36Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r673381345"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5856,
      "file_path": "requests/exceptions.py",
      "line": 11,
      "side": "RIGHT",
      "diff_hunk": "@@ -8,6 +8,16 @@\n \"\"\"\n from urllib3.exceptions import HTTPError as BaseHTTPError\n \n+try:",
      "comment": "Hey @steveberdy, I think there may still be some confusion. If you open the _Files changed_ tab, you should be able to see the full context of this thread. I've written out the [full diff](https://github.com/nateprewitt/requests/commit/665cf30861fb356d84103808e240d6940e8ff3d6) from the suggestion above to minimize ambiguity. You should find this passes the test suite without issue, so please let me know if there were other concerns you had.\r\n\r\nWhile we're here it would also be good to add a test exercising this change. Something to the effect of the example below should be sufficient:\r\n\r\n```\r\ndef test_json_decode_compatibility(self, httpbin):\r\n    r = requests.get(httpbin('bytes/20'))\r\n    with pytest.raises(requests.exceptions.JSONDecodeError):\r\n        r.json()\r\n```\r\n\r\nThis won't cover simplejson in our general test suite, but I've done a one off run to ensure that's working.",
      "comment_id": 675272659,
      "user": "nateprewitt",
      "created_at": "2021-07-23T02:30:46Z",
      "url": "https://github.com/psf/requests/pull/5856#discussion_r675272659"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5851,
      "file_path": "requests/utils.py",
      "line": 248,
      "side": "RIGHT",
      "diff_hunk": "@@ -245,6 +245,9 @@ def extract_zipped_paths(path):\n     archive, member = os.path.split(path)\n     while archive and not os.path.exists(archive):\n         archive, prefix = os.path.split(archive)\n+        if not prefix:",
      "comment": "This explains why, but the code isn't clear as to what's happening or why this fixes the infinite loop. For example, a far superior comment might be:\r\n\r\n```\r\n# If we don't check for an empty prefix after the split (in other words, archive = / before and after the split), we _can_ end up in an infinite loop on a rare corner case affecting a small number of users\r\n```\r\n\r\nThis comment explains the conditions, why we care (it affects users), and the risk to making a change (if we break this again, we may not find out about it quickly)",
      "comment_id": 664947915,
      "user": "sigmavirus24",
      "created_at": "2021-07-06T23:56:55Z",
      "url": "https://github.com/psf/requests/pull/5851#discussion_r664947915"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5851,
      "file_path": "requests/utils.py",
      "line": 248,
      "side": "RIGHT",
      "diff_hunk": "@@ -245,6 +245,9 @@ def extract_zipped_paths(path):\n     archive, member = os.path.split(path)\n     while archive and not os.path.exists(archive):\n         archive, prefix = os.path.split(archive)\n+        if not prefix:",
      "comment": "Thanks for the feedback, I've updated the comment. ",
      "comment_id": 681158168,
      "user": "tl-hbk",
      "created_at": "2021-08-02T17:45:39Z",
      "url": "https://github.com/psf/requests/pull/5851#discussion_r681158168"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5797,
      "file_path": "setup.py",
      "line": 44,
      "side": "RIGHT",
      "diff_hunk": "@@ -41,7 +41,8 @@ def run_tests(self):\n packages = ['requests']\n \n requires = [\n-    'chardet>=3.0.2,<5',\n+    'charset_normalizer>=1.3.9,<2; python_version >= \"3\"',",
      "comment": "```suggestion\r\n    'charset_normalizer~=1.4.0,<2; python_version >= \"3\"',\r\n```",
      "comment_id": 637236978,
      "user": "potiuk",
      "created_at": "2021-05-21T21:16:35Z",
      "url": "https://github.com/psf/requests/pull/5797#discussion_r637236978"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5797,
      "file_path": "setup.py",
      "line": 44,
      "side": "RIGHT",
      "diff_hunk": "@@ -41,7 +41,8 @@ def run_tests(self):\n packages = ['requests']\n \n requires = [\n-    'chardet>=3.0.2,<5',\n+    'charset_normalizer~=1.4.0,<2; python_version >= \"3\"',",
      "comment": "```suggestion\r\n    'charset_normalizer~=1.4.0; python_version >= \"3\"',\r\n```",
      "comment_id": 637237986,
      "user": "potiuk",
      "created_at": "2021-05-21T21:17:59Z",
      "url": "https://github.com/psf/requests/pull/5797#discussion_r637237986"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5797,
      "file_path": "setup.py",
      "line": 107,
      "side": "RIGHT",
      "diff_hunk": "@@ -103,6 +104,7 @@ def run_tests(self):\n         'security': ['pyOpenSSL >= 0.14', 'cryptography>=1.3.4'],\n         'socks': ['PySocks>=1.5.6, !=1.5.7'],\n         'socks:sys_platform == \"win32\" and python_version == \"2.7\"': ['win_inet_pton'],\n+        'lgpl': ['chardet>=3.0.2,<5']",
      "comment": "This seems somewhat disingenuous. For one thing, it's not the _only_ way to get `lgpl` dependencies. For another, it really exists to just force `chardet` to be installed on py3 so should be named something more like `use_chardet_on_py3`",
      "comment_id": 641068555,
      "user": "sigmavirus24",
      "created_at": "2021-05-28T00:15:43Z",
      "url": "https://github.com/psf/requests/pull/5797#discussion_r641068555"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5797,
      "file_path": "requests/__init__.py",
      "line": 83,
      "side": "RIGHT",
      "diff_hunk": "@@ -62,12 +70,19 @@ def check_compatibility(urllib3_version, chardet_version):\n     assert minor >= 21\n     assert minor <= 26\n \n-    # Check chardet for compatibility.\n-    major, minor, patch = chardet_version.split('.')[:3]\n-    major, minor, patch = int(major), int(minor), int(patch)\n-    # chardet >= 3.0.2, < 5.0.0\n-    assert (3, 0, 2) <= (major, minor, patch) < (5, 0, 0)\n-\n+    # Check charset_normalizer for compatibility.\n+    if chardet_version:\n+        major, minor, patch = chardet_version.split('.')[:3]\n+        major, minor, patch = int(major), int(minor), int(patch)\n+        # chardet_version >= 3.0.2, < 5.0.0\n+        assert (3, 0, 2) <= (major, minor, patch) < (5, 0, 0)\n+    elif charset_normalizer_version:\n+        major, minor, patch = charset_normalizer_version.split('.')[:3]\n+        major, minor, patch = int(major), int(minor), int(patch)\n+        # charset_normalizer >= 1.3.9, < 2.0.0\n+        assert (1, 3, 9) <= (major, minor, patch) < (2, 0, 0)",
      "comment": "Changed to 1.4.1 to account for logging fix just added by @ousret ",
      "comment_id": 641297465,
      "user": "potiuk",
      "created_at": "2021-05-28T06:22:26Z",
      "url": "https://github.com/psf/requests/pull/5797#discussion_r641297465"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5797,
      "file_path": "requests/__init__.py",
      "line": 82,
      "side": "RIGHT",
      "diff_hunk": "@@ -62,12 +70,19 @@ def check_compatibility(urllib3_version, chardet_version):\n     assert minor >= 21\n     assert minor <= 26\n \n-    # Check chardet for compatibility.\n-    major, minor, patch = chardet_version.split('.')[:3]\n-    major, minor, patch = int(major), int(minor), int(patch)\n-    # chardet >= 3.0.2, < 5.0.0\n-    assert (3, 0, 2) <= (major, minor, patch) < (5, 0, 0)\n-\n+    # Check charset_normalizer for compatibility.\n+    if chardet_version:\n+        major, minor, patch = chardet_version.split('.')[:3]\n+        major, minor, patch = int(major), int(minor), int(patch)\n+        # chardet_version >= 3.0.2, < 5.0.0\n+        assert (3, 0, 2) <= (major, minor, patch) < (5, 0, 0)\n+    elif charset_normalizer_version:\n+        major, minor, patch = charset_normalizer_version.split('.')[:3]\n+        major, minor, patch = int(major), int(minor), int(patch)\n+        # charset_normalizer >= 1.3.9, < 2.0.0",
      "comment": "```suggestion\r\n        # charset_normalizer >= 1.4.1, < 2.0.0\r\n```",
      "comment_id": 641438297,
      "user": "mik-laj",
      "created_at": "2021-05-28T10:16:17Z",
      "url": "https://github.com/psf/requests/pull/5797#discussion_r641438297"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5797,
      "file_path": "requests/__init__.py",
      "line": 83,
      "side": "RIGHT",
      "diff_hunk": "@@ -62,12 +70,19 @@ def check_compatibility(urllib3_version, chardet_version):\n     assert minor >= 21\n     assert minor <= 26\n \n-    # Check chardet for compatibility.\n-    major, minor, patch = chardet_version.split('.')[:3]\n-    major, minor, patch = int(major), int(minor), int(patch)\n-    # chardet >= 3.0.2, < 5.0.0\n-    assert (3, 0, 2) <= (major, minor, patch) < (5, 0, 0)\n-\n+    # Check charset_normalizer for compatibility.\n+    if chardet_version:\n+        major, minor, patch = chardet_version.split('.')[:3]\n+        major, minor, patch = int(major), int(minor), int(patch)\n+        # chardet_version >= 3.0.2, < 5.0.0\n+        assert (3, 0, 2) <= (major, minor, patch) < (5, 0, 0)\n+    elif charset_normalizer_version:\n+        major, minor, patch = charset_normalizer_version.split('.')[:3]\n+        major, minor, patch = int(major), int(minor), int(patch)\n+        # charset_normalizer >= 1.4.1, < 2.0.0\n+        assert (1, 4, 1) <= (major, minor, patch) < (2, 0, 0)",
      "comment": "If charset_normalizer v2.0.0 is out do we need to update this to be >2?",
      "comment_id": 664014262,
      "user": "sethmlarson",
      "created_at": "2021-07-05T15:34:07Z",
      "url": "https://github.com/psf/requests/pull/5797#discussion_r664014262"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5797,
      "file_path": "setup.py",
      "line": 44,
      "side": "RIGHT",
      "diff_hunk": "@@ -41,7 +41,8 @@ def run_tests(self):\n packages = ['requests']\n \n requires = [\n-    'chardet>=3.0.2,<5',\n+    'charset_normalizer~=1.4.1; python_version >= \"3\"',",
      "comment": "We haven't tested v2. I'd rather get something imperfect out than something perfect. Today's literally the only time I've had to review anything",
      "comment_id": 664015764,
      "user": "sigmavirus24",
      "created_at": "2021-07-05T15:36:53Z",
      "url": "https://github.com/psf/requests/pull/5797#discussion_r664015764"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5797,
      "file_path": "setup.py",
      "line": 44,
      "side": "RIGHT",
      "diff_hunk": "@@ -41,7 +41,8 @@ def run_tests(self):\n packages = ['requests']\n \n requires = [\n-    'chardet>=3.0.2,<5',\n+    'charset_normalizer~=1.4.1; python_version >= \"3\"',",
      "comment": "Makes sense, I/we can handle the upgrade in a follow-up PR.",
      "comment_id": 664016609,
      "user": "sethmlarson",
      "created_at": "2021-07-05T15:38:30Z",
      "url": "https://github.com/psf/requests/pull/5797#discussion_r664016609"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5783,
      "file_path": "requests/utils.py",
      "line": 824,
      "side": "RIGHT",
      "diff_hunk": "@@ -820,7 +821,7 @@ def default_headers():\n     \"\"\"\n     return CaseInsensitiveDict({\n         'User-Agent': default_user_agent(),\n-        'Accept-Encoding': ', '.join(('gzip', 'deflate')),\n+        'Accept-Encoding': make_headers(accept_encoding=True)[\"accept-encoding\"],",
      "comment": "Should we generate this header once and store the result so it doesn't need to be called every time? The value is determined by imports so shouldn't be changing often.",
      "comment_id": 636462152,
      "user": "sethmlarson",
      "created_at": "2021-05-20T20:52:06Z",
      "url": "https://github.com/psf/requests/pull/5783#discussion_r636462152"
    },
    {
      "repo": "psf/requests",
      "pr_number": 5783,
      "file_path": "requests/utils.py",
      "line": 824,
      "side": "RIGHT",
      "diff_hunk": "@@ -820,7 +821,7 @@ def default_headers():\n     \"\"\"\n     return CaseInsensitiveDict({\n         'User-Agent': default_user_agent(),\n-        'Accept-Encoding': ', '.join(('gzip', 'deflate')),\n+        'Accept-Encoding': make_headers(accept_encoding=True)[\"accept-encoding\"],",
      "comment": "This optimization makes sense.  I kindly ask you to implement it in the way, you think fits best.",
      "comment_id": 636746931,
      "user": "dilyanpalauzov",
      "created_at": "2021-05-21T08:45:36Z",
      "url": "https://github.com/psf/requests/pull/5783#discussion_r636746931"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1660,
      "file_path": "requests/cookies.py",
      "line": 59,
      "side": "RIGHT",
      "diff_hunk": "@@ -45,7 +45,14 @@ def get_origin_req_host(self):\n         return self.get_host()\n \n     def get_full_url(self):\n-        return self._r.url\n+        if not self._r.headers.get('Host'):\n+            return self._r.url\n+        host = self._r.headers['Host']\n+        parsed = urlparse(self._r.url)\n+        return urlunparse([\n+            parsed.scheme, host, parsed.path, parsed.params, parsed.query,\n+            parsed.fragment\n+        ])",
      "comment": "Might be a good idea to comment this so we can remember why we did this weird thing. =)\n",
      "comment_id": 6863250,
      "user": "Lukasa",
      "created_at": "2013-10-09T17:34:25Z",
      "url": "https://github.com/psf/requests/pull/1660#discussion_r6863250"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1660,
      "file_path": "requests/cookies.py",
      "line": 59,
      "side": "RIGHT",
      "diff_hunk": "@@ -45,7 +45,14 @@ def get_origin_req_host(self):\n         return self.get_host()\n \n     def get_full_url(self):\n-        return self._r.url\n+        if not self._r.headers.get('Host'):\n+            return self._r.url\n+        host = self._r.headers['Host']\n+        parsed = urlparse(self._r.url)\n+        return urlunparse([\n+            parsed.scheme, host, parsed.path, parsed.params, parsed.query,\n+            parsed.fragment\n+        ])",
      "comment": "LOL If you don't write Ruby and your code isn't self-documenting. ;)\n",
      "comment_id": 6865822,
      "user": "sigmavirus24",
      "created_at": "2013-10-09T18:44:50Z",
      "url": "https://github.com/psf/requests/pull/1660#discussion_r6865822"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1660,
      "file_path": "requests/cookies.py",
      "line": null,
      "side": "RIGHT",
      "diff_hunk": "@@ -45,7 +45,18 @@ def get_origin_req_host(self):\n         return self.get_host()\n \n     def get_full_url(self):\n-        return self._r.url\n+        # Only return the response's URL if the user hadn't set the Host\n+        # header\n+        if not self._r.headers.get('Host'):\n+            return self._r.url\n+        # If they did set it, retrieve it and reconstruct the expected doain",
      "comment": "Psh. Who cares about proper spelling? :wink: \n\nSeriously though, thanks! :cake:\n",
      "comment_id": 6930211,
      "user": "sigmavirus24",
      "created_at": "2013-10-12T01:41:34Z",
      "url": "https://github.com/psf/requests/pull/1660#discussion_r6930211"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1515,
      "file_path": "requests/packages/urllib3/poolmanager.py",
      "line": 253,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,16 +238,22 @@ def _set_proxy_headers(self, url, headers=None):\n \n         if headers:\n             headers_.update(headers)\n-\n         return headers_\n \n-    def urlopen(self, method, url, **kw):\n+    def urlopen(self, method, url, redirect=True, **kw):\n         \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"\n-        kw['assert_same_host'] = False\n-        kw['headers'] = self._set_proxy_headers(url, headers=kw.get('headers'))\n-        return self.proxy_pool.urlopen(method, url, **kw)\n+        u = parse_url(url)\n+\n+        if u.scheme == \"http\":\n+            # It's too late to set proxy headers on per-request basis for\n+            # tunnelled HTTPS connections, should use\n+            # constructor's proxy_headers instead.\n+            kw['headers'] = self._set_proxy_headers(url, kw.get('headers',\n+                                                                self.headers))\n+            kw['headers'].update(self.proxy_headers)",
      "comment": "We need the set the Proxy-Authorization header regardless of HTTP or HTTPS. Is there a reason urllib3 can't do it? Because if there is, we'll need to fix it up in Requests.\n",
      "comment_id": 5728742,
      "user": "Lukasa",
      "created_at": "2013-08-13T05:52:06Z",
      "url": "https://github.com/psf/requests/pull/1515#discussion_r5728742"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1515,
      "file_path": "requests/packages/urllib3/poolmanager.py",
      "line": 253,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,16 +238,22 @@ def _set_proxy_headers(self, url, headers=None):\n \n         if headers:\n             headers_.update(headers)\n-\n         return headers_\n \n-    def urlopen(self, method, url, **kw):\n+    def urlopen(self, method, url, redirect=True, **kw):\n         \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"\n-        kw['assert_same_host'] = False\n-        kw['headers'] = self._set_proxy_headers(url, headers=kw.get('headers'))\n-        return self.proxy_pool.urlopen(method, url, **kw)\n+        u = parse_url(url)\n+\n+        if u.scheme == \"http\":\n+            # It's too late to set proxy headers on per-request basis for\n+            # tunnelled HTTPS connections, should use\n+            # constructor's proxy_headers instead.\n+            kw['headers'] = self._set_proxy_headers(url, kw.get('headers',\n+                                                                self.headers))\n+            kw['headers'].update(self.proxy_headers)",
      "comment": "Appropriate `Proxy-Authorization` header could be set in `proxy_headers` keyword argument for `proxy_from_url()`. I don't really think that proxy authentication belongs to urllib3, so I suggest to wrap `proxy_from_url` in requests with something like:\n\n``` python\nfrom urlparse import urlparse\nimport base64\nfrom .packages.urllib3.poolmanager import  proxy_from_url\n\ndef authenticated_proxy_from_url(url, **kw):\n    parsed_url = urlparse(url)\n    if '@' in parsed_url.netloc:\n        credentials = parsed_url.netloc.split('@')[0]\n        base64string = base64.encodestring(credentials)[:-1]\n        if 'proxy_headers' not in kw:\n            kw['proxy_headers'] = {}\n        kw['proxy_headers']['Proxy-Authorization'] = 'Basic %s' % base64string\n    return proxy_from_url(url, **kw)\n```\n\nOf course it's the most crude example, there's room for further sophistication, such as authentication methods other than Basic.\n",
      "comment_id": 5757098,
      "user": "stanvit",
      "created_at": "2013-08-14T07:39:43Z",
      "url": "https://github.com/psf/requests/pull/1515#discussion_r5757098"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1515,
      "file_path": "requests/packages/urllib3/poolmanager.py",
      "line": 253,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,16 +238,22 @@ def _set_proxy_headers(self, url, headers=None):\n \n         if headers:\n             headers_.update(headers)\n-\n         return headers_\n \n-    def urlopen(self, method, url, **kw):\n+    def urlopen(self, method, url, redirect=True, **kw):\n         \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"\n-        kw['assert_same_host'] = False\n-        kw['headers'] = self._set_proxy_headers(url, headers=kw.get('headers'))\n-        return self.proxy_pool.urlopen(method, url, **kw)\n+        u = parse_url(url)\n+\n+        if u.scheme == \"http\":\n+            # It's too late to set proxy headers on per-request basis for\n+            # tunnelled HTTPS connections, should use\n+            # constructor's proxy_headers instead.\n+            kw['headers'] = self._set_proxy_headers(url, kw.get('headers',\n+                                                                self.headers))\n+            kw['headers'].update(self.proxy_headers)",
      "comment": "Alright, I think we should add this header as part of this PR. We have a `get_auth_from_url` function in `utils.py` which should be used for this. @schlamar you can do this yourself, or if you prefer I can raise a PR against your branch that includes the change.\n",
      "comment_id": 5757723,
      "user": "Lukasa",
      "created_at": "2013-08-14T08:26:22Z",
      "url": "https://github.com/psf/requests/pull/1515#discussion_r5757723"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1515,
      "file_path": "requests/packages/urllib3/poolmanager.py",
      "line": 253,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,16 +238,22 @@ def _set_proxy_headers(self, url, headers=None):\n \n         if headers:\n             headers_.update(headers)\n-\n         return headers_\n \n-    def urlopen(self, method, url, **kw):\n+    def urlopen(self, method, url, redirect=True, **kw):\n         \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"\n-        kw['assert_same_host'] = False\n-        kw['headers'] = self._set_proxy_headers(url, headers=kw.get('headers'))\n-        return self.proxy_pool.urlopen(method, url, **kw)\n+        u = parse_url(url)\n+\n+        if u.scheme == \"http\":\n+            # It's too late to set proxy headers on per-request basis for\n+            # tunnelled HTTPS connections, should use\n+            # constructor's proxy_headers instead.\n+            kw['headers'] = self._set_proxy_headers(url, kw.get('headers',\n+                                                                self.headers))\n+            kw['headers'].update(self.proxy_headers)",
      "comment": "To my utter disgust, GitHub seems unwilling to let me open a PR against your fork, @schlamar. Are you happy to accept an emailed patch? =D\n",
      "comment_id": 5758219,
      "user": "Lukasa",
      "created_at": "2013-08-14T08:59:24Z",
      "url": "https://github.com/psf/requests/pull/1515#discussion_r5758219"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1515,
      "file_path": "requests/packages/urllib3/poolmanager.py",
      "line": 253,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,16 +238,22 @@ def _set_proxy_headers(self, url, headers=None):\n \n         if headers:\n             headers_.update(headers)\n-\n         return headers_\n \n-    def urlopen(self, method, url, **kw):\n+    def urlopen(self, method, url, redirect=True, **kw):\n         \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"\n-        kw['assert_same_host'] = False\n-        kw['headers'] = self._set_proxy_headers(url, headers=kw.get('headers'))\n-        return self.proxy_pool.urlopen(method, url, **kw)\n+        u = parse_url(url)\n+\n+        if u.scheme == \"http\":\n+            # It's too late to set proxy headers on per-request basis for\n+            # tunnelled HTTPS connections, should use\n+            # constructor's proxy_headers instead.\n+            kw['headers'] = self._set_proxy_headers(url, kw.get('headers',\n+                                                                self.headers))\n+            kw['headers'].update(self.proxy_headers)",
      "comment": "> To my utter disgust, GitHub seems unwilling to let me open a PR against your fork,\n\nAny error message or why doesn't that work?\n\n> Are you happy to accept an emailed patch? =D\n\nI can just pull from your branch :) I guess https://github.com/Lukasa/requests/commits/https-proxy-2.0, right?\n",
      "comment_id": 5760175,
      "user": "schlamar",
      "created_at": "2013-08-14T10:49:16Z",
      "url": "https://github.com/psf/requests/pull/1515#discussion_r5760175"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1515,
      "file_path": "requests/packages/urllib3/poolmanager.py",
      "line": 253,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,16 +238,22 @@ def _set_proxy_headers(self, url, headers=None):\n \n         if headers:\n             headers_.update(headers)\n-\n         return headers_\n \n-    def urlopen(self, method, url, **kw):\n+    def urlopen(self, method, url, redirect=True, **kw):\n         \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"\n-        kw['assert_same_host'] = False\n-        kw['headers'] = self._set_proxy_headers(url, headers=kw.get('headers'))\n-        return self.proxy_pool.urlopen(method, url, **kw)\n+        u = parse_url(url)\n+\n+        if u.scheme == \"http\":\n+            # It's too late to set proxy headers on per-request basis for\n+            # tunnelled HTTPS connections, should use\n+            # constructor's proxy_headers instead.\n+            kw['headers'] = self._set_proxy_headers(url, kw.get('headers',\n+                                                                self.headers))\n+            kw['headers'].update(self.proxy_headers)",
      "comment": "> To my utter disgust, GitHub seems unwilling to let me open a PR against your fork\n\nMhh, I see the issue. Our branches our not comparable for whatever reason... I send an issue report to GitHub.\n",
      "comment_id": 5760232,
      "user": "schlamar",
      "created_at": "2013-08-14T10:52:40Z",
      "url": "https://github.com/psf/requests/pull/1515#discussion_r5760232"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1515,
      "file_path": "requests/packages/urllib3/poolmanager.py",
      "line": 253,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,16 +238,22 @@ def _set_proxy_headers(self, url, headers=None):\n \n         if headers:\n             headers_.update(headers)\n-\n         return headers_\n \n-    def urlopen(self, method, url, **kw):\n+    def urlopen(self, method, url, redirect=True, **kw):\n         \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"\n-        kw['assert_same_host'] = False\n-        kw['headers'] = self._set_proxy_headers(url, headers=kw.get('headers'))\n-        return self.proxy_pool.urlopen(method, url, **kw)\n+        u = parse_url(url)\n+\n+        if u.scheme == \"http\":\n+            # It's too late to set proxy headers on per-request basis for\n+            # tunnelled HTTPS connections, should use\n+            # constructor's proxy_headers instead.\n+            kw['headers'] = self._set_proxy_headers(url, kw.get('headers',\n+                                                                self.headers))\n+            kw['headers'].update(self.proxy_headers)",
      "comment": "Yeah, I don't really know how GitHub decides that. There are loads of forks I _can_ open PRs against, just not yours. Very strange. Anyway, I can just email the patch if it's faster.\n",
      "comment_id": 5760248,
      "user": "Lukasa",
      "created_at": "2013-08-14T10:53:27Z",
      "url": "https://github.com/psf/requests/pull/1515#discussion_r5760248"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1515,
      "file_path": "requests/packages/urllib3/poolmanager.py",
      "line": 253,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,16 +238,22 @@ def _set_proxy_headers(self, url, headers=None):\n \n         if headers:\n             headers_.update(headers)\n-\n         return headers_\n \n-    def urlopen(self, method, url, **kw):\n+    def urlopen(self, method, url, redirect=True, **kw):\n         \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"\n-        kw['assert_same_host'] = False\n-        kw['headers'] = self._set_proxy_headers(url, headers=kw.get('headers'))\n-        return self.proxy_pool.urlopen(method, url, **kw)\n+        u = parse_url(url)\n+\n+        if u.scheme == \"http\":\n+            # It's too late to set proxy headers on per-request basis for\n+            # tunnelled HTTPS connections, should use\n+            # constructor's proxy_headers instead.\n+            kw['headers'] = self._set_proxy_headers(url, kw.get('headers',\n+                                                                self.headers))\n+            kw['headers'].update(self.proxy_headers)",
      "comment": "I guess \n\n```\n$ git remote add lukasa https://github.com/Lukasa/requests.git\n$ git fetch lukasa\n$ git merge lukasa/https-proxy-2.0\n```\n\nis faster than processing a patch per mail :)\n",
      "comment_id": 5760951,
      "user": "schlamar",
      "created_at": "2013-08-14T11:36:56Z",
      "url": "https://github.com/psf/requests/pull/1515#discussion_r5760951"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1515,
      "file_path": "requests/packages/urllib3/poolmanager.py",
      "line": 253,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,16 +238,22 @@ def _set_proxy_headers(self, url, headers=None):\n \n         if headers:\n             headers_.update(headers)\n-\n         return headers_\n \n-    def urlopen(self, method, url, **kw):\n+    def urlopen(self, method, url, redirect=True, **kw):\n         \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"\n-        kw['assert_same_host'] = False\n-        kw['headers'] = self._set_proxy_headers(url, headers=kw.get('headers'))\n-        return self.proxy_pool.urlopen(method, url, **kw)\n+        u = parse_url(url)\n+\n+        if u.scheme == \"http\":\n+            # It's too late to set proxy headers on per-request basis for\n+            # tunnelled HTTPS connections, should use\n+            # constructor's proxy_headers instead.\n+            kw['headers'] = self._set_proxy_headers(url, kw.get('headers',\n+                                                                self.headers))\n+            kw['headers'].update(self.proxy_headers)",
      "comment": "Almost certainly true. I blame GitHub for our pain today. =D\n",
      "comment_id": 5760971,
      "user": "Lukasa",
      "created_at": "2013-08-14T11:37:55Z",
      "url": "https://github.com/psf/requests/pull/1515#discussion_r5760971"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1515,
      "file_path": "requests/packages/urllib3/poolmanager.py",
      "line": 253,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,16 +238,22 @@ def _set_proxy_headers(self, url, headers=None):\n \n         if headers:\n             headers_.update(headers)\n-\n         return headers_\n \n-    def urlopen(self, method, url, **kw):\n+    def urlopen(self, method, url, redirect=True, **kw):\n         \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"\n-        kw['assert_same_host'] = False\n-        kw['headers'] = self._set_proxy_headers(url, headers=kw.get('headers'))\n-        return self.proxy_pool.urlopen(method, url, **kw)\n+        u = parse_url(url)\n+\n+        if u.scheme == \"http\":\n+            # It's too late to set proxy headers on per-request basis for\n+            # tunnelled HTTPS connections, should use\n+            # constructor's proxy_headers instead.\n+            kw['headers'] = self._set_proxy_headers(url, kw.get('headers',\n+                                                                self.headers))\n+            kw['headers'].update(self.proxy_headers)",
      "comment": "> That network has a very large number of forks. For performance reasons, we don't show all of the available forked repositories in the Compare drop-down. We're looking into ways of improving this, but in the meantime you can generate a comparison by manually entering the URL. Try this one, for example:\n> \n> https://github.com/Lukasa/requests/compare/schlamar:master...master\n",
      "comment_id": 5772110,
      "user": "schlamar",
      "created_at": "2013-08-14T18:43:14Z",
      "url": "https://github.com/psf/requests/pull/1515#discussion_r5772110"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1515,
      "file_path": "requests/packages/urllib3/poolmanager.py",
      "line": 253,
      "side": "RIGHT",
      "diff_hunk": "@@ -187,16 +238,22 @@ def _set_proxy_headers(self, url, headers=None):\n \n         if headers:\n             headers_.update(headers)\n-\n         return headers_\n \n-    def urlopen(self, method, url, **kw):\n+    def urlopen(self, method, url, redirect=True, **kw):\n         \"Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute.\"\n-        kw['assert_same_host'] = False\n-        kw['headers'] = self._set_proxy_headers(url, headers=kw.get('headers'))\n-        return self.proxy_pool.urlopen(method, url, **kw)\n+        u = parse_url(url)\n+\n+        if u.scheme == \"http\":\n+            # It's too late to set proxy headers on per-request basis for\n+            # tunnelled HTTPS connections, should use\n+            # constructor's proxy_headers instead.\n+            kw['headers'] = self._set_proxy_headers(url, kw.get('headers',\n+                                                                self.headers))\n+            kw['headers'].update(self.proxy_headers)",
      "comment": "Ah, that makes perfect sense. I could have sworn I tried that, but clearly I didn't. Awesome!\n",
      "comment_id": 5772318,
      "user": "Lukasa",
      "created_at": "2013-08-14T18:49:55Z",
      "url": "https://github.com/psf/requests/pull/1515#discussion_r5772318"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1972,
      "file_path": "requests/structures.py",
      "line": null,
      "side": "RIGHT",
      "diff_hunk": "@@ -108,6 +108,9 @@ def copy(self):\n     def __repr__(self):\n         return '%s(%r)' % (self.__class__.__name__, dict(self.items()))\n \n+    def __str__(self):\n+        return '%s' % (dict(self.items()))",
      "comment": "This could be more simply:\n\n``` python\ndef __str__(self):\n    return str(dict(self.items()))\n```\n\nThis isn't a merge blocker though.\n",
      "comment_id": 10865063,
      "user": "sigmavirus24",
      "created_at": "2014-03-23T00:49:11Z",
      "url": "https://github.com/psf/requests/pull/1972#discussion_r10865063"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1507,
      "file_path": "requests/sessions.py",
      "line": 445,
      "side": "RIGHT",
      "diff_hunk": "@@ -422,7 +441,7 @@ def send(self, request, **kwargs):\n \n         # It's possible that users might accidentally send a Request object.\n         # Guard against that specific failure case.\n-        if getattr(request, 'prepare', None):\n+        if not isinstance(request, PreparedRequest):\n             raise ValueError('You can only send PreparedRequests.')",
      "comment": "Out of curiousity, why doesn't this just call `request.prepare()` (or `self.prepare_request(request)`) instead of failing?\n",
      "comment_id": 5517892,
      "user": "rwe",
      "created_at": "2013-07-31T22:28:45Z",
      "url": "https://github.com/psf/requests/pull/1507#discussion_r5517892"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1507,
      "file_path": "requests/sessions.py",
      "line": 445,
      "side": "RIGHT",
      "diff_hunk": "@@ -422,7 +441,7 @@ def send(self, request, **kwargs):\n \n         # It's possible that users might accidentally send a Request object.\n         # Guard against that specific failure case.\n-        if getattr(request, 'prepare', None):\n+        if not isinstance(request, PreparedRequest):\n             raise ValueError('You can only send PreparedRequests.')",
      "comment": "Why would we raise such a horrible stacktrace when we can raise a much cleaner one and provide the user with an exact message as to why their request cannot be sent?\n",
      "comment_id": 5520356,
      "user": "sigmavirus24",
      "created_at": "2013-08-01T01:06:07Z",
      "url": "https://github.com/psf/requests/pull/1507#discussion_r5520356"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1507,
      "file_path": "requests/sessions.py",
      "line": 445,
      "side": "RIGHT",
      "diff_hunk": "@@ -422,7 +441,7 @@ def send(self, request, **kwargs):\n \n         # It's possible that users might accidentally send a Request object.\n         # Guard against that specific failure case.\n-        if getattr(request, 'prepare', None):\n+        if not isinstance(request, PreparedRequest):\n             raise ValueError('You can only send PreparedRequests.')",
      "comment": "I meant this:\n\n``` python\nif isinstance(request, Request):\n    request = request.prepare()\nelif not isinstance(request, PreparedRequest):\n    raise ValueError('You can only send Requests or PreparedRequests')\n```\n\nThis is outside this PR though; not important.\n",
      "comment_id": 5520474,
      "user": "rwe",
      "created_at": "2013-08-01T01:16:20Z",
      "url": "https://github.com/psf/requests/pull/1507#discussion_r5520474"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1507,
      "file_path": "requests/sessions.py",
      "line": 445,
      "side": "RIGHT",
      "diff_hunk": "@@ -422,7 +441,7 @@ def send(self, request, **kwargs):\n \n         # It's possible that users might accidentally send a Request object.\n         # Guard against that specific failure case.\n-        if getattr(request, 'prepare', None):\n+        if not isinstance(request, PreparedRequest):\n             raise ValueError('You can only send PreparedRequests.')",
      "comment": "Why would we contradict ourselves in the documentation then? We documented the API before we made this change. This was to ensure the API (and its documentation) was correct.\n",
      "comment_id": 5520681,
      "user": "sigmavirus24",
      "created_at": "2013-08-01T01:32:24Z",
      "url": "https://github.com/psf/requests/pull/1507#discussion_r5520681"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1507,
      "file_path": "requests/sessions.py",
      "line": 445,
      "side": "RIGHT",
      "diff_hunk": "@@ -422,7 +441,7 @@ def send(self, request, **kwargs):\n \n         # It's possible that users might accidentally send a Request object.\n         # Guard against that specific failure case.\n-        if getattr(request, 'prepare', None):\n+        if not isinstance(request, PreparedRequest):\n             raise ValueError('You can only send PreparedRequests.')",
      "comment": "I can't seem to find where that restriction is documented. That said, my question was more along the lines of why that restriction was designed in without supporting `Request` objects in the first place. I suspect that most users using `Request` objects only create `PreparedRequest` with directly before calling `Session.send()`, without modifying it, and so that extra hoop just gets in the way of the common case. It seemed like an artificial obstacle.\n\nAvoiding the burden lf supporting multiple argument types was the kind of rationale I expected; because it was documented before it was designed isn't.\n\nHowever: this doesn't affect my use case and I was just trying to understand the design decision better. Thanks for your answer.\n",
      "comment_id": 5520977,
      "user": "rwe",
      "created_at": "2013-08-01T02:01:16Z",
      "url": "https://github.com/psf/requests/pull/1507#discussion_r5520977"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1507,
      "file_path": "requests/sessions.py",
      "line": 445,
      "side": "RIGHT",
      "diff_hunk": "@@ -422,7 +441,7 @@ def send(self, request, **kwargs):\n \n         # It's possible that users might accidentally send a Request object.\n         # Guard against that specific failure case.\n-        if getattr(request, 'prepare', None):\n+        if not isinstance(request, PreparedRequest):\n             raise ValueError('You can only send PreparedRequests.')",
      "comment": "The reasoning, essentially, is that Requests assumes that if you're building `Request` and `PreparedRequest` objects yourself, you are doing _everything_ about preparing them yourself. The `Request` -> `PreparedRequest` flow is basically an advanced use case, when you need to work around or change something Requests does internally.\n\nWhen considered in that light, passing a `Request` to `Session.send()` is likely to be a _mistake_: you have a flow through your code where the `Request` doesn't get prepared prior to sending. That was the purpose of this exception: rather than quietly succeed but potentially do something wrong, we assume that advanced users will just fix the exception.\n",
      "comment_id": 5522899,
      "user": "Lukasa",
      "created_at": "2013-08-01T05:58:43Z",
      "url": "https://github.com/psf/requests/pull/1507#discussion_r5522899"
    },
    {
      "repo": "psf/requests",
      "pr_number": 2088,
      "file_path": "test_requests.py",
      "line": null,
      "side": "RIGHT",
      "diff_hunk": "@@ -456,31 +460,36 @@ def test_urlencoded_get_query_multivalued_param(self):\n         assert r.url == httpbin('get?test=foo&test=baz')\n \n     def test_different_encodings_dont_break_post(self):\n-        r = requests.post(httpbin('post'),\n-                          data={'stuff': json.dumps({'a': 123})},\n-                          params={'blah': 'asdf1234'},\n-                          files={'file': ('test_requests.py', open(__file__, 'rb'))})\n+        r = requests.post(\n+            httpbin('post'),",
      "comment": "I'd consider these if the first parameter was included on the first line. \n",
      "comment_id": 13596504,
      "user": "kennethreitz",
      "created_at": "2014-06-10T14:32:31Z",
      "url": "https://github.com/psf/requests/pull/2088#discussion_r13596504"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1959,
      "file_path": "requests/models.py",
      "line": null,
      "side": "RIGHT",
      "diff_hunk": "@@ -410,6 +410,7 @@ def prepare_body(self, data, files):\n             hasattr(data, '__iter__'),\n             not isinstance(data, basestring),\n             not isinstance(data, list),\n+            not isinstance(data, tuple),",
      "comment": "I don't pretend to know who wrote this originally, but all of these should be shortened to:\n\n``` python\nnot isinstance(data, (basestring, list, tuple, dict))\n```\n\n`isinstance` will take a tuple for the second argument and make sure that the class is not one of the classes inside the tuple of classes. Do you mind fixing this up for us @Feng23 ?\n",
      "comment_id": 10606203,
      "user": "sigmavirus24",
      "created_at": "2014-03-14T13:09:05Z",
      "url": "https://github.com/psf/requests/pull/1959#discussion_r10606203"
    },
    {
      "repo": "psf/requests",
      "pr_number": 1959,
      "file_path": "test_requests.py",
      "line": null,
      "side": "RIGHT",
      "diff_hunk": "@@ -1187,5 +1189,28 @@ def test_stream_timeout(self):\n             assert 'Read timed out' in e.args[0].args[0]\n \n \n+class TestModels:",
      "comment": "This can be rewritten like so:\n\n``` python\n@pytest.fixture\ndef list_of_tuples():\n    return [\n        (('a', 'b'), ('c', 'd')),\n        (('c', 'd'), ('e', 'f')),\n        (('a', 'b'), ('c', 'd'), ('e', 'f')),\n    ]\n\ndef test_data_argument_accepts_tuples(list_of_tuples):\n    \"\"\"\n    Ensure that the data argument will accept tuples of strings\n    and properly encode them.\n    \"\"\"\n    for data_tuple in list_of_tuples:\n        p = PreparedRequest()\n        p.prepare(\n            method='GET',\n            url='http://example.com',\n            data=tuple_data,\n            hooks=default_hooks()\n        )\n        assert p.body == urlencode(tuple_data)\n```\n\nIt doesn't need to be in its own class and you're not really generating random data.\n",
      "comment_id": 10606404,
      "user": "sigmavirus24",
      "created_at": "2014-03-14T13:15:04Z",
      "url": "https://github.com/psf/requests/pull/1959#discussion_r10606404"
    }
  ]
}