{
  "format": "chatml",
  "stats": {
    "total": 10809,
    "kept": 7792,
    "filtered": {
      "code_too_long": 1902,
      "mostly_questions": 695,
      "mostly_code_blocks": 20,
      "mostly_links": 30,
      "boilerplate": 274,
      "comment_too_short": 9,
      "comment_too_long": 34,
      "low_value_short": 22,
      "code_too_short": 31
    }
  },
  "train_count": 7012,
  "eval_count": 780,
  "examples": [
    {
      "messages": [
        {
          "role": "system",
          "content": "You are an expert code reviewer. Analyze the provided Python code and give constructive, specific feedback. Focus on bugs, potential issues, code quality, and improvements. Be direct and actionable."
        },
        {
          "role": "user",
          "content": "Review this Python code from `_urlparse.py`:\n\n```python\n# For 'path' we need to drop ? and # from the GEN_DELIMS set.\n    parsed_path: str = quote(path, safe=SUB_DELIMS + \":/[]@\")\n    # For 'query' we need to drop '#' from the GEN_DELIMS set.\n    # We also exclude '/' because it is more robust to replace it with a percent\n    # encoding despite it not being a requirement of the spec and include '%' to\n    # prevent duplicate encoding of previously quoted items.\n    parsed_query: typing.Optional[str] = (\n        None if query is None else quote(query, safe=SUB_DELIMS + \":/?[]@\")\n        None if query is None else quote(query, safe=SUB_DELIMS + \":?[]@%\")\n```"
        },
        {
          "role": "assistant",
          "content": "I was surprised that I needed to include `%` but it was needed to to prevent spaces converted to `%20` from being changed to `%2520` in tests."
        }
      ],
      "_meta": {
        "repo": "encode/httpx",
        "pr_number": 2723,
        "url": "https://github.com/encode/httpx/pull/2723#discussion_r1207129278"
      }
    },
    {
      "messages": [
        {
          "role": "system",
          "content": "You are an expert code reviewer. Analyze the provided Python code and give constructive, specific feedback. Focus on bugs, potential issues, code quality, and improvements. Be direct and actionable."
        },
        {
          "role": "user",
          "content": "Review this Python code from `setup.py`:\n\n```python\n\"tokenizers\",\n    \"tqdm\",\n)\n\na = 1\n```"
        },
        {
          "role": "assistant",
          "content": "This line `a = 1` appears to be accidentally added debug code and should be removed. It serves no purpose in the setup file.\n```suggestion\n\n```"
        }
      ],
      "_meta": {
        "repo": "huggingface/transformers",
        "pr_number": 42260,
        "url": "https://github.com/huggingface/transformers/pull/42260#discussion_r2539083481"
      }
    },
    {
      "messages": [
        {
          "role": "system",
          "content": "You are an expert code reviewer. Analyze the provided Python code and give constructive, specific feedback. Focus on bugs, potential issues, code quality, and improvements. Be direct and actionable."
        },
        {
          "role": "user",
          "content": "Review this Python code from `serialized_dag.py`:\n\n```python\nreturn False\n\n        if dag_version and not dag_version.task_instances:\n            # This is for dynamic DAGs that the hashes changes often. We should update\n            # the serialized dag, the dag_version and the dag_code instead of a new version\n            # if the dag_version is not associated with any task instances\n            latest_ser_dag = cls.get(dag.dag_id, session=session)\n            if TYPE_CHECKING:\n                assert latest_ser_dag is not None\n            # Update the serialized DAG with the new_serialized_dag\n            latest_ser_dag._data = new_serialized_dag._data\n            latest_ser_dag._data_compressed = new_serialized_dag._data_compressed\n            latest_ser_dag.dag_hash = new_serialized_dag.dag_hash\n            session.merge(latest_ser_dag)\n            # The dag_version and dag_code may not have changed, still we should\n            # do the below actions:\n            # Update the latest dag version\n            dag_version.bundle_name = bundle_name\n            dag_version.bundle_version = bundle_version\n            session.merge(dag_version)\n            # Update the latest DagCode\n            DagCode.update_source_code(dag_id=dag.dag_id, fileloc=dag.fileloc, session=session)\n            return True\n            # This is for dynamic DAGs whose hashes change often. We should update\n            # the serialized DAG, the dag_version, and the dag_code instead of creating\n            # a new version if the dag_version has no associated task instances.\n\n            latest_ser_dag = dag_version.serialized_dag  # Use serialized_dag directly from dag_version\n\n            if latest_ser_dag:\n```"
        },
        {
          "role": "assistant",
          "content": "If we have `dag_version`, then there must be a serialized_dag. We need to make sure that latest_ser_dag is never none. You should make sure that `serialized_dag` is loaded when `DagVersion.get_latest_version` is called. So also update that method"
        }
      ],
      "_meta": {
        "repo": "apache/airflow",
        "pr_number": 56422,
        "url": "https://github.com/apache/airflow/pull/56422#discussion_r2432334084"
      }
    },
    {
      "messages": [
        {
          "role": "system",
          "content": "You are an expert code reviewer. Analyze the provided Python code and give constructive, specific feedback. Focus on bugs, potential issues, code quality, and improvements. Be direct and actionable."
        },
        {
          "role": "user",
          "content": "Review this Python code from `modeling_sam3.py`:\n\n```python\nif self.config._attn_implementation != \"eager\":\n            attention_interface = ALL_ATTENTION_FUNCTIONS[self.config._attn_implementation]\n\n        if (\n            self.config._attn_implementation == \"flash_attention_2\"\n            and attention_mask is not None\n            and attention_mask.dtype != torch.bool\n        ):\n            # Relative position bias tensors are represented as float masks and are incompatible with Flash Attention 2.\n            # Fallback to SDPA for this call only so the rest of the model can still benefit from FA2.\n            attention_interface = ALL_ATTENTION_FUNCTIONS[\"sdpa\"]\n            logger.warning_once(\n                \"Sam3Attention: falling back to SDPA for relative-position cross-attention because \"\n                \"Flash Attention 2 does not support additive bias masks.\"\n            )\n```"
        },
        {
          "role": "assistant",
          "content": "But yea, FA itself cannot support relative biases (except alibi). There was a different library which might support this #41882 (FA with biases)."
        }
      ],
      "_meta": {
        "repo": "huggingface/transformers",
        "pr_number": 42543,
        "url": "https://github.com/huggingface/transformers/pull/42543#discussion_r2581308204"
      }
    },
    {
      "messages": [
        {
          "role": "system",
          "content": "You are an expert code reviewer. Analyze the provided Python code and give constructive, specific feedback. Focus on bugs, potential issues, code quality, and improvements. Be direct and actionable."
        },
        {
          "role": "user",
          "content": "Review this Python code from `test_pools.py`:\n\n```python\nassert response_data[\"update\"][\"success\"] == [\"pool1\"]\n\n        # Assert: fetch from DB and check only masked field changed\n        updated_pool = session.query(Pool).filter_by(pool=\"pool1\").one()\n        updated_pool = session.execute(select(Pool).where(Pool.pool == \"pool1\")).scalar_one()\n```"
        },
        {
          "role": "assistant",
          "content": "`.scalar()` works, but `.one()` or `scalar_one(`) are stricter for tests here"
        }
      ],
      "_meta": {
        "repo": "apache/airflow",
        "pr_number": 59733,
        "url": "https://github.com/apache/airflow/pull/59733#discussion_r2649602827"
      }
    },
    {
      "messages": [
        {
          "role": "system",
          "content": "You are an expert code reviewer. Analyze the provided Python code and give constructive, specific feedback. Focus on bugs, potential issues, code quality, and improvements. Be direct and actionable."
        },
        {
          "role": "user",
          "content": "Review this Python code from `module_common.py`:\n\n```python\n)\n\n\ndef _get_action_arg_defaults(action: str, task: Task, templar: TemplateEngine) -> dict[str, t.Any]:\ndef _get_action_arg_defaults(action: str, task: Task, templar: TemplateEngine, finalize: bool = False) -> dict[str, t.Any]:\n    \"\"\"Get module_defaults that match or contain a fully qualified action/module name.\n```"
        },
        {
          "role": "assistant",
          "content": "For consistency with the majority of our multi-line docstrings, put start and end quotes on a line by themselves."
        }
      ],
      "_meta": {
        "repo": "ansible/ansible",
        "pr_number": 85857,
        "url": "https://github.com/ansible/ansible/pull/85857#discussion_r2666408554"
      }
    },
    {
      "messages": [
        {
          "role": "system",
          "content": "You are an expert code reviewer. Analyze the provided Python code and give constructive, specific feedback. Focus on bugs, potential issues, code quality, and improvements. Be direct and actionable."
        },
        {
          "role": "user",
          "content": "Review this Python code from `conformance.py`:\n\n```python\nreturn \"True positives removed\"\n\n\n@dataclass(kw_only=True, slots=True)\nclass Evaluation:\n```"
        },
        {
          "role": "assistant",
          "content": "With the last set of changes, we now count the diagnostics individually. So if ty emits 5 diagnostics on the same line where a \"# E\" is present, we're counting them all as true positives. Similarly, if ty raises 3 diagnostics on one line of a tagged group (no '+') and 1 on each of the other lines, we count the 3 diagnostics as true positives and the remainder as false positives. \n\nHappy to keep iterating on it though if this doesn't make sense."
        }
      ],
      "_meta": {
        "repo": "astral-sh/ruff",
        "pr_number": 22746,
        "url": "https://github.com/astral-sh/ruff/pull/22746#discussion_r2723118794"
      }
    },
    {
      "messages": [
        {
          "role": "system",
          "content": "You are an expert code reviewer. Analyze the provided Python code and give constructive, specific feedback. Focus on bugs, potential issues, code quality, and improvements. Be direct and actionable."
        },
        {
          "role": "user",
          "content": "Review this Python code from `modeling_test_detr.py`:\n\n```python\nbatch_size, num_queries, _ = hidden_states.shape\n        batch_size, sequence_length, _ = encoder_hidden_states.shape\n        total_elements = sum(height * width for height, width in spatial_shapes_list)\n        if total_elements != sequence_length:\n            raise ValueError(\n                \"Make sure to align the spatial shapes with the sequence length of the encoder hidden states\"\n            )\n        check_with(\n            ValueError,\n```"
        },
        {
          "role": "assistant",
          "content": "We should put the value error as a default because it seems to be used everywhere this way the more common cases were checked with function is used will be simplified"
        }
      ],
      "_meta": {
        "repo": "huggingface/transformers",
        "pr_number": 42317,
        "url": "https://github.com/huggingface/transformers/pull/42317#discussion_r2704255253"
      }
    },
    {
      "messages": [
        {
          "role": "system",
          "content": "You are an expert code reviewer. Analyze the provided Python code and give constructive, specific feedback. Focus on bugs, potential issues, code quality, and improvements. Be direct and actionable."
        },
        {
          "role": "user",
          "content": "Review this Python code from `_model_construction.py`:\n\n```python\nreturn super().__setitem__(k, v)\n\n\n@dataclass_transform(kw_only_default=True, field_specifiers=(PydanticModelField, PydanticModelPrivateAttr))\ndef NoInitField(\n    default: Any = PydanticUndefined,\n    *,\n    default_factory: typing.Callable[[], Any] | None = None,\n    init: Literal[False] = False,\n) -> Any:\n    \"\"\"Only for typing purpose. Used as default value of `__pydantic_fields_set__`,\n```"
        },
        {
          "role": "assistant",
          "content": "```suggestion\r\n    \"\"\"Only for typing purposes. Used as default value of `__pydantic_fields_set__`,\r\n```"
        }
      ],
      "_meta": {
        "repo": "pydantic/pydantic",
        "pr_number": 10110,
        "url": "https://github.com/pydantic/pydantic/pull/10110#discussion_r1714810295"
      }
    },
    {
      "messages": [
        {
          "role": "system",
          "content": "You are an expert code reviewer. Analyze the provided Python code and give constructive, specific feedback. Focus on bugs, potential issues, code quality, and improvements. Be direct and actionable."
        },
        {
          "role": "user",
          "content": "Review this Python code from `test_video_processing_qwen2_vl.py`:\n\n```python\nself.assertListEqual(list(encoded_videos.shape), expected_output_video_shape)\n            self.assertListEqual(list(encoded_videos_batched.shape), expected_output_video_shape_batched)\n\n            # Sample with `fps` requires metadata to infer number of frames from total duration\n```"
        },
        {
          "role": "assistant",
          "content": "It was defaulting to `fps=2.0` previously in Qwen without warning/error, so this part is mostly for BC. Yeah, we could raise a warning once to discourage users from falling to default fps path, as you noted in below comment\r\n\r\nThough an error might be a bit breaking especially for such high usage model as Qwen, we never know is users are happily exploiting the default values"
        }
      ],
      "_meta": {
        "repo": "huggingface/transformers",
        "pr_number": 39600,
        "url": "https://github.com/huggingface/transformers/pull/39600#discussion_r2282117663"
      }
    }
  ]
}