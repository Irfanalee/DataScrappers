{
  "tech": "gcp",
  "count": 26,
  "examples": [
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13938,
      "title": "Sporadic `DeadlineExceeded` GRPC errors when queuing tasks to Cloud Task",
      "problem": "### Determine this is the right repository\n\n- [x] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n**Context**\n\nWe have a service that uses Cloud Task to dispatch and run long running tasks. It has been running well for months, but since the 15th May we started noticing some sporadic `DeadlineExceeded` errors raised from gRPC. We have not changed anything in our system or in the way we enqueue tasks.\n\nThe amount of failed tasks raising `DeadlineExceeded` is probably around 20%.\n\nAfter seeing these new recent errors, we decided to add support for retries and a timeout when creating tasks, here is a similar configuration than the we used:\n```python\nretry = Retry(\n    predicate=if_exception_type(\n        exceptions.TooManyRequests,\n        exceptions.ServiceUnavailable,\n        requests.exceptions.ConnectionError,\n        requests.exceptions.ChunkedEncodingError,\n        auth_exceptions.TransportError,\n        exceptions.DeadlineExceeded,  # exception we started noticing\n    ),\n    initial=1.0,\n    maximum=2.0,\n    multiplier=2.0,\n    timeout=15.0,  # how long to keep retrying\n)\nclient.create_task(\n    request={\"parent\": parent, \"task\": task}, timeout=5.0, retry=retry\n)\n```\n\nWe saw the tasks that were raising an exception being retried, but none of them got successfully queued before timing out, and re-raising `DeadlineExceeded`. \n\nThe ones that gets queued successfully are very quick, so the configured timeouts should have been enough.\n\nAfter these failed attempts, the only way for us to actually make it work, and ensure 100% of our tasks are successfully put to the queue, was to switch the transport protocol from GRPC to HTTP.\n\n```python\nclient = CloudTasksClient(\n    transport=CloudTasksRestTransport(credentials=...)\n)\n```\n\nIs there anything that we are missing, or anything that has changed in the way the library is using GRPC that would explain why we started noticing this behaviour?\n\n**Expected Behavior:**\nAll our tasks should be queued successfully when retrying on sporadic `DeadlineExceeded` errors.\n\n**Actual Behavior:**\nWe are getting sporadic `DeadlineExceeded` errors, the task never gets queued, even on retry.\n\n### API client name and version\n\ngoogle-cloud-tasks 2.19.2\n\n### Reproduction steps: code\n\nThis is some pseudo code using the GRPC transport protocol, before we switched to using HTTP. Note that reaching the `DeadlineExceeded` exception seems to only happen on ~20% of the tasks we queued. The rest of the tasks were queued successfully.\n\nfile: main.py\n```python\nclient = CloudTasksClient()\nretry = Retry(\n    predicate=if_exception_type(\n        exceptions.DeadlineExceeded,  # exception we started noticing\n    ),\n    initial=1.0,\n    maximum=2.0,\n    multiplier=2.0,\n    timeout=15.0,  # how long to keep retrying\n)\nclient.create_task(\n    request={\"parent\": parent, \"task\": task}, timeout=5.0, retry=retry\n)\n```\n\n### Reproduction steps: supporting files\n\n_No response_\n\n### Reproduction steps: actual results\n\n_No response_\n\n### Reproduction steps: expected results\n\n\n\n\n### OS & version + platform\n\nDebian Bookworm (12) on App Engine flex\n\n### Python environment\n\nPython 3.12.10\n\n### Python dependencies\n\nHere is the list of our dependencies related to gRPC\n\n```\ngrpc-google-iam-v1                       0.14.2\ngrpcio                                   1.71.0\ngrpcio-status                            1.62.3\n```\n\n### Additional context\n\nHere is a sample of the traceback of the actual exception we've been seeing:\n\n```\n  File \"/opt/.venv/lib/python3.12/site-packages/grpc/_channel.py\", line 1006, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.DEADLINE_EXCEEDED\n\tdetails = \"Deadline Exceeded\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-05-21T14:14:37.173146012+00:00\", grpc_status:4, grpc_message:\"Deadline Exceeded\"}\"\n>\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/opt/.venv/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n    result = target()\n             ^^^^^^^^\n  File \"/opt/.venv/lib/python3.12/site-packages/google/api_core/timeout.py\", line 130, in func_with_timeout\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/.venv/lib/python3.12/site-packages/google/api_core/grpc_helpers.py\", line 78, in error_remapped_callable\n    raise exceptions.from_grpc_error(exc) from exc\ngoogle.api_core.exceptions.DeadlineExceeded: 504 Deadline Exceeded\n```",
      "solution": "Hi @parthea ,\n\nThank you for looking into this, and for the very detailed reply, this is much appreciated.\n\nI should have added more context about things we have tried, instead of setting the timeout to 5 seconds, we also tried using the default timeout (omitting the parameter when calling `create_task`), or increasing it to 30 seconds. Our original setup (when we first noticed the issues) was using the default timeout, and no retry handler. Note we used this config for a long time before we started noticing the `DeadlineExceeded` issues a few days ago. \n\n```py\nclient.create_task(request={\"parent\": parent, \"task\": task})\nclient.create_task(request={\"parent\": parent, \"task\": task}, retry=retry, timeout=30)\n```\n\nWith all the different new configs we tested, we experienced the same issue. We stuck to a 5 seconds as we thought it should still be enough time for the gRPC request to complete and queue the task to Cloud Task. This is also the timeout we are now using using the Rest transport client, and all tasks are queued successfully. Although we're not sure why this is not working anymore on all tries using gRPC.\n\nPlease correct me if I'm wrong, but adding a retry config to our queue would not help in our case, as we are not seeing the timeouts when running the task, but before, when queueing them to Cloud Task (so they can run async)? This means the tasks we tried to create using the default gRPC client never made it to Cloud Task.",
      "labels": [
        "type: question",
        "needs more info"
      ],
      "created_at": "2025-05-21T19:01:20Z",
      "closed_at": "2026-01-29T11:17:32Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13938",
      "comments_count": 2
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 14820,
      "title": "google-cloud-secret-manager is missing the module packaging",
      "problem": "### Determine this is the right repository\n\n- [x] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n**Context**\nI installed the package `google-cloud-secret-manager` with `uv` and imported it into my python script\n\n**Expected Behavior:**\nI expected the script to not throw any error\n\n**Actual Behavior:**\nI received the error: `ModuleNotFoundError: No module named 'packaging'`\n\n\n### API client name and version\n\ngoogle-cloud-secret-manager 2.25.0\n\n### Reproduction steps: code\n\nfile: main.py\n```python\nfrom google.cloud.secretmanager import SecretManagerServiceClient\n```\n\n\n### Reproduction steps: supporting files\n\n_No response_\n\n### Reproduction steps: actual results\n\nRun the file with `python main.py` and obtain this error:\n\n```\nTraceback (most recent call last):\n  File \"/Users/luca/dev/fourgreen/fg-workflows/src/secrets.py\", line 1, in <module>\n    from google.cloud.secretmanager import SecretManagerServiceClient\n  File \"/Users/luca/dev/fourgreen/fg-workflows/.venv/lib/python3.13/site-packages/google/cloud/secretmanager/__init__.py\", line 21, in <module>\n    from google.cloud.secretmanager_v1.services.secret_manager_service.async_client import (\n        SecretManagerServiceAsyncClient,\n    )\n  File \"/Users/luca/dev/fourgreen/fg-workflows/.venv/lib/python3.13/site-packages/google/cloud/secretmanager_v1/__init__.py\", line 21, in <module>\n    from .services.secret_manager_service import (\n    ...<2 lines>...\n    )\n  File \"/Users/luca/dev/fourgreen/fg-workflows/.venv/lib/python3.13/site-packages/google/cloud/secretmanager_v1/services/secret_manager_service/__init__.py\", line 16, in <module>\n    from .async_client import SecretManagerServiceAsyncClient\n  File \"/Users/luca/dev/fourgreen/fg-workflows/.venv/lib/python3.13/site-packages/google/cloud/secretmanager_v1/services/secret_manager_service/async_client.py\", line 32, in <module>\n    from google.api_core import exceptions as core_exceptions\n  File \"/Users/luca/dev/fourgreen/fg-workflows/.venv/lib/python3.13/site-packages/google/api_core/__init__.py\", line 20, in <module>\n    from google.api_core import _python_package_support\n  File \"/Users/luca/dev/fourgreen/fg-workflows/.venv/lib/python3.13/site-packages/google/api_core/_python_package_support.py\", line 28, in <module>\n    from packaging.version import parse as parse_version\nModuleNotFoundError: No module named 'packaging'\n```\n\n\n### Reproduction steps: expected results\n\n_No response_\n\n### OS & version + platform\n\nMac M1\n\n### Python environment\n\nPython 3.13.9\n\n### Python dependencies\n\nPackage                     Version\n--------------------------- -----------\nalembic                     1.17.0\nannotated-doc               0.0.3\nannotated-types             0.7.0\nanyio                       4.11.0\napprise                     1.9.5\napscheduler                 3.11.0\nasyncpg                     0.30.0\nauthlib                     1.6.5\nbcrypt                      5.0.0\nbidict                      0.23.1\ncachetools                  6.2.1\ncertifi                     2025.10.5\ncffi                        1.17.1\ncharset-normalizer          3.4.4\nclick                       8.1.8\ncryptography                44.0.2\nfastapi                     0.120.1\ngoogle-api-core             2.28.0\ngoogle-auth                 2.41.1\ngoogle-cloud-secret-manager 2.25.0\ngoogleapis-common-protos    1.71.0\ngrpc-google-iam-v1          0.14.3\ngrpcio                      1.76.0\ngrpcio-status               1.76.0\nh11                         0.14.0\nhttpcore                    1.0.8\nhttpx                       0.28.1\nidna                        3.11\ninvoke                      2.2.1\nitsdangerous                2.2.0\njinja2                      3.1.6\nmako                        1.3.10\nmarkdown                    3.9\nmarkupsafe                  3.0.3\nnumpy                       2.3.4\noauthlib                    3.3.1\npandas                      2.3.3\nparamiko                    4.0.0\nplombery                    0.5.1\nproto-plus                  1.26.1\nprotobuf                    6.33.0\npyasn1                      0.6.1\npyasn1-modules              0.4.2\npycparser                   2.22\npydantic                    2.12.3\npydantic-core               2.41.4\npydantic-settings           2.11.0\npynacl                      1.6.0\npython-dateutil             2.9.0.post0\npython-dotenv               1.2.1\npython-engineio             4.12.3\npython-gnupg                0.5.5\npython-socketio             5.14.2\npytz                        2025.2\npyyaml                      6.0.3\nrequests                    2.32.5\nrequests-oauthlib           2.0.0\nrsa                         4.9.1\nsimple-websocket            1.1.0\nsix                         1.17.0\nsniffio                     1.3.1\nsqlalchemy                  2.0.44\nstarlette                   0.49.0\ntyping-extensions           4.15.0\ntyping-inspection           0.4.2\ntzdata                      2025.2\ntzlocal                     5.3.1\nurllib3                     2.5.0\nuvicorn                     0.38.0\nwsproto                     1.2.0\n\n\n### Additional context\n\n_No response_",
      "solution": "In the end I just run `uv add packaging` and it solved the issue, though it's still issue :) ",
      "labels": [
        "type: bug",
        "triage me"
      ],
      "created_at": "2025-10-28T17:30:37Z",
      "closed_at": "2025-10-28T20:57:40Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/14820",
      "comments_count": 4
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13874,
      "title": "Add Protobuf 6.x Support (`grpcio-status`)",
      "problem": "All packages in this repository already allow Protobuf 6.x, however there is a dependency `grpcio-status`, shown below, in google-api-core which does not yet allow Protobuf 6.x\n\nhttps://github.com/googleapis/python-api-core/blob/66d84a3a9ef0ab0c2124a1bf12cc3c45c2393e74/pyproject.toml#L65-L66\n\nSee log below which shows that `grpcio-status` is downgraded when requesting protobuf 6.x. \n\n```\nroot@01fd584aff5d:/test_pex# pip install grpcio-status \"protobuf>=6\"\nCollecting grpcio-status\n  Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\nCollecting protobuf>=6\n  Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 316.2/316.2 kB 5.7 MB/s eta 0:00:00\nCollecting googleapis-common-protos>=1.5.5\n  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 294.5/294.5 kB 6.4 MB/s eta 0:00:00\nCollecting grpcio-status\n  Downloading grpcio_status-1.70.0-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.69.0-py3-none-any.whl (14 kB)\nCollecting grpcio>=1.69.0\n  Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n     \u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501 5.9/5.9 MB 17.2 MB/s eta 0:00:00\nCollecting grpcio-status\n  Downloading grpcio_status-1.68.1-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.68.0-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.67.1-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.67.0-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.66.2-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.66.1-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.66.0-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.65.5-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.65.4-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.65.2-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.65.1-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.64.3-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.64.1-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.64.0-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.63.2-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.63.0-py3-none-any.whl (14 kB)\n  Downloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\nInstalling collected packages: protobuf, grpcio, googleapis-common-protos, grpcio-status\nSuccessfully installed googleapis-common-protos-1.70.0 grpcio-1.71.0 grpcio-status-1.62.3 protobuf-6.30.2\n```\n\nAlso see failure when using `pex`\n\n```\nroot@01fd584aff5d:/test_pex# pex grpcio-status \"protobuf>=6\"\nFailed to resolve compatible distributions for 1 target:\n1: cp310-cp310-manylinux_2_39_x86_64 interpreter at /venv/bin/python3.10 is not compatible with:\n    grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1 but 1 incompatible dist was resolved:\n        protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl\n```",
      "solution": "Closing as obsolete. This was fixed with https://pypi.org/project/grpcio/1.72.1/\n\n```\nroot@c0f4e967eee2:/# pex grpcio-status \"protobuf>=6\"\nPex 2.40.1 ephemeral hermetic environment with 2 requirements and 4 activated distributions.\nPython 3.10.15 (main, Mar  3 2025, 21:38:59) [GCC 13.3.0] on linux\nType \"help\", \"pex\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> \n```",
      "labels": [
        "type: bug",
        "priority: p2"
      ],
      "created_at": "2025-05-05T14:43:10Z",
      "closed_at": "2025-06-02T15:09:58Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13874",
      "comments_count": 3
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13871,
      "title": "google.cloud.alloydb PEP 420 namespace issue",
      "problem": "### Determine this is the right repository\n\n- [x] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n**Context**\nI am trying to use `google-cloud-alloydb` and [`alloydb-python-connector`](https://github.com/GoogleCloudPlatform/alloydb-python-connector) in the same Python environment.\n\n**Expected Behavior:**\nI expected to be able to import from `google.cloud.alloydb.connector` after installing both packages.\n\n**Actual Behavior:**\nI get a `ModuleNotFoundError` when trying to import `google.cloud.alloydb.connector`, because the `google-cloud-alloydb` package installs a concrete `__init__.py` file in `google/cloud/alloydb/`, which breaks namespace package resolution (PEP 420)\n\n\n### API client name and version\n\ngoogle-cloud-alloydb-connector 1.8.0, google-cloud-alloydb 0.4.5\n\n### Reproduction steps: code\n\nfile: test.py\n```python\nfrom google.cloud.alloydb.connector import Connector\n\nprint(\"Connector loaded successfully\")\n```\n\n### Reproduction steps: supporting files\n\nHere is a self-contained repro shell script that shows the issue with namespace packages:\n\nfile: repro.sh\n```\n#!/bin/bash\nset -euo pipefail\n\nWORKDIR=$(mktemp -d)\necho \"Working directory: $WORKDIR\"\n\n# Create two isolated package install dirs\nPKG_CONNECTOR=\"$WORKDIR/pkg_alloydb_connector\"\nPKG_CLOUD=\"$WORKDIR/pkg_cloud_alloydb\"\n\nmkdir -p \"$PKG_CONNECTOR\" \"$PKG_CLOUD\"\n\npython3 -m venv \"$WORKDIR/venv\"\nsource \"$WORKDIR/venv/bin/activate\"\n\npip3 install --upgrade pip setuptools wheel\n\n# Install each package into a separate directory\npip3 install --target=\"$PKG_CONNECTOR\" google-cloud-alloydb-connector[pg8000]\npip3 install --target=\"$PKG_CLOUD\" google-cloud-alloydb\n\n# Show resulting google.cloud tree\necho\necho \"Installed paths:\"\nfind \"$WORKDIR\" -path '*/google/cloud/*' -type d\n\necho\necho \"Attempting import...\"\nPYTHONPATH=\"$PKG_CLOUD:$PKG_CONNECTOR\" python3 -c \"from google.cloud.alloydb.connector import Connector\" || {\n  echo\n  echo \"\u274c Import failed as expected due to concrete __init__.py blocking namespace package resolution\"\n  exit 1\n}\n```\n\nNote that if you reverse the order of the $PYTHONPATH entries, the import does work.\n\n### Reproduction steps: actual results\n\n```\nTraceback (most recent call last):\n  File \"/tmp/pex-repro/test.py\", line 1, in <module>\n    from google.cloud.alloydb.connector import Connector\nModuleNotFoundError: No module named 'google.cloud.alloydb.connector'\n```\n\n### Reproduction steps: expected results\n\n```\nConnector loaded successfully\n```\n\n### OS & version + platform\n\nUbuntu 22.04 on x86_64\n\n### Python environment\n\nPython 3.11.8\n\n### Python dependencies\n\n_No response_\n\n### Additional context\n\nThis issue only manifests in isolated environments like [PEX](https://github.com/pex-tool/pex) or when manually simulating PEX-style import resolution. The problem arises because `google/cloud/alloydb/__init__.py` is a concrete file (i.e., not empty or omitted), which causes Python to treat `google.cloud.alloydb` as a non-namespace package.\n\nAs a result, `google.cloud.alloydb.connector`, becomes invisible to the import system.\n\n#### Why this matters\n\nThis breaks compatibility for any downstream environment or tool that expects namespace packages to behave per [PEP 420](https://peps.python.org/pep-0420/). In particular, PEX environments fail to import `google.cloud.alloydb.connector`, even when it's installed.\n\n#### Suggested Fix\n\nPlease remove the `google/cloud/alloydb/__init__.py` file entirely from the `google-cloud-alloydb` distribution. This will allow Python to treat the directory as a namespace package, making it compatible with `alloydb-python-connector`.\n",
      "solution": "Hi @jcrobak, Thanks for reporting this issue! There are at least 2 potential solutions:\n\n1. Remove https://github.com/googleapis/google-cloud-python/blob/main/packages/google-cloud-alloydb/google/cloud/alloydb altogether. Existing statements like `import google.cloud.alloydb` will fail.\n2. Change https://github.com/GoogleCloudPlatform/alloydb-python-connector/tree/main/google/cloud/alloydb/connector to https://github.com/GoogleCloudPlatform/alloydb-python-connector/tree/main/google/cloud/alloydb_connector. Import statements would need to change from `import google.cloud.alloydb.connector` to `google.cloud.alloydb_connector`\n\nEither way this will be a breaking change for existing users. Let me reach out to the authors of https://github.com/GoogleCloudPlatform/alloydb-python-connector to confirm next steps.\n\nThere is also a similar issue with this package: https://github.com/googleapis/google-cloud-python/tree/main/packages/google-cloud-alloydb-connectors\n\n---\n\n> Suggested Fix\n> Please remove the google/cloud/alloydb/__init__.py file entirely from the google-cloud-alloydb distribution. This will allow \n> Python to treat the directory as a namespace package, making it compatible with alloydb-python-connector.\n\n@parthea is this suggestion not an option? Both of the suggested solutions in your comment seem like non-starters, given how extensive the breakage would be.\n\nAs for https://github.com/googleapis/google-cloud-python/tree/main/packages/google-cloud-alloydb-connectors, I don't know how this code ended up in google-cloud-python, but it's effectively a private set of protobuf messages that we otherwise generate Python bindings for ourselves. See https://github.com/GoogleCloudPlatform/alloydb-python-connector/tree/main/google/cloud/alloydb_connectors_v1/proto. \n\nElsewhere we had an informal agreement that everything inside https://github.com/googleapis/googleapis/tree/master/google/cloud/alloydb/connectors would be generated for Go, but not any other language. So, separately from the reported issue, we should be able to remove `google-cloud-alloydb-connectors` from this repo.\n\n",
      "labels": [
        "type: bug",
        "priority: p2"
      ],
      "created_at": "2025-05-03T12:22:29Z",
      "closed_at": "2025-05-14T14:52:00Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13871",
      "comments_count": 9
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13740,
      "title": "Using 3rd party libraries to support image uploads",
      "problem": "### Determine this is the right repository\n\n- [x] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n**Context**\nI am currently using [FAL](https://fal.ai/) to upload images since I use their API for stuff too but Google should be able to fetch the images. If I run multiple requests for the face detection API it seems to throw an error every now and then randomly. I get the following error:\n\n```\nerror {\n  code: 14\n  message: \"We can not access the URL currently. Please download the content and pass it in.\"\n}\n```\n\n**Expected Behavior:**\nThe cloud vision API should be able to support this. Not sure if it's a rate-limiting issue or what. I use FAL with other APIs as well and no issues.\n\n\n### API client name and version\n\ngoogle-cloud-vision 3.10.1\n\n### Reproduction steps: code\n\nfile: main.py\n```python\nfrom google.cloud import vision\nimport fal_client\n\nclient = vision.ImageAnnotatorClient()\nimage_url = fal_client.upload_image(\"path_to_image\")\nimage = vision.Image(source=vision.ImageSource(image_uri=image_url))\n\nresponse = client.face_detection(image=image)\nfaces = response.face_annotations\n```\n\n\n### Reproduction steps: supporting files\n\n_No response_\n\n### Reproduction steps: actual results\n\n_No response_\n\n### Reproduction steps: expected results\n\n_No response_\n\n### OS & version + platform\n\n_No response_\n\n### Python environment\n\nPython 3.12.7\n\n### Python dependencies\n\nPackage                   Version\n------------------------- --------------\nfal_client                          0.5.9\ngoogle-cloud-vision       3.10.1\n\n\n### Additional context\n\n_No response_",
      "solution": "@johnathanchiu This behaviour isn't unexpected i.e. Cloud Vision API throttles external fetches to prevent abuse. As per the `imageUri` documentation for [AnnotateImageRequest](https://cloud.google.com/vision/docs/reference/rest/v1/AnnotateImageRequest):\n\n```\nYour request may fail if the specified host denies the request (e.g. due to request throttling or DOS prevention), or if Google throttles requests to the site for abuse prevention. You should not depend on externally-hosted images for production applications.\n```\n\nThis isn't an issue with the Python client but rather the intended behaviour of the Cloud Vision API. If you'd like to submit a feature request, you can file an issue directly with the Cloud Vision API team via their issue tracker listed here: https://cloud.google.com/support/docs/issue-trackers.\n\nWill be marking this as resolved since the Python client works as expected.",
      "labels": [
        "type: bug",
        "triage me"
      ],
      "created_at": "2025-04-08T03:17:01Z",
      "closed_at": "2025-04-22T03:34:37Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13740",
      "comments_count": 1
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13196,
      "title": "Resource Limits Configuration Errors After Upgrading google-cloud-run from v0.10.3 to v0.10.9",
      "problem": "I'm experiencing issues when upgrading the `google-cloud-run` library from version **0.10.3** to **0.10.9** while developing an API using FastAPI. The API is responsible for creating Cloud Run jobs and requires mounting a volume based on a Google Cloud Storage (GCS) bucket. To achieve this, I needed to update the `google-cloud-run` version since version **0.10.3** does not support mounting a GCS bucket as a volume.\r\n\r\nAfter upgrading to version **0.10.9**, I encountered errors related to configuring resource limits for the Cloud Run jobs. Notably, the documentation does not clarify the need to specify CPU in millicpus (`m`) format. All the documentation references suggest passing CPU as simple string values like `\"1\"`, `\"2\"`, `\"4\"`, `\"8\"`, but after running tests, I discovered that the newer version requires the use of millicpu (e.g., `\"1000m\"`, `\"2000m\"`, `\"4000m\"`, `\"8000m\"`). This difference was not mentioned, causing confusion during the upgrade process.\r\n\r\n## Steps to Reproduce\r\n\r\n1. **Initial Setup with `google-cloud-run==0.10.3`:**\r\n   \r\n   - Set resource limits as follows:\r\n     ```\r\n     container.resources.limits = {\"cpu\": \"8\", \"memory\": \"16G\"}\r\n     ```\r\n   - This configuration works without any issues.\r\n\r\n2. **Upgrade to `google-cloud-run==0.10.9`:**\r\n   \r\n   - Upgrade the library to enable mounting a GCS bucket as a volume.\r\n\r\n3. **Update Resource Limits to New Format:**\r\n   \r\n   - Modify the resource limits to adhere to the new version's requirements:\r\n     ```\r\n     container.resources.limits = {\"cpu\": \"8000m\", \"memory\": \"16Gi\"}\r\n     ```\r\n   \r\n   - **Error Encountered:**\r\n     ```\r\n     Invalid value specified for cpu. Total millicpu may not exceed 8000.\r\n     For more troubleshooting guidance, see https://cloud.google.com/run/docs/configuring/cpu\r\n     ```\r\n\r\n4. **Attempt to Reduce CPU Allocation:**\r\n   \r\n   - Adjust CPU to `\"6000m\"` while keeping memory the same:\r\n     ```\r\n     container.resources.limits = {\"cpu\": \"6000m\", \"memory\": \"16Gi\"}\r\n     ```\r\n   \r\n   - **Same Error Occurs:**\r\n     ```\r\n     Invalid value specified for cpu. Total millicpu may not exceed 8000.\r\n     For more troubleshooting guidance, see https://cloud.google.com/run/docs/configuring/cpu\r\n     ```\r\n\r\n5. **Test Minimum CPU and Increased Memory:**\r\n   \r\n   - Set CPU to `\"1000m\"` and memory to `\"4Gi\"`:\r\n     ```\r\n     container.resources.limits = {\"cpu\": \"1000m\", \"memory\": \"4Gi\"}\r\n     ```\r\n   \r\n   - **Error Encountered:**\r\n     ```\r\n     Invalid value specified for container memory. For 1.0 CPU, memory must be between 128Mi and 4Gi inclusive.\r\n     For more troubleshooting guidance, see https://cloud.google.com/run/docs/configuring/memory-limits\r\n     ```\r\n\r\n6. **Attempt Configuration via Cloud Console:**\r\n   \r\n   - Created a job with 8 CPUs and 16Gi RAM using the following YAML:\r\n     ```\r\n     resources:\r\n       limits:\r\n         cpu: 8000m\r\n         memory: 16Gi\r\n     ```\r\n   \r\n   - Replicated the configuration in the API:\r\n     ```python\r\n     container.resources.limits = {\"cpu\": \"8000m\", \"memory\": \"16Gi\"}\r\n     ```\r\n   \r\n   - **Same CPU Error Returned:**\r\n     ```\r\n     Invalid value specified for cpu. Total millicpu may not exceed 8000.\r\n     For more troubleshooting guidance, see https://cloud.google.com/run/docs/configuring/cpu\r\n     ```\r\n\r\n## Expected Behavior\r\n\r\nAfter upgrading to `google-cloud-run==0.10.9`, it should be possible to configure higher CPU and memory limits to support mounting a GCS bucket as a volume without encountering validation errors.\r\n\r\n## Actual Behavior\r\n\r\n- **CPU Configuration Errors:**\r\n  - `\"Invalid value specified for cpu. Total millicpu may not exceed 8000.\"`\r\n  \r\n- **Memory Configuration Errors:**\r\n  - `\"Invalid value specified for container memory. For 1.0 CPU, memory must be between 128Mi and 4Gi inclusive.\"`\r\n\r\nThese errors prevent the successful deployment of Cloud Run jobs with the desired resource allocations.\r\n\r\n## Environment\r\n\r\n- **Library Version:**\r\n  - Working: `google-cloud-run==0.10.3`\r\n  - Problematic: `google-cloud-run==0.10.9`\r\n  \r\n- **Python Version:** `3.11.6`\r\n\r\n- **Framework:** FastAPI\r\n\r\n- **Deployment Method:** Via API and Cloud Console\r\n\r\n## Additional Information\r\n\r\n- **Documentation References:**\r\n  - [Configuring CPU](https://cloud.google.com/run/docs/configuring/cpu)\r\n  - [Configuring Memory Limits](https://cloud.google.com/run/docs/configuring/memory-limits)\r\n ",
      "solution": "Thanks for reporting this issue! Since this is also happening via the Cloud Console, it seems to be an API issue rather than a client library issue. We'll contact the API team to get this resolved ASAP.\n\nBut since it has been a few months since this report was filed, please confirm this problem is still occurring. Thanks!",
      "labels": [
        "type: bug",
        "priority: p2",
        "needs more info"
      ],
      "created_at": "2024-10-23T19:05:25Z",
      "closed_at": "2025-04-15T20:29:53Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13196",
      "comments_count": 2
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13121,
      "title": "SecretManagerServiceAsyncClient.create_secret: Task got Future attached to a different loop",
      "problem": "### Determine this is the right repository\n\n- [X] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n**Context**\r\n\r\nI am trying to use async client for the GCP Secret Manager in my Telegram bot. I want to create, store and access the secret. I am running this bot in GKE autopilot.\r\n\r\n**Expected Behavior:**\r\n\r\nI expect to be able to create the secret asynchronously. \r\n\r\n**Actual Behavior:**\r\n\r\nWhen attempting to call `create_secret`, you get an error. This error only occurs when I use the secret manager together with the `python-telegram-bot` library, but both work on their own. This leads me to believe that one of them is not handling the asyncio loop correctly or making a new loop when it shouldn't be.\r\n\n\n### API client name and version\n\ngoogle-cloud-secret-manager 2.20.2\n\n### Reproduction steps: code\n\nSee here: https://github.com/rdong8/experiments\r\n\r\n\n\n### Reproduction steps: supporting files\n\nPrerequisites:\r\n- GKE autopilot cluster, or another cluster that has enough permissions to access GCP secret manager\r\n- `kubectl` and `helm`, pointing to the cluster\r\n\r\n1. `git clone https://github.com/rdong8/experiments && cd experiments` \r\n2. Create a `.env` file with a Telegram `BOT_TOKEN` and `GCP_PROJECT_ID` - the schema is in the `.env.template` file. You can get a Telegram bot token by messaging [BotFather](https://t.me/BotFather). Do not use quotes around the values.\r\n3. Create a secret using that file: `kubectl create secret generic experiments-secret -n test --create-namespace --from-env-file=.env`\r\n4. Run from the repo root: `helm install -n test --set image.tag=f1eede3 experiments charts/experiments` \r\n5. Get the pod ID: `kubectl get pods -n test`\r\n6. Watch the logs of the bot: `kubectl logs -n test -f pod/<POD ID>`\r\n7. Start a conversation with the bot you created on Telegram\r\n8. Try to set a secret, ie. send the message `/set mysecret`\r\n9. Observe the exception traceback in the logs\n\n### Reproduction steps: actual results\n\n```\r\nNo error handlers are registered, logging exception.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.12/site-packages/telegram/ext/_application.py\", line 1335, in process_update\r\n    await coroutine\r\n  File \"/usr/local/lib/python3.12/site-packages/telegram/ext/_handlers/basehandler.py\", line 158, in handle_update\r\n    return await self.callback(update, context)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/app/experiments/__main__.py\", line 40, in set_secret\r\n    await client.create_secret(secret_id=secret_id, parent=parent, secret=secret)\r\n  File \"/usr/local/lib/python3.12/site-packages/google/cloud/secretmanager_v1/services/secret_manager_service/async_client.py\", line 539, in create_secret\r\n    response = await rpc(\r\n               ^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.12/site-packages/google/api_core/grpc_helpers_async.py\", line 85, in __await__\r\n    response = yield from self._call.__await__()\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/usr/local/lib/python3.12/site-packages/grpc/aio/_call.py\", line 308, in __await__\r\n    response = yield from self._call_response\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nRuntimeError: Task <Task pending name='Application:7717576672:update_fetcher' coro=<Application._update_fetcher() running at /usr/local/lib/python3.12/site-packages/telegram/ext/_application.py:1258>> got Future <Task pending name='Task-19' coro=<UnaryUnaryCall._invoke() running at /usr/local/lib/python3.12/site-packages/grpc/aio/_call.py:577>> attached to a different loop\r\n```\r\n\n\n### Reproduction steps: expected results\n\nNo output (successfully create secret)\n\n### OS & version + platform\n\nGeneral-purpose compute class on GKE autopilot\n\n### Python environment\n\nPython 3.12.6\n\n### Python dependencies\n\n```\r\nPackage                     Version   Editable project location\r\n--------------------------- --------- ------------------------------\r\nanyio                       4.6.0\r\nbuild                       1.2.2\r\ncachetools                  5.5.0\r\ncertifi                     2024.8.30\r\ncffi                        1.17.1\r\ncharset-normalizer          3.3.2\r\ncryptography                43.0.1\r\ndocutils                    0.21.2\r\ngoogle-api-core             2.20.0\r\ngoogle-auth                 2.35.0\r\ngoogle-cloud-secret-manager 2.20.2\r\ngoogleapis-common-protos    1.65.0\r\ngrpc-google-iam-v1          0.13.1\r\ngrpcio                      1.66.2\r\ngrpcio-status               1.66.2\r\nh11                         0.14.0\r\nhttpcore                    1.0.6\r\nhttpx                       0.27.2\r\nidna                        3.10\r\nimportlib_metadata          8.5.0\r\njaraco.classes              3.4.0\r\njaraco.context              6.0.1\r\njaraco.functools            4.1.0\r\njeepney                     0.8.0\r\nkeyring                     25.4.1\r\nmarkdown-it-py              3.0.0\r\nmdurl                       0.1.2\r\nmore-itertools              10.5.0\r\nnh3                         0.2.18\r\npackaging                   24.1\r\npip                         24.2\r\npkginfo                     1.10.0\r\nproto-plus                  1.24.0\r\nprotobuf                    5.28.2\r\npyasn1                      0.6.1\r\npyasn1_modules              0.4.1\r\npycparser                   2.22\r\nPygments                    2.18.0\r\npyproject_hooks             1.2.0\r\npython-telegram-bot         21.6\r\nreadme_renderer             44.0\r\nrequests                    2.32.3\r\nrequests-toolbelt           1.0.0\r\nrfc3986                     2.0.0\r\nrich                        13.9.1\r\nrsa                         4.9\r\nSecretStorage               3.3.3\r\nsniffio                     1.3.1\r\ntwine                       5.1.1\r\nurllib3                     2.2.3\r\nzipp                        3.20.2\r\n```",
      "solution": "Thanks for reporting this issue! Could you confirm this is still happening? If it is, we'll investigate so we can get things fixed.",
      "labels": [
        "type: bug",
        "priority: p2",
        "needs more info"
      ],
      "created_at": "2024-10-03T00:00:37Z",
      "closed_at": "2025-04-15T18:29:32Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13121",
      "comments_count": 2
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13545,
      "title": "Removal of .proto files from googleapis-common-protos broke us",
      "problem": "### Determine this is the right repository\n\n- [x] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n**Context**\nhttps://github.com/googleapis/google-cloud-python/commit/23e0f96829dbc5105428b8c699c49106f99999d2 removed the source .proto files for Google APIs. Since we use these protos in our project to build our own services with gRPC, this broke our build process.\n\n**Expected Behavior:**\nI would have expected the .proto files to have stayed in place or another pip package to be provided that published the source proto files for existing users.\n\n**Actual Behavior:**\n.proto files removed, build broken\n\n\n### API client name and version\n\n_No response_\n\n### Reproduction steps: code\n\nfile: main.py\n```python\n   def reproduce():\n    # complete code here\n```\n\n<any additional py files>\n\n\n### Reproduction steps: supporting files\n\nfile: mydata.csv\n```\nalpha,1,3\nbeta,2,5\n```\n\n<any additional supporting files>\n\n\n### Reproduction steps: actual results\n\nfile: output.txtmydata.csv\n```\nCalculated: foo\n```\n\n\n### Reproduction steps: expected results\n\nfile: output.txtmydata.csv\n```\nCalculated: bar\n```\n\n\n### OS & version + platform\n\n_No response_\n\n### Python environment\n\n_No response_\n\n### Python dependencies\n\n_No response_\n\n### Additional context\n\n_No response_",
      "solution": "> This does require 2 clicks thought.\n\n@parthea I'm not sure this solution works for existing users of the library. A lot of us have been relying on the fact that the core API proto can be installed with pip, in order to use them when they call protoc.\n\nSay I have a code base with `.proto` file that export common proto from google apis (eg timestamp).\n\n```proto\nsyntax = \"proto3\";\n\npackage demo;\n\nimport \"google/type/date.proto\";\nimport \"google/protobuf/timestamp.proto\";\n\nmessage Demo {\n  google.protobuf.Timestamp timestamp = 1;\n  google.type.Date trade_date = 5;\n}\n\n```\n\nWith the previous version of `goobleapis-common-proto` installed \n\n```shell\n pip install \"googleapis-common-protos<=1.67.0\" grpcio-tools\n```\n\nI can simply build my proto from the command line:\n\n```shell\npython -m grpc_tools.protoc \\\n  --proto_path=$(python -c 'import pathlib;import grpc_tools;print(pathlib.Path(grpc_tools.__file__).parent.absolute() / \"_proto\")') \\\n  --proto_path=$(python -c 'import pathlib;import google;print(pathlib.Path(google.__path__[0]).parent)') \\\n  --proto_path=./ \\\n  --python_out=./ \\\n  demo.proto\n```\n\nThis is no longer possible because half of the protos are missing. The suggested solution requires manually getting the proto from github, which isn't suitable for automated CI pipelines.\n",
      "labels": [
        "type: bug",
        "priority: p2"
      ],
      "created_at": "2025-02-21T17:25:07Z",
      "closed_at": "2025-03-06T15:01:10Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13545",
      "comments_count": 10
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13512,
      "title": "ga4 api python lib gets values which are different from ga4 daashboard",
      "problem": "Hello friends,\n\nI recently encountered an issue with the 'averagePurchaseRevenuePerPayingUser' /  'totalPurchasers' API.\n\nfollowing this lib (run_report) : \nhttps://googleapis.dev/python/analyticsdata/latest/CHANGELOG.html\n\nIt's returning an error value that differs from what I see in the Google Analytics console.\n\nI surveyed a lot and test if it is annoyed be turning on Google Signal. Somehow even the property turns it off, still getting the same results\nhttps://stackoverflow.com/questions/76006877/data-retrieved-by-google-analytics-4-data-api-doesnt-match-that-from-web-interf\n\nIt's vey stable for the past 2 years\nSomehow just get this issue since last month.\nHave you experienced similar problems?\n\nMany Thanks",
      "solution": "As this question is specific to the analytics API, rather than the client library, please use the [help links](https://developers.google.com/analytics/support) for the API to obtain support, You can also create a new thread in the API specific support community: https://support.google.com/analytics/community, or .\n\nI'm going to close this issue as the problem is specific to the API rather than the client library. https://developers.google.com/analytics/support is the best place to get API specific support.",
      "labels": [
        "type: question",
        "priority: p2",
        "needs more info"
      ],
      "created_at": "2025-02-11T02:12:38Z",
      "closed_at": "2025-03-02T16:11:21Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13512",
      "comments_count": 2
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13529,
      "title": "Unable to list Artifact Registries accross all regions",
      "problem": "### Determine this is the right repository\n\n- [x] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n**Context**\nI am trying to list all registries available in a project, using this:\n\n```\nfrom google.cloud.artifactregistry import ArtifactRegistryClient, ListRepositoriesRequest\n\nArtifactRegistryClient().list_repositories(ListRepositoriesRequest(parent=\"projects/<my_project>/locations/*\")))\n```\n\n**Expected Behavior:**\nI expect to receive a list of all repositories, whatever their region.\n\n**Actual Behavior:**\nI get a 400 error: google.api_core.exceptions.InvalidArgument: 400 Invalid project name: \"projects/<my_project>/locations/*\"\n\nListing repositories for a single existing region works as expected.\n\nIt is possible to do this using [the CLI](https://cloud.google.com/artifact-registry/docs/repositories/list-repos#gcloud), and the documentation of [the API](https://cloud.google.com/artifact-registry/docs/reference/rest/v1/projects.locations.repositories/list?rep_location=global) suggests that it should be possible, however it doesn't work in the tester either.\n\nThis seems like an API-side issue.\n\n\n### API client name and version\n\ngoogle-cloud-artifact-registry 1.15.0\n\n### Reproduction steps: code\n\nfile: main.py\n```python\nfrom google.cloud.artifactregistry import ArtifactRegistryClient, ListRepositoriesRequest\n\nArtifactRegistryClient().list_repositories(ListRepositoriesRequest(parent=\"projects/<my_project>/locations/*\")))\n```\n\n### Reproduction steps: supporting files\n\n_No response_\n\n### Reproduction steps: actual results\n\nfile: output.txt\n```\n google.api_core.exceptions.InvalidArgument: 400 Invalid project name: \"projects/<my_project>/locations/*\"\n```\n\n\n### Reproduction steps: expected results\n\nfile: output.txt\n```\n[name: \"projects/<my_project>/locations/europe/repositories/core\"\nformat_: DOCKER\ncreate_time {\n  seconds: 123456789\n  nanos: 123456789\n}\nupdate_time {\n  seconds: 123456789\n  nanos: 123456789\n}\nmode: STANDARD_REPOSITORY\nsize_bytes: 123456789\ndocker_config {\n}\ncleanup_policy_dry_run: true\nvulnerability_scanning_config {\n  enablement_config: DISABLED\n  enablement_state: SCANNING_DISABLED\n  enablement_state_reason: \"API containerscanning.googleapis.com is not enabled.\"\n}]\n```\n\n\n### OS & version + platform\n\nMac OS\n\n### Python environment\n\nPython 3.12\n\n### Python dependencies\n\ngoogle-api-core                2.19.1\ngoogle-auth                    2.34.0\ngoogle-cloud-artifact-registry 1.15.0\ngoogle-cloud-core              2.4.1\ngoogle-cloud-resource-manager  1.14.0\ngoogleapis-common-protos       1.63.2\n\n\n### Additional context\n\n_No response_",
      "solution": "Thanks for reporting this! We will investigate and get back to you. If this is really a an API-side issue, then this is best reported to the API team rather than here.\n\nOne question: when you say it doesn't work in the tester, do you mean it doesn't work in the \"Try this method\" sidebar on [the API reference page](https://cloud.google.com/artifact-registry/docs/reference/rest/v1/projects.locations.repositories/list?rep_location=global)?\n\n---\n\nRegrettably, it is not possible to list all repositories in all regions with a single request. There is an [open feature request](https://issuetracker.google.com/issues/309226678) in the [public issue tracker](https://issuetracker.google.com/savedsearches/559742) for the Artifact Registry API. Please feel free to add a comment in https://issuetracker.google.com/issues/309226678 or add a '+1' on the issue to express interest.\n\nI also checked `gcloud` documentation here: https://cloud.google.com/artifact-registry/docs/repositories/list-repos#view\n\nThey have a request `gcloud artifacts repositories list --project=<project>` that lists all repositories across all regions however when I add the `---log-http` option , I can see that there are actually several requests going out to retrieve the repositories in each region,\n\nSee `gcloud artifacts repositories list --project=<project> ---log-http`\n\nI'm going to close this issue as there is already an open feature request in the API specific issue tracker but please feel free to open a new issue if you have additional questions.",
      "labels": [
        "type: question",
        "priority: p2"
      ],
      "created_at": "2025-02-14T20:24:03Z",
      "closed_at": "2025-03-02T15:59:50Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13529",
      "comments_count": 3
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13531,
      "title": "503 DNS resolution using Discovery Engine endpoint in EU region",
      "problem": "### Determine this is the right repository\n\n- [x] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n**Context**\nI was trying to deploy a Cloud Function which target a Search app based on an existing datastore created in Agent Builder, using the following code and requirements.txt.\n\n**Expected Behavior:**\nA response from the Search app with data suggestions.\n\n**Actual Behavior:**\nGot this error:\n\n```\ngoogle.api_core.exceptions.ServiceUnavailable: 503 DNS resolution failed for https://eu-discoveryengine.googleapis.com: C-ares status is not ARES_SUCCESS qtype=SRV name=_grpclb._tcp.https: Domain name not found\n```\n\nIf I set the `client_options` variable to ``None`, the endpoint is expected to be in a `global` location while I need it to be all in EU.\n\n### API client name and version\n\ngoogle-cloud-discoveryengine 0.13.6\n\n### Reproduction steps: code\n\nfile: main.py\n```python\nimport functions_framework\nimport json\nimport os\nfrom google.cloud import discoveryengine_v1\nfrom google.protobuf.json_format import MessageToDict\nfrom typing import Optional, List, Dict\n\nPROJECT_ID = \"MY PROJECT\"\nDATASTORE_ID = \"MY DATASTORE ID\"\nDATASTORE_LOCATION = \"eu\"\n\n\n@functions_framework.http\ndef retrieve(request):\n    \"\"\"HTTP Cloud Function.\n    Args:\n        request (flask.Request): The request object.\n        <https://flask.palletsprojects.com/en/1.1.x/api/#incoming-request-data>\n        page_size (int): optional number of page size to retrieve\n    Returns:\n        The response text, or any set of values that can be turned into a\n        Response object using `make_response`\n        <https://flask.palletsprojects.com/en/1.1.x/api/#flask.make_response>.\n    \"\"\"\n    request_json = request.get_json(silent=True)\n\n    if request_json and \"search_query\" in request_json:\n        search_results = get_search_results(request_json[\"search_query\"])\n        return format_search_results(search_results)\n    return \"\"\n\ndef format_search_results(\n    response_pager: discoveryengine_v1.SearchResponse,\n) -> List[Dict]:\n    response_pager_dict = MessageToDict(response_pager._pb)\n    return (\n        \"{response:\"\n        + json.dumps(\n            [\n                result[\"document\"][\"structData\"]\n                for result in response_pager_dict[\"results\"]\n            ]\n        )\n        + \"}\"\n    )\n\ndef get_search_results(\n    search_query: str, page_size: Optional[int] = 3\n) -> discoveryengine_v1.SearchResponse:\n    \"\"\"Performs a search query in Discovery Engine and returns the results.\n\n    Args:\n        search_query: The search query text.\n        page_size: (Optional) The max number of search results to return per page. Defaults to 3.\n\n    Returns:\n        A SearchResponse object containing the search results.\n    \"\"\"\n\n    # Create the Discovery Engine client\n    client_options = {\n        \"api_endpoint\": \"https://eu-discoveryengine.googleapis.com\"\n    }\n    client = discoveryengine_v1.SearchServiceClient(client_options=client_options)\n\n    # Construct the full resource name of the serving config\n    serving_config = client.serving_config_path(\n        project=PROJECT_ID,\n        location=DATASTORE_LOCATION,\n        data_store=DATASTORE_ID,\n        serving_config=\"default_config\",\n    )\n\n    # Build the search request\n    request = discoveryengine_v1.SearchRequest(\n        serving_config=serving_config, query=search_query, page_size=page_size\n    )\n\n    # Perform the search and return the response\n    return client.search(request)\n```\n\n\nThe query :\n```\n{\n  \"search_query\": \"shoes order\"\n}\n```\n\n\n### Reproduction steps: supporting files\n\n_No response_\n\n### Reproduction steps: actual results\n\n\n```\n[1:28:07 PM] - [2025-02-15 12:28:07,237] ERROR in app: Exception on / [POST]\nTraceback (most recent call last):\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\", line 76, in error_remapped_callable\n    return callable_(*args, **kwargs)\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/grpc/_interceptor.py\", line 277, in __call__\n    response, ignored_call = self._with_call(\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/grpc/_interceptor.py\", line 332, in _with_call\n    return call.result(), call\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/grpc/_channel.py\", line 440, in result\n    raise self\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/grpc/_interceptor.py\", line 315, in continuation\n    response, call = self._thunk(new_method).with_call(\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/grpc/_channel.py\", line 1198, in with_call\n    return _end_unary_response_blocking(state, call, True, None)\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/grpc/_channel.py\", line 1006, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)  # pytype: disable=not-instantiable\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n        status = StatusCode.UNAVAILABLE\n        details = \"DNS resolution failed for https://eu-discoveryengine.googleapis.com: C-ares status is not ARES_SUCCESS qtype=SRV name=_grpclb._tcp.https: Domain name not found\"\n        debug_error_string = \"UNKNOWN:Error received from peer  {created_time:\"2025-02-15T12:28:07.236177796+00:00\", grpc_status:14, grpc_message:\"DNS resolution failed for https://eu-discoveryengine.googleapis.com: C-ares status is not ARES_SUCCESS qtype=SRV name=_grpclb._tcp.https: Domain name not found\"}\"\n>\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/flask/app.py\", line 1511, in wsgi_app\n    response = self.full_dispatch_request()\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/flask/app.py\", line 919, in full_dispatch_request\n    rv = self.handle_user_exception(e)\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/flask/app.py\", line 917, in full_dispatch_request\n    rv = self.dispatch_request()\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/flask/app.py\", line 902, in dispatch_request\n    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/functions_framework/__init__.py\", line 134, in view_func\n    return function(request._get_current_object())\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/functions_framework/__init__.py\", line 114, in wrapper\n    return func(*args, **kwargs)\n  File \"/workspace/main.py\", line 28, in retrieve\n    search_results = get_search_results(request_json[\"search_query\"])\n  File \"/workspace/main.py\", line 82, in get_search_results\n    return client.search(request)\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/google/cloud/discoveryengine_v1/services/search_service/client.py\", line 921, in search\n    response = rpc(\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py\", line 131, in __call__\n    return wrapped_func(*args, **kwargs)\n  File \"/layers/google.python.pip/pip/lib/python3.10/site-packages/google/api_core/grpc_helpers.py\", line 78, in error_remapped_callable\n    raise exceptions.from_grpc_error(exc) from exc\ngoogle.api_core.exceptions.ServiceUnavailable: 503 DNS resolution failed for https://eu-discoveryengine.googleapis.com: C-ares status is not ARES_SUCCESS qtype=SRV name=_grpclb._tcp.https: Domain name not found\n```\n\n### Reproduction steps: expected results\n\n{response: [....]}\n\n\n### OS & version + platform\n\nCloud Function\n\n### Python environment\n\nPython 3.10\n\n### Python dependencies\n\nfile: requirements.txt\n```\nfunctions-framework==3.5.0  # Framework for running functions locally\ngoogle-cloud-discoveryengine==0.13.6  # Client library for Discovery Engine API\nprotobuf==4.25.3  # Required for MessageToDict\n```\n\n### Additional context\n\nIf I set the `client_options` variable to ``None`, the endpoint is expected to be in a `global` location while I need it to be all in EU.",
      "solution": "I was able to re-create the issue. The problem was solved by changing\n\n```\n    client_options = {\n        \"api_endpoint\": \"https://eu-discoveryengine.googleapis.com\"\n    }\n```\n\nto\n\n\n```\n    client_options = {\n        \"api_endpoint\": \"eu-discoveryengine.googleapis.com\"\n    }\n```\n\nAs per the documentation for [google.api_core.client_options.ClientOptions](https://googleapis.dev/python/google-api-core/latest/client_options.html), the format for `api_endpoint` should be \"<host>.googleapis.com\".\n\nI'm going to close this issue as I was able to re-create the problem, and resolve it locally, but please feel free to open a new issue if you're still seeing the same problem after applying the suggested fix.",
      "labels": [
        "type: question"
      ],
      "created_at": "2025-02-15T12:55:27Z",
      "closed_at": "2025-03-02T15:50:08Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13531",
      "comments_count": 2
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13542,
      "title": "cloud.speech_v2 list_operations always returns []",
      "problem": "### Determine this is the right repository\n\n- [x] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n**Context**\n client.list_operations(req) always returns empty set e.g. \n\n\n**Expected Behavior:**\nlist of operations to match the rest API call\n\n**Actual Behavior:**\nalways returns empty set ()\n\n\n### API client name and version\n\ngoogle-cloud-speech==2.31.0\n\n### Reproduction steps: code\n\nfile: main.py\n```python\nimport os\n\nimport re\nimport argparse\nimport sys\n\nfrom google.cloud import storage\nfrom google.cloud.speech_v2 import SpeechClient\nfrom google.cloud.speech_v2.types import cloud_speech\nfrom google.longrunning import operations_pb2  # type: ignore\nfrom pprint import pprint\n\nPROJECT_ID = os.getenv(\"GOOGLE_CLOUD_PROJECT\")\n\nclient = SpeechClient()\n    req = operations_pb2.ListOperationsRequest(name=f\"projects/{PROJECT_ID}\")\n    ops = client.list_operations(request=req)\n    for operation in ops.operations:\n        print(f\"Operation Name: {operation.name}\")\n        print(f\"Operation Done: {operation.done}\")\n\nif __name__ == \"__main__\":\n    list_operations()\n```\n\n\n\n### Reproduction steps: supporting files\n\n_No response_\n\n### Reproduction steps: actual results\n\n\n```\n()\n```\n\n\n### Reproduction steps: expected results\n\nresults should be similar to this\n```\ncurl   -H \"Authorization: Bearer $(gcloud auth print-access-token)\"   \"https://speech.googleapis.com/v2/projects/${PROJECT_ID}/locations/global/operations?pageSize=100\" | jq . |head\n{\n  \"operations\": [\n    {\n      \"name\": \"xxxxxv2-682b55ae-0000-275b-9b44-xxxxx\",\n      \"metadata\": {\n        \"@type\": \"type.googleapis.com/google.cloud.speech.v2.OperationMetadata\",\n        \"createTime\": \"2025-02-20T00:56:13.403958Z\",\n        \"updateTime\": \"2025-02-20T00:56:13.895357Z\",\n        \"resource\": \"projects/ccrp-2024/locations/global/recognizers/_\",\n        \"method\": \"google.cloud.speech.v2.Speech.BatchRecognize\",\n```\n\n\n### OS & version + platform\n\n_No response_\n\n### Python environment\n\n_No response_\n\n### Python dependencies\n\n```\ncachetools==5.5.1\ncertifi==2025.1.31\ncharset-normalizer==3.4.1\ngoogle-api-core==2.24.1\ngoogle-auth==2.38.0\ngoogle-cloud-core==2.4.1\ngoogle-cloud-speech==2.31.0\ngoogle-cloud-storage==3.0.0\ngoogle-crc32c==1.6.0\ngoogle-resumable-media==2.7.2\ngoogleapis-common-protos==1.67.0\ngrpcio==1.70.0\ngrpcio-status==1.70.0\nidna==3.10\nproto-plus==1.26.0\nprotobuf==5.29.3\npyasn1==0.6.1\npyasn1_modules==0.4.1\nrequests==2.32.3\nrsa==4.9\nurllib3==2.3.0\n\n```\n\n### Additional context\n\n_No response_",
      "solution": "@vchudnov-g i confirmed the issue is specific to the grpc ListOperations API . which repo would be a good place to report the issue? i can reproduce with python & golang speech SDK.  ListOPerations works on `us-central1` but does not work on global `speech.googleapis.com`\n\n#### with grpc:\n\n```\nlistOperations\n[empty set]\n```\n\n#### with REST client (no other code change)\n\ntested with golang SDK /v2 API + curl \n```\ncurl -m 10    -H \"Authorization: Bearer $(gcloud auth print-access-token)\"   \"https://speech.googleapis.com/v2/projects/xxxxxx/locations/global/operations?pageSize=100\" |jq \n```\n\n```\nlistOperations\noperation: projects/yyyyxxxxx/locations/global/operations/v2-68b170d4-0000-296a-815e-14223bca9472\noperation: projects/yyyyxxxxx/locations/global/operations/v2-68be068e-0000-2be2-842e-14223bc9f72a\noperation: projects/yyyyxxxxx/locations/global/operations/v2-68be074f-0000-2f16-a19f-582429b2bb24\noperation: projects/yyyyxxxxx/locations/global/operations/v2-68c20be5-0000-2be2-842e-14223bc9f72a\n...\n```",
      "labels": [
        "type: bug",
        "priority: p2"
      ],
      "created_at": "2025-02-20T01:30:05Z",
      "closed_at": "2025-02-21T22:32:54Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13542",
      "comments_count": 3
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 12423,
      "title": "The code freezes without receiving a response or error when creating a Google Cloud Vision API client (vision.ImageAnnotatorClient)",
      "problem": "I have an aplication with horizontally scaled machines. And when all the machines start working together the client creation with client = vision.ImageAnnotatorClient(credentials=credentials) gets freeze.\r\n\r\nI try the following solutions:\r\n\r\nI have changed the credentials just in case,\r\nI have checked the maximum request quotas and we are not even close to the maximum. \r\nThe internet connection of the machine is correct since the rest of the download and API services work correctly.\r\n\r\nBut it keeps blocking without receiving any response when the following line of code is executed: client = vision.ImageAnnotatorClient(credentials=credentials). This had not happened before.\r\n\r\nIf anyone has had the same problem, please let me know a solution.\r\n\r\nthanks\r\n\r\npip freeze:\r\n```\r\nanyio==4.3.0\r\nblis==0.7.11\r\nboto3==1.34.16\r\nbotocore==1.34.56\r\ncachetools==5.3.3\r\ncatalogue==2.0.10\r\ncertifi==2024.2.2\r\ncharset-normalizer==3.3.2\r\nclick==8.1.7\r\nconfection==0.1.4\r\ncymem==2.0.8\r\ndeepmerge==1.1.1\r\ndistro==1.9.0\r\ndocopt==0.6.2\r\nexceptiongroup==1.2.0\r\nfilelock==3.13.1\r\nfiletype==1.0.7\r\nfsspec==2024.2.0\r\ngoogle-api-core==2.17.1\r\ngoogle-auth==2.28.1\r\ngoogle-cloud-vision==3.7.2\r\ngoogleapis-common-protos==1.62.0\r\ngrpcio==1.62.0\r\ngrpcio-status==1.62.0\r\nh11==0.14.0\r\nhttpcore==1.0.4\r\nhttpx==0.27.0\r\nhuggingface-hub==0.21.3\r\nidna==3.6\r\nJinja2==3.1.3\r\njmespath==1.0.1\r\nlangcodes==3.3.0\r\nLevenshtein==0.23.0\r\nMarkupSafe==2.1.5\r\nmurmurhash==1.0.10\r\nnum2words==0.5.10\r\nnumpy==1.19.5\r\nopenai==1.10.0\r\nopencv-python==4.5.5.64\r\npackaging==23.2\r\npandas==1.1.5\r\npathlib_abc==0.1.1\r\npathy==0.11.0\r\npconf==1.7.2\r\npdf2image==1.16.3\r\npillow==10.2.0\r\npreshed==3.0.9\r\nproto-plus==1.23.0\r\nprotobuf==4.25.3\r\npsycopg2==2.8.6\r\npyasn1==0.5.1\r\npyasn1-modules==0.3.0\r\npydantic==1.10.14\r\nPyMuPDF==1.18.0\r\npython-dateutil==2.9.0.post0\r\npytz==2023.3.post1\r\nPyYAML==6.0.1\r\npyzbar==0.1.9\r\nrapidfuzz==3.6.2\r\nregex==2023.12.25\r\nrequests==2.31.0\r\nrsa==4.9\r\ns3transfer==0.10.0\r\nsafetensors==0.4.2\r\nscipy==1.10.1\r\nsix==1.16.0\r\nsmart-open==6.4.0\r\nsniffio==1.3.1\r\nspacy==3.6.0\r\nspacy-alignments==0.9.1\r\nspacy-legacy==3.0.12\r\nspacy-loggers==1.0.5\r\nspacy-transformers==1.2.5\r\nsqsworkers==1.2\r\nsrsly==2.4.8\r\nthinc==8.1.12\r\ntiktoken==0.6.0\r\ntokenizers==0.13.3\r\ntorch==1.9.1+cpu\r\ntorchvision==0.10.1+cpu\r\ntqdm==4.64.0\r\ntransformers==4.30.2\r\ntyper==0.9.0\r\ntyping_extensions==4.10.0\r\nurllib3==1.26.18\r\nwasabi==1.1.2\r\n```",
      "solution": "@jorgerodriguezsj , \r\n\r\nPlease can you share more information about your environment? Are you running in GCE or GKE ? I found related issues opened in `google-auth` where the Metadata server, which is needed for credentials, may not be ready. Although `vision.ImageAnnotatorClient(credentials=credentials) ` appears to be frozen, I wonder if it's just that the Metadata server is not ready and there are too many requests going out during that time. \r\n\r\nhttps://github.com/googleapis/google-cloud-python/issues/15193\r\nhttps://github.com/googleapis/google-cloud-python/issues/15214\r\n\r\nOne workaround is to create a global credentials object as suggested in this bug to reduce the load on metadata server. \r\nhttps://github.com/googleapis/google-cloud-python/issues/15214#issuecomment-1083744735\r\n\r\nPlease let us know if the workaround solves the issue and whether you are using GCE or GKE.\n\n---\n\nPlease can you try the workaround in https://github.com/googleapis/google-cloud-python/issues/15214#issuecomment-1083744735 and let us know if it helps?\n\n---\n\nI found a similar error report where https://github.com/googleapis/python-vision/issues/523#issue-1611941857 mentions that the issue doesn't occur with REST transport. Can you please try `client = vision.ImageAnnotatorClient(credentials=credentials, transport=\"rest\")` instead of `client = vision.ImageAnnotatorClient(credentials=credentials)` to check if the issue is specific to gRPC? This will help to narrow down the issue and troubleshooting steps.\r\n\r\nSeparately, related to gRPC, https://github.com/googleapis/python-vision/issues/523#issuecomment-1763167922 also mentions that changing the version of dependencies solved the issue for one user. I'm wondering if you get different behaviour with different versions of `grpcio`. If the issue is gRPC specific and occurs in the latest version of `grcpio`, we can file a bug for the gRPC library.",
      "labels": [
        "type: bug",
        "priority: p2",
        "external"
      ],
      "created_at": "2024-03-07T09:23:37Z",
      "closed_at": "2025-02-18T19:35:28Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/12423",
      "comments_count": 8
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 12142,
      "title": "InvalidArgument: 400 Unsupported input file format.",
      "problem": "Hi Team,\r\n\r\nI am trying to extract text using Document AI from a pdf file stored in Google cloud storage bucket. \r\n\r\nI am able to extract text when I process pdf on google console. However, when I am running below python code, I am getting error as 'InvalidArgument: 400 Unsupported input file format'\r\n\r\n**Code below:**\r\n```\r\nfrom google.api_core.client_options import ClientOptions\r\nfrom google.cloud import documentai  # type: ignore\r\nfrom google.cloud import documentai_v1 as documentai\r\nfrom google.cloud import storage\r\n\r\n\r\ndef quickstart(\r\n    project_id: str,\r\n    location: str,\r\n    gcs_output_uri: str,\r\n    processor_display_name: str = \"My Processor\",\r\n):\r\n    \r\n    # Create a processor client\r\n    client = documentai.DocumentProcessorServiceClient()\r\n       \r\n    parent = client.common_location_path(project_id, location)\r\n\r\n    # Create a Processor\r\n    processor = client.create_processor(\r\n        parent=parent,\r\n        processor=documentai.Processor(\r\n            type_=\"OCR_PROCESSOR\",  # Refer to https://cloud.google.com/document-ai/docs/create-processor for how to get available processor types\r\n            display_name=processor_display_name,\r\n        ),\r\n    )\r\n    \r\n    # Print the processor information\r\n    print(f\"Processor Name: {processor.name}\")\r\n\r\n\r\n    # Load binary data\r\n    raw_document = documentai.types.RawDocument(\r\n        content=gcs_output_uri,\r\n        mime_type=\"application/pdf\",  \r\n    )\r\n\r\n    # Configure the process request\r\n    request = documentai.types.ProcessRequest(name=processor.name, raw_document=raw_document)\r\n\r\n    result = client.process_document(request=request)\r\n\r\n    document = result.document\r\n\r\n    # Read the text recognition output from the processor\r\n    print(\"The document contains the following text:\")\r\n    print(document.text)\r\n\r\n\r\n# **Calling the function:**\r\n# GCS URI of the document\r\ngcs_output_uri='gs://pdf_parser_rj/PDF/Winnie_the_Pooh_3_Pages.pdf'\r\n\r\n# Calling function. I replaced below with actual project_id\r\ndata=quickstart('project_id','us',gcs_output_uri,\"process_test\")\r\nprint(data)\r\n```\r\n\r\n**Error:**\r\n![image](https://github.com/googleapis/google-cloud-python/assets/113460610/cd47ed8b-0026-4f72-a1fb-016938dbe786)\r\n![image](https://github.com/googleapis/google-cloud-python/assets/113460610/89a8eea3-016c-4372-ad72-9adaf9aca449)\r\n\r\nCan you please advise how I can resolve this issue?\r\n\r\nThank you\r\nReema Jain",
      "solution": "I'm going to close this issue as stale but please feel free to open a new issue if anyone is still looking for a solution",
      "labels": [
        "type: question",
        "api: documentai"
      ],
      "created_at": "2023-12-29T08:58:05Z",
      "closed_at": "2025-01-27T17:03:00Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/12142",
      "comments_count": 4
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13186,
      "title": "Update public documentation links to include the PyPI package in the url",
      "problem": "It would be helpful if we include the PyPI package name in the url for the public documentation to make it easier to quickly navigate to the documentation for a specific package.\r\n\r\nFor example, for `google-cloud-backupdr`, the documentation exists [here](https://cloud.google.com/python/docs/reference/backupdr/latest/summary_overview) instead of [here](https://cloud.google.com/python/docs/reference/google-cloud-backupdr/latest/summary_overview).\r\nhttps://github.com/googleapis/google-cloud-python/tree/main/packages/google-cloud-backupdr\r\n\r\nIOW, we should have `google-cloud-backupdr` in the url\r\n```\r\nhttps://cloud.google.com/python/docs/reference/google-cloud-backupdr/latest/summary_overview\r\n```\r\ninstead of\r\n```\r\nhttps://cloud.google.com/python/docs/reference/backupdr/latest/summary_overview\r\n```\r\n\r\nSimilarly, for `google-cloud-quotas`, it should be\r\n```\r\nhttps://cloud.google.com/python/docs/reference/google-cloud-quotas/latest/summary_overview\r\n```\r\ninstead of\r\n```\r\nhttps://cloud.google.com/python/docs/reference/google-cloud-cloudquotas/latest/summary_overview\r\n```\r\n\r\nAs part of this bug, we should audit all packages, and make sure it is easy to navigate to the docs by url with only the package name.",
      "solution": "As part of the solution, we should ensure that both the old and the new urls work so that there are no broken links.\r\neg.\r\nBoth https://cloud.google.com/python/docs/reference/google-cloud-quotas/latest/summary_overview and https://cloud.google.com/python/docs/reference/google-cloud-cloudquotas/latest/summary_overview work",
      "labels": [
        "type: cleanup"
      ],
      "created_at": "2024-10-21T17:56:05Z",
      "closed_at": "2025-01-27T17:01:02Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13186",
      "comments_count": 2
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13013,
      "title": "fix and reenable CodeQL",
      "problem": "CodeQL was consistently running out of disk space, which was causing errors and blocking PRs, so I disabled it.\r\n\r\nWe need to fix the underlying issue (possibly by configuring larger runners at the org level; see https://docs.github.com/en/code-security/code-scanning/troubleshooting-code-scanning/out-of-disk-or-memory) and re-enable CodeQL since it provides security checks.",
      "solution": "Googlers: b/360135010 to track a possible org-wide solution, which would unblock reenabling CodeQL in this repo.",
      "labels": [
        "priority: p2",
        "type: process"
      ],
      "created_at": "2024-08-15T16:59:30Z",
      "closed_at": "2025-01-27T16:47:01Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13013",
      "comments_count": 2
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13070,
      "title": "Broken listing zones in `google-cloud-compute` with protobuf=5.28.0",
      "problem": "### Determine this is the right repository\r\n\r\n- [X] I determined this is the correct repository in which to report this bug.\r\n\r\n### Summary of the issue\r\n\r\n**Context**\r\nI tried to list zones in a project using `google-cloud-compute` SDK and it's broken with the protobuf=5.28.0.\r\nI have replicated this behavior with clean python environment.\r\n\r\n**Expected Behavior:**\r\nThe code from https://cloud.google.com/python/docs/reference/compute/latest/google.cloud.compute_v1.services.zones.ZonesClient#google_cloud_compute_v1_services_zones_ZonesClient_list works.\r\n\r\n**Actual Behavior:**\r\n```shell\r\n(gcp_bug) PS C:\\Projects\\aiops-library\\mlops\\experiments\\google-cloud-compute-bug> python get_zones.py\r\nTraceback (most recent call last):\r\n  File \"C:\\Projects\\aiops-library\\mlops\\experiments\\google-cloud-compute-bug\\get_zones.py\", line 18, in <module>\r\n    page_result = client.list(request=request)\r\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\E10270\\.conda\\envs\\gcp_bug\\Lib\\site-packages\\google\\cloud\\compute_v1\\services\\zones\\client.py\", line 867, in list\r\n    response = rpc(\r\n               ^^^^\r\n  File \"C:\\Users\\E10270\\.conda\\envs\\gcp_bug\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py\", line 131, in __call__\r\n    return wrapped_func(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\E10270\\.conda\\envs\\gcp_bug\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py\", line 76, in error_remapped_callable\r\n    return callable_(*args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"C:\\Users\\E10270\\.conda\\envs\\gcp_bug\\Lib\\site-packages\\google\\cloud\\compute_v1\\services\\zones\\transports\\rest.py\", line 394, in __call__\r\n    raise core_exceptions.from_http_response(response)\r\ngoogle.api_core.exceptions.BadRequest: 400 GET https://compute.googleapis.com/compute/v1/projects/xxx/zones?project=: Invalid resource field value in the request.\r\n```\r\nIt all works with `protobuf==5.27.4`.\r\nSo there must be something broken in https://github.com/protocolbuffers/protobuf/releases/tag/v28.0\r\n\r\n### API client name and version\r\n\r\ngoogle-cloud-compute==1.19.2\r\n\r\n### Reproduction steps: code\r\n\r\nfile: get_zones.py\r\n```python\r\nfrom google.cloud import compute_v1\r\n\r\n# Create a client\r\nclient = compute_v1.ZonesClient()\r\n\r\n# Initialize request argument(s)\r\nrequest = compute_v1.ListZonesRequest(\r\n    project=\"xxx\",\r\n)\r\n\r\n# Make the request\r\npage_result = client.list(request=request)\r\nprint(page_result)\r\n```\r\n\r\n\r\n\r\n### Reproduction steps: supporting files\r\n\r\nno files needed\r\n\r\n### Reproduction steps: actual results\r\n\r\nsee the stack trace above\r\n\r\n### Reproduction steps: expected results\r\n\r\nit prints the zones\r\n\r\n### OS & version + platform\r\n\r\nWindows 10\r\n\r\n### Python environment\r\n\r\npython 3.11.9\r\n\r\n### Python dependencies\r\n\r\n```shell\r\n(gcp_bug) PS C:\\Projects\\aiops-library\\mlops\\experiments\\google-cloud-compute-bug> pip freeze                                                \r\ncachetools==5.5.0\r\ncertifi==2024.8.30\r\ncharset-normalizer==3.3.2\r\ngoogle-api-core==2.19.2\r\ngoogle-auth==2.34.0\r\ngoogle-cloud-compute==1.19.2\r\ngoogleapis-common-protos==1.65.0\r\ngrpcio==1.66.1\r\ngrpcio-status==1.62.3\r\nidna==3.8\r\nproto-plus==1.24.0\r\nprotobuf==4.25.4\r\npyasn1==0.6.0\r\npyasn1_modules==0.4.0\r\nrequests==2.32.3\r\nrsa==4.9\r\nurllib3==2.2.2\r\n```",
      "solution": "Hi @racinmat,\r\n\r\nThanks for reporting this issue. The issue has been fixed upstream in https://github.com/protocolbuffers/protobuf/pull/18159. We'll keep this issue open until a new version of `protobuf` is available.\n\n---\n\nRoot cause bug in python is https://github.com/protocolbuffers/protobuf/issues/18045 for cross-reference\n\n---\n\nThis issue is obsolete. The issue was fixed upstream in protobuf.",
      "labels": [
        "type: bug",
        "status: blocked",
        "priority: p2",
        "external"
      ],
      "created_at": "2024-09-09T14:56:46Z",
      "closed_at": "2025-01-27T16:45:17Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13070",
      "comments_count": 3
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13405,
      "title": "Voice Experience Issue in  Google Text to Speech (streaming_synthesize)",
      "problem": "The use of Journey voices in normal TTS gives an engaging voice that attracts a user.\r\nBut when I use the same Journey voice in a streaming text input -> streaming audio output kind of way, the audio I get is a less engaging voice that just speaks out the stuff.\r\n\r\nWhy is it such ?\r\nI don't find any way to control that.\r\n\r\n\r\n[Reference TTS Example ](https://cloud.google.com/text-to-speech/docs/create-audio-text-streaming)\r\n",
      "solution": "I wasn't able to re-create the issue reported in https://github.com/googleapis/google-cloud-python/issues/13405#issue-2772787706, however follow up issues (https://github.com/GoogleCloudPlatform/python-docs-samples/issues/13080 and internal issue  b/391302662) were created to improve the samples documentation, specifically the guidance around creating the necessary header for the `WAV` file.\n\nI'm going to close this issue as not reproducible but please feel free to open a new issue if the problem is still present.",
      "labels": [
        "type: question",
        "needs more info"
      ],
      "created_at": "2025-01-07T12:57:32Z",
      "closed_at": "2025-01-27T16:38:37Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13405",
      "comments_count": 3
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13350,
      "title": "google-cloud-secret-manager: duration \"Fail to convert to Duration\"",
      "problem": "### Determine this is the right repository\n\n- [X] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n**Context**\r\n\r\nTrying to define a secret duration in \"NNx\" format (e.g. \"300s\") fails for latest versions of `protobuf` bundled with secretmanager. \r\n\r\n**Expected Behavior:**\r\n\r\n(No error)\r\n\r\n**Actual Behavior:**\r\n\r\n```\r\nAttributeError: Fail to convert to Duration. Expected a timedelta like object got str: 'str' object has no attribute 'seconds'\r\n```\r\n\n\n### API client name and version\n\ngoogle-cloud-secret-manager 2.21.1\n\n### Reproduction steps: code\n\nfile: main.py\r\n```python\r\nimport google.auth\r\nimport uuid\r\nfrom google.cloud import secretmanager\r\n\r\n_, project_id = google.auth.default()\r\nclient = secretmanager.SecretManagerServiceClient()\r\n\r\nparent = f\"projects/{project_id}\"\r\nttl = \"300s\"\r\n\r\nresponse = client.create_secret(\r\n    request={\r\n        \"parent\": f\"projects/{project_id}\",\r\n        \"secret_id\": f\"secret_{uuid.uuid4()}\",\r\n        \"secret\": {\"replication\": {\"automatic\": {}}, \"ttl\": \"300s\"},\r\n    }\r\n)\r\n```\r\n\n\n### Reproduction steps: supporting files\n\n_No response_\n\n### Reproduction steps: actual results\n\n```\r\nAttributeError: Fail to convert to Duration. Expected a timedelta like object got str: 'str' object has no attribute 'seconds'\r\n```\n\n### Reproduction steps: expected results\n\n(Successful creation)\n\n### OS & version + platform\n\nMacOS 15.1.1 (24B91)\n\n### Python environment\n\nPython 3.13.0\n\n### Python dependencies\n\ncachetools==5.5.0\r\ncertifi==2024.8.30\r\ncharset-normalizer==3.4.0\r\ngoogle-api-core==2.24.0\r\ngoogle-auth==2.37.0\r\ngoogle-cloud-secret-manager==2.21.1\r\ngoogleapis-common-protos==1.66.0\r\ngrpc-google-iam-v1==0.13.1\r\ngrpcio==1.68.1\r\ngrpcio-status==1.68.1\r\nidna==3.10\r\nproto-plus==1.25.0\r\nprotobuf==5.29.1\r\npyasn1==0.6.1\r\npyasn1_modules==0.4.1\r\nrequests==2.32.3\r\nrsa==4.9\r\nurllib3==2.2.3\n\n### Additional context\n\nDependencies based on a current `pip install google-cloud-secret-manager`, which comes with `protobuf==5.29.1`. \r\n\r\nManually running `pip install protobuf==5.27.5`, **the error does not occur**. \r\n\r\nError exists from `protobuf==5.28.0` onwards, without any changes to any other dependencies. ",
      "solution": "My company experienced the same issue but with google-cloud-tasks 2.16.5 using the v2 cloud task client\r\n\r\nrolling back to protobuf 5.27.3 resolved it for us\n\n---\n\nThanks for reporting this issue. We'll work with the protobuf team to get this resolved. For now, the workaround of rolling back to protobuf 5.27.x seems to unblock folks.\n\n---\n\nThanks for reporting this issue @glasnt! This will be fixed in https://github.com/googleapis/proto-plus-python/pull/519",
      "labels": [
        "type: bug",
        "priority: p2"
      ],
      "created_at": "2024-12-12T03:48:25Z",
      "closed_at": "2025-01-21T20:50:29Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13350",
      "comments_count": 3
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13239,
      "title": "texttospeech.AudioEncoding.FLAC not present",
      "problem": "### Determine this is the right repository\n\n- [X] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\ntexttospeech.AudioEncoding.FLAC not present when importing in python:\r\n\r\n```\r\nIn [3]: ? texttospeech.AudioEncoding\r\nInit signature:  texttospeech.AudioEncoding(*values)\r\nDocstring:     \r\nConfiguration to set up audio encoder. The encoding\r\ndetermines the output audio format that we'd like.\r\n\r\nValues:\r\n    AUDIO_ENCODING_UNSPECIFIED (0):\r\n        Not specified. Will return result\r\n        [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].\r\n    LINEAR16 (1):\r\n        Uncompressed 16-bit signed little-endian\r\n        samples (Linear PCM). Audio content returned as\r\n        LINEAR16 also contains a WAV header.\r\n    MP3 (2):\r\n        MP3 audio at 32kbps.\r\n    OGG_OPUS (3):\r\n        Opus encoded audio wrapped in an ogg\r\n        container. The result will be a file which can\r\n        be played natively on Android, and in browsers\r\n        (at least Chrome and Firefox). The quality of\r\n        the encoding is considerably higher than MP3\r\n        while using approximately the same bitrate.\r\n    MULAW (5):\r\n        8-bit samples that compand 14-bit audio\r\n        samples using G.711 PCMU/mu-law. Audio content\r\n        returned as MULAW also contains a WAV header.\r\n    ALAW (6):\r\n        8-bit samples that compand 14-bit audio\r\n        samples using G.711 PCMU/A-law. Audio content\r\n        returned as ALAW also contains a WAV header.\r\n```\r\n\r\nHowever when reading documentation :\r\n\r\nhttps://cloud.google.com/speech-to-text/docs/reference/rest/v1/RecognitionConfig\r\n\r\nlooks like FLAC is one of available formats.\n\n### API client name and version\n\n_No response_\n\n### Reproduction steps: code\n\nfrom google.cloud import texttospeech\r\nprint(texttospeech.AudioEncoding.FLAC)\n\n### Reproduction steps: supporting files\n\nN/A\n\n### Reproduction steps: actual results\n\nN/A\r\n\n\n### Reproduction steps: expected results\n\nN/A\n\n### OS & version + platform\n\nLinux\n\n### Python environment\n\n3.12.6\n\n### Python dependencies\n\nN/A\n\n### Additional context\n\nN/A",
      "solution": "Hi @gwpl,\n\nThe issues with the docs mentioned in https://github.com/googleapis/google-cloud-python/issues/13239#issuecomment-2465624114 have now been fixed.\n\nPlease use the [public issue tracker](https://issuetracker.google.com/issues/new?component=451645&template=0) for the `texttospeech` API to request features for the API such as `FLAC support across the board`. Regrettably, feature requests for the API itself need to be routed through the API specific issue tracker.\n\n",
      "labels": [
        "type: question",
        "api: texttospeech",
        "type: docs"
      ],
      "created_at": "2024-11-01T00:46:23Z",
      "closed_at": "2025-01-21T17:04:08Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13239",
      "comments_count": 4
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13391,
      "title": "Propagation of Exceptions from streaming synthesis (text-to-speech)",
      "problem": "### Determine this is the right repository\n\n- [X] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n**Context**\r\nI was trying to use raise an exception if certain condition is met inside the async iterator that I am providing as an argument to the streaming synthesize tts function.\r\n\r\nThe requirement is to identify that a condition is met in the text yielded by the iterator and stop the streaming synthesis and do some other defined function.\r\n\r\n**Expected Behavior:**\r\nI expected the error to be able to catch from outside, so that I could proceed.\r\n\r\n**Actual Behavior:**\r\nThe streaming synthesis doesn't appear to be stopped. I am also unable to catch the exception that I raised.   \r\n\n\n### API client name and version\n\ngoogle-cloud-texttospeech v2.21.1\n\n### Reproduction steps: code\n\n```\r\nasync def text_stream(response):\r\n    yield self.config_request\r\n    async for chunk in response:\r\n        chunk_message = chunk.choices[0].delta.content\r\n        if \"###\" in chunk_message: raise\r\n        else: yield chunk_message\r\n        \r\nstreaming_responses = await self.client.streaming_synthesize(text_stream(response))\r\n```\n\n### Reproduction steps: supporting files\n\n_No response_\n\n### Reproduction steps: actual results\n\n_No response_\n\n### Reproduction steps: expected results\n\n_No response_\n\n### OS & version + platform\n\nUbuntu 22.04\n\n### Python environment\n\nPython 3.11.10\n\n### Python dependencies\n\nPackage                       Version\r\n----------------------------- -----------\r\naenum                         3.1.15\r\naiohttp                       3.8.4\r\naiosignal                     1.3.1\r\nalembic                       1.13.1\r\naltair                        5.4.1\r\nanyio                         3.7.1\r\nAPScheduler                   3.10.4\r\nasttokens                     2.4.1\r\nasync-timeout                 4.0.3\r\nattrs                         24.2.0\r\nbabel                         2.16.0\r\nbcrypt                        4.2.0\r\nbeautifulsoup4                4.12.2\r\nblinker                       1.6.2\r\nbotbuilder-core               4.14.4\r\nbotbuilder-schema             4.14.4\r\nbotframework-connector        4.14.4\r\nbotframework-streaming        4.14.4\r\nboto3                         1.26.159\r\nbotocore                      1.29.165\r\ncachetools                    5.5.0\r\ncertifi                       2024.8.30\r\ncffi                          1.17.1\r\ncharset-normalizer            3.3.2\r\nclick                         8.1.7\r\nclickhouse-connect            0.8.6\r\ncomm                          0.2.2\r\ncryptography                  41.0.1\r\ndataclasses-json              0.6.7\r\ndebugpy                       1.8.6\r\ndecorator                     5.1.1\r\nDeprecated                    1.2.14\r\ndistro                        1.9.0\r\ndocstring_parser              0.16\r\nexecuting                     2.1.0\r\nfastapi                       0.106.0\r\nfastjsonschema                2.20.0\r\nfrozenlist                    1.4.1\r\ngitdb                         4.0.11\r\nGitPython                     3.1.43\r\ngoogle-api-core               2.20.0\r\ngoogle-api-python-client      2.90.0\r\ngoogle-auth                   2.35.0\r\ngoogle-auth-httplib2          0.2.0\r\ngoogle-auth-oauthlib          1.0.0\r\ngoogle-cloud                  0.34.0\r\ngoogle-cloud-aiplatform       1.72.0\r\ngoogle-cloud-bigquery         3.26.0\r\ngoogle-cloud-core             2.4.1\r\ngoogle-cloud-resource-manager 1.12.5\r\ngoogle-cloud-speech           2.27.0\r\ngoogle-cloud-storage          2.18.2\r\ngoogle-cloud-texttospeech     2.21.1\r\ngoogle-cloud-translate        3.18.0\r\ngoogle-crc32c                 1.6.0\r\ngoogle-resumable-media        2.7.2\r\ngoogleapis-common-protos      1.65.0\r\ngreenlet                      3.1.1\r\ngrpc-google-iam-v1            0.13.1\r\ngrpcio                        1.66.1\r\ngrpcio-status                 1.62.3\r\ngrpcio-tools                  1.62.3\r\ngunicorn                      23.0.0\r\nh11                           0.14.0\r\nhttpcore                      1.0.5\r\nhttplib2                      0.22.0\r\nhttptools                     0.6.1\r\nhttpx                         0.27.2\r\nidna                          3.10\r\nimportlib-metadata            6.11.0\r\nimportlib_resources           6.4.5\r\nipykernel                     6.29.5\r\nipython                       8.27.0\r\nisodate                       0.6.1\r\njedi                          0.19.1\r\nJinja2                        3.1.4\r\njiter                         0.8.2\r\njmespath                      1.0.1\r\njsonpatch                     1.33\r\njsonpickle                    1.4.2\r\njsonpointer                   3.0.0\r\njsonschema                    4.23.0\r\njsonschema-specifications     2023.12.1\r\njupyter_client                8.6.3\r\njupyter_core                  5.7.2\r\nlangchain                     0.2.17\r\nlangchain-community           0.2.19\r\nlangchain-core                0.2.43\r\nlangchain-text-splitters      0.2.4\r\nlangdetect                    1.0.9\r\nlangid                        1.1.6\r\nlangsmith                     0.1.129\r\nlimits                        3.13.0\r\nlxml                          5.3.0\r\nlz4                           4.3.3\r\nmailjet-rest                  1.3.4\r\nMako                          1.3.5\r\nmarkdown-it-py                3.0.0\r\nMarkupSafe                    2.1.5\r\nmarshmallow                   3.22.0\r\nmatplotlib-inline             0.1.7\r\nmdurl                         0.1.2\r\nmsal                          1.28.1\r\nmsrest                        0.6.21\r\nmultidict                     6.1.0\r\nmypy-extensions               1.0.0\r\nnarwhals                      1.8.4\r\nnest-asyncio                  1.6.0\r\nnumpy                         1.26.4\r\noauthlib                      3.2.2\r\nonelogin                      3.1.4\r\nopenai                        1.35.15\r\norjson                        3.10.7\r\npackaging                     23.2\r\npandas                        2.2.3\r\nparso                         0.8.4\r\npasslib                       1.7.4\r\npexpect                       4.9.0\r\nPillow                        9.5.0\r\npip                           24.0\r\nplatformdirs                  4.3.6\r\nprompt_toolkit                3.0.48\r\nproto-plus                    1.24.0\r\nprotobuf                      4.25.5\r\npsutil                        6.0.0\r\nptyprocess                    0.7.0\r\npure_eval                     0.2.3\r\npyarrow                       17.0.0\r\npyasn1                        0.6.1\r\npyasn1_modules                0.4.1\r\nPyAudio                       0.2.14\r\npycparser                     2.22\r\npydantic                      1.10.9\r\npydeck                        0.9.1\r\npydub                         0.25.1\r\nPygments                      2.18.0\r\nPyJWT                         2.7.0\r\nPympler                       1.1\r\nPyMySQL                       1.0.3\r\npyparsing                     3.1.4\r\npypdf                         5.1.0\r\npython-dateutil               2.9.0.post0\r\npython-dotenv                 1.0.1\r\npython-logstash               0.4.8\r\npython-multipart              0.0.6\r\npython3-logstash              0.4.80\r\npython3-saml                  1.16.0\r\npytz                          2023.3\r\npytz-deprecation-shim         0.1.0.post0\r\nPyYAML                        6.0.2\r\npyzmq                         26.2.0\r\nreferencing                   0.35.1\r\nrequests                      2.31.0\r\nrequests-oauthlib             2.0.0\r\nrich                          13.8.1\r\nrpds-py                       0.20.0\r\nrsa                           4.9\r\ns3transfer                    0.6.2\r\nsetuptools                    65.5.0\r\nshapely                       2.0.6\r\nsix                           1.16.0\r\nslack_sdk                     3.33.1\r\nslowapi                       0.1.9\r\nsmmap                         5.0.1\r\nsniffio                       1.3.1\r\nsoupsieve                     2.6\r\nSQLAlchemy                    2.0.16\r\nSQLAlchemy-Utils              0.41.1\r\nstack-data                    0.6.3\r\nstarlette                     0.27.0\r\nstreamlit                     1.23.1\r\nstreamlit-chat                0.1.1\r\ntenacity                      8.5.0\r\ntoml                          0.10.2\r\ntornado                       6.4.1\r\ntqdm                          4.66.5\r\ntraitlets                     5.14.3\r\ntyping_extensions             4.12.2\r\ntyping-inspect                0.9.0\r\ntzdata                        2024.2\r\ntzlocal                       4.3.1\r\nunicodecsv                    0.14.1\r\nuritemplate                   4.1.1\r\nurllib3                       1.26.20\r\nuvicorn                       0.22.0\r\nuvloop                        0.20.0\r\nvalidators                    0.34.0\r\nwatchdog                      5.0.3\r\nwatchfiles                    0.24.0\r\nwcwidth                       0.2.13\r\nwebsocket-client              1.8.0\r\nwebsockets                    14.1\r\nWerkzeug                      2.3.6\r\nwrapt                         1.16.0\r\nxmlsec                        1.3.14\r\nyarl                          1.13.1\r\nzipp                          3.20.2\r\nzstandard                     0.23.0\r\n\n\n### Additional context\n\n_No response_",
      "solution": "Hi @AKSHILMY,\r\n\r\nPlease could you provide the full sample code to help reproduce the issue?\r\n\r\nFor example, it's not clear what `response` is from your code snippet.\r\n```\r\nasync def text_stream(response):\r\n    yield self.config_request\r\n    async for chunk in response:\r\n        chunk_message = chunk.choices[0].delta.content\r\n        if \"###\" in chunk_message: raise\r\n        else: yield chunk_message\r\n        \r\n```",
      "labels": [
        "type: question"
      ],
      "created_at": "2024-12-27T05:04:40Z",
      "closed_at": "2025-01-21T11:40:14Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13391",
      "comments_count": 3
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13419,
      "title": "help: Alternate way of setting ADC for google cloud to run on read-only pipeline systems?",
      "problem": "I'm trying to use the [`kms`](https://cloud.google.com/kms/docs/hsm#kms-encrypt-symmetric-python) module which requires [`ADC`](https://cloud.google.com/docs/authentication/provide-credentials-adc#how-to) which expects `GOOGLE_APPLICATION_CREDENTIALS` which is a `json` credential file. So I aim to pass the necessary `project_id`, `location_id` etc. as secrets to run on GitHub `CI/CD`. \r\n\r\nThe most common way I found is to save the credentials as a string, then read them as a secret and save them in a temporary file on the runner. But the problem is with the production runners which is not the usual GitHub ones. Hence, it's a complete **`read-only`** system. \r\n\r\n`401 API keys are not supported by this API` suggests [`API` keys](https://cloud.google.com/docs/authentication/api-keys-use#python) in place of `ADC` won't work. For this particular task.  Is there a workaround?\r\n\r\nThis is what I'm trying to do. Reference: https://github.com/googleapis/google-cloud-python/blob/main/packages/google-cloud-kms/samples/generated_samples/cloudkms_v1_generated_key_management_service_asymmetric_sign_sync.py\r\n\r\n```py\r\nfrom google.cloud import kms_v1\r\n\r\n\r\ndef sample_asymmetric_sign():\r\n    # Create a client\r\n    client = kms_v1.KeyManagementServiceClient()\r\n\r\n    # Initialize request argument(s)\r\n    request = kms_v1.AsymmetricSignRequest(\r\n        name=\"name_value\",\r\n    )\r\n\r\n    # Make the request\r\n    response = client.asymmetric_sign(request=request)\r\n\r\n    # Handle the response\r\n    print(response)\r\n```",
      "solution": "Hi @Aviksaikat,\n\nThere is a [use-cases](https://cloud.google.com/docs/authentication/use-cases) section in the authentication documentation, which is language agnostic. I believe this specific use case is [external workloads](https://cloud.google.com/docs/authentication/use-cases#external-workloads), but please click the `Send Feedback` button on the [use-cases](https://cloud.google.com/docs/authentication/use-cases) page if you don't find the specific use case you're looking for. The [Workload Identity Federation](https://cloud.google.com/iam/docs/workload-identity-federation) link lists Github as a [Workload identity pool providers](https://cloud.google.com/iam/docs/workload-identity-federation#providers). Please click the `Send Feedback` button if any of the instructions for setting up [Workload Identity Federation](https://cloud.google.com/iam/docs/workload-identity-federation) are unclear. I'm going to close this issue as I believe [Workload Identity Federation](https://cloud.google.com/iam/docs/workload-identity-federation) is the solution, given that `Github` is a supported `Workload identity pool providers`  but please feel free to open a new issue with more information.\n",
      "labels": [
        "type: question"
      ],
      "created_at": "2025-01-09T04:38:37Z",
      "closed_at": "2025-01-20T19:40:07Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13419",
      "comments_count": 1
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13452,
      "title": "\"Items viewed in list\" are returning the value of \"Items clicked in promotion\"",
      "problem": "### Determine this is the right repository\n\n- [x] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n_No response_\n\n### API client name and version\n\n_No response_\n\n### Reproduction steps: code\n\n_No response_\n\n### Reproduction steps: supporting files\n\n_No response_\n\n### Reproduction steps: actual results\n\n_No response_\n\n### Reproduction steps: expected results\n\n_No response_\n\n### OS & version + platform\n\n_No response_\n\n### Python environment\n\n_No response_\n\n### Python dependencies\n\n_No response_\n\n### Additional context\n\nIs there an email address for GA to submit bugs? I tried leaving messages on discord and Twitter, but no one responded.\n\n![Image](https://github.com/user-attachments/assets/6874a9a1-d0f3-443a-aa8c-f06cc5fa3bfb)",
      "solution": "Hi @hama,\n\nRegrettably, this is an issue with the API rather than the python client library. Please use [this issue tracker](https://issuetracker.google.com/issues?q=componentid:187400) to file an issue for the API itself. I found the issue tracker on the [support page](https://developers.google.com/analytics/support) for the Google Analytics API. I'm going to close this issue but please feel free to open a new issue if you encounter any issue with the Python SDK.\n",
      "labels": [
        "type: question",
        "api: analyticsdata"
      ],
      "created_at": "2025-01-19T02:56:21Z",
      "closed_at": "2025-01-20T19:29:04Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13452",
      "comments_count": 1
    },
    {
      "tech": "gcp",
      "repo": "googleapis/google-cloud-python",
      "issue_number": 13451,
      "title": "itemsViewedInList always returns 0 now. Other metrics, such as itemsClickedInList, and itemsViewed are correct.",
      "problem": "### Determine this is the right repository\n\n- [x] I determined this is the correct repository in which to report this bug.\n\n### Summary of the issue\n\n**Context**\n_e.g. I was trying to use the new method Foo_\n\n**Expected Behavior:**\n_e.g. I expected method Foo to paginate_\n\n**Actual Behavior:**\n_e.g. Method Foo did not paginate_        \n\n\n### API client name and version\n\n_No response_\n\n### Reproduction steps: code\n\nfile: main.py\n```python\n   def reproduce():\n    # complete code here\n```\n\n<any additional py files>\n\n\n### Reproduction steps: supporting files\n\nfile: mydata.csv\n```\nalpha,1,3\nbeta,2,5\n```\n\n<any additional supporting files>\n\n\n### Reproduction steps: actual results\n\nfile: output.txtmydata.csv\n```\nCalculated: foo\n```\n\n\n### Reproduction steps: expected results\n\nfile: output.txtmydata.csv\n```\nCalculated: bar\n```\n\n\n### OS & version + platform\n\n_No response_\n\n### Python environment\n\n_No response_\n\n### Python dependencies\n\n_No response_\n\n### Additional context\n\n_No response_",
      "solution": "I'm going to close this issue as there is not enough information populated in the issue report. Please feel free to open a new issue with more information. When opening a new issue, please fill in all the requested information, including sample code. ",
      "labels": [
        "type: bug",
        "triage me"
      ],
      "created_at": "2025-01-17T11:34:04Z",
      "closed_at": "2025-01-17T14:45:05Z",
      "url": "https://github.com/googleapis/google-cloud-python/issues/13451",
      "comments_count": 1
    },
    {
      "tech": "gcp",
      "repo": "GoogleCloudPlatform/python-docs-samples",
      "issue_number": 11616,
      "title": "datacatalog.quickstart.quickstart_test: test_quickstart failed",
      "problem": "Note: #10216 was also for this test, but it was closed more than 10 days ago. So, I didn't mark it flaky.\n\n----\n\ncommit: c8b11a689bc5aacad120b5ee7890835fdd0f0367\nbuildURL: [Build Status](https://source.cloud.google.com/results/invocations/a56cf0c6-9cde-4e3f-b529-d3f5ea607ae6), [Sponge](http://sponge2/a56cf0c6-9cde-4e3f-b529-d3f5ea607ae6)\nstatus: failed",
      "solution": "Oops! Looks like this issue is still flaky. It failed again. :grimacing:\n\nI reopened the issue, but a human will need to close it again.\n\n---\n\ncommit: ecabbe688cd259260049377f5c3357f9edd88e2c\nbuildURL: [Build Status](https://source.cloud.google.com/results/invocations/8863dfa9-cdf5-472a-8337-f952ae0bff8c), [Sponge](http://sponge2/8863dfa9-cdf5-472a-8337-f952ae0bff8c)\nstatus: failed",
      "labels": [
        "priority: p2",
        "type: bug",
        "api: datacatalog",
        "samples",
        "flakybot: issue",
        "flakybot: flaky"
      ],
      "created_at": "2024-05-03T09:30:26Z",
      "closed_at": "2025-07-30T18:16:24Z",
      "url": "https://github.com/GoogleCloudPlatform/python-docs-samples/issues/11616",
      "comments_count": 9
    },
    {
      "tech": "gcp",
      "repo": "GoogleCloudPlatform/python-docs-samples",
      "issue_number": 13456,
      "title": "dataproc: instantiate_inline_workflow_template \"Insufficient 'N2_CPUS' quota.\"",
      "problem": "## In which file did you encounter the issue?\n\ndataproc/snippets/instantiate_inline_workflow_template.py\n\nFound via https://github.com/GoogleCloudPlatform/python-docs-samples/pull/13423\n\n## Did you change the file? If so, how?\nNo change, found when running change to another sample in same snippet/ folder. \n\n## Describe the issue\n\n```\n  File \"/workspace/dataproc/snippets/instantiate_inline_workflow_template_test.py\", line 37, in test_workflows\n    instantiate_inline_workflow_template.instantiate_inline_workflow_template(\n    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n        PROJECT_ID, REGION\n        ^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/workspace/dataproc/snippets/instantiate_inline_workflow_template.py\", line 82, in instantiate_inline_workflow_template\n    operation.result()\n    ~~~~~~~~~~~~~~~~^^\n  File \"/workspace/dataproc/snippets/.nox/py-3-13/lib/python3.13/site-packages/google/api_core/future/polling.py\", line 261, in result\n    raise self._exception\ngoogle.api_core.exceptions.Aborted: 409 Error submitting create cluster request: Insufficient 'N2_CPUS' quota. Requested 12.0, available 0.0. Your resource request exceeds your available quota. See https://cloud.google.com/compute/resource-usage. Use https://cloud.google.com/docs/quotas/view-manage#requesting_higher_quota to request additional quota. 10: Error submitting create cluster request: Insufficient 'N2_CPUS' quota. Requested 12.0, available 0.0. Your resource request exceeds your available quota. See https://cloud.google.com/compute/resource-usage. Use https://cloud.google.com/docs/quotas/view-manage#requesting_higher_quota to request additional quota.\n```",
      "solution": "Running example in a separete project, after enabling the API and waiting a minute for propegation, works without any manual quota changes. \n\nN2_CPUs quota in python-docs-samples-tests set at 24\n\nHowever, noxfile_config.py has these tests running on 3.8, 3.12, and 3.13. It's possible that since the error says `Requested 12.0, available 0.0` that each running execution removes 12 CPU from the quota, so you can only run two concurrent dataproc workflows in the same project at the same time. \n\nSolution may be to increase the quota to allow more concurrent tests, or maybe change the tested versions to just 3.9 and 3.13 (current \"required\" versions)",
      "labels": [
        "triage me",
        "priority: p2",
        "type: bug",
        "api: dataproc",
        "samples"
      ],
      "created_at": "2025-06-25T23:36:05Z",
      "closed_at": "2025-06-26T01:21:45Z",
      "url": "https://github.com/GoogleCloudPlatform/python-docs-samples/issues/13456",
      "comments_count": 2
    }
  ]
}