{
  "tech": "azure",
  "count": 291,
  "examples": [
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 66629862,
      "title": "Cannot determine the organization name for this &#39;dev.azure.com&#39; remote URL",
      "problem": "So I just updated to a new Visual Studio version and I am no longer able to push/pull from/to my Azure Repo (cloning works fine). The exact error I get is\n\nCannot determine the organization name for this 'dev.azure.com' remote\nurl. ensure the `credential.usehttppath` configuration value is set,\nor set the organization name as the user in the remote url\n'{org}@dev.azure.com'.\n\nand only the pull command shows me this error, all the others are failing with git fatal error. I messed with my Credentials Manager cos I suspected it might be the one causing the problem but no luck.",
      "solution": "What fixed the issue for me is going to Tools > Options > Source Control > Git Global Settings, there I changed all 4 dropdowns which were still selected as \"Unset\":\n\nPrune remote branches during fetch - False\nRebase local branch when pulling - False\nCryptographic network provider - OpenSSL\nCredential helper - GCM Core\n\nSource: https://learn.microsoft.com/en-us/visualstudio/ide/git-with-visual-studio?view=vs-2019#personalize-your-git-settings\nNote: These are the settings my organization requires. You might have to tweak them around according to your exact issue.",
      "question_score": 315,
      "answer_score": 615,
      "created_at": "2021-03-14T22:43:50",
      "url": "https://stackoverflow.com/questions/66629862/cannot-determine-the-organization-name-for-this-dev-azure-com-remote-url"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 69919664,
      "title": "Publish error: Found multiple publish output files with the same relative path",
      "problem": "When I publish my ABP project I get the following error:\n```\n`C:\\Program Files\\dotnet\\sdk\\6.0.100-rc.1.21458.32\\Sdks\\Microsoft.NET.Sdk\n\\targets\\Microsoft.NET.ConflictResolution.targets(112,5): \nerror NETSDK1152: Found multiple publish output files with the same relative path: \n\nD:\\Github\\volo\\abp\\lepton-theme\\src\\Volo.Abp.AspNetCore.Mvc.UI.Theme.Lepton\\compilerconfig.json,\nD:\\Github\\volo\\abp\\bookstore\\src\\Acme.BookStore.Theme\\compilerconfig.json, \n\nD:\\Github\\volo\\abp\\lepton-theme\\src\\Volo.Abp.AspNetCore.Mvc.UI.Theme.Lepton\\package.json, \nD:\\Github\\volo\\abp\\bookstore\\src\\Acme.BookStore.Web\\package.json. \n\nD:\\Github\\volo\\abp\\bookstore\\src\\Acme.BookStore.Web\\Acme.BookStore.Web.csproj\n`\n```",
      "solution": "Issue:\nThe issue raises after .NET 6 migration.\nThere's a new feature that blocks multiple files from being copied to the same target directory with the same file name.\nSee https://learn.microsoft.com/en-us/dotnet/core/compatibility/sdk/6.0/duplicate-files-in-output\nSolution #1 (workaround):\nYou can add the following build property to all your publishable (*.Web) projects' *.csproj files.\nThis property will bypass this check and works as previously, in .NET5.\n```\n`\n false\n\n`\n```\nSolution #2:\nExclude the problematic files to be copied to the output folder.\nIn this example we'll exclude these files: `compilerconfig.json` and `package.json`.\nAdd the following lines to your `common.props` (located in the root directory of your solution):\n```\n`\n\n  true\n  Never\n\n`\n```",
      "question_score": 238,
      "answer_score": 444,
      "created_at": "2021-11-10T21:13:59",
      "url": "https://stackoverflow.com/questions/69919664/publish-error-found-multiple-publish-output-files-with-the-same-relative-path"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 75146087,
      "title": "Running Azure functions locally gives &quot;No runtime&quot; error after .NET7 upgrade",
      "problem": "Recently I wanted to upgrade my Azure functions to use .NET 7. For some reasons, after doing all the required steps, when I want to run any of the functions, I keep getting this error message box telling\n\nThere is no Functions runtime available that matches the version\nproject specified by the project\n\nI checked to have the proper settings in the .csproj file:\n```\n`\n    net7.0\n    v4\n    Exe\n    $(MSBuildProjectName.Replace(\" \", \"_\"))\n    true\n    enable\n    true\n\n`\n```\nYes, it is spelled with lowercase v for \"v4\". I checked to have the hosting bundle for .NET7 installed according to my architecture (64-bit Windows) and I restarted the IIS Service after installation. I tried clean-rebuild, reopen Visual Studio, rebooting my compuer and nothing seems to be working. I also have the .NET 7 SDK installed and I am using Visual Studio 2022. If further info is needed, I will update my question accordingly. Thank you!",
      "solution": "I eventually found the solution for my case and I will post it here if anyone else faces it. As mentioned in a comment from this Github issue, I had to go to\n\nTools -> Options -> Projects & Solutions -> Azure functions and click\non the \"Check for updates\" button.\n\nAnd then I had to download and install the pending updates.\n\nThis seems to have solved my issue. Hopefully this solution will help others too.",
      "question_score": 84,
      "answer_score": 318,
      "created_at": "2023-01-17T12:58:35",
      "url": "https://stackoverflow.com/questions/75146087/running-azure-functions-locally-gives-no-runtime-error-after-net7-upgrade"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 69971341,
      "title": "Unable to create secrets in Azure Key Vault if using Azure role-based access control",
      "problem": "I'm really new to Azure but trying to learn - so apologies if this is a daft question. I've started the free trial (which gives me some credit to start with), and I'm trying to create a key vault. If I specify \"Vault access policy\" under access policies, it works great and I'm able to create secrets. I'd like to use \"Azure role-based access control\" though instead. If I create a key vault using Azure role-based access control, I get a message when trying to create a new secret which says \"The operation is not allowed by RBAC. If role assignments were recently changed, please wait several minutes for role assignments to become effective.\" I am logged into Azure as the Service Administrator, so I don't think it's a permissions issue. I have left it overnight, and it still displays the message, so I don't think it's a matter of not waiting long enough for role assignments to become effective. I have tried creating the key vault in different regions and get the same results. Note that this is happening when I create a key vault using Azure role-based access control from scratch (i.e. I am not changing it from one to the other or anything like that.) Does anyone know what I'm doing wrong?\nThanks for any help\nAndrew",
      "solution": "If you are creating the Key vault with RBAC role from scratch then Please assign `Key vault Administrator` to your name for creating/ managing the secrets, certificates and keys.\nSteps:\n\nGo to your Key vault after its created and then click on Access\nControl (IAM):\n\nThen click on Add Role assignment and then add Key vault\nAdministrator Role to your name:\n\nAfter you review and assign the role , you will be successfully able\nto create/manage the objects present inside the Key vault.",
      "question_score": 77,
      "answer_score": 161,
      "created_at": "2021-11-15T09:25:55",
      "url": "https://stackoverflow.com/questions/69971341/unable-to-create-secrets-in-azure-key-vault-if-using-azure-role-based-access-con"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67728499,
      "title": "Azure Functions: There was an error performing a read operation on the Blob Storage Secret Repository",
      "problem": "In testing Azure Functions locally, I am receiving this error:\n\n\"There was an error performing a read operation on the Blob Storage\nSecret Repository. Please ensure the 'AzureWebJobsStorage' connection\nstring is valid.\"\n\nI have Azure Blob Storage setup, including Storage Emulator and Storage Explorer. How can this be fixed?",
      "solution": "I had this issue with Azure Durable Functions, I found the way to resolve it here: https://github.com/Azure/azure-functions-host/issues/3795#issuecomment-430337085\nIn `local.settings.json`, add a new setting called `AzureWebJobsSecretStorageType` and set it to \"files\".\n```\n`{\n  \"IsEncrypted\": false,\n  \"Values\": {\n    \"AzureWebJobsStorage\": \"UseDevelopmentStorage=true\",\n    \"FUNCTIONS_WORKER_RUNTIME\": \"dotnet\",\n    \"AzureWebJobsSecretStorageType\": \"files\"\n  }\n}\n`\n```",
      "question_score": 68,
      "answer_score": 215,
      "created_at": "2021-05-27T21:08:18",
      "url": "https://stackoverflow.com/questions/67728499/azure-functions-there-was-an-error-performing-a-read-operation-on-the-blob-stor"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67722160,
      "title": "What is the point of using Azure Key Vault instead of only App Configuration?",
      "problem": "Is there any point in using Azure Key Vault over App Configuration?\nYes, yes, I know - they are complimentary, key vault for secrets, app config for... well, app config.\nBut, considering they are both encrypted, basically for someone to see either a secret or a config value they'd have to have access to your azure portal (this is a low-level bad guy scenario).\nThe ONLY difference I see is that you can control permissions differently between the vault and config but apart from that if someone unauthorized has access to your portal you've got bigger problems.\nSo - why? and please only good and real arguments no \"because you should\" or \"because person X said so\", what benefits would I reap with key vault that I don't have with app config?",
      "solution": "I appreciate your question.  I'd re-phrase it to this:\nQ) How are are Key Vault and App Configuration designed differently supporting different purposes?  And where can I find a clear comparison table of features and benefits?\nI also appreciate your aside:\n\nplease only good and real arguments no \"because you should\" or\n\"because person X said so\", what benefits would I reap with key vault\nthat I don't have with app config?\n\nHere is what I found to understand benefits as a contrast:\nArticle 1: What is Azure App Configuration?\n\nApp Configuration complements\u00a0Azure Key Vault, which is used to store application secrets. App Configuration makes it easier to implement the following scenarios:\n\nCentralize management and distribution of hierarchical configuration data for different environments and geographies\nDynamically change application settings without the need to redeploy or restart an application\nControl feature availability in real-time\n\nArticle 2 : Key management with Key Vault\n\nKey management with Key Vault\nWithout proper protection and management of the keys, encryption is rendered useless. Key Vault is the Microsoft-recommended solution for managing and controlling access to encryption keys used by cloud services. Permissions to access keys can be assigned to services or to users through Azure Active Directory accounts.\nKey Vault relieves organizations of the need to configure, patch, and maintain hardware security modules (HSMs) and key management software. When you use Key Vault, you maintain control. Microsoft never sees your keys, and applications don\u2019t have direct access to them. You can also import or generate keys in HSMs.\n\nArticle 3: Azure Key Vault recovery management with soft delete and purge protection\n\nSoft delete and purge protection are two different key vault recovery features.",
      "question_score": 39,
      "answer_score": 18,
      "created_at": "2021-05-27T14:29:46",
      "url": "https://stackoverflow.com/questions/67722160/what-is-the-point-of-using-azure-key-vault-instead-of-only-app-configuration"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 71593031,
      "title": "Azure Pipeline step reference task manual validation at version 0.198 which is not valid for the given job target",
      "problem": "I am writing a simple `azure-pipelines.yml` to install terraform and do a manual approval before proceeding to the terraform apply. I get the below error:\n\nJob manual_approval: Step reference task manual validation at version '0.198.0' which is not valid for the given job target\n\nHere's my yaml.\n```\n`# Starter pipeline\n# Start with a minimal pipeline that you can customize to build and deploy your code.\n# Add steps that build, run tests, deploy, and more:\n# https://aka.ms/yaml\n\ntrigger:\n- test\n\npool:\n  vmImage: ubuntu-latest\n\njobs:\n\n  - job: install_terraform\n    displayName: \"Installing Terraform\"\n    steps:\n      - task: ms-devlabs.custom-terraform-tasks.custom-terraform-installer-task.TerraformInstaller@0\n        displayName: 'Install Terraform latest'\n\n  - job: terraform_init\n    displayName: \"Terraform Init\"\n    dependsOn: install_terraform\n    steps:\n      - task: ms-devlabs.custom-terraform-tasks.custom-terraform-release-task.TerraformTaskV2@2\n        displayName: 'Terraform : init'\n        inputs:\n          workingDirectory: Terraform\n          backendServiceArm: 'managedclouds-rnd-001 (xxxx)'\n          backendAzureRmResourceGroupName: 'ssi-tf-state'\n          backendAzureRmStorageAccountName: tfstatessi\n          backendAzureRmContainerName: tfstate\n          backendAzureRmKey: tfstate\n\n  - job: manual_approval\n    displayName: \"Manual Approval\"\n    dependsOn: terraform_init\n    steps:\n      - task: ManualValidation@0\n        timeoutInMinutes: 5\n        inputs:\n          instructions: \"Hi, please validate\"\n\n  - job: terrform_apply\n    displayName: \"Terraform Apply\"\n    dependsOn: manual_approval   \n    steps:    \n      - task: ms-devlabs.custom-terraform-tasks.custom-terraform-release-task.TerraformTaskV2@2\n        displayName: 'Terraform : Apply'\n        inputs:\n          command: apply\n          workingDirectory: Terraform\n          environmentServiceNameAzureRM: 'managedclouds-rnd-001 (xxxx)'\n`\n```\nCan someone please help me, I am new to azure devops.",
      "solution": "Azure Pipeline step reference task manual validation at version 0.198 which is not valid for the given job target\n\nYou should specify the `pool: server` for that task:\n```\n`- job: manual_approval\n  displayName: \"Manual Approval\"\n  dependsOn: terraform_init\n  pool: server\n  steps:\n  - task: ManualValidation@0\n    timeoutInMinutes: 5\n    inputs:\n      instructions: \"Hi, please validate\"\n`\n```\n\nPlease check the Example for some more details.",
      "question_score": 35,
      "answer_score": 46,
      "created_at": "2022-03-23T20:34:09",
      "url": "https://stackoverflow.com/questions/71593031/azure-pipeline-step-reference-task-manual-validation-at-version-0-198-which-is-n"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 66377643,
      "title": "DotNetCoreCLI restore vs NuGetCommand restore",
      "problem": "I am trying to understand the difference between the two nuget restore commands in Azure build pipeline:\n```\n`- task: NuGetCommand@2\n  inputs:\n    restoreSolution: '$(solution)'\n`\n```\nand\n```\n`- task: DotNetCoreCLI@2\n  inputs:\n    command: 'restore'\n    projects: '$(solution)'\n    feedsToUse: 'select'\n`\n```\nI have tried to understand but at microsoft pages all I see is that one can use both - I can't really find anything stating what the differences are. (I do not really understand the `feedsToUse: 'select'` statement either)\nAnd, as a second question, what is the difference between the latter and\n```\n`- task: DotNetCoreCLI@2\n  inputs:\n    command: restore\n    projects: '**/*.csproj'\n`\n```\nGiven that the solution contains all of the csproj (and only csproj)?",
      "solution": "Nuget task is used to install and update NuGet package dependencies, or package and publish NuGet packages. Uses `NuGet.exe` and works with .NET Framework apps. For .NET Core and .NET Standard apps, use the .NET Core task.\n`dotnet restore` internally uses a version of `NuGet.exe` that is packaged with the .NET Core SDK. `dotnet restore` can only restore packages specified in the .NET Core project `.csproj` files. If you also have a Microsoft .NET Framework project in your solution or use `package.json` to specify your dependencies, you must also use the NuGet task to restore those dependencies.\nIn .NET Core SDK version 2.0 and newer, packages are restored automatically when running other commands such as `dotnet build`. However, you might still need to use the .NET Core task to restore packages if you use an authenticated feed.\nRegarding `feedsToUse: 'select'`, when the packages cached in Azure Artifacts with upstream sources, you should use `feedsToUse: 'select'`, and specify `vstsFeed: xxxx`. Check the following syntax (If you want to restore packages from an external custom feed, use `feedsToUse: 'config'`, and specify `nugetConfigPath` and `externalFeedCredentials`):\n```\n`#feedsToUse: # Options: select, config\n#vstsFeed: # Required when feedsToUse == Select\n#nugetConfigPath: # Required when feedsToUse == Config\n#externalFeedCredentials: # Optional\n`\n```\nWhen you don't need packages cached in Azure Artifacts, or from an external custom feed, use the following syntax (You should specify the path to the csproj file(s) to use in `projects`, not the path to the solution):\n```\n`- task: DotNetCoreCLI@2\n  displayName: 'dotnet restore'\n  inputs:\n    command: restore\n    projects: '**/*.csproj'\n`\n```\nUseful links:\n\nhttps://learn.microsoft.com/en-us/azure/devops/pipelines/tasks/package/nuget?view=azure-devops\nhttps://learn.microsoft.com/en-us/azure/devops/pipelines/ecosystems/dotnet-core?view=azure-devops&tabs=dotnetfive",
      "question_score": 35,
      "answer_score": 46,
      "created_at": "2021-02-25T23:48:30",
      "url": "https://stackoverflow.com/questions/66377643/dotnetcorecli-restore-vs-nugetcommand-restore"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 68688838,
      "title": "How to register ServiceBusClient for dependency injection?",
      "problem": "I\u2019m trying to register `ServiceBusClient` from the new Azure.Messaging.ServiceBus package for dependency injection as recommended in this article using `ServiceBusClientBuilderExtensions`, but I can\u2019t find any documentation or any help online on how exactly to go about this.\nI'm trying to add as below\n```\n`public override void Configure(IFunctionsHostBuilder builder)\n{\n    ServiceBusClientBuilderExtensions.AddServiceBusClient(builder, Typsy.Domain.Configuration.Settings.Instance().Connections.ServiceBusPrimary);\n}\n`\n```\nbut I'm getting the error\n\nThe type 'Microsoft.Azure.Functions.Extensions.DependencyInjection.IFunctionsHostBuilder' must be convertible to 'Azure.Core.Extensions.IAzureClientFactoryBuilder' in order to use it as parameter 'TBuilder' in the generic method 'IAzureClientBuilder Microsoft.Extensions.Azure.ServiceBusClientBuilderExtensions.AddServiceBusClient(this TBuilder, string)'\n\nIf anyone can help with this that'll be great!",
      "solution": "`ServiceBusClientBuilderExtensions.AddServiceBusClient` is an extension method of `IAzureClientFactoryBuilder`:\n`public static IAzureClientBuilder AddServiceBusClient(this TBuilder builder, string connectionString)\n            where TBuilder : IAzureClientFactoryBuilder\n`\nTo get an instance of `IAzureClientFactoryBuilder`, you need to call `AzureClientServiceCollectionExtensions.AddAzureClients(IServiceCollection, Action)` for a given `IServiceCollection`, which provides a delegate giving an instance of `IAzureClientFactoryBuilder`. (this method is in the `Microsoft.Extensions.Azure` NuGet package)\nTo call that method, you can use the `IServiceCollection` provided by `IFunctionsHostBuilder`. With all of that, what you have should look something like:\n`public override void Configure(IFunctionsHostBuilder builder)\n{\n    builder.Services.AddAzureClients(clientsBuilder =>\n    {\n        clientsBuilder.AddServiceBusClient(Typsy.Domain.Configuration.Settings.Instance().Connections.ServiceBusPrimary)\n          // (Optional) Provide name for instance to retrieve by with DI\n          .WithName(\"Client1Name\")\n          // (Optional) Override ServiceBusClientOptions (e.g. change retry settings)\n          .ConfigureOptions(options =>\n          {\n              options.RetryOptions.Delay = TimeSpan.FromMilliseconds(50);\n              options.RetryOptions.MaxDelay = TimeSpan.FromSeconds(5);\n              options.RetryOptions.MaxRetries = 3;\n          });\n    });\n}\n`\nTo retrieve the named instance, instead of using `ServiceBusClient` as the injected type you use `IAzureClientFactory`. The `ServiceBusClient` is a Singleton regardless of whether you use a named instance or not.\n` public Constructor(IAzureClientFactory serviceBusClientFactory)\n {\n     // Wherever you need the ServiceBusClient\n     ServiceBusClient singletonClient1 = serviceBusClientFactory.CreateClient(\"Client1Name\")\n }\n`",
      "question_score": 34,
      "answer_score": 55,
      "created_at": "2021-08-07T03:42:56",
      "url": "https://stackoverflow.com/questions/68688838/how-to-register-servicebusclient-for-dependency-injection"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 73034959,
      "title": "Microsoft.Azure.WebJobs.Extensions.Http: Could not load file or assembly",
      "problem": "I'm working in a virtual environment in VS Code and I can't understand why I'm getting this error:\n```\n`[2022-07-19T10:00:31.580Z] A host error has occurred during startup operation '609dfded-e9f5-4fc4-b3a3-554bde11a415'.\n[2022-07-19T10:00:31.582Z] Microsoft.Azure.WebJobs.Extensions.Http: Could not load file or assembly 'System.Net.Http.Formatting, Version=5.2.8.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35'. The system cannot find the file specified.\nValue cannot be null. (Parameter 'provider')\n`\n```\nWhat  should I check?",
      "solution": "My solution to this issue was to go into Windows Defender and exclude:\n```\n`C:\\Program Files\\Microsoft\\Azure Functions Core Tools\\func.exe\n`\n```\nI then reinstalled Azure Functions Core Tools v4 and everything worked as intended.\nPs. After excluding make sure to give time for your system to update. I restarted and all worked as intended. Hope this helps someone.",
      "question_score": 32,
      "answer_score": 1,
      "created_at": "2022-07-19T12:05:02",
      "url": "https://stackoverflow.com/questions/73034959/microsoft-azure-webjobs-extensions-http-could-not-load-file-or-assembly"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 73001634,
      "title": "Azure App Service unable to validate .pfx file: Certificate failed validation because it could not be loaded",
      "problem": "For years I was able to upload new pfx files for SSL binding on Azure App Services using the OpenSSL creation method in this Stack Overflow answer:\n```\n`openssl pkcs12 -export -out domain.name.pfx -inkey domain.name.key -in domain.name.crt\n`\n```\nHowever, doing the same now provides this error:\n\nAt least one certificate is not valid (Certificate failed validation because it could not be loaded.)\n\nWhat ways can this issue be resolved?",
      "solution": "App Service private certificate requirements\nApp Service private certificates must meet the following requirements:\n\nExported as a password-protected PFX file, encrypted using triple DES.\nContains private key at least 2048 bits long\nContains all intermediate certificates and the root certificate in the certificate chain.\n\nOption 1: Use legacy provider in OpenSSL 3+\nOpenSSL 3+ no longer uses DES encryption as a default. The original command needs the `-legacy` and `-provider-path` (path to `legacy.dll`) arguments appended:\n```\n`openssl pkcs12 -export -out domain.name.pfx -inkey domain.name.key -in domain.name.crt -legacy -provider-path 'C:\\Program Files\\OpenSSL-Win64\\bin'\n`\n```\nOption 2: Let Windows re-encrypt the file\nIf for some reason your OpenSSL installation does not contain the legacy provider:\nOpen PowerShell and run this command, replacing `-FilePath` with the path to your non-working pfx file, and the password `-String` argument with its respective password:\n```\n`Import-PfxCertificate -FilePath \"pfx file path\" -CertStoreLocation Cert:\\LocalMachine\\My -Password (ConvertTo-SecureString -String 'MyPassword' -AsPlainText -Force) -Exportable\n`\n```\nA successful output will look like:\n\nUse this thumbprint to export the cert to a new pfx file, replacing the `-Cert`, `-FilePath`, and password `-String` arguments:\n```\n`Export-PfxCertificate -Cert Microsoft.PowerShell.Security\\Certificate::LocalMachine\\My\\B56CE9B122FB04E29A974A4D0DB3F6EAC2D150C0 -FilePath 'newPfxName.pfx' -Password (ConvertTo-SecureString -String 'MyPassword' -AsPlainText -Force)\n`\n```\nAzure should now be able to validate the new pfx file output.",
      "question_score": 26,
      "answer_score": 49,
      "created_at": "2022-07-16T06:57:02",
      "url": "https://stackoverflow.com/questions/73001634/azure-app-service-unable-to-validate-pfx-file-certificate-failed-validation-be"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67976050,
      "title": "SSL certificate problem: unable to get local issuer certificate AZURE DEVOPS",
      "problem": "I have a problem... My code in Gitlab, Pipeline in Azure DevOps. I use classic editor. When i start pipeline i have error \"fatal: unable to access 'fatal: unable to access 'https://my.repos.example:***.git/': SSL certificate problem: unable to get local issuer certificate\"\nPlease help me!",
      "solution": "If you want to cancel check azure devops ssl certificate, you need to go a variable group your pipeline and add GIT_SSL_NO_VERIFY = 1",
      "question_score": 26,
      "answer_score": 6,
      "created_at": "2021-06-14T21:18:48",
      "url": "https://stackoverflow.com/questions/67976050/ssl-certificate-problem-unable-to-get-local-issuer-certificate-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67453259,
      "title": "Azure Devops Pipeline returning: &#39;Failed to deploy web package to App Service. Internal Server Error (CODE: 500)&#39;",
      "problem": "I am trying to use Azure DevOps pipelines to build a .NET 5 (Core) web app and deploy it to my Azure app service. I can't find any complete examples in the documentation that achieve this so I'm following this:\nhttps://github.com/shahedc/NetLearnerApp/blob/main/azure-pipelines.yml.txt\nHowever, the Azure deploy task keeps returning this vague error:\n\nIn my Azure portal I only get this error:\n\nI am assuming the issue is in my pipeline because deployment works when I deploy it directly from the Deployment Center in the Azure portal. Here are the details for the 3 relevant tasks my pipeline:",
      "solution": "I found the solution. It turns out the issue was not in the pipeline, but was caused by a Git connection to the app service I had previously set up in the Azure Deployment Center. Even though I disconnected/removed this Git connection, there was somehow still a residual file left over in Azure that was causing the error. I deleted the 'deployments' folder in Kudu (pictured below) and the pipeline started working as expected.\n\nGetting to the above pictured view:\n\nNavigate to your Azure Function project\nSearch for Advanced Tools\nOpen PowerShell",
      "question_score": 25,
      "answer_score": 42,
      "created_at": "2021-05-09T02:12:04",
      "url": "https://stackoverflow.com/questions/67453259/azure-devops-pipeline-returning-failed-to-deploy-web-package-to-app-service-i"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 66262752,
      "title": "Azure Auth Token - AADSTS500113: No reply address is registered for the application",
      "problem": "I am trying to obtain a token through postman using the following tutorial:\nhttps://learn.microsoft.com/en-us/azure/healthcare-apis/access-fhir-postman-tutorial\nI have successfully filled out the credentials then a pop up appears asking for my credentials. This then throws the following error:\n\nDoes anyone know why this error is occurring or how I can fix it?\nThanks",
      "solution": "According to your error message: no reply address is registered for the application. So, try to set the callback url for your application, usually the url is the reply address.\nGo to AAD>App registrations>your app>Authentication\n\nPlease note that the reply url configured in the Azure portal needs to be the same as the url you used in postman.",
      "question_score": 24,
      "answer_score": 24,
      "created_at": "2021-02-18T16:14:47",
      "url": "https://stackoverflow.com/questions/66262752/azure-auth-token-aadsts500113-no-reply-address-is-registered-for-the-applicat"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 70258702,
      "title": "Azure DevOps YAML Pipeline Error: While parsing a block mapping did not find expected key",
      "problem": "I just created a pipeline using the YAML file and I am always getting the error \"/_Azure-Pipelines/templates/webpart.yml: (Line: 41, Col: 27, Idx: 1058) - (Line: 41, Col: 60, Idx: 1091): While parsing a block mapping, did not find expected key.\". I already verified the indentation of my YAML file and that looks fine.\n\nBelow is my YAML file.\n```\n`parameters:\n  - name: azureSubscription\n    type: string\n  - name: cdnStorageAccount\n    type: string\n  - name: cdnResourceGroupName\n    type: string\n  - name: cdnEndpointName\n    type: string\n  - name: cdnProfileName\n    type: string\n  - name: sourceBranchTrigger\n    type: string\n\nstages:\n  - stage: build_stage\n    displayName: \"Build\"\n    jobs:\n      - job: build_job\n        steps:\n          - task: UseNode@1\n            displayName: \"Use Node 8.x\"\n            inputs:\n              version: \"8.x\"\n\n          - task: CmdLine@2\n            displayName: \"Build\"\n            inputs:\n              script: |\n                cd ./Webparts\n                npm run build-server\n\n          - task: PublishBuildArtifacts@1\n            displayName: \"Publish Build Artifact (Apps)\"\n            condition: ne(variables['Build.Reason'], 'PullRequest')\n            inputs:\n              PathtoPublish: \"Webparts/sharepoint/solution/webpart.sppkg\n              ArtifactName: Apps\n\n          - task: PublishBuildArtifacts@1\n            displayName: \"Publish Build Artifact (Scripts)\"\n            condition: ne(variables['Build.Reason'], 'PullRequest')\n            inputs:\n              PathtoPublish: \"Webparts/temp/deploy\"\n              ArtifactName: Scripts\n`\n```",
      "solution": "It was due to a missing quotation mark in the task `PublishBuildArtifacts@1` for the `PathtoPublish`. I found this error by using a `YAML` extension provided by `RedHat`.\n\nOnce you enabled that extension and set the formatted for YAML (SHIFT + ALT + F), it should show you the errors in your YAML file.",
      "question_score": 23,
      "answer_score": 44,
      "created_at": "2021-12-07T11:42:03",
      "url": "https://stackoverflow.com/questions/70258702/azure-devops-yaml-pipeline-error-while-parsing-a-block-mapping-did-not-find-exp"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 75548945,
      "title": "The &quot;--output&quot; option isn&#39;t supported when building a solution",
      "problem": "I am attempting to deploy a simply Web Api App to Azure to help me familiarise myself with Azure services and Github Actions for deployment.  Below are the steps I have undertaken\n1 - Create a new .NET 7 Web Api App in Visual Studio.  This creates a boilerplate Weatherforecast API app and runs as expected locally through VS.\n2- Create a new github repository and publish my .sln file along with the project folder to this repository\nIn Azure :\n\nCreate new Web App service in my main resource group\n\nDuring creation link to my github account and select the repository and main branch where my project folder and .sln file reside.\n\nNow workflow file is created in the repository and deplyoment will initiate, but after a few minutes it fails with the error:\nThe \"--output\" option isn't supported when building a solution.\n\nI cannot see how to disable this option, below if the workflow file:\n```\n`name: Build and deploy ASP.Net Core app to Azure Web App - muzztest\n\non:\n  push:\n    branches:\n      - main\n  workflow_dispatch:\n\njobs:\n  build:\n    runs-on: windows-latest\n\n    steps:\n      - uses: actions/checkout@v2\n\n      - name: Set up .NET Core\n        uses: actions/setup-dotnet@v1\n        with:\n          dotnet-version: '7.x'\n          include-prerelease: true\n\n      - name: Build with dotnet\n        run: dotnet build --configuration Release\n\n      - name: dotnet publish\n        run: dotnet publish -c Release -o ${{env.DOTNET_ROOT}}/myapp\n\n      - name: Upload artifact for deployment job\n        uses: actions/upload-artifact@v2\n        with:\n          name: .net-app\n          path: ${{env.DOTNET_ROOT}}/myapp\n\n  deploy:\n    runs-on: windows-latest\n    needs: build\n    environment:\n      name: 'Production'\n      url: ${{ steps.deploy-to-webapp.outputs.webapp-url }}\n\n    steps:\n      - name: Download artifact from build job\n        uses: actions/download-artifact@v2\n        with:\n          name: .net-app\n\n      - name: Deploy to Azure Web App\n        id: deploy-to-webapp\n        uses: azure/webapps-deploy@v2\n        with:\n          app-name: 'muzztest'\n          slot-name: 'Production'\n          publish-profile: ${{ secrets.AZUREAPPSERVICE_PUBLISHPROFILE_4F1CE8C3BB3A4BA59C822347153C6D43 }}\n          package: .\n`\n```\nWhat can I do to resolve the stumbling block above?",
      "solution": "This is due to changes in the supported flags for .NET 7 when building solutions.\nInstead of `-o DIR` or `--output DIR` you now need to use `--property:PublishDir=DIR`\nPlease see: https://learn.microsoft.com/en-us/dotnet/core/compatibility/sdk/7.0/solution-level-output-no-longer-valid for further info. Especially the Recommended action section is helpful.",
      "question_score": 20,
      "answer_score": 34,
      "created_at": "2023-02-23T19:33:57",
      "url": "https://stackoverflow.com/questions/75548945/the-output-option-isnt-supported-when-building-a-solution"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 75433821,
      "title": "How to create an Azure.AsyncPageable for mocking?",
      "problem": "I would like to mock a C# method that returns an Azure.AsyncPageable.\nThis class has only protected constructors, so I cannot instantiate it directly. Is there any way to create an instance of this class from some other collection, such as an IAsyncEnumerable or just a List?",
      "solution": "You can create `Page` objects `using Page.FromValues`.\nThen, create a `AsyncPageable` using `AsyncPageable.FromPages`.\nExample:\n`        var page = Page.FromValues(new List\n        {\n            new TableEntity(\"1a\", \"2a\"),\n            new TableEntity(\"1\", \"2b\")\n        }, continuationToken: null, new Mock().Object);\n        var pages = AsyncPageable.FromPages(new[] { page });\n`",
      "question_score": 20,
      "answer_score": 31,
      "created_at": "2023-02-13T10:04:13",
      "url": "https://stackoverflow.com/questions/75433821/how-to-create-an-azure-asyncpageable-for-mocking"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 73211066,
      "title": "Retrieve storage account access keys from a bicep module",
      "problem": "is it possible to retrieve a Storage Account's Access Key when deploying the Storage Account via a Bicep module?\nMy parent bicep creates a storage account using a module file, and it then needs an Access Key but I cannot get it working in a way that's secure:\nParent Bicep\n```\n`module functionAppStorageModule 'storage-account.bicep' = {\n  name: 'functionAppStorage'\n  params: {\n    ...\n  }\n}\n\nresource functionApp 'Microsoft.Web/sites@2021-03-01' = {\n  name: functionAppName\n  location: location\n  kind: 'functionapp'\n  properties: {\n    siteConfig: {\n      appSettings: [\n        {\n          name: 'store_key'\n          value: ???\n        }\n      ]\n    }\n  }\n}\n`\n```\nI can get it working if I set an output on the module file, and use that output in the parent bicep:\nModule Bicep\n```\n`output storageAccountStr string = 'AccountKey=${listKeys(storageAccount.id, storageAccount.apiVersion).keys[0].value}'\n`\n```\nParent Bicep\n```\n`properties: {\n        siteConfig: {\n          appSettings: [\n            {\n              name: 'store_key'\n              value: functionAppStorageModule.outputs.storageAccountStr \n            }\n          ]\n        }\n      }\n`\n```\nBut this does not seem secure to me as the key appears in plain text in Deployments' Output section on the Azure portal.\nAlternatively, I may work around by deploying the storage account beforehand without the use of a module file, as the use of modules seems to be the issue, but just would like to know what I'm trying above is impossible?\nThanks",
      "solution": "If you create the function app in a different module, this should work.\n`storage-account.bicep` file:\n`param storageAccountName string\n...\n\n// Create the storage account\nresource storageAccount 'Microsoft.Storage/storageAccounts@2021-09-01' = {\n  name: storageAccountName\n  ...\n}\n\n// return the name\noutput name string = storageAccount.name\n`\n`function-app.bicep` file:\n`...\nparam storageAccountName string \n\n// Get a reference to the existing storage\nresource storageAccount 'Microsoft.Storage/storageAccounts@2022-09-01' existing = {\n  name: storageAccountName\n}\n\n// Create the function app\nresource functionApp 'Microsoft.Web/sites@2021-03-01' = {\n  ...\n  properties: {\n    siteConfig: {\n      appSettings: [\n        {\n          name: 'store_key'\n          // Here we can securely get the access key\n          value: 'AccountKey=${storageAccount.listKeys().keys[0].value}'\n        }\n      ]\n    }\n  }\n}\n`\nThen in your `main.bicep`:\n`// Create the storage account\nmodule storage 'storage-account.bicep' = {\n  name: 'functionAppStorage'\n  params: {\n    storageAccountName: storageAccountName\n    ...\n  }\n}\n\n// create the function app once the storage has been created\nmodule functionApp 'function-app.bicep' = {\n  name: 'functionApp'\n  params: {\n    ...\n    // depends on storage module\n    storageAccountName: storage.outputs.name\n  }\n}\n`",
      "question_score": 20,
      "answer_score": 30,
      "created_at": "2022-08-02T18:51:19",
      "url": "https://stackoverflow.com/questions/73211066/retrieve-storage-account-access-keys-from-a-bicep-module"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67045378,
      "title": "Using IActionResult with Azure Functions in .NET 5?",
      "problem": "After migrating my Azure Functions project to .NET 5, it has started wrapping my responses in a weird wrapper class.\nFor instance, consider the following endpoint:\n`public record Response(string SomeValue);\n\n[Function(\"Get\")]\npublic async Task Get(\n    [HttpTrigger(AuthorizationLevel.Anonymous, \"get\", Route = \"get-something\")]\n    HttpRequestData request)\n{\n    return new OkObjectResult(new Response(\"hello world\"));\n}\n`\nBefore, it would return:\n`{\n    \"someValue\": \"hello world\"\n}\n`\nBut now, it returns:\n`{\n  \"Value\": {\n    \"SomeValue\": \"hello world\"\n  },\n  \"Formatters\": [],\n  \"ContentTypes\": [],\n  \"DeclaredType\": null,\n  \"StatusCode\": 200\n}\n`\nI get that it must be because it just tries to serialize the object result, but I can't find any documentation on how this is supposed to work in .NET 5.\nMy main function currently looks like this:\n`public static async Task Main()\n{\n    var host = new HostBuilder()\n        .ConfigureFunctionsWorkerDefaults(x => \n            x.UseDefaultWorkerMiddleware())\n        .ConfigureAppConfiguration((_, builder) => builder\n            .AddJsonFile(\"local.settings.json\", true)\n            .Build())\n        .ConfigureServices(ConfigureServices)\n        .Build();\n\n    await host.RunAsync();\n}\n`\nMy project is located here, in case someone are interested: https://github.com/sponsorkit/sponsorkit.io\nCurrently, my .NET 5 work is on a branch called `feature/signup-flow`.",
      "solution": "Using IActionResult with Azure Functions in .NET 5?\n\nYou can't return `IActionResult` with Azure Functions in .NET 5. Or more generally, you can't return `IActionResult` with Azure Functions using the isolated process model. Quote from the docs:\n\nFor HTTP triggers, you must use HttpRequestData and HttpResponseData to access the request and response data. This is because you don't have access to the original HTTP request and response objects when running out-of-process.\n\nInstead of `IActionResult`, you need to return `HttpResponseData`. Example code is here.",
      "question_score": 19,
      "answer_score": 24,
      "created_at": "2021-04-11T15:11:50",
      "url": "https://stackoverflow.com/questions/67045378/using-iactionresult-with-azure-functions-in-net-5"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 70308425,
      "title": "Pull and Push Docker Image task to ACR fails in Azure Devops Pipeline &quot;unauthorized: Invalid clientid or client secret.&quot;",
      "problem": "Pushing and pulling of image to Azure Container Registry task in Azure DevOps pipeline fails. When tried to pull or push from local system, there's no problem but when tried to do it using the Azure Devops pipeline it fails. Docker login was successful but it fails when I want to pull the image from the ACR with the following result:\n```\n`**Error response from daemon: Head \"***/a2/abcd/manifest/latest\": unauthorized: Invalid clientid or client secret. \n\n##[error]Bash exited with code '1'.\n##[debug]Processed: ##vso[task.issue type=error;]Bash exited with code '1'. \n`\n```\nI checked all the service connections in Az Devops, and they all look correctly configured. Checked the associated service principals as well if they have `AcrPull` and `AcrPush` permissions, all of them are in place. Just couldn't understand what's going wrong.\nMy Yaml looks like this:\n```\n`trigger: none\nschedules:\n- cron: \"0 0 0 * *\"\n  displayName: ****  *\n  branches:\n    include:\n    - abcd\n  always: true\n\npool:\n  vmImage: 'ubuntu-latest'\n\nvariables:\n- name: acrname\n  value: *****.azurecr.io\n\nstages:\n- stage: abcd\n  displayName: \"pull images from acr\"\n  jobs:\n  - job: abcdef\n    displayName: \"abcdef\"\n    pool:\n      vmImage: ubuntu-latest\n    steps:\n      - task: Docker@2\n        displayName: Login to ACR\n        inputs:\n          command: login\n          containerRegistry: '*****.azurecr.io'\n          \n\n      - bash: |\n            docker pull $(acrname)/abc-def:latest\n            docker pull $(acrname)/igh-jkl:latest\n        name: pull\n        displayName: 'pull acr images'\n\n`\n```\nCan anyone help?",
      "solution": "I had the same issue with the ACR service connection was expired. So I had to create a new service connection by using these steps.\n\nDocker ID and Docker Password can be obtained from ACR --> Settings --> Access keys\n\nUpdate your pipeline with this new service connection and you are good to go. Please rate if this solution helps you.",
      "question_score": 18,
      "answer_score": 22,
      "created_at": "2021-12-10T18:39:03",
      "url": "https://stackoverflow.com/questions/70308425/pull-and-push-docker-image-task-to-acr-fails-in-azure-devops-pipeline-unauthori"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 69402231,
      "title": "Authenticating my Azure account opens a localhost webpage with invalid security",
      "problem": "I've been using Azure Storage Explorer for a few years without any problems. This morning I opened it and was told that I needed to reauthenticate, so I clicked the `Reauthenticate now` link.\nThis window opened...\n\nAt the same time a browser window opened with a URL which begins...\n\nhttps://localhost:61204/?code=\n\n... and this is displayed...\n\nIs there anything I can do about this? How else can I reauthenticate?\nUPDATE\nIt seems that this problem goes further than I previously thought: I also cannot login to the Azure CLI or run any Powershell scripts which require authentication. In all cases I'm presented with a webpage showing `ERR_SSL_PROTOCOL_ERROR`.\nUPDATE 2\nIt looks like Firefox gives a bit more explanation of the problem:\n\nSure enough, if I change my default browser to Firefox then the process works.",
      "solution": "The following worked for me (across VS, Storage Explorer and the Az Cli):\nFor Edge, go to `edge://net-internals/#hsts`\nfor Google Chrome, go to `chrome://net-internals/#hsts`\nUnder Delete domain security policies, fill in localhost and click Delete\nfrom https://github.com/Azure/azure-cli/issues/10426",
      "question_score": 18,
      "answer_score": 43,
      "created_at": "2021-10-01T09:42:08",
      "url": "https://stackoverflow.com/questions/69402231/authenticating-my-azure-account-opens-a-localhost-webpage-with-invalid-security"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 70639651,
      "title": "Support for signing tags and verifying signatures in Azure DevOps",
      "problem": "Can't find any reference to the possibility to sign tags/verify signatures in Azure DevOps. Seems like you have to implement it yourself if you want to use it in Azure DevOps Pipelines. Am I missing something? Are there any plans in Azure DevOps to natively support this?",
      "solution": "Still not possible :\nhttps://github.com/MicrosoftDocs/azure-devops-docs/issues/1381#issuecomment-537725004\nThe user voice for the request\nhttps://developercommunity.visualstudio.com/t/show-whether-commits-are-verified-with-gpg-key-on/383281",
      "question_score": 18,
      "answer_score": 27,
      "created_at": "2022-01-09T09:38:42",
      "url": "https://stackoverflow.com/questions/70639651/support-for-signing-tags-and-verifying-signatures-in-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 75994613,
      "title": "Unable to connect to the server: getting credentials: exec: executable kubelogin not found",
      "problem": "I created new `config` file for Kubernetes from `Azure` in `Powershell` by `az aks get-credentials --resource-group  --name `. Got a message that `Merged \"cluster_name\" as current context in C:\\michu\\.kube\\config`. I copied this file into default `.kube\\config` location and now when I try to run any command e.g `kubectl get pods` I am receiving:\n```\n`Unable to connect to the server: getting credentials: exec: executable kubelogin not found\n\nIt looks like you are trying to use a client-go credential plugin that is not installed.\n\nTo learn more about this feature, consult the documentation available at:\n      https://kubernetes.io/docs/reference/access-authn-authz/authentication/#client-go-credential-plugins\n`\n```\nWhat is wrong here?\nI just realized that when I type `kubectl config get-contexts` then I can see my `cluster_name` and I can even switch to this by `kubectl config use-context cluster_name` and message is correct: `Switched to context cluster_name` but then still all other commands ends with `Unable to connect to the server: getting credentilas: exec: executable kubelogin not found`",
      "solution": "The error implies that the `kubelogin` executable could not be located. You need to install `kubelogin` in the azure cli using\n`az aks install-cli`, then it works as expected.\nRefer github for installation process.\nI tried the same requirement in my environment, and it worked for me as follows.\n`az aks get-credentials --resource-group caroline --name sampleaks1\nkubectl get pods\n`\nOutput:\n\nOnce you have the `aks` credentials, running `kubectl get pods` will prompt you for an `Azure kubernetes service authentication with AAD`, as shown.\n\nJust give `kubectl` in the bash to verify whether it is installed successfully.\n\nIf still the issue persists,\n\nDelete all the cache or any unused folders inside the ~/.kube/ and ran the aks credentials command by adding\n`--admin` flag in the end.\nRefer this doc by @Geert Baeke for more related information.\n\nCheck the kube config version and upgrade if required.",
      "question_score": 18,
      "answer_score": 21,
      "created_at": "2023-04-12T12:52:55",
      "url": "https://stackoverflow.com/questions/75994613/unable-to-connect-to-the-server-getting-credentials-exec-executable-kubelogin"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 70499991,
      "title": "Cannot connect Azure DevOps organization to Azure Active Directory",
      "problem": "I have created an Azure DevOps organization.  I have created it with my outlook account. I want to connect it to Azure Active Directory (AAD), Default Directory, on my Azure portal. I am using the free account on Azure portal which allows me to have one subscription. The AAD directory is shown below:\n\nI want to connect my Azure DevOps organization to Azure Active Directory. I am using the same user in Azure portal and Azure DevOps. I have basically created both by the same account. I am following the instruction at this link to connect Azure DevOps organization to Azure AD. I emphasize that in my case both are created by the same email. However, in Azure DevOps Organization settings, by clicking on \"connect directory\" under \"Azure Active Directory\", I get an error that: \"User myuser@outlook.com is a guest in the target AAD tenant Default Directory. The current organization policy does not allow guest users to access the organization. Change the policy setting to allow external guest access and try again.\"\nThis is what I see at organization settings in DevOps:\n\nThis is the error when I try to connect it to AAD:\n\nWhen I check my user in Azure Active Directory I can see it has global admin role, and is a member, not guest! It is after all the user by which I have created this account and all the resources: (It is the user on the second row:)\n\nAs mentioned earlier, this user has global administrator role:\n\nI also tried changing my policies at AAD side to be able to connect my DevOps project to AAD, but again it fails. This is how the policies are:\n\nI basically don't know what else I should do to connect DevOps to AAD. Any help is appreciated.",
      "solution": "When you log in to Azure DevOps, it logs in with Microsoft Directory.\nYou need to switch the tenant to your default directory\n\nThen you would be able to link your Azure AD tenant to your Azure DevOps Organization",
      "question_score": 18,
      "answer_score": 18,
      "created_at": "2021-12-27T21:12:13",
      "url": "https://stackoverflow.com/questions/70499991/cannot-connect-azure-devops-organization-to-azure-active-directory"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 71332944,
      "title": "AuthenticationException: The remote certificate is invalid because of errors in the certificate chain: UntrustedRoot",
      "problem": "I am performing a task to authenticate a Active-directory B2C instance in Azure from a local ToDo WebApp using a local WebAPI service.\nI have created 2 Apps App1 and App2, apart from adding a B2C instance in a trial-version subscription of Azure. In local windows 10 OS, in Visual-Studio, I collected code for the ToDo Webapp and WebAPI Service as per a Microsoft-blog here\nHowever, when I start the WebAPI service, and run the ToDoWebapp, the login after creating a user works fine, but after that, for any call to the service, I get the error-page with the message:\nAuthenticationException: The remote certificate is invalid because of errors in the certificate chain: UntrustedRoot\n\nHttpRequestException: The SSL connection could not be established, see inner exception.\n\nHow can one resolve this error?",
      "solution": "Please check below points:\n\nInstalling the .NET Core SDK installs the ASP.NET Core HTTPS\ndevelopment certificate to the local user certificate store  as part\nof the first-run experience, but it is not trusted. To trust the\ncertificate, perform the one-time step to run the dotnet dev-certs\ntool.\nCheck the certificates in the certificate store.Find\nlocalhost certificate with the ASP.NET Core HTTPS development\ncertificate both under Current User > Personal > Certificates and\nCurrent User > Trusted root certification authorities > Certificates\nTry to remove all found certificates by checking carefully from both Personal and Trusted root certification authorities.\n\nNote: Do not remove the IIS Express localhost certificate.\n\nTry to run the following commands in .NET CLI and try again\n```\n`dotnet dev-certs https --clean\ndotnet dev-certs https --trust\n`\n```\n\nNote: Untrusted certificates should only be used during app development. Production apps should always use valid certificates.\n\nReferences:\n\nTrust the ASP.NET Core HTTPS development certificate on Windows and\nmacOS\nEnforce HTTPS in ASP.NET Core | Microsoft Docs",
      "question_score": 17,
      "answer_score": 29,
      "created_at": "2022-03-03T07:29:50",
      "url": "https://stackoverflow.com/questions/71332944/authenticationexception-the-remote-certificate-is-invalid-because-of-errors-in"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 72275772,
      "title": "What is a valid binding name for azure function?",
      "problem": "When I try to run the azure function defined below, I get the following error log\n```\n`The 'my_function' function is in error: The binding name my_function_timer is invalid. Please assign a valid name to the binding.\n`\n```\nWhat is the format of a valid binding name for Azure Function ?\nFunction definition\nI have two files in `my_function` directory:\n\n`__init__.py` contains the python code of the function\n`function.json` contains the configuration of the function\n\nHere is the content of those two files\n`__init__.py`\n`import azure.functions as func\nimport logging\n\ndef main(my_function_timer: func.TimerRequest) -> None:\n    logging.info(\"My function starts\")\n    print(\"hello world\")\n    logging.info(\"My function stops\")\n`\n`function.json`\n`{\n  \"scriptFile\": \"__init__.py\",\n  \"bindings\": [\n    {\n      \"name\": \"my_function_timer\",\n      \"type\": \"timerTrigger\",\n      \"direction\": \"in\",\n      \"schedule\": \"0 0 1 * * *\"\n    }\n  ]\n}\n`\nI deploy this function using Azure/functions-action@v1 github action",
      "solution": "I couldn't find anything in the documentation either, but looking at the source code of azure-functions-host(which contains code for the runtime host used by the Azure Functions service), it uses following regex to validate the binding `name`.\n```\n`^([a-zA-Z][a-zA-Z0-9]{0,127}|\\$return)$\n`\n```\nThis means that, for a valid binding name\n\nFirst character must be a letter and can be followed by letters or digits(at most 127 characters).\nOR\n\nLiteral string `$return`\n\nSince your binding name contains an underscore(`_`), the above regex does not match which will result in validation error.",
      "question_score": 17,
      "answer_score": 25,
      "created_at": "2022-05-17T16:23:45",
      "url": "https://stackoverflow.com/questions/72275772/what-is-a-valid-binding-name-for-azure-function"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 77264367,
      "title": "Cannot log in to Visual Studio Account in VS 2022",
      "problem": "When click the login button on visual studio, I am presented with an error and then VS becomes totally unresponsive:\n\nThe error reads as follows\n```\n`We could not add the account\nUnknown Status: Unexpected\nError: 0xffffffff80070520\nContext: Unexpected exception while waiting for accounts control to finish:\n        'A specified logon session does not exist. It may already have been terminated.'\nTag: 0x1f7d734b (error code -2147023584) (internal error code 528315211)\n`\n```\nWe use TFS to do our source control, but searching online for solutions, this error always seems to be associated with Git (or maybe it's just more popular?), so solutions mention the GCM credential helper that is an option with Git, but does not apply to TFS.\nI can't access the TFS server through VS either - when I first open it up, I see this message in the output window:\n```\n`TF205020: Could not connect to server \u2018[server]\u2019. This server was used in your last session, but it might be offline or unreachable.\nConfirm that the server is available on the network. To attempt to connect again, or to a different server, click \u2018Connect To Azure DevOps Server\u2019 in Team Explorer or the Team menu.\n\nThe server returned the following error: TF30063: You are not authorized to access [server].\n`\n```\nI was able to confirm that the TFS server is available on the network; I can log in and access it in my browser using the same account. I clicked `Help->My Subscription->Benifits` and when that opened up in the browser, I could log in fine there as well.\nYesterday afternoon, the account that I am using was locked out of Windows, but it was reinstated in Active Directory - This is the first time I am logging into VS since then, which seems like strong circumstancial evidence for the cause of the problem!\nHow can I log in?\nEDIT - Adding additional info:\nI uninstalled Visual Studio 2022, then reinstalled and got the logon window as part of my first time opening the newly installed application, but the same error appeared.",
      "solution": "It seems to have resolved for me... only by luck. Steps followed Link: Click here I tried this In the \"Account Settings\" window click \"Account options\", change the drop-down for \"Add and reauthenticate account using:\" from \"Embedded web browser\" to \"System web browser\". but it did not open the browser after few attempts, so put the setting back to Embedded. Tried login again and it worked.\nOpen VS 2022 -> Tools (at the very top) -> Options , search for connect, see under Environment -> accounts , then follow rest of the steps as above",
      "question_score": 16,
      "answer_score": 36,
      "created_at": "2023-10-10T11:09:21",
      "url": "https://stackoverflow.com/questions/77264367/cannot-log-in-to-visual-studio-account-in-vs-2022"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 68350021,
      "title": "Azure Function Middleware: How to return a custom HTTP response?",
      "problem": "I am exploring Azure Function running on `.net 5` and I found out about the new middleware capabilities.\nI have built a dummy middleware like this one:\n```\n`public sealed class ExceptionLoggingMiddleware : IFunctionsWorkerMiddleware\n{\n    private readonly ILogger m_logger;\n\n    public ExceptionLoggingMiddleware(ILogger logger)\n    {\n        m_logger = logger;\n    }\n\n    public async Task Invoke(FunctionContext context, FunctionExecutionDelegate next)\n    {\n        try\n        {\n            await next(context);\n        }\n        catch (Exception unhandledException)\n        {\n            m_logger.LogCritical(unhandledException, \"Unhandled exception caught: {UnhandledException}\", unhandledException.Message);\n        }\n    }\n}\n`\n```\nIn my use case, the Azure Function is an HTTP triggered function:\n```\n`public sealed class StorageAccountsFunction\n{\n    private readonly ILogger m_logger;\n\n    public StorageAccountsFunction\n    (\n        ILogger logger\n    )\n    {\n        m_logger = logger;\n    }\n\n    [Function(\"v1-post-storage-account\")]\n    public async Task CreateAsync\n    (\n        [HttpTrigger(AuthorizationLevel.Anonymous, \"POST\", Route = \"v1/storage-accounts\")] \n        HttpRequestData httpRequestData, \n        FunctionContext context\n    )\n    {\n        m_logger.LogInformation(\"Processing a request to create a new storage account\");\n\n        throw new Exception(\"Oh no! Oh well..\");\n    }\n}\n`\n```\nIn my Function App running in-process on `.net core 3.1`, each Function had the responsibility of catching the unhandled exception (via a base class) and returned the appropriate HTTP status code.\nI would like to have that logic sit in a middleware instead to have it centralized and avoid any future mistakes.\nQuestion\nThe exception is caught by the middleware properly. However, I do not see how I can alter the response and return something more appropriate, instead of a `500 Internal Server Error` that I get right now?",
      "solution": "According to this issue, there is currently no official implementation regarding this, but they also mention a \"hacky workaround\" until the proper functionality is implemented directly into Azure functions\nWe created an extension method for FunctionContext:\n```\n`internal static class FunctionUtilities\n{\n    internal static HttpRequestData GetHttpRequestData(this FunctionContext context)\n    {\n        var keyValuePair = context.Features.SingleOrDefault(f => f.Key.Name == \"IFunctionBindingsFeature\");\n        var functionBindingsFeature = keyValuePair.Value;\n        var type = functionBindingsFeature.GetType();\n        var inputData = type.GetProperties().Single(p => p.Name == \"InputData\").GetValue(functionBindingsFeature) as IReadOnlyDictionary;\n        return inputData?.Values.SingleOrDefault(o => o is HttpRequestData) as HttpRequestData;\n    }\n\n    internal static void InvokeResult(this FunctionContext context, HttpResponseData response)\n    {\n        var keyValuePair = context.Features.SingleOrDefault(f => f.Key.Name == \"IFunctionBindingsFeature\");\n        var functionBindingsFeature = keyValuePair.Value;\n        var type = functionBindingsFeature.GetType();\n        var result = type.GetProperties().Single(p => p.Name == \"InvocationResult\");\n        result.SetValue(functionBindingsFeature, response);\n    }\n}\n`\n```\nThe usage in the middleware looks like this:\n```\n`public async Task Invoke(FunctionContext context, FunctionExecutionDelegate next)\n{\n   try\n   {\n       await next(context);\n   }\n   catch (Exception ex)\n   {\n       if (ex.InnerException is *NameOfExceptionYouNeed* e)\n       {\n           var req = context.GetHttpRequestData();\n           var res = await req.ErrorResponseAsync(e.Message);\n           context.InvokeResult(res);\n           return;\n       }\n\n       throw;\n   }\n}\n`\n```",
      "question_score": 16,
      "answer_score": 14,
      "created_at": "2021-07-12T17:27:59",
      "url": "https://stackoverflow.com/questions/68350021/azure-function-middleware-how-to-return-a-custom-http-response"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 66966418,
      "title": "Download pipeline artifact from another pipeline Azure",
      "problem": "I'm very new to this pipeline and i'm trying to build a automated way to build the `.msi` installer file for my application.\nI have 2 projects `.Net Core` and `Python`, so i created 2 pipelines. The .Net Core pipeline will build and save the files in a location and Python pipeline uses those files(from location) for its dependency and builds a new `.msi` file, the last portion in the pipeline `newsetup.py` builds the `.msi` to which i'll be passing the location of the output files of .Net Core pipeline.\nThe error i get is `Artifact dropcli was not found for build 150.`\n.Net Core pipeline script:\n```\n`- task: VSBuild@1\n  inputs:\n    solution: '$(solution)'\n    msbuildArgs: '/p:DeployOnBuild=true /p:WebPublishMethod=Package /p:PackageAsSingleFile=true /p:SkipInvalidConfigurations=true /p:DesktopBuildPackageLocation=\"$(Build.ArtifactStagingDirectory)\\WebApp.zip\" /p:DeployIisAppPath=\"Default Web Site\"'\n    platform: '$(buildPlatform)'\n    configuration: '$(buildConfiguration)'\n    \n- task: PublishPipelineArtifact@1\n  inputs:\n   targetPath: '$(Pipeline.Workspace)'\n   artifact: 'dropcli'\n   publishLocation: 'pipeline'\n\n- task: VSTest@2\n  inputs:\n    platform: '$(buildPlatform)'\n    configuration: '$(buildConfiguration)'\n`\n```\nPython pipeline script:\n```\n`- task: DownloadPipelineArtifact@2\n  inputs:\n    buildType: 'current'\n    artifactName: 'dropcli'\n    targetPath: '$(Pipeline.Workspace)'\n\n- task: PythonScript@0\n  inputs:\n    scriptSource: 'filePath'\n    scriptPath: 'src/python/newsetup.py'\n    arguments: 'bdist_msi $(Pipeline.Workspace)'\n`\n```\nAlso if i specify the build number somewhere won't it be an issue when a new pipeline is created? Or is that an limitation?",
      "solution": "In your `DownloadPipelineArtifact@2` task, the value of `buildType` is `current`. This means that you are downloading the artifact in the current run. You should set `buildType` to `specific`. Here is an example to download the latest artifact from a specific pipeline:\n```\n`- task: DownloadPipelineArtifact@2\n  inputs:\n    buildType: 'specific'\n    project: '{project id}'\n    definition: '{pipeline id}'\n    buildVersionToDownload: 'latest'\n    artifactName: 'dropcli'\n    targetPath: '$(Pipeline.Workspace)'\n`\n```\nYou can click \"Settings\" at the top of the task, it will help you to complete your task more easily.\n\nClick Download Pipeline Artifacts task for detailed information about arguments of this task.\n\nIf i specify the build number somewhere won't it be an issue when a new pipeline is created? Or is that an limitation?\n\nYou don't need to specify the build number, and what you need to specify is the pipeline definition id. You can either download the latest artifact of a pipeline or the artifact of a specific build of a pipeline.",
      "question_score": 16,
      "answer_score": 34,
      "created_at": "2021-04-06T11:53:47",
      "url": "https://stackoverflow.com/questions/66966418/download-pipeline-artifact-from-another-pipeline-azure"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 70246046,
      "title": "Azure DevOps AzCopy Authentication failed, it is either not correct, or expired, or does not have the correct permission",
      "problem": "I am using the task `Azure file copy` to upload the build artefacts to the blob container. But I am always getting an error as preceding.\n```\n`0.0 %, 0 Done, 0 Failed, 1 Pending, 0 Skipped, 1 Total, \nINFO: Authentication failed, it is either not correct, or expired, or does not have the correct permission -> github.com/Azure/azure-storage-blob-go/azblob.newStorageError, /home/vsts/go/pkg/mod/github.com/!azure/azure-storage-blob-go@v0.10.1-0.20201022074806-8d8fc11be726/azblob/zc_storage_error.go:42\n===== RESPONSE ERROR (ServiceCode=AuthorizationPermissionMismatch) =====\nDescription=This request is not authorized to perform this operation using this permission.\nRequestId:ae545517-501e-00ce-0798-ea489e000000\nTime:2021-12-06T11:54:25.0571292Z, Details: \n   Code: AuthorizationPermissionMismatch\n   PUT mybloburl?blockid=YjA4YjIzN2UtODJhMC1mMjQzLTUwOGYtNmYxNDcwOGJjZmY0&comp=block&timeout=901\n   Authorization: REDACTED\n   Content-Length: [8388608]\n   User-Agent: [TFS_useragent AzCopy/10.8.0 Azure-Storage/0.10 (go1.13; Windows_NT)]\n   X-Ms-Client-Request-Id: [65465-83ea-4410-450e-dd5b722b6cb3]\n   X-Ms-Version: [2019-12-12]\n   --------------------------------------------------------------------------------\n   RESPONSE Status: 403 This request is not authorized to perform this operation using this permission.\n`\n```\nBelow is my `YAML` file content for this task.\n```\n`steps:\n- task: AzureFileCopy@4\n  displayName: 'AzureBlob File Copy'\n  inputs:\n    SourcePath: '$(Build.ArtifactStagingDirectory)/myfile.zip'\n    azureSubscription: 'my-azure-connection'\n    Destination: AzureBlob\n    storage: mystorage\n    ContainerName: mycontainer\n`\n```",
      "solution": "After looking at this issue, I figured out what could be the reason. As you might have already known that a new service principal will be created whenever you create a service connection in the Azure DevOps, I have explained this in detail here. To make the `AzureFileCopy@4` task work, we will have to add a role assignment under the Role Assignment in the resource group. You can see this when you click on the Access control (IAM). You can also click on the `Manage service connection roles` in the service connection you had created for this purpose, which will redirect you to the IAM screen.\n\nClick on the +Add and select Add role assignment\nSelect the role as either `Storage Blob Data Contributor` or `Storage Blob Data Owner`\nClick Next; on the next screen add the service principal as a member by searching for the name of the service principal. (You can get the name of the service principal from Azure DevOps, on the page for the Service Connection, by clicking on the `Manage Service Principal` link. My service principal looked like \"AzureDevOps.userna.[guid]\".)\n\nClick on Review + assign once everything is configured.\nWait for a few minutes and run your pipeline again. Your pipeline should run successfully now.\n\nYou can follow the same fix when you get the error \"Upload to container: '' in storage account: '' with blob prefix: ''\"",
      "question_score": 16,
      "answer_score": 30,
      "created_at": "2021-12-06T14:10:19",
      "url": "https://stackoverflow.com/questions/70246046/azure-devops-azcopy-authentication-failed-it-is-either-not-correct-or-expired"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 66206530,
      "title": "RPC failed: curl 56 failure when receiving data from the peer",
      "problem": "I have just created a small corporate repository on Azure ( 1 commit per each of 2 branches, totall about 200mb of repo), then I deleted local repository. When I try to clone it to my local machine back( I assume proxy might be an issue here ) I get:\n```\n`RPC failed: curl 56 failure when receiving data from the peer. \n`\n```\n(However, if that is important, I also see that 100% objects received, 100% deltas resolved.)\nI am a very distant GIT user, but I have found a way to do the so called shallow clone of repo.\nQuestion is: did I clone the repo with correctly? (it seems yes so far, but do the commands bellow look valid theoretically?):\n```\n`git clone URL --depth=1 \ngit remote set-branches origin '*'\ngit fetch -v --depth=1\n`\n```\nQuestion 2. I still do not understand what was the issue with the error curl56.. Any ideas?\nP.S. Isn't it possible to download zipped repo from remote to local machine and then somehow link the unzipped directory to the remote(upstream)?",
      "solution": "This error message means that your machine was unable to receive all of the data from the remote side.  It could be that the other side hung up or the connection was interrupted; it's really not possible to say without more information.\nIf you're using a proxy, then yes, that's likely the problem.  Unfortunately, proxies, antivirus programs, non-standard firewalls, and TLS MITM boxes all tend to tamper with connections and they are probably the single biggest cause of this problem with Git.  These problems are all due to this software improperly tampering with the connection and can't be fixed by Git.  You should report this to your network administrator and ask them to drop or fix the proxy (preferably the former), or you can use a network that doesn't have one.\nIt is not possible to download a zipped directory and then fill in the Git repository from that.  Git stores the entire history of the project and determines what it needs from negotiation which commits are common on both sides.  There's no way to get one of those commits from the contents of a zip file, so you'd have no common commits and you'd have to send everything anyway.\nThe usual way to clone a repository as a shallow one and then unshallow it is this:\n```\n`$ git clone --depth=1 https://github.com/git/git.git\n$ cd git\n$ git fetch --unshallow origin\n`\n```",
      "question_score": 15,
      "answer_score": 12,
      "created_at": "2021-02-15T11:42:46",
      "url": "https://stackoverflow.com/questions/66206530/rpc-failed-curl-56-failure-when-receiving-data-from-the-peer"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 66059911,
      "title": "Login into Azure cli for a service principal",
      "problem": "I'm trying to get my ansible script to get logged into azure via azure cli. For some reasons, I'm not allowed to use the ansible azure package. I have to use the shell and call directly the commands from there.\nI'm fairly new with azure in general, so all this tenants, service principals and such are still concepts that I don't fully grasp.\nI've been checking official the documentation. I've created an app registration for it (Named ansible_test). I get all I need, including the secret. and then I call the the commands as this:\n```\n`az login --service-principal -u $AZURE_SERVICE_PRINCIPAL_NAME -p $AZURE_SECRET --tenant $AZURE_TENANT\n`\n```\nwhere:\n```\n`$AZURE_SERVICE_PRINCIPAL_NAME = ansible_test\n$AZURE_SECRET = ${The one that I've defined via Certificates & secrets section in the app registration}\n$AZURE_TENANT = ${The azure tenant that I find in the app registration}\n`\n```\nI'm getting the error:\n```\n`Get Token request returned http error: 400 and server response: {\"error\":\"unauthorized_client\",\"error_description\":\"AADSTS700016: Application with identifier 'ansible_test' was not found in the directory '${AZURE_TENANT}(Blurred because I'm not sure this is something secret or not)'. This can happen if the application has not been installed by the administrator of the tenant or consented to by any user in the tenant. You may have sent your authentication request to the wrong tenant.\n`\n```\nAs I understand, I got the wrong tenant. But I'm getting the exact one that I'm getting from the app registration. I've been hitting my head against this wall for some time. I've tried many other things, but it doesn't seem to work.\nIn this image, I'm trying to show that I've indeed created the app registration (What I'm understanding that it's a service principal). I've blurred the ids just out of ignorance whether they are private or not.\n\nWhat is that I'm doing wrong? I can't really understand the origin of the error...",
      "solution": "The username for a service principal is its Application (client) ID, so you need to use that instead of the app name.\nIt uses client credentials flow under the covers to get tokens which requires the client id, tenant id + client secret/client certificate to authenticate.",
      "question_score": 15,
      "answer_score": 15,
      "created_at": "2021-02-05T09:25:43",
      "url": "https://stackoverflow.com/questions/66059911/login-into-azure-cli-for-a-service-principal"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 66209674,
      "title": "Unable to read data from the transport connection: Operation canceled",
      "problem": "We have a .NET WorkerService that is running in the background pending trigger from the Event Hubs to push data to an API webservice but we are running into this issue:\nAny ideas what could be causing this ?\n```\n`\u200b\u200b\u200b\u200bExceptionSource: \"System.Net.Http\", ExceptionType: \"System.Threading.Tasks.TaskCanceledException: The operation was canceled. \n\nSystem.IO.IOException: Unable to read data from the transport connection: Operation canceled.\n\nSystem.Net.Sockets.SocketException (125): Operation canceled \n\nEnd of inner exception stack trace --- \nat System.Net.Sockets.Socket.AwaitableSocketAsyncEventArgs.ThrowException(SocketError error, CancellationToken cancellationToken) \nat System.Net.Sockets.Socket.AwaitableSocketAsyncEventArgs.GetResult(Int16 token) \nat System.Net.Security.SslStream.g__InternalFillBufferAsync|215_0[TReadAdapter](TReadAdapter adap, ValueTask`1 task, Int32 min, Int32 initial) \nat System.Net.Security.SslStream.ReadAsyncInternal[TReadAdapter](TReadAdapter adapter, Memory`1 buffer) \nat System.Net.Http.HttpConnection.FillAsync() \nat System.Net.Http.HttpConnection.ReadNextResponseHeaderLineAsync(Boolean foldedHeadersAllowed) \nat System.Net.Http.HttpConnection.SendAsyncCore(HttpRequestMessage request, CancellationToken cancellationToken) \n\n--- End of inner exception stack trace --- \nat System.Net.Http.HttpConnection.SendAsyncCore(HttpRequestMessage request, CancellationToken cancellationToken) \nat System.Net.Http.HttpConnectionPool.SendWithNtConnectionAuthAsync(HttpConnection connection, HttpRequestMessage request, Boolean doRequestAuth, CancellationToken cancellationToken) \nat System.Net.Http.HttpConnectionPool.SendWithRetryAsync(HttpRequestMessage request, Boolean doRequestAuth, CancellationToken cancellationToken) \nat System.Net.Http.RedirectHandler.SendAsync(HttpRequestMessage request, CancellationToken cancellationToken) \nat System.Net.Http.HttpClient.FinishSendAsyncUnbuffered(Task`1 sendTask, HttpRequestMessage request, CancellationTokenSource cts, Boolean disposeCts) \nat Client.MyClient.UpdateAsync(DataRequestUpdate DataRequest, CancellationToken cancellationToken) in /src/Client/Client.cs:line 1232 \nat Client.Repository.Update(Request data) in /src/Client/Repository.cs:line 32 \nat WorkerService.EventProcessor.Update(UpdateRequest request) in /src/WorkerService/EventProcessor.cs:line 390\", Message: \"The operation was canceled.\" }\u200b\n`\n```",
      "solution": "The default .NET httpclient timeout is 100 secs. If your client takes more than 100 secs, it will result in the above error. To solve this, simply increase the timeout value.\n```\n`HttpClient httpClient = new HttpClient(); \nhttpClient.Timeout = TimeSpan.FromMinutes(10); //Eg. 10mins timeout \n`\n```",
      "question_score": 15,
      "answer_score": 22,
      "created_at": "2021-02-15T15:17:34",
      "url": "https://stackoverflow.com/questions/66209674/unable-to-read-data-from-the-transport-connection-operation-canceled"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 71558801,
      "title": "Creation of local blob container gives error message InvalidHeaderValue",
      "problem": "How can I upgrade my local azurite version to 3.16.0 or downgrade some process that uses v3.16.0 to 3.14.1? Will that solve the InvalidHeaderValue issue?\n\nError\n```\n`Headers:\nServer: Azurite-Blob/3.14.1\nx-ms-error-code: InvalidHeaderValue\nx-ms-request-id: a3aca2f1-c0af-4af5-a54c-d7e24c188ba0\nDate: Mon, 21 Mar 2022 13:22:04 GMT\nConnection: keep-alive\nKeep-Alive: REDACTED\nTransfer-Encoding: chunked\nContent-Type: application/xml\n\n    \n    \n    InvalidHeaderValue\n     The value for one of the HTTP headers is not in the correct format.\n    RequestId:a3aca2f1-c0af-4af5-a54c-d7e24c188ba0\n    Time:2022-03-21T13:22:04.189Z\n    x-ms-version\n    2021-04-10\n    \n`\n```\nIf I look on Github : `https://github.com/Azure/Azurite` .And read the description from :\nAPI Version Compatible Strategy\nIf an incoming request has a higher API version than Azurite, Azurite will return a InvalidHeaderValue error for x-ms-version (HTTP status code 400 - Bad Request).\nWhat can be correct because in the api errormessage it claims that there is a headervalue : HeaderValue: 2021-04-10 (what is the newest api version 3.16.0 of Azurite see github).\nAnd if you look to the error again in the Headers is the azurite(server) AZurite-blob/3.14.1 . The version that is delivered with VS2022. So, this means that the headervalue is from the latest azurite version, but the azurite server that is used is version 3.14.1",
      "solution": "Each version of the SDK as well as Azurite targets a specific REST API version. The reason you are getting this error is because installed version of Azurite targets an older REST API version than the SDK you are using.\nTwo possible solutions:\n\nUpgrade the Azurite version: If you have installed Azurite through npm, simply execute the following command to upgrade to the latest version of Azurite.\n\n```\n`npm update -g azurite\n`\n```\n\nDowngrade the SDK version: You can downgrade the SDK version from 12.11.0 to 12.10.0. Please check the changelog before downgrading to ensure that your code is not using anything specific to the latest version. You will need to uninstall version 12.11.0 and then install 12.10.0.",
      "question_score": 15,
      "answer_score": 8,
      "created_at": "2022-03-21T14:54:21",
      "url": "https://stackoverflow.com/questions/71558801/creation-of-local-blob-container-gives-error-message-invalidheadervalue"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 68633776,
      "title": "Azure Table Storage: Ignoring a property of a TableEntity when using the Azure.Data.Tables package",
      "problem": "I am using the new Azure.Data.Tables library from Microsoft to deal with Azure Table Storage. With the old library when you had an entity that implemented ITableEntity and you had a property that you did not want to save to the storage table you would use the [IgnoreProperty] annotation. However, this does not seem to be available on the new library.\nWhat would be the equivalent on the Azure.Data.Tables package or how do you now avoid saving a property to table storage now?\nThis is the class I want to persist:\n`public class MySpatialEntity : ITableEntity\n{\n    public int ObjectId { get; set; }\n    public string Name { get; set; }\n    public int MonitoringArea { get; set; }\n\n    //This is the property I want to ignore because table storage cannot store it\n    public Point Geometry { get; set; }\n\n    //ITableEntity Members\n    public virtual string PartitionKey { get => MonitoringArea.ToString(); set => MonitoringArea = int.Parse(value); }\n    public virtual string RowKey { get => ObjectId.ToString(); set => ObjectId = int.Parse(value); }\n    public DateTimeOffset? Timestamp { get; set; }\n    public ETag ETag { get; set; }\n}\n`",
      "solution": "As of version 12.2.0.beta.1, Azure.Data.Tables table entity models now support ignoring properties during serialization via the `[IgnoreDataMember]` attribute and renaming properties via the `[DataMember(Name=\"\")]` attribute.\nSee the changelog here.",
      "question_score": 14,
      "answer_score": 38,
      "created_at": "2021-08-03T11:43:47",
      "url": "https://stackoverflow.com/questions/68633776/azure-table-storage-ignoring-a-property-of-a-tableentity-when-using-the-azure-d"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 75991406,
      "title": "How do you solve AZFD0005 Azure Function App Error",
      "problem": "Currently having issues with a Node Azure Function App throwing Error AZFD0005. The node application runs fine locally. The specific error from Azure is :\n`Microsoft.Azure.WebJobs.Script.ExternalStartupException : Error building configuration in an external startup class. ---> Microsoft.Azure.WebJobs.Script.HostInitializationException : Referenced bundle Microsoft.Azure.Functions.ExtensionBundle of version 1.8.1 does not meet the required minimum version of 2.6.1. Update your extension bundle reference in host.json to reference 2.6.1 or later. For more information see https://aka.ms/func-min-bundle-versions. `\n\nWe have a total of 3 Function apps in a resource group that seem to have this error which started Friday 4/07/23. Before this time, the functions were running fine with no errors. We can focus on 1.\nI have tried several different ways to solve this error, first one being the obvious. Lets call the problem app stackoverflow-test-app.\n\nI deleted the function app : stackoverflow-test-app using the portal and re-deployed using the infrastructure pipeline with upgraded host.json to `[3.3.0, 4.0.0)`. - This did not remove the error\n\nI deployed a function app : stackoverflow-test-app-two with a new name using the infrastructure pipeline and using the same configuration as stackoverflow-test-app (this was done to try and replicate the error on a new function app) - This somehow works and doesn't show the AZFD0005 error\n\nI decided to not use our infrastructure pipeline and not deploy code (so have the function app bare bones) and try deploying using CLI. I used the \"az functionapp create\" command (this was done to ensure nothing unexpected was going on in our infrastructure) - This did not remove the error\n\nThe command i used was:\n\naz functionapp create -g \"groupHere\" -p \"planHere\" -n \"nameHere\" -s \"storageHere\" --assign-identity '[system]' --runtime node --runtime-version 16 --functions-version 4\n\nI thought maybe something was broken with node runtime 16 so decided to use the command above and use node 14 function version 3. This did not remove the error\n\nI deleted the function app : stackoverflow-test-app and created the same function using the portal - This did not remove the error\n\nThis is what baffles me, the only thing that removed the error was creating a whole new function appstackoverflow-test-app-two with a separate name and using the same configuration. I can delete the problem function app : stackoverflow-test-app fine, but the moment i re-create it with the same function name whether that's with the portal or CLI commands, the AZFD0005 error pops up again.\nI can confirm all is okay with the resource group, app service plan or storage account since any new function app created will work fine.\nHere is my host.json:\n```\n`{\n      \"version\": \"2.0\",\n      \"logging\": {\n        \"applicationInsights\": {\n          \"samplingSettings\": {\n            \"isEnabled\": true,\n            \"excludedTypes\": \"Request\"\n          }\n        }\n      },\n      \"extensionBundle\": {\n        \"id\": \"Microsoft.Azure.Functions.ExtensionBundle\",\n        \"version\": \"[3.3.0, 4.0.0)\"\n    }\n    }\n`\n```",
      "solution": "So apparently MSFT has said the error sticks with your function app even when you resolve the error.\nIn my case, the error was fixed but the portal still showed the error. You can clear the error by heading over to the storage account associated with your function app and clearing the table :\n\n\"AzureFunctionsDiagnosticEventsDATEHERE\"\n\nIf you clear the table and the error persists, then you did not fix the underlying problem. You can confirm this by checking the table you just cleared to ensure no new entries have been made, if an entry has been made after you cleared the table, you still have issues.",
      "question_score": 14,
      "answer_score": 31,
      "created_at": "2023-04-12T04:18:23",
      "url": "https://stackoverflow.com/questions/75991406/how-do-you-solve-azfd0005-azure-function-app-error"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 71414009,
      "title": "How to add environment variables to Azure Container App",
      "problem": "I cannot find a way to add environment values to `Azure Container App` in the portal.\nHow can I add within `Azure Portal`?",
      "solution": "Azure Container App is in Preview and currently, not all settings are available in the Portal.  You can use the CLI to add env variables:\n```\n`az containerapp update -n MyContainerapp -g MyResourceGroup -v myenvvar=foo,anotherenvvar=bar\n`\n```\nRefer to the CLI doc:\n```\n`az containerapp --help\n`\n```",
      "question_score": 14,
      "answer_score": 6,
      "created_at": "2022-03-09T19:03:02",
      "url": "https://stackoverflow.com/questions/71414009/how-to-add-environment-variables-to-azure-container-app"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67989426,
      "title": "Azure key vault creation error: VaultAlreadyExists - I can&#39;t find the existing vault",
      "problem": "I'm trying to create a key vault in Azure using this CLI command...\n```\n`az keyvault create --location $location --name $keyVaultName --resource-group $resourceGroupMainName --output none\n`\n```\nBut this returns the error...\n\n(VaultAlreadyExists) The vault name '[value of $keyVaultName]' is\nalready in use. Vault names are globaly unique so it is possible that\nthe name is already taken. If you are sure that the vault name was not\ntaken then it is possible that a vault with the same name was recently\ndeleted but not purged after being placed in a recoverable state. If\nthe vault is in a recoverable state then the vault will need to be\npurged before reusing the name. For  more information on soft delete\nand purging a vault follow this link\nhttps://go.microsoft.com/fwlink/?linkid=2147740.\n\nSo I ran both of these...\n```\n`az keyvault list\naz keyvault list-deleted\n`\n```\nAnd `$keyVaultName` does not appear in either list. I've asked a colleague to double-check those results but it really doesn't appear. I've also looked in the Manage deleted vaults blade in the portal and that matches the results from the CLI - it's not there.\nI also tried to `recover` the key vault with that name...\n\n(DeletedVaultNotFound) The specified deleted vault '[value of $keyVaultName]' does not exist.\n\n...and to `purge` a key vault with that name...\n\nNo deleted Vault or HSM was found with name [value of $keyVaultName]\n\nSo why does Azure think that the name is already in use?",
      "solution": "As provided in the comment, Similar to Storage Accounts in Azure, the keyvault is also unique across globally. You can check the similar error code from the docs,\n\nYour attempt to create a new key vault with the specified name has\nfailed since the name is already in use. If you recently deleted a key\nvault with this name, it may still be in the soft deleted state\nVault names and Managed HSM pool names are selected by the user and\nare globally unique.\n\nYou can verify the existence using Powershell or Rest API",
      "question_score": 14,
      "answer_score": 4,
      "created_at": "2021-06-15T17:42:48",
      "url": "https://stackoverflow.com/questions/67989426/azure-key-vault-creation-error-vaultalreadyexists-i-cant-find-the-existing-v"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 72051754,
      "title": "apt-update in Azure Nvidia gives publickey error",
      "problem": "I started a NVIDIA VM on AZURE and trying to do update using\n`sudo apt update`\nbut gives error:\n```\n`Hit:2 http://azure.archive.ubuntu.com/ubuntu focal InRelease                                                 \nHit:3 http://azure.archive.ubuntu.com/ubuntu focal-updates InRelease                                         \nHit:4 http://azure.archive.ubuntu.com/ubuntu focal-backports InRelease                                   \nHit:5 https://packages.microsoft.com/repos/azure-cli focal InRelease        \nHit:6 http://security.ubuntu.com/ubuntu focal-security InRelease            \nErr:1 http://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC\nReading package lists... Done\nW: GPG error: http://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC\nE: The repository 'http://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease' is no longer signed.\nN: Updating from such a repository can't be done securely, and is therefore disabled by default.\nN: See apt-secure(8) manpage for repository creation and user configuration details.\n`\n```\nto install the keys i used\n`sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv A4B469963BF863CC`\nbut that gives No data error. `gpg: keyserver receive failed: No data `\nI can run `sudo apt-get upgrade` but not the update.\nAny help would be appreciated\nEven though there is cuda installed but it still doesnt find cuda libraries, and that could be due to update.",
      "solution": "the following worked for me\n```\n`apt-key del 7fa2af80\nrm /etc/apt/sources.list.d/cuda.list\nrm /etc/apt/sources.list.d/nvidia-ml.list\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-keyring_1.0-1_all.deb\ndpkg -i cuda-keyring_1.0-1_all.deb\n`\n```\nI ran those commands in docker container, so in VM you might need to add sudo.",
      "question_score": 14,
      "answer_score": 15,
      "created_at": "2022-04-29T03:06:35",
      "url": "https://stackoverflow.com/questions/72051754/apt-update-in-azure-nvidia-gives-publickey-error"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 71185859,
      "title": "How do I diagnose a failed Azure Container App revision?",
      "problem": "I'm currently working through some Azure Container App quick starts. I've just attempted to create one that's Dapr enabled with storage account state store. It has a provision status of failed but seemingly no other information. I'm not aware of how to access any logs from the container and there's nothing in the Log Analytics workspace. The others examples I've tested have worked so far so I think it's related to the Dapr config.\nIs there a way to attach to the container and see what's happening? Or anywhere I can find more detail on what error is being thrown?",
      "solution": "Here is what sequence of actions helped me sort out what was going on in my case:\n\nOpen Azure Container App  (Screenshot 1)\nGo to Revision management (Screenshot 1)\nFind out which revision fails and click on its name. The Details panel should pop to the right. (Screenshot 1)\nClick \"View details\" next to \"System logs\". The Logs screen will open. (Screenshot 1)\nScroll to the bottom and search for the log that describes what went wrong. (Screenshot 2)\nIn my case the issue description was \"Container was terminated with error code '1'\". I googled it online and found out the following \"Exit Code 1: Indicates failure due to application error\". Which means that I had an error in the code. For you, the message in the logs might be different. So pay attention. (Screenshot 2)\n\nHere's a good article of Container Image Exit Codes: https://betterprogramming.pub/understanding-docker-container-exit-codes-5ee79a1d58f6",
      "question_score": 14,
      "answer_score": 5,
      "created_at": "2022-02-19T15:24:13",
      "url": "https://stackoverflow.com/questions/71185859/how-do-i-diagnose-a-failed-azure-container-app-revision"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 75652378,
      "title": "IServiceCollection does not contain a definition for AddAzureClients",
      "problem": "I am trying to add a blob service client for dependency injection.\nI'm using the latest version of `Microsoft.Extensions.Azure`, however my service collection does not contain the extension method of `AddAzureClients`. The service collection is of type `Microsoft.Extensions.DependencyInjection.IServiceCollection`.\nI've not really found anything for this issue by researching online. I'm not sure what I'm doing wrong here. Probably something very simple I'm missing!\n```\n`using Microsoft.Extensions.Azure;\nusing Microsoft.Extensions.Configuration;\nusing Microsoft.Extensions.DependencyInjection;\n\nnamespace MY.API\n{\n    public class Startup\n    {\n        public Startup(IConfiguration configuration)\n        {\n            Configuration = configuration;\n        }\n\n        public IConfiguration Configuration { get; }\n\n        // This method gets called by the runtime. Use this method to add services to the container.\n        public void ConfigureServices(IServiceCollection services)\n        {\n            services.AddAzureClients(builder => // IServiceCollection does not contain a definition for AddAzureClients\n            {\n                builder.AddBlobServiceClient(Configuration.GetConnectionString(\"BlobStorage\"));\n            });\n        }\n    }\n}\n`\n```",
      "solution": "I solved this, not sure why it behaved this way.\nDespite me having `using Microsoft.Extensions.Azure` in my `.cs` file and it appearing as installed, the package wasn't actually installed to the project. After installing it manually in NuGet package manager it works as expected.",
      "question_score": 13,
      "answer_score": 30,
      "created_at": "2023-03-06T15:59:24",
      "url": "https://stackoverflow.com/questions/75652378/iservicecollection-does-not-contain-a-definition-for-addazureclients"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 74292401,
      "title": "How to react to message from Microsoft regarding updating API&#39;s",
      "problem": "I got a message from Microsoft in the last few days\n\nAzure SQL Database 2014-04-01 APIs will be retired on 31 October 2025.\nYou're receiving this email because you use Azure SQL Database APIs.\nTo improve performance and security, we're updating Azure SQL Database\nAPIs. As part of this, all version 2014-04-01 APIs will be retired on\n31 October 2025. You'll need to update your resources, including\ntemplates, tools, scripts, and programs, to use a newer API version by\nthen. Any API calls still using the older versions after that date\nwill stop working until you've updated them.\n\nI access my Azure SQL Databases in the following manner.\n\nFrom the WebApp via a Java connection and an ODBC driver\n```\n`public final class DBConnection {\nprivate static DataSource ds = null;\nprivate static DBConnection instance = null;\n\nprivate DBConnection() throws NamingException {\n   InitialContext ic = new InitialContext();\n   ds = (DataSource) ic.lookup(Monitor.getDsName());\n}\n\n     com.microsoft.sqlserver\n     mssql-jdbc\n     10.2.1.jre11\n \n`\n```\n\nvia `sqlcmd`\n\nvia `node.js`\n```\n` const configDB = {\n\n user: \"\",\n password: \"\",\n server: \"myserver.database.windows.net\",\n database: \"mydb\",\n connectionTimeout: 3000,\n parseJSON: true,\n options: {\n     encrypt: true,\n     enableArithAbort: true\n },\n pool: {\n     min: 0,\n     idleTimeoutMillis: 3000\n }\n };\n const poolDB = new sql.ConnectionPool(configDB);\n aLine='EXEC ...'\n await poolFOI.connect();\n let resultDB = await poolDB.request().query(aLine);\n`\n```\n\nVia `Azure Logic Apps` (using an API Connections)\n\nVia `Azure Function Apps` (connecting similar to the WebApp Above)\n\nVia `SSMS`\n\nWhich of these are possibly triggering the message about Azure SQL Database APIs?\nAlso I started using Azure after 2020, so it does not make sense to me that I would be using APIs from 2014",
      "solution": "The API mentioned in the email (I also got the same) is for managing the SQL Database Servers and the Database itself (in other words they are the control plane API) and not the data inside them. You would use the SQL REST API to perform management operations on the SQL Database resources.\nThey will have no impact on how you connect to the database and manage the data inside those databases which is what your code is currently doing.\nSo unless you are using the version 2014-04-01 of the REST API to manage the SQL Database Servers and SQL Databases (and not the data inside them), you can safely ignore the email.\nYou can learn more about the SQL Database REST APIs here: https://learn.microsoft.com/en-us/rest/api/sql/.",
      "question_score": 13,
      "answer_score": 15,
      "created_at": "2022-11-02T17:12:53",
      "url": "https://stackoverflow.com/questions/74292401/how-to-react-to-message-from-microsoft-regarding-updating-apis"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 74019739,
      "title": "How to pull image from existing azure container registry?",
      "problem": "Created a docker image. Deployed the app as web service; create a registry and push the image to azure container and the app is running fine online. I tried to login but cant. Username or password incorrect. On top of that my laptop crashed and I did not save a copy.\nCan someone help me on how to pull the image from acr with the source code and download to my local machine. I found some tutorial online but was a bit vague.\nPlease help",
      "solution": "Login to your Azure account\n\n`az login\n`\n\nLogin to Azure Container Registry\n\n`az acr login --name $REGISTRY\n`\n\nPull your Image\n\n`docker pull ${REGISTRY}.azurecr.io/${IMAGE}:${TAG}\n`\nOptionnal:\nList your images\n```\n`az acr repository list -n $REGISTRY --output table\n`\n```",
      "question_score": 13,
      "answer_score": 27,
      "created_at": "2022-10-10T21:14:46",
      "url": "https://stackoverflow.com/questions/74019739/how-to-pull-image-from-existing-azure-container-registry"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 68664319,
      "title": "Why I got an error request every 5 minutes in an Azure App Service",
      "problem": "I have a java web app on Azure, and I got failed requests in it's Application Insights. It look likes someone are calling 'http://myApp.azurewebsites.net/error' every 5 minutes, but I do not have this interface, so there are many failed requests with 404 in Application Insights. Then I add this interface in app, but there are still many failed requests with 404 code. I have no idea about those requests, I do not know where are them from or what do them want to do. Did I set wrong configurations in my app?",
      "solution": "There is a setting named 'Always on' in App Service's configuration, and it's works fine when I turned off this setting.",
      "question_score": 13,
      "answer_score": 4,
      "created_at": "2021-08-05T11:49:42",
      "url": "https://stackoverflow.com/questions/68664319/why-i-got-an-error-request-every-5-minutes-in-an-azure-app-service"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 70652241,
      "title": "SQL Server Pre-Login Handshake (error: 31 - Encryption(ssl/tls) handshake failed)",
      "problem": "I have a SQL server version `12.0.6205` and the following code in a .Net Core 3.1 (or 6) Web Api controller:\n```\n` var builder = new SqlConnectionStringBuilder\n{\n    DataSource = DataSource,\n    UserID = UserID,\n    Password = Password,\n    InitialCatalog = InitialCatalog,\n    ApplicationIntent = ApplicationIntent.ReadWrite,\n    \n    // Same result if true/true\n    Encrypt = false,\n    TrustServerCertificate = false\n};\n\nvar connection = new SqlConnection(builder.ToString());\nusing (var cmd = new SqlCommand() { Connection = connection, CommandText = \"SELECT TOP 1 * FROM [dbo].[Table]\" })\n{\n    connection.Open(); // Breaks here\n    var reader = cmd.ExecuteReader();\n    Console.WriteLine(reader.HasRows);\n}\n`\n```\nLocally this code works without issues but when executing in Azure's App service it breaks when opening the connection with:\n```\n`System.Data.SqlClient.SqlException (0x80131904): A connection was successfully established with the server, but then an error occurred during the pre-login handshake. (provider: SSL Provider, error: 31 - Encryption(ssl/tls) handshake failed)\n`\n```\nI also have been able to reproduce the error, locally, if creating\na docker imaged based on `appsvc/dotnetcore` (any tag)\n```\n`FROM mcr.microsoft.com/appsvc/dotnetcore:3.1-latest_20220105.1\n\nENV ASPNETCORE_URLS=http://+:80  \n\nEXPOSE 8080\nWORKDIR /home/site/wwwroot/\nCOPY . .\n\nENTRYPOINT [\"dotnet\", \"Test.dll\"]\n`\n```",
      "solution": "Like @DraggonDragger said this is a TLS issue but in my specific case I can't rely on the SQL server being updated to allow TLS 1.2 therefore I had to allow TLS 1.0 in the application.\nI ended up following this answer: https://stackoverflow.com/a/61523341/17892120;\nEssentially, for docker images, adding this line is enough:\n`RUN sed -i 's/DEFAULT@SECLEVEL=2/DEFAULT@SECLEVEL=1/g' /etc/ssl/openssl.cnf`\nAnd for Azure's App Service, we can add\n`sed -i 's/DEFAULT@SECLEVEL=2/DEFAULT@SECLEVEL=1/g' /etc/ssl/openssl.cnf && dotnet Test.dll` for the startup command.\nFor future reference, there's also a discussion about this in GitHub, link.",
      "question_score": 13,
      "answer_score": 13,
      "created_at": "2022-01-10T13:16:36",
      "url": "https://stackoverflow.com/questions/70652241/sql-server-pre-login-handshake-error-31-encryptionssl-tls-handshake-failed"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 66497630,
      "title": "What is the proper way to expose an Azure Container Instance that is inside a vnet?",
      "problem": "I have an ACI that is running a REST API that needs to be exposed publicly, but needs to access resources inside a vnet.\nFor some reason, unlike normal VMs, if an ACI is inside a vnet, it cannot have a public IP address. If you try to give it a DNS name it fails.\nThe only option seems to be to use an Application Gateway as described here:\nhttps://learn.microsoft.com/en-us/azure/container-instances/container-instances-application-gateway\nAnd also here: Assign Static Public Address to Azure Container Instance deployment\nBut this approach has a fatal flaw, as indicated in the documentation itself: \"If the container group is stopped, started, or restarted, the container group's private IP is subject to change. If this happens, you will need to update the application gateway configuration.\"\nThe Application Gateway has the option to select a backend pool by resource name, but this is only for normal VMs. The other option is to put in the IP address directly.\nAn ACI can easily get restarted without knowing. From experience, it happens relatively often that the host kills it and restarts it, possibly taking a different IP.\nWhat is the right approach to expose a service running on an ACI instance on the internet, and at the same time have it access resources behind a vnet? The Application Gateway approach is evidently not the right approach.\nI need a solution that can work easily with Azure CLI, since I am deploying my ACI through Bitbucket Pipes.\nUPDATE:\nAzure Container Instances are just a pile of junk. The only way to expose them from a vnet is to use an Application Gateway, which after a month running it, ends up costing more than the Container Instance itself! Moreover, Azure Container Instances are very unstable in certain regions (in West EU they keep getting killed), with support not understanding what is going on (apparently its an issue with multiple customers). So every time the instance gets restarted, it will get a different IP address, and the costly Application Gateway, which can run into over $100 per month, won't even know that the IP address changed.",
      "solution": "If you only want to use the ACI, then there is no way to solve it. What you have found is the only way to access the ACI inside the VNet. But if you do not mind, maybe you can use the AKS, then enable the virtual node, then you also can run the ACI in the VNet and access it outside. Of course, you can use the AKS only, it also helps you run the application in the VNet and access outside.",
      "question_score": 13,
      "answer_score": 1,
      "created_at": "2021-03-05T19:17:53",
      "url": "https://stackoverflow.com/questions/66497630/what-is-the-proper-way-to-expose-an-azure-container-instance-that-is-inside-a-vn"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 71736633,
      "title": "Azure Pipelines DotNetCoreCLI - .Net Core SDK End of Life",
      "problem": "I am receiving an error in Azure CI pipelines. While trying to run a DotNetCoreCLI `restore` task.\nBeen scrapping the net for hours to no avail, no solution from related questions have helped me understand the problem.\nBasically, we have added a new project to a repo. This project requires a dotnet restore command to be run to create the `project.assets.json` file.\nPlease see script below and log snapshot for each task.\nScript:\n\nUseDotNet snapshot:\n\nDotNetCoreCLI error message:\nInfo: .NET Core SDK/runtime 2.2 and 3.0 are now End of Life(EOL) and have been removed from all hosted agents. If you're using these SDK/runtimes on hosted agents, kindly upgrade to newer versions which are not EOL, or else use UseDotNet task to install the required version.\n##[error]No files matched the search pattern.\nInfo: Azure Pipelines hosted agents have been updated and now contain .Net 5.x SDK/Runtime along with the older .Net Core version which are currently lts.\nHave looked around quite a bit. Nothing seems to help me understand what is going wrong here.\nAny assistance would be appreciated.",
      "solution": "Turns out the issue was in the folder location referenced as `$(UtilityLibrary)`.\nTook me a while to figure out as I didn't have access to the actual variable set.",
      "question_score": 13,
      "answer_score": 2,
      "created_at": "2022-04-04T13:39:52",
      "url": "https://stackoverflow.com/questions/71736633/azure-pipelines-dotnetcorecli-net-core-sdk-end-of-life"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67671421,
      "title": "Azure Service Bus managed identity in Visual Studio returning 401 - Token issuer is invalid",
      "problem": "I'm attempting to access Azure Service Bus using a managed identity from my code. At the moment I'm just trying this locally.\nWhen I debug my code I get the following error\n`System.UnauthorizedAccessException: Put token failed. status-code: 401, status-description: InvalidIssuer: Token issuer is invalid`\nHere is my service bus instance\n\nHere is my user with `Azure Service Bus Data Owner` permissions\n\nAnd here is my code\n`_client = new ServiceBusClient(\"oconnorevents.servicebus.windows.net\", new DefaultAzureCredential());\n`\nI am logged into Visual Studio as the same user added to the service bus. I also tried logging in via the CLI but it didn't help.\nWhere am I going wrong here?\nI've looked at this similar recent question here but the solutions proposed didn't work for me.",
      "solution": "If you use `DefaultAzureCredential` to auth, it will try several credential types to auth as mentioned here, one of them is `VisualStudioCredential`, but it will auth to the home AAD tenant of the user logged in VS, in your case, I suppose the service bus is in a subscription which is not under the home tenant of the user.\nI can also reproduce your issue on my side.\n\nTo solve the issue, just use `VisualStudioCredential` directly, then simply specify the `TenantId` via `VisualStudioCredentialOptions`, then it will work fine.\nSample:\nTo find the `TenantId`, just navigate to the `Azure Active Directory` which the subscription of your service bus located.\n\n```\n`TokenCredential tokenCredential = new VisualStudioCredential(new VisualStudioCredentialOptions {TenantId = \"xxxxxxx\" });\nServiceBusClient client = new ServiceBusClient(\"xxx.servicebus.windows.net\", tokenCredential);\n`\n```",
      "question_score": 12,
      "answer_score": 7,
      "created_at": "2021-05-24T13:36:29",
      "url": "https://stackoverflow.com/questions/67671421/azure-service-bus-managed-identity-in-visual-studio-returning-401-token-issuer"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 77365775,
      "title": "AzureDev Repos, how to change target for pull request",
      "problem": "I have created a pull request in AzureDevops Repos. Pull request is from \"green_branch\" into \"master\". I would like to change the target of this pull request from \"master\" to \"develop\" but I cannot find anywhere any \"edit\" button.\n\nHow can I change the target of pull request?",
      "solution": "How can I change the target of pull request?\n\nYou can use the option:Change target branch in Pull Request -> more action button(...)\n\nThen you can select the target branch in the list.",
      "question_score": 12,
      "answer_score": 21,
      "created_at": "2023-10-26T11:31:29",
      "url": "https://stackoverflow.com/questions/77365775/azuredev-repos-how-to-change-target-for-pull-request"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67296022,
      "title": "How can I solve COPY failed: file not found in build context or excluded in Azure Pipeline?",
      "problem": "I got stuck very interesting issue with azure pipeline. The issue is \"Forbidden path outside the build context\".If you have an add line in the Dockerfile which points to another directory, the build of the image fails with the message \"Forbidden path\".How can I solve this?\nI was recently attempting to Dockerize a C# project, so I added a docker folder to the project and created a simple Dockerfile to get started like below:\nError:\n```\n`f83e9c616794: Pulling fs layer\n9887694812e5: Pulling fs layer\n9887694812e5: Verifying Checksum\n9887694812e5: Download complete\ndd4da9d953fb: Verifying Checksum\ndd4da9d953fb: Download complete\nf83e9c616794: Verifying Checksum\nf83e9c616794: Download complete\ndd4da9d953fb: Pull complete\nf83e9c616794: Pull complete\n9887694812e5: Pull complete\nDigest: sha256:85ea9832ae26c70618418cf7c699186776ad066d88770fd6fd1edea9b260379a\nStatus: Downloaded newer image for mcr.microsoft.com/dotnet/sdk:5.0\n ---> bd73c72c93a1\nStep 5/25 : WORKDIR /src\n ---> Running in b457b1934a7e\nRemoving intermediate container b457b1934a7e\n ---> a50c5df6f929\nStep 6/25 : COPY [\"./src/xxxxx.Web/xxxxx.Web.csproj\", \"src/xxxxx.Web/\"]\nCOPY failed: file not found in build context or excluded by .dockerignore: stat src/xxxxx.Web/xxxxx.Web.csproj: file does not exist\n##[error]COPY failed: file not found in build context or excluded by .dockerignore: stat src/xxxxx.Web/xxxxx.Web.csproj: file does not exist\n##[error]The process '/usr/bin/docker' failed with exit code 1\nFinishing: Build and push an image to container registry\n`\n```\nDockerFiles/Dockerfile.xxxxx.Web:\n```\n`FROM mcr.microsoft.com/dotnet/aspnet:5.0 AS base\nWORKDIR /app\nEXPOSE 80\n\nFROM mcr.microsoft.com/dotnet/sdk:5.0 AS build\nWORKDIR /src\nCOPY [\"src/xxxxx.Web/xxxxx.Web.csproj\", \"src/xxxxx.Web/\"]\nRUN dotnet restore \"src/xxxxx.Web/xxxxx.Web.csproj\"\nCOPY . .\nWORKDIR \"/src/src/xxxxx.Web\"\nRUN dotnet build \"xxxxx.Web.csproj\" -c Release -o /app\n\nFROM build AS publish\nRUN dotnet publish \"xxxxx.Web.csproj\" -c Release -o /app\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app .\nENTRYPOINT [\"dotnet\", \"xxxxx.Web.dll\"]\n`\n```\nazure-pipeline.yml:\n```\n` # Deploy to Azure Kubernetes Service\n# Build and push image to Azure Container Registry; Deploy to Azure Kubernetes Service\n# https://learn.microsoft.com/azure/devops/pipelines/languages/docker\n\ntrigger:\n- test\n\nvariables:\n\n  # Container registry service connection established during pipeline creation\n  dockerRegistryServiceConnection: 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n  imageRepository: 'xxxxxxxx'\n  containerRegistry: 'xxxxxxxxxxxx.azurecr.io'\n  dockerfilePath: '**/DockerFiles/Dockerfile.xxxxx.Web'\n  tag: '$(Build.BuildNumber)'\n\n  # Agent VM image name\n  vmImageName: 'ubuntu-latest'\n\nstages:\n- stage: Build\n  displayName: Build stage\n  jobs:\n  - job: Build\n    displayName: Build\n    pool:\n      vmImage: $(vmImageName)\n    steps:\n    - task: Docker@2\n      displayName: Build and push an image to container registry\n      inputs:\n        command: buildAndPush\n        repository: $(imageRepository)\n        dockerfile: $(dockerfilePath)\n        containerRegistry: $(dockerRegistryServiceConnection)\n        tags: |\n          $(tag)\n\n    - publish: manifests\n      artifact: manifests\n\n- stage: Deploy\n  displayName: Deploy stage\n  dependsOn: Build\n\n  jobs:\n  - deployment: Deploy\n    displayName: Deploy-xxxxx.Web\n    pool:\n      vmImage: $(vmImageName)\n    environment: 'xxxxx-5982.default'\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n\n          - task: KubernetesManifest@0\n            displayName: Deploy to Kubernetes cluster\n            inputs:\n              action: deploy\n              manifests: |\n                $(Pipeline.Workspace)/manifests/deployment.eventhub.web.yml\n                $(Pipeline.Workspace)/manifests/service.eventhub.web.yml\n              containers: |\n                $(containerRegistry)/$(imageRepository):$(tag)\n\n`\n```\nHow can I solve \"COPY failed: Forbidden path outside the build context\"? I want to use Dockerfile in DockerFiles Directory.",
      "solution": "You can try to add `buildContext` parameter in the Docker task.\nbuildContext: Path to the build context\nHere is a case you can refer to.",
      "question_score": 12,
      "answer_score": 11,
      "created_at": "2021-04-28T09:51:53",
      "url": "https://stackoverflow.com/questions/67296022/how-can-i-solve-copy-failed-file-not-found-in-build-context-or-excluded-in-azur"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 65846738,
      "title": "How does message locking and lock renewal work in Azure Service Bus?",
      "problem": "I'm getting a bit confused trying to nail down how peek lock works in Service Bus. In particular I'm using Microsoft.Azure.ServiceBus with Azure Functions and a ServiceBusTrigger.\nFrom what I can make out the time a message gets locked for is set on the queue itself and defaults to 30 seconds though it can be set to be anywhere up to 5 minutes.\nWhen a message is peeked from the queue this lock kicks in.\nThere is then a setting called maxAutoRenewDuration which when using Azure Functions is set in the host.json file under Extensions:ServiceBus:messageHandlerOptions.  This allows the client to automatically request one or more extensions to a lock until the maxAutoRenewDuration is reached. Once you hit this limit a renewal won't be requested and the lock will be released.\nRenewals are best effort and can't be guaranteed so ideally you try to come up with a design where messages are typically processed within the lock period specified on the queue.\nHave I got this right so far?\nQuestions I still have are\n\nare there and limits on what maxAutoRenewDuration can be set to. One article I read seemed to suggest that this could be set to whatever I need to ensure my message is processed (link).  The Microsoft Documentation though states that the maximum value for this is also limited to 5 minutes (link).\n\nThe maxAutoRenewDuration is configurable in host.json, which maps to OnMessageOptions.MaxAutoRenewDuration. The maximum allowed for this setting is 5 minutes according to the Service Bus documentation\n\nWhich is correct?  I know the default lock duration has a maximum of 5 minutes but it doesn't seem to make sense that this also applies to maxAutoRenewDuration?\n\nI've read about a setting called MaxLockDuration in some articles (e.g. link).  Is this just referring to the lock duration set on the queue itself?\n\nAm I missing anything else?  Are the lock duration set on the queue and the maxAutoRenewDuration in my code the main things I need to consider when dealing with locks and renewals?\n\nThanks\nAlan",
      "solution": "I understand your confusion. The official doc explanation of `maxAutoRenewDuration` seems wrong. There is already an open doc issue https://github.com/MicrosoftDocs/azure-docs/issues/62110 and also a reference https://github.com/Azure/azure-functions-host/issues/6500.\nTo pinpoint your questions:\n\n#1: As told above, the there is open doc issue.\n#2: MaxLockDuration is Service Bus queue side setting which basically signifies that if you peek lock a message from the queue, the message is locked for the consumer for that duration. So, unless you complete your message processing or renew lock within that period, the lock is going to expire.\n#3: @sean-feldman 's awesome explanation in the thread https://stackoverflow.com/a/60381046/13791953 should answer that.\n\nWhat it does is extends the message lease with the broker, \"re-locking\" it for the competing consumer that is currently handling the message. MaxAutoRenewDuration should be set to the \"possibly maximum processing time a lease will be required\".",
      "question_score": 12,
      "answer_score": 4,
      "created_at": "2021-01-22T15:10:04",
      "url": "https://stackoverflow.com/questions/65846738/how-does-message-locking-and-lock-renewal-work-in-azure-service-bus"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 70605728,
      "title": "Azure Functions: Blob Storage emulator stopped working after moving to VS2022",
      "problem": "I have one old Azure Functions project (v3). It contains several timer triggered functions. They stopped working on VS2022. You can see the logs below. If I create a new Functions project via VS2022, it will work fine. Looks like Azurite also starts up fine. Setting \"AzureWebJobsStorage\" equals \"UseDevelopmentStorage=true\". What can I do?\n```\n`[2022-01-06T10:17:15.675Z] Host lock lease acquired by instance ID '000000000000000000000000DC2A3C3E'.\n[2022-01-06T10:17:35.554Z] The listener for function 'Function1' was unable to start.\n[2022-01-06T10:17:35.556Z] The listener for function 'Function1' was unable to start. Azure.Storage.Blobs: Service request failed.\n[2022-01-06T10:17:35.557Z] Status: 500 (Internal Server Error)\n[2022-01-06T10:17:35.557Z]\n[2022-01-06T10:17:35.558Z] Headers:\n[2022-01-06T10:17:35.559Z] Server: Azurite-Blob/3.14.1\n[2022-01-06T10:17:35.560Z] ETag: \"0x234B8B049DD4280\"\n[2022-01-06T10:17:35.561Z] x-ms-blob-type: BlockBlob\n[2022-01-06T10:17:35.562Z] x-ms-lease-state: available\n[2022-01-06T10:17:35.562Z] x-ms-lease-status: unlocked\n[2022-01-06T10:17:35.563Z] x-ms-client-request-id: a3bc0141-7bcb-420c-84a9-eadf86f8c685\n[2022-01-06T10:17:35.564Z] x-ms-request-id: 88474d4b-bc15-4f45-95d5-0a01682d883d\n[2022-01-06T10:17:35.565Z] x-ms-version: 2020-10-02\n[2022-01-06T10:17:35.566Z] Accept-Ranges: bytes\n[2022-01-06T10:17:35.566Z] Date: Thu, 06 Jan 2022 10:17:35 GMT\n[2022-01-06T10:17:35.567Z] x-ms-server-encrypted: true\n[2022-01-06T10:17:35.570Z] x-ms-blob-content-md5: jhxvLoUrRfc2dXn/gXokig==\n[2022-01-06T10:17:35.570Z] Connection: keep-alive\n[2022-01-06T10:17:35.571Z] Keep-Alive: REDACTED\n[2022-01-06T10:17:35.572Z] Last-Modified: Tue, 28 Dec 2021 11:10:44 GMT\n[2022-01-06T10:17:35.573Z] Content-Length: 115\n[2022-01-06T10:17:35.574Z] Content-Type: application/octet-stream\n[2022-01-06T10:17:35.574Z] Content-MD5: jhxvLoUrRfc2dXn/gXokig==\n`\n```\nUPDATE\nI have added few new functions to the same project. They work fine. I have changed function and method names and old functions also start working. Looks like it caches somewhere names. I tried clean rebuild but it didn't help. I have no idea why it doesn't work with old names.",
      "solution": "I was able to solve this issue by using Azure Storage Explorer and deleting the related blob folder under azure-webjobs-hosts in the local storage blob container\nThe root folders will be found at:\n`Local & Attached > Storage Accounts > (Emulator - Default Ports) > Blob Containers -> azure-webjobs-hosts`\nMake sure the project is open or Storage Explorer may not load the containers.\nOnce deleted, the problem function began running as expected",
      "question_score": 11,
      "answer_score": 41,
      "created_at": "2022-01-06T11:27:51",
      "url": "https://stackoverflow.com/questions/70605728/azure-functions-blob-storage-emulator-stopped-working-after-moving-to-vs2022"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 73741756,
      "title": "Disabling allow public blob access using terraform",
      "problem": "I have created a storage account using a Terraform. I would like to disable the option found under the storage account settings and configuration in the Azure portal called Allow public blob access, however under the azurerm_storage_account command, I cannot seem to find the option required to achieve this.\nBelow is my code so far to create the storage account, which works, but if anyone could point me in the right direction that would be great, thank you.\nStorage Account\n```\n`resource \"azurerm_storage_account\" \"st\" {\n    name = var.st.name\n    resource_group_name = var.rg_shared_name\n    location = var.rg_shared_location\n    account_tier = var.st.tier\n    account_replication_type = var.st.replication\n    public_network_access_enabled = false\n}\n`\n```",
      "solution": "As soon as I've posted this question, I found the command, so I apologise for wasting your time.\nThe command to use is allow_nested_items_to_be_public, if you set this to false it will disable the feature found under Storage Account > Settings > Configuration, Allow blob public access\nSource\nhttps://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/storage_account#allow_nested_items_to_be_public\nUpdated Code\n```\n`resource \"azurerm_storage_account\" \"st\" {\n    name = var.st.name\n    resource_group_name = var.rg_shared_name\n    location = var.rg_shared_location\n    account_tier = var.st.tier\n    account_replication_type = var.st.replication\n    public_network_access_enabled = false\n    allow_nested_items_to_be_public = false\n}\n`\n```",
      "question_score": 11,
      "answer_score": 11,
      "created_at": "2022-09-16T10:06:52",
      "url": "https://stackoverflow.com/questions/73741756/disabling-allow-public-blob-access-using-terraform"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 68844740,
      "title": "This Static Web App has the maximum number of staging environments",
      "problem": "When setting up Azure Static Web Apps and using Github workflow, sometimes pull-request builds will fail. The error is:\n\nThis Static Web App already has the maximum number of staging environments.\n\nHere's an excerpt from the GitHub Workflow build log:\n\nHow do I remove some of the staging environments so builds / pull-requests can complete?",
      "solution": "The reason for this is most likely because you've opened PR and closed them before the build has completed. Doing so leaves them in a \"void\" state, and is a current limitation of Azure Static Web Apps. In order to complete the builds you need to delete some of the previous staging environments first. The free hosting plan has 3 staging environments, while the Standard has 10.\nYou do this by going to your Static Web App in Azure and clicking \"Environments\" (Marked 1). Your staging environments are displayed under \"Staging\".\n\nThen check the ones you want to delete (Marked 2) and click \"Delete\" (Marked 3). That's it. Now you can re-run your pull-requests and the build will complete.",
      "question_score": 11,
      "answer_score": 26,
      "created_at": "2021-08-19T10:51:41",
      "url": "https://stackoverflow.com/questions/68844740/this-static-web-app-has-the-maximum-number-of-staging-environments"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 72140664,
      "title": "Azure build error: &quot;Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8&quot;",
      "problem": "When building `Flutter` app in `azure devOps`, I receive this error:\n```\n`Build file 'D:\\a\\1\\s\\android\\app\\build.gradle' line: 24\n\n* What went wrong:\nA problem occurred evaluating project ':app'.\n> Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n     You can try some of the following options:\n       - changing the IDE settings.\n       - changing the JAVA_HOME environment variable.\n       - changing `org.gradle.java.home` in `gradle.properties`.\n`\n```\nI've tried, these solutions:\n\nCreating `jitpack.yml` file, with `- openjdk11` value.\nAdding below lines to `app/build.gradle` file inside `android {}` block:\n\n...\n```\n`compileOptions {\n\nsourceCompatibility JavaVersion.VERSION_11\n\n    targetCompatibility JavaVersion.VERSION_11\n}\n\nkotlinOptions {\n    jvmTarget = JavaVersion.VERSION_11.toString()\n}\n`\n```\nAnd another solutions, but my error doesn't solve. By the way, I easily run app and build apk, locally on my mac without any errors, but when I push my code, Azure gives those build error.",
      "solution": "My error is solved by adding below lines into `azure-pipelines.yml` file:\n```\n`steps:\n - task: JavaToolInstaller@0\n    inputs:\n      versionSpec: '11'\n      jdkArchitectureOption: 'x64'\n      jdkSourceOption: 'PreInstalled'\n`\n```",
      "question_score": 11,
      "answer_score": 25,
      "created_at": "2022-05-06T13:20:49",
      "url": "https://stackoverflow.com/questions/72140664/azure-build-error-android-gradle-plugin-requires-java-11-to-run-you-are-curre"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 66721744,
      "title": "Azure Kubernetes .NET Core App to Azure SQL Database Intermittent Error 258",
      "problem": "We are running a .NET Core 3.1 application in a Kubernetes cluster. The application connects to an Azure SQL Database using EF Core 3.1.7, with Microsoft.Data.SqlClient 1.1.3.\nAt seemingly random times, we would receive the following error.\n```\n` ---> System.Data.SqlClient.SqlException (0x80131904): Timeout expired.  The timeout period elapsed prior to completion of the operation or the server is not responding.\n ---> System.ComponentModel.Win32Exception (258): Unknown error 258\n   at System.Data.SqlClient.SqlInternalConnection.OnError(SqlException exception, Boolean breakConnection, Action`1 wrapCloseInAction)\n   at System.Data.SqlClient.TdsParser.ThrowExceptionAndWarning(TdsParserStateObject stateObj, Boolean callerHasConnectionLock, Boolean asyncClose)\n   at System.Data.SqlClient.TdsParserStateObject.ThrowExceptionAndWarning(Boolean callerHasConnectionLock, Boolean asyncClose)\n   at System.Data.SqlClient.TdsParserStateObject.ReadSniError(TdsParserStateObject stateObj, UInt32 error)\n   at System.Data.SqlClient.TdsParserStateObject.ReadSniSyncOverAsync()\n   at System.Data.SqlClient.TdsParserStateObject.TryReadNetworkPacket()\n   at System.Data.SqlClient.TdsParserStateObject.TryPrepareBuffer()\n   at System.Data.SqlClient.TdsParserStateObject.TryReadByte(Byte& value)\n   at System.Data.SqlClient.TdsParser.TryRun(RunBehavior runBehavior, SqlCommand cmdHandler, SqlDataReader dataStream, BulkCopySimpleResultSet bulkCopyHandler, TdsParserStateObject stateObj, Boolean& dataReady)\n   at System.Data.SqlClient.SqlDataReader.TryConsumeMetaData()\n   at System.Data.SqlClient.SqlDataReader.get_MetaData()\n   at System.Data.SqlClient.SqlCommand.FinishExecuteReader(SqlDataReader ds, RunBehavior runBehavior, String resetOptionsString)\n   at System.Data.SqlClient.SqlCommand.RunExecuteReaderTds(CommandBehavior cmdBehavior, RunBehavior runBehavior, Boolean returnStream, Boolean async, Int32 timeout, Task& task, Boolean asyncWrite, SqlDataReader ds)\n   at System.Data.SqlClient.SqlCommand.ExecuteScalar()\n`\n```\nEven though it seems random, it definitely happens more often under heavier loads. From my research, it appears as if this specific timeout is related to the connection timeout rather than the command timeout. I.e. the client is not able to establish a connection at all. This is not a query that is timing out.\nPotential root causes we've eliminated:\n\nAzure SQL Server Capacity: The behaviour is observed whether we run on 4 or 16 vCPUs. Azure Support also confirmed that there are no issues in the logs. This includes the number of open connections, which is only around 50. We also ran load tests from other connections and the server held up fine.\nMicrosoft.Data.SqlClient Versions: We've been running on version 1.1.3 and this behaviour only started a week ago (2021-03-16).\nNetwork Capacity: We are maxing out at around 1-2MB/s at this stage, which is pretty pedestrian.\nKubernetes Scaling: There is no correlation between the occurrence of the events and when we scale up more pods.\nConnection String Issues: Our system used to work fine, but regardless we changed a few settings mentioned in other articles to see if the issue would not resolve itself. Mars is disabled. We cannot disable connection pooling. We have `TrusServerCertificate` set to true. Here is the current connection string: `Server=tcp:***.database.windows.net,1433;Initial Catalog=***;Persist Security Info=False;User ID=***;Password=***;MultipleActiveResultSets=False;Encrypt=True;Connection Timeout=60;TrustServerCertificate=True;`\n\nUpdate 1:\nAs requested, an example of two timeouts that just occurred. It is a Sunday, so traffic is extremely low. Database utilization (CPU, Mem, IO) is sitting between 2-6%.\n```\n`Microsoft.Data.SqlClient.SqlException (0x80131904): Execution Timeout Expired.  The timeout period elapsed prior to completion of the operation or the server is not responding.\n ---> System.ComponentModel.Win32Exception (258): Unknown error 258\n   at Microsoft.Data.SqlClient.SqlInternalConnection.OnError(SqlException exception, Boolean breakConnection, Action`1 wrapCloseInAction)\n   at Microsoft.Data.SqlClient.TdsParser.ThrowExceptionAndWarning(TdsParserStateObject stateObj, Boolean callerHasConnectionLock, Boolean asyncClose)\n   at Microsoft.Data.SqlClient.TdsParserStateObject.ThrowExceptionAndWarning(Boolean callerHasConnectionLock, Boolean asyncClose)\n   at Microsoft.Data.SqlClient.TdsParserStateObject.ReadSniError(TdsParserStateObject stateObj, UInt32 error)\n   at Microsoft.Data.SqlClient.TdsParserStateObject.ReadSniSyncOverAsync()\n   at Microsoft.Data.SqlClient.TdsParserStateObject.TryReadNetworkPacket()\n   at Microsoft.Data.SqlClient.TdsParserStateObject.TryPrepareBuffer()\n   at Microsoft.Data.SqlClient.TdsParserStateObject.TryReadByte(Byte& value)\n   at Microsoft.Data.SqlClient.TdsParser.TryRun(RunBehavior runBehavior, SqlCommand cmdHandler, SqlDataReader dataStream, BulkCopySimpleResultSet bulkCopyHandler, TdsParserStateObject stateObj, Boolean& dataReady)\n   at Microsoft.Data.SqlClient.TdsParser.Run(RunBehavior runBehavior, SqlCommand cmdHandler, SqlDataReader dataStream, BulkCopySimpleResultSet bulkCopyHandler, TdsParserStateObject stateObj)\n   at Microsoft.Data.SqlClient.TdsParser.TdsExecuteTransactionManagerRequest(Byte[] buffer, TransactionManagerRequestType request, String transactionName, TransactionManagerIsolationLevel isoLevel, Int32 timeout, SqlInternalTransaction transaction, TdsParserStateObject stateObj, Boolean isDelegateControlRequest)\n   at Microsoft.Data.SqlClient.SqlInternalConnectionTds.ExecuteTransactionYukon(TransactionRequest transactionRequest, String transactionName, IsolationLevel iso, SqlInternalTransaction internalTransaction, Boolean isDelegateControlRequest)\n   at Microsoft.Data.SqlClient.SqlInternalConnection.BeginSqlTransaction(IsolationLevel iso, String transactionName, Boolean shouldReconnect)\n   at Microsoft.Data.SqlClient.SqlConnection.BeginTransaction(IsolationLevel iso, String transactionName)\n   at Microsoft.Data.SqlClient.SqlConnection.BeginDbTransaction(IsolationLevel isolationLevel)\n   at Microsoft.EntityFrameworkCore.Storage.RelationalConnection.BeginTransaction(IsolationLevel isolationLevel)\n   at Microsoft.EntityFrameworkCore.SqlServer.Storage.Internal.SqlServerExecutionStrategy.Execute[TState,TResult](TState state, Func`3 operation, Func`3 verifySucceeded)\n`\n```\nWe are also receiving errors on our database health checker when using this command: `Microsoft.EntityFrameworkCore.Infrastructure.DatabaseFacade.CanConnect()`\nThe above stack trace is the issue we are trying to solve versus this stack trace below of the SQL query timing out.\n```\n`Microsoft.Data.SqlClient.SqlException (0x80131904): Execution Timeout Expired.  The timeout period elapsed prior to completion of the operation or the server is not responding.\n ---> System.ComponentModel.Win32Exception (258): Unknown error 258\n   at Microsoft.Data.SqlClient.SqlConnection.OnError(SqlException exception, Boolean breakConnection, Action`1 wrapCloseInAction)\n   at Microsoft.Data.SqlClient.TdsParser.ThrowExceptionAndWarning(TdsParserStateObject stateObj, Boolean callerHasConnectionLock, Boolean asyncClose)\n   at Microsoft.Data.SqlClient.TdsParser.TryRun(RunBehavior runBehavior, SqlCommand cmdHandler, SqlDataReader dataStream, BulkCopySimpleResultSet bulkCopyHandler, TdsParserStateObject stateObj, Boolean& dataReady)\n   at Microsoft.Data.SqlClient.SqlDataReader.TryConsumeMetaData()\n   at Microsoft.Data.SqlClient.SqlDataReader.get_MetaData()\n   at Microsoft.Data.SqlClient.SqlCommand.FinishExecuteReader(SqlDataReader ds, RunBehavior runBehavior, String resetOptionsString, Boolean isInternal, Boolean forDescribeParameterEncryption, Boolean shouldCacheForAlwaysEncrypted)\n   at Microsoft.Data.SqlClient.SqlCommand.RunExecuteReaderTds(CommandBehavior cmdBehavior, RunBehavior runBehavior, Boolean returnStream, Boolean isAsync, Int32 timeout, Task& task, Boolean asyncWrite, Boolean inRetry, SqlDataReader ds, Boolean describeParameterEncryptionRequest)\n   at Microsoft.Data.SqlClient.SqlCommand.RunExecuteReader(CommandBehavior cmdBehavior, RunBehavior runBehavior, Boolean returnStream, TaskCompletionSource`1 completion, Int32 timeout, Task& task, Boolean& usedCache, Boolean asyncWrite, Boolean inRetry, String method)\n   at Microsoft.Data.SqlClient.SqlCommand.ExecuteReader(CommandBehavior behavior)\n`\n```",
      "solution": "The problem was an infrastructure issue at Azure.\n\nThere is a known issue within Azure Network where the dhcp lease is\nlost whenever a disk attach/detach happens on some VM fleets. There is\na fix rolling out at the moment to regions. I'll check to see when\nAzure Status update will be published for this.\n\nThe problem disappeared, so it appears as if the fix has been rolled out globally.\nFor anyone else running into this issue in the future, you can identify it by establishing an SSH connection into the node (not the pod). Do an `ls -al /var/log/` and identify all the `syslog` files and run the following grep on each file.\n```\n`cat /var/log/syslog | grep 'carrier'\n`\n```\nIf you have any `Lost carrier` and `Gained carrier` messages in the log, there is a some sort of a network issue. In our case it was the DHCP lease.",
      "question_score": 11,
      "answer_score": 11,
      "created_at": "2021-03-20T13:44:10",
      "url": "https://stackoverflow.com/questions/66721744/azure-kubernetes-net-core-app-to-azure-sql-database-intermittent-error-258"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 68350196,
      "title": "How to manually handle message completion in C# azure function with azure service bus 5.0.0",
      "problem": "I'm writing an Azure Function to get the messages in an Azure Service Bus.\nI want to handle any exceptions manually (`\"autoCompleteMessages\": false`)\nCan't figure how to send the complete or abandon back to the service queue.\nTried Option 1:\n```\n`[FunctionName(\"SBQ_F1_VC\")]\npublic static async Task Run([ServiceBusTrigger(\"sbqfn1\", Connection = \"BrnlTest1_SERVICEBUS\")]\n    ServiceBusReceivedMessage msg, ILogger log)\n{\n//.....\n\n    if(!Int32.TryParse(msg.ApplicationProperties.GetValueOrDefault(\"vid\").ToString(), out vid))\n    {   await using ServiceBusClient client = new ServiceBusClient(Environment.GetEnvironmentVariable(\"BrnlTest1_SERVICEBUS\"));\n        ServiceBusReceiver msgRcvr = client.CreateReceiver(Environment.GetEnvironmentVariable(\"queueName\"), new ServiceBusReceiverOptions()); \n        //await msgRcvr.RenewMessageLockAsync(msg);\n        await msgRcvr.AbandonMessageAsync(msg);  //vid = 0;\n    }\n\n//.....\n}\n`\n```\nErrors Option 1\n```\n`System.Private.CoreLib: Exception while executing function: SBQ_F1_VC. Azure.Messaging.ServiceBus: The lock supplied is invalid. Either the lock expired, or the message has already been removed from the queue, or was received by a different receiver instance. (MessageLockLost).\n`\n```\nTried Option 2:\n```\n`[FunctionName(\"SBQ_F1_VC\")]\n        public static async Task Run([ServiceBusTrigger(\"sbqfn1\", Connection = \"BrnlTest1_SERVICEBUS\")]\n         ServiceBusReceivedMessage[] msgs,\n         ServiceBusMessageActions msgActions)\n        {\n        //.....\n        await msgActions.DeadLetterMessageAsync(msg);\n        \n        }\n`\n```\nErrors Option 2:\n```\n`Microsoft.Azure.WebJobs.Host: Error indexing method 'SBQ_F1_VC'. Microsoft.Azure.WebJobs.Host: Cannot bind parameter 'msgActions' to type ServiceBusMessageActions. Make sure the parameter Type is supported by the binding. If you're using binding extensions (e.g. Azure Storage, ServiceBus, Timers, etc.) make sure you've called the registration method for the extension(s) in your startup code (e.g. builder.AddAzureStorage(), builder.AddServiceBus(), builder.AddTimers(), etc.).\n`\n```\nNotes:\n\nService Bus is 5.0.0 so I have to use `Azure.Messaging.ServiceBus` namespace\n\nThis implies the message object is `ServiceBusReceivedMessage`\n\nWhat worked (based on Jesse's and Josh's answers)\nThe Parameter Name for `ServiceBusMessageActions` MUST be `messageActions`.\nChanging this name is not tolerated for some reason...\n```\n`public static async Task Run(\n        [ServiceBusTrigger(\"sbqfn1\", Connection = \"BrnlTest1_SERVICEBUS\")]\n        ServiceBusReceivedMessage[] msgs,\n        ServiceBusMessageActions messageActions)\n        {\n`\n```",
      "solution": "You will need to use \"messageActions\" as the parameter name rather than \"msgActions\".",
      "question_score": 11,
      "answer_score": 11,
      "created_at": "2021-07-12T17:41:17",
      "url": "https://stackoverflow.com/questions/68350196/how-to-manually-handle-message-completion-in-c-azure-function-with-azure-servic"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 68371747,
      "title": "Azure C# Cosmos DB: Property &quot;id&quot; is missing when it&#39;s actually present",
      "problem": "I'm getting started with CosmosDB now and I'm running into the following error when trying to insert some data in the database:\n```\n`The input content is invalid because the required properties - 'id; ' - are missing.\n`\n```\nI understand that there should be a `string` field called `id` in my document, but the error persists even after I add `[JsonPropertyName(\"id\")]` as an annotation to my object's `Id` field.\nHere's the call to CosmosDB:\n```\n`var insertionResponse = await container.CreateItemAsync(\n    item: article,\n    partitionKey: new PartitionKey(article.Id.ToString())\n);\n`\n```\nAnd here's the `Article` class:\n```\n`public partial class Article\n{\n    [JsonPropertyName(\"id\")]\n    public Guid Id { get; set; }\n    public Guid CreatedBy { get; set; }\n    public DateTime CreatedOn { get; set; }\n\n    public string Title { get; set; }\n    public string Body { get; set; }\n}\n`\n```\nAny ideas why this is happening?",
      "solution": "The issue is happening because of different JSON libraries being used by your code and the SDK. Your code is using `System.Text.Json` whereas the SDK uses `Newtonsoft.Json` by default for serialization/deserialization. Because of this, the SDK does not understand `[JsonPropertyName(\"id\")]` attribute and does not serialize the document properly.\n2 Possible solutions:\n\nUse `Newtonsoft.Json` instead of `System.Text.Json`.\n\nConfigure the SDK to use `System.Text.Json` for serialization/deserialization. Please see this link for more details: https://github.com/ealsur/ondotnet-cosmosdb/tree/master/src/episode1/customserializer.\n\nUPDATE\nI ran into the exact same issue not too long ago and I reached out to one of the Cosmos DB SDK team member. He pointed me to the link I shared in #2 above. Caveat he mentioned is that using `System.Text.Json` might not work if you're using LINQ queries.\nOther alternative (though not recommended) is to use version 4 of the Cosmos DB SDK which uses System.Text.Json by default. It is currently in preview and as per the comments from the SDK team, there's no ETA on the release date. Furthermore, not all features that are available in SDK version 3 are available in version 4 as of now (hence \"not recommended\" comment above).\nUPDATE 2\nThere's a better implementation (than what I shared earlier in #2) of using System.Text.Json with v3 of Cosmos DB SDK. Please see this link for more details: https://github.com/Azure/azure-cosmos-dotnet-v3/tree/master/Microsoft.Azure.Cosmos.Samples/Usage/SystemTextJson.",
      "question_score": 11,
      "answer_score": 14,
      "created_at": "2021-07-14T05:44:43",
      "url": "https://stackoverflow.com/questions/68371747/azure-c-cosmos-db-property-id-is-missing-when-its-actually-present"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 65935259,
      "title": "terraform: add public IP to only one azure VM",
      "problem": "I'm creating 4 vms through count in azurerm_virtual_machine but i want to create only one public IP and associate it with the first VM ? is that possible if so how ?\nbelow is my template file\n```\n`resource \"azurerm_network_interface\" \"nics\" {\n  count               = 4\n  name                = ...\n  location            = ...\n  resource_group_name = ...\n  ip_configuration {\n    subnet_id                     = ... \n    private_ip_address_allocation = \"Static\"\n    private_ip_address = ...\n  }\n}\n\nresource \"azurerm_public_ip\" \"public_ip\" {\n  name                = ...\n  location            = ...\n  resource_group_name = ...\n}\n\nresource \"azurerm_virtual_machine\" \"vms\" {\n  count                             = 4\n  network_interface_ids             = [element(azurerm_network_interface.nics.*.id, count.index)]\n}\n`\n```\ni have already gone through below questions but they are create multiple public ip's & add them to all vms.\nmultiple-vms-with-public-ip\nset-dynamic-ip\nattach-public-ip",
      "solution": "Public IPs are created using azurerm_public_ip:\n```\n`resource \"azurerm_public_ip\" \"public_ip\" {\n  name                = \"acceptanceTestPublicIp1\"\n  resource_group_name = azurerm_resource_group.example.name\n  location            = azurerm_resource_group.example.location\n  allocation_method   = \"Dynamic\"\n}\n`\n```\nHaving the address in your `azurerm_network_interface` you could do the following using Conditional Expressions:\n```\n`resource \"azurerm_network_interface\" \"nics\" {\n  count               = 4\n  name                = ...\n  location            = ...\n  resource_group_name = ...\n\n  ip_configuration {\n\n    subnet_id                     = ... \n    private_ip_address_allocation = \"Static\"\n    private_ip_address            = ...\n    \n    public_ip_address_id = count.index == 1 ? azurerm_public_ip.public_ip.id : null\n  }\n}\n`\n```",
      "question_score": 11,
      "answer_score": 13,
      "created_at": "2021-01-28T11:28:34",
      "url": "https://stackoverflow.com/questions/65935259/terraform-add-public-ip-to-only-one-azure-vm"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 70197745,
      "title": "How to resolve &#39;Value cannot be null&#39; error when using Azure Functions Core Tools?",
      "problem": "I am using Azure Functions Core Tools from a cloned repository. When I try to run `npm run watch` this error occurs: \n`Value cannot be null. (Parameter 'provider')`\nError in Terminal\nI've installed Azure Functions Core Tools from this https://learn.microsoft.com/en-us/azure/azure-functions/functions-run-local?tabs=v3%2Clinux%2Ccsharp%2Cportal%2Cbash%2Ckeda and was logged in on azure using azure-cli. I'm currently using Ubuntu 20.04.3 LTS.",
      "solution": "There are situations in which it is best to install the Azure Function Core Tools explicitly to avoid any conflict or versioning problems:\nhttps://learn.microsoft.com/en-us/azure/azure-functions/functions-bindings-register#explicitly-install-extensions\nFurther discussion of this issue can be seen in:\nhttps://github.com/Azure/azure-functions-core-tools/issues/2232",
      "question_score": 11,
      "answer_score": 5,
      "created_at": "2021-12-02T11:25:34",
      "url": "https://stackoverflow.com/questions/70197745/how-to-resolve-value-cannot-be-null-error-when-using-azure-functions-core-tool"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67616266,
      "title": "How to Connect Visual Studio Code with Azure GIT Repo",
      "problem": "I want to connect Visual Studio Code with Azure GIT Repo.\nFor this I have Azure GIT Repo with empty files, installed VS Code which have following details and installed Azure extension (Argutec Azure Repos)\n\nWhen I type >Team: Signin I get following error\n`(team) No Azure DevOps Services or Team Foundation Server repository configuration was found. Ensure you've opened a folder that contains a repository`.\nAnd also some time I get following error\n`Command 'Team: Signin' resulted in an error (command 'team.Signin' not found)`\nhow I can git rid of above error.\nthe project I have on my local system which needs to be uploaded under Azure git repo\nEDIT\nAlso I have given the path  under Tvc: Location\n```\n`C:\\\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer\\TF.exe\n`\n```",
      "solution": "To connect VS Code with Git repository from Azure Repos, you can try like as below:\n\nIf you want push you local code to a new Git repository on Azure Repos.\n\nCreate an empty Git repository on Azure Repos. This repository does not contain any code files.\n\nOpen the folder of your local code on VS Code.\n\nGo to 'Source Control' tab on VS Code, if you local source code folder has not been initialized as a local Git repository, click 'Initialize Repository'.\n\nAfter the initialization, add the empty repository on Azure Repos as the remote of the local repository. You can navigate to '...' > 'Remote' > 'Add Remote...', enter the clone URL of the remote empty repository, and provide a remote name. When the first time to connect the remote, you may be asked to provide your login authentication such as you email and password.\n\nCommit and push the code files from the local repository to the remote repository. After completing the push, you can open or refresh the web page of the remote repository, then you can see the code files haven been pushed to the remote.\n\nIf you want to connect to an existing and not empty remote Git repository on Azure Repos.\n\nOpen VS Code to clone the remote repository to local.\n\nNavigate to 'Source Control' tab on VS Code, click 'Clone Repository', enter the clone URL of the remote repository. After completing the clone, you can click the 'Open' button to directly open the local repository on VS Code. When the first time to connect the remote, you may be asked to provide your login authentication such as you email and password.\n\nAfter you make some changes on the local repository, then commit and push these changes to the remote repository.",
      "question_score": 10,
      "answer_score": 30,
      "created_at": "2021-05-20T09:57:15",
      "url": "https://stackoverflow.com/questions/67616266/how-to-connect-visual-studio-code-with-azure-git-repo"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 66468815,
      "title": "How to publish docker image as an artifact in azure devops",
      "problem": "I am building a Docker image in my Azure pipeline. Now, I want to push this image to multiple aws accounts(dev, stage, prod) depending on the configuration parameters. The problem is, image is not available in publish artifact. I came across this and this article during my research. I am confused about the solution regarding saving the docker image so it can be available in publish artifact. I have two specific questions:\n\nHow will I use the `docker save` command in Azure pipeline task after docker build. The available docker task doesn't have this command.\nIs there any better way of doing this apart from saving an image.",
      "solution": "After a lot of reserach I found this article which resolved my issue https://dev.to/n3wt0n/container-image-promotion-across-environments-build-artifact-5887\nNote: We can manually add commands which are not present in the Docker task snippet available in Azure DevOps. This is also mentioned in the article and steps to do this.",
      "question_score": 10,
      "answer_score": 6,
      "created_at": "2021-03-04T05:56:34",
      "url": "https://stackoverflow.com/questions/66468815/how-to-publish-docker-image-as-an-artifact-in-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 73293980,
      "title": "Terraform: Failed to query available provider packages (Azapi)",
      "problem": "I try to use the Azure/Azapi Provider within my Terraform project but after I add the provider and run `terraform init`, I get the following error:\n```\n`Error: Failed to query available provider packages\nCould not retrieve the list of available versions for provider hashicorp/azapi: provider registry registry.terraform.io does not have a provider named registry.terraform.io/hashicorp/azapi \n`\n```\nThis is how my providers.tf looks like:\n```\n`terraform {\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"=3.16.0\"\n    }\n    azapi = {\n      source  = \"azure/azapi\"\n      version = \"=0.4.0\"\n    }\n\n  }\n\n  required_version = \"=1.2.6\"\n}\n\nprovider \"azurerm\" {\n  features {}\n}\n\nprovider \"azapi\" {\n}\n`\n```\nWhen I run `terraform providers`, I can see that the provider has a wrong registry URL within my module:\n```\n`\u251c\u2500\u2500 module.az-aca-env\n\u2502   \u2514\u2500\u2500 provider[registry.terraform.io/hashicorp/azapi]\n`\n```\nI would expect something like registry.terraform.io/azure/azapi.\nAny ideas?",
      "solution": "Okay, I found a workaround. I have to add a `providers.tf` inside my module directory (/modules/az-aca-env) with the following content:\n```\n`terraform {\n  required_providers {\n    azapi = {\n      source  = \"Azure/azapi\"\n      version = \"=0.4.0\"\n    }\n  }\n}\n`\n```\nAfter adding it, the `terraform init` works \u2705.",
      "question_score": 10,
      "answer_score": 20,
      "created_at": "2022-08-09T16:58:16",
      "url": "https://stackoverflow.com/questions/73293980/terraform-failed-to-query-available-provider-packages-azapi"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 72879892,
      "title": "What and where is Azure App Service Default Timeout value?",
      "problem": "Can default timeout of Azure app service be viewed or changed in Azure using portal / Powershell / CLI?\nHere is reference from General Settings: I could find none.",
      "solution": "According to MughundhanRaveendran and KetanChawda:\n\n230 seconds is a default timeout configured at the Azure App service load balancer.\nThis is a part of the Azure App service architecture and cannot be configured or changed.\n\nReferences: Why does my request time out after 230 seconds?, Time Out After 230 seconds and Increase azure web app request timeout",
      "question_score": 10,
      "answer_score": 21,
      "created_at": "2022-07-06T10:05:51",
      "url": "https://stackoverflow.com/questions/72879892/what-and-where-is-azure-app-service-default-timeout-value"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67827882,
      "title": "How do I use both a variable group and variables in the variable section of a YAML file?",
      "problem": "I've created a variable group in an Azure Pipeline library. It has the password to a certificate I want to apply to signing the executables during the Azure build pipeline. I've encrypted the password by clicking on the lock icon. The problem I'm having is I've got other variables, not a part of the variable group, which I'm including in the `variables` section of the YAML file. I'm getting error, telling me it is an invalid YAML file. Here's what I've got:\n`variables:\n  solution: '**/*.sln'\n  buildPlatform: 'Any CPU'\n  DOTNET_SKIP_FIRST_TIME_EXPERIENCE: true\n  buildConfiguration: 'Release'\n  Binaries: test\n- group: 'acdc-pipeline-group'\n`\nI've tried to find a way of doing this, but the documentation I've found only lists the variable group by itself in the `variables` section. Unless I'm misunderstanding the linked documentation: Add & use variable groups\nI've made a mistake in the `variables`, but I'm not sure what I've done wrong.",
      "solution": "So I think it should be something like:\n```\n`variables:\n- name: solution\n  value: '**/*.sln'\n- name: buildPlatform\n  value: 'Any CPU'\n- name: DOTNET_SKIP_FIRST_TIME_EXPERIENCE: \n  value: true\n- name: buildConfiguration\n  value: 'Release'\n- name: Binaries\n  value: test\n- group: 'acdc-pipeline-group'\n`\n```\nThen you can use your variable like `$(YOURVARIABLEFROMTHEGROUP)` or `$[variables.YOURVARIABLEFROMTHEGROUP]`\nActually, that is somewhat mentioned at the docs you reference, although in a bit confusing and implicit manner and with no proper example, so let here be one :)",
      "question_score": 10,
      "answer_score": 18,
      "created_at": "2021-06-03T21:50:40",
      "url": "https://stackoverflow.com/questions/67827882/how-do-i-use-both-a-variable-group-and-variables-in-the-variable-section-of-a-ya"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 68919661,
      "title": "Azure, .Net, Cobertura - ##[warning]Multiple file or directory matches were found",
      "problem": "Hi i am trying to get code coverage with .net5 in azure pipeline.\nRun tests (not entire file)\n```\n`Starting test execution, please wait...\nA total of 1 test files matched the specified pattern.\nResults File: /home/vsts/work/_temp/_fv-az43-964_2021-08-25_08_31_59.trx\n\nAttachments:\n  /home/vsts/work/_temp/f5dd5e9f-e260-437d-80ef-4fb917215b09/coverage.cobertura.xml\nPassed!  - Failed:     0, Passed:    16, Skipped:     0, Total:    16, Duration: 732 ms - /home/vsts/work/1/s/sda2021_webapi/Test/sda2021_api.tests/bin/Release/net5.0/sda2021_webapi.tests.dll (net5.0)\nResult Attachments will be stored in LogStore\nRun Attachments will be stored in LogStore\nInfo: Azure Pipelines hosted agents have been updated and now contain .Net 5.x SDK/Runtime along with the older .Net Core version which are currently lts. Unless you have locked down a SDK version for your project(s), 5.x SDK might be picked up which might have breaking behavior as compared to previous versions. You can learn more about the breaking changes here: https://learn.microsoft.com/en-us/dotnet/core/tools/ and https://learn.microsoft.com/en-us/dotnet/core/compatibility/ . To learn about more such changes and troubleshoot, refer here: https://learn.microsoft.com/en-us/azure/devops/pipelines/tasks/build/dotnet-core-cli?view=azure-devops#troubleshooting\nAsync Command Start: Publish test results\nPublishing test results to test run '5152'.\nTestResults To Publish 16, Test run id:5152\nTest results publishing 16, remaining: 0. Test run id: 5152\nPublished Test Run : https://dev.azure.com/sda-shs/Bratislava2021/_TestManagement/Runs?runId=5152&_a=runCharts\nAsync Command End: Publish test results\nFinishing: Dotnet run tests\n`\n```\nPublish tests(not entire file)\n```\n`##[warning]Multiple file or directory matches were found. Using the first match: /home/vsts/work/_temp/_fv-az43-964_2021-08-25_08_31_59/In/fv-az43-964/coverage.cobertura.xml\n/opt/hostedtoolcache/dotnet/dotnet /home/vsts/work/_tasks/PublishCodeCoverageResults_2a7ebc54-c13e-490e-81a5-d7561ab7cd97/1.189.0/netcoreapp2.0/ReportGenerator.dll -reports:/home/vsts/work/_temp/**/coverage.cobertura.xml -targetdir:/home/vsts/work/_temp/cchtml -reporttypes:HtmlInline_AzurePipelines\n2021-08-25T08:32:03: Arguments\n2021-08-25T08:32:03:  -reports:/home/vsts/work/_temp/**/coverage.cobertura.xml\n`\n```\nAnd of course my pipeline\n```\n`task: DotNetCoreCLI@2\n            displayName: Dotnet run tests\n            inputs:\n              command: \"test\"\n              projects: \"**/xxxxx/*.tests.csproj\"\n              arguments: '--configuration Release /p:CoverletOutputFormat=cobertura --collect:\"XPlat Code Coverage\" --no-build'\n              testRunTitle: \"xxxx\"\n          - task: PublishCodeCoverageResults@1\n            displayName: \"publish coverage results\"\n            inputs:\n              codeCoverageTool: \"Cobertura\"\n              summaryFileLocation: \"$(Agent.TempDirectory)/**/coverage.cobertura.xml\"\n`\n```\nWhy is more then one XML generated? I am basically balancing between no XML and more XML. I am just unable to generate one XML. (on my localhost it generates only one) Thanks for any tips.",
      "solution": "UPDATE 06.05.2024\nYou can use version 2 which allows you to pass multiple files without merging them first:\n`       - task: PublishCodeCoverageResults@2\n         displayName: 'Publish code coverage results'\n         inputs:\n           codeCoverageTool: Cobertura\n           summaryFileLocation: '$(Agent.TempDirectory)/**/coverage.cobertura.xml'\n`\n\nsummaryFileLocation - Path to summary files\nSpecifies the path of the summary file containing code coverage statistics, such as line, method, and class coverage. Multiple summary files are merged into a single report. The value may contain minimatch patterns. For example: $(System.DefaultWorkingDirectory)/MyApp/**/site/cobertura/coverage.xml\n\nOLD ANSWER\nPlease replace your `PublishCodeCoverageResults` with the following steps:\n`       - task: reportgenerator@4\n         displayName: 'Merge code coverage reports'\n         inputs:\n           reports: '$(Agent.TempDirectory)/**/coverage.cobertura.xml'\n           targetdir: '$(Pipeline.Workspace)/coverlet'\n           reporttypes: 'Cobertura'\n           verbosity: 'Verbose'\n     \n       - task: PublishCodeCoverageResults@1\n         displayName: 'Publish code coverage results'\n         inputs:\n           codeCoverageTool: Cobertura\n           summaryFileLocation: '$(Pipeline.Workspace)/coverlet/Cobertura.xml'\n`\nAnd you have multiple files, because probably you have more than one test project.",
      "question_score": 10,
      "answer_score": 17,
      "created_at": "2021-08-25T10:45:35",
      "url": "https://stackoverflow.com/questions/68919661/azure-net-cobertura-warningmultiple-file-or-directory-matches-were-foun"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 70258235,
      "title": "How can I view logs in Application Insights?",
      "problem": "I created Web application in App Service using a custom container from Azure Container Registry, enabled File System logging for it, add Application Insights for this app service. Application write logs to this app insights. But how can I see those logs in Azure portal? I open \"Logs\" sub-menu in Application Insights and see here \"Queries\". What am I doing wrong?\nWhy Azure can't provide just full logs in the portal?",
      "solution": "`Application Insights` -> `Transaction search`\nHere you can filter data by TRACE type and it is your application logs",
      "question_score": 10,
      "answer_score": 16,
      "created_at": "2021-12-07T11:08:48",
      "url": "https://stackoverflow.com/questions/70258235/how-can-i-view-logs-in-application-insights"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 76995900,
      "title": "How to grant a Managed Identity permissions to an Azure SQL Database using IaC?",
      "problem": "I use GitHub actions to spin up Azure resources from scratch using Infrastructure as Code (IaC). In my case Bicep, but it could be Terraform. This includes an Azure SQL Server, a SQL Database, and a User Assigned Managed Identity. After the resources are created I'm trying to get the GitHub action to grant the managed identity access to the database using this SQL script:\n```\n`CREATE USER [MyManagedIdentity] FROM EXTERNAL PROVIDER;\nALTER ROLE db_datareader ADD MEMBER [MyManagedIdentity];\nALTER ROLE db_datawriter ADD MEMBER [MyManagedIdentity];\n`\n```\nThis is however failing because this requires that either the SQL Server or the GitHub action needs to read the Managed Identity from the Azure AD. Even if I manually add the Service Principal used by the GitHub action to the built-in \"Directory Readers\" role group (or to the Global Administrator for testing purposes) this does not work. I'm also unable to get the GitHub action to grant the SQL Server permissions to read the Active Directory (e.g. add it to the \"Directory Readers\" role).\nIt's a catch-22. After spending too much time on this, I believe it's not possible to create a new Azure SQL Server, a SQL Database, and a managed identity using Infrastructure as Code (IaC) and grant the Managed Identity reader and writer access to the database, but I would love to be proven wrong.\nIf I login to the SQL database with my own user (who is the Azure Admin on the SQL Server), this works fine. I assume it works because a normal AD user can read the Active Directory. It seems like an Azure service principal cannot be granted these permissions.\nIf I manually add the Azure SQL Server to the \"Directory Readers\" built-in Azure role, it also works. But I want to avoid manual steps, as I plan to create many Azure databases.\nI'm okay with having a few manual steps when setting up the GitHub workflow, the Azure AD, and the Azure subscription. But my goal is to have all Azure resources from that point created using Infrastructure as Code, orchestrated from a GitHub action. Another goal is to have everything created without having any secrets, so a solution where I have AD username and password as GitHub secrets are also not acceptable. The GitHub Action uses a service principal that is using the new federated credentials instead of secrets, so I truly mean \"no secrets\".\nI'm building a multi-tenant SaaS reference architecture called PlatformPlatform with .NET, DDD, Clean Architecture, CQRS, ASP.NET Minimal API, TypeScript, GitHub actions, IaC, Azure Container Apps, and you guessed it: \"enterprise grade security\". So if you need to have access to a test out a solution you can find a full example on GitHub. If anyone can solve this problem I will of course mark the correct answer, but you will also be able to see whatever workaround I find on GitHub.",
      "solution": "When you run the command `CREATE USER [] FROM EXTERNAL PROVIDER;`, it creates an entry in the `[sys].[database_principals]` table.\nAzure SQL will retrieve the managed identity AppId/ClientId connecting to AAD. That's why the user/principal running your Iac code needs directory read permission.\nThe AppId/ClientId is then converted to varbinary and inserted in the `[sys].[database_principals]` table as the sid (Security Identifier).\nSo `CREATE USER [] FROM EXTERNAL PROVIDER;` is equivalent to `CREATE USER [] WITH DEFAULT_SCHEMA=[dbo], SID = '', TYPE = 'E';`\nUsing powershell (as an example), you can convert the AppId/ClientId to sid like that:\n```\n`$appId = 'xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx'\n$sid = \"0x\" + [System.BitConverter]::ToString(([guid]$appId).ToByteArray()).Replace(\"-\", \"\")\n`\n```\nSo in your IaC pipeline:\n\nCreate the Azure SQL DB\nCreate the managed identity and retrieve the AppId/ClientId\nConvert the AppId/ClientId to sid\nInvoke SQL server (SqlCommand) to create the the sql user and grant it the required permissions.",
      "question_score": 10,
      "answer_score": 12,
      "created_at": "2023-08-28T22:41:34",
      "url": "https://stackoverflow.com/questions/76995900/how-to-grant-a-managed-identity-permissions-to-an-azure-sql-database-using-iac"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 68070143,
      "title": "Azure Blob Storage SDK v12 - BlobClient DownloadAsync gone?",
      "problem": "I have production code that uses the `BlobClient.DownloadAsync()` method to download a file from Azure Blob Storage using the `Azure.Storage.Blobs` nuget package v12.8, and it seems to be working just fine.  However, I upgraded the nuget package and was about to write some new code to deal with zip files, that also relies on downloading in order to extract the zip...but noticed some changes in the latest APIs of the Storage SDK.\nApart from nearly EVERY sample from Microsoft, as well as from the interwebs, being slightly incorrect since that method wraps the returned `BlobDownloadInfo` into a `Response` object - forcing you to do a call to `.Value` first, they also seem to use the above method to download blob files - BUT I can no longer find that method via Intellisense.\nWhen I looked at the source which takes me to `BlobBaseClient.DownloadAsync()` method, I see that it is decorated with `[EditorBrowsable(EditorBrowsableState.Never)]`, implying that  this API might slowly be taken away via hiding it from devs, but without breaking existing code or marking as `Obsolete`.  But I can't find any articles/issues/docs that point to that for sure. Here's what that looks like:\n\nWith that being said.....what is THE way someone should be downloading files from Azure Blob Storage (block blobs) using the .NET SDK as of v12.9, in an asynchronous fashion, if the goal is to \"stream\" it down thru an ASP.NET controller action (REST endpoint) to a client like a browser, etc. (NOT save to a local file on server)?\nThere seems to be several available \"download\" APIs on the `BlobClient`, but their docs are somewhat vague or ambiguous and the MS Docs don't seem to clarify any further:\n\nDownloadAsync() - marked as not browsable, but de facto way, based on all samples/blogs\nDownloadStreamingAsync()\nDownloadContentAsync()\nDownloadToAsync()\nOpenReadAsync()\n\nAdditionally, if trying to do some other operation that is not downloading to a browser client via a REST API, for example, if you're unzipping a blob file and the extracted files are also going into blob storage, would one be better not downloading but instead opening it via `OpenReadAsync()`?",
      "solution": "For anyone else coming to this trying to figure out how to stream/download files from Azure blob storage into an object,the OP Github issue is the best documentation I have come across.\nIn short the main methods to use:\n```\n`DownloadContentAsync() - preferred way to fetch blobs that fit in memory\nDownloadStreamingAsync() - stream when bandwidth adequate (otherwise OpenReadAsync)\nOpenReadAsync() - fetches buffered chunks when bandwidth inadequate or consumer slow (otherwise DownloadStreamingAsync)\n`\n```\nDo not use:\n```\n`DownloadAsync() - replaced by DownloadStreamingAsync()\n`\n```\nWhen you simply want to download a file from blob storage:\n```\n`DownloadToAsync() - downloads a blob using parallel requests, and writes the content to destination\n`\n```\nDownloadContentAsync is very useful.\nFor JSON files and other small blobs this conveniently provides the data as BinaryData allowing you to easily retrieve commonly used primitives (string, streams, bytes).\nExample:\n```\n`BlobContainerClient containerClient = new BlobContainerClient(_settings.ConnectionString, _settings.ContainerName);\n    \nvar blobClient = containerClient.GetBlobClient($\"{folderName}/{fileName}\");\n    \nBlobDownloadResult download = await blobClient.DownloadContentAsync();\n    \nMyJSONData json = download.Content.ToObjectFromJson();\n`\n```",
      "question_score": 10,
      "answer_score": 13,
      "created_at": "2021-06-21T16:54:02",
      "url": "https://stackoverflow.com/questions/68070143/azure-blob-storage-sdk-v12-blobclient-downloadasync-gone"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 70778809,
      "title": "How to retrieve blobs within a blob directory path using the Azure.Storage.Blobs BlobClient?",
      "problem": "I'm not seeing any examples online on how to get all the blobs located inside a certain directory within a `BlobContainerClient`.\nPreviously, I was using the `Microsoft.Azure.Storage` packages, but those have since been deprecated. My old code that was scanning a directory for all blobs was:\n```\n`public async Task ListAllBlobs(string path)\n{\n    var myContainer = await GetCloudBlobClientAsync();\n    var directory = myContainer.GetDirectoryReference(path);\n    var blobs = await directory.ListBlobsSegmentedAsync(true, BlobListingDetails.None, \n        blobSettings.MaxResult, null, null, null);\n    var results = blobs.Results;\n\n    foreach(CloudBlockBlob b in results)\n    {\n        // non-relevant code\n    }\n}\n\nprivate async Task GetCloudBlobClientAsync()\n{\n    var storageAccount = CloudStorageAccount.Parse(azureBlobStorageConnectionString);\n    var blobClient = storageAccount.CreateCloudBlobClient();\n    var container = blobClient.GetContainerReference(blobStorageSettings.ContainerName);\n\n    if (!await container.ExistsAsync())\n    {\n        await container.CreateAsync();\n    }\n\n    return container;\n}\n`\n```\nEssentially, I'm moving the above code from `Microsoft.Azure.Storage` over to `Azure.Storage.Blobs`.\nIf I were to recreate the `ListAllBlobs(string path)` function to use `Azure.Storage.Blobs`, I'm confused on how to setup a container and then access an inner container based on a path that's passed in - then cycle through the blobs that exist within that container. Can anyone help?\nHere's what I have so far:\n```\n`public async Task ListAllBlobs(string path)\n{\n    var myContainer = await GetCloudBlobClientAsync();\n    var directory = myContainer.GetBlobClient(path);\n\n    // This doesn't work because I can't do 'GetBlobs' on the Client, only on the container.\n    foreach(BlobItem blob in directory.GetBlobs(Blobtraits.None, BlobStates.None, string.Empty))\n    {\n        // more non-relevant code\n    }\n}\n`\n```\nTo clarify, in the above code, it doesn't like that I'm calling `GetBlobs` on a Client, rather than on the Container, but I can't pass in a path to the container.",
      "solution": "You were almost there. You would still use `BlobContainerClient` and call `GetBlobsAsync` method on that. What you missed is that you will need to set the `prefix` parameter's value as the `path`.\nSo your code would be something like:\n```\n`var myContainer = await GetCloudBlobClientAsync();\nvar blobsListingResult = await myContainer.GetBlobsAsync(prefix=path);\n`\n```\nUPDATE\nPlease try the following code:\n```\n`var myContainer = await GetCloudBlobClientAsync();\nawait foreach (BlobItem blob in myContainer.GetBlobsAsync(BlobTraits.None, BlobStates.None, path))\n{\n  names.Add(blob.Name);\n}\n`\n```",
      "question_score": 10,
      "answer_score": 5,
      "created_at": "2022-01-19T23:57:45",
      "url": "https://stackoverflow.com/questions/70778809/how-to-retrieve-blobs-within-a-blob-directory-path-using-the-azure-storage-blobs"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67845857,
      "title": "Can a &quot;User Assigned Managed Identity&quot; be used locally?",
      "problem": "I am trying to use a `User Assigned Managed Identity` in one of our applications. I also read about the differences between `System Assigned Managed Identity and User Assigned Managed Identity`.\nIt is very clear to me that a `System Assigned Managed Identity` cannot be used locally as there you're assigning an identity to an Azure Resource.\nHowever I am not clear if a `User Assigned Managed Identity` can be used locally. Only thing I could find is the following:\n\nIn my scenario, I would like to read some secrets from an Azure Key Vault. I have created a User Assigned Managed Identity and configured access policies on the Key Vault to give necessary permissions to this identity. Considering I am using this identity to access Azure Key Vault (which is an Azure resource), my expectation is that it should work regardless of the location (using JetBrains Rider as my IDE) from where my code is running.\nHowever when I try to do something like:\n```\n`var managedIdentityCredential = new ManagedIdentityCredential(\"managed-identity-id\");\nSecretClient secretClient = new(new Uri(\"https://mykeyvault.vault.azure.net/\"), managedIdentityCredential);\nKeyVaultSecret secret = await secretClient.GetSecretAsync(key);\n`\n```\nI get the `Azure.Identity.CredentialUnavailableException` with `ManagedIdentityCredential authentication unavailable. No Managed Identity endpoint found` error message when I run the code locally:\n```\n`Azure.Identity.CredentialUnavailableException: ManagedIdentityCredential authentication unavailable. No Managed Identity endpoint found.\n   at Azure.Identity.ManagedIdentityClient.AuthenticateAsync(Boolean async, TokenRequestContext context, CancellationToken cancellationToken)\n   at Azure.Identity.ManagedIdentityCredential.GetTokenImplAsync(Boolean async, TokenRequestContext requestContext, CancellationToken cancellationToken)\n   at Azure.Identity.CredentialDiagnosticScope.FailWrapAndThrow(Exception ex)\n   at Azure.Identity.ManagedIdentityCredential.GetTokenImplAsync(Boolean async, TokenRequestContext requestContext, CancellationToken cancellationToken)\n   at Azure.Identity.ManagedIdentityCredential.GetTokenAsync(TokenRequestContext requestContext, CancellationToken cancellationToken)\n   at Azure.Security.KeyVault.ChallengeBasedAuthenticationPolicy.AuthenticateRequestAsync(HttpMessage message, Boolean async, AuthenticationChallenge challenge)\n   at Azure.Security.KeyVault.ChallengeBasedAuthenticationPolicy.ProcessCoreAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\n   at Azure.Core.Pipeline.RetryPolicy.ProcessAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\n   at Azure.Core.Pipeline.RetryPolicy.ProcessAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\n   at Azure.Core.Pipeline.HttpPipeline.SendRequestAsync(Request request, CancellationToken cancellationToken)\n   at Azure.Security.KeyVault.KeyVaultPipeline.SendRequestAsync(Request request, CancellationToken cancellationToken)\n   at Azure.Security.KeyVault.KeyVaultPipeline.SendRequestAsync[TResult](RequestMethod method, Func`1 resultFactory, CancellationToken cancellationToken, String[] path)\n   at Azure.Security.KeyVault.Certificates.CertificateClient.GetCertificateAsync(String certificateName, CancellationToken cancellationToken)\n`\n```\nAny insights into this will be highly appreciated.",
      "solution": "No. User managed identity is also not supported with `ManagedIdentityCredential` in the local environment.\nYou should use DefaultAzureCredential for the code to work in local environment.\nSee the Note tip here.\n\nNote\nThe `ManagedIdentityCredential` works only in Azure environments of\nservices that support managed identity authentication. It doesn't work\nin the local environment. Use DefaultAzureCredential for the code\nto work in both local and Azure environments as it will fall back to a\nfew authentication options including managed identity.\nIn case you want to use a user-asigned managed identity with the\n`DefaultAzureCredential` when deployed to Azure, specify the\nclientId.",
      "question_score": 10,
      "answer_score": 10,
      "created_at": "2021-06-05T04:55:32",
      "url": "https://stackoverflow.com/questions/67845857/can-a-user-assigned-managed-identity-be-used-locally"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 68334416,
      "title": "ERROR: The requested resource requires user authentication: in AzureCLI task build pipeline",
      "problem": "I am unable to trigger azure pipeline build from azureCLI task\nTask :\n```\n`- task: AzureCLI@2\n  inputs:\n    azureSubscription: 'Free Trial(My subscription)'\n    scriptType: 'pscore'\n    scriptLocation: 'inlineScript'\n    inlineScript: |\n      az --version\n      echo \"Running : az account show\"\n      az account show\n      #export AZURE_DEVOPS_EXT_PAT='mypat'\n      $env:AZURE_DEVOPS_EXT_PAT='mypat'\n      az pipelines create --name newPipeline --org https://dev.azure.com/AbiNilOrg/ --project azure-devops-kubernetes-terraform --branch master\n`\n```\nThe output with error :\n```\n`Running : az account show\n{\n  \"environmentName\": \"AzureCloud\",\n  \"homeTenantId\": \"***\",\n  \"id\": \"73c1af29-384c-4574-bd88-92d7bb392cfc\",\n  \"isDefault\": true,\n  \"managedByTenants\": [],\n  \"name\": \"Free Trial\",\n  \"state\": \"Enabled\",\n  \"tenantId\": \"***\",\n  \"user\": {\n    \"name\": \"***\",\n    \"type\": \"servicePrincipal\"\n  }\n}\nWARNING: This command is in preview and under development. Reference and support \nlevels: https://aka.ms/CLI_refstatus\nERROR: The requested resource requires user authentication: \nhttps://dev.azure.com/AbiNilOrg/azure-devops-kubernetes- \nterraform/_apis/serviceendpoint/endpoints\n##[error]Script failed with exit code: 1\n`\n```\nI understand that azure is unable to form the correct URI to hit the rest point\n```\n`ERROR: The requested resource requires user authentication: \nhttps://dev.azure.com/AbiNilOrg/azure-devops-kubernetes- \nterraform/_apis/serviceendpoint/endpoints\n`\n```\nThe suffix serviceendpoint/endpoints of the URI isnt correct.\nADO guys, if have any idea on this can please help!\nThanks in advace!\nNilotpal",
      "solution": "When you set `env:AZURE_DEVOPS_EXT_PAT` you still need to login via calling:\n```\n`az devops login --organization https://dev.azure.com/contoso\n`\n```\nbecause:\n\nIf you have already signed in with az login interactively or using user name and password, then you don't have to provide a token as az devops commands now support sign in through az login. However, service principal log in via az login isn't supported, in which case a PAT token is required.\n\nAnd here this task behing the scene login via service principal what you also see on account show:\n`  \"user\": {\n    \"name\": \"***\",\n    \"type\": \"servicePrincipal\"\n  }\n`\nFor more details please check documentation here",
      "question_score": 10,
      "answer_score": 8,
      "created_at": "2021-07-11T10:15:17",
      "url": "https://stackoverflow.com/questions/68334416/error-the-requested-resource-requires-user-authentication-in-azurecli-task-bui"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 77694659,
      "title": "Azure Function - Error building configuration in an external startup class",
      "problem": "I'm using an Azure Function in \".Net 8\", I'm trying to use a custom start-up by following this article here.\nhere is the custom start-up:\n```\n`using System;\nusing System.IO;\nusing Microsoft.Azure.Functions.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Configuration;\nusing Microsoft.Extensions.DependencyInjection;\nusing System.Xml.Linq;\n\n[assembly: FunctionsStartup(typeof(Startup))]\n\nnamespace Function;\n\npublic class Startup : FunctionsStartup\n{\n    private IConfiguration Configuration { get; set; }\n\n    public override void Configure(IFunctionsHostBuilder builder)\n    {\n        builder.Services.AddHttpClient();\n    }\n\n    public override void ConfigureAppConfiguration(IFunctionsConfigurationBuilder builder)\n    {\n        var context = builder.GetContext();\n\n        builder.ConfigurationBuilder\n            .AddJsonFile(Path.Combine(context.ApplicationRootPath, \"function.json\"), optional: true, reloadOnChange: false)\n            .AddJsonFile(Path.Combine(context.ApplicationRootPath, $\"function.{context.EnvironmentName}.json\"), optional: true, reloadOnChange: false)\n            .AddEnvironmentVariables();\n    }\n}\n`\n```\nBut When I run the function, I'm getting the following error:\n```\n`Error building configuration in an external startup class.\nError building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nA host error has occurred during startup operation '2fff8edb-0e76-4789-b51b-bdcbea0ad107'.\nMicrosoft.Azure.WebJobs.Script: Error building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nValue cannot be null. (Parameter 'provider')\nPress any key to continue....[2023-12-20T21:35:26.832Z] Error building configuration in an external startup class.\nError building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nA host error has occurred during startup operation 'e8145c61-4903-402b-b164-3f9c3866817e'.\nMicrosoft.Azure.WebJobs.Script: Error building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nError building configuration in an external startup class.\nError building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nA host error has occurred during startup operation '7b68f1b4-7d74-4221-afe2-13ec1ab77ef7'.\nMicrosoft.Azure.WebJobs.Script: Error building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nError building configuration in an external startup class.\nError building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nA host error has occurred during startup operation '9c04f584-294b-4f01-9c70-ba1df345ce13'.\nMicrosoft.Azure.WebJobs.Script: Error building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nError building configuration in an external startup class.\nError building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nA host error has occurred during startup operation '2f294885-00a4-46a1-b4f8-5cb7c55ac9b0'.\nMicrosoft.Azure.WebJobs.Script: Error building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nError building configuration in an external startup class.\nError building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nA host error has occurred during startup operation '0b2168d4-efdc-4cdc-8100-2575c5b0a77a'.\nMicrosoft.Azure.WebJobs.Script: Error building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nError building configuration in an external startup class.\nError building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\nA host error has occurred during startup operation 'd2ba0a10-bbe7-4dea-a11d-ca64de26ea84'.\nMicrosoft.Azure.WebJobs.Script: Error building configuration in an external startup class. Function: Could not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=8.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.\n`\n```\nHere are also my package references:\n```\n`\n\n`\n```\nhost.json:\n```\n`{\n  \"version\": \"2.0\",\n  \"logging\": {\n    \"applicationInsights\": {\n      \"samplingSettings\": {\n        \"isEnabled\": true,\n        \"excludedTypes\": \"Request\"\n      },\n      \"enableLiveMetricsFilters\": true\n    }\n  }\n}\n`\n```\nI looked at similar questions and problems in different links but couldn't find any solution.",
      "solution": "As I mentioned in the comments, .NET 8 Isolated function doesn't have a separate Startup class.\nThe Startup class you are using supports In-Process Functions.\n\nMSDOC states that isolated functions contain a `Program.cs` file which provides complete access to the Host instance for setting any code configurations & dependencies.\nRefer GitHub for sample project of .NET 8 Isolated function.\n\nCreated a .NET 8 Isolated function:\n\nMy Program.cs:\n`using Microsoft.Azure.Functions.Worker;\nusing Microsoft.Extensions.Configuration;\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Hosting;\n\nvar host = new HostBuilder()\n    .ConfigureFunctionsWorkerDefaults()\n    .ConfigureServices(services =>\n    {\n        services.AddApplicationInsightsTelemetryWorkerService();\n        services.ConfigureFunctionsApplicationInsights();\n    })\n    .ConfigureAppConfiguration((hostingContext, configBuilder) =>\n    {\n        var env = hostingContext.HostingEnvironment;\n        configBuilder\n          .AddJsonFile($\"appsettings.json\", optional: true, reloadOnChange: true)\n          .AddJsonFile($\"appsettings.{env.EnvironmentName}.json\", optional: true, reloadOnChange: true)\n          ;\n    })\n    .Build();\n\nhost.Run();\n`\nFunction.cs:\n`public class Function1\n{\n    private readonly ILogger _logger;\n\n    public Function1(ILogger logger)\n    {\n        _logger = logger;\n    }\n\n    [Function(nameof(Function1))]\n    public void Run([QueueTrigger(\"myqueue-items\", Connection = \"demo\")] QueueMessage message)\n    {\n        _logger.LogInformation($\"C# Queue trigger function processed: {message.MessageText}\");\n    }\n`\n.csproj:\n`\n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n`\nConsole Response:\n```\n`Azure Functions Core Tools\nCore Tools Version:       4.0.5455 Commit hash: N/A  (64-bit)\nFunction Runtime Version: 4.27.5.21554\n\n[2023-12-21T13:30:44.145Z] Found C:\\Users\\username\\Source\\Repos\\FunctionApp20\\FunctionApp20\\FunctionApp20.csproj. Using for user secrets file configuration.\n[2023-12-21T13:30:51.827Z] Azure Functions .NET Worker (PID: 31452) initialized in debug mode. Waiting for debugger to attach...\n[2023-12-21T13:30:51.980Z] Worker process started and initialized.\n\nFunctions:\n\n        Function1: queueTrigger\n\nFor detailed output, run func with --verbose flag.\n[2023-12-21T13:31:37.924Z] Host lock lease acquired by instance ID '000000000000000000000000F72731CC'.\n[2023-12-21T13:33:05.554Z] Executing 'Functions.Function1' (Reason='New queue message detected on 'myqueue-items'.', Id=5ebXXXXXXX5ade3)\n[2023-12-21T13:33:05.560Z] Trigger Details: MessageId: b47f66XXXXXXXXXXXXXd2793e21d, DequeueCount: 1, InsertedOn: 2023-12-21T13:33:02.000+00:00\n[2023-12-21T13:33:06.055Z] C# Queue trigger function processed: Hello world\n[2023-12-21T13:33:06.155Z] Executed 'Functions.Function1' (Succeeded, Id=5eb356d2-e5dc-XXXXXXXXXXXXd67025ade3, Duration=703ms)\n`\n```",
      "question_score": 10,
      "answer_score": 5,
      "created_at": "2023-12-20T22:47:07",
      "url": "https://stackoverflow.com/questions/77694659/azure-function-error-building-configuration-in-an-external-startup-class"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 68726691,
      "title": "BrowserAuthError: interaction_in_progress - Unable to fix, regardles of solutions found",
      "problem": "I'm implementing security for the applications at the company I'm working at right now. I'm using `@azure/msal-angular@2.0.2`, `@azure/msal-browser@2.16.1`. I followed the example found here\nand got it working for the first application. I went on to implement it for the next application, which is basically the same one, just talks to a different api, but the complexity is the same. After possibly doing something wrong I keep getting the error:\n```\n`core.js:6157 ERROR Error: Uncaught (in promise): BrowserAuthError: interaction_in_progress: Interaction is currently in progress. Please ensure that this interaction has been completed before calling an interactive API.  For more visit: aka.ms/msaljs/browser-errors.\nBrowserAuthError: interaction_in_progress: Interaction is currently in progress. Please ensure that this interaction has been completed before calling an interactive API.  For more visit: aka.ms/msaljs/browser-errors.\n`\n```\nI found several other posts that said to clear the caches, storages etc... But none of it works. All it does is prompt me to log in again, only to fill in the sessionStorage back with the same entries, amongst them the entry that says `msal.442edcf7-9e0c-469b-93fb-daa1839724bd.interaction.status` `interaction_in_progress`. As far as I know I've tried everthing I've found. Also the solution from AzureAD themselves doesn't work.\nI'm very new to this so I might have missed something simple, if so, my apologies.\nMy code can be found below.\nAngular version\n`11.0.2`\napp.module.ts\n```\n`import {\n  MsalBroadcastService,\n  MsalGuard,\n  MsalInterceptor,\n  MsalModule, MsalRedirectComponent,\n  MsalService\n} from \"@azure/msal-angular\";\nimport {BrowserCacheLocation, InteractionType, LogLevel, PublicClientApplication} from '@azure/msal-browser';\n\nconst isIE = window.navigator.userAgent.indexOf('MSIE ') > -1 || window.navigator.userAgent.indexOf('Trident/') > -1;\n@NgModule({\n  declarations: [\n    AppComponent,\n    HeaderComponent,\n    RibonComponent\n  ],\n  imports: [\n    BrowserModule,\n    AppRoutingModule,\n    ...,\n    MsalModule.forRoot(\n      new PublicClientApplication({ // MSAL Configuration\n        auth: {\n          clientId: \"442edcf7-...\",\n          authority: \"https://login.microsoftonline.com/81fa766e-...\",\n          redirectUri: window.location.origin,\n        },\n        cache: {\n          cacheLocation : BrowserCacheLocation.LocalStorage,\n          storeAuthStateInCookie: false, // set to true for IE 11\n        },\n        system: {\n          loggerOptions: {\n            loggerCallback: (level: LogLevel, message: string, containsPii: boolean): void => {\n              if (containsPii) {\n                return;\n              }\n              switch (level) {\n                case LogLevel.Error:\n                  console.error(message);\n                  return;\n                case LogLevel.Info:\n                  console.info(message);\n                  return;\n                case LogLevel.Verbose:\n                  console.debug(message);\n                  return;\n                case LogLevel.Warning:\n                  console.warn(message);\n                  return;\n              }\n              },\n            piiLoggingEnabled: false\n          }\n        }\n      }), {\n        interactionType: InteractionType.Popup, // MSAL Guard Configuration\n      }, {\n        protectedResourceMap: new Map([\n          [ 'http://localhost:8400/', ['api://442edcf7-9e0c-469b-93fb-daa1839724bd/acces_as_user/Acces-user']],\n          [ 'https://quality-score-dev-pcq-dev.bravo-apps.volvocars.biz/', ['api://442edcf7-9e0c-469b-93fb-daa1839724bd/acces_as_user/Acces-user']]\n        ]),\n        interactionType: InteractionType.Redirect // MSAL Interceptor Configuration\n      }\n    )\n  ],\n  providers: [\n    EnvServiceProvider,\n    {\n      provide: MatPaginatorIntl,\n      useClass: MatPaginatorIntlTranslator\n    },\n    {\n      provide: HTTP_INTERCEPTORS,\n      useClass: MsalInterceptor,\n      multi: true\n    },\n    MsalService,\n    MsalGuard,\n    MsalBroadcastService,\n  ],\n  bootstrap: [AppComponent]\n})\nexport class AppModule { }\n`\n```\napp.component.ts\n```\n`\n@Component({\n  selector: 'app-root',\n  templateUrl: './app.component.html',\n  styleUrls: ['./app.component.scss']\n})\nexport class AppComponent implements OnInit, OnDestroy{\n  title = 'Quality score';\n\n  isIframe = false;\n  loginDisplay = false;\n\n  activeUser = '';\n\n  private readonly onDestroy$ = new Subject()\n\n  constructor(\n    @Inject(MSAL_GUARD_CONFIG) private msalGuardConfig: MsalGuardConfiguration,\n    private languageService: LanguageService,\n    private authService: MsalService,\n    private msalBroadcastService: MsalBroadcastService,\n    private location: Location,\n    private userService: UserService\n  ){}\n\n  ngOnInit(): void {\n    const currentPath = this.location.path();\n    // Dont perform nav if in iframe or popup, other than for front-channel logout\n    this.isIframe = BrowserUtils.isInIframe() && !window.opener && currentPath.indexOf(\"logout\")  status === InteractionStatus.None),\n        takeUntil(this.onDestroy$)\n      )\n      .subscribe(() => {\n        this.setLoginDisplay();\n        this.checkAndSetActiveAccount();\n      })\n  }\n\n  ngOnDestroy() {\n    this.onDestroy$.next();\n  }\n\n  setLoginDisplay() {\n    this.loginDisplay = this.authService.instance.getAllAccounts().length > 0;\n  }\n  checkAndSetActiveAccount(){\n    /**\n     * If no active account set but there are accounts signed in, sets first account to active account\n     * To use active account set here, subscribe to inProgress$ first in your component\n     * Note: Basic usage demonstrated. Your app may require more complicated account selection logic\n     */\n    let activeAccount = this.authService.instance.getActiveAccount();\n\n    if (!activeAccount && this.authService.instance.getAllAccounts().length > 0) {\n      let accounts = this.authService.instance.getAllAccounts();\n      this.authService.instance.setActiveAccount(accounts[0]);\n    }\n\n    if(activeAccount) {\n      this.userService.activeUserName = activeAccount.name;\n      this.activeUser = activeAccount.name;\n    }\n  }\n\n  logout(): void{\n    this.authService.logoutRedirect();\n  }\n}\n`\n```\nI'm really lost and have no idea what I have done wrong. From my understanding there is a login process that was interupted, probably by me leaving the login screen, but now I have no idea how to \"finish it up\" or complete the process.\nUpdate\nI tried copying the LocalStorage values from the working application and I got it to work. Refreshing works and no errors appear, but when I logout and after it prompted me to login again and I do, then it's right back to the start again.\nSolution update\nI've had a breakthrough. If I change the login type to Popup and handle it this way, it's fixed. I can login and logout without any issues. However if I then change it back to Redirect, it's broken again. So for now I'll keep it on Popup. Simple solution, but I hadn't thought of it because I assumed the issue would be occur there as well.",
      "solution": "I can't tell by the code provided, but I had a similar issue. On top of that I was getting the following error in the console: `Error: The selector \"app-redirect\" did not match any elements`\nThis lead me to the following post: https://github.com/AzureAD/microsoft-authentication-library-for-js/issues/3114#issuecomment-788394239\nI added `` to the `index.html` page, below `app-root` as suggested and this seemed to sort both issues.",
      "question_score": 10,
      "answer_score": 6,
      "created_at": "2021-08-10T14:17:45",
      "url": "https://stackoverflow.com/questions/68726691/browserautherror-interaction-in-progress-unable-to-fix-regardles-of-solution"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 69032013,
      "title": "Yaml Azure Devops TerraformInstaller is ambiguous",
      "problem": "Here i am trying to create aks using terraform, using azure-devops to deploy the resource to azure.\npipeline job has failed within a sec.\nbelow is the pipeline code.\n```\n`trigger:\n- main\n\npool:\n  vmImage: 'ubuntu-latest'\n\nstages:\n- stage: TerraformValidate\n  jobs:\n    - job: TerraformValidateJob\n      continueOnError: false\n      steps:\n      - task: PublishPipelineArtifact@1\n        displayName: Publish Artifacts\n        inputs:\n          targetPath: '$(System.DefaultWorkingDirectory)/terraform-manifests'\n          artifact: 'terraform-manifests-out'\n          publishLocation: 'pipeline'\n      - task: TerraformInstaller@0\n        displayName: Terraform Install\n        inputs:\n          terraformVersion: 'latest'\n      - task: TerraformCLI@0\n        displayName: Terraform Init\n        inputs:\n          command: 'init'\n          workingDirectory: '$(System.DefaultWorkingDirectory)/terraform-manifests'\n          backendType: 'azurerm'\n          backendServiceArm: ''\n          backendAzureRmResourceGroupName: ''\n          backendAzureRmStorageAccountName: ''\n          backendAzureRmContainerName: ''\n          backendAzureRmKey: 'aks-base.tfstate'\n          allowTelemetryCollection: false\n      - task: TerraformCLI@0\n        displayName: Terraform Validate\n        inputs:\n          command: 'validate'\n          workingDirectory: '$(System.DefaultWorkingDirectory)/terraform-manifests'\n          allowTelemetryCollection: false       \n`\n```\ngetting below error :\n\nI have installed both the extensions:",
      "solution": "After installing these two extensions at the same time, I can reproduce the same issue.\n\nThe root cause of the issue is that terraform install task exists in both extensions at the same time.\n\nTheir simplified version of YAML task names are all `TerraformInstaller@0`.\nTo solve this issue, you can uninstall one of the two extensions.\nOr you can  specify the full name.\nFor example:\n```\n`- task: ms-devlabs.custom-terraform-tasks.custom-terraform-installer-task.TerraformInstaller@0\n`\n```\nOR\n```\n`- task: charleszipp.azure-pipelines-tasks-terraform.azure-pipelines-tasks-terraform-installer.TerraformInstaller@0\n`\n```",
      "question_score": 9,
      "answer_score": 21,
      "created_at": "2021-09-02T16:15:34",
      "url": "https://stackoverflow.com/questions/69032013/yaml-azure-devops-terraforminstaller-is-ambiguous"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 74237694,
      "title": "Azure container app, unable to pull from private registry",
      "problem": "I have just created an Azure Container App and I am trying to link it to a private repository on docker.io. It works if I make it pull a public image but not if it's private, even though I specified all the information. I have also used the automatic \"continuous deployment\" with github (the azure portal basically did everything, which one would assume would work), I entered the same information ( docker.io, username and password and the image   tag, all working when I test in console ), the generated github action is able to build and push to docker registry, proving the user and password are good, but it doesn't want to update the container app either.\nHere is the latest error I had trying to do it through the github action:\nThe following field(s) are either invalid or missing. Invalid value: \"docker.io/pasc32/companio:latest\": GET https:: UNAUTHORIZED: authentication required; [map[Action:pull Class: Name:pasc32/companio Type:repository]]: template.containers.test.image.\nWhen I try to do it directly from the portal, it'll add a notification at the top, which will turn forever, if I refresh the page nothing's change and the container is back to how it was before, no trace of the notification in the activity log either.\n\nDoes anyone have an idea of what the issue it ?\nThank!",
      "solution": "This is a known issue and container apps team is working on it.\nAs a workaround, use `registry.hub.docker.com` as the server value instead of `docker.io`.",
      "question_score": 9,
      "answer_score": 18,
      "created_at": "2022-10-28T17:36:18",
      "url": "https://stackoverflow.com/questions/74237694/azure-container-app-unable-to-pull-from-private-registry"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67378867,
      "title": "User delegation key vs account key - security?",
      "problem": "In Microsoft's documentation for user delegation key, it says:\n\nA SAS token for access to a container, directory, or blob may be\nsecured by using either Azure AD credentials or an account key. A SAS\nsecured with Azure AD credentials is called a user delegation SAS.\nMicrosoft recommends that you use Azure AD credentials when possible\nas a security best practice, rather than using the account key, which\ncan be more easily compromised. When your application design requires\nshared access signatures, use Azure AD credentials to create a user\ndelegation SAS for superior security.\n\nWhy do this approach give \"superior security\"? I guess the SAS tokens are both safe? So why exactly is one approach safer than the other? If you use Stored Access Policy, you can also revoke SAS tokens when they have been issues with account keys.",
      "solution": "A user-delegation SAS token is more secure that it does not rely on the permissions included in the SAS token only. It also takes into consideration the RBAC permissions of the user who created this SAS token. A SAS token created using shared access key simply considers the permissions included in the SAS token.\nFor example, let's say the user who's creating a user-delegation SAS only has `Read` permissions on a blob container (i.e. they can only list or download blobs in a blob container). Now let's say the user creates a SAS token with `Write` permission. When this SAS token is used to upload a blob, the operation will fail because the user does not have `Write` permissions on that blob container whereas the upload operation would have succeeded if the SAS token was created using shared access key.\nMore information on this can be found `here` (emphasis mine):\n\nWhen a client accesses a Blob storage resource with a user delegation\nSAS, the request to Azure Storage is authorized with the Azure AD\ncredentials that were used to create the SAS. The role-based access\ncontrol (RBAC) permissions granted for that Azure AD account, together\nwith the permissions explicitly granted on the SAS, determine the\nclient's access to the resource. This approach provides an additional\nlevel of security and avoids the need to store your account access key\nwith your application code. For these reasons, creating a SAS using\nAzure AD credentials is a security best practice.\nThe permissions granted to a client who possesses the SAS are the\nintersection of the permissions granted to the security principal that\nrequested the user delegation key and the permissions granted to the\nresource on the SAS token using the signedPermissions (sp) field. If a\npermission granted to the security principal via RBAC is not also\ngranted on the SAS token, then that permission is not granted to the\nclient who attempts to use the SAS to access the resource. When\ncreating a user delegation SAS, make sure that the permissions granted\nvia RBAC and the permissions granted via the SAS token both align to\nthe level of access required by the client.",
      "question_score": 9,
      "answer_score": 17,
      "created_at": "2021-05-04T06:35:35",
      "url": "https://stackoverflow.com/questions/67378867/user-delegation-key-vs-account-key-security"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 76757194,
      "title": "Why do I get the error &quot;Unrecognized request argument supplied: functions&quot; when using `functions` when calling Azure OpenAI GPT?",
      "problem": "I'm trying to use `functions` when calling Azure OpenAI GPT, as documented in https://platform.openai.com/docs/api-reference/chat/create#chat/create-functions\nI use:\n```\n`import openai\nopenai.api_type = \"azure\"\nopenai.api_base = \"https://XXXXXXXX.openai.azure.com/\"\nopenai.api_version = \"2023-06-01-preview\"\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\nresponse = openai.ChatCompletion.create(\n            engine=\"gpt-35-turbo-XXX\",\n            model=\"gpt-35-turbo-0613-XXXX\"\n            messages=messages,\n            functions=functions,\n            function_call=\"auto\",\n        )\n`\n```\nbut I get the error:\n```\n`openai.error.InvalidRequestError:\nUnrecognized request argument supplied: functions\n`\n```\nWhy?\n\nData to run the example code above (`messages` and `functions` need to be defined):\n```\n`messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Hello!\"}]\nfunctions = [\n    {\n        \"name\": \"fetch_pages\",\n        \"description\": \"Fetch the content of specified pages from the document.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"pages\": {\n                    \"type\": \"array\",\n                    \"items\": {\n                        \"type\": \"number\"\n                    },\n                    \"description\": \"The list of pages to fetch.\"\n                }\n            },\n            \"required\": [\"pages\"]\n        }\n    },\n    {\n        \"name\": \"fetch_section\",\n        \"description\": \"Fetch the content of a specified section.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"section_title\": {\n                    \"type\": \"string\",\n                    \"description\": \"The title of the section to fetch.\"\n                }\n            },\n            \"required\": [\"section_title\"]\n        }\n    },\n    {\n        \"name\": \"search\",\n        \"description\": \"Search the document for a string query.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"The search term.\"\n                }\n            },\n            \"required\": [\"query\"]\n        }\n    }\n]\n`\n```",
      "solution": "Function support with the Azure API was added in 2023-07-01-preview. The API version needs to be updated in your example:\n```\n`openai.api_version = \"2023-07-01-preview\"\n`\n```",
      "question_score": 9,
      "answer_score": 15,
      "created_at": "2023-07-24T20:35:33",
      "url": "https://stackoverflow.com/questions/76757194/why-do-i-get-the-error-unrecognized-request-argument-supplied-functions-when"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 70244400,
      "title": "Azure Application Insights not showing data",
      "problem": "I have an ASP.NET Core application running as Azure App Service. Azure Application Insights is enabled (I followed these instructions). The problem is my instance of Azure Insights on Azure Portal isn't showing any useful data except for Live Metrics (see the screenshot). As you can see there are multiple requests and custom events on the screenshot.\nHowever, when I open Transaction search it shows nothing (see the screenshot).\nEvents page is empty as well (see the screenshot).\nSo far I double-checked an InstrumentKey. Also I tried to use ConnectionString instead of InstrumentKey, but it didn't help.\nMy app is running on .NET Core 3.1. I installed the latest version of Microsoft.ApplicationInsights.AspNetCore package which is 2.19.0.\nHere is how logging is configured in Program.cs:\n```\n`public static IWebHostBuilder CreateWebHostBuilder(string[] args) =>\n        WebHost.CreateDefaultBuilder(args)\n            .UseStartup()\n            .ConfigureLogging(builder =>\n            {\n                builder.AddFilter(\"\", LogLevel.Information);\n            });\n`\n```\nAnd below is code from Startup.cs:\n```\n`services.AddApplicationInsightsTelemetry(new ApplicationInsightsServiceOptions \n        {\n            ConnectionString = Environment.GetEnvironmentVariable(\"APPLICATIONINSIGHTS_CONNECTION_STRING\")\n        });\n`\n```\nLogLevel is also configured in appsettings.json:\n```\n`\"Logging\": {\n\"LogLevel\": {\n  \"Default\": \"Warning\"\n},\n\"ApplicationInsights\": {\n  \"LogLevel\": {\n    \"Default\": \"Information\"\n  }\n}\n`\n```\nUpdate:\nMy Admin who has more permissions can see all data, including events, performance operations etc. So I suppose there's something to do with permissions. Though it's strange that I'm not seeing any warning messages. The Admin assigned me more roles (see the screenshot), but it didn't make any difference.\nI would appreciate any help on this issue!",
      "solution": "After tearing almost all hair off my head I finally solved the issue!\nTurned out the instance of Azure Application Insights was linked to a Log Analytic Workspace that belonged to a Resource Group to which I didn't have access. So logs were stored properly, but I didn't have permission to read them.\nMy admin solved the issue by creating a new instance of Azure Application Insights which was linked to a Log Analytic Workspace within my Resource Group.\nTo anyone who isn't familiar with Log Analytic Workspace - it can be specified when you create a new instance of Azure Application Insights (see the screen).\nThanks everyone for trying to help me!\nUPDATE: As Jonathan L. mentioned in the comments, instead of creating a new Application Insights instance, one can just change Workspace in Properties.",
      "question_score": 9,
      "answer_score": 13,
      "created_at": "2021-12-06T11:59:07",
      "url": "https://stackoverflow.com/questions/70244400/azure-application-insights-not-showing-data"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 75138646,
      "title": "@azure/msal-browser TypeError: this.startPerformanceMeasurement is not a function",
      "problem": "Introduction\nBecause there is no build in Auth library for nuxt 3 yet, I am trying to create my own composable called useAuth.\nThe Problem\nI am getting a startPerformanceMeasurement error when i try to call the loginRedirect or loginPopup method.\n```\n`Uncaught (in promise) TypeError: this.startPerformanceMeasurement is not a function\n    at PerformanceClient2.startMeasurement (PerformanceClient.ts:100:45)\n    at BrowserPerformanceClient2.startMeasurement (BrowserPerformanceClient.ts:46:55)\n    at RedirectClient2. (StandardInteractionClient.ts:204:64)\n    at step (_tslib.js:87:23)\n    at Object.next (_tslib.js:68:53)\n    at _tslib.js:61:71\n    at new Promise ()\n    at __awaiter (_tslib.js:57:12)\n    at StandardInteractionClient2.getDiscoveredAuthority (StandardInteractionClient.ts:202:115)\n    at RedirectClient2. (StandardInteractionClient.ts:142:48)\n`\n```\nCode\ncomposables/useAuth.js\n`import * as msal from '@azure/msal-browser'\n\nlet state = {\n    authService: null,  \n}\n\nexport const useAuth = () => {\n    // use public configuration from nuxt \n    var config = useAppConfig();\n    //create authentication instance\n    state.authService = new msal.PublicClientApplication(config.msalConfig);\n\n    //return signIn method\n    return {\n        signIn\n    }\n}\n\nconst signIn = async () => {\n    const tokenRequest = {\n        scopes: [\n            'openid', \n            'offline_access', \n            'Users.Read'\n        ],\n    }\n    const response = await state.authService\n        .loginRedirect(tokenRequest)\n        .then(() => {\n\n        })\n        .catch(err => {\n            console.log(err) //TypeError: this.startPerformanceMeasurement is not a function\n        });\n}\n`\nIndex.vue\n`\nif(process.client) {\n    const auth = useAuth()\n    auth.signIn()   \n}\n\n`",
      "solution": "Apparently this is a bug in the MSAL library.\nAs mentioned in this issue on Github, they're currently working on a fix.\nAs a temporary solution, you could downgrade to a previous version. Downgrading might be as simple as just removing the caret character (^) when referring to the version in your package.json.\nEdit: They've released a fix as part of msal-common v9.1.1.",
      "question_score": 9,
      "answer_score": 11,
      "created_at": "2023-01-16T20:05:32",
      "url": "https://stackoverflow.com/questions/75138646/azure-msal-browser-typeerror-this-startperformancemeasurement-is-not-a-functio"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 69766994,
      "title": "Can&#39;t create a file share in a storage account while deploying Logic App from the Portal",
      "problem": "I am getting the below error while creating a Logic App from the portal.\n\n\"Creation of storage file share failed with: 'The remote server\nreturned an error: (403) Forbidden.'. Please check if the storage\naccount is accessible.\"\n\nWhile selecting the initial Logic App configuration, I am selecting an existing storage account, which should allow accesses from azure trusted services (configuration below).\n\nThis will fail if there are private endpoints defined in the storage account (like in the images below), but also without defining private endpoints. And since the \"Allow Azure trusted services\" setting is turned on, I believe these shouldn't disallow public traffic, and trusted services should be able to communicate with the storage account via the Azure backbone. Right?\nBut assuming that Azure Resource Manager is not a trusted Azure service, I whitelisted the Azure Resource Manager IP addresses, and the outcome was still the same.\nAny idea what might be the issue(s) here?",
      "solution": "It seems not to be possible to deploy a Standard Logic App from the portal, if the targeted storage account will be hidden behind a firewall. The workaround is to deploy the Standard Logic app via ARM template. What will happen is that first the Storage account & File share will be created, and and then the firewall will be enabled on it.\nThe resources will be created in the following order:\n\nStorage account which denies the public traffic.\n\nVNET and Subnets.\n\nPrivate DNS Zones and Private Endpoints for blob, file, queue, and table services.\n\nFile Share (Logicapp App settings requires a file share to create the host runtime directories and files).\n\nApp Service Plan (Workflow standard -WS1) to host Standard Logic App resources.\n\nStandard Logic App, and set network config with the VNET integration (to connect to storage account on private endpoints).\n\nMore information here.",
      "question_score": 9,
      "answer_score": 2,
      "created_at": "2021-10-29T11:58:52",
      "url": "https://stackoverflow.com/questions/69766994/cant-create-a-file-share-in-a-storage-account-while-deploying-logic-app-from-th"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 66166628,
      "title": "Why am I getting a build error from GitHub Actions when attempting to deploy a no framework static web app on Azure?",
      "problem": "I have a simple, static website that I'm attempting to deploy as an Azure Static Web App (no framework) using GitHub Actions.  My directory structure is:\n```\n`\u251c\u2500\u2500 .github/workflows/\n\u251c\u2500\u2500 css/\n\u251c\u2500\u2500 img/\n\u251c\u2500\u2500 js/\n\u251c index.html\n`\n```\nWhen I make a push to the GitHub repo, the Azure Static Web Apps CI/CD action starts the build & deploy job.  In my YAML configuration file in the .github/workflows directory, I have set the following for my Repository/Build Configuration:\n```\n`app_location: \"/\"    # The app source code is in the root directory for the repo\napi_location: \"\"     # There is no API that needs to be configured\noutput_location: \"/\" # my index.html file is in the root directory for the repo\n`\n```\nHowever, I get the following error in my Build and Deploy Job:\n\nFailed to find a default file in the app artifacts folder (/). Valid\ndefault files: index.html,Index.html. If your application contains\npurely static content, please verify that the variable 'app_location'\nin your workflow file (located in .github/workflows) points to the root of your application.\n\nWhy am I getting this error when I've specified where the index.html file is?",
      "solution": "Because the deploy container was based on Ubuntu, I guessed that the output location may be getting confused with the root directory for the entire system.\nSo, I set the output location in the workflow YAML file to:\n```\n`output_location: \"./\"\n`\n```\nWith that change, the build completes and the static web app deploys successfully.",
      "question_score": 9,
      "answer_score": 12,
      "created_at": "2021-02-12T06:09:10",
      "url": "https://stackoverflow.com/questions/66166628/why-am-i-getting-a-build-error-from-github-actions-when-attempting-to-deploy-a-n"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67803744,
      "title": "Azure global admin cannot(disabled) add roles under &quot;Access Control(IAM)&quot;",
      "problem": "I activated my global admin role in Privileged Identity Management like so\n\nWhen I navigate to the Access Control blade under a subscription, I see the Add role assignment options disabled.\n\nDoesn't global admin has global rights and can do this?\nThanks",
      "solution": "Doesn't global admin has global rights and can do this?\n\nNo. You're global admin in your Azure AD so you can perform all operations in Azure AD. Azure AD roles are different than Azure Subscription roles.\nTo be able to perform IAM related activities in an Azure Subscription, you must be assigned an `Owner` or `User Access Administrator` role in that Azure Subscription.\nConsidering you're the global admin in your Azure AD, you can elevate your permissions to perform IAM activities in Azure Subscription. Please see this link for more details: https://learn.microsoft.com/en-us/azure/role-based-access-control/elevate-access-global-admin.\nOther option would be to ask someone in your team with proper access in the Azure Subscription to assign you in `Owner` or `User Access Administrator` role.",
      "question_score": 9,
      "answer_score": 7,
      "created_at": "2021-06-02T12:52:48",
      "url": "https://stackoverflow.com/questions/67803744/azure-global-admin-cannotdisabled-add-roles-under-access-controliam"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67165101,
      "title": "Azure ChainedTokenCredential Fails after Password Change",
      "problem": "Azure `ChainedTokenCredential` fails for local development after password change. I've been using `ChainedTokenCredential` for several weeks to authenticate using `ManagedIdentityCredential` in Azure and `DefaultAzureCredential` for local testing of my Function App. Everything was working as exected. Here is a code example that was working and still works in Azure but not locally.\n```\n`def get_client():\n\n    MSI_credential = ManagedIdentityCredential()\n    default_credential = DefaultAzureCredential()\n    credential_chain = ChainedTokenCredential(MSI_credential, default_credential)\n\n    storageurl = os.environ[\"STORAGE_ACCOUNT\"]\n\n    client = BlobServiceClient(storageurl, credential=credential_chain)\n    return client\n`\n```\nLast week I had to change my password and since then I get the following error.\n```\n`[2021-04-19T15:18:06.931Z] SharedTokenCacheCredential.get_token failed: Azure Active Directory error '(invalid_grant) AADSTS50173: The provided grant has expired due to it being revoked, a fresh auth token is needed. The user might have changed or reset their password. The grant was issued on '2021-02-08T20:05:01.4240000Z' and the TokensValidFrom date (before which tokens are not valid) for this user is '2021-04-15T15:49:33.0000000Z'.\n[2021-04-19T15:18:06.963Z] Trace ID: xxx\n[2021-04-19T15:18:06.972Z] Correlation ID: xxx\n[2021-04-19T15:18:06.974Z] Timestamp: 2021-04-19 15:17:46Z'\n[2021-04-19T15:18:06.977Z] DefaultAzureCredential.get_token failed: SharedTokenCacheCredential raised unexpected error \"Azure Active Directory error '(invalid_grant) AADSTS50173: The provided grant has expired due to it being revoked, a fresh auth token is needed. The user might have changed or reset their password. The grant was issued on '2021-02-08T20:05:01.4240000Z' and the TokensValidFrom date (before which tokens are not valid) for this user is '2021-04-15T15:49:33.0000000Z'.\n[2021-04-19T15:18:07.014Z] Trace ID: xxx\n[2021-04-19T15:18:07.040Z] Correlation ID: \n[2021-04-19T15:18:07.046Z] Timestamp: 2021-04-19 15:17:46Z'\"\n[2021-04-19T15:18:07.061Z] DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n        EnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n        ManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no managed identity endpoint found.\n        SharedTokenCacheCredential: Azure Active Directory error '(invalid_grant) AADSTS50173: The provided grant has expired due to it being revoked, a fresh auth token is needed. The user might have changed or reset their password. The grant was issued on '2021-02-08T20:05:01.4240000Z' and the TokensValidFrom date (before which tokens are not valid) for this user is '2021-04-15T15:49:33.0000000Z'.\n[2021-04-19T15:18:07.094Z] Trace ID: xxx\n[2021-04-19T15:18:07.097Z] Correlation xxx\n[2021-04-19T15:18:07.108Z] Timestamp: 2021-04-19 15:17:46Z'\n[2021-04-19T15:18:07.111Z] ChainedTokenCredential.get_token failed: DefaultAzureCredential raised unexpected error \"DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n        EnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n        ManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no managed identity endpoint found.\n        SharedTokenCacheCredential: Azure Active Directory error '(invalid_grant) AADSTS50173: The provided grant has expired due to it being revoked, a fresh auth token is needed. The user might have changed or reset their password. The grant was issued on '2021-02-08T20:05:01.4240000Z' and the TokensValidFrom date (before which tokens are not valid) for this user is '2021-04-15T15:49:33.0000000Z'.\n[2021-04-19T15:18:07.147Z] Trace ID: xxx\n[2021-04-19T15:18:07.181Z] Correlation ID: xxx\n[2021-04-19T15:18:07.195Z] Timestamp: 2021-04-19 15:17:46Z'\"\n[2021-04-19T15:18:07.201Z] ChainedTokenCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n        ManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no managed identity endpoint found.\n        DefaultAzureCredential: DefaultAzureCredential failed to retrieve a token from the included credentials.\nAttempted credentials:\n        EnvironmentCredential: EnvironmentCredential authentication unavailable. Environment variables are not fully configured.\n        ManagedIdentityCredential: ManagedIdentityCredential authentication unavailable, no managed identity endpoint found.\n        SharedTokenCacheCredential: Azure Active Directory error '(invalid_grant) AADSTS50173: The provided grant has expired due to it being revoked, a fresh auth token is needed. The user might have changed or reset their password. The grant was issued on '2021-02-08T20:05:01.4240000Z' and the TokensValidFrom date (before which tokens are not valid) for this user is '2021-04-15T15:49:33.0000000Z'.\n[2021-04-19T15:18:07.241Z] Trace ID: xxx\n[2021-04-19T15:18:07.264Z] Correlation ID: xxx\n[2021-04-19T15:18:07.303Z] Timestamp: 2021-04-19 15:17:46Z'\n`\n```\nThings I've tried to resolve the issue:\n\nSigning in and out of VSCode Azure Extension\nSigning in and out of `az cli`\n`az account clear`\nClearing browser cache.\nRestarting PC and VSCode.\nClearing VSCode Cache\n\n`C:\\Users\\\\AppData\\Roaming\\Code\\Cache`\n`C:\\Users\\\\AppData\\Roaming\\Code\\CacheData`\n\nI am using the Azure Extension 'Attach to Python Functions' to run the debugger. I am uncertain of how `DefaultAzureCredential` is obtaining my credentials. I believe it is stored locally because I get the same error when running the debugger while not signed into the Azure extension. I thought `DefaultAzureCredential` would use my Azure Extension sign in as me to authenticate but I am uncertain.\nAny help would be appreciated!",
      "solution": "The issue was resolve by using @Charles Lowell's solution. I was having trouble finding the file due to using fzf.exe (fuzzy finding tool) and it does not look in hidden folders by default. Removing `C:\\Users\\\\AppData\\Local\\.IdentityService\\msal.cache` worked.\nAn alternative I found was using `VisualStudioCodeCredential()` instead of `DefaultAzureCredential()`. This uses the vscode extension to authenticate. I prefer this method but not all developers use VSCode. I'm glad to get `DefaultAzureCredential` working.\n```\n`def get_client():\n\n    MSI_credential = ManagedIdentityCredential()\n    vscode_credential = VisualStudioCodeCredential()\n    credential_chain = ChainedTokenCredential(MSI_credential, vscode_credential)\n`\n```\nMore information on `DefaultAzureCredential()` can be found here.\nThanks to all!",
      "question_score": 9,
      "answer_score": 11,
      "created_at": "2021-04-19T17:39:51",
      "url": "https://stackoverflow.com/questions/67165101/azure-chainedtokencredential-fails-after-password-change"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 71158721,
      "title": "Dedicated or shared Storage Account for Azure Function Apps with the names less than 32 symbols",
      "problem": "Short Version\nWe want to migrate to v4 and our app names are less than 32 symbols.\nShould we migrate to dedicated `Storage Accounts` or not?\nLong Version\nWe use `Azure Functions` v3. From start one `Storage Account` was shared between 10+ `Azure Function Apps`. It could be by luck but the names are less than 32 symbols and it is not going to change. We are not using slots as they were initially not recommended and then with no adoption time or recommendation made generally available.\nPre-question research revealed this question but it looks like more related to the `durable functions`. Another question looks more up the point but outdated and the accepted answer states that one `Storage Account` can be used.\nFirstly, the official documentation has a page with storage considerations and it states (props to ijabit for pointing to it.):\n\nIt's possible for multiple function apps to share the same storage account without any issues. For example, in Visual Studio you can develop multiple apps using the Azure Storage Emulator. In this case, the emulator acts like a single storage account. The same storage account used by your function app can also be used to store your application data. However, this approach isn't always a good idea in a production environment.\n\nUnfortunately it does not elaborate further on the rationale behind the last sentence.\nThe page with best practices for `Azure Function` mentions:\n\nTo improve performance in production, use a separate storage account for each function app. This is especially true with Durable Functions and Event Hub triggered functions.\n\nTo my greater confusion there was a subsection on this page that said \"Avoid sharing storage accounts\". But it was later removed.\nThis issue is somehow superficially related to the question as it mentions the recommendation in the thread.\nSecondly, we had contacted Azure Support for different not-related to this question issues and the two different support engineers shared different opinions on the current issue. One said that we can share a Storage Account among Functions Apps and another one said that we should not. So the recommendation from the support was mixed.\nThirdly, we want to migrate to v4 and in the migration notes it is stated:\n\nFunction apps that share storage accounts will fail to start if their computed hostnames are the same. Use a separate storage account for each function app. (#2049)\n\nDigging deeper into the topic, the only issue is the collision of the function host names that are used to obtain the lock that was known even in Oct 2017. One can follow the thread and see how in Jan 2020 the recommendation was made to update the official Azure naming recommendation but it was made only on late Nov 2021. I also see that a non-intrusive, i.e. without renaming, solution is to manually set the host id. The two arguments raised by balag0 are: single point of failure and better isolation. They sound good from the perspective of cleaner architecture but pragmatically I personally find `Storage Accounts` reliable, especially if read about redundancy or consider that MS is dog-fooding it for other services. So it looks more like a backbone of Azure for me.\nFinally, as we want to migrate to v4, should we migrate to dedicated `Storage Accounts` or not?",
      "solution": "For the large project with 30+ Azure Functions I work on, we have gone with dedicated Storage Accounts. The reason why is Azure Storage account service limits. As the docs mention, this really comes into play with Durable Task Functions, but can also come into play in other high volume scenarios. There's a hard limit of 20k requests per second for a Storage Account. Hit that limit, and requests will fail and will return HTTP 429 responses. This means that your Azure Function invocation will fail too. We're running some high-volume scenarios and ran into this.\nIt can also cause problems with Durable Task Functions if two functions have the same TaskHub ID in host.json. This causes a collision when Durable Task Framework does its internal bookkeeping using Storage Queues and Table Storage, and there's lots of pain and agony as things fail in spectacular fashion.\nNote that the 20k requests per second service limit can be raised with a support ticket to Azure. If approved, the max they'll raise it to is 50k requests/second.\nSo avoid the potential headaches and go with a Storage Account per Function.",
      "question_score": 9,
      "answer_score": 12,
      "created_at": "2022-02-17T14:06:36",
      "url": "https://stackoverflow.com/questions/71158721/dedicated-or-shared-storage-account-for-azure-function-apps-with-the-names-less"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 69005962,
      "title": "Azure App Service seems to have NLS enabled in .NET 5 mode",
      "problem": "After spending countless of hours on getting to the core of a bug, I eventually boiled down a problem to the use of `string.Compare` with `StringComparison.InvariantCultureIgnoreCase` in .NET 5.\nConsider the following two dotnetfiddles:\n\n.NET 4.7.2: https://dotnetfiddle.net/KdErSK\n.NET 5: https://dotnetfiddle.net/ZWfprp\n\nWhen running the .NET 4.7.2 you get -1 as a result, when running .NET 5 you get 1 as a result.\nAfter some browsing, this led to the following notice:\n\nhttps://learn.microsoft.com/en-us/dotnet/standard/base-types/string-comparison-net-5-plus\nhttps://learn.microsoft.com/en-us/dotnet/core/extensions/globalization-icu\n\nSo, going by this, a result of -1 is the NLS version, whereas the .NET 5 result of 1 is the ICU version.\nHowever, when I spin up an Azure App Service in .NET 5 mode, the result of the above code in a Razor page is -1, AKA: the NLS version.\nThis can cause all kinds of weird issues, because two different systems lead to unexpected results.\nWhen I add add the following to my project-file, as mentioned in the last article, my local environment also outputs a -1.\n```\n`\n  \n\n`\n```\nNo matter what kind of configuration I use in Azure, it will always keep outputting -1.\nLong story, something is up on Azure. As per documentation, my Windows version is new enough to have ICU enabled. Looks like the Azure App Service is either using a forced NLS mode, or is running some ICU version my local machine doesn't have.\nAnyone know how I can figure out which ICU version (if any) Azure is using, so I can use the  suggestion from the documentation to use a AppLocalIcu? Otherwise, if something is clearly on the side of Azure, then my question is what the best location would be to report this?",
      "solution": "Someone at the Azure App Service team dove into this:\n\nMost Azure App Services run on Windows 2016, more specifically at the time of writing:\n\n```\n`Major  Minor  Build  Revision\n-----  -----  -----  --------\n10     0      14393  0   \n`\n```\n\nIn the Windows Server landscape ICU was introduced in Windows Server 2019.\n\nSo to answer my own question: Azure App Services are indeed using NLS by default. This is not a bug!\nBy including the following in your project-file, ICU will be forced:\n```\n`\n  \n  \n\n`\n```\nThis is in line with the solution that @Crazy Crab mentioned, thanks!\nAlso see https://www.nuget.org/packages/Microsoft.ICU.ICU4C.Runtime for the latest version (68.2.0.9 at the time of writing).\nI'm going to accept my own answer, as I feel it gives a better answer to the \"Why is this happening\" question, rather than just fixing it.",
      "question_score": 9,
      "answer_score": 9,
      "created_at": "2021-09-01T00:37:35",
      "url": "https://stackoverflow.com/questions/69005962/azure-app-service-seems-to-have-nls-enabled-in-net-5-mode"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67869677,
      "title": "How does ExponentialBackoffRetry works with ServiceBus Trigger for Azure function?",
      "problem": "I want to implement a very simple behavior in my Azure Function: if there is an exception during handling, I want to postpone the next retry for some time. As far as I know there is no direct possibility for that in the Service Bus e.g. (unless one creates a new message), but Service Bus Trigger has a possibility for `ExponentialBackoffRetry`.\nI have not found any documentation on how that might work with regards to Service Bus Connection. I.e. what happens with the message after the execution of the function fails.\nOne possible way is to keep the message in functions infrastructure and keep renewing the lock for the duration I suppose. Some more practical questions on what I am wondering about:\n\nHow long can I use backoff retry (e.g. if I want retry to up to 7 days e.g. will that work?)\nWhat happens when host is being reset/restarted/scaled, do I lose this backoff due to implementation details or it is still somehow maintained?",
      "solution": "From the documentation:\n\nUsing retry support on top of trigger resilience\nThe function app retry policy is independent of any retries or resiliency that the trigger provides. The function retry policy will only layer on top of a trigger resilient retry. For example, if using Azure Service Bus, by default queues have a message delivery count of 10. The default delivery count means after 10 attempted deliveries of a queue message, Service Bus will dead-letter the message. You can define a retry policy for a function that has a Service Bus trigger, but the retries will layer on top of the Service Bus delivery attempts.\nFor instance, if you used the default Service Bus delivery count of 10, and defined a function retry policy of 5. The message would first dequeue, incrementing the service bus delivery account to 1. If every execution failed, after five attempts to trigger the same message, that message would be marked as abandoned. Service Bus would immediately requeue the message, it would trigger the function and increment the delivery count to 2. Finally, after 50 eventual attempts (10 service bus deliveries * five function retries per delivery), the message would be abandoned and trigger a dead-letter on service bus.\n\nFor the exponential retries, you likely need to keep the total backoff time + processing to less than what a function can hold on to the message or else the lock will expire, and even successful processing will result in an exception and retry.\nThe way Service Bus locks messages today, exponential backoff on top of Azure Service Bus is not a great idea. Once durable terminus is possible (unlimited lock time w/o the need to renew), this will make much more sense.\nUpdate: Functions retry feature is being deprecated.",
      "question_score": 9,
      "answer_score": 7,
      "created_at": "2021-06-07T12:05:11",
      "url": "https://stackoverflow.com/questions/67869677/how-does-exponentialbackoffretry-works-with-servicebus-trigger-for-azure-functio"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 76560363,
      "title": "Cannot use bicepparam file in Azure deployment",
      "problem": "I am trying to use a `.bicepparam` parameter file in my Azure CLI deployment and I get an error of `unrecognized template parameter 'using './test.bicep'`. My deployment does work if I use a traditional ARM parameter JSON file.\nIs this a problem with my syntax or is this a bug? It's almost as if the Azure CLI isn't aware of bicepparam files. I haven't seen anyone else with this problem other than one person for GitHub issue 111296 I created regarding the Bicep parameter file documentation, so it's very possible it's some syntax problem on my end.\nBelow is my test Bicep template, Bicep parameter file, and the command I used. I am trying this on macOS, but I also have this problem when using Windows 11. I expect this template to return JSON showing the output for combinedValue to be `Hello World!'`. Here is additional information.\n\nmacOS Ventura 13.4.1\nAzure CLI 2.49.0\nAzure CLI Bicep 0.18.4\n\ntest.bicep\n```\n`param value1 string\nparam value2 string\n\noutput combinedValue string = '${value1} ${value2}'\n`\n```\ntest.bicepparam\n```\n`using './test.bicep'\n\nparam value1 = 'Hello'\nparam value2 = 'World!'\n`\n```\nCommand (zsh)\n```\n`% az deployment group create --name test --resource-group test-resouce-group --template-file test.bicep --parameters @test.bicepparam\nunrecognized template parameter 'using './test.bicep'\n\nparam value1 '. Allowed parameters: value1, value2\n`\n```",
      "solution": "[This was answered by @Thomas and @GordonBy in the comments.]\nThe `@parameters.json` syntax is not used when deploying a .bicepparam file with Azure CLI. Instead, just specify the filename as so:\n`% az deployment group create --name test --resource-group test-resouce-group --template-file test.bicep --parameters test.bicepparam\n`\nThis is different from a traditional JSON ARM parameter file, where you do use the `@` symbol before the filename. As per Thomas' comment below, the @ symbol loads the contents of the file, so it's effectively the same as typing the inline parameters on the CLI. Since that's not what we want to do with a .bicepparam file, we don't need use the @ symbol.",
      "question_score": 9,
      "answer_score": 11,
      "created_at": "2023-06-26T23:34:23",
      "url": "https://stackoverflow.com/questions/76560363/cannot-use-bicepparam-file-in-azure-deployment"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 71414233,
      "title": "Create Azure Key Vault backed secret scope in Databricks with AAD Token",
      "problem": "My ultimate goal is to mount ADLS gen2 containers into my Databricks workspace as part of my Terraform-managed deployment under the auspices of an Azure Service Principal. This is a single deployment that creates all the Azure resources (networking, firewall, storage accounts, Databricks workspaces, etc.) and then configures the Databricks workspace, using the Databricks Terraform provider.\nThis answer says I cannot do AAD passthrough mounting with a Service Principal, which means I have to use OAuth2 authentication. For which, I need an Azure Key Vault backed secret scope in Databricks. The Terraform documentation says I can only do this with user-based authentication, not with my Service Principal.\nSo I thought maybe I could implement a hack: Create a Databricks PAT in Terraform (again, always as the Service Principal), then use the Terraform `external` resource to \"shell out\" to the Databricks CLI, authenticating with this PAT. I tried this manually and got this error:\n```\n`{\n  \"error_code\": \"INVALID_PARAMETER_VALUE\",\n  \"message\": \"Scope with Azure KeyVault must have userAADToken defined!\"\n}\n`\n```\nThis stands to reason, because the PAT is created for the Service Principal. However, as an alternative, this answer suggests using Azure AD token authentication, rather than the PAT. So down that rabbit hole, I go!\nI can get the Azure AD token following Microsoft's documentation, then use that to authenticate for the Databricks CLI:\n```\n`export ARM_TENANT_ID=\"...\"\nexport ARM_CLIENT_ID=\"...\"\nexport ARM_CLIENT_SECRET=\"...\"\n\nexport DATABRICKS_AAD_TOKEN=\"$(curl -X POST \\\n                                    -H 'Content-Type: application/x-www-form-urlencoded' \\\n                                    -d \"client_id=${ARM_CLIENT_ID}\" \\\n                                    -d 'grant_type=client_credentials' \\\n                                    -d 'scope=2ff814a6-3304-4ab8-85cb-cd0e6f879c1d%2F.default' \\\n                                    -d \"client_secret=${ARM_CLIENT_SECRET}\" \\\n                                    https://login.microsoftonline.com/${ARM_TENANT_ID}/oauth2/v2.0/token \\\n                             | jq -r .access_token)\"\n\ndatabricks configure --aad-token --host https://my-databricks-host.com\n`\n```\nThis authentication works: I can run various CLI commands (e.g., `databricks tokens list`) that return the expected result. However, now when I try to create the secret scope, it gives me a completely different error:\n```\n`databricks secrets create-scope --scope \"test\" \\\n                                --scope-backend-type AZURE_KEYVAULT \\\n                                --resource-id \"/subscriptions/my/key/vault/resource/id\" \\\n                                --dns-name \"https://my-vault-name.vault.azure.net/\"\n\nError: Your authentication information may be incorrect. Please reconfigure with ``dbfs configure``\n`\n```\nMy first question would be: Is my hack even going to work? If it is, where am I going wrong with the AAD token authentication? If it isn't going to work, is my ultimate goal even possible, or would I have to run several Terraform deployments -- each with their own state -- in phases, under different AAD identities (Service Principal and regular user)?",
      "solution": "Update May 2023: it's now possible to use service principal to create a secret scope on top of Azure KeyVault.\nYes, you can\u2019t do that using AAD token issued for a service principal - it works only with AAD token of real user. It\u2019s well known and well documented limitation of Azure, hopefully it will be fixed in future.\nThis is one of the major roadblocks on the way of implementing end-to-end automated provisioning of Azure Databricks workspaces",
      "question_score": 9,
      "answer_score": 10,
      "created_at": "2022-03-09T19:21:30",
      "url": "https://stackoverflow.com/questions/71414233/create-azure-key-vault-backed-secret-scope-in-databricks-with-aad-token"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 68360871,
      "title": "Timer Trigger with Azure Functions V3 (.NET 5)",
      "problem": "I am using .NET 5 and developing Azure Functions. When adding a new Timer Trigger function through Visual Studio it adds a file with this content:\n`public static class Function1\n    {\n        [FunctionName(\"Function1\")]\n        public static void Run([TimerTrigger(\"0 */5 * * * *\")]TimerInfo myTimer, ILogger log)\n        {\n            log.LogInformation($\"C# Timer trigger function executed at: {DateTime.Now}\");\n        }\n    }\n`\nI'm including it as a photo here to highlight that it doesn't compile because the TimerTrigger class doesn't exist.\nIntellisense suggests that I add the following using:\n```\n`using Microsoft.Azure.WebJobs;\n`\n```\nBut that doesn't make sense, because that belongs to the previous version of Azure Functions. And sure enough, Intellisense detects this and show this error.\n\nSo how do I use TimerTrigger in .NET 5?\nMaybe because this is relatively new, there seems to be no documentation or popular posts about this yet.",
      "solution": "Try the `Microsoft.Azure.Functions.Worker.Extensions.Timer` package, as documented here:\n\nBecause functions that run in a .NET isolated process use different binding types, they require a unique set of binding extension packages.\n\nYou'll find these extension packages under Microsoft.Azure.Functions.Worker.Extensions.\n\nDirect link to NuGet",
      "question_score": 9,
      "answer_score": 9,
      "created_at": "2021-07-13T12:41:43",
      "url": "https://stackoverflow.com/questions/68360871/timer-trigger-with-azure-functions-v3-net-5"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 67507145,
      "title": "Stream Bytes chunks to csv rows in python",
      "problem": "I need to process a large remote CSV line by line without downloading it entirely.\nBelow is the closest I got.\nI iterate byte chunks from Azure, and have some code to handle truncated lines.\nBut this cannot work if csv values contain a newline as I am not able to discernate between value newlines and csv newlines.\n```\n`# this does not work\ndef azure_iter_lines(logger_scope, client, file_path):\n    # get a StorageStreamDownloader\n    # https://learn.microsoft.com/en-us/python/api/azure-storage-file-datalake/azure.storage.filedatalake.storagestreamdownloader?view=azure-python\n    file_client = client.get_file_client(file_path)\n    file_handle = file_client.download_file()\n\n    truncated_line = ''\n    for chunk in file_handle.chunks():\n        # have the previous truncated line appended to the next block\n        chunk_txt = truncated_line + chunk.decode(\"utf-8\")\n        lines = chunk_txt.split('\\n') # THIS CANNOT WORK AS VALUES CONTAIN NEWLINES\n        for line in lines[0:len(lines)-2]:\n            yield line\n        truncated_line = lines[len(lines)-1]\n\n    # process the last chunk (same code)\n    chunk_txt = truncated_line\n    lines = chunk_txt.split('\\n') # THIS CANNOT WORK AS VALUES CONTAIN NEWLINES\n    for line in lines[0:len(lines)-2]:\n        yield line\n    truncated_line = lines[len(lines)-1]\n`\n```\nIdeally I would use csv.DictReader() but I was not able to to so as it downloads the file entirely.\n```\n`# this does not work\ndef azure_iter_lines(logger_scope, client, file_path):\n    file_client = client.get_file_client(file_path)\n    file_handle = file_client.download_file()\n    buffer = io.BytesIO()\n    file_handle.readinto(buffer) # THIS DOWNLOADS THE FILE ENTIRELY\n    csvreader = csv.DictReader(buffer, delimiter=\";\")\n    return csvreader\n`\n```\nHere is an update using some hints by @H.Leger\nPlease note that this still does not work\n```\n`file_client = client.get_file_client(file_path)\nfile_handle = file_client.download_file()\nstream = codecs.iterdecode(file_handle.chunks(), 'utf-8')\ncsvreader = csv.DictReader(stream, delimiter=\";\")\nfor row in csvreader:\n    print(row)\n# => _csv.Error: new-line character seen in unquoted field - do you need to open the file in universal-newline mode?\n`\n```\nEDIT: Final solution based on @paiv answer\nEDIT: Updated solution to use io instead of codecs for faster parsing\n```\n`import io\nimport csv\nimport ctypes as ct\n\n# bytes chunk iterator to python stream adapter \n# https://stackoverflow.com/a/67547597/2523414\n\nclass ChunksAdapter:\n    def __init__(self, chunks):\n        self.chunks = chunks\n        self.buf = b''\n        self.closed = False\n    \n    def readable(self):\n        return True\n        \n    def writable(self):\n        return False\n    \n    def seekable(self):\n        return False\n        \n    def close(self):\n        self.closed = True\n        \n    def read(self, size):\n        if not self.buf:\n            self.buf = next(self.chunks, b'')\n        res, self.buf = self.buf[:size], self.buf[size:]\n        return res\n\n# get the downloader object\nfile_client = client.get_file_client(file_path)\ndownloader = file_client.download_file()\n# adapt the downloader iterator to a byte stream\nfile_object = ChunksAdapter(downloader.chunks())\n# decode bytes stream to utf-8\ntext_stream = io.TextIOWrapper(file_object, encoding='utf-8', newline='') \n\n# update csv field limit to handle large fields\n# https://stackoverflow.com/a/54517228/2523414\ncsv.field_size_limit(int(ct.c_ulong(-1).value // 2)) \n\ncsvreader = csv.DictReader(text_stream, delimiter=\";\", quotechar='\"', quoting=csv.QUOTE_MINIMAL)\nfor row in csvreader:\n    print(row)\n`\n```",
      "solution": "Disclaimer: I know little Azure specifics. Ultimately, you would want to stream separate chunks too.\nIn Python, given a file object, you can set up CSV streaming this way:\n`import codecs\nimport csv\n`\n`codec = codecs.getreader('utf-8')\ntext_stream = codec(file_object)\ncsvreader = csv.DictReader(text_stream)\n`\nNow you can iterate over `csvreader`, and it will read from `file_object` in a streaming fasion.\nEdit: as @Martijn Pieters suggested, we can gain performance with `TextIOWrapper` instead of `codecs`:\n`text_stream = io.TextIOWrapper(file_object, encoding='utf-8', newline='')\n`\nCheck the comment in csv module on `newline` parameter.\nBut Azure's StorageStreamDownloader does not provide python's file object interface. It has `.chunks()` generator (which I assume will invoke separate HTTP request to retrieve next chunk).\nYou can adapt `.chunks()` into a file object with a simple adapter:\n`class ChunksAdapter:\n    def __init__(self, chunks):\n        self.chunks = chunks\n        self.buf = b''\n        \n    def read(self, size):\n        if not self.buf:\n            self.buf = next(self.chunks, b'')\n        res, self.buf = self.buf[:size], self.buf[size:]\n        return res\n`\nAnd use like\n`downloader = file_client.download_file()\nfile_object = ChunksAdapter(downloader.chunks())\n`\nBe sure to configure `DictReader` for the appropriate CSV dialect.\nAnd set appropriate values for `max_single_get_size`, `max_chunk_get_size` on the blob client.",
      "question_score": 9,
      "answer_score": 7,
      "created_at": "2021-05-12T18:02:01",
      "url": "https://stackoverflow.com/questions/67507145/stream-bytes-chunks-to-csv-rows-in-python"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 69639973,
      "title": "Getting Insufficient privileges to complete the operation error while creating service principal from terraform",
      "problem": "I want to create service principal with terraform and have written terraform script for that. I have Azure DevOps pipelone in which I ma running this pipeline. Service principal which I am using to run the terraform script has owner access on subscription. I am getting below error while creating azure ad application\n```\n`\u2502 \n\u2502   with module.appregister.azuread_application.auth,\n\u2502   on modules/appregister/main.tf line 6, in resource \"azuread_application\" \"auth\":\n\u2502    6: resource \"azuread_application\" \"auth\" {\n\u2502 \n\u2502 ApplicationsClient.BaseClient.Post(): unexpected status 403 with OData\n\u2502 error: Authorization_RequestDenied: Insufficient privileges to complete the\n\u2502 operation.\n\u2575\n##[error]Error: The process '/agent/_work/_tool/terraform/1.0.3/x64/terraform' failed with exit code\n`\n```\nWhat sort of Permissions are required to run this?",
      "solution": "Considering Service Principals are created in Azure AD, the Service Principal used to run your Terraform script needs to have proper permission in Azure AD and not in Azure Subscription.\nAt the very least, I believe your Service Principal should be either in `Application Administrator` or `Application Developer`. For a list of complete Azure AD built-in roles, please see this link: https://learn.microsoft.com/en-us/azure/active-directory/roles/permissions-reference.",
      "question_score": 9,
      "answer_score": 8,
      "created_at": "2021-10-20T05:26:24",
      "url": "https://stackoverflow.com/questions/69639973/getting-insufficient-privileges-to-complete-the-operation-error-while-creating-s"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 70341723,
      "title": "502 Error: Bad Gateway on Azure App Service with IronPDF",
      "problem": "I am attempting to get IronPDF working on my deployment of an ASP.NET Core 3.1 App Service.\nI am not using Azure Functions for any of this, just a regular endpoints on an Azure App Service -which, when a user calls it, the service generates and returns a generated PDF document.\nWhen running the endpoint on localhost, it works perfectly- generating the report from the HTML passed into the method. However, once I deploy it to my Azure Web App Service, I am getting a 502 - Bad Gateway error, as attached (displayed in Swagger for neatness sake).\n\nController:\n```\n`[HttpPost]\n[Route(\"[action]\")]\n[ProducesResponseType(StatusCodes.Status200OK)]\npublic async Task AgencyDownload([FromBody] AgencyReportSubmissionDto filters)\n{\n  var user = await _userService.GetUserByIdAsync(HttpContext.User.GetUserId());\n\n  // Generate the PDF\n  var content = await _agencyReport.Generate(user, null, filters.FilterDate, filters.Content, filters.Type);\n\n  // Return the PDF to the browser\n  return new FileContentResult(content.BinaryData, \"application/pdf\") { FileDownloadName = \"report.pdf\" };\n}\n`\n```\nService:\n```\n`public async Task Generate(User user, byte[] letterhead, DateTimeOffset filterDate, string html, AgencyReportTypes reportType)\n{\n   var corporateIdentity = new CorporateIdentity()\n   {\n        PrimaryColor = \"#000000\",\n        PrimaryTextColor = \"#ffffff\",\n        SecondaryColor = \"#ffffff\"\n   };\n\n    // Inserts the HTML content (from form) into the HTML template\n    var htmlContent = Template(corporateIdentity.PrimaryColor, corporateIdentity.PrimaryTextColor).Replace(\"{{HtmlContent}}\", html);\n        \n    TimeZoneInfo tz = TimeZoneInfo.FindSystemTimeZoneById(\"South Africa Standard Time\");\n    var convertedDate = TimeZoneInfo.ConvertTimeFromUtc(filterDate.UtcDateTime, tz);\n    var Renderer = new ChromePdfRenderer();\n\n    Renderer.RenderingOptions.Title = \"Agency Report - for \" + convertedDate.ToString(\"d MMMM yyyy\");\n    Renderer.RenderingOptions.PaperSize = IronPdf.Rendering.PdfPaperSize.A4;\n\n    var doc = await Renderer.RenderHtmlAsPdfAsync(htmlContent);\n    return doc;\n}\n`\n```\nSolution:\nI noticed that if I performed a manual deployment to that app service, it was working, but when I was deploying from my pipeline- I had the error above.\nSo I went snooping around my pipelines and upon changing it to this, it worked.\n```\n`            - task: AzureRmWebAppDeployment@4\n              displayName: Deploy API Artifact\n              inputs:\n                ConnectionType: 'AzureRM'\n                AzureSubscription: 'My-Azure-Subscription'\n                enableCustomDeployment: true\n                DeploymentType: 'zipDeploy'\n                deployToSlotOrASE: true\n                SlotName: 'development'\n                AppType: 'webApp'\n                WebAppName: 'my-api'\n                Package: '$(Pipeline.Workspace)/**/API.zip'\n                ResourceGroupName: 'MyResource'\n`\n```\nthe 'DeploymentType: 'zipDeploy'\" was key.\nThanks to Alex Hanneman for pointing me in the right direction.",
      "solution": "I am also using Azure App Service as an API, wrapping IronPDF. Upgrading to latest Iron PDF package also broke my app, returning a 502.\nWhat I did to fix it is deploy the code using ZipDeploy and then set WEBSITE_RUN_FROM_PACKAGE to 0. This is also needed to get the Iron PDF log files to show up in Azure, as they recommend here: https://iron.helpscoutdocs.com/article/122-azure-log-files.",
      "question_score": 9,
      "answer_score": 6,
      "created_at": "2021-12-13T23:33:11",
      "url": "https://stackoverflow.com/questions/70341723/502-error-bad-gateway-on-azure-app-service-with-ironpdf"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 75164721,
      "title": "NextAuth refresh token with Azure AD",
      "problem": "Since the default valid time for an access token is 1 hour, I am trying to get refresh tokens to work  in my application. I have been stuck with this problem for a couple of weeks now, and cannot seem to fix it. I have verified my `refreshAccessToken(accessToken)` function to work (where `accessToken` is an object with the expired token, the refresh token and some other stuff).\nI pinpointed the issue to the `async session()` function. While in the `async jwt()` function, refreshAccessToken gets called, the `async session()` function still results in an error, because the parameter `token` is undefined. This results in the error `cannot read property accessToken from undefined` (since `token.accessToken` is on the first line). How could I solve this, and somehow make the function `async session()` wait for the access token to refresh, before sending it to the client, together with all other information (groups, username etc.)?\n`/**\n * All requests to /api/auth/* (signIn, callback, signOut, etc.) will automatically be handled by NextAuth.js.\n */\n\nimport NextAuth from \"next-auth\"\nimport AzureAD from \"next-auth/providers/azure-ad\";\n\nasync function refreshAccessToken(accessToken) {\n  try {\n    const url = \"https://login.microsoftonline.com/02cd5db4-6c31-4cb1-881d-2c79631437e8/oauth2/v2.0/token\"\n    await fetch(url, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/x-www-form-urlencoded\",\n      },\n      body: `grant_type=refresh_token`\n      + `&client_secret=${process.env.AZURE_AD_CLIENT_SECRET}`\n      + `&refresh_token=${accessToken.refreshToken}`\n      + `&client_id=${process.env.AZURE_AD_CLIENT_ID}`\n    }).then(res => res.json())\n      .then(res => {\n        return {\n          ...accessToken,\n          accessToken: res.access_token,\n          accessTokenExpires: Date.now() + res.expires_in * 1000,\n          refreshToken: res.refresh_token ?? accessToken.refreshToken, // Fall backto old refresh token\n        }\n      })\n  } catch (error) {\n    console.log(error)\n\n    return {\n      ...accessToken,\n      error: \"RefreshAccessTokenError\",\n    }\n  }\n}\n\nexport const authOptions = {\n  providers: [\n    AzureAD({\n      clientId: process.env.AZURE_AD_CLIENT_ID,\n      clientSecret: process.env.AZURE_AD_CLIENT_SECRET,\n      tenantId: process.env.AZURE_AD_TENANT_ID,\n      authorization: {\n        params: {\n          scope: \"offline_access openid profile email Application.ReadWrite.All Directory.ReadWrite.All \" +\n            \"Group.ReadWrite.All GroupMember.ReadWrite.All User.Read User.ReadWrite.All\"\n        }\n      }\n    }),\n  ],\n  callbacks: {\n    async jwt({token, account, profile}) {\n      // Persist the OAuth access_token and or the user id to the token right after signin\n      if (account && profile) {\n        token.accessToken = account.access_token;\n        token.accessTokenExpires = account.expires_at * 1000;\n        token.refreshToken = account.refresh_token;\n\n        token.id = profile.oid; // For convenience, the user's OID is called ID.\n        token.groups = profile.groups;\n        token.username = profile.preferred_username;\n      }\n\n      if (Date.now()  0 ? splittedName[0] : null;\n      session.user.lastName = splittedName.length > 1 ? splittedName[1] : null;\n\n      return session;\n    },\n  },\n  pages: {\n    signIn: '/login',\n  }\n}\n\nexport default NextAuth(authOptions)\n`\nI tried searching everywhere online, but it is hard to even find people using Azure AD with NextAuth at all (NOT the B2C version, but the B2B/organisations version).\nTLDR: Using the refreshToken to get a new accessToken works, but NextAuth does not pass this token to the frontend, and instead throws an error, since in `async session()`, token is undefined.",
      "solution": "In the provided code, I made the mistake of mixing async with promises (credits to @balazsorban44 on GitHub). This means that the `return` statement in the `.then` returns the value to where the fetch request was initiated, instead of it returning a value from the function `refreshAccessToken()` as a whole. I moved away from using promises and only used an async function:\n`    const req = await fetch(url, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/x-www-form-urlencoded\",\n      },\n      body: `grant_type=refresh_token`\n      + `&client_secret=${process.env.AZURE_AD_CLIENT_SECRET}`\n      + `&refresh_token=${accessToken.refreshToken}`\n      + `&client_id=${process.env.AZURE_AD_CLIENT_ID}`\n    })\n\n    const res = await req.json();\n`",
      "question_score": 9,
      "answer_score": 6,
      "created_at": "2023-01-18T21:04:51",
      "url": "https://stackoverflow.com/questions/75164721/nextauth-refresh-token-with-azure-ad"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure",
      "question_id": 73901031,
      "title": "How to remove Azure.Storage.Blobs logging from Azure Function App logs?",
      "problem": "I have started using Azure.Storage.Blobs nuget in my Function Apps.\nOnly problem it causes at the moment is that it logs a lot of unnecessary stuff that I don't need to see. Mainly Request and Response messages that fill a large amount of my application insights now.\nIs there a way to remove those without touching any other logs? I would assume you should be able to do something from host.json, but so far nothing has worked for me to tackle this problem.\nExample logs that I get:\nRequest [f42fdb4b-8d26-418d-ae67-1d4e79bdabd6] GET  x-ms-version:2021-08-06 Accept:application/xml x-ms-client-request-id: x-ms-return-client-request-id:true User-Agent:azsdk-net-Storage.Blobs/12.13.0,(.NET 6.0.8; Microsoft Windows 10.0.14393) x-ms-date:Thu, 29 Sep 2022 19:07:43 GMT Authorization:REDACTED client assembly: Azure.Storage.Blobs\nResponse [f42fdb4b-8d26-418d-ae67-1d4e79bdabd6] 200 OK (00.0s) Accept-Ranges:bytes ETag:\"\" Server:Windows-Azure-Blob/1.0,Microsoft-HTTPAPI/2.0 x-ms-request-id: x-ms-client-request-id: x-ms-version:2021-08-06 x-ms-version-id:REDACTED x-ms-is-current-version:REDACTED x-ms-creation-time:Thu, 29 Sep 2022 19:07:39 GMT x-ms-lease-status:unlocked x-ms-lease-state:available x-ms-blob-type:BlockBlob x-ms-server-encrypted:true Date:Thu, 29 Sep 2022 19:07:43 GMT Content-Length:222058 Content-Type:application/pdf Content-MD5: Last-Modified:Thu, 29 Sep 2022 19:07:39 GMT Content-Disposition:\nIn functions where blobs are handled there will be A LOT of request/response logs like these. I tend to wrap my operations with try-catch and log possible errors, so these are completely pointless to write.",
      "solution": "Found the solution to this a while back already, but forgot to post answer.\nI managed to remove unnecessary loggings using host.json file included in Azure Function projects. Adding Azure.Core as Error did the trick.\n```\n`{\n  \"version\": \"2.0\",\n  \"logging\": {\n    \"applicationInsights\": {\n      \"samplingSettings\": {\n        \"isEnabled\": false\n      },\n      \"enableDependencyTracking\": true\n    },\n    \"logLevel\": {\n      \"default\": \"Information\",\n      \"Azure.Core\": \"Error\",\n      \"System.Net.Http.HttpClient\": \"Information\",\n      \"Azure.Messaging.ServiceBus\": \"Error\"\n    }\n  }\n}\n`\n```",
      "question_score": 9,
      "answer_score": 5,
      "created_at": "2022-09-29T22:02:12",
      "url": "https://stackoverflow.com/questions/73901031/how-to-remove-azure-storage-blobs-logging-from-azure-function-app-logs"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 68405027,
      "title": "How to resolve &quot;No hosted parallelism has been purchased or granted&quot; in free tier?",
      "problem": "I've just started with Azure DevOps pipelines and just created a very simple pipeline with a Maven task. For now I don't care for parallelism and I'm not sure in which way I've added it to my pipeline. Is there any way to use the Maven task on the free tier without parallelism?\nThis is my pipeline:\n```\n` trigger:\n - master\n    \n pool:\n   vmImage: ubuntu-latest\n    \n steps:\n - task: Maven@3\n`\n```\nMy thought was that tasks are always parallel? Other than that I cannot see where's the parallel step.",
      "solution": "First - tasks are always executed sequentially. And 1 sequential pipeline is documented as \"1 parallel agent\", yes naming could be better. Due to the changes laid out below new accounts now get zero parallel agents, and a manual request must be made to get the previous default of 1 parallel pipeline and the free build minutes.\nSee this:\n\nWe have temporarily disabled the free grant of parallel jobs for public projects and for certain private projects in new organizations. However, you can request this grant by submitting a request. Existing organizations and projects are not affected. Please note that it takes us 2-3 business days to respond to your free tier requests.\n\nMore background information on why these limitations are in play:\n\nChange in Azure Pipelines Grant for Private Projects\nChange in Azure Pipelines Grant for Public Projects\nChanges to Azure Pipelines free grants\n\nTLDR; People were using automation to spin up 1000's of Azure DevOps organizations, adding a pipeline and using the service to send spam, mine bitcoin or for other nefarious purposes. The fact that they could do so free, quick and without any human intervention was a burden on the team. Automatic detection of nefarious behavior proved hard and turned into an endless cat-and-mouse game. The manual step a necessary evil that has put a stop to this abuse and is in no way meant as a step towards further monetization of the service. It's actually to ensure a free tier remains something that can be offered to real peopjle like you and me,",
      "question_score": 86,
      "answer_score": 94,
      "created_at": "2021-07-16T09:22:15",
      "url": "https://stackoverflow.com/questions/68405027/how-to-resolve-no-hosted-parallelism-has-been-purchased-or-granted-in-free-tie"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 69730032,
      "title": "Pipeline Failure NET SDK does not support targeting",
      "problem": "Why is the pipeline for Azure Functions .NET6 (on Windows) failing with this error?\n\nError NETSDK1045: The current .NET SDK does not support targeting .NET 6.0.  Either target .NET 5.0 or lower, or use a version of the .NET SDK that supports .NET 6.0.",
      "solution": "I found the solution here https://jaliyaudagedara.blogspot.com/2021/07/azure-devops-building-projects.html \nIt works if I specify the .NET Core SDK version & set preview version to true\n```\n`- task: UseDotNet@2\n  displayName: 'Use .NET Core sdk'\n  inputs:\n    packageType: 'sdk'\n    version: '6.0.x'\n    includePreviewVersions: true\n`\n```\nSo my final pipelines looks something like this\n```\n`# .NET Core Function App to Windows on Azure\n# Build a .NET Core function app and deploy it to Azure as a Windows function App.\n# Add steps that analyze code, save build artifacts, deploy, and more:\n# https://learn.microsoft.com/en-us/azure/devops/pipelines/languages/dotnet-core\n\ntrigger:\n- master\n- main\n- dev\n\nvariables:\n  azureSubscription: 'XXXX'\n  functionAppName: 'XXXX'\n  vmImageName: 'windows-latest'\n  workingDirectory: '$(System.DefaultWorkingDirectory)/XXXX'\n\nstages:\n- stage: Build\n  displayName: Build stage\n\n  jobs:\n  - job: Build\n    displayName: Build\n    pool:\n      vmImage: $(vmImageName)\n\n    steps:\n    - task: UseDotNet@2\n      displayName: 'Use .NET 6 Core sdk'\n      inputs:\n        packageType: 'sdk'\n        version: '6.0.x'\n        includePreviewVersions: true\n\n    - task: DotNetCoreCLI@2\n      displayName: Build\n      inputs:\n        command: 'build'\n        projects: |\n          $(workingDirectory)/*.csproj\n        arguments: --output $(System.DefaultWorkingDirectory)/publish_output --configuration Release\n\n    - task: ArchiveFiles@2\n      displayName: 'Archive files'\n      inputs:\n        rootFolderOrFile: '$(System.DefaultWorkingDirectory)/publish_output'\n        includeRootFolder: false\n        archiveType: zip\n        archiveFile: $(Build.ArtifactStagingDirectory)/$(Build.BuildId).zip\n        replaceExistingArchive: true\n\n    - publish: $(Build.ArtifactStagingDirectory)/$(Build.BuildId).zip\n      artifact: drop\n\n- stage: Deploy\n  displayName: Deploy stage\n  dependsOn: Build\n  condition: succeeded()\n\n  jobs:\n  - deployment: Deploy\n    displayName: Deploy\n    environment: 'development'\n    pool:\n      vmImage: $(vmImageName)\n\n    strategy:\n      runOnce:\n        deploy:\n\n          steps:\n          - task: AzureFunctionApp@1\n            displayName: 'Azure functions app deploy'\n            inputs:\n              azureSubscription: '$(azureSubscription)'\n              appType: functionApp\n              appName: $(functionAppName)\n              package: '$(Pipeline.Workspace)/drop/$(Build.BuildId).zip'\n`\n```",
      "question_score": 62,
      "answer_score": 59,
      "created_at": "2021-10-26T23:13:26",
      "url": "https://stackoverflow.com/questions/69730032/pipeline-failure-net-sdk-does-not-support-targeting"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 65800001,
      "title": "Microsoft Azure DevOps Repo: search for text/code in specific branch",
      "problem": "I'm embarrassed to ask what should be a simple thing to figure out....\nHowever, when I'm viewing a specific branch in an Azure DevOps repository online (e.g., when reviewing a PR), I can't figure out how to perform a search of that branch's code.\nI see a global search textbox at the top, as follows:\n\nAnd I see a textbox for searching the branch for file/folder names, as follows:\n\nBut what I don't see is a textbox for searching the contents of the files in that branch....e.g. for finding occurrences of `someFunction()` or `somePropertyName` or whatever inside the code files for that particular branch.\nDid Microsoft really omit this functionality?  Or am I missing something?  How do we perform such a search?",
      "solution": "First, input content in the global search textbox at the top and search:\n\nNow, you can select your repo and branch in the dropdown lists:\n\nBy default, code search only applies to your default branch. You may add up to 5 more here:\n\nPlease notice that when a new branch is configured for search via \u201cinclude/exclude searchable branches\u201d, the branch list of search is not immediately populated with the newly configured branch. This happens because it takes some time to on-board a new branch and make it searchable. It takes up to 12 hours to fully initialize the branch.\nYou can also refer to this document about searching your code.",
      "question_score": 30,
      "answer_score": 32,
      "created_at": "2021-01-19T22:46:39",
      "url": "https://stackoverflow.com/questions/65800001/microsoft-azure-devops-repo-search-for-text-code-in-specific-branch"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 71486310,
      "title": "AzurePipeline failing due to: The reference assemblies for .NETFramework,Version=v4.6.1 were not found",
      "problem": "I have an Azure pipeline setup for my builds. I have been running into this issue recently and cannot figure out a way to fix this:\n```\n`##[error]C:\\Program Files\\Microsoft Visual Studio\\2022\\Enterprise\\MSBuild\\Current\\Bin\\Microsoft.Common.CurrentVersion.targets(1220,5): Error MSB3644: The reference assemblies for .NETFramework,Version=v4.6.1 were not found. To resolve this, install the Developer Pack (SDK/Targeting Pack) for this framework version or retarget your application. You can download .NET Framework Developer Packs at https://aka.ms/msbuild/developerpacks\n`\n```\nAbout a week or so ago lots of our builds were failing, MS had changed something and we were getting this sort of thing:\n```\n`[error]C:\\Users\\VssAdministrator\\.nuget\\packages\\codegeneration.roslyn.buildtime\\0.6.1\\build\\CodeGeneration.Roslyn.BuildTime.targets(73,5): Error CGR1001: CodeGeneration.Roslyn.Tool (dotnet-codegen) is not available, code generation won't run. Please check https://github.com/AArnott/CodeGeneration.Roslyn for usage instructions. \n`\n```\nHowever was able to solve this by explicitily adding a task to include the netcore2.1 sdk\n`    - task: UseDotNet@2\n      inputs:\n        packageType: 'sdk'\n        version: '2.x'\n`\nNow this issues is fixed we are now posed with the error complaining it cannot find .NET Framework 4.6.1.\nAnyways any idea whats going on, this is driving me banannas - any advice or insight greatly appreciated.",
      "solution": "The .Net framework version `4.6.1` has been deprecated by Azure DevOps Microsoft-hosted agent. For now, there are two kinds of Microsoft-hosted agents:\n`windows-2019` OR `windows-latest`: .Net framework version `4.7.2` and `4.8` preinstalled. This is documented here.\n`windows-2022`: .Net framework version `4.8` preinstalled. This is documented here.\nThat is, you need to use self-hosted agent to use .Net framework `4.6.1` in the pipeline.",
      "question_score": 26,
      "answer_score": 32,
      "created_at": "2022-03-15T18:10:38",
      "url": "https://stackoverflow.com/questions/71486310/azurepipeline-failing-due-to-the-reference-assemblies-for-netframework-version"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 69493762,
      "title": "Visual Studio Code showing error: Property Stages is not allowed, Property parameters is not allowed",
      "problem": "I created reusable templates from Azure DevOps yaml pipeline. The build.yaml you see below is one such template.\nWhen I push code, the pipeline successfully runs on Azure DevOps without complaining. However Visual Studio Code complains as I hover on parameters or stages.\n```\n`Property Stages is not allowed \nProperty parameters is not allowed\n`\n```\nAm I missing any settings here? Why VS Code shows errors while azure devops runs the same successfully?\n\nAnd interestingly, I have another template in the same directory, which does not show any such error messages. What am I missing? I restarted vs code, still same.",
      "solution": "I observed this problem with both Visual Studio Code as well as Visual Studio 2022 Preview.\nThis lead me to think, I renamed the file build.yaml to build-stage.yaml. This fixed  the issue finally. May be build is some keyword kind of thing internally.",
      "question_score": 21,
      "answer_score": 34,
      "created_at": "2021-10-08T11:40:36",
      "url": "https://stackoverflow.com/questions/69493762/visual-studio-code-showing-error-property-stages-is-not-allowed-property-param"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 70431528,
      "title": "MAC verification failed during PKCS12 import (wrong password?) / Azure Devops",
      "problem": "I'm using the InstallAppleCertificate@2 task from Azure DevOps but each time I try running it this error pops up\n```\n`security: SecKeychainItemImport: MAC verification failed during PKCS12 import (wrong password?)\n`\n```\nthis is the task I'm using\n```\n`- task: InstallAppleCertificate@2\ninputs:\n  certSecureFile: \"${{ parameters.certificateSecureFileName }}\"\n  certPwd: \"${{ parameters.certificatePassword }}\"\ndisplayName: \"Install AdHoc Certificate\"\n`\n```\nI'm pretty sure the password is correct since I tried the same command locally and it worked. Password doesn't contain any special characters and is being stored in a variables group.\nAny help would be appreciated. Thank you",
      "solution": "OpenSSL 3.x changed its default algorithm in `pkcs12`. Which is not compatible with embedded Security frameworks in macOS/iOS. You could alternatively use OpenSSL 1.x.\nSee:\n\nChange default algorithms in PKCS12_create() and PKCS12_set_mac()\nMacOS security framework fails to import RFC 7292 compliant PKCS #12 v1.1 file into keychain using modern cyphers\n\nTo macOS users: If you're using `openssl@3` command line tool installed via Homebrew, downgrade to `openssl@1.1` and modify your `PATH` in `~/.zshrc`. For example:\n`export PATH=\"/opt/homebrew/opt/openssl@3/bin:$PATH\"\n`\n`export PATH=\"/opt/homebrew/opt/openssl@1.1/bin:$PATH\"\n`\nIf you're using `openssl@3` libraries (`libcrypto` and `libssl`) with `SecKeychainItemImport` or `SecPKCS12Import`, have a look at the commit page above and do some modifications to your codes.",
      "question_score": 20,
      "answer_score": 20,
      "created_at": "2021-12-21T07:40:47",
      "url": "https://stackoverflow.com/questions/70431528/mac-verification-failed-during-pkcs12-import-wrong-password-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 68819306,
      "title": "&quot;Configuring the trigger failed, edit and save the pipeline again&quot; with no noticeable error and no further details",
      "problem": "I have run in to an odd problem after converting a bunch of my YAML pipelines to use templates for holding job logic as well as for defining my pipeline variables.  The pipelines run perfectly fine, however I get a \"Some recent issues detected related to pipeline trigger.\" warning at the top of the pipeline summary page and viewing details only states: \"Configuring the trigger failed, edit and save the pipeline again.\"\nThe odd part here is that the pipeline works completely fine, including triggers.  Nothing is broken and no further details are given about the supposed issue.  I currently have YAML triggers overridden for the pipeline, but I did also define the same trigger in the YAML to see if that would help (it did not).\nI'm looking for any ideas on what might be causing this or how I might be able to further troubleshoot it given the complete lack of detail that the error/warning provides.  It's causing a lot of confusion among developers who think there might be a problem with their builds as a result of the warning.\nHere is the main pipeline.  the build repository is a shared repository for holding code that is used across multiple repos in the build system.  dev.yaml contains dev environment specific variable values.  Shared holds conditionally set variables based on the branch the pipeline is running on.\n```\n`name: ProductName_$(BranchNameLower)_dev_$(MajorVersion)_$(MinorVersion)_$(BuildVersion)_$(Build.BuildId)\nresources:\n  repositories:\n    - repository: self\n    - repository: build\n      type: git\n      name: Build\n      ref: master\n\n# This trigger isn't used yet, but we want it defined for later.\ntrigger: \n  batch: true\n  branches:\n    include: \n    - 'dev'\n\nvariables:\n- template: YAML/variables/shared.yaml@build\n- template: YAML/variables/dev.yaml@build\n\njobs:\n- template: ProductNameDevJob.yaml\n  parameters:\n    pipelinePool: ${{ variables.PipelinePool }}\n    validRef: ${{ variables.ValidRef }}\n`\n```\nThen this is the start of the actual job yaml.  It provides a reusable definition of the job that can be used in more than one over-arching pipeline:\n```\n`parameters:\n- name: dependsOn\n  type: object\n  default: {}\n- name: pipelinePool\n  default: ''\n- name: validRef\n  default: ''\n- name: noCI\n  type: boolean\n  default: false\n- name: updateBeforeRun\n  type: boolean\n  default: false\n\njobs:\n- job: Build_ProductName\n  displayName: 'Build ProductName'\n  pool:\n    name: ${{ parameters.pipelinePool }}\n    demands: \n    - msbuild\n    - visualstudio\n  dependsOn: \n  - ${{ each dependsOnThis in parameters.dependsOn }}:\n    - ${{ dependsOnThis }}\n  condition: and(succeeded(), eq(variables['Build.SourceBranch'], variables['ValidRef']))\n\n  steps:\n**step logic here\n`\n```\nFinally, we have the variable YAML which conditionally sets pipeline variables based on what we are building:\n```\n`variables:\n- ${{ if or(eq(variables['Build.SourceBranch'], 'refs/heads/dev'), eq(variables['Build.SourceBranch'], 'refs/heads/users/ahenderson/azure_devops_build')) }}:\n  - name: BranchName\n    value: Dev\n** Continue with rest of pipeline variables and settings of each value for each different context.\n`\n```",
      "solution": "I think I may have figured out the problem.  It appears that this is related to the use of conditionals in the variable setup.  While the variables will be set in any valid trigger configuration, it appears that the proper values are not used during validation and that may have been causing the problem.  Switching my conditional variables to first set a default value and then replace the value conditionally seems to have fixed the problem.\nIt would be nice if Microsoft would give a more useful error message here, something to the extent of the values not being found for a given variable, but adding defaults does seem to have fixed the problem.",
      "question_score": 20,
      "answer_score": 5,
      "created_at": "2021-08-17T16:36:26",
      "url": "https://stackoverflow.com/questions/68819306/configuring-the-trigger-failed-edit-and-save-the-pipeline-again-with-no-notic"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 69681452,
      "title": "How can I suppress or resolve &quot;info: detecting host provider for...&quot; in Git?",
      "problem": "I'm getting the following output when executing a fetch / pull via a powershell script:\n\ninfo: detecting host provider for '[devops site address]'...\n\nNormally, this wouldn't be an issue, however, Azure DevOps sees this output as an error and labels the release stage as such. Is there a way I can either suppress this output, or resolve it via GIT?\nThe remote location for the repository is an on-prem version of DevOps.\nThanks!",
      "solution": "This comes indeed from the GCM used by Git.\nYou can either downgrade to Git 2.32, or wait for the recently released Git-Credential-Manager-Core v2.0.603, which does remove those messages.\nSaid release is not yet packaged with the latest Git for Windows, like the recent 2.34.0, but expect it in 2.34.1.\nA `set GCM_PROVIDER=generic` could help too.\n\nUpdate Nov. 25th, 2021: Git for Windows 2.34.1 has been released, and it does include Git Credential Manager Core v2.0.605.12951.\nThat GCM 2.0.605 includes \"Remove noisy messages during auto-detection\" (#492, #494).",
      "question_score": 20,
      "answer_score": 18,
      "created_at": "2021-10-22T20:16:22",
      "url": "https://stackoverflow.com/questions/69681452/how-can-i-suppress-or-resolve-info-detecting-host-provider-for-in-git"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 72699533,
      "title": "How can I get the current date in an Azure Pipeline YAML file to use ase a variable?",
      "problem": "I'm trying to inject a useful version number into my ASP Core application which I'm building and deploying using an Azure DevOps pipeline.\n```\n`- script: dotnet publish -c $(buildConfiguration) -p:Version=2022.06.21 -p:SourceRevisionId=$(Build.SourceVersion)\n`\n```\nBut I cannot for the life of me work out how to get the date into a variable where I can actually use it. Which is pretty remarkable really since the current date (with some other fluff appended) is what DevOps itself uses for the default build number.\nThe documentation is horrendous. How do I do this?",
      "solution": "With the `format` expression you can transform the `pipeline.startTime` into a formatted date. In your case, define the variable like the following:\n`variables:\n  currentDate: $[ format('{0:yyyy}.{0:MM}.{0:dd}', pipeline.startTime) ]\n`\nThen use the variable like the following:\n```\n`- script: dotnet publish -c $(buildConfiguration) -p:Version=$(currentDate) -p:SourceRevisionId=$(Build.SourceVersion)\n`\n```",
      "question_score": 18,
      "answer_score": 29,
      "created_at": "2022-06-21T12:55:30",
      "url": "https://stackoverflow.com/questions/72699533/how-can-i-get-the-current-date-in-an-azure-pipeline-yaml-file-to-use-ase-a-varia"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 68332967,
      "title": "Error: Unable to locate executable file: &#39;powershell&#39; when running Azure CLI task in ADO pipeline",
      "problem": "I am trying to run an Azure CLI task in pipeline and getting the following error :\n```\n`Starting: AzureCLI\n==============================================================================\nTask         : Azure CLI\nDescription  : Run Azure CLI commands against an Azure subscription in a PowerShell \nCore/Shell script when running on Linux agent or PowerShell/PowerShell Core/Batch script when running on Windows agent.\nVersion      : 2.1.0\nAuthor       : Microsoft Corporation\nHelp         : https://learn.microsoft.com/azure/devops/pipelines/tasks/deploy/azure-cli\n==============================================================================\n##[error]Script failed with error: Error: Unable to locate executable file: 'powershell'. Please verify either the file path exists or the file can be found within a directory specified by the PATH environment variable. Also check the file mode to verify the file is executable.\nFinishing: AzureCLI\n`\n```\nThe pre-requisites mentioned in https://learn.microsoft.com/en-us/azure/devops/pipelines/tasks/deploy/azure-cli?view=azure-devops is fulfilled.\n```\n`**Pre-requisites mentioned in the ms site :**  \nMicrosoft hosted agents have Azure CLI pre-installed. However if you are using private agents, install Azure CLI on the computer(s) that run the build and release agent. If an agent is already running on the machine on which the Azure CLI is installed, restart the agent to ensure all the relevant stage variables are updated.\n`\n```\nI am not using any private agents. I am using a free subscription.\nThe task in pipeline yaml is as :\n```\n` - task: AzureCLI@2\n  inputs:\n    azureSubscription: 'Free Trial()'\n    scriptType: 'ps'\n    scriptLocation: 'inlineScript'\n    inlineScript: |\n      az --version\n      az account show\n`\n```\nWhy is the agent not able to find powershell in its system!!\nIs this a bug?\nThanks!",
      "solution": "Hi try without \"scriptType\" and change the CLI version to 1, Please see the below script,\n```\n` - task: AzureCLI@1\n  inputs:\n    azureSubscription: 'Free Trial()'\n    scriptLocation: 'inlineScript'\n    inlineScript: |\n      az --version\n      az account show\n`\n```",
      "question_score": 16,
      "answer_score": 4,
      "created_at": "2021-07-11T05:12:35",
      "url": "https://stackoverflow.com/questions/68332967/error-unable-to-locate-executable-file-powershell-when-running-azure-cli-tas"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 68486027,
      "title": "How to force an Azure DevOps pipeline to fail if any previous tasks have failed?",
      "problem": "My YAML-based Azure DevOps pipeline contains several tasks in which `continueOnError: true`. I did this deliberately so that I can run all test suites even when some of them fail (each task runs a different suite of tests). At the moment the build is marked as 'partially succeeded' if any of these tasks fail. Now how do I force the build to be marked as 'failed' instead?\nI could probably do this manually by setting a build variable in each task if it fails, and then checking the value of this variable in a final step. But what's the easiest way to force a build to fail if any of the previous steps in the pipeline have failed?",
      "solution": "Adding one of these tasks to the end of each job seems to do the trick:\n```\n`- bash: |\n    echo AGENT_JOBSTATUS = $AGENT_JOBSTATUS\n    if [[ \"$AGENT_JOBSTATUS\" == \"SucceededWithIssues\" ]]; then exit 1; fi\n  displayName: Fail build if partially successful\n`\n```\nThe `echo` line is optional. See the Azure docs here re the agent variable called `Agent.JobStatus` and the values it can take.\nOr you can use Azure's built-in conditions to check the variable directly:\n```\n`- bash: exit 1\n  displayName: Fail build if partially successful\n  condition: eq(variables['Agent.JobStatus'], 'SucceededWithIssues')\n`\n```\nMaking the bash task return any non-zero value will cause it to fail when the `condition` is met.",
      "question_score": 16,
      "answer_score": 24,
      "created_at": "2021-07-22T15:50:38",
      "url": "https://stackoverflow.com/questions/68486027/how-to-force-an-azure-devops-pipeline-to-fail-if-any-previous-tasks-have-failed"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 66286924,
      "title": "How to work with DependsOn having stage dependency in Azure DevOps",
      "problem": "I have below template which does multi stage deployment:\n```\n`parameters:\n- name: Stage\n  type: string\n- name: Environment\n  type: string\n- name: Enabled  \n  type: boolean\n  default: false\n- name: WebAppName\n  type: string\n- name: ArtifactName\n  type: string\n\nstages:\n\n- stage: ${{ parameters.Stage }}  \n  displayName: '${{ parameters.Stage }} Stage'\n  dependsOn: '${{ parameters.DependsOn }}'\n  jobs:\n   - deployment: ${{ parameters.Environment }} \n     timeoutInMinutes: 70\n     environment: '${{ parameters.Environment }} Environment'\n     pool:\n        vmImage: $(vmImageName)\n     strategy:\n      runOnce:\n        deploy:\n          steps:\n          - task: DownloadBuildArtifacts@0\n            inputs:\n              buildType: 'current'\n              downloadType: 'single'\n              artifactName: ${{ parameters.ArtifactName }}\n              downloadPath: '$(System.ArtifactsDirectory)'\n          - task: AzureRmWebAppDeployment@4\n            inputs:\n              ConnectionType: 'AzureRM'\n              azureSubscription: 'AzureConnectionSC'\n              appType: 'webApp'\n              WebAppName: ${{ parameters.WebAppName }}\n              package: '$(System.ArtifactsDirectory)/**/*.zip'\n`\n```\nAnd from my pipeline I am using the template:\n```\n`- template: azure-pipelines-multi-stage-release.yml  # Template reference\n    parameters:\n       Environment: 'Dev'\n       Enabled: True\n       WebAppName: 'azureappservicehelloworldapp-dev'\n       Stage: 'Dev'\n       ArtifactName : 'helloWorldArtifact'\n\n  - template: azure-pipelines-multi-stage-release.yml  # Template reference\n    parameters:\n       Environment: 'UAT'\n       Enabled: True\n       WebAppName: 'azureappservicehelloworld-uat'\n       Stage: 'UAT'\n       ArtifactName : 'helloWorldArtifact'\n\n  - template: azure-pipelines-multi-stage-release.yml  # Template reference\n    parameters:\n       Environment: 'Prod'\n       Enabled: True\n       WebAppName: 'azureappservicehelloworld'\n       Stage: 'Prod'\n       ArtifactName : 'helloWorldArtifact'\n`\n```\nHow do I pass DependsOn onto the template, in dev there is no stage dependency so it should deploy directly but UAT is dependent on Dev, Prod is Dependent on UAT. How can I pass value to template, if nothing is passed it should go on with deployment and if something is passed as dependency it should validate that stage before installing.",
      "solution": "You declare a `DependsOn` object parameter in your template. It will be required, but checked in the template. If you don't want a dependency, just pass an empty DependsOn. This is set up as an object, so that you can pass a list of stages, in case you have a stage that's dependent on more than one.\nSet your pipeline up like this:\n`stages:\n- template: azure-pipelines-multi-stage-release.yml  # Template reference\n  parameters:\n      Environment: 'Dev'\n      Enabled: True\n      WebAppName: 'azureappservicehelloworldapp-dev'\n      Stage: Dev\n      ArtifactName : 'helloWorldArtifact'\n      # empty DependsOn, as Dev depends on nothing\n      DependsOn:\n- template: azure-pipelines-multi-stage-release.yml  # Template reference\n  parameters:\n      Environment: 'UAT'\n      Enabled: True\n      WebAppName: 'azureappservicehelloworld-uat'\n      Stage: UAT\n      ArtifactName : 'helloWorldArtifact'\n      DependsOn:\n      - Dev\n- template: azure-pipelines-multi-stage-release.yml  # Template reference\n  parameters:\n      Environment: 'Prod'\n      Enabled: True\n      WebAppName: 'azureappservicehelloworld'\n      Stage: Prod\n      ArtifactName : 'helloWorldArtifact'\n      DependsOn:\n      - UAT\n`\nand your template up like this:\n`parameters:\n- name: Stage\n  type: string\n- name: Environment\n  type: string\n- name: Enabled  \n  type: boolean\n  default: false\n- name: WebAppName\n  type: string\n- name: ArtifactName\n  type: string\n- name: DependsOn\n  type: object\n\nstages:\n- stage: ${{ parameters.Stage }}  \n  displayName: '${{ parameters.Stage }} Stage'\n  # only include the DependsOn parameter if provided\n  ${{ if parameters.DependsOn }}:\n    dependsOn: '${{ parameters.DependsOn }}'\n  jobs:\n   - deployment: ${{ parameters.Environment }} \n     timeoutInMinutes: 70\n     environment: '${{ parameters.Environment }} Environment'\n     pool:\n        vmImage: $(vmImageName)\n     strategy:\n      runOnce:\n        deploy:\n          steps:\n          - task: DownloadBuildArtifacts@0\n            inputs:\n              buildType: 'current'\n              downloadType: 'single'\n              artifactName: ${{ parameters.ArtifactName }}\n              downloadPath: '$(System.ArtifactsDirectory)'\n          - task: AzureRmWebAppDeployment@4\n            inputs:\n              ConnectionType: 'AzureRM'\n              azureSubscription: 'AzureConnectionSC'\n              appType: 'webApp'\n              WebAppName: ${{ parameters.WebAppName }}\n              package: '$(System.ArtifactsDirectory)/**/*.zip'\n`\nand your pipeline will expand to:\n`stages:\n- stage: Dev\n  displayName: Dev Stage\n  jobs:\n  - deployment: Dev\n    timeoutInMinutes: 70\n    environment:\n      name: Dev Environment\n    pool:\n      vmImage: $(vmImageName)\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - task: DownloadBuildArtifacts@0\n            inputs:\n              buildType: 'current'\n              downloadType: 'single'\n              artifactName: helloWorldArtifact\n              downloadPath: '$(System.ArtifactsDirectory)'\n          - task: AzureRmWebAppDeployment@4\n            inputs:\n              ConnectionType: 'AzureRM'\n              azureSubscription: 'AzureConnectionSC'\n              appType: 'webApp'\n              WebAppName: azureappservicehelloworldapp-dev\n              package: '$(System.ArtifactsDirectory)/**/*.zip'\n- stage: UAT\n  displayName: UAT Stage\n  dependsOn:\n  - Dev\n  jobs:\n  - deployment: UAT\n    timeoutInMinutes: 70\n    environment:\n      name: UAT Environment\n    pool:\n      vmImage: $(vmImageName)\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - task: DownloadBuildArtifacts@0\n            inputs:\n              buildType: 'current'\n              downloadType: 'single'\n              artifactName: helloWorldArtifact\n              downloadPath: '$(System.ArtifactsDirectory)'\n          - task: AzureRmWebAppDeployment@4\n            inputs:\n              ConnectionType: 'AzureRM'\n              azureSubscription: 'AzureConnectionSC'\n              appType: 'webApp'\n              WebAppName: azureappservicehelloworld-uat\n              package: '$(System.ArtifactsDirectory)/**/*.zip'\n- stage: Prod\n  displayName: Prod Stage\n  dependsOn:\n  - UAT\n  jobs:\n  - deployment: Prod\n    timeoutInMinutes: 70\n    environment:\n      name: Prod Environment\n    pool:\n      vmImage: $(vmImageName)\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - task: DownloadBuildArtifacts@0\n            inputs:\n              buildType: 'current'\n              downloadType: 'single'\n              artifactName: helloWorldArtifact\n              downloadPath: '$(System.ArtifactsDirectory)'\n          - task: AzureRmWebAppDeployment@4\n            inputs:\n              ConnectionType: 'AzureRM'\n              azureSubscription: 'AzureConnectionSC'\n              appType: 'webApp'\n              WebAppName: azureappservicehelloworld\n              package: '$(System.ArtifactsDirectory)/**/*.zip'\n\n`",
      "question_score": 15,
      "answer_score": 31,
      "created_at": "2021-02-20T02:01:04",
      "url": "https://stackoverflow.com/questions/66286924/how-to-work-with-dependson-having-stage-dependency-in-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 77485593,
      "title": "Azure DevOps: git push fails with LFS with large file (&gt;150MB)",
      "problem": "Even though Azure DevOps docs mention that file size limit is 5GB even without LFS, all of my pushes with LFS file of size larger than ~100MB fail with this message that I find difficult to extract useful information from:\n```\n`Uploading LFS objects:   0% (0/1), 0 B | 7.4 MB/s, done.\nLFS: Client error &{%!!(string=https) %!!(string=) %!!(*url.Userinfo=) %!!(string=yyy.visualstudio.com) %!!(string=/engineering/_git/3d-printing/info/lfs/objects/07fe4f13daae6a98e27d50c6bb900850ec810f59bcf09b03ededfa02f38be225) %!!(string=) %!!(bool=false) %!!(bool=false) %!!(string=) %!!(string=) %!!(string=)}s(MISSING) from HTTP 413\nerror: failed to push some refs to 'https://yyy.visualstudio.com/engineering/_git/3d-printing'\nCompleted with errors, see above.\n`\n```\nCurious if anyone ran into similar situations before and what might be causing this issue? Thanks!\nPushing from different PCs running Windows 11 with Git 2.42.0 and and git LFS version 3.4.0 resulting in the same outcome.",
      "solution": "LFS: Client error &{%!!(string=https) %!!(string=) %!!(*url.Userinfo=) %!!(string=yyy.visualstudio.com) %) from HTTP 413\n\nHTTP 413 is usually a proxy or any other networking/machine limitation.\nTo solve this issue, you can run the following command on your local machine.\n```\n`git config http.version HTTP/1.1\n`\n```\nOn the other hand, you can also check if the presence of a local proxy server will affect git lfs.",
      "question_score": 13,
      "answer_score": 25,
      "created_at": "2023-11-15T07:12:37",
      "url": "https://stackoverflow.com/questions/77485593/azure-devops-git-push-fails-with-lfs-with-large-file-150mb"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 70199030,
      "title": "NPM install task failing in Azure Devops, same code worked previously",
      "problem": "I have `yaml` pipeline running a build in Azure Devops. The `Npm@1` task has started failing this morning. `npm install` works locally with npm version 6.14.5 and it's all green lights on npm Status.\n```\n`pool:\n  name: 'Azure Pipelines'\n  vmImage: ubuntu-latest\n\nstages:\n  - stage: \n    variables:\n      buildConfiguration: \"Release\"\n      buildPlatform: \"AnyCPU\"\n    jobs:\n    - job: \n      steps:      \n      - task: Npm@1\n        displayName: 'npm install'\n        inputs:\n          workingDir: Azure/MySite/ClientApp\n`\n```\nHere's where things start to go wrong in the logs:\n```\n`\n1156 verbose pkgid node-sass@4.14.1\n1157 verbose cwd /home/vsts/work/1/s/Azure/MySite/ClientApp\n1158 verbose Linux 5.11.0-1021-azure\n1159 verbose argv \"/usr/local/bin/node\" \"/usr/local/bin/npm\" \"install\"\n1160 verbose node v16.13.0\n1161 verbose npm  v8.1.0\n1162 error code 1\n1163 error path /home/vsts/work/1/s/Azure/MySite/ClientApp/node_modules/node-sass\n1164 error command failed\n1165 error command sh -c node scripts/build.js\n1166 error Building: /usr/local/bin/node /home/vsts/work/1/s/Azure/MySite/ClientApp/node_modules/node-gyp/bin/node-gyp.js rebuild --verbose --libsass_ext= --libsass_cflags= --libsass_ldflags= --libsass_library=\n1166 error make: Entering directory '/home/vsts/work/1/s/Azure/MySite/ClientApp/node_modules/node-sass/build'\n1166 error   g++ '-DNODE_GYP_MODULE_NAME=libsass' '-DUSING_UV_SHARED=1' '-DUSING_V8_SHARED=1' '-DV8_DEPRECATION_WARNINGS=1' '-DV8_DEPRECATION_WARNINGS' '-DV8_IMMINENT_DEPRECATION_WARNINGS' '-D_GLIBCXX_USE_CXX11_ABI=1' '-D_LARGEFILE_SOURCE' '-D_FILE_OFFSET_BITS=64' '-D__STDC_FORMAT_MACROS' '-DOPENSSL_NO_PINSHARED' '-DOPENSSL_THREADS' '-DLIBSASS_VERSION=\"3.5.5\"' -I/home/vsts/.node-gyp/16.13.0/include/node -I/home/vsts/.node-gyp/16.13.0/src -I/home/vsts/.node-gyp/16.13.0/deps/openssl/config -I/home/vsts/.node-gyp/16.13.0/deps/openssl/openssl/include -I/home/vsts/.node-gyp/16.13.0/deps/uv/include -I/home/vsts/.node-gyp/16.13.0/deps/zlib -I/home/vsts/.node-gyp/16.13.0/deps/v8/include -I../src/libsass/include  -fPIC -pthread -Wall -Wextra -Wno-unused-parameter -m64 -O3 -fno-omit-frame-pointer -std=gnu++14 -std=c++0x -fexceptions -frtti -MMD -MF ./Release/.deps/Release/obj.target/libsass/src/libsass/src/ast.o.d.raw   -c -o Release/obj.target/libsass/src/libsass/src/ast.o ../src/libsass/src/ast.cpp\n1166 error   g++ '-DNODE_GYP_MODULE_NAME=libsass' '-DUSING_UV_SHARED=1' '-DUSING_V8_SHARED=1' '-DV8_DEPRECATION_WARNINGS=1' '-DV8_DEPRECATION_WARNINGS' '-DV8_IMMINENT_DEPRECATION_WARNINGS' '-D_GLIBCXX_USE_CXX11_ABI=1' '-D_LARGEFILE_SOURCE' '-D_FILE_OFFSET_BITS=64' '-D__STDC_FORMAT_MACROS' '-DOPENSSL_NO_PINSHARED' '-DOPENSSL_THREADS' '-DLIBSASS_VERSION=\"3.5.5\"' -I/home/vsts/.node-gyp/16.13.0/include/node -I/home/vsts/.node-gyp/16.13.0/src -I/home/vsts/.node-gyp/16.13.0/deps/openssl/config -I/home/vsts/.node-gyp/16.13.0/deps/openssl/openssl/include -I/home/vsts/.node-gyp/16.13.0/deps/uv/include -I/home/vsts/.node-gyp/16.13.0/deps/zlib -I/home/vsts/.node-gyp/16.13.0/deps/v8/include -I../src/libsass/include  -fPIC -pthread -Wall -Wextra -Wno-unused-parameter -m64 -O3 -fno-omit-frame-pointer -std=gnu++14 -std=c++0x -fexceptions -frtti -MMD -MF ./Release/.deps/Release/obj.target/libsass/src/libsass/src/ast_fwd_decl.o.d.raw   -c -o Release/obj.target/libsass/src/libsass/src/ast_fwd_decl.o ../src/libsass/src/ast_fwd_decl.cpp\n1166 error   g++ '-DNODE_GYP_MODULE_NAME=libsass' '-DUSING_UV_SHARED=1' '-DUSING_V8_SHARED=1' '-DV8_DEPRECATION_WARNINGS=1' '-DV8_DEPRECATION_WARNINGS' '-DV8_IMMINENT_DEPRECATION_WARNINGS' '-D_GLIBCXX_USE_CXX11_ABI=1' '-D_LARGEFILE_SOURCE' '-D_FILE_OFFSET_BITS=64' '-D__STDC_FORMAT_MACROS' '-DOPENSSL_NO_PINSHARED' '-DOPENSSL_THREADS' '-DLIBSASS_VERSION=\"3.5.5\"' -I/home/vsts/.node-gyp/16.13.0/include/node -I/home/vsts/.node-gyp/16.13.0/src -I/home/vsts/.node-gyp/16.13.0/deps/openssl/config -I/home/vsts/.node-gyp/16.13.0/deps/openssl/openssl/include -I/home/vsts/.node-gyp/16.13.0/deps/uv/include -I/home/vsts/.node-gyp/16.13.0/deps/zlib -I/home/vsts/.node-gyp/16.13.0/deps/v8/include -I../src/libsass/include  -fPIC -pthread -Wall -Wextra -Wno-unused-parameter -m64 -O3 -fno-omit-frame-pointer -std=gnu++14 -std=c++0x -fexceptions -frtti -MMD -MF ./Release/.deps/Release/obj.target/libsass/src/libsass/src/backtrace.o.d.raw   -c -o Release/obj.target/libsass/src/libsass/src/backtrace.o ../src/libsass/src/backtrace.cpp\n1166 error   g++ '-DNODE_GYP_MODULE_NAME=libsass' '-DUSING_UV_SHARED=1' '-DUSING_V8_SHARED=1' '-DV8_DEPRECATION_WARNINGS=1' '-DV8_DEPRECATION_WARNINGS' '-DV8_IMMINENT_DEPRECATION_WARNINGS' '-D_GLIBCXX_USE_CXX11_ABI=1' '-D_LARGEFILE_SOURCE' '-D_FILE_OFFSET_BITS=64' '-D__STDC_FORMAT_MACROS' '-DOPENSSL_NO_PINSHARED' '-DOPENSSL_THREADS' '-DLIBSASS_VERSION=\"3.5.5\"' -I/home/vsts/.node-gyp/16.13.0/include/node -I/home/vsts/.node-gyp/16.13.0/src -I/home/vsts/.node-gyp/16.13.0/deps/openssl/config -I/home/vsts/.node-gyp/16.13.0/deps/openssl/openssl/include -I/home/vsts/.node-gyp/16.13.0/deps/uv/include -I/home/vsts/.node-gyp/16.13.0/deps/zlib -I/home/vsts/.node-gyp/16.13.0/deps/v8/include -I../src/libsass/include  -fPIC -pthread -Wall -Wextra -Wno-unused-parameter -m64 -O3 -fno-omit-frame-pointer -std=gnu++14 -std=c++0x -fexceptions -frtti -MMD -MF ./Release/.deps/Release/obj.target/libsass/src/libsass/src/base64vlq.o.d.raw   -c -o Release/obj.target/libsass/src/libsass/src/base64vlq.o ../src/libsass/src/base64vlq.cpp\n\n`\n```\nThere hadn't been any changes to the  `package.json` in several months. Going by the error message, I've narrowed the problem down to something to do with `note-sass` so here's a minimal `package.json` to reproduce the error.\n```\n`{\n  \"dependencies\": {\n    \"node-sass\": \"^4.14.1\"\n  }\n}\n\n`\n```",
      "solution": "There are two mysteries in the universe: 1) its spatial extent and 2) why does NPM fail?\n```\n`10990 error path /home/vsts/work/1/s/Azure/MySite/ClientApp/node_modules/node-sass\n10991 error command failed\n10992 error command sh -c node scripts/build.js\n10993 error Building: /usr/local/bin/node /home/vsts/work/1/s/Azure/MySite/ClientApp/node_modules/node-gyp/bin/node-gyp.js rebuild --verbose --libsass_ext= --libsass_cflags= --libsass_ldflags= --libsass_library=\n10993 error make: Entering directory '/home/vsts/work/1/s/Azure/MySite/ClientApp/node_modules/node-sass/build'\n`\n```\nFrom what I can see in your logs, it's matter of guessing, likeliness, and personal experience. Your pipeline is compiling `node-sass`, which I believe is the source of most evil in the nodejs world.\nYou likely didn't upgrade your dependencies, which is a problem in `node-sass`. Node-sass, in fact, is binary compiled to the nodejs version.\nAzure DevOps normally upgrades the Node runtime without telling anyone (I posted a question yesterday, about SonarCloud integration).\nNow, if you (or Azure) upgrade the Nodejs runtime, then you must find a more recent version of node-sass to use that is also compatible with your own app.\nIn your question, you did state what is the npm version you are running locally, but not the nodejs version, which is 16 on Azure.\nAs a workaround, you can instruct Azure to use a different Node version\n```\n`      - task: NodeTool@0\n        displayName: Install Node.js\n        inputs:\n          versionSpec: 'Your version e.g. 14.x'\n`\n```",
      "question_score": 13,
      "answer_score": 15,
      "created_at": "2021-12-02T12:59:00",
      "url": "https://stackoverflow.com/questions/70199030/npm-install-task-failing-in-azure-devops-same-code-worked-previously"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 72616684,
      "title": "Excluding files from code coverage analysis in Azure devops pipeline",
      "problem": "I have enabled code coverage in Cobertura format and I am trying to exclude some files (Especially 3rd party DLLs) from Code Coverage analysis in the Azure DevOps pipeline. Currently, below is the output I get in the pipeline\n\nHere 3rd party DLLs are also included in the coverage report. I want to exclude all 3rd party DLLs like FluentAssertion, Microsoft.Azure etc.\nBelow are the some line from my YAML file which produces above output\n`- task: VSTest@2\n  displayName: 'Run .NET Core Unit Tests $(ucSolution)'\n  continueOnError: true\n  inputs:\n    testSelector: 'testAssemblies'\n    testAssemblyVer2: |\n      **\\MyApp.*.UnitTests.dll\n      !**\\*TestAdapter.dll\n      !**\\obj\\**\n      !**\\ref\\**\n    searchFolder: '$(System.DefaultWorkingDirectory)'\n    platform: '$(buildPlatform)'\n    configuration: '$(buildConfiguration)'\n    diagnosticsEnabled: true\n    rerunFailedTests: true\n    rerunFailedThreshold: '10'\n    rerunMaxAttempts: '1'\n    resultsFolder: '$(build.ArtifactStagingDirectory)\\Test\\Results\\core'\n    otherConsoleOptions: '/collect:\"Code Coverage;Format=Cobertura\"'\n\n- task: PublishCodeCoverageResults@1\n  displayName: 'Publish code coverage results'\n  inputs:\n    codeCoverageTool: Cobertura\n    summaryFileLocation: $(build.ArtifactStagingDirectory)/Test/Results/**/**/*.cobertura.xml\n`\nCould anyone suggest how I can exclude 3rd party DLLs from the analysis or code coverage report?\nI really appreciate any help you can provide.",
      "solution": "Add a .runsettings file to your solution, and reference it in the test step. The runsettings file will need a `ModulePaths`, `Exclude`, `ModulePath` nodes see below:\n`    \n    \n        \n            \n                \n                    \n                        \n                            \n                                .*FluentAssertions.*\n                            \n                        \n                    \n                \n            \n        \n    \n`\nExample test task in the pipeline yaml. It'll be slightly different for your `VSTest@2` task but similar principal. See how I've added an argument for a .net core test task `--settings MyFolder/.runsettings`\n`      - task: DotNetCoreCLI@2\n        displayName: 'Tests'\n        inputs:\n          command: test\n          projects: 'MyTestProject.csproj'\n          arguments: '--configuration debug --collect:\"XPlat Code Coverage\" --settings MyFolder/.runsettings'\n          publishTestResults: true\n          testRunTitle: \"Run Tests\"\n`\nMicrosoft documentation can be found here:\nhttps://learn.microsoft.com/en-us/visualstudio/test/customizing-code-coverage-analysis?view=vs-2022",
      "question_score": 13,
      "answer_score": 7,
      "created_at": "2022-06-14T14:06:13",
      "url": "https://stackoverflow.com/questions/72616684/excluding-files-from-code-coverage-analysis-in-azure-devops-pipeline"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 65584209,
      "title": "How to set an azure devops pipeline result as success even if one of the job fails",
      "problem": "I am developing an Azure CD YAML pipeline to deploy the result of a CI pipeline onto a Virtual Machine.\nRight now and simplifying things a little for the purpose of this post, the CD pipeline is quite simple and consist of a single stage with 3 jobs:\n\nThe first job runs scripts to stop a somehow complex applications. This can sometimes fail.\nThe second job will only run if first job fails. This to give the opportunity for an administrator to do a manual intervention (leveraging the built-in Manual Validation task) and fix the issue encountered in the first job. If the administrator is happy to continue to run the deployment pipeline, he will resume the run of the pipeline.\nThe third step is the deployment of the new version of the application.\n\nHere is the overall structure of the YAML pipeline:\n```\n`jobs:\n  - deployment: StopApplication\n    environment:\n      name: 'EnvA'  # This environment is a set of virtual machines running self-hosted Azure Agents.\n      resourceType: VirtualMachine\n    strategy:\n          rolling:\n            maxParallel: 1\n            deploy:\n              steps:\n              - task: ...\n  - job: ManualIntervation\n        displayName: Manual intervention to fix issue while stopping application\n        pool: server\n        dependsOn: StopApplication\n        condition: failed()  # This job will run only if job StopApplication has failed.\n        timeoutInMinutes: 60 \n        steps:\n        - task: ManualValidation@0\n          timeoutInMinutes: 50\n          inputs:\n            notifyUsers:\n              someone@somewhere.com\n            instructions: 'Do something'\n            onTimeout: 'reject'\n  - deployment: DeployApp\n        dependsOn:\n        - StopApplication\n        - ManualIntervation\n        condition: xor(succeeded('StopApplication'), succeeded('ManualIntervation'))\n        workspace:\n          clean: all\n        environment:\n          name: 'EnvA'  # This environment is a set of virtual machines running self-hosted Azure Agents.\n          resourceType: VirtualMachine\n        strategy:\n          rolling:\n            maxParallel: 1\n            deploy:\n              steps:\n              - task: ...\n`\n```\nThe problem I have is that if the first deployment job fails but that the administrator review the problem, fixes it, resume the run of the pipeline and that the last deployment job succeeds, Azure DevOps shows my pipeline as Failed (red cross in the DevOps portal) which I can understand as one of the jobs failed.\nNevertheless, functionally, the deployment succeeded and so I would like to set/force the result of the pipeline run as a success so that Azure DevOps display the green check.\nDoes anyone know the way to achieve this?\nI would assume that it is possible otherwise I would not understand why we have the opportunity for manual interventions in a pipeline.",
      "solution": "The build result is read-only and cannot be updated after the build is completed. However, You can check out below workarounds to get rid of the Failed sign(Red Cross) in Devops portal.\n1, Use `continueOnError` for the task in `StopApplication` job. For below example:\n```\n`jobs:\n - deployment: StopApplication\n   ...\n    steps:\n    - task: taskName\n       ...\n      continueOnError: true\n`\n```\nWhen the continueOnError attribute is set to true. The pipeline's result will be set to `SucceededWithIssues` when the task failed. You will have a exclamation mark instead of red Cross\n\nYou also need to change to the `condition` for job `ManualIntervation`.\nThen change the condition for job `ManualIntervation` to check if the flag variable was set to true. See below:\n```\n`- job: ManualIntervation\n  dependsOn: StopApplication\n  condition: eq(dependencies.StopApplication.result, 'SucceededWithIssues')\n`\n```\n2, Another workaround is to separate the `StopApplication` job from  the others jobs in a different pipeline.\nYou need to create two pipelines. The first pipeline only have `StopApplication` job. The second pipeline contains the rest of the jobs. And trigger the second pipeline from the first pipeline using rest api.\nIn the First pipeline.  And a powershell task after the failed task to check if the job status and trigger the second pipeline using rest api. See below example:\n```\n` - powershell: |\n      \n      $body = @{\n                templateParameters=@{\n                    ManualIntervation= \"false\"\n                }\n              }\n\n      if(\"$(Agent.JobStatus)\" -eq \"Failed\"){\n          $body.templateParameters.ManualIntervation='true'\n      }\n      $url = \"$(System.TeamFoundationCollectionUri)$(System.TeamProject)/_apis/pipelines/{second-pipelineId}/runs?api-version=6.1-preview.1\"\n      $result5 = Invoke-RestMethod -Uri $url -Headers @{Authorization = \"Bearer $(system.accesstoken)\"} -Method post -Body (convertto-json $body) -ContentType \"application/json\" \n\n    condition: always() #always run this task\n`\n```\nThen in the second pipeline define a runtime parameter `ManualIntervation` and set the condition for job `ManualIntervation` see below:\n```\n`parameters:\n- name: ManualIntervation\n  type: string\n  default: false\n  \n...\n\n- job: ManualIntervation\n  dependsOn: StopApplication\n  condition: eq('${{parameters.ManualIntervation}}', 'true') \n`\n```\nWhen the first pipeline is executed. The powershell task will be trigger the second pipeline will the template parameter request body to override the parameter `ManualIntervation` in the second pipeline. If the `ManualIntervation` is true. Then the ManualIntervation job will be executed.\nSo that the second pipeline will be succeeded even if the first pipeline failed.",
      "question_score": 13,
      "answer_score": 8,
      "created_at": "2021-01-05T19:03:35",
      "url": "https://stackoverflow.com/questions/65584209/how-to-set-an-azure-devops-pipeline-result-as-success-even-if-one-of-the-job-fai"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 68824938,
      "title": "Is there a way to configure retries for Azure DevOps pipeline tasks or jobs?",
      "problem": "Currently I have a OneBranch DevOps pipeline that fails every now and then while restoring packages. Usually it fails because of some transient error like a socket exception or timeout. Re-trying the job usually fixes the issue.\nIs there a way to configure a job or task to retry?",
      "solution": "Azure Devops now supports the `retryCountOnTaskFailure` setting on a task to do just this.\nSee this page for further information:\nhttps://learn.microsoft.com/en-us/azure/devops/release-notes/2021/pipelines/sprint-195-update",
      "question_score": 12,
      "answer_score": 17,
      "created_at": "2021-08-18T01:08:13",
      "url": "https://stackoverflow.com/questions/68824938/is-there-a-way-to-configure-retries-for-azure-devops-pipeline-tasks-or-jobs"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 68032579,
      "title": "Yaml-Pipeline starts on every commit even though it should only be triggered on schedule",
      "problem": "I have an Azure Devops- pipeline that should be run each day at 3:00 on the `develop` - Branch. The start of the Yaml looks like this:\n```\n`schedules:\n- cron: \"0 3 * * *\"\n  displayName: 3 build\n  branches:\n    include:\n    - develop\n  \npool:\n  name: default\n  demands: Agent.OS -equals Windows_NT\nsteps: \n...\n`\n```\nNow my problem is: Whenever I push changes to ANY branch the pipeline starts to run (\"Individual CI for \") so not only the cron is ignored, also the branchfilter seems to be ignored.\nI have no overridden Trigger setup in the DevOps - UI.\nWhat went wrong?\n(there are no branch-policies that trigger this pipeline)",
      "solution": "If you don't specify a set of triggers then Azure DevOps assumes that you want triggers on everything.\nso not having a `trigger` section is the same as writing\n```\n`trigger:\n  branches:\n    include:\n    - '*'\n`\n```\nIf you don't want any triggers then you need to add the following to your pipeline\n```\n`trigger: none \n`\n```\nThis will explicitly tell Azure DevOps that you do not want to run the pipeline when a branch changes.",
      "question_score": 12,
      "answer_score": 25,
      "created_at": "2021-06-18T11:21:44",
      "url": "https://stackoverflow.com/questions/68032579/yaml-pipeline-starts-on-every-commit-even-though-it-should-only-be-triggered-on"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 73053721,
      "title": "Azure Devops pipelines to trigger ONLY on Merge",
      "problem": "I'm looking on a way to trigger a Azure pipeline ONLY on successful (or attempted) pull request merge.\nNow I have :\n```\n`trigger:\n branches:\n  include:\n    - DEV\n\nsteps:\n- script: FOO\n`\n```\nBut this runs EVERY time there is a change on the DEV branch and I would like to avoid that.\nBesides, I want a programmatic response not going trough the UI each time.\nEDIT:\nA weird thing is happnening\n```\n`condition: and(succeeded(), eq(variables['Build.Reason'], 'PullRequest'))\n`\n```\ngets:\n```\n`Expanded: and(True, eq('IndividualCI', 'PullRequest'))\" \n`\n```\nWhen doing a PR, and thus doesn't work as intented",
      "solution": "I'm looking on a way to trigger a Azure pipeline ONLY on successful (or attempted) pull request merge.\n\nThere is no such out of box way to achieve this at this moment.\nWe could only set the CI trigger on the target branch, but we could set the condotion for the pipeline to avoid build any task:\n```\n`and(succeeded(), eq(variables['Build.Reason'], 'PullRequest'))\n`\n```\nFor example:\n```\n`trigger:\n branches:\n  include:\n    - DEV\n\nsteps:\n- script: FOO\n  condition: and(succeeded(), eq(variables['Build.Reason'], 'PullRequest'))\n`\n```\nOr you could set the condition for the stage, job and so on.\nPlease check the document Specify conditions for some more details.\nIf there is a change on the `DEV` branch and it would be avoided by the condition.\nNote: With above way, the pipeline will be triggered, but no task will be executed.\nAnd if you even do not want the pipeline be triggered. You could add new pipeline with powershall task to invoke REST API to trigger above pipeline and set the condition to the powershell task.\nIn this way, the pipeline will only triggered when the commit comes from the PR.\nUpdate:\n\nDoing a PR on the DEV branch results in : \"Expanded: and(True,\neq('IndividualCI', 'PullRequest'))\"\n\nYes,you are correct. That because azure devops does not have the feature to trigger the pipeline after the PR completed. Pull request trigger and Build Validation both trigger the pipeline when the PR starts.\nTo resolve this request, we could try create a service hook to monitor PR status. If the PR status changes, the pipeline is triggered through API or Application, you could check this document for some more details.\nAnd another way to achieve is using the REST API.\nThe main idea is\uff1a\n\ncreate a pipeline and set it as Build validation, but not set it as Required, should set it as Optional:\n\nAdd powershell task in above pipeline to invoke REST API to monitor the PR status until it complated, and add another task to invoke the REST API to trigger your current pipeline.\n\nSo, you could remove the:\n```\n`trigger:\n branches:\n  include:\n    - DEV\n`\n```\nin your current pipeline.",
      "question_score": 12,
      "answer_score": 14,
      "created_at": "2022-07-20T16:43:46",
      "url": "https://stackoverflow.com/questions/73053721/azure-devops-pipelines-to-trigger-only-on-merge"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 65804770,
      "title": "Include local dll in Azure DevOps pipeline",
      "problem": "In my C# project I'm referencing one of my company's DLLs, which is not on NuGet (as it's not public) and my pipeline in Azure DevOps keeps failing because it says it cannot find the reference.\n```\n`Error CS0234: The type or namespace name 'YYY' does not exist in the namespace 'ZZZ' (are you missing an assembly reference?)\n`\n```\nFollowing the advice from this post I have copied the dll in my solution and I'm referencing it from there, so the dll is version controlled and lives in the repo.\nHere an extract from the csproj:\n```\n`\n  False\n  ..\\PrivateReferences\\ZZZ.YYY.dll\n  False\n\n`\n```\nThe solution builds perfectly from my machine, but it keeps failing on Azure. What am I missing?\nThanks!\nEDIT AFTER Bright Ran-MSFT REPLY\nHere is the extract from my yaml:\n```\n`trigger:\n- develop\n\npool: 'Default'\n\nvariables:\n  solution: '**/*.sln'\n  buildPlatform: 'Any CPU'\n  buildConfiguration: 'Debug'\n\nsteps:\n\n- task: NuGetToolInstaller@1\n\n- task: NuGetCommand@2\n  inputs:\n    restoreSolution: '$(solution)'\n\n- task: NuGetCommand@2\n  inputs:\n    command: 'restore'\n    restoreSolution: '**/*.sln'\n    feedsToUse: 'select'\n    vstsFeed: ''\n\n- task: VSBuild@1\n  inputs:\n    solution: '$(solution)'\n    platform: '$(buildPlatform)'\n    configuration: '$(buildConfiguration)'\n`\n```",
      "solution": "You can publish these DLLs as yourself custom NuGet package to an Azure Artifacts feed on Azure DevOps. Then in the pipeline for your project, you can use the NuGet restore task to restore the package into your project.\nAfter publishing the package, when building your project via Visual Studio on your local machine, you also can connect to the Azure Artifacts feed to restore the package into your project.\n[UPDATE]\nHave you checked the output console logs of the pipeline run to see what caused the package can't be restored? Whether the reason is unauthorized error, such as `401` or `403`?\nIf so, before the  NuGet restore task, you need to use the NuGet Authenticate task to provide the authentication information. Here you also need to create a NuGet service connection for use.\nNormally, the feed you set up to publish yourself custom packages is private, when accessing the feed in the pipeline, the authentication is required.\nOn your local Visual Studio, due to you have log in with your account, VS will automatically authenticate with your account when you connect to the feed.",
      "question_score": 12,
      "answer_score": 9,
      "created_at": "2021-01-20T08:19:12",
      "url": "https://stackoverflow.com/questions/65804770/include-local-dll-in-azure-devops-pipeline"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 66185420,
      "title": "Azure DevOps REST api - Run pipeline with variables",
      "problem": "I have a pipeline on Azure Devops that I'm trying to run programatically/headless using the REST api: https://learn.microsoft.com/en-us/rest/api/azure/devops/pipelines/runs/run%20pipeline?view=azure-devops-rest-6.0\nSo far so good, I can auth and start a run. I would like to pass data to this pipeline which the docs suggests is possible using `variables` in the request body. My request body:\n```\n`{\n    \"variables\": {\n        \"HELLO_WORLD\": {\n            \"isSecret\": false,\n            \"value\": \"HelloWorldValue\"\n        }\n    }\n}\n`\n```\nMy pipeline YAML looks like this:\n```\n`trigger: none\n\npr: none\n\npool:\n  vmImage: 'ubuntu-latest'\n\nsteps:\n- task: Bash@3\n  inputs:\n    targetType: 'inline'\n    script: |\n      KEY=$(HELLO_WORLD)\n      echo \"Hello world key: \" $KEY\n`\n```\nThis however gives me an error that \"HELLO_WORLD: command not found\".\nI have tried adding a \"HELLO_WORLD\" variable to the pipeline and enabled the \"Let users override this value when running this pipeline\"-setting. This results in the `HELLO_WORLD` variable no longer being unknown, but instead its stuck on its initial value and not set when i trigger a run with the REST api\nHow do you pass variables to a pipeline using the REST api? It is important that the variable value is set only for a specific run/build\nI found another API to run a build, but it seems like you cannot use Personal Access Token auth with it, like you can with the pipeline api - only OAuth2 - https://learn.microsoft.com/en-us/rest/api/azure/devops/build/builds/queue?view=azure-devops-rest-6.0",
      "solution": "You can do it with both the Runs API and  Build Queue API, both work with Personal Access Tokens. For which one is the better/preferred, see this question: Difference between Azure Devops Builds - Queue vs run pipeline REST APIs, but in short the Runs API will be the more future proof option\nOption 1: Runs API\n```\n`POST https://dev.azure.com/{{organization}}/{{project}}/_apis/pipelines/{{PipelineId}}/runs?api-version=6.0-preview.1\n`\n```\nYour body will be of type `application/json` (HTTP header `Content-Type` is set to `application/json`) and similar to the below, just replace `resources.repositories.self.refName` with the appropriate value\n`{\n    \"resources\": {\n        \"repositories\": {\n            \"self\": {\n                \"refName\": \"refs/heads/main\"\n            }\n        }\n    },\n    \"variables\": {\n        \"HELLO_WORLD\": {\n            \"isSecret\": false,\n            \"value\": \"HelloWorldValue\"\n        }\n    }\n}\n`\nOption 2: Build API\n```\n`POST https://dev.azure.com/{{organization}}/{{project}}/_apis/build/builds?api-version=6.0\n`\n```\nYour body will be of type `application/json` (HTTP header `Content-Type` is set to `application/json`), something similar to below, just replace `definition.id` and `sourcebranch` with appropriate values. Please also note the \"stringified\" content of the parameter section (it should be a string representation of a json map)\n`{\n    \"parameters\": \"{\\\"HELLO_WORLD\\\":\\\"HelloWorldValue\\\"}\",\n    \"definition\": {\n        \"id\": 1\n    },\n    \"sourceBranch\": \"refs/heads/main\"\n}\n`",
      "question_score": 11,
      "answer_score": 23,
      "created_at": "2021-02-13T14:04:11",
      "url": "https://stackoverflow.com/questions/66185420/azure-devops-rest-api-run-pipeline-with-variables"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 66033709,
      "title": "How to create a build pipeline for Blazor WebAssembly Hosted app on Azure DevOps that publishes the server project not the client?",
      "problem": "I'm trying to deploy a Blazor WASM Hosted app from our Git repo on our DevOps server using a DevOps Build pipeline and a separate release pipeline.\nThe project comprises of a Server project and a Client project (as per the standard structure created by the Blazor WebAssembly Hosted template in VS).\nI've used the classic editor and the ASP.NET Core template and the site loads, but the console shows HTTP errors connecting to the server, which makes me think I've deployed the Client project not the Server project.  I'm pretty sure that's the case because my Drop artifact contains a file called Client.zip.\nHow can I change this to deploy the Server app instead?\n(There are a number of questions on this already, e.g. here, but none of the cover the classic editor approach)",
      "solution": "This is the complete process that got it working for me:\nYAML Approach\nI haven't tried this, but this post by muddybeard210 on the GitHub post Blazor WASM ASP.NET Core Hosted Azure Devops Only Publishes Client/Shared folder gave me the clue as to how to get this working in the classic editor.\n\n```\n`- task: DotNetCoreCLI@2\n  displayName: Publish\n  inputs:\n    command: 'publish'\n    publishWebProjects: false\n    projects: '**/SkillBoard.Server.csproj'\n    arguments: '--configuration $(BuildConfiguration) --output $(build.artifactstagingdirectory)'\n`\n```\nIt is important to note that publishWebProjects is set to false. This\nis because \"If true, the task will try to find the web projects in the\nrepository and run the publish command on them. Web projects are\nidentified by presence of either a web.config file or wwwroot folder\nin the directory.\" - Azure devops info button\nDue to this being true originally, it was selecting Client every time\nbecause the CLIENT project has a wwwroot folder. With\npublishWebProjects set to false, you can specify a particular project\nwith projects and use the traditional wild card characters.\n\nClassic Editor approach\nIn the pipelines in VS, choose to add a new pipeline:\n\nClick the 'Use the classic editor' link at the bottom\nOn the next page pick the repo\n\nChoose the ASP.NET Core template:\n\nThat gets you this:\n\nThen, you just need to change some of the settings on the Publish task:\n\nOn that task, untick 'Publish web projects' so the Path to project(s) box is shown:\n\nThen click the link icon and choose to Unlink:\n\nAnd finally enter a path to just your Server project in the format `**/YourWebServerProject.csproj`:\n\nAnd that's it.  When you run the pipeline your drop should now contain a file called Server.zip instead of Client.zip:",
      "question_score": 11,
      "answer_score": 19,
      "created_at": "2021-02-03T19:38:46",
      "url": "https://stackoverflow.com/questions/66033709/how-to-create-a-build-pipeline-for-blazor-webassembly-hosted-app-on-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 71524681,
      "title": "Run Job in sequence in Azure Devops",
      "problem": "```\n`stages:\n- stage: A\n     jobs:\n     - job: A1\n     pool: CloneX\n     displayname: My Job A\n     - job: A2\n     pool: CloneX\n     displayname: My Job B\n`\n```\nThis is my yaml for Azure Devops.\nI noticed 2 Agents( as windows service) running on same Pool machine CloneX.  Its an inhouse machine.\nJob A1 and Job A2 MUST run in sequence.\nHowever both A1 and A2 gets scheduled in parallel.\nHow to fix this issue?\nBy moving Job A2 to Stage B? OR\nKeeping only 1 agent on pool CloneX?",
      "solution": "You can specify job dependencies\n```\n`jobs:\n- job: Debug\n  steps:\n  - script: echo hello from the Debug build\n- job: Release\n  dependsOn: Debug\n  steps:\n  - script: echo hello from the Release build\n`\n```",
      "question_score": 11,
      "answer_score": 17,
      "created_at": "2022-03-18T10:09:48",
      "url": "https://stackoverflow.com/questions/71524681/run-job-in-sequence-in-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 69074181,
      "title": "Azure DevOps Permission to disable &quot;Delete branch&quot; option",
      "problem": "I have created Coders User group with object level permission. Group is given Contributor permission for the project. When it comes to specific repository, I have applied object level permission- Like unable to delete a branch. When I verified it, the group is still able to see the Delete Branch option and they are able to delete it.\n\nI have gone through Project Collection level permissions,Project permissions and Object level permissions. Even if we set Deny for Force Push, the group is able to use Delete branch option. So far, I have not seen an option to disable Delete branch option.\n\nHas anyone set it before?\nI am updating one more question here, regarding the New Folder in Pipeline.\nIs there a way to disable this as well for certain user group?",
      "solution": "For question 1 related to repo:\nBased on my test, disabling the Force Push Permission indeed can block users deleting the branch.\nUsers can see the Delete Branch option, but when the user click the delete option, it will show the error message:\nFor example:\n\nIf the users in the Coders Group still can delete the branch, you may need to check the permission for Single user.\n\nFor question 1 related to Pipeline:\nI am afraid that there is no specific permission to prevent users from deleting the Pipeline folder.\nFor a workaround, you can create or add an exising Pipeline to the folder and Deny the Delete Build Pipeline Permission.\n\nThen the users will have no access to delete the folder.",
      "question_score": 11,
      "answer_score": 1,
      "created_at": "2021-09-06T13:58:54",
      "url": "https://stackoverflow.com/questions/69074181/azure-devops-permission-to-disable-delete-branch-option"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 70895449,
      "title": "Update PAT of Self hosted agent",
      "problem": "The user from whose PAT a self hosted agent was configured is leaving the organization.\nOnce the users leaves the org, his account would be deleted from Azure AD and hence his PAT would be expired.\nHow should one take over the self hosted agent or update the PAT with other users account?\nI was unable to see any MSFT docs w.r.t PAT updates.\nIs uninstalling and reinstalling the only option in this scenario?",
      "solution": "You do not need to update PAT. Check the documentation: https://learn.microsoft.com/en-us/azure/devops/pipelines/agents/v2-windows?view=azure-devops",
      "question_score": 11,
      "answer_score": 13,
      "created_at": "2022-01-28T15:36:08",
      "url": "https://stackoverflow.com/questions/70895449/update-pat-of-self-hosted-agent"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 73222880,
      "title": "Push an existing project into a new Azure DevOps repository in Visual Studio 2022",
      "problem": "I have an existing Visual Studio project with existing code\nand a newly created Azure DevOps (git) project with an empty repository.\nNow from Visual Studio 2022 I want to push my project into the DevOps repository.\nThis should be a very common problem, I guess.\nHowever, when I use \"Create Git Repository\", it won't let me create the repository with the same name, since it already exists, because DevOps automatically creates a repository with the same name for a new project:\n\nSo I don't really need to create a new repository, but just connect to the existing one, so I can push the project there. But I haven't found a good way to do so.\nMy workaround so far was:\n- Create the new DevOps project \"MyApp\"\n- Create a second repository \"Dummy\" there, because there must be at least one\n- Delete the \"MyApp\" repository\n- Create a new \"MyApp\" repository from Visual Studio\n- Delete the \"Dummy\" repository\nThat works, but it's obviously stupid. There should be a straightforward, obvious way to do it.\nI'm really confused I couldn't find a good answer online, as I believe this must be the second most common use case (after creating both a new DevOps project and a new VS project at the same time). Maybe I'm just terribly bad at googling.",
      "solution": "In the image, under Other you have Existing Remote. You can use this and add the url to the repo that was created by default",
      "question_score": 11,
      "answer_score": 3,
      "created_at": "2022-08-03T15:57:09",
      "url": "https://stackoverflow.com/questions/73222880/push-an-existing-project-into-a-new-azure-devops-repository-in-visual-studio-202"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 71516792,
      "title": "Azure DevOps Pipeline error &quot;Package (...) is not compatible with net60&quot;",
      "problem": "I have source control and pipelines in Azure Devops.\nMy project has two target frameworks: 3.1 and 6.\nWhile running the pipeline, it throws errors when restoring packages:\n\n##[error]The nuget command failed with exit code(1) and error(Errors in D:\\a\\1\\s\\nuget-tst\\src\\nuget-tst.csproj\nPackage Microsoft.Extensions.Configuration.Json 3.1.3 is not compatible with net60 (.NETFramework,Version=v6.0). Package\nMicrosoft.Extensions.Configuration.Json 3.1.3 supports:\n- netcoreapp3.1 (.NETCoreApp,Version=v3.1)\n- netstandard2.0 (.NETStandard,Version=v2.0)\nPackage Microsoft.Extensions.Configuration.FileExtensions 3.1.3 is not compatible with net60 (.NETFramework,Version=v6.0). Package\nMicrosoft.Extensions.Configuration.FileExtensions 3.1.3 supports:\n- netcoreapp3.1 (.NETCoreApp,Version=v3.1)\n- netstandard2.0 (.NETStandard,Version=v2.0)\nPackage Microsoft.Extensions.Configuration.EnvironmentVariables 3.1.3 is not compatible with net60 (.NETFramework,Version=v6.0). Package Microsoft.Extensions.Configuration.EnvironmentVariables 3.1.3\nsupports:\n- netcoreapp3.1 (.NETCoreApp,Version=v3.1)\n- netstandard2.0 (.NETStandard,Version=v2.0)\nOne or more packages are incompatible with .NETFramework,Version=v6.0.\nPackage Microsoft.IdentityModel.Tokens 6.5.0 is not compatible with netcoreapp3.1 (.NETCoreApp,Version=v3.1). Package\nMicrosoft.IdentityModel.Tokens 6.5.0 supports:\n- net45 (.NETFramework,Version=v4.5)\n- net461 (.NETFramework,Version=v4.6.1)\n- netstandard2.0 (.NETStandard,Version=v2.0)\nPackage Microsoft.Extensions.FileSystemGlobbing 3.1.3 is not compatible with netcoreapp3.1 (.NETCoreApp,Version=v3.1). Package\nMicrosoft.Extensions.FileSystemGlobbing 3.1.3 supports: netstandard2.0\n(.NETStandard,Version=v2.0)\nOne or more packages are incompatible with .NETCoreApp,Version=v3.1.)\n##[error]Packages failed to restore\n\nThe azure pipelines yaml:\n```\n`    trigger:\n  branches:\n      include:\n      - master\n\npr:\n- master\n- develop\n\npool:\n  vmImage: 'windows-latest'\n\nvariables:\n  solution: '*.sln'\n  buildPlatform: 'Any CPU'\n  buildConfiguration: 'Release'\n  major: 1\n  minor: 0\n\nname: $(major).$(minor)$(Rev:.r)\n\nstages:\n\n# Versioning master branch builds\n\n- stage:\n  displayName: Build_Master_Version_Number\n  condition: eq(variables['Build.SourceBranch'], 'refs/heads/master')\n  jobs:\n  - job: Build_Master_Version_Number\n    variables:\n       patch: $[counter(variables['minor'], 0)]\n    steps:\n      - bash: |\n           echo \"##vso[build.updatebuildnumber]$(major).$(minor).$(patch)\"\n        name: SetMasterBuildName\n\n# Versioning feature branch and PR builds\n\n- stage:\n  displayName: Build_Branch_Version_Number\n  condition: ne(variables['Build.SourceBranch'], 'refs/heads/master')\n  jobs:\n  - job: Build_Branch_Version_Number\n    variables:\n       prpatch: $[counter(variables['system.pullrequest.pullrequestid'], 0)]\n       brpatch: $[counter(variables['build.sourcebranchname'], 0)]\n    steps:\n      - bash: |\n           echo \"##vso[build.updatebuildnumber]$(major).$(minor)-PullRequest.$(prpatch)\"\n        condition: eq(variables['Build.Reason'], 'PullRequest')\n        name: SetPRBuildName\n      - bash: |\n           echo \"##vso[build.updatebuildnumber]$(major).$(minor)-$(Build.SourceBranchName).$(brpatch)\"\n        condition: ne(variables['Build.Reason'], 'PullRequest')\n        name: SetBranchBuildName\n\n# Stage for building your application\n\n- stage: Build_Steps\n  displayName: Build_Steps\n  condition: always()\n  jobs:  \n  - job: Build_Steps\n    displayName: Build_Steps\n\n    steps:\n\n    - task: UseDotNet@2\n      displayName: 'Use .NET Core SDK 3.1.200'\n      inputs:\n        packageType: sdk\n        version: 3.1.200\n\n    - task: UseDotNet@2\n      displayName: 'Install .NET 6 SDK'\n      inputs:\n        packageType: 'sdk'\n        version: '6.0.x'\n        performMultiLevelLookup: true\n\n    - task: NuGetCommand@2\n      displayName: 'Restore packages'\n      inputs:\n        command: 'restore'\n\n    - task: DotNetCoreCLI@2\n      displayName: 'Build solution'\n      inputs:\n        command: 'build'\n        arguments: '--configuration $(buildConfiguration) --no-restore /p:Version=$(Build.BuildNumber)'\n        projects: '$(solution)'\n    \n    - task: DotNetCoreCLI@2  \n      displayName: 'Pack packages'\n      inputs:\n        command: 'pack'\n        versioningScheme: byBuildNumber\n        arguments: '--configuration $(buildConfiguration)'\n        packagesToPack: '**/*.csproj'\n        nobuild: true\n        packDestination: '$(Build.ArtifactStagingDirectory)'\n    \n    - task: NuGetCommand@2\n      displayName: \"Publish to Nuget Feed\"\n      inputs:\n        command: 'push'\n        feedsToUse: 'select'\n        packagesToPush: '$(Build.ArtifactStagingDirectory)/**/*.nupkg;!$(Build.ArtifactStagingDirectory)/**/*.symbols.nupkg'\n        vstsFeed: 'nugetfeeds/Dev'\n        publishVstsFeed: 'nugetfeeds/Dev'\n    \n`\n```\nThe only way I found out to overcome was to set vmImage to 'windows-2019' but that seems odd to me. Why shouldn't it work with latest version (windows-latest)?",
      "solution": "something similar happened to me.\nSolved it by adding a nuget tool installer task  before the  nuget restore step:\n```\n` - task: NuGetToolInstaller@1\n  inputs:\n    versionSpec: \n    checkLatest: true\n`\n```\nBefore adding this step, the nuget tool version was very old (see this line from the output logs of the nuget restore task)\n```\n`Caching tool: NuGet 5.4.0 x64\n`\n```\nAfter this modification, the same log shows this:\n```\n`Detected NuGet version 6.1.0.106 / 6.1.0 ...\n`\n```\nI go the idea from here:\nDotnet github issues",
      "question_score": 10,
      "answer_score": 27,
      "created_at": "2022-03-17T18:40:06",
      "url": "https://stackoverflow.com/questions/71516792/azure-devops-pipeline-error-package-is-not-compatible-with-net60"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 70929356,
      "title": "Azure Pipelines local agent failing to connect with SSL error",
      "problem": "We have an on premise server (Windows Server 2012 R2) with an Azure Pipelines agent running on it. Today (31st Jan 2022) this agent could not longer connect to our Azure DevOps organisation.\n\nJudging by the log files, I assume this is because it is trying to connect with an older TLS version, which as of today is no longer available - https://devblogs.microsoft.com/devops/azure-devops-services-to-require-tls-1-2/\nSo I followed the instructions on how to make sure TLS 1.2 was enabled, and confirmed my settings in the registry editor and by running the PowerShell script suggested here - https://learn.microsoft.com/en-us/security/engineering/solving-tls1-problem#update-windows-powershell-scripts-or-related-registry-settings\nAll seems ok, yet it still fails to connect with the same issue. The machine has been restarted as well. If I try the URL it is requesting in the in built Internet Explorer browser, it fails, but with Chrome it succeeds, so it must still be trying to connect with TLS 1.2, but I don't know why. I've tried reinstalling the agent (with the latest build) as well but it fails on the same error. Any suggestions?",
      "solution": "Enabling below Cyphers with IISCrypto on the server helped us fix the issue\nCipher Suites\nTLS 1.2 (suites in server-preferred order)\n\nTLS_DHE_RSA_WITH_AES_256_GCM_SHA384 (0x9f) DH 2048 bits FS 256\nTLS_DHE_RSA_WITH_AES_128_GCM_SHA256 (0x9e) DH 2048 bits FS 128\n\nThis from Vijay's solution",
      "question_score": 10,
      "answer_score": 9,
      "created_at": "2022-01-31T17:25:55",
      "url": "https://stackoverflow.com/questions/70929356/azure-pipelines-local-agent-failing-to-connect-with-ssl-error"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 69661626,
      "title": "How to limit TOC level in wiki in Azure DevOps",
      "problem": "I cannot see here\nhttps://learn.microsoft.com/en-us/azure/devops/project/wiki/wiki-markdown-guidance?view=azure-devops#table-of-contents-toc-for-wiki-pages\nany rule to do something like that:\n```\n`[[__TOC__ limit:3]]\n`\n```\nTo limit the level of collected headers. Is it possible?",
      "solution": "I had the same question and found a workaround. This ADO help page mentions \"Only Markdown headings are considered for TOC (HTML heading tags aren't considered).\"\nFor example, to eliminate the duplicate page title in the embedded TOC, I used `page title` instead of `#page title`. This eliminated the page title from the embedded TOC, but the page title still rendered in the same visual style on the wiki page. The same approach worked for subtitles: using `subtitle` instead of `###subtitle` rendered the subtitle appearing like a subtitle in the wiki page, but kept it out of the TOC.\nIt's a manual approach but it helped keep the TOC simplified which is what I wanted.",
      "question_score": 10,
      "answer_score": 12,
      "created_at": "2021-10-21T14:01:50",
      "url": "https://stackoverflow.com/questions/69661626/how-to-limit-toc-level-in-wiki-in-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 70990049,
      "title": "Azure Devops pipeline: import variables from template and declare variables in the same variables block",
      "problem": "Is there any way that we can mix the variable reuse with template and variable declaration in the same `variables` block ?\nSomething like this:\n```\n`variables:\n  - template: vars.yml  # Template reference\n  anotherVar: http://$(oneVarFromVarsYml)/xxx\n`\n```\nAfter the test, it doesn't work, I would like to know if you have a workaround.\nI know I can define the var `anotherVar`  in the same template `vars.yml`,  but I have the needs to define it directly here not in the template.\nThe below official Azure Devops docs gives only how to import vars from a template, but it doesn't provide an example for case we have mixed template vars and direct vars:\nhttps://learn.microsoft.com/en-us/azure/devops/pipelines/process/templates?view=azure-devops#variable-reuse",
      "solution": "This section of Azure docs mentions it:\nIf you use both variables and variable groups, use the `name/value` syntax for the individual non-grouped variables:\nYAML\n```\n`variables:\n- group: my-variable-group\n- name: my-bare-variable\n  value: 'value of my-bare-variable'\n`\n```\nRef: https://learn.microsoft.com/en-us/azure/devops/pipelines/library/variable-groups?view=azure-devops&tabs=yaml#use-a-variable-group",
      "question_score": 10,
      "answer_score": 3,
      "created_at": "2022-02-04T17:52:58",
      "url": "https://stackoverflow.com/questions/70990049/azure-devops-pipeline-import-variables-from-template-and-declare-variables-in-t"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 66296458,
      "title": "Retrieving project version from csproj in Azure Pipeline .NET Core CLI task",
      "problem": "I have the following tasks in my yaml file in Azure DevOps\nIt publishes my console application and zip it in a file\n```\n`- task: DotNetCoreCLI@2\n  inputs:\n    command: 'publish'\n    publishWebProjects: false\n    projects: '**/MyApp.csproj'\n    arguments: '-r win-x64 -p:PublishSingleFile=True --self-contained true -o $(Build.ArtifactStagingDirectory)'\n\n- task: PublishBuildArtifacts@1\n  inputs:\n    PathtoPublish: '$(Build.ArtifactStagingDirectory)'\n    ArtifactName: 'drop'\n    publishLocation: 'Container'\n`\n```\nI set the project version directly on the project file in Visual Studio when I make any changes.\nNow I'm trying to get that version when I am publishing the project in AzureDevOps and customise the file name, lets say for a project version 1.2.1 the archived file output of the publish in azure should be MyApp-v1.2.1.zip\nCurrently it only output file as MyApp.zip\nNot sure if even my approach towards versioning is correct, so appreciate any input!\nUpdated:\nUnfortunately the provided answer didn't work for me, I can get the version but I cannot rename the file, even copying the exact script below results in the same zip file, not renamed! The folder will be renamed but the zip file stays as MyApp.zip.\nI have the following script now, trying to rename using PowerShell at the end but that successfully finish executing and again results in exact the same MyApp.zip file in the drop folder\n```\n`\n- task: PowerShell@2\n  inputs:\n    targetType: 'inline'\n    script: |\n         $xml = [Xml] (Get-Content .\\MyApp\\MyApp.csproj)\n         $version = $xml.Project.PropertyGroup.Version\n         echo $version\n         echo \"##vso[task.setvariable variable=version]$version\"\n\n- task: DotNetCoreCLI@2\n  inputs:\n    command: 'publish'\n    publishWebProjects: false\n    projects: '**/MyApp.csproj'\n    arguments: '-r win-x64 -p:PublishSingleFile=True --self-contained true -o $(Build.ArtifactStagingDirectory)'\n\n- task: PublishBuildArtifacts@1\n  displayName: 'Publish Artifact'\n  inputs:\n    PathtoPublish: '$(build.artifactstagingdirectory)'\n  condition: succeededOrFailed()\n  \n- task: PowerShell@2\n  inputs:\n    targetType: 'inline'\n    script: 'Rename-Item -Path \"$(Build.ArtifactStagingDirectory)\\MyApp.zip\" -NewName \"$(Build.ArtifactStagingDirectory)\\MyApp-Win-x64-v$(version).zip\"'\n\n`\n```\nHowever the above script doesn't work either, as if we don't have permission to change that zip file, no matter what I cannot rename it.\nFixed - Solution\nI had to move the rename power shell script to before Publish Artifact\n```\n`\n- task: PowerShell@2\n  inputs:\n    targetType: 'inline'\n    script: |\n         $xml = [Xml] (Get-Content .\\MyApp\\MyApp.csproj)\n         $version = $xml.Project.PropertyGroup.Version\n         echo $version\n         echo \"##vso[task.setvariable variable=version]$version\"\n\n- task: DotNetCoreCLI@2\n  inputs:\n    command: 'publish'\n    publishWebProjects: false\n    projects: '**/MyApp.csproj'\n    arguments: '-r win-x64 -p:PublishSingleFile=True --self-contained true -o $(Build.ArtifactStagingDirectory)'\n\n- task: PowerShell@2\n  inputs:\n    targetType: 'inline'\n    script: 'Rename-Item -Path \"$(Build.ArtifactStagingDirectory)\\MyApp.zip\" -NewName \"$(Build.ArtifactStagingDirectory)\\MyApp-Win-x64-v$(version).zip\"'\n\n- task: PublishBuildArtifacts@1\n  displayName: 'Publish Artifact'\n  inputs:\n    PathtoPublish: '$(build.artifactstagingdirectory)'\n  condition: succeededOrFailed()\n  \n\n`\n```",
      "solution": "To set the name of the output file(zip file), you need to set the corresponding format in dotnet build argument.\n```\n`--configuration $(BuildConfiguration) --output $(build.artifactstagingdirectory)/MyApp-$(version)\n`\n```\nIn order to get the Version value in csproj file, you can add a powershell task before the Dotnet Publish task. Then you could retrieve project version from csproj\nHere is my example:\n```\n`- powershell: |\n   $xml = [Xml] (Get-Content .\\MyApp.csproj)\n   $version = $xml.Project.PropertyGroup.Version\n   \n   echo $version\n   \n   echo \"##vso[task.setvariable variable=version]$version\"\n  displayName: 'PowerShell Script'\n\n- task: DotNetCoreCLI@2\n  displayName: Publish\n  inputs:\n    command: publish\n    publishWebProjects: false\n    projects: '**/*.csproj'\n    arguments: '--configuration $(BuildConfiguration) --output $(build.artifactstagingdirectory)/MyApp-$(version)'\n\n- task: PublishBuildArtifacts@1\n  displayName: 'Publish Artifact'\n  inputs:\n    PathtoPublish: '$(build.artifactstagingdirectory)'\n  condition: succeededOrFailed()\n`\n```\nResult:\n\nYou can also try to set the name as `$(build.artifactstagingdirectory)/MyApp-v$(version)`\nThe output name will be `MyApp-v1.0.0.zip`\nUpdate:\nI have tested your sample in Yaml Pipeline and I could reproduce this issue.\nTo solve this issue, you could add the parameter: `modifyOutputPath: false` in Dotnet Publish task.\nHere is the yaml sample:\n```\n`- task: PowerShell@2\n  inputs:\n    targetType: 'inline'\n    script: |\n         $xml = [Xml] (Get-Content .\\MyApp\\MyApp.csproj)\n         $version = $xml.Project.PropertyGroup.Version\n         echo $version\n         echo \"##vso[task.setvariable variable=version]$version\"\n\n- task: DotNetCoreCLI@2\n  displayName: Publish\n  inputs:\n    command: publish\n    publishWebProjects: false\n    projects: '**/*.csproj'\n    arguments: '--configuration $(BuildConfiguration) --output $(build.artifactstagingdirectory)/MyApp-v$(version)'\n    modifyOutputPath: false\n\n- task: PublishBuildArtifacts@1\n  displayName: 'Publish Artifact'\n  inputs:\n    PathtoPublish: '$(build.artifactstagingdirectory)'\n  condition: succeededOrFailed()\n`\n```",
      "question_score": 10,
      "answer_score": 14,
      "created_at": "2021-02-20T21:55:54",
      "url": "https://stackoverflow.com/questions/66296458/retrieving-project-version-from-csproj-in-azure-pipeline-net-core-cli-task"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 66580943,
      "title": "How to specify an API Key when publishing to a private nuget source in Azure Devops?",
      "problem": "I am trying to publish a NuGet package to a NuGet feed I created in Azure Devops. I have experience in doing these kind of things (I published on NuGet.org) but for some reason I do not understand, it is not working when I try to do this for my employer.\nWhen I click \"Connect To Feed\", I see this explanation:\n\nThis clearly shows where to put my package path and where to put the source. However, it does not show where to put the API key I generated.\nBut I gave it a try and typed (after generating the package file):\n```\n`dotnet nuget push --source \"Test\" --api-key az ClassLibrary1.1.0.0.nupkg\n`\n```\nThis was not working (401)\n\nI really do not understand this part of the explanation: \"API Key (any string will do)\". Why possibly \"any string will do\". I need a valid API key.... Not \"any string\".\nAfter that I tried to publish in way I have good experience with (when publishing nuget.org public nuget packages). In this statement, the source and key are clearly specified.\nHere is how I did it:\n\nAlso that does not work. I got a 401 again.\nMy API key that should give me access (and thus prevents a 401) should be fine. This is how I generated the API key:\n\nMost likely, there is something wrong with the way I specified my API key, not with the API key itself. So how do I specify it correctly in my command-line statement in order to successfully publish my package?",
      "solution": "There are a few steps you'll have to take before you can push to your NuGet feed locally:\n\nInstall the Azure Artifact Credential Provider: https://go.microsoft.com/fwlink/?linkid=2099625\nRun `dotnet restore --interactive`, this will prompt you for credentials\nRun `dotnet nuget push --source \"BackgroundJobs\" --api-key anyapikey `\n\nNote: You can use any API key.",
      "question_score": 10,
      "answer_score": 13,
      "created_at": "2021-03-11T11:43:35",
      "url": "https://stackoverflow.com/questions/66580943/how-to-specify-an-api-key-when-publishing-to-a-private-nuget-source-in-azure-dev"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 68542830,
      "title": "Create a json file during Azure DevOps build pipeline",
      "problem": "I have a Azure DevOps build pipeline that runs a Cypress test. In that Cypress test we have a test user login with a e-mail and password. On my local system I have the password in a `cypress.env.json` file.\nOn the Azure build pipeline I get the message that the password is `undefined` which makes sense since we put the `cypress.env.json` file in the .gitignore not to expose it to the repo.\nI've created a Azure variable to represent the password: `$(ACCOUNT_PASSWORD)`\nSo I think I need to create the `cypress.env.json` file in the build pipeline and use Azure variables for it, but I can't figure out how to create a file during the build step.\nI have this task:\n```\n`- task: CmdLine@2\n  displayName: 'run Cypress'\n  inputs:\n    script: |\n      npm run ci\n`\n```\nSo I need to add a task before this that creates the `cypress.env.json` file with the variable that represents the password:\n```\n`{\n  \"ACCOUNT_PASSWORD\": $(ACCOUNT_PASSWORD)\n}\n`\n```",
      "solution": "You can add a simple PS script that creates the file:\n```\n`- task: PowerShell@2\n  inputs:\n    targetType: 'inline'\n    script: |\n      $json = '{\n       \"ACCOUNT_PASSWORD\": $(ACCOUNT_PASSWORD)\n      }'\n        \n      $json | Out-File cypress.env.json\n    workingDirectory: '$(Build.SourcesDirectory)'\n    pwsh: true # For Linux\n`\n```\nIn the `workingDirectory` set the path to where you want the file to be created.",
      "question_score": 10,
      "answer_score": 10,
      "created_at": "2021-07-27T12:00:42",
      "url": "https://stackoverflow.com/questions/68542830/create-a-json-file-during-azure-devops-build-pipeline"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 66597901,
      "title": "Install multiple Azure DevOps environment agents on server",
      "problem": "We have a dev server hosting webservices from multiple Azure DevOps projects. To use yaml deployment pipelines, we migrated from deployment pools to environments/resources. Unlike deployment pools neither environments nor resources can be shared between projects. You can upvote here to change that.\nWe work around this as follows.\n\nCreate an environment for each project.\nFor each environment add the dev server as a resource.\nInstall one environment agent per project on the server.\n\nUnfortunately, this creates a naming conflict if there is already an environment agent installed on the server.\n```\n`The service already exists: vstsagent.MyDevOpsAccount..MyServer, it will be replaced\nError: Operation CreateService failed with return code 1072\n`\n```",
      "solution": "TLDR: In the powershell installation script, change `--agent $env:COMPUTERNAME` to `--agent \"$env:COMPUTERNAME-MyProject\"`\nThe reason seems to be that the windows service name of the agent is determined as follows.\n`serviceName = StringUtil.Format(serviceNamePattern, accountName, settings.PoolName, settings.AgentName);\n`\nIt uses the Azure DevOps organization name, the name of the deployment pool and the agent name. Since the organization name is fixed and the deployment pool name unavailable for environment agents, the agent name seems to be the only chance.",
      "question_score": 10,
      "answer_score": 10,
      "created_at": "2021-03-12T11:08:58",
      "url": "https://stackoverflow.com/questions/66597901/install-multiple-azure-devops-environment-agents-on-server"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 79442808,
      "title": "No template with an identifier of &#39;xamarinandroid&#39; could be found",
      "problem": "Could not find a question about this, and just spent 1 day figuring this out, so as community service:\nTrying to create new Pipeline in a private Azure Devops project always results in the following error: `No template with an identifier of 'xamarinandroid' could be found`.\n\nMy repository has nothing to do with Xamarin. There are no options to choose from and  I cannot finish pipeline creation.\nHow can I create a new Pipeline?",
      "solution": "for people using the restclient extension in vscode (I'm not 100% certain but I thing there is also one for visual studio), here is an example of an *.http file to create a pipeline based on the answer by tonsteri\n```\n`@token=your-actual-personal-access-token\n@organization=your-organization\n@project=your-project\n@repositoryName=your-repository-name\n@repositoryId=the-id-of-the-repository\n\n### Create Pipeline and organize into folder /Publish or set to null\nPOST https://dev.azure.com/{{organization}}/{{project}}/_apis/pipelines/?api-version=7.1\ncontent-type: application/json\nAuthorization: Bearer {{token}}\n\n{\n    \"folder\": \"/Publish\",\n    \"name\": \"the-name-of-the-pipeline\",\n    \"configuration\": {\n      \"type\": \"yaml\",\n      \"path\": \"the-path-to-the-pipeline-yml-file\",\n      \"repository\": {\n        \"id\": \"{{repositoryId}}\",\n        \"name\": \"{{repositoryName}}\",\n        \"type\": \"azureReposGit\"\n      }\n    }\n}\n`\n```\ncopy, save as *.http file in vscode and then you should be able to click on the \"Send Request\"",
      "question_score": 10,
      "answer_score": 1,
      "created_at": "2025-02-16T09:34:59",
      "url": "https://stackoverflow.com/questions/79442808/no-template-with-an-identifier-of-xamarinandroid-could-be-found"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 75185189,
      "title": "Azure DevOps Pull Request policy requiring one of two required reviewers",
      "problem": "In my team, we have 6 developers, 2 of them are tech leads, so at least one of them needs to approve the PR. The other 4 developers are optional.\nIs there a way to allow to complete the PR if any one of the required reviewers/approvers approves the PR?\nI managed to add the two tech leads as required reviewers, but the issue is that both of them need to approve the PR.",
      "solution": "You can setup a minimum of reviewers as a branch policy:\n\nThen only use optional reviewers in the PR, as the policy already enforces one to be mandatory.\n\nTo achieve that one of those reviewers is a tech lead, create a group for the tech leads and make this group mandatory.\nAs soon as one of the members approves the PR it counts for the mandatory reviewer, and adds the user who approved it automatically as optional reviewer.\n\nThis group, tech leads in your use case, can then be configured as a branch policy, in Settings > Repositories > Build policy: :\n\nSince this is a branch policy, the look and feel is slightly different in the PR, but never the less your goals is achieved:",
      "question_score": 9,
      "answer_score": 18,
      "created_at": "2023-01-20T15:13:08",
      "url": "https://stackoverflow.com/questions/75185189/azure-devops-pull-request-policy-requiring-one-of-two-required-reviewers"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 65782514,
      "title": "Suppress warnings using .NET Core CLI task (DotNetCoreCLI@2) in Azure DevOps pipeline",
      "problem": "Trying to suppress warnings in Azure DevOps pipeline using .NET Core CLI task (DotNetCoreCLI@2), but getting the following error:\nMSBUILD : error MSB1001: Unknown switch.\nSwitch: --noWarn:MSB3277\nHere is an example of the code, which is similar to how the switch is used in a couple of posts I found related to msbuild cli reference:\n```\n`- task: DotNetCoreCLI@2\n  displayName: Release Build\n  inputs:\n    command: 'build'\n    projects: '${{ parameters.solutionPath }}'\n    arguments: --configuration Release --noWarn:MSB3277\n`\n```\nI have tried lowercase --nowarn as well, but still no luck, so any help with this issue would be gratefully appreciated.\nThanks in advance for your support,\nTerry",
      "solution": "Please use `/nowarn:msb3277`\n`- task: DotNetCoreCLI@2\n  displayName: Release Build\n  inputs:\n    command: 'build'\n    projects: '${{ parameters.solutionPath }}'\n    arguments: --configuration Release /nowarn:msb3277\n`",
      "question_score": 9,
      "answer_score": 13,
      "created_at": "2021-01-18T22:48:01",
      "url": "https://stackoverflow.com/questions/65782514/suppress-warnings-using-net-core-cli-task-dotnetcorecli2-in-azure-devops-pip"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 67197245,
      "title": "yaml pipeline job condition throwing unrecognized value error",
      "problem": "I have a pipeline in Azure DevOps which build my iOS application I want to separate the environments and what I am building for by jobs and conditions.  I have set up the initial parameter select:\n`parameters:\n  - name: Environment\n    displayName: \"Environment\"\n    type: string\n    default: Dev\n    values:\n    - Dev\n    - Live\n  - name: Build\n    displayName: \"Build\"\n    type: string\n    default: iPhone\n    values:\n    - iPhone\n    - iPhoneSimulator\n`\nand then where I set up the different job I have added a condition:\n`      - job:\n        condition: and(succeeded(), eq(${{ parameters.Build }}, iPhone))\n        steps:\n          - checkout: none\n`\nWhen I try to run this I get the following error:\n```\n`An error occurred while loading the YAML build pipeline. Unrecognized value: 'iPhone'. Located at position 21 within expression: and(succeeded(), eq(iPhone, iPhone)).\n`\n```",
      "solution": "`iPhone` is not a valid literal. Since parameter expansion happens before condition evaluation, you need to make sure that your condition has proper syntax after parameter expansion by enclosing string literals in single quotes:\n```\n`and(succeeded(), eq('${{ parameters.Build }}', 'iPhone'))\n`\n```",
      "question_score": 9,
      "answer_score": 18,
      "created_at": "2021-04-21T15:50:42",
      "url": "https://stackoverflow.com/questions/67197245/yaml-pipeline-job-condition-throwing-unrecognized-value-error"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 69165530,
      "title": "How to properly use expression results as booleans on Azure Devops pipelines?",
      "problem": "I'm trying to use an `or` expression to define a boolean on a template as follows:\n`parameters:\n  - name: A\n    default: true\n  - name: B\n    default: false\n\nstages:\n  - template: bacon.yml@template\n    parameters:\n      booleanParameter: or(eq(${{ parameters.A }}, true), eq(${{ parameters.B}}, true))\n`\nIn my head, it should work just fine, yet I keep getting this same error:\n```\n`The 'booleanParameter' parameter value 'or(eq(True, true), eq(False, true))' is not a valid Boolean.\n`\n```\nI've tried some small variations of syntax, all of them resulting in the same error.\nWhat am I missing here?",
      "solution": "You should use template expression to wrap whole expression:\n```\n`booleanParameter: ${{ or(eq(parameters.A, true), eq(parameters.B, true)) }}\n`\n```",
      "question_score": 9,
      "answer_score": 17,
      "created_at": "2021-09-13T17:38:59",
      "url": "https://stackoverflow.com/questions/69165530/how-to-properly-use-expression-results-as-booleans-on-azure-devops-pipelines"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 71583663,
      "title": "Android, Azure Devops geting error while run pipeline ##[error]Error: The process &#39;/Users/runner/work/1/s/gradlew&#39; failed with exit code 1",
      "problem": "Android, Azure Devops geting error while run pipeline  ##[error]Error: The process '/Users/runner/work/1/s/gradlew' failed with exit code 1\nAt locale system everything working apk generated but when run pipeline at azure devops it showing the error\n```\n`FAILURE: Build failed with an exception.\n\n* Where: Build file '/Users/runner/work/1/s/app/build.gradle' line: 2\n\n* What went wrong: An exception occurred applying plugin request [id: \n'com.android.application']\n > Failed to apply plugin 'com.android.internal.application'.\n   > Android Gradle plugin requires Java 11 to run. You are currently using Java 1.8.\n`\n```\nI'm already using Java 11\nI searched for same but not get any solution.",
      "solution": "I have solved the issue by adding task for maven in `azure-pipelines.yml`\n```\n`steps:\n  - task: Maven@3\n    inputs:\n      mavenPomFile: 'pom.xml'\n      publishJUnitResults: false\n      javaHomeOption: 'JDKVersion'\n      jdkVersionOption: '1.11'\n      mavenVersionOption: 'Default'\n      mavenOptions: '-Xmx3072m'\n`\n```\nHope this will helpful for other...",
      "question_score": 9,
      "answer_score": 8,
      "created_at": "2022-03-23T09:04:23",
      "url": "https://stackoverflow.com/questions/71583663/android-azure-devops-geting-error-while-run-pipeline-errorerror-the-proces"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 68621481,
      "title": "Failed to check the resource group status: 403 while deploying ARM template using CD pipeline through service principal/connection",
      "problem": "While deploying Azure Data Factory's ARM template through service principal, I am getting below error:\n[error]Failed to check the resource group status. Error: {\"statusCode\":403}.\nIs it a service connection Access related issue? How to check/resolve this?",
      "solution": "The error means the service principal used in your Azure DevOps service connection does not have enough permission to perform the action.\nTo solve the issue, you need to add an Azure RBAC role for the service principal, navigate to the `Project Settings` in Azure DevOps -> `Service connections` -> find the service connection you used(whose type is `Azure Resource Manager`) and select it -> select `Manage service connection roles`.\n\nThen it will open a page for the Azure subscription in Azure portal, navigate to the `Access control (IAM)` -> add your service principal as a `Contributor` role as below.\nNote: To assign the role for your service principal, your user account logged in Azure portal needs the RBAC role e.g. `Owner`, `User Access Administrator`.",
      "question_score": 9,
      "answer_score": 7,
      "created_at": "2021-08-02T14:18:27",
      "url": "https://stackoverflow.com/questions/68621481/failed-to-check-the-resource-group-status-403-while-deploying-arm-template-usin"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 71500900,
      "title": "Don&#39;t trigger builds for branches that already have a pull request in Azure DevOps",
      "problem": "We use Azure DevOps for continuous integration. The pipeline is configured to run a build whenever a change is pushed to a feature branch. This is desired for quick feedback.\nAdditionally, we have the policy for the master branch that a successful validation build is required before a feature branch can be merged. Azure DevOps now automatically triggers the corresponding validation build when a pull request (PR) is created for a feature branch.\nAll of this is fine, but there is an adversity: if a PR is already created and the feature branch is updated, two builds are triggered (one for the feature branch alone and one for the outcome of the merge, i.e., the validation build).\nI understand that some people might want both builds, but in our case (an probably in every normal case) it would be better if only the validation build was triggered.\nQuestion: Is there a way to tell Azure DevOps that it should ignore branch triggers for any branch that already has a PR? Workarounds with an equivalent outcome are also welcome, of course.\nThe question has already been posted as an issue here, but I could not find a satisfying answer in the replies (e.g., branch filters and a naming strategy do not solve the problem).",
      "solution": "I have solved the issue like suggested by Shamrai. I'm adding this as another answer to share my code.\nAdd the following PowerShell code to a step at the beginning of the pipeline. It uses the Azure DevOps REST API to check for an existing PR of the current branch. If there is no such PR or if the current build was manually queued, or if the PR is not ready to be merged (e.g. conflicts), the build continues as normal. Otherwise, it is cancelled.\n```\n`$BaseApiUri_Builds   = \"https://my.tfs.server.com/MyCollection/MyProject/_apis/build/builds\"\n$BaseApiUri_GitRepos = \"https://my.tfs.server.com/MyCollection/MyProject/_apis/git/repositories\"\n$AuthenicationHeader = @{ Authorization = \"Bearer ${env:System_AccessToken}\" }\n\n# Cancels the current build\nfunction Cancel-This-Build()\n{\n    Cancel-Build -BuildId ${env:Build_BuildId}\n}\n\n# Cancels the given build\nfunction Cancel-Build([String] $BuildId)\n{\n    Write-Host \"Cancelling build ${BuildId}...\"\n    \n    $BuildApiUri = \"${BaseApiUri_Builds}/${BuildId}?api-version=5.1\"\n    $CancelBody = @{ status = \"cancelling\" } | ConvertTo-Json\n    Invoke-RestMethod -Uri $BuildApiUri -Method PATCH -ContentType application/json -Body $CancelBody -Header $AuthenicationHeader\n}\n\n# Detects if a validation build is queued for the given branch. This is the case if an active PR exists that does not have merge conflicts.\nfunction Check-For-Validation-Build([String] $BranchName)\n{\n    Write-Host \"Checking for validation builds of branch '${BranchName}' in repository ${env:Build_Repository_ID}...\"\n    \n    $GetPRsApiUri = \"${BaseApiUri_GitRepos}/${env:Build_Repository_ID}/pullrequests?api-version=5.1&searchCriteria.sourceRefName=${BranchName}\"\n    $PRs = Invoke-RestMethod -Uri $GetPRsApiUri -Method GET -Header $AuthenicationHeader\n    \n    ForEach($PR in $PRs.Value)\n    {\n        Write-Host \"Found PR $($PR.pullRequestId) '$($PR.title)': isDraft=$($PR.isDraft), status=$($PR.status), mergeStatus=$($PR.mergeStatus)\"\n        \n        if (!$PR.isDraft -and ($PR.mergeStatus -eq \"succeeded\") -and ($PR.status -eq \"active\"))\n        {\n            Write-Host \"Validation build is queued for branch '${BranchName}'.\"\n            return $true\n        }\n    }\n    \n    Write-Host \"No validation build is queued for branch '${BranchName}'.\"\n    return $false\n}\n\n# Check if a valid PR exists. If so, cancel this build, because a validation build is also queued. \n$HasValidationBuild = Check-For-Validation-Build -BranchName ${env:Build_SourceBranch}\nif (($HasValidationBuild -eq $true) -and (${env:Build_Reason} -ne \"Manual\") -and !${env:Build_SourceBranch}.EndsWith('/merge'))\n{\n    Cancel-This-Build\n}\n`\n```\nNote that the `System.AccessToken` environment variable must be made visible for the script to work.",
      "question_score": 9,
      "answer_score": 4,
      "created_at": "2022-03-16T17:34:16",
      "url": "https://stackoverflow.com/questions/71500900/dont-trigger-builds-for-branches-that-already-have-a-pull-request-in-azure-devo"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 70438197,
      "title": "Can I run Azure DevOps pipeline without committing it?",
      "problem": "I am planning to experiment building a pipeline using Azure DevOps. One thing that I noticed early on is, after `azure-pipelines.yml` created, I have to commit this first before being able to run it. But I want to experiment on it which revolves around trial and error. Doing multiple commit just to test things out are not feasible.\nIn Jenkins I can just define my steps and try to run it without committing the file.\nIs this also possible to do in Azure DevOps?",
      "solution": "You cannot run YAML pipelines without committing them, but you can create classic pipelines and run them without committing anything pipeline-related to the repository (except for the source code you want to build). Classic pipelines  can later be turned (or copy-pasted, to be exact) into yaml pipelines with view YAML -option.\nhttps://learn.microsoft.com/en-us/azure/devops/pipelines/get-started/pipelines-get-started?view=azure-devops#define-pipelines-using-the-classic-interface",
      "question_score": 9,
      "answer_score": 1,
      "created_at": "2021-12-21T16:56:03",
      "url": "https://stackoverflow.com/questions/70438197/can-i-run-azure-devops-pipeline-without-committing-it"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 67570577,
      "title": "Changing the working directory for all steps in Azure Pipelines YAML",
      "problem": "It's possible to set the working directory for separate scripts:\n`- script: foo\n  workingDirectory: bar\n`\nHowever, if all the steps are meant to run in a specific directory, it becomes repetitive to define it for each step.\nUsing `cd` doesn't affect other steps:\n```\n`- script: cd foo\n- script: pwd # returns default working dir instead of foo\n`\n```\nTwo specific examples for when this issue matters are:\n\nwhen checking out multiple repos as resources, so the default working directory is one level above the checked out repos\nwhen running a pipeline for a project that's located in a subdirectory (like in a monorepo)",
      "solution": "Instead of changing the working directory for the tasks, a workaround is to move the files into the default working directory, and a convenient way to do it is using `git-sparse-checkout` like so:\n```\n`git sparse-checkout set example && mv example/{*,.*} . || true\n`\n```\nThe `{*,.*}` part is for also moving the dotfiles, and `|| true` is needed because that also tries to move `.` and `..`.",
      "question_score": 9,
      "answer_score": 2,
      "created_at": "2021-05-17T15:23:16",
      "url": "https://stackoverflow.com/questions/67570577/changing-the-working-directory-for-all-steps-in-azure-pipelines-yaml"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 66696715,
      "title": "Azure devops pipeline is not running because you have reached the maximum number of requests that can run for parallelism",
      "problem": "type 'Microsoft-Hosted Private'\nGetting this error running a pipeline on a new account so there're enough credits/limits\nIt has been stuck for close 20+ hours now, have tried to recreate projects/subscriptions/pipelines and what not but no dice\nThere are similar questions on vscommunity but no answers so hoping someone has insights here\nTurns out this is a \"feature\" implemented recently, closing this question\nwill leave it here till it's deleted or whatever in case someone stumbles upon this same error\nhttps://devblogs.microsoft.com/devops/change-in-azure-pipelines-grant-for-private-projects/",
      "solution": "The root cause of the stuck issue is that the pipeline microsoft-hosted agent for public and private projects in the new organization has been restricted in the latest update.\nFor more detailed info, you could refer to these two docs: Private Project Pipelines, Public Project Pipelines.\nIn Release 183, the reasons for adding restrictions are as follows:\n\nOver the past few months, the situation has gotten substantially worse, with a high percentage of new public projects in Azure DevOps being used for crypto mining and other activities we classify as abusive. In addition to taking an increasing amount of energy from the team, this puts our hosted agent pools under stress and degrades the experience of all our users \u2013 both open-source and paid.\n\nPrivate Project:\nYou could send email to `azpipelines-freetier@microsoft.com` in order to get your free tier.\n\nYour name\nName of the Azure DevOps organization\n\nPublic Project:\nYou could send email to `azpipelines-ossgrant@microsoft.com` in order to get your free tier.\n\nYour name\nAzure DevOps organization for which you are requesting the free grant\nLinks to the repositories that you plan to build\nBrief description of your project",
      "question_score": 8,
      "answer_score": 18,
      "created_at": "2021-03-18T19:06:48",
      "url": "https://stackoverflow.com/questions/66696715/azure-devops-pipeline-is-not-running-because-you-have-reached-the-maximum-number"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 77458849,
      "title": "Error The Angular CLI requires a minimum Node.js version of v18.13 in Azure Pipelines",
      "problem": "My Azure pipeline started to fail. My error is at follows:\n`Node.js version v16.20.2 detected.\nThe Angular CLI requires a minimum Node.js version of v18.13.\n\n`\nI didnt change anything. This is part of my pipeline:\n`pool:\n  vmImage: 'ubuntu-latest'\n\nsteps:\n- task: NodeTool@0\n  inputs:\n    versionSpec: '16.x'\n  displayName: 'Install Node.js'\n\n- script: |\n    sudo npm install -g @angular/cli\n    npm install\n    ng build -c=release --output-path=web/wwwroot\n  displayName: 'npm install and build'\n`\nTwo weeks ago that script works.\nMy question is, how to fix it in Azure pipelines? I am using Microsoft hosted agents",
      "solution": "I can reproduce the same issue with the same YAML Pipeline.\n\nThe cause of the issue is that the command: npm install -g @angular/cli will download the latest angular cli package by default.\nThe latest Angular CLI version 17.0.0 requests the node version 18.13.\nTo solve this issue, you can downgrade the angular CLI version in Azure Pipeline.\nFor example: `npm install -g @angular/cli@16.2.10`\n```\n`steps:\n- task: NodeTool@0\n  inputs:\n    versionSpec: '16.x'\n  displayName: 'Install Node.js'\n\n- script: |\n    npm install -g @angular/cli@16.2.10\n    npm install\n    ng build --prod\n  displayName: 'npm install and build'\n`\n```",
      "question_score": 8,
      "answer_score": 14,
      "created_at": "2023-11-10T10:11:32",
      "url": "https://stackoverflow.com/questions/77458849/error-the-angular-cli-requires-a-minimum-node-js-version-of-v18-13-in-azure-pipe"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 75261412,
      "title": "YAML Implicit keys need to be on a single line, Implicit map keys need to be followed by map values",
      "problem": "`trigger:\n- develop\n\npool:\n  vmImage: windows-2019\n\n- task: MSBuild@1\n  inputs:\n    solution: '**/*.sln'\n- task: DownloadBuildArtifacts@1\n  inputs:\n    buildType: 'current'\n    downloadType: 'single'\n    itemPattern: '**/*.exe'\n    downloadPath: '$(System.ArtifactsDirectory)'\n`\nI get an error with this YAML in both Azure DevOps and using the YAML extension for VS Code.  I'm trying to build a Windows Service and then put the .exe file somewhere that I can download it.\nAzure DevOps:\n\nVSCode\n\nError:\n\nImplicit keys need to be on a single line, Implicit map keys need to\nbe followed by map values",
      "solution": "Although the error looks some what confusing, your are missing the keyword `steps`.\n`\ntrigger:\n- develop\n\npool: \n  vmImage: windows-2019\n\nsteps:\n- task: MSBuild@1 \n  inputs: \n    solution: '**/*.sln'\n- task: DownloadBuildArtifacts@1 \n  inputs: \n    buildType: 'current' \n    downloadType: 'single' \n    itemPattern: '**/*.exe' \n    downloadPath: '$(System.ArtifactsDirectory)' \n\n`",
      "question_score": 8,
      "answer_score": 7,
      "created_at": "2023-01-27T18:25:54",
      "url": "https://stackoverflow.com/questions/75261412/yaml-implicit-keys-need-to-be-on-a-single-line-implicit-map-keys-need-to-be-fol"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 75210497,
      "title": "Allowing &#39;delete branch&#39; without allowing &#39;rewrite history&#39; in Azure DevOps",
      "problem": "If I try to remove a branch from an Azure DevOps GIT repository, the Force Push permission is required, according to the error message that is shown:\n\nHowever, allowing \"force pushes\" also allows rewriting history. This is even explicitly stated at the place these rights are configured.\n\nIn my understanding of Git, branches are nothing more than bookmarks/shortcuts to changes. In a way, they're a special kind of tag. If these are discarded at during a merge, no force push right is required.\nI'd like to authorize people to be able to delete branches without giving them the right to mess with history. They shouldn't be able to edit/remove actual change set, but they can do all the want to these special kinds of tags. How do I configure that?\nOr am I misunderstanding the amount of history one can rewrite by allowing force pushes? All I'd like preserved is what code change was checked in by whom. Can this history be broken by allowing force pushes?",
      "solution": "I'd like to authorize people to be able to delete branches without giving them the right to mess with history.\n\nBased on the available permission options, you can't achieve exactly what you're asking, however, it turns out that there's probably a better way anyway. If tl;dr applies then skip to the bottom section: \"Where you probably want to land\".\nBackground, Q and A style:\n\nQuestion: What is a \"force push\"?\n\nWe usually say \"a force push rewrites history.\" Another way to think about this which may be more useful in the context of this question is: A \"force push\" is required anytime you wish to remove one or more commits from the branch's reachable history. If you aren't doing that, and the tip of the remote branch is reachable by the new tip commit you are pushing, then a regular push will suffice.\n\nQuestion: Why are \"force push\" and \"delete branches\" lumped together into the same permission?\n\nConsider a branch that reaches 3 commits: `A-B-C`\nAdd one commit: `A-B-C-D` = regular push.\nRemove one commit: `A-B` = force push.\nReplace one commit completely (i.e. remove one and add one commit): `A-B-X` = force push.\nModify one commit slightly (i.e. remove one and add one commit): `A-B-C'` = force push.\nRemove all commits (i.e. delete the branch) = force push.\nIf we define a \"force push\" as \"removing one or more commits from a branch\", then deleting a branch is conceptually a subset of that (removing all commits), and there is a special syntax for deleting a branch: `git push -d origin my-branch` or `git push origin :my-branch`.\nNow let's suppose we did what you asked: We could define \"force push\" as \"remove one or more commits, but not all commits\", and then separate the permissions such that you enable \"delete a branch\" but do not allow \"force push\". As pointed out in Romain Valeri's comment, there's nothing to stop someone from deleting a branch, and then re-using that branch name to push out a new commit- effectively achieving a \"force push\" anyway. That being said, if you added a third permission for \"Create a new branch\", then perhaps your desire would work. However, allowing people to delete a branch but not create a branch would likely cause more pain than it solves in most workflows. (This doesn't mean no one would find value in it though...)\n\nQuestion: When is it OK to use \"force push\"?\n\nThis is highly dependent on your situation and preferences. Some people believe the answer is \"never\", though that strict dogma is probably in the minority view. The majority position is to disallow force pushing shared branches, and allowing force pushing otherwise. In general, and especially in private repos, it's pretty common for people to have their own personal branches that they are working on, and therefore regularly rebasing those branches against a shared target is encouraged, so force pushing personal branches would be considered a normal and frequent occurrence. In a private AzDO repo it therefore makes sense to allow both deleting and force pushing a branch, as long as it's a personal branch.\nWhere you probably want to land in Azure DevOps:\n\nFor all users that will contribute to any AzDO Git repos, by default, set:\nAllow for \"Contribute\" and \"Force Push\".\nNot set for everything else.\nNote these settings will apply to most branches.\n\nFor specific protected branches, use branch policies. This will require a Pull Request (with many configurable options) in order to merge into protected branches, and effectively also prevents anyone from force pushing or deleting these branches.\n\nFor protected branches, if needed, you can optionally add additional security by turning off inheritance, and then setting explicit security if required. In that case you could add \"Contribute\" for the set of users that can complete PRs into the branch, but (probably) don't include \"Force Push\" this time1. Additional permission examples might include:\n\nYou may have a specific set of automated build users that are allowed to \"Bypass polices when pushing\" so they can push commits without a Pull Request.\nPerhaps a group of people that are allowed to \"Bypass policies when completing Pull Request\" if they need to bypass a gated checkin, or use a certain type of merge that is not allowed by the branch policy.\nA set of Admins that are given \"Manage Permissions\", so in an emergency scenario where a force push is required, they can temporarily give someone the ability to \"Force Push\" and \"Bypass polices when pushing\", and then remove those 2 permissions right after the force push is done.\n\nAzure DevOps tried to prevent this, and almost succeeded:\nI think it's important to point out that behind the scenes, AzDO actually  assigns meaning to the creator of a branch. This concept doesn't actually exist in Git, but (by trial and error I've confirmed that) AzDO defines it as:\n\nThe branch creator is the most recent authenticated user to push a branch name when it didn't exist.\n\nNote this means that the branch creator can change, for example if the branch is deleted and then someone else pushes a branch of the same name- the last person to push it while it doesn't exist becomes the creator. Also, the person to push is the person that is authenticated in AzDO (either in the client or in the UI); this person has nothing to do with the author of the commits on the branch.\nThe interesting part here is that the \"creator\" of a branch automatically gets additional permissions to that branch, including force-push permissions, which means that if you don't enable force-push for everyone by default like I recommend above, this person (or an admin or group of people specifically given force push permissions) can still delete their own branch. IMHO this was a really good attempt to avoid giving everyone force-push permissions, but in practice I've found it doesn't work. The problem is that when you select the option to delete your branch upon completing a PR, it will only work if the \"creator\" of that branch is the person to complete the PR. If anyone else completes the PR, the branch deletion will fail. This is a significant enough problem in my workflow with many people completing other people's PRs that we have to give everyone force-push permission by default.\n\n1 Note that once branch policies are enabled, in order to force push you must have \"Allow\" set for two permissions: \"Force Push\" and \"Bypass polices when pushing\". This means that it's OK for any user to have one or the other, as long as they don't have both. This is why you \"probably\" want to remove \"force push\" permission from everyone on protected branches, for sanity purposes, but it may not be actually necessary to do so.",
      "question_score": 8,
      "answer_score": 17,
      "created_at": "2023-01-23T14:54:11",
      "url": "https://stackoverflow.com/questions/75210497/allowing-delete-branch-without-allowing-rewrite-history-in-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 71307245,
      "title": "Terraform source error - Error: Failed to query available provider packages",
      "problem": "I am trying to deploy a new infrastructure using terraform (for the first time) and I am getting the following error. I've tried everything but nothing seems to fix the issue.\nLooks like it is asking for a provider hashicorp/azure ?\nCan anyone help please??\n```\n`Initializing provider plugins...\n- Finding latest version of hashicorp/azure...\n- Finding hashicorp/azurerm versions matching \"2.98.0\"...\n- Installing hashicorp/azurerm v2.98.0...\n- Installed hashicorp/azurerm v2.98.0 (signed by HashiCorp)\n\u2577\n\u2502 Error: Failed to query available provider packages\n\u2502 \n\u2502 Could not retrieve the list of available versions for provider hashicorp/azure: provider registry registry.terraform.io does not have a provider named registry.terraform.io/hashicorp/azure\n\u2502 \n\u2502 Did you intend to use terraform-providers/azure? If so, you must specify that source address in each module which requires that provider. To see which modules are currently depending on hashicorp/azure, run the following command:\n\u2502     terraform providers\n\u2575\n\nlucas@Azure:~$ terraform providers\n\nProviders required by configuration:\n.\n\u251c\u2500\u2500 provider[registry.terraform.io/hashicorp/azurerm] 2.98.0\n\u2514\u2500\u2500 provider[registry.terraform.io/hashicorp/azure]\n`\n```\nThe code that I am using to create the infrastructure is the below:\n```\n`  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"=2.98.0\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  features {}\n  subscription_id = \"910910be-a61e-4e1f-a72a-7e43456c0836\"\n}\n\n# Create a resource group\nresource \"azurerm_resource_group\" \"rg\" {\n  name     = \"default\"\n  location = \"West Europe\"\n}\n\n# Create a virtual network\nresource \"azurerm_virtual_network\" \"vpc\" {\n  name                = \"default-network\"\n  resource_group_name = azurerm_resource_group.rg.name\n  location            = azurerm_resource_group.rg.location\n  address_space       = [\"10.0.0.0/16\"]\n}\n\n# Create frontend subnet\nresource \"azurerm_subnet\" \"subnet_frontend\" {\n  name                 = \"internal\"\n  resource_group_name  = azurerm_resource_group.rg.name\n  virtual_network_name = azurerm_virtual_network.vpc.name\n  address_prefixes     = [\"10.0.1.0/24\"]\n}\n\n# Create backend subnet\nresource \"azurerm_subnet\" \"subnet_backend\" {\n  name                 = \"internal\"\n  resource_group_name  = azurerm_resource_group.rg.name\n  virtual_network_name = azurerm_virtual_network.vpc.name\n  address_prefixes     = [\"10.0.2.0/24\"]\n}\n\n# Create frontend network interface\nresource \"azurerm_network_interface\" \"frontend_nic\" {\n  name                = \"frontend_nic\"\n  location            = azurerm_resource_group.rg.location\n  resource_group_name = azurerm_resource_group.rg.name\n\n  ip_configuration {\n    name                          = \"internal\"\n    subnet_id                     = azurerm_subnet.subnet_frontend.id\n    private_ip_address_allocation = \"Dynamic\"\n  }\n}\n\n# Create backend network interface\nresource \"azurerm_network_interface\" \"backend_nic\" {\n  name                = \"backend_nic\"\n  location            = azurerm_resource_group.rg.location\n  resource_group_name = azurerm_resource_group.rg.name\n\n  ip_configuration {\n    name                          = \"internal\"\n    subnet_id                     = azurerm_subnet.subnet_backend.id\n    private_ip_address_allocation = \"Dynamic\"\n  }\n}\n\n# Create frontend VM based on module\nresource \"azure_instance\" \"frontend\" {\n  source   = \"./vm\"\n  name     = \"frontend\"\n  rg       = module.azurerm_resource_group.rg.name\n  location = module.azurerm_resource_group.rg.location\n  nic      = module.azurerm_network_interface.frontend_nic\n}\n\n# Create backend VM based on module\nresource \"azure_instance\" \"backend\" {\n  source   = \"./vm\"\n  name     = \"backend\"\n  rg       = module.azurerm_resource_group.rg.name\n  location = module.azurerm_resource_group.rg.location\n  nic      = module.azurerm_network_interface.backend_nic\n} \n`\n```\nMy terraform version is: Terraform v1.1.5 and I am using on Azure CLI via bash.\nAny idea of what is causing this issue and how to fix it?\nThanks!",
      "solution": "This often happens when one accidentally specifies \"hashicorp/azure\" or \"hashicorp/azurem\" instead of \"hashicorp/azurerm\" in the required_providers block. Did you check the \"vm\" module referenced in the \"azure_instance\" module calls? There might be an erroneous \"hashicorp/azure\" specified there.",
      "question_score": 8,
      "answer_score": 10,
      "created_at": "2022-03-01T11:44:26",
      "url": "https://stackoverflow.com/questions/71307245/terraform-source-error-error-failed-to-query-available-provider-packages"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 70874759,
      "title": "CopyFiles Task not picking up files",
      "problem": "Using Azure DevOps YAML in a database project build and release pipeline\nThis bit of code correctly picks up my four dacpac files, I can see these being copied in the console\n```\n`    - task: CopyFiles@2\n      displayName: Copy build output to artifacts staging\n      inputs:\n        SourceFolder: \"$(Build.SourcesDirectory)\"\n        flattenFolders: true\n        Contents: '**\\bin\\**\\*.dacpac'\n        TargetFolder: \"$(Build.ArtifactStagingDirectory)\"\n`\n```\nThis bit of code correctly picks up my publish files, I can see these being copied in the console\n```\n`    - task: CopyFiles@2\n      displayName: Copy build output to artifacts staging\n      inputs:\n        SourceFolder: \"$(Build.SourcesDirectory)\"\n        flattenFolders: true\n        Contents: '**\\PublishProfile\\*.publish.xml'\n        TargetFolder: \"$(Build.ArtifactStagingDirectory)\"\n`\n```\nThis bit of code reports \"zero files found\"\n```\n`    - task: CopyFiles@2\n      displayName: Copy build output to artifacts staging\n      inputs:\n        SourceFolder: \"$(Build.SourcesDirectory)\"\n        flattenFolders: true\n        Contents: |\n          '**\\bin\\**\\*.dacpac'\n          '**\\PublishProfile\\*.publish.xml'\n        TargetFolder: \"$(Build.ArtifactStagingDirectory)\"\n`\n```\nThis pipe multiline syntax is all over the examples\nhttps://learn.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/copy-files?view=azure-devops&tabs=yaml#examples\nI've also used Get-ChildItem to doubly confirm that the files exist.\nIt seems like | / multiline doesn't work as described.",
      "solution": "As usual, as I write this I checked in detail and the one difference between my code and the example was single quotes.\nSo it works if you remove single quotes.\nDoes anyone even QA this stuff?\n```\n`    - task: CopyFiles@2\n      displayName: Copy build output to artifacts staging\n      inputs:\n        SourceFolder: \"$(Build.SourcesDirectory)\"\n        flattenFolders: true\n        Contents: |\n          # NOTE THESE PATHS ARE NOT SURROUNDED BY SINGLE QUOTES\n          # EVEN THOUGH THIS WORKS IN THE SINGLE LINE VERSION\n          **\\bin\\**\\*.dacpac\n          **\\PublishProfile\\*.publish.xml\n        TargetFolder: \"$(Build.ArtifactStagingDirectory)\"\n`\n```\nOther hot tips to save you hours:\n\nUse this to list files to help troubleshoot missing files\n```\n`- task: Bash@3\n  inputs:\n    targetType: inline\n    workingDirectory: $(PIPELINE.WORKSPACE)\n    script: ls -R\n`\n```\n\nRemember Linux is CASE SENSITIVE - get the case wrong and it won't find your files\n\nAs of right now, you can't parameterise service connections. Maybe that will change in future\n\nIt's possible to get indentation wrong in YAML and it gives you no clues\n\nThis code makes all the variables in the variable group `TST` available (these are under \"Library\" not \"Environment\" - go figure)\n```\n`variables:\n- group: TST\n`\n```\nThis code (with extra indentation) doesn't throw an error or give any clues, it just doesn't make any variables available. All your variables like `$(MyVariable)` will be treated as literals\n```\n`variables:\n  - group: TST\n`\n```",
      "question_score": 8,
      "answer_score": 15,
      "created_at": "2022-01-27T08:28:59",
      "url": "https://stackoverflow.com/questions/70874759/copyfiles-task-not-picking-up-files"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 69733179,
      "title": "Azure Devops - Hosted pool - ubuntu latest - How do i get ubuntu-latest to have the latest visual studio build tools (preview 2022)?",
      "problem": "Our azure devops pipelines are configured to use hosted ubuntu-latest\n\nI am using Azure Functions that require the package: packages/microsoft.net.sdk.functions/4.0.0\nThe hosted ubuntu latest is throwing non compatible framework version error.\n```\n` /home/vsts/.nuget/packages/microsoft.net.sdk.functions/4.0.0/build/Microsoft.NET.Sdk.Functions.Build.targets(32,5):\n error : It was not possible to find any compatible framework version \n /home/vsts/.nuget/packages/microsoft.net.sdk.functions/4.0.0/build/Microsoft.NET.Sdk.Functions.Build.targets(32,5):\n error : The framework 'Microsoft.NETCore.App', version\n '6.0.0-rc.1.21451.13' was not found.**\n`\n```\n\nWhen changing the pool to run on an on premise build agent, I was able to install the latest build tools (the one that comes with visual studio 2022 preview) and everything works fine.\nMy question is how do I get the ubuntu-latest to have the latest dotnet build tools?\nThis is the output of dotnet info of the ubuntu-latest agent.\n```\n`2021-10-27T04:54:16.4629465Z .NET SDKs installed:\n2021-10-27T04:54:16.4630372Z   2.1.302 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4630865Z   2.1.403 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4631327Z   2.1.526 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4631821Z   2.1.617 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4632292Z   2.1.701 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4632746Z   2.1.818 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4633218Z   3.1.120 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4633687Z   3.1.202 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4634147Z   3.1.302 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4634616Z   3.1.414 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4635086Z   5.0.104 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4635541Z   5.0.208 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4636008Z   5.0.303 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4636462Z   5.0.402 [/usr/share/dotnet/sdk]\n2021-10-27T04:54:16.4636703Z \n2021-10-27T04:54:16.4637082Z .NET runtimes installed:\n2021-10-27T04:54:16.4637683Z   Microsoft.AspNetCore.All 2.1.2 [/usr/share/dotnet/shared/Microsoft.AspNetCore.All]\n2021-10-27T04:54:16.4638405Z   Microsoft.AspNetCore.All 2.1.5 [/usr/share/dotnet/shared/Microsoft.AspNetCore.All]\n2021-10-27T04:54:16.4639112Z   Microsoft.AspNetCore.All 2.1.12 [/usr/share/dotnet/shared/Microsoft.AspNetCore.All]\n2021-10-27T04:54:16.4639839Z   Microsoft.AspNetCore.All 2.1.24 [/usr/share/dotnet/shared/Microsoft.AspNetCore.All]\n2021-10-27T04:54:16.4640553Z   Microsoft.AspNetCore.All 2.1.30 [/usr/share/dotnet/shared/Microsoft.AspNetCore.All]\n2021-10-27T04:54:16.4641691Z   Microsoft.AspNetCore.App 2.1.2 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n2021-10-27T04:54:16.4642420Z   Microsoft.AspNetCore.App 2.1.5 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n2021-10-27T04:54:16.4643130Z   Microsoft.AspNetCore.App 2.1.12 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n2021-10-27T04:54:16.4643823Z   Microsoft.AspNetCore.App 2.1.24 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n2021-10-27T04:54:16.4644541Z   Microsoft.AspNetCore.App 2.1.30 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n2021-10-27T04:54:16.4645263Z   Microsoft.AspNetCore.App 3.1.4 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n2021-10-27T04:54:16.4645958Z   Microsoft.AspNetCore.App 3.1.6 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n2021-10-27T04:54:16.4646889Z   Microsoft.AspNetCore.App 3.1.20 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n2021-10-27T04:54:16.4647598Z   Microsoft.AspNetCore.App 5.0.4 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n2021-10-27T04:54:16.4648286Z   Microsoft.AspNetCore.App 5.0.9 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n2021-10-27T04:54:16.4648995Z   Microsoft.AspNetCore.App 5.0.11 [/usr/share/dotnet/shared/Microsoft.AspNetCore.App]\n2021-10-27T04:54:16.4649693Z   Microsoft.NETCore.App 2.1.2 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n2021-10-27T04:54:16.4650357Z   Microsoft.NETCore.App 2.1.5 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n2021-10-27T04:54:16.4651045Z   Microsoft.NETCore.App 2.1.12 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n2021-10-27T04:54:16.4651737Z   Microsoft.NETCore.App 2.1.24 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n2021-10-27T04:54:16.4652407Z   Microsoft.NETCore.App 2.1.30 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n2021-10-27T04:54:16.4653101Z   Microsoft.NETCore.App 3.1.4 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n2021-10-27T04:54:16.4653781Z   Microsoft.NETCore.App 3.1.6 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n2021-10-27T04:54:16.4654445Z   Microsoft.NETCore.App 3.1.20 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n2021-10-27T04:54:16.4655124Z   Microsoft.NETCore.App 5.0.4 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n2021-10-27T04:54:16.4655799Z   Microsoft.NETCore.App 5.0.9 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n2021-10-27T04:54:16.4656459Z   Microsoft.NETCore.App 5.0.11 [/usr/share/dotnet/shared/Microsoft.NETCore.App]\n2021-10-27T04:54:16.4656807Z \n`\n```",
      "solution": "use this in your pipeline definition:\n`- task: UseDotNet@2\n  displayName: 'Use .NET Core sdk'\n  inputs:\n    version: 6.0.x\n    includePreviewVersions: true\n`\nTo explain, firstly Visual Studio only runs on Windows, so you can't install Visual Studio on Linux, but that's fine because you actually only want the .NET SDK. Secondly, both Visual Studio 2022 and .NET 6 are in preview.\nNext, Azure DevOps have documented what software is pre-installed on all their hosted agents: https://learn.microsoft.com/en-us/azure/devops/pipelines/agents/hosted?view=azure-devops&tabs=yaml#software\nIf you follow the link to .NET Core SDK on Ubuntu 20.04 (latest), you see that they only pre-install Generally Available (GA; released) versions of the .NET SDK, not preview versions.  After all, most customers building their production applications don't want the risk of using preview tools that might have bugs and break their builds.\nSo, if you want a preview .NET SDK, you need to explicitly install it as part of your build steps. The UseDotNet task does that, allowing you to specify a bunch of parameters, but in this case the most important two are version and include preview versions.\nFor other scenarios, for example anyone not using Azure Pipelines, the .NET team also have dotnet-install scripts, which you can download and execute in your pipeline.\nFor what it's worth, .NET 6 is having a launch party on the 9th to the 11th of November, and Visual Studio 2022 is having a launch event on the 8th of November. I don't know how quickly Azure DevOps will update their VM images with the newly released tools, but I guess it will be within days, so installing preview tooling in your build scripts won't be needed for much longer, unless you want to keep using preview tools. Note that once .NET 6 SDK's 6.0.100 goes GA, then the script that installs preview 6.0.x tooling will start installing the preview 6.0.200 previews",
      "question_score": 8,
      "answer_score": 15,
      "created_at": "2021-10-27T07:24:43",
      "url": "https://stackoverflow.com/questions/69733179/azure-devops-hosted-pool-ubuntu-latest-how-do-i-get-ubuntu-latest-to-have"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 69310342,
      "title": "Azure YAML Pipelines: How to refer a project and repo in another project in Azure DevOps",
      "problem": "I am in an Organization ABC, It has three Azure DevOps projects, namely A, B, and C. Everything is under Azure Repos that means we are not using GitHub.\nI am trying to perform a checkout in Project C the repos from project A and B. Every project will have its ow microservices but Shared Platform Services will automate what needs to be deployed into AKS.\nProblem Statement: I get error like below when I am trying to checkout repos from projects A and B in Project C. Snippet is as below:\n```\n`resources:\n  repositories:\n    - repository: microservice-a\n      type: git\n      name: 'InPlaceCommunications/microservice-a'\n      ref: master\n\n    - repository: microservice-b\n      type: git\n      name: 'Project B/microservice-b'\n      ref: master\n`\n```\nHowever, I get error as below:\n\nremote: TF401019: The Git repository with name or identifier microservice-a does not exist or you do not have permissions for the operation you are attempting.\n\nI do note that I have full permissions to clone the repo myself it is just not happening on the Pipeline.",
      "solution": "remote: TF401019: The Git repository with name or identifier microservice-a does not exist or you do not have permissions for the operation you are attempting.\n\nBased on the error message, you need to check the following two points:\n\nCheck if the option Limit job authorization scope to current project for non-release pipelines is disable in Project C -> Project Settings -> Settings. You need to disable this option.\n\nCheck if the Service Account: Project Collection Build Service (OrganizationName) has the Read Permission in Project A/B -> Project Settings -> Repositories -> Target repos -> Security.",
      "question_score": 8,
      "answer_score": 13,
      "created_at": "2021-09-24T08:14:02",
      "url": "https://stackoverflow.com/questions/69310342/azure-yaml-pipelines-how-to-refer-a-project-and-repo-in-another-project-in-azur"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 67483599,
      "title": "Azure Devops Get a repositoryId by using repository name",
      "problem": "I am writing a BASH script, where its creating an azure repo and then pushing code. post this step it will go-ahead and create an azure pipeline via `azure-pipeline.yaml` file present in the Azure repo.\nAt this step we need to pass the repository ID in-order to create the pipeline, but issue here is I can't keep it as a user input as it will be getting created within script itself, now I am struck with this.\nIs there any way that we can get the repo id from the newly created repo directly within the script?\n```\n`https://dev.azure.com/{{organization}}/{{project}}/_apis/pipelines?api-version=6.0-preview.1\n`\n```\n```\n`{\n    \"folder\": \"Folder-Name\",\n    \"name\": \"Pipeline-Name\",\n    \"configuration\": {\n        \"type\": \"yaml\",\n        \"path\": \"azure-pipelines.yml\",\n        \"repository\": {\n            \"id\": \"Repo-ID\",\n            \"name\": \"Repo-Name\",\n            \"type\": \"azureReposGit\"\n        }\n    }\n}\n`\n```",
      "solution": "This can be done by taking the output to another file as a variable (As suggested by @Shayki Abramczyk), then with the help of below command we can call the ID variable in the script file\n```\n`$ jq -r '.id' Repooutput.txt\ndad04f6d-4e06-4420-b0bc-cb2dcfee2dcf\n\n`\n```",
      "question_score": 8,
      "answer_score": 1,
      "created_at": "2021-05-11T10:59:14",
      "url": "https://stackoverflow.com/questions/67483599/azure-devops-get-a-repositoryid-by-using-repository-name"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 78853139,
      "title": "Azure Pipeline fails to checkout a submodule",
      "problem": "I have an Azure DevOps pipeline that should run for every push on the master branch. My repository has a submodule defined:\n```\n`[submodule \"submodules/shared_components\"]\n    path = submodules/shared_components\n    url = ../shared_components\n`\n```\nThe submodule is basically checked out (when using `git clone  --recurse-submodules -j8`) and everything works fine. However, my Azure pipeline is unable to do a checkout on the submodule, claiming:\n```\n`git submodule sync --recursive\ngit --config-env=http.https://myorg@dev.azure.com.extraheader=env_var_http.https://myorg@dev.azure.com.extraheader submodule update --init --force --depth=1 --recursive\nSubmodule 'submodules/shared_backend' (https://myorg@dev.azure.com/myorg/MyProject/_git/shared_backend) registered for path 'submodules/shared_backend'\nCloning into '/home/vsts/work/1/s/submodules/shared_backend'...\nremote: TF401019: The Git repository with name or identifier shared_backend does not exist or you do not have permissions for the operation you are attempting.\nfatal: repository 'https://dev.azure.com/myorg/MyProject/_git/shared_backend/' not found\nfatal: clone of 'https://myorg@dev.azure.com/myorg/MyProject/_git/shared_backend' into submodule path '/home/vsts/work/1/s/submodules/shared_backend' failed\nFailed to clone 'submodules/shared_backend'. Retry scheduled\nCloning into '/home/vsts/work/1/s/submodules/shared_backend'...\nremote: TF401019: The Git repository with name or identifier shared_backend does not exist or you do not have permissions for the operation you are attempting.\nfatal: repository 'https://dev.azure.com/myorg/MyProject/_git/shared_backend/' not found\nfatal: clone of 'https://myorg@dev.azure.com/myorg/MyProject/_git/shared_backend' into submodule path '/home/vsts/work/1/s/submodules/shared_backend' failed\nFailed to clone 'submodules/shared_backend' a second time, aborting\n##[error]Git submodule update failed with exit code: 1\n`\n```\nConsidering the fact that the main repository (the one with the `azure-pipeline.yml`) gets checked out just fine, it makes no sense to me that the submodule could not be checked out, especially since both repositories are in the same Azure DevOps organization and also in the same project. This is my YAML file:\n`trigger:\n- master\n\npool:\n  vmImage: ubuntu-latest\n\nvariables:\n  buildConfiguration: 'Release'\n\nsteps:\n- checkout: self\n  displayName: 'Checkout'\n  submodules: recursive\n  persistCredentials: true\n\n- script: dotnet build --configuration $(buildConfiguration)\n  displayName: 'Dotnet Build $(buildConfiguration)'\n`\nI also tried a different approach by creating a PAT with access to repos read and then using that, but to no avail.\n`- powershell: |\n    $header = \"AUTHORIZATION: bearer $(System.AccessToken)\"\n    git -c http.extraheader=\"$header\" submodule sync\n    git -c http.extraheader=\"$header\" submodule update --init --force --depth=1\n`\nAm I missing something here?\nEDIT: Forgot to post, I've already given the Build Service permissions to access the submodule repository:",
      "solution": "After dealing with this for about a day, I managed to find an article named \"Dealing with error TF401019 when using submodules in Azure Pipelines\" written by Tim Schaeps.\nLong story short, cloning submodules from pipelines seems to be disabled for security reasons. I had to disable 3 options for this work (had to disable them on organization level first before I could set a specific value for them in my Azure DevOps project):\n\nLimit job authorization scope to current project for non-release pipelines\nLimit job authorization scope to current project for release pipelines\nProtect access to repositories in YAML pipelines\n\nHuge shoutout to Tim Schaeps for the article! You rock!",
      "question_score": 8,
      "answer_score": 11,
      "created_at": "2024-08-09T15:49:40",
      "url": "https://stackoverflow.com/questions/78853139/azure-pipeline-fails-to-checkout-a-submodule"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 69219819,
      "title": "Adding condition for selecting branch to fetch the yaml template in Azure pipelines",
      "problem": "I have added yaml templates for .Net CI CD pipeline in a separate repository named 'DevOps'. Each .Net service pipeline is calling this yaml template from 'DevOps'.\nIn DevOps I have two branches - one is main and one is beta.\nAll the triggers from source/development branches in .Net service pipeline should use the template in beta branch of 'DevOps'. Pipeline trigger from main branch in .Net service pipeline should use the template in main.- this is the requirement.\nI have used regular expression/if condition/syntax using when/if, all these are either throwing expression/condition error or simply take the template from main. Below is the screenshot of various attempts (older ones are commented) I have made.\n\nIs there a way to implement a condition in repository syntax?\nUpdate:\nI have updated pipeline like below as per Kotaro's solution. I hope variable can be added inside resource syntax\n\nBut this is what I am getting when I try to run the pipeline:",
      "solution": "How about this?\n`trigger: none\n\npr: none\n\nresources:\n  repositories:\n  - repository: main\n    type: git\n    ref: main\n    name: xxxxx/DevOps\n\n  - repository: beta\n    type: git\n    ref: beta\n    name: xxxxx/DevOps\n    \nsteps:\n  - ${{ if ne(variables['Build.SourceBranchName'], 'main') }}:\n    - template: aaaaa.yml@beta\n  - ${{ if eq(variables['Build.SourceBranchName'], 'main') }}:\n    - template: aaaaa.yml@main\n\n`",
      "question_score": 8,
      "answer_score": 9,
      "created_at": "2021-09-17T10:01:27",
      "url": "https://stackoverflow.com/questions/69219819/adding-condition-for-selecting-branch-to-fetch-the-yaml-template-in-azure-pipeli"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 68594089,
      "title": "Using pipeline variables across stages with template jobs",
      "problem": "Problem Description\nI was having some problems trying to use variables created in one stage in another stage and managed to find various articles old and new describing how this can be done.  The more recent articles/posts identifying the new syntax\n`$[stageDependencies.{stageName}.{jobName}.outputs['{stepName}.{variableName}']`\nUsed like this:\n```\n`variables:\n  myVariable: $[stagedependencies.CreateStageVarStage.CreateStageVarJob.outputs['SetValueStep.VariableFromFirstStage']]\n`\n```\nThis works great until you needed to use job templates.\nNone of the samples I found online covered the situation of templates.  They just demonstrated how multiple stages in the same yaml file could obtain the value.\nThe syntax depends on being able to put the expression into a variable.  Unfortunately, when you use a template for a job, it's not possible to declare variables and passing it as a parameter results in it being unevaluated.\n```\n`- stage: UseJobTemplateStage\n  displayName: 'Use Job Template Stage'\n  dependsOn: CreateStageVarStage\n  jobs:\n  - template: templates/job-showstagevars.yml\n    parameters:\n      ValueToOutput: $[ stagedependencies.CreateStageVarStage.CreateStageVarJob.outputs['SetValueStep.VariableFromFirstStage'] ]\n`\n```\nIn this snippet, it comes through as-is.  The value does not get substituted in.\nTheoretically, you could set your job to have the expression present in the variables block but that sort of hard-coding undermines one of the main benefits of templates.\nRelated Articles\nShare variables across stages in Azure DevOps Pipelines \nAzure DevOps Release Notes - sprint 168",
      "solution": "Solution\nThe answer isn't actually far away.  The original expression just need to be passed through a variable in the template job. Basically, set a variable to be the value of the parameter and use the macro syntax to evaluate the variable.\n```\n`parameters:\n- name: ValueToOutput\n  type: string\n\n...\n\n  variables:\n  - name: LocalVarOfValueToOutputParam\n    value: ${{ parameters.ValueToOutput }}\n`\n```\nUsing the macro syntax of `$(LocalVarOfValueToOutputParam)` will result in the value making its way into the template job correctly.\nFew other pointers:\n\nif you have a matrix-strategy defined you will need to add the `Strategy` in `ValueToOutput: $[ stagedependencies.CreateStageVarStage.CreateStageVarJob.outputs['Strategy.SetValueStep.VariableFromFirstStage'] ]`\nif you are using `script` instead of powershell, you have to use `true` without $ in `echo \"##vso[task.setvariable variable=VariableFromFirstStage;isOutput=true]$message\"`\nif you're not doing this in between stages, but in between jobs, use `$[ dependencies.CreateStageVarStage.CreateStageVarJob.outputs['Strategy.SetValueStep.VariableFromFirstJob'] ]`\n\nExample\nIf we have a yaml file for the build definition:\n```\n`stages:\n- stage: CreateStageVarStage\n  displayName: 'Create StageVar Stage'\n  jobs:\n  - job: CreateStageVarJob\n    displayName: 'Create StageVar Job'\n    timeoutInMinutes: 5\n    pool:\n      name:    'Azure Pipelines'\n      vmImage: 'windows-2019'\n    steps:\n      - checkout: none \n      - pwsh: |\n          [string]$message = 'This is the value from the first stage'\n          Write-Host \"Setting output variable 'VariableFromFirstStage' to '$message'\"\n          Write-Output \"##vso[task.setvariable variable=VariableFromFirstStage;isOutput=$true]$message\"\n        name: SetValueStep\n\n- stage: UseJobTemplateStage\n  displayName: 'Use Job Template Stage'\n  dependsOn: CreateStageVarStage\n  jobs:\n  - template: templates/job-showstagevars.yml\n    parameters:\n      ValueToOutput: $[ stagedependencies.CreateStageVarStage.CreateStageVarJob.outputs['SetValueStep.VariableFromFirstStage'] ]\n`\n```\nThat uses the job template `templates/job-showstagevars.yml`\n```\n`parameters:\n- name: ValueToOutput\n  type: string\n\njobs:\n- job: ShowStageVarJob\n  displayName: 'Show stage var'\n  timeoutInMinutes: 5\n  pool:\n    name:    'Azure Pipelines'\n    vmImage: 'windows-2019'\n\n  variables:\n  - name: LocalVarOfValueToOutputParam\n    value: ${{ parameters.ValueToOutput }}\n\n  steps:\n  - checkout: none\n  - pwsh: |\n      Write-Host \"ValueToOutput parameter=${{ parameters.ValueToOutput }}\"\n      Write-Host \"LocalVarOfValueToOutputParam (pre-processor syntax)=${{ variables.LocalVarOfValueToOutputParam }}\"\n      Write-Host \"LocalVarOfValueToOutputParam (macro syntax)=$(LocalVarOfValueToOutputParam)\"\n    displayName: 'Show StageVariable'\n`\n```\nWhat we get in our output of the second stage is this. Note how only the last expression evaluates to the correct value!\n```\n`ValueToOutput parameter=$[ stagedependencies.CreateStageVarStage.CreateStageVarJob.outputs['SetValueStep.VariableFromFirstStage'] ]\nLocalVarOfValueToOutputParam (pre-processor syntax)=$[ stagedependencies.CreateStageVarStage.CreateStageVarJob.outputs['SetValueStep.VariableFromFirstStage'] ]\nLocalVarOfValueToOutputParam (macro syntax)=This is the value from the first stage\n`\n```",
      "question_score": 8,
      "answer_score": 6,
      "created_at": "2021-07-30T18:14:05",
      "url": "https://stackoverflow.com/questions/68594089/using-pipeline-variables-across-stages-with-template-jobs"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 79218580,
      "title": "Azure DevOps CI - Can&#39;t Deploy bc System.Text.Json, Version=8.0.0.4 not found",
      "problem": "I'm trying to resubmit a question from another author that was closed for lack of details.  I have an ASP MVC .NET6 WebApp that has been running fine for a long time. Yesterday, I added some minor code and pushed it to my Devops repository which is linked via Pipeline to a staging slot on my Webapp (via Deployment Center section).  This has all been working fine for many months but yesterday, it started failing.  My deployment log looks fine until it hits this error\n```\n`C:\\Program Files (x86)\\dotnet\\sdk\\9.0.100\\Sdks\\Microsoft.NET.Sdk\\targets\\Microsoft.PackageDependencyResolution.targets(266,5): error NETSDK1060: Error reading assets file: \nError loading lock file 'C:\\home\\site\\repository\\obj\\project.assets.json' : \nCould not load file or assembly 'System.Text.Json, Version=8.0.0.4, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51' or one of its dependencies. \nThe system cannot find the file specified. [C:\\home\\site\\repository\\[MyApp].csproj]\n    Done Building Project \"C:\\home\\site\\repository\\[MyApp].csproj\" (default targets) -- FAILED.\n`\n```\nI don't even use System.Text.Json in my code although it is certainly a dependency of several other nuget packages (Azure.Storage.Blobs, Azure.Search etc...)\nI'm confused on what 'Version=8.0.0.4' is anyway?  Why 4 levels?  Shouldn't it be 8.0.0?  Looking at the project.assets.json, none of the dependencies require that version.\nMy temp solution was to compile locally and deploy myself.  I have to create a brand new slot and, using VS Code's Azure Tools, do an Azure App Service: Deploy to Slot.  This only works on a brand new slot - it fails if I try to deploy to the slot that previously failed using the DevOps deployment above above.\nAny advice on how to actually fix the problem in my Devops deploy would be welcome.",
      "solution": "Based on your description, when you using deployment center to deploy .net6 project, it will show the error:\n\nCould not load file or assembly 'System.Text.Json, Version=8.0.0.4,...\n\nI had the exact same problem on my recent deployments.\nThe root cause of the issue is that the Azure Web App Service will keep using the .net9(.net 9.0.100) by default and will ignore the custom .net version (e.g. .net6.0)in your web app or project.\nThe issue seems to come from the App service itself. I suggest that you can report this issue to Product Feedback site: Azure Community\nFor a workaround, you can define global.json file at the root of your project and set the target .net version.\nFor example: .net6.0\nglobal.json\n```\n`{\n  \"sdk\": {\n    \"version\": \"6.0.424\",\n    \"rollForward\": \"latestFeature\"\n  }\n}\n`\n```\nHere are the available .net version in Web App:\n\nIn this case, it will use the version set in global.json file to build and deploy your project.",
      "question_score": 8,
      "answer_score": 9,
      "created_at": "2024-11-23T19:45:43",
      "url": "https://stackoverflow.com/questions/79218580/azure-devops-ci-cant-deploy-bc-system-text-json-version-8-0-0-4-not-found"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 71336524,
      "title": "Azure DevOps Pipelines: how to check out branch of the self repo?",
      "problem": "I have a yaml pipeline which I want to make it to run for more branches. Therefore I am trying to checkout one branch, specified in pipeline variables. I'm unable to do so, the error being `Unexpected value 'ref'`.\nThe pipeline file is:\n```\n`trigger:\n  batch: true\n  branches:\n    include:\n      - 'release/dev'\n      - 'release/test'\n      - 'release/prod'\n  paths:\n    include:\n    - '*'\n\nresources:\n- repo: self\n  ref: $(branch)\n\nvariables:\n  dockerRegistryServiceConnection: 'conn'\n  containerRegistry: 'conn.reg'\n  tag: '$(Build.BuildId)'\n  vmImageName: 'ubuntu-latest'\n\nstages:\n- stage: Build\n  displayName: Build and push stage\n  jobs:  \n  - job: Build\n    displayName: Build\n    pool:\n      vmImage: $(vmImageName)\n    steps:\n    - template: docker-build-template.yml\n      parameters:\n        dockerfilePath: $(Build.SourcesDirectory)/Dockerfile.release\n        imageName: conn.reg/container\n        imageRepository: container\n        pushToRegistry: true\n    \n`\n```\nHow can I checkout different branches for building the container out of them?\nLater edit: I want the pipeline to automatically run after a PR or a commit is pushed on any of the braches. (Manually it can be run with specifiyng a branch.)",
      "solution": "Azure DevOps Pipelines: how to check out branch of the self repo?\n\nYou could specify the name of the self repo in the resource with a specific ref,like:\n```\n`resources:\n  repositories:\n  - repository: MyTestProject \n    type: git\n    name: MyTestProject\n    ref: ${{ variables['Build.SourceBranch'] }}\n`\n```\nThen checkout with another path:\n```\n`steps:\n- checkout: MyTestProject\n  path: Another path/xxxx/xxx\n`\n```",
      "question_score": 8,
      "answer_score": 8,
      "created_at": "2022-03-03T12:37:17",
      "url": "https://stackoverflow.com/questions/71336524/azure-devops-pipelines-how-to-check-out-branch-of-the-self-repo"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 73585377,
      "title": "WARNING: 401 Error, Credentials not correct for Azure Artifact during Pip install",
      "problem": "When I attempt to install a package from our Azure DevOps Artifacts feed, I get the error:\nCommand:\n```\n`pip install org-test-framework --index-url https:///tfs//_packaging//pypi/simple/   \n`\n```\nThe keyring prompts for username and password for the site once entered getting the error as\nbelow\nError:\n```\n`WARNING: 401 Error, Credentials not correct for https:///tfs//_packaging//pypi/simple/org-test-framework/\nERROR: Could not find a version that satisfies the requirement org-test-framework (from versions: none)\nERROR: No matching distribution found for org-test-framework\n`\n```\nNote: Same user and password works when I try in the browser and able to download the package directly from above url, so the issue is not my credentials. Also I have tried with everyone in the team and same issue exist!",
      "solution": "You need to use PAT for authenticate as password.\nCreate a Personal access token with Packaging > Read scope to authenticate into Azure DevOps.\nRefer to this official link for details: https://learn.microsoft.com/en-us/azure/devops/artifacts/quickstarts/python-packages?view=azure-devops#manually-configure-authentication",
      "question_score": 8,
      "answer_score": 7,
      "created_at": "2022-09-02T18:10:05",
      "url": "https://stackoverflow.com/questions/73585377/warning-401-error-credentials-not-correct-for-azure-artifact-during-pip-instal"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 70156381,
      "title": "Using podman instead of docker for the Docker@2 task in Azure DevOps",
      "problem": "Our build agent is running Podman 3.4.2 and there is a global alias in place for each terminal session that simply replaces docker with podman, so the command `docker --version` yields `podman version 3.4.2` as a result.\nThe goal is to use podman for the `Docker@2` task in a Azure DevOps pipeline:\n`steps:\n- task: Docker@2\n  displayName: Build and push an image to container registry\n  inputs:\n    command: buildAndPush\n    repository: aspnet-web-mhi\n    dockerfile: $(dockerfilePath)\n    containerRegistry: $(dockerRegistryServiceConnection)\n    tags: |\n      $(tag) \n`\nTurns out I was a bit naive in my assumptions, that this would work as the ado_agent is having none of it:\n\n##[error]Unhandled: Unable to locate executable file: 'docker'. Please verify either the file path exists or the file can be found within a directory specified by the PATH environment variable. Also check the file mode to verify the file is executable.\n\nIs there a way to make that replacement work without too much fuss? I'd avoid scripting everything by myself to use podman instead of docker and push it to a registry, if I can avoid it.",
      "solution": "Since I needed to make progress on this, I've decided to go the down the bash-route and built, pushed, pulled and run the images manually. This is the gist of it:\n```\n`steps:\n  - task: Bash@3\n    displayName: Build Docker Image for DemoWeb\n    inputs:\n      targetType: inline\n      script: |\n        podman build -f $(dockerfilePath) -t demoweb:$(tag) .\n  - task: Bash@3\n    displayName: Login and Push to ACR\n    inputs:\n      targetType: inline\n      script: |\n        podman login -u $(acrServicePrincipal) -p $(acrPassword) $(acrName)\n        podman push demoweb-mhi:$(tag) $(acrName)/demoweb:$(tag)\n  - task: Bash@3\n    displayName: Pull image from ACR\n    inputs:\n      targetType: inline\n      script: |\n        podman pull $(acrName)/demoweb:$(tag) --creds=$(acrServicePrincipal):$(acrPassword)\n  - task: Bash@3\n    displayName: Run container\n    inputs:\n      targetType: inline\n      script: |\n        podman run -p 8080:80 --restart unless-stopped $(acrName)/demoweb:$(tag) \n`\n```\nIf you decide to go down that route, please make sure to not expose your service principal and password as variables in your yml file, but create them as secrets.\nI'll keep this question open - maybe someone with more expertise in handling GNU/Linux finds a more elegant way.",
      "question_score": 8,
      "answer_score": 6,
      "created_at": "2021-11-29T15:32:37",
      "url": "https://stackoverflow.com/questions/70156381/using-podman-instead-of-docker-for-the-docker2-task-in-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 66954831,
      "title": "Git repository permissions issue in Azure DevOps Pipeline",
      "problem": "In an Azure Pipelines Task, I am attempting to create and push a new branch. I am able to clone the repo using the `$(System.AccessToken)` variable, bit when I try to push the new branch I get the following error:\n```\n`remote: TF401027: You need the Git 'GenericContribute' permission to perform this action. Details: identity 'Build\\(GUID)', scope 'repository'.\n`\n```\nIf I check my repository security, I see that both the Build Service user and Project Collection Build Service Accounts group has Contribute, Create Branch, Contribute to pull request, and Create Tag permission set to \"Allow\", which from all the research I've done is all I should need to do.\nHow can I troubleshoot this issue? I assume that either I am missing something silly, or there's a permissions inheritance issue. However, if I'm setting security on the repository itself my assumption is that should override any inherited permissions.\nPipeline:\n```\n`steps:\n- powershell: |\n   git -c http.extraheader=\"AUTHORIZATION: bearer $(System.AccessToken)\" clone \"https://repoaddress/_git/common\"\n   cd common\n   git checkout develop\n   git checkout -b release/$(build.buildNumber) $(build.buildNumber)\n   git -c http.extraheader=\"AUTHORIZATION: bearer $(System.AccessToken)\" push -u origin HEAD\n   \n  displayName: 'Create Branch From Tag'\n`\n```\nPermissions:",
      "solution": "It should caused by your build service account do not have the contribute permission for this repository.\nGo Project setting --> Repositories --> click Repos you want to operate -->set repository permissions accordingly.\nNote: Service account is Project Collection Build Service (org name)\n\nUpdate1\nI got the issue, add this service account `{project name} Build Service ({Org name})` and configure the account permission, it will work.\n\nAccording to the error message: `Details: identity 'Build\\(GUID)', scope 'repository'.`, we could get the service account GUID\nCheck this REST API, it could list the service account, we could search the service account name via the GUID, then configure the permission.\nUpdate2\nSince you are using `AccessToken`, it update the repo via service account, as another workaround, we could use Personal access token do the same things, and it do not need to configure service account permission.\nUpdate2\nA sample power shell script to clone the repo via PAT token:\n```\n`$MyPat = 'yourPAT'\n$B64Pat = [Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes(\":$MyPat\"))\ngit -c http.extraHeader=\"Authorization: Basic $B64Pat\" clone https://dev.azure.com/yourOrgName/yourProjectName/_git/yourRepoName\n`\n```\nAnd we will receive two notifications during the lifetime of a PAT - one upon creation and the other seven days before the expiration. You could refer to this doc for more details.\nSeven days before your PAT expires, you receive a notification similar to the following example.\n\nThen we could change the Expiration time.",
      "question_score": 8,
      "answer_score": 7,
      "created_at": "2021-04-05T16:42:08",
      "url": "https://stackoverflow.com/questions/66954831/git-repository-permissions-issue-in-azure-devops-pipeline"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 71871488,
      "title": "Not able to resolve conflict in Azure DevOps",
      "problem": "Unable to merge the conflict in `Azure Devops` I have created the `Pull Request` from `api_integration` branch to `development` branch. But there are some conflicts I can see but as my Complete button is disabled, not sure how to deal with code merging here.\nI tried to switch to `development` branch in my android studio and pull the request but it says `All files are up to date`.\n\nNot sure how to resolve this issue of PR with merge conflict.",
      "solution": "Basically you should resolve them locally with git commands, see tutorial here.\nBut - better way is to use the Pull Request Merge Conflict Extension for Azure DevOps.\nAfter the installation you will have \"conflicts\" tab inside the PR:",
      "question_score": 8,
      "answer_score": 6,
      "created_at": "2022-04-14T14:19:15",
      "url": "https://stackoverflow.com/questions/71871488/not-able-to-resolve-conflict-in-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 71001203,
      "title": "Azure DevOps deployment agent can&#39;t connect due to SSL issues",
      "problem": "Azure deployment agent doesn't work since a couple of days anymore due to SSL issues.\nI got a couple of servers that can't connect to Azure DevOps anymore.\nI found the following blog that tls 1.2 should be enabled.\nhttps://devblogs.microsoft.com/visualstudio/azure-devops-requires-tls-1-2-on-all-connections-including-visual-studio/\nI checked if we have the correct security protocols enabled.\n```\n`C:\\azagent\\A2> [System.Net.ServicePointManager]::SecurityProtocol\nSsl3, Tls, Tls12\n`\n```\nI also followed the following to make sure TLS is enabled in the windows register. I added the values by hand because some didn't exists.\n```\n`Path                                                                                          Name                        Value\n----                                                                                          ----                        -----\nHKLM:\\SOFTWARE\\WOW6432Node\\Microsoft\\.NETFramework\\v4.0.30319                                 SystemDefaultTlsVersions    1\nHKLM:\\SOFTWARE\\WOW6432Node\\Microsoft\\.NETFramework\\v4.0.30319                                 SchUseStrongCrypto          1\nHKLM:\\SOFTWARE\\Microsoft\\.NETFramework\\v4.0.30319                                             SystemDefaultTlsVersions    1\nHKLM:\\SOFTWARE\\Microsoft\\.NETFramework\\v4.0.30319                                             SchUseStrongCrypto          1\nHKLM:\\SYSTEM\\CurrentControlSet\\Control\\SecurityProviders\\SCHANNEL\\Protocols\\TLS 1.2\\Server    Enabled                     1\nHKLM:\\SYSTEM\\CurrentControlSet\\Control\\SecurityProviders\\SCHANNEL\\Protocols\\TLS 1.2\\Server    DisabledByDefault           0\nHKLM:\\SYSTEM\\CurrentControlSet\\Control\\SecurityProviders\\SCHANNEL\\Protocols\\TLS 1.2\\Client    Enabled                     1\nHKLM:\\SYSTEM\\CurrentControlSet\\Control\\SecurityProviders\\SCHANNEL\\Protocols\\TLS 1.2\\Client    DisabledByDefault           0\n`\n```\nI posted the log below because I don't know what's going on. Does anyone else have any idea?\nLog:\n```\n`[2022-02-05 18:38:37Z INFO AgentProcess] Agent package win-x64.\n[2022-02-05 18:38:37Z INFO AgentProcess] Running on Windows (X64).\n[2022-02-05 18:38:37Z INFO AgentProcess] RuntimeInformation: Microsoft Windows 6.3.9600.\n[2022-02-05 18:38:37Z INFO AgentProcess] Version: 2.198.2\n[2022-02-05 18:38:37Z INFO AgentProcess] Commit: d1b85881abfe7b5e575af095daf0ee27e099b904\n[2022-02-05 18:38:37Z INFO AgentProcess] Culture: nl-NL\n[2022-02-05 18:38:37Z INFO AgentProcess] UI Culture: en-US\n[2022-02-05 18:38:37Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:37Z INFO HostContext] Well known directory 'Root': 'C:\\azagent\\A2'\n[2022-02-05 18:38:37Z INFO AgentProcess] Validating directory permissions for: 'C:\\azagent\\A2'\n[2022-02-05 18:38:37Z INFO PowerShellExeUtil] Generation: '1'\n[2022-02-05 18:38:37Z INFO PowerShellExeUtil] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\PowerShell\\1\\PowerShellEngine', value name 'PowerShellVersion': '2.0'\n[2022-02-05 18:38:37Z INFO PowerShellExeUtil] Unsupported version. Skipping.\n[2022-02-05 18:38:37Z INFO PowerShellExeUtil] Generation: '3'\n[2022-02-05 18:38:37Z INFO PowerShellExeUtil] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\PowerShell\\3\\PowerShellEngine', value name 'PowerShellVersion': '4.0'\n[2022-02-05 18:38:37Z INFO PowerShellExeUtil] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\PowerShell\\3\\PowerShellEngine', value name 'ApplicationBase': 'C:\\Windows\\System32\\WindowsPowerShell\\v1.0'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\.NETFramework', value name 'InstallRoot': 'C:\\Windows\\Microsoft.NET\\Framework64\\'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'SOFTWARE\\Microsoft\\NET Framework Setup\\NDP' contains sub keys:\n[2022-02-05 18:38:37Z INFO AgentProcess]  'CDF'\n[2022-02-05 18:38:37Z INFO AgentProcess]  'v2.0.50727'\n[2022-02-05 18:38:37Z INFO AgentProcess]  'v3.0'\n[2022-02-05 18:38:37Z INFO AgentProcess]  'v3.5'\n[2022-02-05 18:38:37Z INFO AgentProcess]  'v4'\n[2022-02-05 18:38:37Z INFO AgentProcess]  'v4.0'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v2.0.50727', value name 'Version': '2.0.50727.4927'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v2.0.50727', value name 'Install': '1'\n[2022-02-05 18:38:37Z INFO AgentProcess] Testing directory: 'C:\\Windows\\Microsoft.NET\\Framework64\\v2.0.50727'\n[2022-02-05 18:38:37Z INFO AgentProcess] Found version: 2.0.50727\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v3.0', value name 'Version': '3.0.30729.4926'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v3.0', value name 'Install': '1'\n[2022-02-05 18:38:37Z INFO AgentProcess] Testing directory: 'C:\\Windows\\Microsoft.NET\\Framework64\\v3.0'\n[2022-02-05 18:38:37Z INFO AgentProcess] Found version: 3.0\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v3.5', value name 'Version': '3.5.30729.4926'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v3.5', value name 'Install': '1'\n[2022-02-05 18:38:37Z INFO AgentProcess] Testing directory: 'C:\\Windows\\Microsoft.NET\\Framework64\\v3.5'\n[2022-02-05 18:38:37Z INFO AgentProcess] Found version: 3.5\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4', value name 'Version' is null.\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4', value name '' is null.\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4' contains sub keys:\n[2022-02-05 18:38:37Z INFO AgentProcess]  'Client'\n[2022-02-05 18:38:37Z INFO AgentProcess]  'Full'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Client', value name 'Version': '4.8.03761'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Client', value name 'Install': '1'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Client', value name 'InstallPath': 'C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Client', value name 'Release': '528049'\n[2022-02-05 18:38:37Z INFO AgentProcess] Type is System.Int32\n[2022-02-05 18:38:37Z INFO AgentProcess] Interpreted version: 4.7.0\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Full', value name 'Version': '4.8.03761'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Full', value name 'Install': '1'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Full', value name 'InstallPath': 'C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\'\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4\\Full', value name 'Release': '528049'\n[2022-02-05 18:38:37Z INFO AgentProcess] Type is System.Int32\n[2022-02-05 18:38:37Z INFO AgentProcess] Interpreted version: 4.7.0\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4.0', value name 'Version' is null.\n[2022-02-05 18:38:37Z INFO AgentProcess] Key name 'HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\NET Framework Setup\\NDP\\v4.0', value name '': 'deprecated'\n[2022-02-05 18:38:37Z INFO AgentProcess] Found 5 versions:\n[2022-02-05 18:38:37Z INFO AgentProcess]  2.0.50727\n[2022-02-05 18:38:37Z INFO AgentProcess]  3.0\n[2022-02-05 18:38:37Z INFO AgentProcess]  3.5\n[2022-02-05 18:38:37Z INFO AgentProcess]  4.7.0\n[2022-02-05 18:38:37Z INFO AgentProcess]  4.7.0\n[2022-02-05 18:38:37Z INFO AgentProcess] Testing for min NET Framework version: '4.5'\n[2022-02-05 18:38:37Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:37Z INFO HostContext] Well known directory 'Root': 'C:\\azagent\\A2'\n[2022-02-05 18:38:38Z INFO CommandSettings] Configure {\n  \"AcceptTeeEula\": false,\n  \"AddDeploymentGroupTags\": false,\n  \"AddEnvironmentVirtualMachineResourceTags\": false,\n  \"AddMachineGroupTags\": false,\n  \"AlwaysExtractTask\": false,\n  \"Agent\": \"IIS18\",\n  \"CollectionName\": null,\n  \"DeploymentGroup\": false,\n  \"DeploymentGroupName\": null,\n  \"DeploymentGroupTags\": null,\n  \"DeploymentPool\": false,\n  \"DeploymentPoolName\": null,\n  \"EnvironmentVMResource\": true,\n  \"EnvironmentName\": \"Logic4-Next - Production\",\n  \"EnvironmentVMResourceTags\": null,\n  \"GitUseSChannel\": false,\n  \"DisableLogUploads\": false,\n  \"MachineGroup\": false,\n  \"MachineGroupName\": null,\n  \"MachineGroupTags\": null,\n  \"MonitorSocketAddress\": null,\n  \"NotificationPipeName\": null,\n  \"NotificationSocketAddress\": null,\n  \"NoRestart\": false,\n  \"OverwriteAutoLogon\": false,\n  \"Pool\": null,\n  \"ProjectName\": \"Logic4Desktop\",\n  \"ProxyPassword\": null,\n  \"ProxyUserName\": null,\n  \"ProxyUrl\": null,\n  \"Replace\": false,\n  \"RunAsAutoLogon\": false,\n  \"RunAsService\": true,\n  \"RunOnce\": false,\n  \"PreventServiceStart\": false,\n  \"SslCACert\": null,\n  \"SslClientCert\": null,\n  \"SslClientCertArchive\": null,\n  \"SslClientCertKey\": null,\n  \"SslClientCertPassword\": null,\n  \"SslSkipCertValidation\": false,\n  \"Url\": \"https://dev.azure.com/organization/\",\n  \"WindowsLogonAccount\": null,\n  \"WindowsLogonPassword\": null,\n  \"Work\": \"_work\",\n  \"Auth\": \"PAT\",\n  \"LaunchBrowser\": false,\n  \"Password\": null,\n  \"Token\": \"***\",\n  \"Unattended\": false,\n  \"UserName\": null,\n  \"Help\": false,\n  \"Version\": false\n}\n[2022-02-05 18:38:38Z INFO AgentProcess] Arguments parsed\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Root': 'C:\\azagent\\A2'\n[2022-02-05 18:38:38Z INFO HostContext] Well known config file 'Proxy': 'C:\\azagent\\A2\\.proxy'\n[2022-02-05 18:38:38Z INFO VstsAgentWebProxy] No proxy setting found.\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Root': 'C:\\azagent\\A2'\n[2022-02-05 18:38:38Z INFO HostContext] Well known config file 'Certificates': 'C:\\azagent\\A2\\.certificates'\n[2022-02-05 18:38:38Z INFO AgentCertificateManager] No certificate setting found.\n[2022-02-05 18:38:38Z INFO Agent] ExecuteCommand\n[2022-02-05 18:38:38Z INFO ConfigurationStore] currentAssemblyLocation: C:\\azagent\\A2\\bin\\Agent.Listener.dll\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:38Z INFO ConfigurationStore] binPath: C:\\azagent\\A2\\bin\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Root': 'C:\\azagent\\A2'\n[2022-02-05 18:38:38Z INFO ConfigurationStore] RootFolder: C:\\azagent\\A2\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Root': 'C:\\azagent\\A2'\n[2022-02-05 18:38:38Z INFO HostContext] Well known config file 'Agent': 'C:\\azagent\\A2\\.agent'\n[2022-02-05 18:38:38Z INFO ConfigurationStore] ConfigFilePath: C:\\azagent\\A2\\.agent\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Root': 'C:\\azagent\\A2'\n[2022-02-05 18:38:38Z INFO HostContext] Well known config file 'Credentials': 'C:\\azagent\\A2\\.credentials'\n[2022-02-05 18:38:38Z INFO ConfigurationStore] CredFilePath: C:\\azagent\\A2\\.credentials\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Root': 'C:\\azagent\\A2'\n[2022-02-05 18:38:38Z INFO HostContext] Well known config file 'Service': 'C:\\azagent\\A2\\.service'\n[2022-02-05 18:38:38Z INFO ConfigurationStore] ServiceConfigFilePath: C:\\azagent\\A2\\.service\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Root': 'C:\\azagent\\A2'\n[2022-02-05 18:38:38Z INFO HostContext] Well known config file 'Autologon': 'C:\\azagent\\A2\\.autologon'\n[2022-02-05 18:38:38Z INFO ConfigurationStore] AutoLogonSettingsFilePath: C:\\azagent\\A2\\.autologon\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Root': 'C:\\azagent\\A2'\n[2022-02-05 18:38:38Z INFO HostContext] Well known config file 'Options': 'C:\\azagent\\A2\\.options'\n[2022-02-05 18:38:38Z INFO ConfigurationStore] RuntimeOptionsFilePath: C:\\azagent\\A2\\.options\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Root': 'C:\\azagent\\A2'\n[2022-02-05 18:38:38Z INFO HostContext] Well known config file 'SetupInfo': 'C:\\azagent\\A2\\.setup_info'\n[2022-02-05 18:38:38Z INFO ConfigurationStore] SetupInfoFilePath: C:\\azagent\\A2\\.setup_info\n[2022-02-05 18:38:38Z INFO Terminal] WRITE LINE: \n  ___                      ______ _            _ _\n / _ \\                     | ___ (_)          | (_)\n/ /_\\ \\_____   _ _ __ ___  | |_/ /_ _ __   ___| |_ _ __   ___  ___\n|  _  |_  / | | | '__/ _ \\ |  __/| | '_ \\ / _ \\ | | '_ \\ / _ \\/ __|\n| | | |/ /| |_| | | |  __/ | |   | | |_) |  __/ | | | | |  __/\\__ \\\n\\_| |_/___|\\__,_|_|  \\___| \\_|   |_| .__/ \\___|_|_|_| |_|\\___||___/\n                                   | |\n        agent v2.198.2             |_|          (commit d1b8588)\n\n[2022-02-05 18:38:38Z INFO ConfigurationManager] CheckAgentRootDirectorySecure\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Bin': 'C:\\azagent\\A2\\bin'\n[2022-02-05 18:38:38Z INFO HostContext] Well known directory 'Root': 'C:\\azagent\\A2'\n[2022-02-05 18:38:38Z INFO ConfigurationManager] ConfigureAsync\n[2022-02-05 18:38:38Z INFO ConfigurationStore] IsConfigured()\n[2022-02-05 18:38:38Z INFO ConfigurationStore] IsConfigured: False\n[2022-02-05 18:38:38Z INFO ConfigurationManager] Is configured: False\n[2022-02-05 18:38:38Z INFO CommandSettings] Flag 'sslskipcertvalidation': 'False'\n[2022-02-05 18:38:38Z INFO ConfigurationManager] Testing for min NET Framework version: '4.6'\n[2022-02-05 18:38:38Z INFO CommandSettings] Flag 'deploymentgroup': 'False'\n[2022-02-05 18:38:38Z INFO CommandSettings] Flag 'deploymentpool': 'False'\n[2022-02-05 18:38:38Z INFO CommandSettings] Flag 'environment': 'True'\n[2022-02-05 18:38:38Z INFO ExtensionManager] Getting extensions for interface: 'Microsoft.VisualStudio.Services.Agent.Listener.Configuration.IConfigurationProvider'\n[2022-02-05 18:38:38Z INFO ExtensionManager] Creating instance: Microsoft.VisualStudio.Services.Agent.Listener.Configuration.BuildReleasesAgentConfigProvider, Agent.Listener\n[2022-02-05 18:38:38Z INFO ExtensionManager] Creating instance: Microsoft.VisualStudio.Services.Agent.Listener.Configuration.DeploymentGroupAgentConfigProvider, Agent.Listener\n[2022-02-05 18:38:38Z INFO ExtensionManager] Creating instance: Microsoft.VisualStudio.Services.Agent.Listener.Configuration.SharedDeploymentAgentConfigProvider, Agent.Listener\n[2022-02-05 18:38:38Z INFO ExtensionManager] Creating instance: Microsoft.VisualStudio.Services.Agent.Listener.Configuration.EnvironmentVMResourceConfigProvider, Agent.Listener\n[2022-02-05 18:38:38Z INFO Terminal] WRITE LINE: \n[2022-02-05 18:38:38Z INFO Terminal] WRITE LINE: >> Connect:\n[2022-02-05 18:38:38Z INFO Terminal] WRITE LINE: \n[2022-02-05 18:38:38Z INFO CommandSettings] Arg 'url': 'https://dev.azure.com/organization/'\n[2022-02-05 18:38:38Z INFO EnvironmentVMResourceConfigProvider] url - https://dev.azure.com/organization/\n[2022-02-05 18:38:38Z INFO ConfigurationManager] GetCredentialProvider\n[2022-02-05 18:38:38Z INFO CommandSettings] Arg 'auth': 'PAT'\n[2022-02-05 18:38:38Z INFO ConfigurationManager] Creating credential for auth: PAT\n[2022-02-05 18:38:38Z INFO CredentialManager] GetCredentialProvider\n[2022-02-05 18:38:38Z INFO CredentialManager] Creating type PAT\n[2022-02-05 18:38:38Z INFO CredentialManager] Creating credential type: PAT\n[2022-02-05 18:38:38Z INFO PersonalAccessToken] EnsureCredential\n[2022-02-05 18:38:38Z INFO CommandSettings] Arg 'token': '***'\n[2022-02-05 18:38:38Z INFO PersonalAccessToken] GetVssCredentials\n[2022-02-05 18:38:38Z INFO PersonalAccessToken] token retrieved: 52 chars\n[2022-02-05 18:38:38Z INFO PersonalAccessToken] cred created\n[2022-02-05 18:38:38Z INFO ConfigurationManager] cred retrieved\n[2022-02-05 18:38:38Z INFO VisualStudioServices] Starting operation Location.GetConnectionData\n[2022-02-05 18:38:38Z WARN VisualStudioServices] Attempt 1 of GET request to https://dev.azure.com/organization/_apis/connectionData?connectOptions=1&lastChangeId=320929845&lastChangeId64=320929845 failed (Socket Error: ConnectionReset). The operation will be retried in 10,8320613 seconds.\n[2022-02-05 18:38:49Z WARN VisualStudioServices] Attempt 2 of GET request to https://dev.azure.com/organization/_apis/connectionData?connectOptions=1&lastChangeId=320929845&lastChangeId64=320929845 failed (Socket Error: ConnectionReset). The operation will be retried in 13,2434562 seconds.\n[2022-02-05 18:39:03Z WARN VisualStudioServices] Attempt 3 of GET request to https://dev.azure.com/organization/_apis/connectionData?connectOptions=1&lastChangeId=320929845&lastChangeId64=320929845 failed (Socket Error: ConnectionReset). The operation will be retried in 15,8216932 seconds.\n[2022-02-05 18:39:18Z ERR  VisualStudioServices] Attempt 4 of GET request to https://dev.azure.com/organization/_apis/connectionData?connectOptions=1&lastChangeId=320929845&lastChangeId64=320929845 failed (Socket Error: ConnectionReset). The maximum number of attempts has been reached.\n[2022-02-05 18:39:18Z INFO VisualStudioServices] Finished operation Location.GetConnectionData\n[2022-02-05 18:39:18Z INFO LocationServer] Unable to connect to https://dev.azure.com/organization/.\n[2022-02-05 18:39:19Z ERR  LocationServer] System.Net.Http.HttpRequestException: The SSL connection could not be established, see inner exception.\n ---> System.IO.IOException: Unable to read data from the transport connection: An existing connection was forcibly closed by the remote host..\n ---> System.Net.Sockets.SocketException (10054): An existing connection was forcibly closed by the remote host.\n   --- End of inner exception stack trace ---\n   at System.Net.Sockets.Socket.AwaitableSocketAsyncEventArgs.ThrowException(SocketError error, CancellationToken cancellationToken)\n   at System.Net.Sockets.Socket.AwaitableSocketAsyncEventArgs.GetResult(Int16 token)\n   at System.Net.FixedSizeReader.ReadPacketAsync(Stream transport, AsyncProtocolRequest request)\n   at System.Net.Security.SslStream.ThrowIfExceptional()\n   at System.Net.Security.SslStream.InternalEndProcessAuthentication(LazyAsyncResult lazyResult)\n   at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n   at System.Net.Security.SslStream.EndAuthenticateAsClient(IAsyncResult asyncResult)\n   at System.Net.Security.SslStream.<>c.b__65_1(IAsyncResult iar)\n   at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Net.Http.ConnectHelper.EstablishSslConnectionAsyncCore(Stream stream, SslClientAuthenticationOptions sslOptions, CancellationToken cancellationToken)\n   --- End of inner exception stack trace ---\n   at Microsoft.VisualStudio.Services.Common.VssHttpRetryMessageHandler.SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at System.Net.Http.HttpClient.FinishSendAsyncBuffered(Task`1 sendTask, HttpRequestMessage request, CancellationTokenSource cts, Boolean disposeCts)\n   at Microsoft.VisualStudio.Services.WebApi.VssHttpClientBase.SendAsync(HttpRequestMessage message, HttpCompletionOption completionOption, Object userState, CancellationToken cancellationToken)\n   at Microsoft.VisualStudio.Services.WebApi.VssHttpClientBase.SendAsync[T](HttpRequestMessage message, Object userState, CancellationToken cancellationToken)\n   at Microsoft.VisualStudio.Services.Location.Client.LocationHttpClient.GetConnectionDataAsync(ConnectOptions connectOptions, Int64 lastChangeId, CancellationToken cancellationToken, Object userState)\n   at Microsoft.VisualStudio.Services.WebApi.Location.VssServerDataProvider.GetConnectionDataAsync(ConnectOptions connectOptions, Int32 lastChangeId, CancellationToken cancellationToken)\n   at Microsoft.VisualStudio.Services.WebApi.Location.VssServerDataProvider.ConnectAsync(ConnectOptions connectOptions, CancellationToken cancellationToken)\n   at Microsoft.VisualStudio.Services.Agent.LocationServer.ConnectAsync(VssConnection jobConnection)\n[2022-02-05 18:39:19Z INFO CommandSettings] Flag 'unattended': 'False'\n[2022-02-05 18:39:19Z ERR  Terminal] WRITE ERROR (exception):\n[2022-02-05 18:39:19Z ERR  Terminal] System.Net.Http.HttpRequestException: The SSL connection could not be established, see inner exception.\n ---> System.IO.IOException: Unable to read data from the transport connection: An existing connection was forcibly closed by the remote host..\n ---> System.Net.Sockets.SocketException (10054): An existing connection was forcibly closed by the remote host.\n   --- End of inner exception stack trace ---\n   at System.Net.Sockets.Socket.AwaitableSocketAsyncEventArgs.ThrowException(SocketError error, CancellationToken cancellationToken)\n   at System.Net.Sockets.Socket.AwaitableSocketAsyncEventArgs.GetResult(Int16 token)\n   at System.Net.FixedSizeReader.ReadPacketAsync(Stream transport, AsyncProtocolRequest request)\n   at System.Net.Security.SslStream.ThrowIfExceptional()\n   at System.Net.Security.SslStream.InternalEndProcessAuthentication(LazyAsyncResult lazyResult)\n   at System.Net.Security.SslStream.EndProcessAuthentication(IAsyncResult result)\n   at System.Net.Security.SslStream.EndAuthenticateAsClient(IAsyncResult asyncResult)\n   at System.Net.Security.SslStream.<>c.b__65_1(IAsyncResult iar)\n   at System.Threading.Tasks.TaskFactory`1.FromAsyncCoreLogic(IAsyncResult iar, Func`2 endFunction, Action`1 endAction, Task`1 promise, Boolean requiresSynchronization)\n--- End of stack trace from previous location where exception was thrown ---\n   at System.Net.Http.ConnectHelper.EstablishSslConnectionAsyncCore(Stream stream, SslClientAuthenticationOptions sslOptions, CancellationToken cancellationToken)\n   --- End of inner exception stack trace ---\n   at Microsoft.VisualStudio.Services.Common.VssHttpRetryMessageHandler.SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)\n   at System.Net.Http.HttpClient.FinishSendAsyncBuffered(Task`1 sendTask, HttpRequestMessage request, CancellationTokenSource cts, Boolean disposeCts)\n   at Microsoft.VisualStudio.Services.WebApi.VssHttpClientBase.SendAsync(HttpRequestMessage message, HttpCompletionOption completionOption, Object userState, CancellationToken cancellationToken)\n   at Microsoft.VisualStudio.Services.WebApi.VssHttpClientBase.SendAsync[T](HttpRequestMessage message, Object userState, CancellationToken cancellationToken)\n   at Microsoft.VisualStudio.Services.Location.Client.LocationHttpClient.GetConnectionDataAsync(ConnectOptions connectOptions, Int64 lastChangeId, CancellationToken cancellationToken, Object userState)\n   at Microsoft.VisualStudio.Services.WebApi.Location.VssServerDataProvider.GetConnectionDataAsync(ConnectOptions connectOptions, Int32 lastChangeId, CancellationToken cancellationToken)\n   at Microsoft.VisualStudio.Services.WebApi.Location.VssServerDataProvider.ConnectAsync(ConnectOptions connectOptions, CancellationToken cancellationToken)\n   at Microsoft.VisualStudio.Services.Agent.LocationServer.ConnectAsync(VssConnection jobConnection)\n   at Microsoft.VisualStudio.Services.Agent.Util.ServerUtil.GetConnectionData(String serverUrl, VssCredentials credentials, ILocationServer locationServer)\n   at Microsoft.VisualStudio.Services.Agent.Util.ServerUtil.DetermineDeploymentType(String serverUrl, VssCredentials credentials, ILocationServer locationServer)\n   at Microsoft.VisualStudio.Services.Agent.Listener.Configuration.ConfigurationManager.ConfigureAsync(CommandSettings command)\n[2022-02-05 18:39:19Z ERR  Terminal] WRITE ERROR: Failed to connect.  Try again or ctrl-c to quit\n[2022-02-05 18:39:59Z INFO CommandSettings] Arg 'url': 'https://dev.azure.com/organization/'\n[2022-02-05 18:39:59Z INFO EnvironmentVMResourceConfigProvider] url - https://dev.azure.com/organization/\n[2022-02-05 18:39:59Z INFO ConfigurationManager] GetCredentialProvider\n[2022-02-05 18:39:59Z INFO CommandSettings] Arg 'auth': 'PAT'\n[2022-02-05 18:39:59Z INFO ConfigurationManager] Creating credential for auth: PAT\n[2022-02-05 18:39:59Z INFO CredentialManager] GetCredentialProvider\n[2022-02-05 18:39:59Z INFO CredentialManager] Creating type PAT\n[2022-02-05 18:39:59Z INFO CredentialManager] Creating credential type: PAT\n[2022-02-05 18:39:59Z INFO PersonalAccessToken] EnsureCredential\n[2022-02-05 18:39:59Z INFO CommandSettings] Arg 'token': '***'\n[2022-02-05 18:39:59Z INFO PersonalAccessToken] GetVssCredentials\n[2022-02-05 18:39:59Z INFO PersonalAccessToken] token retrieved: 52 chars\n[2022-02-05 18:39:59Z INFO PersonalAccessToken] cred created\n[2022-02-05 18:39:59Z INFO ConfigurationManager] cred retrieved\n[2022-02-05 18:39:59Z INFO VisualStudioServices] Starting operation Location.GetConnectionData\n[2022-02-05 18:39:59Z WARN VisualStudioServices] Attempt 1 of GET request to https://dev.azure.com/organization/_apis/connectionData?connectOptions=1&lastChangeId=320929845&lastChangeId64=320929845 failed (Socket Error: ConnectionReset). The operation will be retried in 10,8212117 seconds.\n[2022-02-05 18:40:10Z WARN VisualStudioServices] Attempt 2 of GET request to https://dev.azure.com/organization/_apis/connectionData?connectOptions=1&lastChangeId=320929845&lastChangeId64=320929845 failed (Socket Error: ConnectionReset). The operation will be retried in 13,0277663 seconds.\n[2022-02-05 18:40:11Z INFO Terminal] WRITE LINE: Exiting...\n`\n```",
      "solution": "If people still encounter this, I found a script that checks all the problems and generates a solution that works :-)\nAzure DevOps TLS 1.2 transition readiness checker\nAzure DevOps Services (as many other Microsoft services) is undergoing transition to deprecate transport protocols TLS 1.0, TLS 1.1 and some TLS 1.2 cipher suites which are considered weak.\nSee announcement from Azure DevOps team here: https://devblogs.microsoft.com/devops/deprecating-weak-cryptographic-standards-tls-1-0-and-1-1-in-azure-devops-services/\nThe purpose of this project is to simplify the task of preparation for the transition. We gathered most frequently seen TLS-compatibility issues reported by our customers and made a script which detects them and points the user towards the mitigation.\nRun the script:\n\nAzureDevOpsTls12Analysis.ps1\n\nRun in Powershell version 4 or higher. Windows-only, the script has been tested on Windows Server 2012 R2 and above.\nWhat the script does:\n\nperforms a probe by opening a test secure connection to https://status.dev.azure.com. This site requires TLS 1.2 & strong cipher suites as will all Azure DevOps sites after the deprecation of TLS 1.0 and 1.1 protocols takes place.\n\nThe probe recognizes when the issue is network connectivity or DNS resolving problem vs. when it is caused by TLS incompatibility.\nSuccessfull probe is a proof that the OS allows TLS 1.2 and at least one of the required cipher suites is available. This does not guarantee that all other software connecting to Azure DevOps from this computer will work without TLS issues.\n\nperforms an analysis of OS-level issues by looking at the selected Windows registry keys which enable/disable TLS 1.2 protocol and influence the set of usable cipher suites. OS-level configuration is shared by all the software which uses HTTPS/TLS stack provided by OS.\nperforms an analysis of .NET Framework: checks version of .NET framework installed and configuration in Windows registry.\n\nLooks for presence of registry changes which enable .NET apps built against .NET Framework versions prior to 4.7 to leverage TLS capabilities suported by OS. Without these changes, old .NET apps will default to usage of TLS 1.0 even when TLS 1.2 is enabled by the OS.\nIf you don't intend to use legacy .NET programs that communicate over network on the computer, no need to apply these.\n\nWhat the script does not:\n\nThe script does not execute any mitigations itself. It only prints mitigation advice which consists of URL of docs article and steps to be executed (either cmdlets to call or registry changes to make).\nThe script does not need elevated permissions to run.\nThe script cannot say if specific app will have TLS issues. There are apps which have TLS/SSL version of choice hard-code or configured.\n\nSource and script:\nhttps://github.com/microsoft/azure-devops-tls12",
      "question_score": 8,
      "answer_score": 5,
      "created_at": "2022-02-05T19:59:25",
      "url": "https://stackoverflow.com/questions/71001203/azure-devops-deployment-agent-cant-connect-due-to-ssl-issues"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 77186491,
      "title": "How do I find out who resolved a PR comment?",
      "problem": "When I spot an issue during the code review for a pull request (PR) on Azure DevOps, I can leave a comment (actually, a new comment thread).\nResolution of all comments can be configured as a prerequisite for completing the PR. Thus, setting a comment (thread) to Resolved is not an insignificant action.\nHow can I find out who set a given comment thread to Resolved?\n\nSome context: Once a PR has gathered some 50 or more comment threads, it gets cumbersome for reviewers to always sift through all comments anew on every review round. The only meaningful way to tell which comments are already resolved satisfactorily that Azure DevOps appears to supply is the distinction between active and closed comments. But sometimes, developers set comments to \"Resolved\" themselves instead of leaving this to the commenter, at which point it gets quite confusing to find out whether the solution for a closed comment was actually checked by the reviewer already.",
      "solution": "I dislike my own answer, but AFAIK it is the answer to this question.\nCurrently it's not possible to determine who resolved a PR comment.\nAfter digging through the API I can see comments have a \"publishedDate\" and also a \"lastUpdatedDate\", as well as a \"status\", which for example has a possible state of \"fixed\". However, I cannot find anywhere that says who did it. Furthermore, there is a MS Developer Community thread about this which unfortunately is closed and can no longer be voted on. Perhaps a new one can be started to see if it gets more traction this time.\nSide Note: Perhaps a takeaway of this is that one should only use \"Approve with suggestions\" if they're OK with the suggestions being ignored. If that wouldn't be acceptable, then one should block the PR.",
      "question_score": 8,
      "answer_score": 3,
      "created_at": "2023-09-27T12:07:35",
      "url": "https://stackoverflow.com/questions/77186491/how-do-i-find-out-who-resolved-a-pr-comment"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 72040764,
      "title": "Unable to automate AD user creation in Azure SQL database",
      "problem": "I'm trying to set up automated pipeline for database creation and need to open access for all users of some AD group. Last part is done through CREATE USER [Group Name] FROM EXTERNAL PROVIDER;\nIn order to execute this command, one needs to be logged in with AAD and the only Azure DevOps task used to execute SQL scripts (SqlAzureDacpacDeployment@1) has limited options to sign with AD. Currently it supports sign in with AD username/password and AD Integrated. User/password option is not possible as we use two factor authentication. And the latter requires self-hosted agent for pipeline which we do not have.\nAdditionally, there is one more sign in option that look promising (Service Principal: Uses the Authentication data from Azure Subscription), but after trying it failed miserably with error:\n##[error]Principal 'web-API' could not be created. Only connections established with Active Directory accounts can create other Active Directory users.\nAre the any other options we could use to create AD users in Azure SQL database? Any help would be appreciated.",
      "solution": "I was finally able to resolve this challange and the solution was in this Mircrosoft doc. The biggest showstopper is the permission required by Azure SQL Server. As per article the servers must have Directory Readers permission in order to fetch AD users and groups when adding them to sql database. This is more or less a manual step unless your pipeline has admin rights which ofc is not recommended. So to automate it as much as possible we will need to create an AD Group with Directory Readers permission and just add our SQL Servers (we had tree, dev/test and prod) to it, this way servers will inherit this permission.\nHere is a step-by-step tutorial how we solved this issue:\n\nWe use Bicep for infrastructure automated deployment and had to specify there that we want our SQL Server to have SystemAssigned identity and output this value for later use:\n\n```\n`resource sqlServer 'Microsoft.Sql/servers@2022-05-01-preview' = {\n  name: sqlServerName\n  location: location\n  identity: {\n    type: 'SystemAssigned'\n  }\n  properties: {\n    minimalTlsVersion: '1.2'\n    publicNetworkAccess: 'Enabled'\n    administratorLogin: '...'\n    administratorLoginPassword: '...'\n  }\n}\n\noutput SqlServerIdentityId string = reference(sqlServer.id, '2022-11-01-preview', 'Full').identity.principalId\n`\n```\n\nNow we use Azure CLI task to add our newly created SQL Server to our group with Directory Readers permissions. We use jq to parse iacOutputs and extract SqlServerIdentityId  from step 1:\n\n```\n`- task: AzureCLI@2\n  displayName: \"Give SqlServer DirectoryReader permission\"\n  inputs:\n    azureSubscription: \"${{variables.YourServiceConnection}}\"\n    scriptType: 'bash'\n    scriptLocation: 'inlineScript'\n    inlineScript: |\n      sqlServerIdentityId=$(echo $IAC_OUTPUTS | jq -r '.sqlServerIdentityId.value')\n      expectedErrorMessage=\"ERROR: One or more added object references already exist for the following modified properties: 'members'.\"\n      actualErrorMessage=$(az ad group member add --group \"$DirectoryReaderRoleGroupId\" --member-id \"$sqlServerIdentityId\" 2>&1)\n\n      if [ $? -eq 0 ] || [ \"$expectedErrorMessage\" != \"$actualErrorMessage\" ]; then\n          echo $actualErrorMessage\n          echo \"##[warning]Could not give SqlServer DirectoryReader permission, would not be able to ad Azure AD users to SqlServer\"\n          exit 1;\n      fi\n  env:\n    DirectoryReaderRoleGroupId: a7xxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxb0 # ObjectId of your Group\n    IAC_OUTPUTS: $(iacOutputs)\n`\n```\niacOutputs is the output you capture from AzureResourceManagerTemplateDeployment task with following code:\n\n```\n`- task: AzureResourceManagerTemplateDeployment@3\n  inputs:\n    ...\n    deploymentOutputs: 'iacOutputs'\n`\n```\n\nNow you can add AD users and groups to your sql server:\n\n```\n`- task: SqlAzureDacpacDeployment@1\n  inputs:\n    azureSubscription: \"${{variables.YourServiceConnection}}\"\n    AuthenticationType: 'servicePrincipal'\n    ServerName: '...'\n    DatabaseName: '...'\n    IpDetectionMethod: 'AutoDetect'\n    deployType: 'InlineSqlTask'\n    SqlInline: |\n      IF DATABASE_PRINCIPAL_ID('Azure AD Group name') IS NULL\n        CREATE USER [Azure AD Group name] FROM EXTERNAL PROVIDER;\n`\n```\nor even run EF Core migrations using AD Authentications with no SQL username or passowrds in the code\n\n```\n`- task: AzureCLI@2\n  displayName: EF database update\n  inputs:\n    azureSubscription: \"${{variables.YourServiceConnection}}\"\n    scriptType: 'bash'\n    scriptLocation: 'inlineScript'\n    inlineScript: |\n        dotnet new tool-manifest\n        dotnet tool install dotnet-ef\n        dotnet ef database update --connection \"Server=tcp:$(serverUrl),1433;Database=$(dbName);Encrypt=true;Connection Timeout=30;Authentication=\\\"Active Directory Default\\\"\" --no-build\n`\n```\nHope this helped :)",
      "question_score": 8,
      "answer_score": 2,
      "created_at": "2022-04-28T10:54:51",
      "url": "https://stackoverflow.com/questions/72040764/unable-to-automate-ad-user-creation-in-azure-sql-database"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 71171933,
      "title": "Error CS0104: &#39;Guid&#39; is an ambiguous reference between &#39;System.Guid&#39; and &#39;System.Guid&#39;",
      "problem": "On one of my projects I have enabled ImplicitUsings (C# 10) feature. The project is an Sdk project multi-targeting .NET 4.8 Framework and .NET 6. As of yesterday my builds started failing on Azure DevOps with the following error:\n\nError CS0104: 'Guid' is an ambiguous reference between 'System.Guid' and 'System.Guid'\n\nEven a build of a previously known-good commit (day before yesterday) is now failing. The pipeline hasn't changed. Inspecting the agent's image yields the same version (20220207.1). The problem doesn't reproduce locally on the latest Visual Studio 2022 (17.1).\nThe problem occurs in files that include `using System`, such as EF Core migration files. I probably could resolve the problem by removing these \"unused\" usings, but the problem will reappear whenever a new migration is created. The generated usings (`obj\\Debug\\net48\\Project.GlobalUsings.g.cs`) declare the following using `global using global::System;`. Using `Guid` in other files don't produce this error.\nUpdate. The saga continues. I'm now also getting a build failure on a .NET 6 project referencing other .NET Standard 2 projects. The error lies in a generated source file (DragonFruit) with the line `using System.Threading.Tasks`. Builds fine locally, but fails on Azure DevOps with this error:\n\nD:\\a\\1\\s\\XXX\\obj\\Debug\\net6.0\\XXX.g.cs(8,31): error CS0104: 'Task<>' is an ambiguous reference between 'System.Threading.Tasks.Task' and 'System.Threading.Tasks.Task' [D:\\a\\1\\s\\Source\\XXX.csproj]\n\nWhat could've changed that these usings are now causing build failures? And how can I resolve this warning without having the manually update the migrations?",
      "solution": "Posted on the Sonar Community:\n\nFYI for those not following the Roslyn bug #60259, Microsoft have identified an issue in the compiler that could cause the observed behaviour in some multi-threaded scenarios.\nUpdate: ... and the issue has been fixed. The fix is currently linked to the v17.3 release i.e. it is not yet available.\n\nSo Visual Studio 17.3 (and related tooling) will contain a fix for this.\nUpdate: since updating to 17.3 I haven\u2019t seen this error anymore.",
      "question_score": 8,
      "answer_score": 1,
      "created_at": "2022-02-18T11:26:42",
      "url": "https://stackoverflow.com/questions/71171933/error-cs0104-guid-is-an-ambiguous-reference-between-system-guid-and-system"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 74643045,
      "title": "No pool was specified, although a pool is specified in the Azure pipeline",
      "problem": "I have a problem in the ADOS system that the pipeline fails because there is no \"pool\" specified. Also the validation shows this error. However, I have defined a pool.\n`trigger: \n  branches:\n    include:\n      - 'main'\n\npool: \n  name: my-pool\n  demands:\n    - my_pool_demands\n\n[...]\n`\nDo you have any clue?\nI tried to\n\nrun the pipeline with other pool\nrun the pipeline without pool\nrun the pipeline with minimum tasks (only build task)\nrun the pipeline without any comments in it\n\nNothing could change the \"No pool was specified\" error.",
      "solution": "After hours of modifying my pipeline and reading the documentation, I finally figured out how to fix this problem. It is not because of the yaml file. The error must be related to the pipeline. The solution is to create a new pipeline. The same yaml file will work fine in the new pipeline.",
      "question_score": 7,
      "answer_score": 11,
      "created_at": "2022-12-01T14:59:04",
      "url": "https://stackoverflow.com/questions/74643045/no-pool-was-specified-although-a-pool-is-specified-in-the-azure-pipeline"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 73485194,
      "title": "This virtual machine scale set is already in use by pool",
      "problem": "I had created a virtual machine scaleset agent pool. After testing I have deleted the agent pool and the virtual machine scaleset. Again I have created a new virtual machine scale set with the same name created before and when adding it to the agent pool I am getting the error \"This virtual machine scale set is already in use by pool\"",
      "solution": "To fix this issue delete manually the tag from the scaleset. You can do this via the Azure Portal. In the scaleset, click the Tags link on the left and delete the tags labeled",
      "question_score": 7,
      "answer_score": 18,
      "created_at": "2022-08-25T11:33:31",
      "url": "https://stackoverflow.com/questions/73485194/this-virtual-machine-scale-set-is-already-in-use-by-pool"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 77785866,
      "title": "How to set .NET 8.0 in DevOps Release pipeline?",
      "problem": "When using Azure Web App Deploy Task you must choose Runtime Stack that will be used in the Azure Web App.\nI have recently updated from .NET 6 to .NET 8 and to my surprise you can set .NET 8 everywhere needed (like Pipeline build, Azure General Settings), but not in the Azure Web App Deploy Task where it is missing from dropdown and that causes your Web App service to fallback to .NET 7, which can make your app stop running.\nHow can you fix that broken pipeline?",
      "solution": "It's unclear from the screenshot on @wade-zhou-msft's answer if the App Service is deploying to Windows or Linux, of if there is a difference between OS'es.\nHowever for my Linux App Service, I had to use a slightly different value: `DOTNETCORE|8.0`\nTo copy my answer on the VS dev community channel:\n\nI was able to use v4 of the Azure App Service deploy task to manually enter \u201cDOTNETCORE|8.0\u201d - note the slightly different format from the selectable options. Only tested for Azure Resource Manager for Linux.\n\nLogs after deploy:",
      "question_score": 7,
      "answer_score": 9,
      "created_at": "2024-01-09T11:02:01",
      "url": "https://stackoverflow.com/questions/77785866/how-to-set-net-8-0-in-devops-release-pipeline"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 73785436,
      "title": "Azure DevOps pipeline task `task: gitversion/execute@0` fails with unexpected error &quot;##[error]SyntaxError: Unexpected end of JSON input&quot;",
      "problem": "I was running the pipeline with a simple task to install the git and check the version by the following `tasks`.\nEverything was running well till the time I created another temporary pipeline with the same yaml file for some additional tests and development.\nI did not change anything from the yaml file which is running green still, with the same tasks.\nBut the execute task in the new pipeline fails with an 'unexpected' error\n```\n`  steps:\n    - task: gitversion/setup@0\n      displayName: Install GitVersion\n      inputs:\n        versionSpec: \"5.10.x\"\n    \n    - task: gitversion/execute@0\n      displayName: Determine Version\n      inputs:\n        useConfigFile: true\n        configFilePath: ./gitversion.yml\n`\n```\nThe output looks like this:\n```\n`\nCommand: dotnet-gitversion /agent/_work/26/s /output json /output buildserver /config /agent/_work/26/s/gitversion.yml\n/opt/hostedtoolcache/GitVersion.Tool/5.10.3/x64/dotnet-gitversion /agent/_work/26/s /output json /output buildserver /config /agent/_work/26/s/gitversion.yml\n  ERROR [09/20/22 12:54:22:24] An unexpected error occurred:\nSystem.NullReferenceException: Object reference not set to an instance of an object.\n   at LibGit2Sharp.Core.Handles.ObjectHandle.op_Implicit(ObjectHandle handle) in /_/LibGit2Sharp/Core/Handles/Objects.cs:line 509\n   at LibGit2Sharp.Core.Proxy.git_commit_author(ObjectHandle obj) in /_/LibGit2Sharp/Core/Proxy.cs:line 289\n   at LibGit2Sharp.Core.LazyGroup`1.Dependent`2.LibGit2Sharp.Core.LazyGroup.IEvaluator.Evaluate(TInput input) in /_/LibGit2Sharp/Core/LazyGroup.cs:line 88\n   at LibGit2Sharp.Core.LazyGroup`1.b__6_0(T input) in /_/LibGit2Sharp/Core/LazyGroup.cs:line 36\n   at LibGit2Sharp.Core.GitObjectLazyGroup.EvaluateInternal(Action`1 evaluator) in /_/LibGit2Sharp/Core/GitObjectLazyGroup.cs:line 20\n   at LibGit2Sharp.Core.LazyGroup`1.Evaluate() in /_/LibGit2Sharp/Core/LazyGroup.cs:line 34\n   at LibGit2Sharp.Core.LazyGroup`1.Dependent`2.Evaluate() in /_/LibGit2Sharp/Core/LazyGroup.cs:line 80\n   at LibGit2Sharp.Core.LazyGroup`1.Dependent`2.get_Value() in /_/LibGit2Sharp/Core/LazyGroup.cs:line 73\n   at LibGit2Sharp.Commit.get_Committer() in /_/LibGit2Sharp/Commit.cs:line 87\n   at GitVersion.Commit..ctor(Commit innerCommit) in D:\\a\\GitVersion\\GitVersion\\src\\GitVersion.LibGit2Sharp\\Git\\Commit.cs:line 17\n   at GitVersion.Commit.<>c.b__3_0(Commit parent) in D:\\a\\GitVersion\\GitVersion\\src\\GitVersion.LibGit2Sharp\\Git\\Commit.cs:line 16\n   at System.Linq.Enumerable.SelectEnumerableIterator`2.MoveNext()\n   at System.Linq.Enumerable.Count[TSource](IEnumerable`1 source)\n   at GitVersion.Configuration.BranchConfigurationCalculator.InheritBranchConfiguration(Int32 recursions, IBranch targetBranch, BranchConfig branchConfiguration, ICommit currentCommit, Config configuration, IList`1 excludedInheritBranches) in D:\\a\\GitVersion\\GitVersion\\src\\GitVersion.Core\\Configuration\\BranchConfigurationCalculator.cs:line 77\n   at GitVersion.Configuration.BranchConfigurationCalculator.GetBranchConfigurationInternal(Int32 recursions, IBranch targetBranch, ICommit currentCommit, Config configuration, IList`1 excludedInheritBranches) in D:\\a\\GitVersion\\GitVersion\\src\\GitVersion.Core\\Configuration\\BranchConfigurationCalculator.cs:line 54\n\n....\nSystem.NullReferenceException: Object reference not set to an instance of an object.\n   at GitVersion.GitVersionCalculateTool.CalculateVersionVariables() in D:\\a\\GitVersion\\GitVersion\\src\\GitVersion.Core\\Core\\GitVersionCalculateTool.cs:line 52\n   at LibGit2Sharp.Core.Handles.ObjectHandle.op_Implicit(ObjectHandle handle) in /_/LibGit2Sharp/Core/Handles/Objects.cs:line 509\n   at GitVersion.GitVersionExecutor.RunGitVersionTool(GitVersionOptions gitVersionOptions) in D:\\a\\GitVersion\\GitVersion\\src\\GitVersion.App\\GitVersionExecutor.cs:line 66\n   at LibGit2Sharp.Core.Proxy.git_commit_author(ObjectHandle obj) in /_/LibGit2Sharp/Core/Proxy.cs:line 289\n   at LibGit2Sharp.Core.LazyGroup`1.Dependent`2.LibGit2Sharp.Core.LazyGroup.IEvaluator.Evaluate(TInput input) in /_/LibGit2Sharp/Core/LazyGroup.cs:line 88\n   at LibGit2Sharp.Core.LazyGroup`1.b__6_0(T input) in /_/LibGit2Sharp/Core/LazyGroup.cs:line 36\n   at LibGit2Sharp.Core.GitObjectLazyGroup.EvaluateInternal(Action`1 evaluator) in /_/LibGit2Sharp/Core/GitObjectLazyGroup.cs:line 20\n   at LibGit2Sharp.Core.LazyGroup`1.Evaluate() in /_/LibGit2Sharp/Core/LazyGroup.cs:line 34\n\n.....\n   at GitVersion.VersionCalculation.NextVersionCalculator.get_context() in D:\\a\\GitVersion\\GitVersion\\src\\GitVersion.Core\\VersionCalculation\\NextVersionCalculator.cs:line 15\n   at GitVersion.VersionCalculation.NextVersionCalculator.FindVersion() in D:\\a\\GitVersion\\GitVersion\\src\\GitVersion.Core\\VersionCalculation\\NextVersionCalculator.cs:line 30\n   at GitVersion.GitVersionCalculateTool.CalculateVersionVariables() in D:\\a\\GitVersion\\GitVersion\\src\\GitVersion.Core\\Core\\GitVersionCalculateTool.cs:line 52\n   at GitVersion.GitVersionExecutor.RunGitVersionTool(GitVersionOptions gitVersionOptions) in D:\\a\\GitVersion\\GitVersion\\src\\GitVersion.App\\GitVersionExecutor.cs:line 66\n  INFO [09/20/22 9:44:27:78] Attempting to show the current git graph (please include in issue): \n  INFO [09/20/22 9:44:27:78] Showing max of 100 commits\n  INFO [09/20/22 9:44:27:80] * 03932e8 2 hours ago  (grafted, HEAD -> feature/legok8sdeploy, origin/03932e8129e442c335e9ffd69a88b0ce4df3a3f0, 03932e8129e442c335e9ffd69a88b0ce4df3a3f0)\n\n  INFO [09/20/22 9:44:27:82] Done writing \n##[error]SyntaxError: Unexpected end of JSON input\n`\n```\nThe error doesn't seem to be very intuitive.\nI could find a GitHub issue opened here:\nhttps://github.com/GitTools/GitVersion/issues/3081\nBut this doesn't give any solution to resolve and make the task green again.\n\nNote: I'm running it from my branch and not main.",
      "solution": "The cause of the issue could be related to the fetch depth of the Pipeline repo.\nBy default, the Shallow fetch of the pipeline repo is  1 by default.\nYou can try to set the fetchDepth to 0 in YAML Pipeline.\nFor example:\n```\n`steps:\n    - checkout: self\n      fetchDepth: 0\n    - task: gitversion/setup@0\n      displayName: Install GitVersion\n      inputs:\n        versionSpec: \"5.10.x\"\n    \n    - task: gitversion/execute@0\n      displayName: Determine Version\n      inputs:\n        useConfigFile: true\n        configFilePath: ./gitversion.yml\n`\n```\nOr you can navigate to YAML Pipeline -> ... -> Triggers -> YAML -> Get sources -> Shallow fetch.  You can unselect the option.",
      "question_score": 7,
      "answer_score": 16,
      "created_at": "2022-09-20T12:45:30",
      "url": "https://stackoverflow.com/questions/73785436/azure-devops-pipeline-task-task-gitversion-execute0-fails-with-unexpected-er"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 70661849,
      "title": "Error view Index.cshtml not found for ASP.NET Core 6 MVC app when build on Azure build agent",
      "problem": "I get an error \"View Index.cshtml not found\" for my ASP.NET Core 6 MVC app when building it on Azure build agent, but when building locally, it is working fine.\nI tried same command which is executed on build agent still could not get the issue. Tried several code changes to fix this issue but still no clues. Searched on net even on stackoverflow but sadly no solution works.\nPlease someone help me out.\nI am using following input in pipeline.yaml:\n```\n`      solution: 'src/Indl.Web.Core.sln'\n      msbuildArgs: '/property:OutDir=\"$(BUILD.BINARIESDIRECTORY)\"\\x64\\ /p:RunWixToolsOutOfProc=true /p:PackageVersion=$(GitVersion.SemVer) /p:SASigning=true /p:SACertificate=prod.prot /p:PackageOutputPath=\"$(BUILD.BINARIESDIRECTORY)\"\\x64\\'\n      platform: 'x64'\n      vsVersion: '16.0'\n      configuration: 'Release'\n      clean: true\n      msbuildArchitecture: 'x64\n`\n```\nThe solution has one more mvc app which is working as expected.\nI cross verified dll and found that the section 'AspNetCoreGeneratedDocument' is not available in dll which is usually has all view related information.",
      "solution": "Please use following command in pipeline.yaml\nhope it should work.\n```\n`solution: 'src/Indl.Web.Core.sln'\n  msbuildArgs: '/property:OutDir=\"$(BUILD.BINARIESDIRECTORY)\"\\x64\\ /p:RunWixToolsOutOfProc=true /p:PackageVersion=$(GitVersion.SemVer) /p:SASigning=true /p:SACertificate=prod.prot /p:PackageOutputPath=\"$(BUILD.BINARIESDIRECTORY)\"\\x64\\'\n  platform: 'x64'\n  vsVersion: '17.0'\n  configuration: 'Release'\n  clean: true\n  msbuildArchitecture: 'x64\n`\n```\nActually you used vsVersion of vs 2019(16.0) but since you are compiling .Net 6.0 which is fully supported in vs 2022(17.0)",
      "question_score": 7,
      "answer_score": 1,
      "created_at": "2022-01-11T06:01:32",
      "url": "https://stackoverflow.com/questions/70661849/error-view-index-cshtml-not-found-for-asp-net-core-6-mvc-app-when-build-on-azure"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 76070532,
      "title": "Az version null not avaiable locally on the agent. Validate-VersionParameters: Cannot convert value &#39;null&#39; to type &#39;System.Version&#39;",
      "problem": "Facing an issue while trying to run the AzurePowerShell@5 task in Azure devops\n```\n`Az version null not avaiable locally on the agent. Downloading dynamically.\nValidate-VersionParameters: Cannot convert value 'null' to type 'System.Version'\nException: /home/vsts/work/_tasks/AzurePowerShell_72a1931b-effb-4d2e-8fd8-f8472a07cb62/5.218.0/Utility.ps1:94\nLine |\n94 |  \u2026             throw (\"Could not find the module path with given version \u2026\n |                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n | Could not find the module path with given version.\n [![enter image description here][1]][1]\n`\n```",
      "solution": "This task requires a parameter azurePowerShellVersion. Provide the value 'Latest' or 'Other'.\nThere was a github issue raised for this issue. https://github.com/MicrosoftDocs/azure-devops-docs/issues/11928 .\nThe highlighted parameter is required. https://learn.microsoft.com/en-us/azure/devops/pipelines/tasks/reference/azure-powershell-v5?view=azure-pipelines",
      "question_score": 7,
      "answer_score": 13,
      "created_at": "2023-04-21T08:40:44",
      "url": "https://stackoverflow.com/questions/76070532/az-version-null-not-avaiable-locally-on-the-agent-validate-versionparameters-c"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 66846584,
      "title": "Replace tokens during release in Azure DevOps",
      "problem": "I have a release pipeline to deploy an ASP.NET Core web app. This was created from a simple ASP.NET web deploy template on Azure DevOps. The web deploy step just points to the .zip file of the artifact drop folder and deploys the app.\nI would like to replace tokens in my appSettings.Staging.json file for example:\n\nI am using Token Replace marketplace tool: https://github.com/qetza/vsts-replacetokens-task and setting it up in a pretty standard way as documented:\n\nand setting up my variables in devops:\n\nI would like the \"DummyValue\" to be replaced with \"ActualValue\".\nSince the artifact is a zip file, I added the \"File Extractor\" task to unzip the the archive and then had Token Replace task target that folder. According to the logs, it seems like the Token Replace did end up replacing a value, but I can't access those resources directly to make sure.\nSince I am now extracting files, I pointed the web deploy task to the new folder where the unarchived files reside, and it successfully deployed, but the resulting appsettings.Staging.json file still doesn't have the token replaced. In the logs of the deploy job I saw this:\n\n2021-03-28T07:36:19.6554561Z Package deployment using ZIP Deploy\ninitiated. 2021-03-28T07:38:08.8457706Z Successfully deployed web\npackage to App Service.\n\nSeems like it's still using ZIP deployment, and I am not sure where it's finding the zip file as there's nothing in the DevOps logs for that.\nJust wondering if anybody else has experienced this and what the best way is to go with this.",
      "solution": "It seems that you are using this extension: XDT Transform. After installing it in organization, there are 2 external tasks: XDT tranform task and Replace Tokens task in release pipeline.\nThere is `appSettings.Staging.json` file in my repo and it will be published into zip artifact.\n\nIn my release pipeline, the path to this artifact is `$(System.DefaultWorkingDirectory)/Drop/drop/aspnet-core-dotnet-core.zip`.\n\nIf I want to replace the `DummyValue` token in `appSettings.Staging.json` file of this artifact, creating pipeline variable `DummyValue` and using the Extract Files task, Replace Tokens task, and Archive Files task, finally the release will archive the replaced folders to replace original zip artifact, so it is done.  so it is done. The unnecessary PowerShell task is used to output the replaced file.",
      "question_score": 7,
      "answer_score": 12,
      "created_at": "2021-03-28T23:56:28",
      "url": "https://stackoverflow.com/questions/66846584/replace-tokens-during-release-in-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 74027158,
      "title": "VSCode Azure Functions - Error: Cannot read properties of undefined (reading &#39;createClient&#39;)",
      "problem": "I'm unable to upload the code to azure functions for some reason. It was working few days ago when I tried.\nNow I get the below error. Here is a screenshot of the error.\n\n```\n`4:27:59 PM: Error: Cannot read properties of undefined (reading 'createClient')\n4:28:03 PM: Error: Cannot read properties of undefined (reading 'createClient')\n4:31:28 PM: Error: Cannot read properties of undefined (reading 'createClient')\n`\n```\nOnly thing I modified this time is the `local.settings.json` as below.\n```\n`{\n  \"IsEncrypted\": false,\n  \"Values\": {\n    \"FUNCTIONS_WORKER_RUNTIME\": \"dotnet\",\n    \"AzureWebJobsStorage\": \"##########\",\n    \"CosmosDBConnection\": \"##########\",\n    \"StorageConnectionString\": \"#########\"\n  }\n}\n`\n```\ntried the old version of the code which used to work and there were no modification but now that also reports the same error.\nAny idea what the issue is? I'm guessing something wrong with vscode.\nHere is my `local.settings.json`:\n```\n`{\n  \"IsEncrypted\": false,\n  \"Values\": {\n    \"FUNCTIONS_WORKER_RUNTIME\": \"dotnet\",\n    \"AzureWebJobsStorage\": \"#############\",\n    \"CosmosDBConnection\": \"#############\",\n    \"StorageConnectionString\": \"#############\"\n  }\n}\n`\n```\nHere is the .vscode\\settings.json\n```\n`{\n  \"azureFunctions.deploySubpath\": \"bin/Release/netcoreapp3.1/publish\",\n  \"azureFunctions.projectLanguage\": \"C#\",\n  \"azureFunctions.projectRuntime\": \"~3\",\n  \"debug.internalConsoleOptions\": \"neverOpen\",\n  \"azureFunctions.preDeployTask\": \"publish (functions)\"\n}\n`\n```\nUpdate: Uploading from resource view works but uploading from workspace doesn't work. Here is a reference to the bug reported and the work around.",
      "solution": "Figured it out.\nDelete or move the `.vscode` folder from the project folder and restart the Visual studio code and it'll initialize the function app again. Now you can upload the function without any issues.",
      "question_score": 7,
      "answer_score": 10,
      "created_at": "2022-10-11T13:10:33",
      "url": "https://stackoverflow.com/questions/74027158/vscode-azure-functions-error-cannot-read-properties-of-undefined-reading-cr"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 69356649,
      "title": "Use parameter in PowerShell in Azure DevOps pipeline",
      "problem": "We have recently started using Azure DevOps Pipelines for our Dynamics 365 CRM implementation, but it is still new to me\nI recently came across this blog post by Joe Griffin on how you can use PowerShell in Azure DevOps pipelines to ensure, that Access Team Templates works when deploying a solution - and I would like to use that.\nHowever, I don't know where I add my parameters to script. Can I do that inline or do I need to add the script to my repo to do that? If so - how can I do that?\n```\n`param(\n    #objectTypeCode: Unique Code that identifies the table in the environment for the Access Team Template. Always potentially different.\n    [Parameter(Mandatory=$true)]\n    [int]$objectTypeCode,\n    #atName: Name of the Access Team Template\n    [Parameter(Mandatory=$true)]\n    [String]$atName,\n    #accessRights: Number which represents the access rights defined for the template. Refer to this article for details on how to construct: https://learn.microsoft.com/en-us/dynamics365/customer-engagement/web-api/accessrights?view=dynamics-ce-odata-9\n    [Parameter(Mandatory=$true)]\n    [int]$accessRights,\n    #d365URL: URL of the environment to connect to\n    [Parameter(Mandatory=$true)]\n    [String]$d365URL,\n    #clientID: AAD Client ID for the Application User linked to this environment\n    [Parameter(Mandatory=$true)]\n    [String]$clientID,\n    #clientSecret: AAD Client Secret for the Application User linked to this environment\n    [Parameter(Mandatory=$true)]\n    [String]$clientSecret\n)\n\n#Install dependencies\nInstall-Module Microsoft.Xrm.Data.PowerShell -Scope CurrentUser -Force\n#Connect to the D365 environment\n$conn = Connect-CrmOnline -ServerUrl $d365URL -ClientSecret $clientSecret -OAuthClientId $clientID -OAuthRedirectUri \"http://localhost\"\n#We first attempt to retrieve the rows if they already exist, and update it accordingly; if this errors, then the row does not exist, so we need to create it instead\nWrite-Host \"Processing Access Team Template for $atName...\"\ntry\n{\n    $atTemplate = Get-CrmRecord -conn $conn -EntityLogicalName teamtemplate -Id \"44396647-CEDF-EB11-BACB-000D3A5810F2\" -Fields teamtemplateid,teamtemplatename,objecttypecode,defaultaccessrightsmask,issystem\n    $atTemplateId = $atTemplate.teamtemplateid\n    Write-Host \"Got existing Access Team Template row with ID $atTemplateId!\"\n    $atTemplate.teamtemplatename = $atName\n    $atTemplate.objecttypecode = $objectTypeCode\n    $atTemplate.defaultaccessrightsmask = $accessRights\n    $atTemplate.issystem = 0\n    Set-CrmRecord -conn $conn -CrmRecord $atTemplate\n    Write-Host \"Successfully updated Access Team Template row with ID $atTemplateId!\"\n}\ncatch [System.Management.Automation.RuntimeException]\n{\n    Write-Host \"Access Template row with ID $atTemplateId does not exist, creating...\"\n    $atTemplateId = New-CrmRecord -conn $conn -EntityLogicalName teamtemplate `\n    -Fields @{\"teamtemplateid\"=[guid]\"{44396647-CEDF-EB11-BACB-000D3A5810F2}\";\"teamtemplatename\"=$atName;\"objecttypecode\"=$objectTypeCode;\"defaultaccessrightsmask\"=$accessRights;\"issystem\"=0}   \n    Write-Host \"Successfully created new Access Template row with ID $atTemplateId\"\n}\nWrite-Host \"Script execution finished!\"\n`\n```",
      "solution": "You can use \"Azure Powershell\" task (If the script has to do something on azure) and can specify path to your powershell file and can add parameter values as in this screenshot,\n\nor you can use \"Powershell\"task and can add path to the file and parameter,",
      "question_score": 7,
      "answer_score": 2,
      "created_at": "2021-09-28T08:15:56",
      "url": "https://stackoverflow.com/questions/69356649/use-parameter-in-powershell-in-azure-devops-pipeline"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 66850265,
      "title": "How to see commits by user accross multiple repositories in Azure DevOps?",
      "problem": "I want to see the commits by a user across all repositories in my organization in Azure DevOps. I cannot see such options available.\nI can see the below option in Azure DevOps, but it shows commits in a single repository.\n\nI know we can use the below git command to see the commits in a single repository.\n```\n`git log --author --all ( or --branches)\n`\n```",
      "solution": "Check this REST API sample By author, it contain the filed author, we could enter Alias or display name of the author to list all commit info.\nIn addition, we could add the filed `searchCriteria.itemVersion.version` to filter branch.\n```\n`GET https://dev.azure.com/{Org name}/{project name}/_apis/git/repositories/{repo name}/commits?searchCriteria.author={searchCriteria.author}&searchCriteria.itemVersion.version={branch name}&api-version=6.0\n`\n```\n\nI want to see the commits by a user across all repositories in my organization in Azure DevOps\n\na. List all projects via org name and get the project name.\n```\n`GET https://dev.azure.com/{organization}/_apis/projects?api-version=6.0\n`\n```\nb. List all repos via org name and project name and get the repo name.\n```\n`GET https://dev.azure.com/{organization}/{project}/_apis/git/repositories?api-version=6.0\n`\n```\nc. List all branches via org name, project name and repo name, then get branch name\n```\n`GET https://dev.azure.com/{Org name}/{project name}/_apis/git/repositories/{repo name}/refs?filter=heads&api-version=6.1-preview.1\n`\n```\nd. List commit info via Alias or display name of the author\n```\n`GET https://dev.azure.com/{Org name}/{project name}/_apis/git/repositories/{repo name}/commits?searchCriteria.author={searchCriteria.author}&searchCriteria.itemVersion.version={branch name}&api-version=6.0\n`\n```\nPower shell script:\n```\n`cls\n\n#List all projects via org name\n$ListAllProjectsURL=\"https://dev.azure.com/{org name}/_apis/projects?api-version=6.0\"\n$PAT=\"{pat}\"\n$base64AuthInfo= [System.Convert]::ToBase64String([System.Text.Encoding]::ASCII.GetBytes(\":$($PAT)\"))\n\n#get the project name\n$ListAllProjects = Invoke-RestMethod -Uri $ListAllProjectsURL -Headers @{Authorization = \"Basic {0}\" -f $base64AuthInfo} -Method get\n\nForEach ($ProjectName in $ListAllProjects.value.name){\n    #Write-Host $ProjectName\n    #List all repos via org name and project name and get the repo name.\n    $ListAllRepoURL = \"https://dev.azure.com/{org name}/$($ProjectName)/_apis/git/repositories?api-version=6.0\"\n    $ListAllRepo = Invoke-RestMethod -Uri $ListAllRepoURL -Headers @{Authorization = \"Basic {0}\" -f $base64AuthInfo} -Method get\n\n    ForEach ($RepoName in $ListAllRepo.value.name){\n        #Write-Host $RepoName\n        $ListAllBranchURL =\"https://dev.azure.com/{org name}/$($ProjectName)/_apis/git/repositories/$($RepoName)/refs?filter=heads&api-version=6.1-preview.1\"                          \n        $ListBranchName = Invoke-RestMethod -Uri $ListAllBranchURL -Headers @{Authorization = \"Basic {0}\" -f $base64AuthInfo} -Method get\n        #get branch name\n        foreach($Branch in $ListBranchName.value){\n            $BranchName = $Branch.name.split(\"/\",3)[-1]\n            #write-host $BranchName\n\n            #List the commits by a user across all repositories in one organization in Azure DevOps\n            $ListCommitInfoViaUserURL = \"https://dev.azure.com/{org name}/$($ProjectName)/_apis/git/repositories/$($RepoName)/commits?searchCriteria.author={User display name}&searchCriteria.itemVersion.version=$($BranchName)&api-version=6.0\"\n            $ListCommitInfo = Invoke-RestMethod -Uri $ListCommitInfoViaUserURL -Headers @{Authorization = \"Basic {0}\" -f $base64AuthInfo} -Method get\n\n            if($ListCommitInfo.count -eq 0){\n\n            }else{\n                Write-Host \"Project name is:\"$ProjectName \"    repo name is:\" $RepoName    \"branch name is:\" $BranchName    \"and commit ID is:\" $ListCommitInfo.value.commitId \n            }\n        }\n    }\n}\n`\n```\nResult:",
      "question_score": 7,
      "answer_score": 9,
      "created_at": "2021-03-29T09:33:52",
      "url": "https://stackoverflow.com/questions/66850265/how-to-see-commits-by-user-accross-multiple-repositories-in-azure-devops"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 66738557,
      "title": "How to generate sensible error messages in azure devops pipeline from a python script",
      "problem": "I'm using python in my build pipeline to run some checks on pull requests. When checks fail, I use `sys.exit('reason')` to exit the script. This works but the output is not helpful. All that's shown in the PR page is this:\n\nThe process 'C:\\hostedtoolcache\\windows\\Python\\3.7.9\\x64\\python.exe'\nfailed with exit code 1\n\nI would like to know how to pass the reason to this page so the developers don't have to dig into the pipeline log to see what actually went wrong. In powershell I can use the following commands:\n```\n`Write-Host \"##vso[task.logissue type=error;]Reason\"\nWrite-Host \"##vso[task.complete result=Failed;]Text\"\n`\n```",
      "solution": "You can use the same logging commands in python also, with `print()`:\n```\n`steps:\n- task: PythonScript@0\n  inputs:\n    scriptSource: inline\n    script: |\n     print(\"##vso[task.logissue type=error;]Reason\")\n     print(\"##vso[task.complete result=Failed;]Text\")\n`\n```\nIn the PR you will see:",
      "question_score": 7,
      "answer_score": 9,
      "created_at": "2021-03-22T00:16:46",
      "url": "https://stackoverflow.com/questions/66738557/how-to-generate-sensible-error-messages-in-azure-devops-pipeline-from-a-python-s"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 67018840,
      "title": "How to source Terraform module hosted within Azure DevOps Repo via ssh",
      "problem": "Looking for the correct/working way to source a Terraform module that is hosted within a private Azure DevOps git repo via SSH (see TF Docs on Git repo sourcing via ssh).\nIt's undesirable to have a PAT token as it will eventually expire and renewal can't be automated yet (although coming soon apparently). Despite that, have validated the https method but I would like to avoid needing to edit the source if I can as module source references can't include terraform vars at init time.\nI have followed the following steps to generate an ssh private/public key pair and those files have been added to my local `.ssh` folder @ `C:\\Windows\\Users\\\\.ssh`.\nExample terraform code below:\n```\n`module \"test\" {\n    source = \"\"\n}\n`\n```\nWhere `` has been tested with:\n\n`git::https://:dev.azure.com///_git///?ref=` - worked/validated https approach as last resort\n`git::ssh://git@ssh.dev.azure.com:v3///_git///?ref=`\n`git::ssh://git@ssh.dev.azure.com/v3///_git///?ref=` - see terraform/issues/18869\n\nAfter reading about multiple keys here:\n\nGenerally, if you configure multiple keys for an SSH client and connect to an SSH server, the client can try the keys one at a time until the server accepts one. However, this doesn't work with Azure DevOps for technical reasons related to the SSH protocol and how our Git SSH URLs are structured. Azure DevOps will blindly accept the first key that the client provides during authentication. If that key is invalid for the requested repo, the request will fail with the following error: remote: Public key authentication failed.\nfatal: Could not read from remote repository.\n\nI played around with my `.ssh/config` file including\n\nRemoving all other keys other than the `automation` ssh key pair that I wanted to use specifically for this case (as opposed to my own personal SSH key identifying me)\nUpdating `.ssh/config` to look like:\n\n```\n`Host automation\n    HostName ssh.dev.azure.com\n    IdentityFile ~/.ssh/automation_account\n    IdentitiesOnly yes\nHost azuredevops\n    HostName ssh.dev.azure.com\n    IdentityFile ~/.ssh/azuredevops\n    IdentitiesOnly yes\n`\n```\nAnd then within the `` trying:\n\n`git::ssh://git@automation/v3///_git///?ref=`\n`git::ssh://automation/v3///_git///?ref=`\n\nWhere all of these attempts result in:\n```\n`Permission denied, please try again.\ngit@ssh.dev.azure.com: Permission denied (password,publickey).\nfatal: Could not read from remote repository.\n`\n```\nOr\n```\n`does not appear to be a git repository\nfatal: Could not read from remote repository.\n`\n```\nThe ssh key that I am using, have validated that it is registered with Azure DevOps by getting the thumbprint `ssh-keygen -E md5 -lf ` and getting back `2048 MD5:ab:e2:... automation (RSA)` which I can confirm exists within Azure DevOps under my SSH keys.\nI have validated that the key allows me to access one of my target TF repos by adding a new git remote using that specific key. `git remote -v` gives me:\n```\n`aorigin       git@automation:v3///_git/ (fetch)\naorigin       git@automation:v3///_git/ (push)\norigin  git@ssh.dev.azure.com:v3///_git/ (fetch)\norigin  git@ssh.dev.azure.com:v3///_git/ (push)\n`\n```\nAnd a `git pull aorigin` works as expected. Origin is the original SSH clone url from the Azure DevOps gui.\nAlmost certain that I am missing something obvious but after extensive Googling and a number of different configurations, cannot for the life of me get it to work. Help/pointers/suggestions appreciated\nVersions of tools:\n\nTerraform v0.13.4\ngit version 2.17.1.windows.2\nOpenSSH_for_Windows_7.7p1, LibreSSL 2.6.5",
      "solution": "Following this issue and the Terraform documentation, I would try the URL\n```\n`git::automation:v3///_git///?ref=\n`\n```\n(Adding `User git` to my `.ssh/config` file, right after `Hostname`, in order to not have to add the user)\n\nMake sure to upgrade Git first to 2.31.1.\nTry and `set GIT_SSH_COMMAND=\"ssh -Tv\"` before your terraform command, in order to see what key is used.\nCheck if referencing directly OpenSSH would help (unless it is already in your `%PATH%`: check with `where ssh`)\n\nThe OP Jamie performed the following steps:\n\nUpdated Git to mentioned version\nRegenerated some new keys using steps in MS Docs\nAdded all keys using ssh-add\nAdded public keys to Azure DevOps\nMade the following changes to `.ssh/config` file:\n\n```\n`Host ssh.dev.azure.com \n  IdentityFile ~/.ssh/me\n  IdentitiesOnly yes\n\nHost automation\n  HostName ssh.dev.azure.com\n  User git\n  IdentityFile ~/.ssh/auto \n  IdentitiesOnly yes \n\nHost automationsec \n  HostName ssh.dev.azure.com \n  User git \n  IdentityFile ~/.ssh/auto_sec \n  IdentitiesOnly yes \n`\n```\n\nTested with the two following cases:\n```\n`module \"test\" {\n  source     = \"git::automation:v3///_git///?ref=\"\n}\n`\n```\nand\n```\n`module \"test\" {\n  source     = \"git::automationsec:v3///_git///?ref=\"\n}\n`\n```\nThe first passwordless entry works, the second case doesn't. Unsure of the root cause as to why a ssh key with a passphrase isn't accepted",
      "question_score": 7,
      "answer_score": 1,
      "created_at": "2021-04-09T11:47:52",
      "url": "https://stackoverflow.com/questions/67018840/how-to-source-terraform-module-hosted-within-azure-devops-repo-via-ssh"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 66694677,
      "title": "Azure DevOps pipeline template - how to concatenate a parameter",
      "problem": "All afternoon I have been trying to get my head around concatenating a parameter in an ADO template. The parameter is a source path and in the template a next folder level needs to be added. I would like to achieve this with a \"simple\" concatenation.\nThe simplified template takes the parameter and uses it to form the inputPath for a PowerShell script, like this:\n```\n`parameters:\n  sourcePath: ''\n\nsteps:   \n- task: PowerShell@2\n  inputs:\n    filePath: 'PSRepo/Scripts/MyPsScript.ps1'\n    arguments: '-inputPath ''$(sourcePath)/NextFolder''\n`\n```\nI have tried various ways to achieve this concatenation:\n\n'$(sourcePath)/NextFolder'\n\nsee above\n\n'$(variables.sourcePath)/NextFolder'\n\nI know sourcePath is not a variable, but tried based on the fact that using a parameter in a task condition it apparently only works when referencing through variables\n\n'${{ parameters.sourcePath }}/NextFolder'\n\nAnd some other variations, all to no avail.\nI also tried to introduce a variables section in the template, but that is not possible.\nI have searched the internet for examples/documentation, but no direct answers and other issues seemed to hint to some solution, but were not working.\nI will surely be very pleased if someone could help me out.\nThanx in advance.",
      "solution": "Thanx, Yujun. In meantime did get it working. Apparently there must have been some typo that did block the script from executing right as the se solution looks like one of the options mentioned above.\n```\n`parameters:\n  sourcePath: ''\n\nsteps:   \n- task: PowerShell@2\n  inputs:\n    filePath: 'PSRepo/Scripts/MyPsScript.ps1'\n    arguments: '-inputPath ''$(sourcePath)/NextFolder''\n`\n```",
      "question_score": 7,
      "answer_score": 2,
      "created_at": "2021-03-18T17:00:35",
      "url": "https://stackoverflow.com/questions/66694677/azure-devops-pipeline-template-how-to-concatenate-a-parameter"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-devops",
      "question_id": 68896612,
      "title": "Working directory parameter of DotNetCoreCL Publish step",
      "problem": "I have a repository with many solutions in it. I'd like to set up a build pipeline in Azure DevOps and build specific solution. I only need the \"standard\" steps as \"restore packages, build, run unit tests, publish\". However, the \"publish\" step gives me a headache.\nThe folder hierarchy for the repository looks like this:\n`src\n    - Solution1\n        - Project1\n        - Project2\n        - Project3\n    - Solution2\n        - Project4\n        - Project5\n    ...\n`\nMy goal would be to publish only the projects of e.g. Solution2 - so Project4 and Project5. Setting the value of `workingDirectory` to \"src/Solution2\" or \"$(System.DefaultWorkingDirectory)/src/Solution2\" don't work as I expected.\nHere's the definition of the build step.\n```\n`- task: DotNetCoreCLI@2\n  displayName: Publish\n  inputs:\n    command: publish\n    arguments: '--configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory)'\n    workingDirectory: src/Solution2\n`\n```\nIn the logs, I see\n\n\"C:\\Program Files\\dotnet\\dotnet.exe\" publish [path_to_agent]_work\\1\\s\\src\\Solution1\\Project1\\Project1.csproj --configuration Release --output [path_to_agent]_work\\1\\a\\Project1\n\nand similar entries for every single project in the repository.\nAs a workaround I tried using the \"custom\" command, but it didn't work out either.\n```\n`- task: DotNetCoreCLI@2\n  displayName: 'Publish'\n  inputs:\n    command: custom\n    arguments: 'src/Solution2 --configuration $(BuildConfiguration) --output $(Build.ArtifactStagingDirectory) '\n    custom: publish\n`\n```\nThis produces a log entry as\n\n\"C:\\Program Files\\dotnet\\dotnet.exe\" publish [path_to_agent]_work\\1\\s\\src\\Solution1\\Project1\\Project1.csproj src/Solution2 --configuration Release --output [path_to_agent]_work\\1\\a\\Project1\n\nand eventually the pipeline fails as `Only one project can be specified`.\nAny ideas what I'm doing wrong?",
      "solution": "I had the same problem. After a lot of trials and errors I came to the conclusion that the workingdirectory parameter is just ignored as explained here.\nAlso I noticed globbing (**/*) does not work if you use quotes. Also publishWebProjects has to be set to false otherwise it will start searching for other projects from the default working folder.\nSo this worked for me:\n```\n`- task: DotNetCoreCLI@2\ninputs:\ncommand: 'publish'\npublishWebProjects: false\nconfiguration: $(buildConfiguration)\nprojects: |\n  $(System.DefaultWorkingDirectory)/pathToProjectA/projectA.csproj\n  $(System.DefaultWorkingDirectory)/pathToProjectB/*.csproj\n`\n```",
      "question_score": 7,
      "answer_score": 5,
      "created_at": "2021-08-23T19:18:48",
      "url": "https://stackoverflow.com/questions/68896612/working-directory-parameter-of-dotnetcorecl-publish-step"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 70051683,
      "title": "System.InvalidOperationException: The gRPC channel URI &#39;http://0&#39; could not be parsed",
      "problem": "Using .NET5 Azure function in Visual Studio 2019, I am getting the below exception from Program.cs:\n\nSystem.InvalidOperationException: The gRPC channel URI 'http://0' could\nnot be parsed\n\nMy `Program.cs` is below:\n```\n`public static void Main()\n{\n    var host = new HostBuilder()\n            .ConfigureFunctionsWorkerDefaults()\n            .ConfigureServices(services =>\n            {\n                services.AddSingleton(data =>\n                {\n                    var result = new ConfigurationBuilder()\n                        .SetBasePath(Directory.GetCurrentDirectory())\n                        .AddJsonFile(\"AppSettings.json\", false, true)\n                        .AddJsonFile($\"AppSettings.{Environment.GetEnvironmentVariable(\"ASPNETCORE_ENVIRONMENT\") ?? \"Production\"}.json\", true)\n                        .AddEnvironmentVariables()\n                        .Build();\n                    return result;\n                });\n\n                services.AddSingleton();\n            })\n            .UseDefaultServiceProvider(options => options.ValidateScopes = false)\n            .Build();\n\n    host.Run();\n}\n`\n```\nThe exception is being thrown from `host.Run()` in Debug mode. Any clue?",
      "solution": "My issue has been solved. Once I set the `IConfiguration` from `ConfigureAppConfiguratio` middleware, the exception is gone\n```\n`public static void Main()\n{\n    var host = new HostBuilder()\n                    .ConfigureFunctionsWorkerDefaults()\n                    .ConfigureAppConfiguration(config =>\n                    {\n                        config.SetBasePath(Directory.GetCurrentDirectory())\n                            .AddJsonFile(\"AppSettings.json\", false, true)\n                            .AddJsonFile(\n                                $\"AppSettings.{Environment.GetEnvironmentVariable(\"ASPNETCORE_ENVIRONMENT\") ?? \"Production\"}.json\",\n                                true)\n                            .AddEnvironmentVariables();\n                    })\n                    .ConfigureServices(services =>\n                    {\n                        \n                    })\n                    .UseDefaultServiceProvider(options => options.ValidateScopes = false)\n                    .Build();\n\n            host.Run();\n}\n`\n```",
      "question_score": 31,
      "answer_score": 12,
      "created_at": "2021-11-21T04:49:04",
      "url": "https://stackoverflow.com/questions/70051683/system-invalidoperationexception-the-grpc-channel-uri-http-0-could-not-be-p"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 69709882,
      "title": "The type initializer for &#39;Microsoft.EntityFrameworkCore.Query.QueryableMethods&#39; threw an exception",
      "problem": "I've got one function app which throws following error when I run it with `azure-functions-core-tools@4.0.3780` `start` command.\n```\n`func start\n`\n```\n```\n`System.Private.CoreLib: Exception while executing function: Test. \nMicrosoft.EntityFrameworkCore: The type initializer for \n'Microsoft.EntityFrameworkCore.Query.Internal.NavigationExpandingExpressionVisitor' \nthrew an exception. Microsoft.EntityFrameworkCore: \nThe type initializer for \n'Microsoft.EntityFrameworkCore.Query.QueryableMethods' threw an exception. \nSystem.Linq: Sequence contains more than one matching element.\n`\n```\nEntrypoint\n`private readonly IRepository _repository;\n\n[FunctionName(\"Test\")]\n        public async Task TestAsync(\n            [ServiceBusTrigger(\n                \"%topic%\",\n                \"%subscription%\",\n                Connection = \"connectionString\")]\n            Message message)\n    {\n        var result = await _repository.ToListAsync();\n    }\n`\nIt works fine when function app is launched from Visual Studio.\nI thought I could get rid of that by directly referencing `Microsoft.EntityFrameworkCore` in function app csproj.\nAny ideas?\nThanks\nFunctionApp.csproj\n```\n`  \n    \n    \n    \n  \n  \n    \n  \n`\n```\nFirstLib.csproj\n```\n`  \n    \n  \n`\n```\nSecondLib.csproj\n```\n` \n    \n    \n    \n  \n`\n```\nVisual Studio version\n```\n`Microsoft Visual Studio Professional 2019\nVersion 16.10.4\n`\n```",
      "solution": "The problem went away when I upgraded `Microsoft.EntityFrameworkCore` to `5.0.0` in `SecondLib` dependency.\n```\n`\n    \n    \n    \n  \n`\n```\nThe `TargetFramework` wasn't touched\n```\n`netcoreapp3.1\nv3\n`\n```",
      "question_score": 31,
      "answer_score": 46,
      "created_at": "2021-10-25T16:30:55",
      "url": "https://stackoverflow.com/questions/69709882/the-type-initializer-for-microsoft-entityframeworkcore-query-queryablemethods"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 78169424,
      "title": "Azure function &quot;.NET 8.0 Isolated&quot; isn t available in Visual Studio 2022 v17.9.3",
      "problem": "After I have installed the latest .Net 8 version (currently v8.0.3) from https://dotnet.microsoft.com/en-us/download and update Visual Studio to 17.9.3 (then restart), I cannot create a Azure function project with the .NET 8 because the entry is missing in the dropdown.\n\nI have updated Azure function core tools too (then restart Visual studio)\nhttps://github.com/Azure/azure-functions-core-tools?tab=readme-ov-file#installing\nbut i cannot still view it ...",
      "solution": "After some google search, i have found the answer on a forum https://developercommunity.visualstudio.com/t/Net-8-is-missing-for-Azure-Function-proj/10520997\nYou can try the following steps to resolve this:\n\nNavigate to Tools -> Options -> Projects and Solutions -> Azure Functions\nClick on Check for Updates, then Download and install.\n\nRestart Visual Studio\n\nEt voil\u00e0 ;)",
      "question_score": 25,
      "answer_score": 66,
      "created_at": "2024-03-15T21:05:26",
      "url": "https://stackoverflow.com/questions/78169424/azure-function-net-8-0-isolated-isn-t-available-in-visual-studio-2022-v17-9-3"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 71292716,
      "title": "Im not able to mock ServiceBusReceivedMessage and ServiceBusMessageActions",
      "problem": "we want to write unit-test for servicebus message trigger. we are using Azure.Messaging.ServiceBus nuget package\n```\n`     [FunctionName(\"serviebustrigger\")]\n  public async Task Run ([ServiceBusTrigger(\"xxxxtopic\", \"xxxxsubscription\", Connection = \"Abs-Connection\", AutoCompleteMessages = false)] ServiceBusReceivedMessage message, ServiceBusMessageActions messageActions)\n\n    {\n        _logger.LogInformation($\"{nameof(Run)} execution started for MessageId:{{MessageId}}\", message.MessageId);\n        try\n        {\n                //some code\n             await messageActions.CompleteMessageAsync(message);\n        }\n        catch (Exception ex)\n         {\n             await messageActions.DeadLetterMessageAsync(message);\n         }\n    }\n`\n```\nNow I want to write unit test for the above code. But I'm not able mock ServiceBusReceivedMessage  and  ServiceBusMessageActions  as these have Internal Constructor. Can someone suggest me better way to write unit test",
      "solution": "There was an oversight with the implementation of `ServiceBusMessageActions` where the mocking constructor was initially missed.  This was corrected in v5.2.0 of the extensions package.\nWith that fix, a parameterless constructor is available to ensure that `ServiceBusMessageActions` is usable with a mocking framework such as Moq or FakeItEasy.  Each of the public members are `virtual` or settable and the class is not sealed.  You should be able to mock using the same approach that you prefer for other types - whether with a mocking framework or inheriting from the class and creating your own mock type - and make use of the model factory to simulate behavior.\nFor `ServiceBusReceivedMessage` and other model types that are returned by service operations, the ServiceBusModelFactory is used to create instances for testing purposes.",
      "question_score": 25,
      "answer_score": 48,
      "created_at": "2022-02-28T10:14:07",
      "url": "https://stackoverflow.com/questions/71292716/im-not-able-to-mock-servicebusreceivedmessage-and-servicebusmessageactions"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 77565541,
      "title": "logs not appearing in Application Insights for Azure Functions v4 with .NET 8",
      "problem": "I have functions being called, and I do logging as such:\n```\n`_logger.LogInformation(...);\n`\n```\nThese do show in the live Log Stream on the portal.\nHowever, when querying the logs in Application Insights (traces), they do not show. whereas all sorts of other info is available, such as\n```\n`Executed 'Functions.' (Succeeded, Id=a23d6397-3a9f-4663-8f26-1b2693a362d5, Duration=14523ms)\n`\n```\nIn my hosts.json file I have:\n```\n`  \"version\": \"2.0\",\n  \"logging\": {\n    \"logLevel\": {\n      \"Default\": \"Information\",\n     ...\n`\n```\nI also used the telemetryClient, and those items do appear (customEvents) in the logs. However, as I said, the items from ILogger do not appear.\n\ntech\nIn App Insights\nIn Live Log Stream\n\nILogger<>\nNO\nYES\n\nTelemetryClient\nYES\nNO\n\nThis is happening with .NET 8 -- I did not have this issue using earlier .NET core versions; items logged via ILogger<> were showing up as expected in the traces table of Application Insights.\nAny thoughts?\nAdditional info...\nILogger info\nThis says that the config must look something like this:\n```\n`{\n  \"Logging\": {\n    \"LogLevel\": {\n      \"Default\": \"Information\"\n    },\n    \"ApplicationInsights\": {\n      \"LogLevel\": {\n        \"Default\": \"Information\"\n      }\n    }\n  }\n}\n`\n```\nYet, the schema here contradicts that!\nAnd even when I change my config to this, I cannot get anything lower than warnings to appear in Application Insights.",
      "solution": "The answer is here.\nA filter, which is, unfortunately and bizarrely, automatically added, must be explicitly removed. Here's an example:\n```\n`var host = new HostBuilder()\n    .ConfigureFunctionsWorkerDefaults()\n    .ConfigureServices(s =>\n    {\n        s.AddApplicationInsightsTelemetryWorkerService();\n        s.ConfigureFunctionsApplicationInsights();\n        s.AddSingleton();\n        s.Configure(options =>\n        {\n            // The Application Insights SDK adds a default logging filter that instructs ILogger to capture only Warning and more severe logs. Application Insights requires an explicit override.\n            // Log levels can also be configured using appsettings.json. For more information, see https://learn.microsoft.com/en-us/azure/azure-monitor/app/worker-service#ilogger-logs\n            LoggerFilterRule toRemove = options.Rules.FirstOrDefault(rule => rule.ProviderName\n                == \"Microsoft.Extensions.Logging.ApplicationInsights.ApplicationInsightsLoggerProvider\");\n\n            if (toRemove is not null)\n            {\n                options.Rules.Remove(toRemove);\n            }\n        });\n    })\n    .Build();\n`\n```\nThanks to this comment and this answer.",
      "question_score": 25,
      "answer_score": 35,
      "created_at": "2023-11-28T17:25:21",
      "url": "https://stackoverflow.com/questions/77565541/logs-not-appearing-in-application-insights-for-azure-functions-v4-with-net-8"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 70764836,
      "title": "TimeTrigger Exception &quot;Could not create BlobContainerClient for ScheduleMonitor.&quot;",
      "problem": "When I run my azure function with TimeTrigger I have this error:\n\nMicrosoft.Azure.WebJobs.Extensions.Timers.Storage: Could not create BlobContainerClient for ScheduleMonitor.\n\nI use a host builder:\n`public static async Task Main()\n{\n    var host = CreateHostBuilder().Build();\n\n    using (host)\n    {\n        await host.RunAsync();\n    }\n\nstatic IHostBuilder CreateHostBuilder() => new HostBuilder()\n    .UseServiceProviderFactory(new AutofacServiceProviderFactory())\n    .ConfigureFunctionsWorkerDefaults()\n    .ConfigureHostConfiguration(configHost =>\n    {\n        configHost.SetBasePath(Directory.GetCurrentDirectory());\n        configHost.AddJsonFile(\"host.json\", optional: true);\n        configHost.AddEnvironmentVariables();\n    })\n    .ConfigureAppConfiguration((hostContext, configApp) =>\n    {\n        var env = hostContext.HostingEnvironment;\n        configApp.AddJsonFile(\"appsettings.json\", optional: true);\n        configApp.AddJsonFile($\"appsettings.{env.EnvironmentName}.json\", optional: true);\n        configApp.AddEnvironmentVariables();\n        configApp.AddApplicationInsightsSettings(developerMode: !env.IsProduction());\n    })\n    .ConfigureServices((hostContext, services) =>\n    {\n       [...]\n    })\n    .ConfigureContainer(builder =>\n    {\n        builder.RegisterModule();\n    })\n    .ConfigureLogging((hostContext, configLogging) =>\n    {\n        if (hostContext.HostingEnvironment.IsDevelopment())\n        {\n            configLogging.AddConsole();\n            configLogging.AddDebug();\n        }\n    })\n    .UseConsoleLifetime();\n`\nand here is the function:\n`[Function(\"QueueMessage\")]\npublic async Task QueueMessageAsync(\n    [TimerTrigger(\"%MessageQueuerOccurence%\", RunOnStartup = true)] TimerInfo timer\n)\n{\n   [...]\n}\n`\ncsproj:\n`\n        net6.0\n        v4\n        Exe\n    \n\n    \n        \n    \n    \n    \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    \n`\nlocal.settings.json:\n`{\n  \"IsEncrypted\": false,\n  \"Values\": {\n    \"AzureWebJobsStorage\": \"UseDevelopmentStorage=true\",\n    \"MessageQueuerOccurence\": \"0 */15 * * * *\",\n    \"FUNCTIONS_WORKER_RUNTIME\": \"dotnet-isolated\"\n  }\n}\n`\nWhat did I miss?\nNote: link to GitHub: https://github.com/Azure/azure-functions-dotnet-worker/issues/779",
      "solution": "I was having this issue because I didn't have the storage emulator running...\nIt worked once I installed and ran `azurite`, which is the storage emulator that is being maintained (`Azure Storage Emulator` has been discontinued). You can find more information here on how to install it and use it.\nI am using VS Code on a Mac OS, and I found the simplest solution to install `azurite` extension on VS Code. After the installation, I just had to edit the extension settings, in order to set the `location` setting (any folder should work). After that I was able to start `azurite` by running the `Azurite: Start` from the VS Code command palette.\n\nAs per the comments, it might also be necessary to edit the `local.settings.json` file and change the `AzureWebJobsStorage` value to `UseDevelopmentStorage=true`.",
      "question_score": 23,
      "answer_score": 43,
      "created_at": "2022-01-19T04:04:09",
      "url": "https://stackoverflow.com/questions/70764836/timetrigger-exception-could-not-create-blobcontainerclient-for-schedulemonitor"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 72722971,
      "title": "Getting error when upgrading from Serilog.Sinks.ApplicationInsights v3.1 to v4.0",
      "problem": "I have an Azure Function that uses Serilog to write to AppInsights with Serilog AppInsights sink v3.1.\nThe code in `Startup.cs` looks like this\n```\n`Log.Logger = new LoggerConfiguration()\n            .ReadFrom.Configuration(config)\n            .CreateLogger();\n`\n```\nand `appsettings.json`\n```\n`\"Serilog\": {\n    \"Using\": [\n      \"Serilog.Sinks.ApplicationInsights\"\n    ],\n    \"WriteTo\": [\n      {\n        \"Name\": \"ApplicationInsights\",\n        \"Args\": {\n          \"instrumentationKey\": \"...\",\n          \"restrictedToMinimumLevel\": \"Verbose\",\n          \"telemetryConverter\": \"Serilog.Sinks.ApplicationInsights.Sinks.ApplicationInsights.TelemetryConverters.TraceTelemetryConverter, Serilog.Sinks.ApplicationInsights\"\n      }\n    }\n  ],\n  ...\n`\n```\nIt can happily write application logs into AppInsights.\nThe latest Github documentation mentioned the deprecation of telemetry configuration active and future removal support of Instrumentation Key therefore I would like to upgrade the library to version 4.0.\nHowever, when I upgrade to the sink to v4.0, I get this exception:\n\nPlease help.",
      "solution": "So I just spent a good chunk of time debugging this, because I also ran into the issue.  I'll admit I should have look at the git log for the app insights sink, because the offending commit is right here\nhttps://github.com/serilog-contrib/serilog-sinks-applicationinsights/commit/8e4e26a8fdfa12da6ed15afcc94889e5f399ff97#diff-bc9f0e00aaa0aef88484faa764a62f13d26f07bf6c2b6df21cd8d893aa47c2e0\nThey adjusted their namespaces, which causes the Serilog Configuration binding not to be able to find the type `Serilog.Sinks.ApplicationInsights.Sinks.ApplicationInsights.TelemetryConverters.TraceTelemetryConverter` anymore.  Instead the namespace is `Serilog.Sinks.ApplicationInsights.TelemetryConverters.TraceTelemetryConverter` as shown in the commit I linked.\nHope this helps",
      "question_score": 23,
      "answer_score": 52,
      "created_at": "2022-06-23T01:22:48",
      "url": "https://stackoverflow.com/questions/72722971/getting-error-when-upgrading-from-serilog-sinks-applicationinsights-v3-1-to-v4-0"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 71034036,
      "title": "How to setup Serilog with Azure Functions v4 correctly?",
      "problem": "I want to use Serilog in an Azure Function v4 (.net 6) (the logs should be sent to Datadog). For this I have installed the following nuget packages:\n```\n`\n\n`\n```\nBelow is the configuration in the Startup.cs class:\n```\n`public override void Configure(IFunctionsHostBuilder builder)\n{\n  builder.Services.AddHttpClient();\n  \n  //... adding services etc.\n\n  Log.Logger = new LoggerConfiguration()\n    .MinimumLevel.Override(\"Microsoft\", LogEventLevel.Warning)\n    .MinimumLevel.Override(\"Worker\", LogEventLevel.Warning)\n    .MinimumLevel.Override(\"Host\", LogEventLevel.Warning)\n    .MinimumLevel.Override(\"System\", LogEventLevel.Error)\n    .MinimumLevel.Override(\"Function\", LogEventLevel.Error)\n    .MinimumLevel.Override(\"Azure.Storage.Blobs\", LogEventLevel.Error)\n    .MinimumLevel.Override(\"Azure.Core\", LogEventLevel.Error)\n    .Enrich.WithProperty(\"Application\", \"Comatic.KrediScan.AzureFunctions\")\n    .Enrich.FromLogContext()\n    .WriteTo.DatadogLogs(\"XXXXXXXXXXX\", configuration: new DatadogConfiguration() { Url = \"https://http-intake.logs.datadoghq.eu\" }, logLevel:   LogEventLevel.Debug)\n    .WriteTo.Console()\n    .CreateLogger();\n\n  builder.Services.AddSingleton(sp => new SerilogLoggerProvider(Log.Logger, true));\n\n  builder.Services.AddLogging(lb =>\n  {\n    //lb.ClearProviders(); //--> if used nothing works...\n    lb.AddSerilog(Log.Logger, true);\n  });\n`\n```\nBasically logging works, but all log statements are written twice (with a few milliseconds difference, Datadog and Console).\n\nObviously I am doing something fundamentally wrong with the configuration. I don't use appsettings.json, the configuration of Serilog takes place exclusively in the code. I have scoured the entire internet and read just about every article on Serilog and Azure Functions. On Stackoverflow I also read virtually every question about it and tried all the answers. Unfortunately, so far without success.\nSO-Questions for example:\nUse Serilog with Azure Log Stream\nHow do I use Serilog with Azure WebJobs?\nSerilog enricher Dependency Injection with Azure Functions\nhttps://github.com/hgmauri/sample-azure-functions/blob/main/src/Sample.AzureFunctions.DotNet31/Startup.cs\nIs there any example for setting up Serilog with Azure Functions v4 / .net 6?\nThanks a lot for the help!\nMichael Hachen",
      "solution": "Got it! After replacing all `ILogger` with `ILogger` and removing the line `builder.Services.AddSingleton(sp => new SerilogLoggerProvider(Log.Logger, true));` everything worked as expected.\nStartup.cs\n```\n`Log.Logger = new LoggerConfiguration()\n          .MinimumLevel.Override(\"Microsoft\", LogEventLevel.Warning)\n          .MinimumLevel.Override(\"Worker\", LogEventLevel.Warning)\n          .MinimumLevel.Override(\"Host\", LogEventLevel.Warning)\n          .MinimumLevel.Override(\"System\", LogEventLevel.Error)\n          .MinimumLevel.Override(\"Function\", LogEventLevel.Error)\n          .MinimumLevel.Override(\"Azure.Storage.Blobs\", LogEventLevel.Error)\n          .MinimumLevel.Override(\"Azure.Core\", LogEventLevel.Error)\n          .Enrich.WithProperty(\"Application\", $\"xxxxx.AzureFunctions.{builder.GetContext().EnvironmentName}\")\n          .Enrich.FromLogContext()\n          .Enrich.WithExceptionDetails(new DestructuringOptionsBuilder()\n            .WithDefaultDestructurers()\n            .WithDestructurers(new[] { new SqlExceptionDestructurer() }))\n          .WriteTo.Seq(builder.GetContext().EnvironmentName.Equals(\"Development\", StringComparison.OrdinalIgnoreCase) ? \"http://localhost:5341/\" : \"https://xxxxxx.xx:5341/\", LogEventLevel.Verbose)\n          .WriteTo.Console(theme: SystemConsoleTheme.Literate)\n          .CreateLogger();\n      \n      builder.Services.AddLogging(lb =>\n      {\n        lb.AddSerilog(Log.Logger, true);\n      });\n`\n```",
      "question_score": 21,
      "answer_score": 13,
      "created_at": "2022-02-08T13:36:23",
      "url": "https://stackoverflow.com/questions/71034036/how-to-setup-serilog-with-azure-functions-v4-correctly"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 79099831,
      "title": "Find/Set Azure Functions Core Tools version Visual Studio use",
      "problem": "Got below error while trying to run the Azure Function in VS2022 locally.\n```\n`This version of the Azure Functions Core Tools requires your project to reference version 4.5.0 or later of Microsoft.NET.Sdk.Functions. \n`\n```\nIt can be fixed by updating the version of Microsoft.NET.Sdk.Functions, however that's also mean I will need to spend quite some times to test as code coverage is not good enough.\nAs a short term solution, would like to know how can I find out the Azure Functions Core Tools version VS is using, as well as how to rollback to the pervious version?",
      "solution": "This error appeared with visual studio 2022 v17.12.0\nafter this update VS installed and forcing the Azure Functions Tools v4.0.6517 by default and based on Microsoft documentations\n\nSo we have to solution to solve this issue, the first one is to Update Microsoft.NET.Sdk.Functions nuget package to be 4.5.0 and this will solve the issue,\nbut what if you don't want to update this package at all, then you will need to downgrade the version of Azure Core Tools, so the following steps explains how to do it\n\nClose the VS\nDo manual installation for Core Tools v4.0.6280 (older version)\nCopy the content of folder --> C:\\ProgramFiles\\Microsoft\\Azure Functions Core Tools\nPaste it to --> C:\\Users\\{your username}\\AppData\\Local\\AzureFunctionsTools\\Releases\\4.104.0\\cli_x64\nRestart your PC or Laptop\nOpen the VS again and try to run any azure function, you will notice that the console is now showing the older version of the Core Tools.\n\nI hope this answer may help someone.",
      "question_score": 16,
      "answer_score": 1,
      "created_at": "2024-10-17T23:07:43",
      "url": "https://stackoverflow.com/questions/79099831/find-set-azure-functions-core-tools-version-visual-studio-use"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 78005859,
      "title": "Azure Functions - .NET 8 isolated - logging no longer showing up in Azure Portal Invocation Traces",
      "problem": "When writing Azure Functions in C#, I find it very useful that I am able to output some selected messages to a logger, and that those messages show up in the \"Invocation Traces\" in the Azure Portal:\nThis has worked just fine, from the Azure Function v1 up to those written against .NET 6.0 Isolated.\n\nBut now, I've created a few more new functions, using .NET 8.0 Isolated, and now it seems, outputting those log/trace messages no longer works....\n\nWhat has changed so fundamentally that my logging no longer shows up in the Azure Portal?\nRight now, I'm injecting the `ILoggerFactory` into my Azure Function class and creating an `ILogger` from it (where `T` is the type of my function class).\n```\n`public class MyAzureFunction\n{\n    private readonly IConfiguration _configuration;\n    private readonly ILoggerFactory _factory;\n    private readonly ILogger _logger;\n\n    public MyAzureFunction(IConfiguration configuration, ILoggerFactory factory)\n    {\n        _configuration = configuration;\n        _factory = factory;\n        _logger = factory.CreateLogger();\n    }\n    \n    // Actual Azure Function code follows here\n}\n`\n```\nI also tried to use the `FunctionContext` as an injectable parameter to my Azure Function method that gets triggered (by a HTTP call, or a timer) and create the `ILogger` from that:\n```\n`[Function(\"MyAzureFunction\")]\npublic async Task Run([HttpTrigger(AuthorizationLevel.Function, \"post\")] HttpRequest req, \n                                     FunctionContext executionContext)\n{\n    ILogger _logger = executionContext.GetLogger(nameof(MyAzureFunction));\n    \n    _logger.LogInformation(\"My Azure Function was HTTP triggered\");\n    \n    // rest of the function code\n}\n`\n```\nNeither of these approaches seems to work - none of my own custom messages, output by `_logger.LogInformation`, actually show up in the Azure Portal \"Invocation Traces\" display.\nI've also played around with various settings in the `_host.json` - but to no avail - and not knowing exactly where the problem lies, and how to fix it, this all seems like a bit of a messy \"trial & error\" without really understanding what the issue is, and how to solve it.\nCan anyone enlighten me? What am I missing? What has changed with .NET 8.0 support in Azure Functions? How can I get my own custom messages to show up in the Azure Invocation Traces again?",
      "solution": "You should call `AddApplicationInsightsTelemetryWorkerService()` and `ConfigureFunctionsApplicationInsights()` during service configuration in your `Program.cs` file:\n```\n`using Microsoft.Azure.Functions.Worker;\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Hosting;\n    \nvar host = new HostBuilder()\n    .ConfigureFunctionsWorkerDefaults()\n    .ConfigureServices(services => {\n        services.AddApplicationInsightsTelemetryWorkerService();\n        services.ConfigureFunctionsApplicationInsights();\n    })\n    .Build();\n\nhost.Run();\n`\n```\nAlso note that by default, the Application Insights SDK adds a logging filter that instructs the logger to capture only warnings and more severe logs. If you want to disable this behavior, remove the filter rule as part of service configuration:\n```\n`var host = new HostBuilder()\n    .ConfigureFunctionsWorkerDefaults()\n    .ConfigureServices(services => {\n        services.AddApplicationInsightsTelemetryWorkerService();\n        services.ConfigureFunctionsApplicationInsights();\n    })\n    .ConfigureLogging(logging =>\n    {\n        logging.Services.Configure(options =>\n        {\n            LoggerFilterRule defaultRule = options.Rules.FirstOrDefault(rule => rule.ProviderName\n                == \"Microsoft.Extensions.Logging.ApplicationInsights.ApplicationInsightsLoggerProvider\");\n            if (defaultRule is not null)\n            {\n                options.Rules.Remove(defaultRule);\n            }\n        });\n    })\n    .Build();\n\nhost.Run();\n`\n```",
      "question_score": 15,
      "answer_score": 22,
      "created_at": "2024-02-16T08:59:47",
      "url": "https://stackoverflow.com/questions/78005859/azure-functions-net-8-isolated-logging-no-longer-showing-up-in-azure-portal"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 74427826,
      "title": "Specifying JsonSerializerOptions in .NET 6 isolated Azure Function",
      "problem": "I'm trying to call a Web API from code in an Azure Function that I've just ported to .NET 6 (isolated hosting model). I took the chance of the migration to get rid of the RestSharp and Json.NET dependencies, now only just using `HttpClient` and `System.Text.Json` for handling the HTTP calls and JSON stuff.\nI did try to use this code which seemed like the perfect combo:\n```\n`Project project = await _httpClient.GetFromJsonAsync(someUrl);\n\nif (project != null)\n{\n    HttpResponseData callResponse = req.CreateResponse(HttpStatusCode.OK);\n    \n    await callResponse.WriteAsJsonAsync(project);\n    \n    return callResponse;\n}\n`\n```\nThe call works fine - I get back my `Project` object without any hitch.\nBut unfortunately, with this code, I cannot seem to influence the way the JSON in the response gets rendered - e.g. in my case, `null` values are returned (which I want to avoid), and all property names are capitalized (\"Institute\", instead of \"institute\", \"LeadLanguage\" instead of \"leadLanguage\").\nNo problem - just use a `JsonSerializerOptions` object and define what you want, I thought. Sure, I can create such an object - but where would I plug that in??\n`WriteAsJsonAsync` doesn't seem to support any serializer options as parameter (why??), and I couldn't find a way to globally define my `JsonSerializerOptions` (since everything I find seems to be based on the `services.AddControllers().AddJsonOptions()` method - which I cannot use since my Azure Function doesn't have the `AddControllers` part in its startup code).\nI have managed to get the results I want by doing this:\n```\n`if (project != null)\n{\n    HttpResponseData callResponse = req.CreateResponse(HttpStatusCode.OK);\n    \n    callResponse.Headers.Add(\"Content-Type\", \"application/json\");\n    string jsonResponse = JsonSerializer.Serialize(project, settings);\n    await callResponse.WriteStringAsync(jsonResponse, Encoding.UTF8);\n\n    return callResponse;\n}\n`\n```\nbut that seems a bit convoluted and \"low-level\" - manually converting the result object into string, having to manually set the `Content-Type` and all ....\nIs there really no way in an Azure Function (.NET 6 isolated hosting model) to globally specify `JsonSerializerOptions` - or call `WriteAsJsonAsync` with a specific serializer options object?",
      "solution": "And 10 seconds after I posted the question - of course! - I ran across the way to do it with an Azure Function.\nSomething like this:\n```\n`var host = new HostBuilder()\n    .ConfigureFunctionsWorkerDefaults()\n    .ConfigureServices(s =>\n    {\n        s.AddHttpClient();\n        // define your global custom JSON serializer options\n        s.Configure(options =>\n        {\n            options.AllowTrailingCommas = true;\n            options.DefaultIgnoreCondition = JsonIgnoreCondition.WhenWritingNull;\n            options.PropertyNamingPolicy = JsonNamingPolicy.CamelCase;\n            options.PropertyNameCaseInsensitive = true;\n        });\n`\n```\nHope that might help someone else down the line!",
      "question_score": 13,
      "answer_score": 34,
      "created_at": "2022-11-14T07:50:12",
      "url": "https://stackoverflow.com/questions/74427826/specifying-jsonserializeroptions-in-net-6-isolated-azure-function"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 66084145,
      "title": "Azure Functions, Could not load file or assembly",
      "problem": "When using the NuGet.Protocol NuGet Package in Azure Functions, I get the following error: `System.Private.CoreLib: Could not load file or assembly`.\n`[4/18/2020 8:51:43 AM] The 'Function1' function is in error: Unable to load one or more of the requested types.\n[4/18/2020 8:51:43 AM] Could not load file or assembly 'NuGet.Protocol, Version=5.5.1.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35'. The system cannot find the file specified.\n[4/18/2020 8:51:43 AM] Microsoft.Azure.WebJobs.Host: Error indexing method 'Function1'. System.Private.CoreLib: Could not load file or assembly 'NuGet.Protocol, Version=5.5.1.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35'. The system cannot find the file specified.\n`\nI confirmed that the `NuGet.Protocol.dll` file exists in the `bin` output.\n\nWhy can Azure Functions not find `NuGet.Protocol.dll`?",
      "solution": "This is a known-problem with Azure Functions, introduced in `Microsoft.NET.Sdk.Functions` v3.0.4, and still present today (v3.0.11).\nTo prevent Azure Functions from removing this library, add the following to your CSPROJ:\n`\n    true\n\n`\nHere is an example of how I use it in my GitTrends app:\nhttps://github.com/brminnick/GitTrends/blob/22d748fc72452dcd39bb3866e30f339827ded3dd/GitTrends.Functions/GitTrends.Functions.csproj#L10",
      "question_score": 13,
      "answer_score": 36,
      "created_at": "2021-02-07T03:57:50",
      "url": "https://stackoverflow.com/questions/66084145/azure-functions-could-not-load-file-or-assembly"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 67516951,
      "title": "Disable Entity Framework logging in Azure Function",
      "problem": "I have an Azure Function in .net5 (a.k.a. `dotnet-isolated`) and I've added Entity Framework like this\n```\n`services.AddDbContext(options =>\n{\n    options.UseSqlServer(context.Configuration[...], builder =>\n    {\n        builder.EnableRetryOnFailure();\n    });\n});\n`\n```\nWhen I run the function I see the DB queries from EF in the console (info level judging by the color).\n\nHow can I disable them? I tried obvious options in my `host.json`:\n```\n`\"logging\": {\n    \"logLevel\": {\n        \"Microsoft.EntityFrameworkCore\": \"Warning\",\n    }\n}\n`\n```\nand\n```\n`\"logging\": {\n    \"logLevel\": {\n        \"default\": \"Information\",\n        \"Microsoft.EntityFrameworkCore\": \"Warning\",\n        \"Microsoft.EntityFrameworkCore.Database\": \"Warning\",\n        \"Microsoft.EntityFrameworkCore.Query\": \"Warning\"\n    }\n}\n`\n```\nor even\n```\n`\"logging\": {\n    \"logLevel\": {\n        \"Microsoft\": \"Warning\",\n    }\n}\n`\n```\nbut it didn't help. The only option which worked was\n```\n`\"logging\": {\n    \"logLevel\": {\n        \"default\": \"Warning\",\n    }\n}\n`\n```\nAm I missing something?",
      "solution": "Found a way. That's a bit strange though and I still wanna understand how it works and why it's done this way. Anyways, from AppInsights logs I found out that EF logs are written under the `Function..User` category. (turns out that a standard EF category is somehow overwritten by the functions runtime or so?).\nThat means that I can impact on the overall log level of a specific function by\n```\n`    \"logging\": {\n        \"logLevel\": {\n            \"Function.MyFunc1.User\": \"Debug\",\n            \"Function.MyFunc2.User\": \"Warning\"\n        }\n    }\n\n`\n```\nin the `host.json`. It can be helpful but it doesn't solve my problem.\nIf however I now add a filter in the `Program.cs` like this:\n```\n`var host = new HostBuilder()\n  .ConfigureFunctionsWorkerDefaults()\n  ...               \n  .ConfigureLogging(builder =>\n  {\n    builder.AddFilter(\"Microsoft.EntityFrameworkCore\", LogLevel.Warning);\n  })\n  ...\n`\n```\nthe EF info logs are gone.",
      "question_score": 12,
      "answer_score": 18,
      "created_at": "2021-05-13T11:31:50",
      "url": "https://stackoverflow.com/questions/67516951/disable-entity-framework-logging-in-azure-function"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 67526631,
      "title": "How can I debug Azure Functions using .NET 5 (isolated process) in Visual Studio?",
      "problem": "I've recently migrated from .NET Core 3.1 to .NET 5.0 (using isolated/out-of-process runtime) for an Azure Function project in C#. Everything is working as expected. However, whenever I debug, none of my breakpoints hits. Why can't I debug my Azure Function app now, but I used to be able to?",
      "solution": "If you are using Visual Studio Version 16.10 or later, debugging in Visual Studio is straightforward.\nThe updated steps from Microsoft are as follows:\n\nVisual Studio integrates with Azure Functions Core Tools so that you\ncan test your functions locally using the full Azure Functions\nruntime.\n\nTo run your function, press F5 in Visual Studio. You might need to enable a firewall exception so that the tools can handle HTTP\nrequests. Authorization levels are never enforced when you run a\nfunction locally.\n\nCopy the URL of your function from the Azure Functions runtime output and run the request. A welcome to Functions message is\ndisplayed when the function runs successfully and logs are written to\nthe runtime output.\n\nTo stop debugging, press Shift+F5 in Visual Studio.\n\nAfter you've verified that the function runs correctly on your local\ncomputer, it's time to publish the project to Azure.\n\nThis below section only applies if you are using Visual Studio Version 16.9 or earlier. I highly recommend upgrading Visual Studio instead of using this \"PITA\" method.\n(Please see the answer from Andrii for an alternative solution)\nAfter  doing a deal of research online, I've learned that the isolated process used by .NET 5 for Azure Functions doesn't support debugging by default. To do so in Visual Studio, you need to follow these steps (link used to be valid, but has since been updated).\n\nOpen your solution in Visual Studio\nOpen PowerShell within Visual Studio (View -> Terminal, or Ctrl-`)\nNavigate to your project `cd MyProject`\nStart the function with debugging enabled `func start \u2013-dotnet-isolated-debug`\nAt this point, you should see a PID printed in the terminal output that looks similar to the following\n\n```\n` Functions:\n     HttpExample: [GET,POST] http://localhost:7071/api/HttpExample\n For detailed output, run func with --verbose flag.\n [2021-03-09T08:41:41.904Z] Azure Functions .NET Worker (PID: 81720) initialized in debug mode. Waiting for debugger to attach...\n`\n```\n\nOpen the Attach Process (Open -> Debug) window, and select the PID found in the console output\nAt this point, the breakpoints are now valid and will be hit.",
      "question_score": 11,
      "answer_score": 10,
      "created_at": "2021-05-13T23:48:29",
      "url": "https://stackoverflow.com/questions/67526631/how-can-i-debug-azure-functions-using-net-5-isolated-process-in-visual-studio"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 74470489,
      "title": "System.IO.FileNotFoundException: Could not load file or assembly &#39;Microsoft.Extensions.Options&#39;",
      "problem": "I've been getting this error message when I try to run my Azure function v4.\n`System.IO.FileNotFoundException: 'Could not load file or assembly 'Microsoft.Extensions.Options, Version=7.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified.'`\nThis used to work like a week ago, and now it's throwing this error at runtime. Latest changes I did was to update EF Core to version 7. But I guess that's not relevant because that's in a different project, so not related to the function project.\nThese are the package references in my function project:\n```\n`\n    net6.0\n    v4\n  \n  \n    \n    \n    \n    \n    \n  \n`\n```\nHas anyone else got it or any idea how to resolve it?\nTried removing all the Nuget packages and installing them. That didn't work.\nI can see the Microsoft.Extensions.Options.dll (v7) in the debug folder as well. Not sure why the runtime complains about it.\nI recently updated to VS 2022 Version 17.4.1. Maybe that's the issue here?",
      "solution": "I have reproduced in my environment,I have observed that the same packages you have given is working fine in .NET 6 Azure functions project\n\nAnd it is working fine in .NET 7 isolated when I remove `Microsoft.NET.Sdk.Functions` (last package).\n\nCould not load file or assembly 'Microsoft.Extensions.Configuration.Abstractions, Version=7.0.0.0, Culture=neutral, PublicKeyToken=adb9793829ddae60'. The system cannot find the file specified\n\nAs discussed in comments Try to degrade\n`Microsoft.Extensions.Configuration.Abstractions` nuget package to Version=\"6.0.0\". Try to revert back to older versions",
      "question_score": 11,
      "answer_score": 9,
      "created_at": "2022-11-17T06:15:39",
      "url": "https://stackoverflow.com/questions/74470489/system-io-filenotfoundexception-could-not-load-file-or-assembly-microsoft-exte"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 72377636,
      "title": "Runing a functions project locally",
      "problem": "I am truing to get a existing .Net functions app runing locally. It has been developed on Windows with Visual Studio, but I am on a Mac (M1 CPU) and using VS Code. I am pretty new to .Net I am struggeling to figure out what needs to be configured to get the project running.\nI have added a launch.json:\n```\n`{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Attach to .NET Functions\",\n            \"type\": \"coreclr\",\n            \"request\": \"attach\",\n            \"processId\": \"${command:azureFunctions.pickProcess}\"\n        }\n    ]\n}`\n```\nand a local.settings.json:\n```\n`{\n    \"IsEncrypted\": false,\n    \"Values\": {\n        \"AzureWebJobsStorage\": \"UseDevelopmentStorage=true\",\n        \"FUNCTIONS_WORKER_RUNTIME\": \"dotnet\"\n    }\n}`\n```\nand there is a tasks.json already in the project:\n```\n`{\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"clean (functions)\",\n            \"command\": \"dotnet\",\n            \"args\": [\n                \"clean\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"type\": \"process\",\n            \"problemMatcher\": \"$msCompile\",\n            \"options\": {\n                \"cwd\": \"${workspaceFolder}/Naboor.Statistics\"\n            }\n        },\n        {\n            \"label\": \"build (functions)\",\n            \"command\": \"dotnet\",\n            \"args\": [\n                \"build\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"type\": \"process\",\n            \"dependsOn\": \"clean (functions)\",\n            \"group\": {\n                \"kind\": \"build\",\n                \"isDefault\": true\n            },\n            \"problemMatcher\": \"$msCompile\",\n            \"options\": {\n                \"cwd\": \"${workspaceFolder}/Naboor.Statistics\"\n            }\n        },\n        {\n            \"label\": \"clean release (functions)\",\n            \"command\": \"dotnet\",\n            \"args\": [\n                \"clean\",\n                \"--configuration\",\n                \"Release\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"type\": \"process\",\n            \"problemMatcher\": \"$msCompile\",\n            \"options\": {\n                \"cwd\": \"${workspaceFolder}/Naboor.Statistics\"\n            }\n        },\n        {\n            \"label\": \"publish (functions)\",\n            \"command\": \"dotnet\",\n            \"args\": [\n                \"publish\",\n                \"--configuration\",\n                \"Release\",\n                \"/property:GenerateFullPaths=true\",\n                \"/consoleloggerparameters:NoSummary\"\n            ],\n            \"type\": \"process\",\n            \"dependsOn\": \"clean release (functions)\",\n            \"problemMatcher\": \"$msCompile\",\n            \"options\": {\n                \"cwd\": \"${workspaceFolder}/Naboor.Statistics\"\n            }\n        },\n        {\n            \"type\": \"func\",\n            \"dependsOn\": \"build (functions)\",\n            \"options\": {\n                \"cwd\": \"${workspaceFolder}/Naboor.Statistics/bin/Debug/net6.0\"\n            },\n            \"command\": \"host start\",\n            \"isBackground\": true,\n            \"problemMatcher\": \"$func-dotnet-watch\"\n        }\n    ]\n}`\n```\nShould I be able to run this project from the commandline somehow? Do I need to point to a task in the tasks.json?\nIf I run it with F5 in VS Code, I get this error:\n```\n`Executing task: func host start\n\nCan't determine project language from files. Please use one of [--csharp, --javascript, --typescript, --java, --python, --powershell, --custom]\nCan't determine project language from files. Please use one of [--csharp, --javascript, --typescript, --java, --python, --powershell, --custom]\nCan't determine project language from files. Please use one of [--csharp, --javascript, --typescript, --java, --python, --powershell, --custom]\n\nAzure Functions Core Tools\nCore Tools Version:       4.0.4544 Commit hash: N/A  (64-bit)\nFunction Runtime Version: 4.3.2.18186\n\nCan't determine project language from files. Please use one of [--csharp, --javascript, --typescript, --java, --python, --powershell, --custom]\nCan't determine project language from files. Please use one of [--csharp, --javascript, --typescript, --java, --python, --powershell, --custom]\n[2022-05-25T12:24:12.674Z] Failed to initialize worker provider for: /opt/homebrew/Cellar/azure-functions-core-tools@4/4.0.4544/workers/python\n[2022-05-25T12:24:12.682Z] Microsoft.Azure.WebJobs.Script: Architecture Arm64 is not supported for language python.\n[2022-05-25T12:24:12.991Z] Failed to initialize worker provider for: /opt/homebrew/Cellar/azure-functions-core-tools@4/4.0.4544/workers/python\n[2022-05-25T12:24:12.991Z] Microsoft.Azure.WebJobs.Script: Architecture Arm64 is not supported for language python.\n[2022-05-25T12:24:13.118Z] A host error has occurred during startup operation 'a0f1f8a3-92f6-434a-9ab1-17055f0828f4'.\n[2022-05-25T12:24:13.118Z] Microsoft.Azure.WebJobs.Script.WebHost: Secret initialization from Blob storage failed due to missing both an Azure Storage connection string and a SAS connection uri. For Blob Storage, please provide at least one of these. If you intend to use files for secrets, add an App Setting key 'AzureWebJobsSecretStorageType' with value 'Files'.\nValue cannot be null. (Parameter 'provider')\nThe terminal process \"/opt/homebrew/bin/zsh '-c', 'func host start'\" terminated with exit code: 1.`\n```\nI thought that was what the ```\n`\"FUNCTIONS_WORKER_RUNTIME\": \"dotnet\"`\n``` part of local.settings.json was for?\nHow can this be resolved?",
      "solution": "We have tried the same in our local and able to run it successfully.\nI believe that you are just missing the configuration in your local .\nHere are the steps :-\n\nMake sure the `Azure function runtime` , `Dotnet sdk`, storage emulator has been installed in your local . If not you can download from VS CODE extension called `AZURITE` instead of emulator as it has been deprecated.\n\nIn VS CODE install extensions Azure where all the tools will be available , c# (Any language that you want to prefer) & Azure function being installed.\n\n.\n\nIf you want to create new project click f1> Select create new azure function . As you have existing file there is no need to point `task.json` file once the aforementioned has been done test your project by running :\n\n. `dotnet build` once build succeed run ,\n. `func host start` (If you have existing/new project don't run `func init` as it will create one more `.csproj` file and then it may occur to fail)\nSNAPSHOTS FOR REFERENCE:-\n\nSTORAGE EMULATOR STARTED IN LOCAL:-\n\nFor more information please refer this MICROSOFT DOCUMENTATION| STEP BY STEP TUTORIAL TO CREATE AZURE FUNCTION IN VS CODE.\nAlternatively, If you want to learn using Visual studio Create Azure function on Macos please refer this MICROSOFT DOCUMENTATION.",
      "question_score": 10,
      "answer_score": 1,
      "created_at": "2022-05-25T14:26:31",
      "url": "https://stackoverflow.com/questions/72377636/runing-a-functions-project-locally"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 70544301,
      "title": "Getting Cannot access a disposed object. Object name: &#39;SocketsHttpHandler&#39; exception in .Net 6 Application",
      "problem": "In one of my Azure Function app(.Net 6 isolated process) and I am making some http requests with a client certificate. I'm registering my services in the Program.cs like this,\n```\n`var handler = new HttpClientHandler();\nhandler.ClientCertificates.Add(clientCertificate);\n\nservices.AddHttpClient().Configure(\n               \"myClient\", options =>\n                   options.HttpMessageHandlerBuilderActions.Add(builder =>\n                       builder.PrimaryHandler = handler));\n\nservices.AddTransient(provider =>\n           new MyCustomClient(provider.GetService(),\n               cutomParameter1, cutomParameter2));\n\nservices.AddSingleton();\n`\n```\nAnd injecting MyCustomClient in MyCustomService constructor\n```\n`private readonly IMyCustomClient _myCustomClient;\n\npublic PlatformEventManagementService(IMyCustomClient myCustomClient)\n{\n    _myCustomClient = myCustomClient;\n}\n`\n```\n`var result = await _myCustomClient.GetResponse();`\nIt works fine for some time and getting the below exception after sending many requests.\n`Cannot access a disposed object. Object name: 'SocketsHttpHandler'.`",
      "solution": "You are supplying the factory with a single instance of `HttpClientHandler` to use in all clients. Once the default HandlerLifetime has elapsed (2 minutes) it will be marked for disposal, with the actual disposal occurring after all existing `HttpClient`s referencing it are disposed.\nAll clients created after the handler is marked continue to be supplied the soon-to-be disposed handler, leaving them in an invalid state once the disposal is actioned.\nTo fix this, the factory should be configured to create a new handler for each client. You may wish to use the simpler syntax shown in the MS documentation.\n`// Existing syntax\nservices.AddHttpClient().Configure(\n                \"myClient\", options =>\n                    options.HttpMessageHandlerBuilderActions.Add(builder =>\n                    {\n                        var handler = new HttpClientHandler();\n                        handler.ClientCertificates.Add(clientCertificate);\n                        builder.PrimaryHandler = handler;\n                    }));\n\n// MS extension method syntax\nservices\n    .AddHttpClient(\"myClient\")\n    // Lambda could be static if clientCertificate can be retrieved from static scope\n    .ConfigurePrimaryHttpMessageHandler(_ =>\n    {\n        var handler = new HttpClientHandler();\n        handler.ClientCertificates.Add(clientCertificate);\n        return handler;\n    });\n`",
      "question_score": 9,
      "answer_score": 20,
      "created_at": "2021-12-31T18:08:14",
      "url": "https://stackoverflow.com/questions/70544301/getting-cannot-access-a-disposed-object-object-name-socketshttphandler-excep"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 67788636,
      "title": "How to embed Image inline in Email Body using Microsoft Graph",
      "problem": "I am using a Function app to trigger a mail, using MS Graph API, the mail body text is getting triggered properly but facing issue in rendering the header and footer image shown in picture. How to solve this issue in the body level.\n\nBelow are the references of the above images in HTML/Blob file\n```\n`  &lt;img src=cid:Header.jpg&gt;\n    &lt;img src=cid:footer.png&gt;\n    Header.jpg, footer.png\n`\n```\nCode used in rendering the body.\n```\n`             var mailContent = new Message\n                {\n                    Subject = em.Subject,\n                    Body = new ItemBody\n                    {\n                        ContentType = BodyType.Html,\n                        Content = m.Body,\n                        ODataType = null\n                    },\n                    ToRecipients = toEmails,\n                    CcRecipients = ccEmails,\n                    ODataType = null\n                };    \n`\n```\nEDIT:\nCurrently facing bad request in Function App after this changes. I am trying to resolve that. If you see any discrepancy in this below code feel free to comment.\n```\n`            var imagePath = @\"\";\n            var imageID = \"Header.jpg\";//file name\n            byte[] imageArray = System.IO.File.ReadAllBytes(imagePath);\n            var imagePath2 = @\";\n            var imageID2 = \"footer.png\";\n            byte[] imageArray2 =System.IO.File.ReadAllBytes(imagePath2);\n\n            \n            var mContent = new Message\n            {\n                Subject = t.Subject,//parsing from the template\n                Body = new ItemBody\n                {\n                    ContentType = BodyType.Html,\n                    Content = m.Body,\n                    ODataType = \"#microsoft.graph.fileAttachment\"\n                },\n                ToRecipients = toEmails,\n                CcRecipients = ccEmails,\n                ODataType = \"#microsoft.graph.fileAttachment\",\n                HasAttachments = true,\n                Attachments = new MessageAttachmentsCollectionPage()\n                    {\n                            new FileAttachment\n                        {\n                                \n                                ContentBytes= imageArray,\n                                ContentType = \"image/jpeg\",\n                                ContentId= imageID,\n                                IsInline=true,\n                                Name = \"theHead\",\n                               \n                        },\n                            new FileAttachment\n                            {\n                                \n                                ContentBytes= imageArray2,\n                                ContentType = \"image/png\",\n                                ContentId= imageID2,\n                                IsInline=true,\n                                Name = \"thefoot\",\n                            }\n                    }\n            };\n`\n```",
      "solution": "I write a demo for you , try the simple console app below:\n```\n`using Microsoft.Graph;\nusing Microsoft.Graph.Auth;\nusing Microsoft.Identity.Client;\nusing System;\nusing System.Collections.Generic;\n\nnamespace sendEmails\n{\n    class Program\n    {\n        static void Main(string[] args)\n        {\n            var appID = \"\";\n            var appSec = \"\";\n            var tenantID = \"\";\n            \n\n            IConfidentialClientApplication confidentialClientApplication = ConfidentialClientApplicationBuilder\n                .Create(appID)\n                .WithTenantId(tenantID)\n                .WithClientSecret(appSec)\n                .Build();\n\n            ClientCredentialProvider authenticationProvider = new ClientCredentialProvider(confidentialClientApplication);\n\n            GraphServiceClient graphServiceClient = new GraphServiceClient(authenticationProvider);\n\n            var imagePath = @\"\";\n            var imageID = \"image1\";\n            \n\n            byte[] imageArray = System.IO.File.ReadAllBytes(imagePath);\n\n            var body = \"this is superman  \";\n            var attachments = new MessageAttachmentsCollectionPage()\n            {\n                new FileAttachment{\n                    ContentType= \"image/jpeg\",\n                    ContentBytes = imageArray,\n                    ContentId = imageID,\n                    Name= \"test-image\"\n                }\n            };\n            \n            var message = new Message\n            {\n                Subject = \"TEST SENDING IMAGE \",\n                Body = new ItemBody\n                {\n                    ContentType = BodyType.Html,\n                    Content = body,\n                    ODataType = null\n                },\n                ToRecipients = new List()\n                {\n                    new Recipient\n                    {\n                        EmailAddress = new EmailAddress\n                        {\n                            Address = \"\"\n                        }\n                    }\n                },\n                Attachments = attachments\n\n            };\n            \n            graphServiceClient.Users[\"\"].SendMail(message, false).Request().PostAsync().GetAwaiter().GetResult();\n            Console.WriteLine(\"ok\");\n        }\n    }\n}\n`\n```\nResult :",
      "question_score": 9,
      "answer_score": 11,
      "created_at": "2021-06-01T14:10:34",
      "url": "https://stackoverflow.com/questions/67788636/how-to-embed-image-inline-in-email-body-using-microsoft-graph"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 70034969,
      "title": "Azure Function Can&#39;t bind parameter &#39;messageReceiver&#39; to type &#39;Microsoft.Azure.ServiceBus.Core.MessageReceiver&#39;",
      "problem": "Having upgraded to Microsoft.Azure.ServiceBus v5.2.0 MessageReceiver no longer works.\n```\n`MessageReceiver messageReceiver\n`\n```\n\nMicrosoft.Azure.WebJobs.Host: Error indexing method\n'BrunelWMSServiceBus'. Microsoft.Azure.WebJobs.Host: Can't bind\nparameter 'messageReceiver' to type\n'Microsoft.Azure.ServiceBus.Core.MessageReceiver'.\n\n`MessageReceiver` is still supported according to the doc but it no longer works in the run-time. I've seen references to parameter naming but `messageReceiver` is apparently ok.\n```\n`ServiceBusMessageActions messageActions\n`\n```\nworks but MUST be called `messageActions` or it will fail to bind too. Just wondering whether to stop using `MessageReceiver` and use `ServiceBusMessageActions` instead.",
      "solution": "It's not added to the specs yet, but obviously IMessageReceiver shouldn't be used any longer as it belongs to Microsoft.Azure.ServiceBus library which is deprecated and not referenced by Microsoft.Azure.WebJobs.Extensions.ServiceBus SDK anymore. So ServiceBusMessageActions messageActions parameter is definitely the way to go now.\nhttps://github.com/Azure/azure-sdk-for-net/tree/main/sdk/servicebus/Microsoft.Azure.WebJobs.Extensions.ServiceBus#message-settlement",
      "question_score": 9,
      "answer_score": 9,
      "created_at": "2021-11-19T13:37:35",
      "url": "https://stackoverflow.com/questions/70034969/azure-function-cant-bind-parameter-messagereceiver-to-type-microsoft-azure-s"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 76385900,
      "title": "Azure Functions ( Http Triggered) started throwing TaskCancelled Exception randomly",
      "problem": "How do I go about troubleshooting this?\n\nI have a couple of Azure functions that use the following trigger\nsignature [HttpTrigger(AuthorizationLevel.Anonymous, \"get\", \"post\").\n\nThe functions are running on a consumption plan.\n\nThey get triggered 2-3 times a day.\n\nThe function intermittently fails to trigger with the following exception:\nDiagnostic from Azure shows that the task was canceled before the worker process was called.\n\n```\n`public class AlpacaSample \n{\n    private ILogger logger;\n\n    public AlpacaSample(ILoggerFactory loggerFactory)\n    {\n        this.logger = loggerFactory.CreateLogger();\n    }\n\n    [Function(\"AlpacaSample\")]\n    public async Task Run([HttpTrigger(AuthorizationLevel.Anonymous, \"get\", \"post\")] HttpRequestData req)\n    {\n        try\n        {\n            this.requestData = req;\n            string requestBody = await new StreamReader(req.Body).ReadToEndAsync();\n            var message = $\"Received a trigger {requestBody}\";\n            this.logger.LogInformation(message);\n\n            // Business logic removed for brevity \n\n            return await this.CreateStringResponse(req, \"All Good\");\n        }\n\n        catch (Exception ex)\n        {\n            string responseMessage =\n                   $\"Error occurrend while handling the message. Error: {ex.Message} \\n {ex}\";\n            this.logger.LogError(responseMessage);\n            return await this.CreateStringResponse(req, responseMessage);\n        }\n\n    }\n\n    private async Task CreateStringResponse(HttpRequestData req, string msg, HttpStatusCode httpStatusCode = HttpStatusCode.OK)\n    {\n        var res = HttpResponseData.CreateResponse(req);\n        res.StatusCode = httpStatusCode;\n        await res.WriteStringAsync(msg);\n        return res;\n    }\n}\n`\n```\nFull Call stack :\n```\n`   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+d__26.MoveNext (Microsoft.Azure.WebJobs.Host, Version=3.0.37.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35: D:\\a\\_work\\1\\s\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:352)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+d__18.MoveNext (Microsoft.Azure.WebJobs.Host, Version=3.0.37.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35: D:\\a\\_work\\1\\s\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:108)\nInner exception Microsoft.Azure.WebJobs.Script.Description.FunctionInvocationCanceledException handled at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw:\n   at Microsoft.Azure.WebJobs.Script.Description.WorkerFunctionInvoker+d__9.MoveNext (Microsoft.Azure.WebJobs.Script, Version=4.21.0.0, Culture=neutral, PublicKeyToken=null: /_/src/WebJobs.Script/Description/Workers/WorkerFunctionInvoker.cs:106)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Script.Description.FunctionInvokerBase+d__24.MoveNext (Microsoft.Azure.WebJobs.Script, Version=4.21.0.0, Culture=neutral, PublicKeyToken=null: /_/src/WebJobs.Script/Description/FunctionInvokerBase.cs:82)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Script.Description.FunctionGenerator+d__3`1.MoveNext (Microsoft.Azure.WebJobs.Script, Version=4.21.0.0, Culture=neutral, PublicKeyToken=null: /_/src/WebJobs.Script/Description/FunctionGenerator.cs:225)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionInvoker`2+d__10.MoveNext (Microsoft.Azure.WebJobs.Host, Version=3.0.37.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35: D:\\a\\_work\\1\\s\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionInvoker.cs:52)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+d__33.MoveNext (Microsoft.Azure.WebJobs.Host, Version=3.0.37.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35: D:\\a\\_work\\1\\s\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:581)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+d__32.MoveNext (Microsoft.Azure.WebJobs.Host, Version=3.0.37.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35: D:\\a\\_work\\1\\s\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:527)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+d__26.MoveNext (Microsoft.Azure.WebJobs.Host, Version=3.0.37.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35: D:\\a\\_work\\1\\s\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:306)\nInner exception System.Threading.Tasks.TaskCanceledException handled at Microsoft.Azure.WebJobs.Script.Description.WorkerFunctionInvoker+d__9.MoveNext:\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Script.Description.WorkerFunctionInvoker+d__9.MoveNext (Microsoft.Azure.WebJobs.Script, Version=4.21.0.0, Culture=neutral, PublicKeyToken=null: /_/src/WebJobs.Script/Description/Workers/WorkerFunctionInvoker.cs:101)\n`\n```\nJust My Code call stack\n```\n`   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+d__26.MoveNext (Microsoft.Azure.WebJobs.Host, Version=3.0.37.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35: D:\\a\\_work\\1\\s\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:352)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+d__18.MoveNext (Microsoft.Azure.WebJobs.Host, Version=3.0.37.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35: D:\\a\\_work\\1\\s\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:108)\nInner exception Microsoft.Azure.WebJobs.Script.Description.FunctionInvocationCanceledException handled at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw:\n   at Microsoft.Azure.WebJobs.Script.Description.WorkerFunctionInvoker+d__9.MoveNext (Microsoft.Azure.WebJobs.Script, Version=4.21.0.0, Culture=neutral, PublicKeyToken=null: /_/src/WebJobs.Script/Description/Workers/WorkerFunctionInvoker.cs:106)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Script.Description.FunctionInvokerBase+d__24.MoveNext (Microsoft.Azure.WebJobs.Script, Version=4.21.0.0, Culture=neutral, PublicKeyToken=null: /_/src/WebJobs.Script/Description/FunctionInvokerBase.cs:82)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Script.Description.FunctionGenerator+d__3`1.MoveNext (Microsoft.Azure.WebJobs.Script, Version=4.21.0.0, Culture=neutral, PublicKeyToken=null: /_/src/WebJobs.Script/Description/FunctionGenerator.cs:225)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionInvoker`2+d__10.MoveNext (Microsoft.Azure.WebJobs.Host, Version=3.0.37.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35: D:\\a\\_work\\1\\s\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionInvoker.cs:52)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+d__33.MoveNext (Microsoft.Azure.WebJobs.Host, Version=3.0.37.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35: D:\\a\\_work\\1\\s\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:581)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+d__32.MoveNext (Microsoft.Azure.WebJobs.Host, Version=3.0.37.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35: D:\\a\\_work\\1\\s\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:527)\n   at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Host.Executors.FunctionExecutor+d__26.MoveNext (Microsoft.Azure.WebJobs.Host, Version=3.0.37.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35: D:\\a\\_work\\1\\s\\src\\Microsoft.Azure.WebJobs.Host\\Executors\\FunctionExecutor.cs:306)\nInner exception System.Threading.Tasks.TaskCanceledException handled at Microsoft.Azure.WebJobs.Script.Description.WorkerFunctionInvoker+d__9.MoveNext:\n   at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult (System.Private.CoreLib, Version=6.0.0.0, Culture=neutral, PublicKeyToken=7cec85d7bea7798e)\n   at Microsoft.Azure.WebJobs.Script.Description.WorkerFunctionInvoker+d__9.MoveNext (Microsoft.Azure.WebJobs.Script, Version=4.21.0.0, Culture=neutral, PublicKeyToken=null: /_/src/WebJobs.Script/Description/Workers/WorkerFunctionInvoker.cs:101)\n`\n```\nTrace\n```\n`6/1/2023, 7:45:03 AM\n-\nREQUEST\nURL: https://******.azurewebsites.net/api/******\nResponse code: 0\nResponse time: 3.1 s\n6/1/2023, 7:45:03 AM\n-\nTRACE\nFUNCTIONS_WORKER_RUNTIME set to dotnet-isolated. Skipping WorkerConfig for language: java\nSeverity level: Information\n6/1/2023, 7:45:03 AM\n-\nTRACE\nFUNCTIONS_WORKER_RUNTIME set to dotnet-isolated. Skipping WorkerConfig for language: node\nSeverity level: Information\n6/1/2023, 7:45:03 AM\n-\nTRACE\nFUNCTIONS_WORKER_RUNTIME set to dotnet-isolated. Skipping WorkerConfig for language: powershell\nSeverity level: Information\n6/1/2023, 7:45:03 AM\n-\nTRACE\nInitializing Warmup Extension.\nSeverity level: Information\n6/1/2023, 7:45:03 AM\n-\nTRACE\nInitializing Host. OperationId: 'fd2e77ef-c3b6-4a31-9d77-24c0de283e1f'.\nSeverity level: Information\n6/1/2023, 7:45:03 AM\n-\nTRACE\nHost initialization: ConsecutiveErrors=0, StartupCount=4, OperationId=fd2e77ef-c3b6-4a31-9d77-24c0de283e1f\nSeverity level: Information\n6/1/2023, 7:45:03 AM\n-\nTRACE\nLoading functions metadata\nSeverity level: Information\n6/1/2023, 7:45:03 AM\n-\nTRACE\nReading functions metadata\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\n2 functions found\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\n1 functions loaded\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nApplicationInsightsLoggerOptions { \"SamplingSettings\": { \"EvaluationInterval\": \"00:00:15\", \"InitialSamplingPercentage\": 100.0, \"MaxSamplingPercentage\": 100.0, \"MaxTelemetryItemsPerSecond\": 20.0, \"MinSamplingPercentage\": 0.1, \"MovingAverageRatio\": 0.25, \"SamplingPercentageDecreaseTimeout\": \"00:02:00\", \"SamplingPercentageIncreaseTimeout\": \"00:15:00\" }, \"SamplingExcludedTypes\": \"Request\", \"SamplingIncludedTypes\": null, \"SnapshotConfiguration\": null, \"EnablePerformanceCountersCollection\": true, \"HttpAutoCollectionOptions\": { \"EnableHttpTriggerExtendedInfoCollection\": true, \"EnableW3CDistributedTracing\": true, \"EnableResponseHeaderInjection\": true }, \"LiveMetricsInitializationDelay\": \"00:00:15\", \"EnableLiveMetrics\": true, \"EnableDependencyTracking\": true, \"DependencyTrackingOptions\": null }\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nLoggerFilterOptions { \"MinLevel\": \"None\", \"Rules\": [ { \"ProviderName\": null, \"CategoryName\": null, \"LogLevel\": null, \"Filter\": \"b__0\" }, { \"ProviderName\": \"Microsoft.Azure.WebJobs.Script.WebHost.Diagnostics.SystemLoggerProvider\", \"CategoryName\": null, \"LogLevel\": \"None\", \"Filter\": null }, { \"ProviderName\": \"Microsoft.Azure.WebJobs.Script.WebHost.Diagnostics.SystemLoggerProvider\", \"CategoryName\": null, \"LogLevel\": null, \"Filter\": \"b__0\" }, { \"ProviderName\": \"Microsoft.Azure.WebJobs.Logging.ApplicationInsights.ApplicationInsightsLoggerProvider\", \"CategoryName\": null, \"LogLevel\": \"Trace\", \"Filter\": null } ] }\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nLoggerFilterOptions { \"MinLevel\": \"None\", \"Rules\": [ { \"ProviderName\": null, \"CategoryName\": null, \"LogLevel\": null, \"Filter\": \"b__0\" }, { \"ProviderName\": \"Microsoft.Azure.WebJobs.Script.WebHost.Diagnostics.SystemLoggerProvider\", \"CategoryName\": null, \"LogLevel\": \"None\", \"Filter\": null }, { \"ProviderName\": \"Microsoft.Azure.WebJobs.Script.WebHost.Diagnostics.SystemLoggerProvider\", \"CategoryName\": null, \"LogLevel\": null, \"Filter\": \"b__0\" }, { \"ProviderName\": \"Microsoft.Azure.WebJobs.Logging.ApplicationInsights.ApplicationInsightsLoggerProvider\", \"CategoryName\": null, \"LogLevel\": \"Trace\", \"Filter\": null } ] }\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nConcurrencyOptions { \"DynamicConcurrencyEnabled\": false, \"MaximumFunctionConcurrency\": 500, \"CPUThreshold\": 0.8, \"SnapshotPersistenceEnabled\": true }\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nFunctionResultAggregatorOptions { \"BatchSize\": 1000, \"FlushTimeout\": \"00:00:30\", \"IsEnabled\": true }\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nSingletonOptions { \"LockPeriod\": \"00:00:15\", \"ListenerLockPeriod\": \"00:01:00\", \"LockAcquisitionTimeout\": \"10675199.02:48:05.4775807\", \"LockAcquisitionPollingInterval\": \"00:00:05\", \"ListenerLockRecoveryPollingInterval\": \"00:01:00\" }\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nScaleOptions { \"ScaleMetricsMaxAge\": \"00:02:00\", \"ScaleMetricsSampleInterval\": \"00:00:10\", \"MetricsPurgeEnabled\": true, \"IsTargetScalingEnabled\": true, \"IsRuntimeScalingEnabled\": false }\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nStarting JobHost\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nStarting Host (HostId=******, InstanceId=8f937b40-6d44-4919-******-ec66a372643a, Version=4.21.2.20699, ProcessId=5844, AppDomainId=1, InDebugMode=False, InDiagnosticMode=False, FunctionsExtensionVersion=~4)\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nGenerating 1 job function(s)\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nFound the following functions: Host.Functions.******\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nInitializing function HTTP routes Mapped function route 'api/******' [get,post] to '******'\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nHost initialized (12ms)\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nHost started (12ms)\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nJob host started\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nHttpOptions { \"DynamicThrottlesEnabled\": true, \"EnableChunkedRequestBinding\": false, \"MaxConcurrentRequests\": 100, \"MaxOutstandingRequests\": 200, \"RoutePrefix\": \"api\" }\nSeverity level: Information\n6/1/2023, 7:45:04 AM\n-\nTRACE\nExecuting 'Functions.******' (Reason='This function was programmatically called via the host APIs.', Id=1fd81ebd-e455-4a79-a9e8-5a02972a124d)\nSeverity level: Information\n6/1/2023, 7:45:06 AM\n-\nTRACE\nWorker process started and initialized.\nSeverity level: Information\n6/1/2023, 7:45:06 AM\n-\nEXCEPTION\nException while executing function: Functions.******\nProblem Id: System.Threading.Tasks.TaskCanceledException at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess\n6/1/2023, 7:45:06 AM\n-\nTRACE\nExecuted 'Functions.******' (Failed, Id=1fd81ebd-e455-4a79-a9e8-5a02972a124d, Duration=2825ms)\nSeverity level: Error\n6/1/2023, 7:45:06 AM\n-\nEXCEPTION\nException while executing function: Functions.******\nProblem Id: System.Threading.Tasks.TaskCanceledException at System.Runtime.CompilerServices.TaskAwaiter.ThrowForNonSuccess\n6/1/2023, 7:45:09 AM\n-\nTRACE\nHost lock lease acquired by instance ID '3caa8b34bd20508b527345686484c415'.\nSeverity level: Information```\n\n`\n```",
      "solution": "The error occurs due to an update to the underlying Azure runtime release at the end of May. The temporary workaround is to pin the Azure runtime to 4.17.3. This information was provided by Azure technical support.",
      "question_score": 9,
      "answer_score": 1,
      "created_at": "2023-06-01T23:41:16",
      "url": "https://stackoverflow.com/questions/76385900/azure-functions-http-triggered-started-throwing-taskcancelled-exception-rando"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 71532944,
      "title": "Unable to debug Python Azure function in VS Code IDE. Getting connect ECONNREFUSED 127.0.0.1:9091 error",
      "problem": "I am trying to debug Azure functions python code using VS code IDE.\nLocal.settings.json is updated with below config\n```\n`\"AzureWebJobsStorage\": \"UseDevelopmentStorage=true\"\n`\n```\nThings I tried so far :- \n\nI reinstalled VS code, \nDowngraded Azure Function Core Tools from 4.0 to 3.0 \nAny pointers to solve this issue will be super helpful. \n\nBelow is the error on VS Code IDE when trying to debug Azure function written in Python: \n\nHost.json below\n```\n`{\n  \"version\": \"2.0\",\n  \"logging\": {\n    \"applicationInsights\": {\n      \"samplingSettings\": {\n        \"isEnabled\": true,\n        \"excludedTypes\": \"Request\"\n      }\n    }\n  },\n  \"extensionBundle\": {\n    \"id\": \"Microsoft.Azure.Functions.ExtensionBundle\",\n    \"version\": \"[2.*, 3.0.0)\"\n  },\n  \"functionTimeout\": \"20:00:00\",\n  \"extensions\": {\n    \"durableTask\": {\n      \"maxConcurrentActivityFunctions\": 1\n    }\n  }\n}\n`\n```\nlaunch.json below\n```\n`{\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"Attach to Python Functions\",\n            \"type\": \"python\",\n            \"request\": \"attach\",\n            \"port\": 9091,\n            \"preLaunchTask\": \"func: host start\"\n        }\n    ]\n}\n`\n```\ntask.json\n```\n`{\n    \"version\": \"2.0.0\",\n    \"tasks\": [\n        {\n            \"label\": \"cmd host start\",\n            \"type\": \"shell\",\n            \"dependsOn\": \"pip install (functions)\",\n            \"windows\": {\n                \"command\": \". ${config:azureFunctions.pythonVenv}\\\\Scripts\\\\activate && func host start --verbose\"\n            },\n            \"isBackground\": true,\n            \"problemMatcher\": \"$func-python-watch\"\n        },\n        {\n            \"label\": \"pipInstall\",\n            \"type\": \"shell\",\n            \"osx\": {\n                \"command\": \"${config:azureFunctions.pythonVenv}/bin/python -m pip install -r requirements.txt\"\n            },\n            \"windows\": {\n                \"command\": \". ${config:azureFunctions.pythonVenv}\\\\Scripts\\\\python -m pip install -r requirements.txt\"\n            },\n            \"linux\": {\n                \"command\": \"${config:azureFunctions.pythonVenv}/bin/python -m pip install -r requirements.txt\"\n            },\n            \"problemMatcher\": []\n        },\n        {\n            \"type\": \"func\",\n            \"command\": \"host start\",\n            \"problemMatcher\": \"$func-python-watch\",\n            \"isBackground\": true,\n            \"dependsOn\": \"func: extensions install\"\n        },\n        \n        {\n            \"type\": \"func\",\n            \"command\": \"extensions install\",\n            \"dependsOn\": \"pip install (functions)\",\n            \"problemMatcher\": []\n        },\n        {\n            \"label\": \"pip install (functions)\",\n            \"type\": \"shell\",\n            \"osx\": {\n                \"command\": \"${config:azureFunctions.pythonVenv}/bin/python -m pip install -r requirements.txt\"\n            },\n            \"windows\": {\n                \"command\": \". ${config:azureFunctions.pythonVenv}\\\\Scripts\\\\python -m pip install -r requirements.txt\"\n            },\n            \"linux\": {\n                \"command\": \"${config:azureFunctions.pythonVenv}/bin/python -m pip install -r requirements.txt\"\n            },\n            \"problemMatcher\": []\n        }\n        \n    ]\n}\n`\n```",
      "solution": "There were many workarounds to resolve `ECONNREFUSED 127.0.0.1:9091` in Visual Studio Code - Stack: Python Azure Functions:\nApproach 1:\nModify the `tasks.json` (available in `.vscode` folder in VS Code) like the below one:\n\nApproach 2:\nIf you don't want to use the above modifications of `task.json` in every new project whenever this error `ECONNREFUSED 127.0.0.1:9091` occurs, then you can use this workaround given in the GitHub vsCode-AzureFunctions Issue No: 760.\n\nVS Code > Your Python Azure Functions Project > View Menu > Open the Command Palette or Ctrl + Shift + P.\nType User Settings and Select: Go to Features in User Menu > Select Terminal > Make the setting `\"terminal.integrated.shell.windows\"` value should be `powershell.exe`.\n\nThe debug task uses different command according to OS and command for Windows only works for PowerShell.\n\nNote:\n\nAs per my research, the error message is too generic. Different Systems/Projects of same type (Azure Functions Python) are having different solutions as I was experienced in.\nFor Few Systems/Projects, changing the port works. As 7071 is the default port for executing HTTP functions in the tooling whereas the debugger needs to attach over a different port.\nWhile changing the debug port, it should be changed in both `launch.json` and `tasks.json`.\n\nThere are two distinct ports at work when the host is started with Python debugging capabilities:\n. `7071` is the default port where the HTTP endpoint is exposed by the host.\n\nWhere is this set?\n\n`9091` is the default port used for starting the debugging endpoint for the Python worker. This is needed for remote attaching to the worker. This needs to be the same in `tasks.json` (`-m ptvsd --host 127.0.0.1 --port 9091`) and `launch.json`. These are set to `9091`\nBoth of these need to be distinct from each other but, other than that, it doesn't matter what values they have. These settings should be handled by the VSCode function creation experience so that conflicts do not arise.\n\nApproach 3:\nAs specified in the MSFT Q&A for the error `ECONNREFUSED 127.0.0.1:9091` in Azure Functions Python, could you please explicit the Azure Functions Extension Bindings/Bundles explicitly as python is Non .NET Language and run/debug the Function.\nApproach 4:\nAs mentioned in the GitHub - Azure Functions - Issue No 1016, two other workarounds of this kind of issue exists longback were:\n\nChange the PowerShell separator (`;`) to the cmd separator (`&&`) in your  `.vscode/tasks.json`  file.\nChange your terminal to PowerShell. See here for more info:  https://code.visualstudio.com/docs/editor/integrated-terminal#_configuration",
      "question_score": 9,
      "answer_score": 2,
      "created_at": "2022-03-18T21:40:29",
      "url": "https://stackoverflow.com/questions/71532944/unable-to-debug-python-azure-function-in-vs-code-ide-getting-connect-econnrefus"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-functions",
      "question_id": 76202060,
      "title": "Could not load type Microsoft.Azure.WebJobs.ParameterBindingData",
      "problem": "I am currently developing an Azure Function in VS Code. I am encountering an error that has already been reported in this GitHub issue. In full, the error reads: `Microsoft.Azure.WebJobs.Extensions.ServiceBus: Could not load type 'Microsoft.Azure.WebJobs.ParameterBindingData' from assembly 'Microsoft.Azure.WebJobs, Version=3.0.34.0, Culture=neutral, PublicKeyToken=****'. Value cannot be null. (Parameter 'provider')`\nOne of the suggested solutions is to downgrade the package version of the `Microsoft.Azure.WebJobs.Extensions.Storage`. However, I do not know how to downgrade a package from an extension bundle. In my local development environment, I'm using the following default `host.json` configuration:\n```\n`{\n  \"version\": \"2.0\",\n  \"logging\": {\n    \"applicationInsights\": {\n      \"samplingSettings\": {\n        \"isEnabled\": true,\n        \"excludedTypes\": \"Request\"\n      }\n    }\n  },\n  \"extensionBundle\": {\n    \"id\": \"Microsoft.Azure.Functions.ExtensionBundle\",\n    \"version\": \"[3.15.0, 4.0.0)\"\n  }\n}\n`\n```\nI already tried multiple version ranges, each lead to the same error.\nSince I'm not familiar with `.NET`, I would appreciate any help or advice on how to downgrade the package to resolve this issue. Thank you.\nAdditional information:\nI am developing an EventHub Triggered Function locally using the test trigger:\n```\n`@app.function_name(name=\"EventHubTrigger1\")\n@app.event_hub_message_trigger(arg_name=\"myhub\", event_hub_name=\"samples-workitems\",\n                               connection=\"\") \n\ndef test_function(myhub: func.EventHubEvent):\n    logging.info('Python EventHub trigger processed an event: %s',\n                myhub.get_body().decode('utf-8'))\n`\n```\nThe `local.settings.json` is as follows:\n```\n`{\n  \"IsEncrypted\": false,\n  \"Values\": {\n    \"FUNCTIONS_WORKER_RUNTIME\": \"python\",\n    \"AzureWebJobsStorage\": \"UseDevelopmentStorage=true\",\n    \"AzureWebJobsFeatureFlags\": \"EnableWorkerIndexing\"\n  }\n}\n`\n```\nUpdate:\nAnother way to solve this issue was to reinstall/ update the azure function core tools using these commands:\n```\n`sudo apt-get update\nsudo apt-get install azure-functions-core-tools-4\n`\n```",
      "solution": "Refer my answer in this Post to resolve the similar error code.\nRefer the answer by Jon koeter and this answer by Victoria Berra\nMake sure you delete these 2 folders from your Local machine that might be conflicting when you run the Azure Function locally:-\n\nAfter deleting these 2 folders, Make sure you delete Azure Function Core tools, you can get the path to your Azure Function Core tools from Environment variable from below settings in your local machine:-\n\nVisit > C:\\Program Files\\Microsoft\\Azure Functions Core Tools\\ and then delete the Azure Functions Core Tools folder.\n\nNow, Install Azure Function core tools from this MS Document again and then create and run the Azure Function event grid trigger.\n\nI installed Azure Function Core tools again by following the link above and Created one Azure Event grid trigger locally the Trigger ran successfully like below:-",
      "question_score": 8,
      "answer_score": 6,
      "created_at": "2023-05-08T17:30:05",
      "url": "https://stackoverflow.com/questions/76202060/could-not-load-type-microsoft-azure-webjobs-parameterbindingdata"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 76362300,
      "title": "Azure cli - Failed to connect to MSI",
      "problem": "How do I solve this error?\n```\n`az account get-access-token --resource https://cognitiveservices.azure.com                                        \nFailed to connect to MSI. Please make sure MSI is configured correctly.\nGet Token request returned: \n`\n```",
      "solution": "When I ran same command as you in Azure Cloud Shell, I got same error as below:\n```\n`az account get-access-token --resource https://cognitiveservices.azure.com  \n`\n```\nResponse:\n\nTo resolve the error, you need to run `az login` first and connect with vaild identity(user account) like below:\n```\n`az login --only-show-errors\n`\n```\nResponse:\n\nWhen I ran below command again after signing in with valid user account, I got access token successfully like this:\n```\n`az account get-access-token --resource https://cognitiveservices.azure.com\n`\n```\nResponse:\n\nI executed the same commands in my local environment too and got an access token successfully like below:\n```\n`az login\naz account show\naz account get-access-token --resource https://cognitiveservices.azure.com\n`\n```\nResponse:\n\nIn your case, check how you are connecting to Azure from CLI and make sure to sign in with valid identity while running `az login`.",
      "question_score": 8,
      "answer_score": 8,
      "created_at": "2023-05-30T09:00:21",
      "url": "https://stackoverflow.com/questions/76362300/azure-cli-failed-to-connect-to-msi"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 68957371,
      "title": "How to run multiple commands using terraform local-exec",
      "problem": "I am trying to run a few az cli commands using terraform using local-exec provisioner but I keep running into an error that says:\n```\n`Error: Invalid expression\n\nOn modules/eventgrid/main.tf line 68: Expected the start of an expression, but\nfound an invalid expression token.\n\n`\n```\nHere's my code:\n```\n`resource \"null_resource\" \"eg-role-assignment\" {\n  provisioner \"local-exec\" {\n    \n    interpreter = [\"/bin/bash\", \"-c\"]\n    command = Can anybody please guide me as to what's wrong ?",
      "solution": "With your `\nFinally, as the cause of the issue, you have a space after `EOT`.\n```\n`command = <<-EOT\n          az account set --subscription foo\n          az eventgrid topic update --resource-group $RESOURCE_GROUP --name $EVENTGRID_NAME --identity systemassigned\nEOT\n`\n```",
      "question_score": 7,
      "answer_score": 15,
      "created_at": "2021-08-27T19:30:58",
      "url": "https://stackoverflow.com/questions/68957371/how-to-run-multiple-commands-using-terraform-local-exec"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 69453392,
      "title": "az tag update ERROR: (MissingSubscription) The request did not have a subscription or a valid tenant level resource provider",
      "problem": "I am trying to set a tag named \"GitBranch\" on an Azure Resource Group:\n\nWhen I call the command in PowerShell window -\n```\n`az tag update --resource-id \"/subscriptions/79ca5b...7f/resourceGroups/ccg-afarber2\" --subscription \"79ca5b...7f\" --operation merge --tags GitBranch=Test\n`\n```\nthen it works:\n\nBut when I try the same command in Git Bash window, then it fails.\nI have also tried calling the following commands before and also tried both double and single quotes\n```\n`az login\naz account set --subscription \"79ca5b....7f\"\n`\n```\nbut the error is still the same:\n\nERROR: (MissingSubscription) The request did not have a subscription or a valid tenant level resource provider.\n\nAnd the reason why I am trying to get the command working in bash is because I get the same error for my Azure pipeline task:\n```\n`  - task: AzureCLI@2\n    displayName: 'Set Resource Group tag'\n    inputs:\n      azureSubscription: '${{ parameters.ArmConnection }}'\n      scriptType: 'bash'\n      scriptLocation: 'inlineScript'\n      inlineScript: |\n        az tag update \\\n          --resource-id '/subscriptions/${{ parameters.SubscriptionId }}/resourceGroups/${{ parameters.ResourceGroupName }}' \\\n          --subscription '${{ parameters.SubscriptionId }}' \\\n          --operation Merge --tags \\\n          GitBranch=$(git branch --show-current)\n`\n```\n\nWhat is happening here please?\nOn my PC I have azure-cli 2.28.0 installed.",
      "solution": "I have found a solution myself!\nIn a AzureCLI pipeline task, when you run an az cli command, which has parameters starting with a slash, then the MinGW bash will auto-append the current path.\nTo prevent this, you can prepend the following variable to the az command:\n```\n`MSYS_NO_PATHCONV=1 az ....\n`\n```\nA double slash works too:",
      "question_score": 7,
      "answer_score": 11,
      "created_at": "2021-10-05T17:35:11",
      "url": "https://stackoverflow.com/questions/69453392/az-tag-update-error-missingsubscription-the-request-did-not-have-a-subscripti"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 78912586,
      "title": "Can&#39;t create Azure Storage Account: SubscriptionNotFound",
      "problem": "I'm working through some tutorials, and after successfully creating a resource group, I cannot create a corresponding storage account.\n```\n`az login\n`\n```\nCmd to create resource group:\n```\n`az group create --location \"Central US\" --name \n`\n```\nThis runs with `\"provisioningState\": \"Succeeded\"`\nCmd to create account storage:\n```\n`az storage create --name \"some_name\" --resource-group  \n`\n```\nThis fails with `(SubscriptionNotFound)`\n```\n`Subscription  was not found.\nCode: SubscriptionNotFound\nMessage: Subscription  was not found.\n`\n```\nIs the tutorial missing a step in between? Azure is obviously 'finding' my subscription id, but I'm not sure what else is causing the error.",
      "solution": "Subscription  was not found.\nCode: SubscriptionNotFound\nMessage: Subscription  was not found.\n\nThe above error occurs when `Microsoft.Storage` Resource Provider is not registered for the subscription.\nPortal:\nPortal->  -> Resource providers -> search Microsoft. Storage -> Register.",
      "question_score": 6,
      "answer_score": 11,
      "created_at": "2024-08-26T03:15:07",
      "url": "https://stackoverflow.com/questions/78912586/cant-create-azure-storage-account-subscriptionnotfound"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 69099977,
      "title": "Using outputs of Powershell in Github Actions",
      "problem": "I am trying to get connection string using Powershell and pass this argument to another step in the actions, but I am getting this error:\n`Input required and not supplied: connection-string`\nBut I am following a similar behaviour that I use before but I am not sure why it is not working, Here is part of my script:\n```\n`      - name: Secrets to Key Vault\n        uses: azure/powershell@v1\n        env:\n          POWERSHELL_TELEMETRY_OPTOUT: 1\n        with:\n          inlineScript: |\n            $sqlConnectionString = (az keyvault secret show --vault-name  --name  --query [value] --output tsv)\n            echo ::set-output name=sqlConnectionString::$( $sqlConnectionString)\n          azPSVersion : '3.1.0'\n        \n\n      - name: Deploy Core Module\n        uses: azure/sql-action@v1\n        id: sqlConnection\n        with:\n          server-name: \n          connection-string: ${{\u202fsteps.sqlConnection.outputs.sqlConnectionString}}\n          dacpac-package: './Database.dacpac'\n`\n```\nI think problem is related to the output of the variable but I use similar syntax previously just in a simple run and it worked. Could it be related to the behaviour of the Powershell?",
      "solution": "Plese add id to you first action:\n`      - name: Secrets to Key Vault\n        uses: azure/powershell@v1\n        id: setSqlConnection\n        env:\n          POWERSHELL_TELEMETRY_OPTOUT: 1\n        with:\n          inlineScript: |\n            $sqlConnectionString = (az keyvault secret show --vault-name  --name  --query [value] --output tsv)\n            echo ::set-output name=sqlConnectionString::$( $sqlConnectionString)\n          azPSVersion : '3.1.0'\n        \n\n      - name: Deploy Core Module\n        uses: azure/sql-action@v1\n        id: sqlConnection\n        with:\n          server-name: \n          connection-string: ${{\u202fsteps.setSqlConnection.outputs.sqlConnectionString}}\n          dacpac-package: './Database.dacpac'\n`\nand then use it to access output `${{\u202fsteps.setSqlConnection.outputs.sqlConnectionString}}`",
      "question_score": 6,
      "answer_score": 2,
      "created_at": "2021-09-08T10:55:58",
      "url": "https://stackoverflow.com/questions/69099977/using-outputs-of-powershell-in-github-actions"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 68496321,
      "title": "az: &#39;upgrade&#39; is not in the &#39;az&#39; command group",
      "problem": "I want to upgrade azure cli to 2.26.1 version from 2.0.81 in window subsystem of linux(wsl ubuntu). I am trying to use command `az upgrade` . It is giving following error:\n\naz: 'upgrade' is not in the 'az' command group. See 'az --help'. If the command is from an extension, please make sure the corresponding extension is installed. To learn more about extensions, please visit https://learn.microsoft.com/en-us/cli/azure/azure-cli-extensions-overview\n\nIs there some way to upgrade it in ubuntu?",
      "solution": "I got the solution of it. I just reinstall the azure cli through following link.\nhttps://learn.microsoft.com/en-us/cli/azure/install-azure-cli-linux?pivots=apt",
      "question_score": 6,
      "answer_score": 7,
      "created_at": "2021-07-23T10:33:17",
      "url": "https://stackoverflow.com/questions/68496321/az-upgrade-is-not-in-the-az-command-group"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 66674862,
      "title": "Azure CLI: Unable to escape pipe character (|) in Windows PowerShell",
      "problem": "Scenario\nI try to create an Azure web app with Azure CLI on my windows machine. Unfortunately, I am not able to choose runtime for my webapp. When I try: `az webapp create -n name -g grop -p plan -r \"DOTNETCORE|3.1\"`, I am getting an error:\n```\n`'3.1' is not recognized as an internal or external command,\n`\n```\noperable program or batch file.\nI was trying to escape pipe with backslash `\\` but it does not help",
      "solution": "You need to enclose within quotes, try this\n```\n`az webapp create --name somename -g grop  --plan plan  --runtime='\"DOTNETCORE|3.1\"'\n`\n```",
      "question_score": 5,
      "answer_score": 5,
      "created_at": "2021-03-17T15:12:46",
      "url": "https://stackoverflow.com/questions/66674862/azure-cli-unable-to-escape-pipe-character-in-windows-powershell"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 76379624,
      "title": "Unable to use Azure Developer CLI (azd) in vsCode even after extensions installed",
      "problem": "I have been attempting to integrate and utilize Azure DevOps (AZD) within Visual Studio Code (VSCode) for my development work. Despite trying multiple methods and approaches, I have consistently encountered issues that prevent successful utilization.\nThe main problem is that every time I attempt to use AZD in VSCode, the operation fails. This issue persists regardless of the specific function or feature of AZD I'm trying to use. The failure does not seem to be tied to a specific action or command within the AZD extension.\nI have followed several online tutorials and official documentation to set up and use AZD in VSCode, ensuring that all the necessary prerequisites and settings are correctly configured. Despite this, the problem remains unresolved.\n\nInstall the** Azure Developer CLI ** extension:\n\nInstall the standalone Azure Developer CLI via the following command in vscode terminal.\n\n`powershell -ex AllSigned -c \"Invoke-RestMethod 'https://aka.ms/install-azd.ps1' | Invoke-Expression\" `\n```\n`VERBOSE: Downloading build from https://azure-dev.azureedge.net/azd/standalone/release/latest/azd-windows-amd64.msi\nVERBOSE: Verifying signature of D:\\Users\\2303906\\AppData\\Local\\Temp\\4ofthncj.h02\\azd-windows-amd64.msi\nVERBOSE: Installing MSI\nVERBOSE: Cleaning temporary install directory: D:\\Users\\2303906\\AppData\\Local\\Temp\\4ofthncj.h02\nSuccessfully installed azd\nAzure Developer CLI (azd) installed successfully. You may need to restart running programs for installation to take effect.\n- For Windows Terminal, start a new Windows Terminal instance.\n- For VSCode, close all instances of VSCode and then restart it.\n\nThe Azure Developer CLI collects usage data and sends that usage data to Microsoft in order to help us improve your experience.\nYou can opt-out of telemetry by setting the AZURE_DEV_COLLECT_TELEMETRY environment variable to 'no' in the shell you use.\n`\n```\nBut when I tried to verify, I still met the issue:\n```\n`azd auth login\n\nazd: The term 'azd' is not recognized as a name of a cmdlet, function, script file, or executable program.\nCheck the spelling of the name, or if a path was included, verify that the path is correct and try again.\n`\n```",
      "solution": "When I tried to reproduce the same in my environment, I was getting the same error.\n\nSteps I followed to install Azure Developer CLI:\n\nInstalled Azure Developer CLI in visual studio code->Extensions:\n\nTo fix the error:\n\n`The term azd is not recognized as the name of the cmdlet`\n\nInstall `az` module by running the below command:\n`Install-Module -Name Az -Scope CurrentUser -Repository PSGallery -Force`\n\nNow, able to login to azd:\n\nInitialized a new project:\n\nReferences:\nInstall Azure Developer CLI",
      "question_score": 5,
      "answer_score": 8,
      "created_at": "2023-06-01T09:33:56",
      "url": "https://stackoverflow.com/questions/76379624/unable-to-use-azure-developer-cli-azd-in-vscode-even-after-extensions-installe"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 78293396,
      "title": "How can I use azcopy CLI in Azure Devops Pipelines running on Linux using managed identity to authenticate to azure file share without a SAS token?",
      "problem": "Right now we have this azure pipeline AzureCLI task where we use the preinstalled azcopy cli in to copy files from the pipeline workspace/git into our azure file share. We were previously using a SAS token in the URL, however, those tokens eventually expire and its another secret to manage. We know there is a way to upload files to azure file share without a SAS token, and the documentation says it should work with a simple cli task like this\n` - task: AzureCLI@2\n      inputs:\n        azureSubscription: your-azure-service-connection-name\n        scriptType: 'bash'\n        scriptLocation: 'inlineScript'\n        inlineScript: |                    \n              export AZCOPY_AUTO_LOGIN_TYPE=AZCLI\n              azcopy sync directory/MyFilesToCopy https://mystorageaccount.file.core.windows.net --recursive --put-md5\n        addSpnToEnvironment: true\n        failOnStandardError: true\n`\nThe error we got was:\n```\n`Failed to perform Auto-login: AzureCLICredential: WARNING: Could not retrieve credential from local cache for service principal *** under tenant common. Trying credential under tenant xxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx, assuming that is an app credential.\nERROR: AADSTS700016: Application with identifier '***' was not found in the directory 'Microsoft'. This can happen if the application has not been installed by the administrator of the tenant or consented to by any user in the tenant. You may have sent your authentication request to the wrong tenant. Trace ID: b0c23ef4-f557-4151-8a1a-375d236b4700 Correlation ID: 2066f167-dae6-4dd1-9031-7b0a1136ac4b Timestamp: 2024-04-08 14:34:32Z\nInteractive authentication is needed. Please run:\naz login\n`\n```\nThis one was telling because directly above this, i can see the successful azure cli login info\n```\n`/usr/bin/az login --service-principal -u *** --tenant xxxxx-xxxx-xxxx-xxxx-xxxxxxxx --allow-no-subscriptions --federated-token ***\n[\n  {\n    \"cloudName\": \"AzureCloud\",\n    .....\n\n`\n```",
      "solution": "Our Solution:\nYou need to add the azure tenantId as an environment variable that way azcopy autologin knows which tenant to use, despite our error message saying it was attempted to connect using our tenant, specifying it forced it to not use the Microsoft \"common\" tenant.\nAdditionally, you need to make sure that your service connection has Contributor rights over your resource group (figure 1) and that the Service Principal has Storage File Data Privileged Contributor rights over your storage account.\n\nThis is stated in the documentation here: https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-authorize-azure-active-directory. There was no mention of the tenantId needing to be included in the auto login section.\n` - task: AzureCLI@2\n      inputs:\n        azureSubscription: your-azure-service-connection-name\n        scriptType: 'bash'\n        scriptLocation: 'inlineScript'\n        inlineScript: |                    \n              export AZCOPY_AUTO_LOGIN_TYPE=AZCLI\n              export AZCOPY_TENANT_ID=$tenantId\n              azcopy sync directory/MyFilesToCopy https://mystorageaccount.file.core.windows.net --recursive --put-md5\n        addSpnToEnvironment: true\n        failOnStandardError: true\n`",
      "question_score": 5,
      "answer_score": 7,
      "created_at": "2024-04-08T16:56:02",
      "url": "https://stackoverflow.com/questions/78293396/how-can-i-use-azcopy-cli-in-azure-devops-pipelines-running-on-linux-using-manage"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 69915974,
      "title": "How to delete a folder from an Azure Fileshare using cli",
      "problem": "I'm trying to delete the contents of a fileshare via script in order to clean it on schedule or on demand.\n`az storage file delete -s $myshare -p $folderOrFileName --account-name $accountName --account-key $accountKey`\nAllow me to delete files but I cannot delete a folder. Searching the web I've found several disjoined solutions like using azcopy tool or PS commands but none of them worked for me so far.\nHelp will be appreciated.",
      "solution": "You have to use `az storage directory delete` instead of `az storage file delete` to delete a folder present inside the Fileshare as file delete only deletes files and not the folders (directories).\nI tested the Scenario in my environment :\n\nBut When I directly use the below command , I get another error as the directory is not empty , its not able to delete the entire directory.\n\n```\n` az storage directory delete --share-name test --name ansumandirectory --account-name ansumanadls1234 --account-key \n`\n```\n\nSo , In order to delete the Directory ,I have to delete the files present inside it as well first . So I used the below script :\n```\n`$sharename = \"test\"\n$foldername = \"ansumandirectory\"\n$accountname = \"ansumanadls1234\"\n$accountkey = \"accountkey\"\n$source= \"$sharename/$foldername\"\naz storage file delete-batch --source $source --account-name $accountname --account-key $accountkey \naz storage directory delete --share-name $sharename --name $foldername --account-name $accountname --account-key $accountkey\n`\n```\nOutput:\n\nNote: If Your directory is Empty then you can directly use the `az storage directory delete` command , it will delete the folder. But if its not empty then use the `az storage file delete-batch` to delete all the files with the directory delete command (as done in the above script).",
      "question_score": 5,
      "answer_score": 6,
      "created_at": "2021-11-10T16:26:42",
      "url": "https://stackoverflow.com/questions/69915974/how-to-delete-a-folder-from-an-azure-fileshare-using-cli"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 67348226,
      "title": "Install azure cli via brew not working in mac m1",
      "problem": "I have be trying to install azure cli in new mac m1. But it fails. I get the following error\n```\n`brew reinstall azure-cli\n==> Downloading https://ghcr.io/v2/homebrew/core/azure-cli/manifests/2.22.1\n######################################################################## 100.0%\n==> Downloading https://ghcr.io/v2/homebrew/core/azure-cli/blobs/sha256:1980c967\n==> Downloading from https://pkg-containers-az.githubusercontent.com/ghcr1/blobs\n######################################################################## 100.0%\n==> Reinstalling azure-cli \n==> Pouring azure-cli--2.22.1.arm64_big_sur.bottle.tar.gz\n\ud83c\udf7a  /opt/homebrew/Cellar/azure-cli/2.22.1: 19,449 files, 329.3MB\n`\n```\nAfter Pouring it just stops. I also tried to install using pip3 and I can install that successfully but when I type \"az\" command I get the following error\n```\n`/opt/homebrew/bin/az: line 2: 64784 Killed: 9               AZ_INSTALLER=HOMEBREW /opt/homebrew/Cellar/azure-cli/2.22.1/libexec/bin/python -m azure.cli \"$@\"\n`\n```",
      "solution": "As mentioned in the comments: My python3 wasn't installed via brew. So first uninstalled brew and python3. Then installed brew again(before that made sure Rosetta 2 is working). Then tried brew doctor. There was error saying /usr/... then, I deleted those files. Once successfully removed/deleted brew doctor will run fine.",
      "question_score": 5,
      "answer_score": 3,
      "created_at": "2021-05-01T18:00:58",
      "url": "https://stackoverflow.com/questions/67348226/install-azure-cli-via-brew-not-working-in-mac-m1"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 72972375,
      "title": "How to store a private key in Azure Keyvault?",
      "problem": "I am trying to store a private key as a secret in the Azure Keyvault through the Azure portal but when I retrieve the value, I see it's modified (additional spaces are added). I also tried to add the secret through the `az cli` as follows:\n`$file = get-content C:\\Dev\\private.key`\n`az keyvault secret set --name private_key --value $file --vault-name testing-kv`\nBut I encountered the following error:\n`unrecognized arguments: MIIEXXXXXXX...` Only the `-----BEGIN PRIVATE KEY-----` part of the private key is recognized but the rest isn't.\nI also looked at this post Store Private Key into Azure KeyVault, value got changed and the solution indicates to convert the private key as a secure string and upload the encoded value to the key vault:\n`$secretvalue = ConvertTo-SecureString 'C:\\Dev\\private.key' -AsPlainText -Force`\n`az keyvault secret set --name private_key --value $secretValue`\nBut this didn't work because it stores the string `[System.Secure.String]` in the keyvault.\nHow can I store this private key in its integrity into the keyvault?",
      "solution": "I had to run in Powershell:\n`az login`\n`az account set --subscription mysub`\nGo to the folder where you have the private cert and type:\n`az keyvault secret set --name mynewkey --vault-name test-kv --file .\\private.key`\nThis command reads the private key from a file and stores it in the keyvault without any modification",
      "question_score": 4,
      "answer_score": 15,
      "created_at": "2022-07-13T22:38:11",
      "url": "https://stackoverflow.com/questions/72972375/how-to-store-a-private-key-in-azure-keyvault"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 74386606,
      "title": "How to delete a revision in Azure Container Apps?",
      "problem": "Is there a way to delete a revision on Azure Container Apps?\nScenario\nI have an Azure Container App instance for testing puposes which I regularly push new revisions to using the `az containerapp update` command in my CI/ CD pipeline whenever I merge a change onto my `master` branch. As the revisions all use a Docker image with the same tag `:latest` - but not (necessarily) the same code inside the Docker container - I create a new unique revision suffix for each revision in order to create a revision-scope change.\nI am using the single-revision mode, therefore there's only ever one revision which serves 100% of the traffic. So whenever I push a new revision with a new revision-suffix a new revision gets created and activated and the previous revision gets deactivated.\nUsing this approach with time a lot of revisions get created and most of them will not be needed anymore but will still occupy storage and - as revision names must be unqiue - a lot of names which I would like to re-use, therefore I'd like to delete them.\nHowever, looking at the available commands in the Azure CLI for revisions there does not seem to be a way to delete a revision.\nThe question therefore is, if there is a way how can I delete those revisions? Alternatively if revisions cannot be deleted, is there another way so I can force the container app to update the docker image it is running even though the tag of the docker image does not change (in that case I would not (necessarily) need to create a new revision every time)?\nExpectation\nI would have expected there was a deletion command as there will be many container apps with many revisions which will need lots of storage (which one might need to pay for eventually) as a revision might be activated again at any time, so Microsoft or Azure users should at least to my mind have the same desire to delete outdated/ deprecated/ unused revisions.",
      "solution": "Agreed the point of @ahmelsayed that is not possible to delete the revisions manually and they should eventually be pruned to the most recent 100.\n\nI would have expected there was a deletion command as there will be many container apps with many revisions which will need lots of storage (which one might need to pay for eventually) as a revision might be activated again at any time, so Microsoft or Azure users should at least to my mind have the same desire to delete outdated/ deprecated/ unused revisions.\n\nAs mentioned in this MS Doc, max. 100 revisions are allowed and older than that are purged where there is no cost for inactive revisions.\nYou can deactivate the unused or outdated revisions using the Azure Portal or Azure CLI or REST API or Code like Java, Go, and JS and activate also.\nHere is the syntax of deactivating the Azure Container Apps Revisions using Azure CLI:\n`az containerapp revision deactivate --revision  --resource-group \n`",
      "question_score": 4,
      "answer_score": 8,
      "created_at": "2022-11-10T10:16:19",
      "url": "https://stackoverflow.com/questions/74386606/how-to-delete-a-revision-in-azure-container-apps"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 70766999,
      "title": "Az CLI: Cannot run pipeline with runtime parameters",
      "problem": "I'm trying to run a pipeline using AZ CLI. I have a simple pipeline:\n```\n`parameters:\n- name: initials\n  displayName: Initials\n  type: string\n\ntrigger:\n- master\n\npool:\n  vmImage: ubuntu-latest\n\nsteps:\n- script: echo ${{ parameters.initials }}\n  displayName: Test\n`\n```\nAnd I try to run it using:\n```\n`az pipelines run --organization  --project  --name  --branch  --debug --variables initials=maim\n`\n```\nThen I end up with an error:\n\nValidationResults\":[{\u201cresult\u201d:\u201cerror\u201d,\u201cmessage\u201d:\"A value for the parameter must be provided\n\nWhich is a bit odd since you can tell from the debug that the parameter is being set:",
      "solution": "It because you need to send `parameters` and you send `variables`.\nAccording to this GitHub issue it fixed in a new version:\n\nNeed to remove old package first:\n\n```\n`az extension remove -n azure-devops\naz extension add --source https://github.com/roshan-sy/release-repo/releases/download/1/azure_devops-0.23.0-py2.py3-none-any.whl\n`\n```\n\nInitial test looks good:\n\n```\n`az login\naz pipelines run --help\n...\n--parameters : Space separated \"name=value\" pairs for the parameters you would like to set.\n...\naz pipelines run --name \"{pipeline.name}\" --parameters Param1={Value1}\n`\n```",
      "question_score": 4,
      "answer_score": 8,
      "created_at": "2022-01-19T08:53:41",
      "url": "https://stackoverflow.com/questions/70766999/az-cli-cannot-run-pipeline-with-runtime-parameters"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 66835138,
      "title": "Error while trying to assign a custom role &quot;Secret Reader&quot; to an object ID for an Azure Key Vault",
      "problem": "Can anyone tell me why i am getting this error while trying to run this command and assign a custom role \"Secret Reader\" to a guest account Object Id :\naz role assignment create --role \"Secret Reader\" --assignee-object-id \"12526c57-c91b-405b-9068-2b582b23e83a\" --scope \"/subscriptions/Not-putting this-here/resourceGroups/pallabdev/providers/Microsoft.KeyVault/vaults/testhalvault\"\nThe error i get is :\n```\n`request failed: Error occurred in request., InvalidSchema: No connection adapters were found for 'C:/Program Files/Git/subscriptions/Not-Putting-This-Here/resourceGroups/pallabdev/providers/Microsoft.KeyVault/vaults/testhalvault/providers/Microsoft.Authorization/roleDefinitions?$filter=roleName%20eq%20%27Secret%20Reader%27&api-version=2018-01-01-preview'\n`\n```",
      "solution": "From the error message, I suppose you ran the command in Git Bash of Windows, I can also reproduce this on my side, it was caused by the Auto-translation of Resource IDs in Git Bash, similar issue here.\nTo solve this issue, just set environment variable `MSYS_NO_PATHCONV=1` or set it temporarily when you running the command.\n```\n`$ MSYS_NO_PATHCONV=1 az role assignment create --role \"Secret Reader\" --assignee-object-id \"12526c57-c91b-405b-9068-2b582b23e83a\" --scope \"/subscriptions/Not-putting this-here/resourceGroups/pallabdev/providers/Microsoft.KeyVault/vaults/testhalvault\"\n`\n```",
      "question_score": 4,
      "answer_score": 5,
      "created_at": "2021-03-27T20:07:50",
      "url": "https://stackoverflow.com/questions/66835138/error-while-trying-to-assign-a-custom-role-secret-reader-to-an-object-id-for-a"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 71491555,
      "title": "Some azure cli commands return SubscriptionNotExists errors?",
      "problem": "I have a free trial subscription on Azure:\n`$ az account subscription list                  \n                                                                                         \nCommand group 'account subscription' is experimental and under development. Reference and support levels: https://aka.ms/CLI_refstatus\n[\n  {\n    \"authorizationSource\": \"RoleBased\",\n    \"displayName\": \"Azure subscription 1\",\n    \"id\": \"/subscriptions/fffffff-ffff-ffff-ffff-ffffffffffff\",\n    \"state\": \"Enabled\",\n    \"subscriptionId\": \"fffffff-ffff-ffff-ffff-ffffffffffff\",\n    \"subscriptionPolicies\": {\n      \"locationPlacementId\": \"Public_2014-09-01\",\n      \"quotaId\": \"FreeTrial_2014-09-01\",\n      \"spendingLimit\": \"On\"\n    }\n  }\n]\n`\nbut when I execute the command (list MariaDB SKUs) I get the following error:\n`$ az mariadb server list-skus --location eastus       \n                                                                                  \n(SubscriptionNotExists) Subscription 'fffffff-ffff-ffff-ffff-ffffffffffff' does not exist.\nCode: SubscriptionNotExists\nMessage: Subscription 'fffffff-ffff-ffff-ffff-ffffffffffff' does not exist.\n`\nWorks fine under my other account where I have a pay-as-you-go subscription. Same thing with the go SDK.\nIf the free trial is the issue it would be great to document it somewhere.",
      "solution": "Turns out you have to register provider resources for your subscription before you can use them. For some reason MariaDB was already registered for one of my accounts but not for the other. The error `SubscriptionNotExists` is extremely confusing in that regard.",
      "question_score": 4,
      "answer_score": 4,
      "created_at": "2022-03-16T04:37:53",
      "url": "https://stackoverflow.com/questions/71491555/some-azure-cli-commands-return-subscriptionnotexists-errors"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 74376920,
      "title": "How to increase Node Drain Timeout for AKS node upgrade rollout",
      "problem": "Problem:\n\nPDB with maxUnavailable of 1\nPods have LONG grace period of 15 hours (technical requirement for the business case at hand handling stateful connections. Also induced by external dependency, so no way for me to change this)\nNode Drain timeout is only 1 hour?\n\nDuring an upgrade, a pod that needs to be evicted off a node might take longer than the Node Drain timeout and yields the following error:\n```\n`(UpgradeFailed) Drain of NODE_NAME did not complete pods [STS_NAME:POD_NAME]: Pod\n POD_NAME still in state Running on node NODE_NAME, pod termination grace period 15h0m0s was\n greater than remaining per node drain timeout. See http://aka.ms/aks/debugdrainfailures\nCode: UpgradeFailed\n`\n```\nAfter which the cluster is in failed state.\nDue to the grace period of pods not being in my control, I would like to increase the node drain timeout to 31 hours, as there can be 2 of those long grace period pods on a single node. I haven't been able to find anything regarding the node drain timeout though.\nI can't even figure out, if it's part of K8s, or AKS specifically.\nHow to increase the per node drain timeout, such that my long grace period pods don't interrupt my node upgrade operations?\nEDIT:\nIn the kubectl cli reference, the drain command takes a timeout parameter. As I don't invoke the drain myself, I don't see how this helps me. It lead me to believe that, if anywhere, this needs to be dealt with on the AKS side of things.",
      "solution": "Drain timeout is configurable in the august api of aks. Documetnation still pending.\nA link to the August API Update that provides drainTimeoutInMinutes:\n2023-08-02-preview",
      "question_score": 4,
      "answer_score": 2,
      "created_at": "2022-11-09T15:56:45",
      "url": "https://stackoverflow.com/questions/74376920/how-to-increase-node-drain-timeout-for-aks-node-upgrade-rollout"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 72044477,
      "title": "Creating container registry from Azure Bicep and deploying image to this registry in the same build pipeline in Azure Devops",
      "problem": "I'm running into an issue in Azure Devops. I have two questions regarding the issue. The issue is that I have an Azure Bicep template that deploys a bunch of resources in a resource group within my Azure subscription.\nOne of these resources is an Azure Container Registry (ACR) to which I want to push a certain image when the image code is updated. Now what I essentially am trying to achieve is that I have a single multi-stage Azure build Pipeline in which\n\nThe resources are deployed via Azure Bicep, after which\nI build and push the image to the (ACR) automatically\n\nNow the issue here is that to push an image to ACR a service connection needs to be made in Azure Devops, which can only happen through the portal after the Azure Bicep pipeline has run. Now I have found that I can use an Azure CLI command: `az devops service-endpoint create` to create a connection from a .json-file from the command line, which essentially means I could maybe add a .json-file, however I would not have the right credentials until after the AZ bicep build and would probably have to expose sensitive Azure account information in my json file to create the connection (if even possible).\nThis leaves me with two questions:\n\nIn practice, is this something that one would do, or does it make more sense to just have two pipelines; one for the infrastructure-as-code and one for the application code. I would think that it is preferable to be able to deploy everything in one go, but am quite new to DevOps and can't really find an answer to this question.\nIs there anyway that this would still be possible to achieve securely in a single Azure DevOps pipeline?",
      "solution": "Answer to Q1.\nFrom my experience, infrastructure and application has always been kept separate. We generally want to split those two so that it's easier to manage. For example, you might want to test a new feature of the ACR separately, like new requirements for adding firewall rules to your ACR, or maybe changing replication settings, without rebuilding/pushing a new image every time.\nOn the other hand the BAU pipeline involves building new images daily or weekly. One action is a one-off thing, the other is more of a BAU. You usually just want to build the ACR and forget about it, only referencing when required.\nIn addition, the ACR could eventually be used for images of many other application pipelines you would have in the future. So you don't really want to tie it to a specific application pipeline. If you wanted to have a future proof solution, I'd suggest keeping them separate and then have different pipelines for different applications builds.\nIt's generally best to keep core infrastructure resources code separate from the BAU stuff.\nAnswer to Q2.\nI don't know in detail the specifics of how you're running your pipeline but from what I understand, regarding exposing the sensitive content, there are two ways (best practice) I would handle this.\n\nKeep the file with the sensitive content as secure file in the pipeline library and then retrieve it when required.\nKeep the content or any secrets in an Azure KeyVault and read them during your pipeline run.",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2022-04-28T15:23:34",
      "url": "https://stackoverflow.com/questions/72044477/creating-container-registry-from-azure-bicep-and-deploying-image-to-this-registr"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 70108607,
      "title": "Azure DevOps &amp; Azure CLI: Unable to locate executable file",
      "problem": "When trying to run a simple Azure CLI Task in my ubuntu-based Azure DevOps pipeline I get the following error message:\n```\n`##[error]Script failed with error: Error: Unable to locate executable file: \n'/home/vsts/work/_temp/azureclitaskscript1637831708745.bat'. \nPlease verify either the file path exists or the file can be found within a directory specified by the PATH environment variable. \nAlso check the file mode to verify the file is executable.\n`\n```\nIf I'm reading this correctly the inline script is not being found, right? What am I missing here? Here's the full YAML:\n```\n`trigger:\n- main\n- dev\n\npool:\n  vmImage: ubuntu-latest\n\nsteps:\n- task: AzureCLI@2\n  inputs:\n    azureSubscription: 'My Subscription Name'\n    scriptType: 'batch'\n    scriptLocation: 'inlineScript'\n    inlineScript: 'az --version'\n`\n```",
      "solution": "You're running your task on Linux, you can't use `batch` there, you'll need to pick `pscore` or `bash` instead, or switch to a `windows-latest` vmImage.\n\nScript Type*: Select the type of script to be executed on the agent. Task supports four types: Batch / Shell / PowerShell / PowerShell Core scripts, default selection being empty. Select Shell/PowerShell Core script when running on Linux agent or Batch/PowerShell/PowerShell Core script when running on Windows agent. PowerShell Core script can run on cross-platform agents (Linux, macOS, or Windows)\n\nhttps://github.com/microsoft/azure-pipelines-tasks/tree/master/Tasks/AzureCLIV2#parameters-of-the-task\nThe actual strings to pass to the arguments can be found in the task.json. It looks like the task doesn't do any validation on these fields, causing this weird error situation.\n```\n`            \"options\": {\n                \"ps\": \"PowerShell\",\n                \"pscore\": \"PowerShell Core\",\n                \"batch\": \"Batch\",\n                \"bash\": \"Shell\"\n            }\n`\n```",
      "question_score": 3,
      "answer_score": 7,
      "created_at": "2021-11-25T10:26:14",
      "url": "https://stackoverflow.com/questions/70108607/azure-devops-azure-cli-unable-to-locate-executable-file"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 69919761,
      "title": "The term &#39;AzCopy&#39; is not recognized as a name of a cmdlet, function, script file",
      "problem": "I need to copy tables from table storage into a different storage account. When attempting to execute `AzCopy` I'm getting the following exception:\n\nThe term 'AzCopy' is not recognized as a name of a cmdlet, function,\nscript file, or executable program. Check the spelling of the name, or\nif a path was included, verify that the path is correct and try again.\n\nI'm connected to the terminal from the portal, and have a powershell prompt:\n\nThe issue seems to be with this line:\n```\n`    AzCopy /Source:$SrcTableUrl `\n                      /Dest:$DstBlobUrl/$TableName `\n                      /SourceKey:$SrcAccessKey `\n                      /Destkey:$DstAccessKey\n`\n```\nHow do we run AzCopy command in the terminal in the Azure portal?\nHere's the full code powershell script that I'm attempting to execute:\n```\n`# This simple PowerShell script will copy one or more Azure storage table from one location into another azure storage table\n#\n# Dependencies :\n#   https://learn.microsoft.com/en-us/azure/storage/common/storage-use-azcopy\n#   https://learn.microsoft.com/en-us/powershell/azure/overview?view=azps-1.6.0\n#\n# Usage :\n#        Copy-AzureStorageTable -SrcStorageName \"\" -SrcAccessKey \"\" -DstStorageName \"\" -DstAccessKey \"\" -IncludeTable All  \n#        Copy-AzureStorageTable -SrcStorageName \"\" -SrcAccessKey \"\" -DstStorageName \"\" -DstAccessKey \"\" -IncludeTable Table1,Table2,Table3  \n\nfunction Copy-AzureStorageTable\n{\n    param\n    (\n        [parameter(Mandatory=$true)]\n        [String]\n        $SrcStorageName,\n\n        [parameter(Mandatory=$true)]\n        [String]\n        $SrcAccessKey,\n\n        [parameter(Mandatory=$true)]\n        [String]\n        $DstStorageName,\n\n        [parameter(Mandatory=$true)]\n        [String]\n        $DstAccessKey,\n\n        [parameter(Mandatory=$true)]\n        [String[]]\n        $IncludeTable\n    )\n\n    # Check if logged in\n    Azure-Login\n\n    # Source Account Storage Parameters\n    $SrcContext = New-AzureStorageContext -StorageAccountName $SrcStorageName -StorageAccountKey $SrcAccessKey\n    $SrcBaseUrl = \"https://\" + $SrcStorageName + \".table.core.windows.net/\"\n\n    # Destination Account Storage Parameters\n    $DstContext = New-AzureStorageContext -StorageAccountName $DstStorageName -StorageAccountKey $DstAccessKey\n    $DstTempContainer = \"temptable\"\n    $DstBlobUrl = \"https://\" + $DstStorageName + \".blob.core.windows.net/$DstTempContainer\"\n    $DstTableUrl = \"https://\" + $DstStorageName + \".table.core.windows.net\"\n\n    # Create container in destination blob\n    Write-Host \"$DstTempContainer is not existing in $DstStorageName...\"\n    Write-Host \"Creating container $DstTempContainer in $DstStorageName...\"\n    New-AzureStorageContainer -Name $DstTempContainer -Permission Off -Context $DstContext\n\n    # Get all tables from source\n    $SrcTables = Get-AzureStorageTable -Name \"*\" -Context $SrcContext\n    foreach($table in $SrcTables)\n    {\n        $TableName = $table.Name                \n        Write-Host \"Table $TableName\"\n\n        # Validate if copy all table from source\n        # Validate if table name is included in our list\n        if(!$IncludeTable.Contains(\"All\") -and !$IncludeTable.Contains($TableName))\n        {\n           Write-Host \"Skipping table $TableName\"\n           return\n        }\n                \n        Write-Host \"Migrating Table $TableName\"      \n        $SrcTableUrl = $SrcBaseUrl + $TableName\n\n        # Copy Table from source to blob destination. As far as I know there is way no way to copy table to table directly.\n        # Alternatively, we will copy the table temporaryly into destination blob.\n        # Take note to put the actual path of AzCopy.exe\n        Write-Host \"Start exporting table $TableName...\"\n        Write-Host \"From    : $SrcTableUrl\"\n        Write-Host \"To      : $DstBlobUrl/$TableName\"\n\n        AzCopy /Source:$SrcTableUrl `\n                          /Dest:$DstBlobUrl/$TableName `\n                          /SourceKey:$SrcAccessKey `\n                          /Destkey:$DstAccessKey\n   \n        # Get the newly created blob\n        Write-Host \"Get all blobs in $DstTempContainer...\"\n        $CurrentBlob = Get-AzureStorageBlob -Container $DstTempContainer -Prefix $TableName -Context $DstContext\n\n        # Loop and check manifest, then import blob to table\n        foreach($blob in $CurrentBlob)\n        {\n            if(!$blob.Name.contains('.manifest'))\n            {\n                return\n            }\n\n            $manifest = $($blob.Name).split('/')[1]\n\n            Write-Host \"Start importing $TableName...\"\n            Write-Host \"Source blob url : $DstBlobUrl/$TableName\"\n            Write-Host \"Dest table url  : $DstTableUrl/$TableName\"           \n            Write-Host \"Manifest name   : $manifest\"\n                \n            # Import blob to table. Insert entity if missing and update entity if exists\n            AzCopy /Source:$DstBlobUrl/$TableName `\n                              /Dest:$DstTableUrl/$TableName `\n                              /SourceKey:$DstAccessKey `\n                              /DestKey:$DstAccessKey `\n                              /Manifest:$manifest `\n                              /EntityOperation:\"InsertOrReplace\"            \n        }\n    }\n\n    # Delete temp table storage after export and import process\n    Write-Host \"Removing $DstTempContainer from destination blob storage...\"\n    Remove-AzureStorageContainer -Name $DstTempContainer -Context $DstContext -Force\n}\n\n# Login\nfunction Azure-Login\n{\n    $needLogin = $true\n\n    Try \n    {\n        $content = Get-AzureRmContext\n\n        if ($content) \n        {\n            $needLogin = ([string]::IsNullOrEmpty($content.Account))\n        } \n    } \n    Catch \n    {\n        if ($_ -like \"*Login-AzureRmAccount to login*\") \n        {\n            $needLogin = $true\n        } \n        else \n        {\n            throw\n        }\n    }\n\n    if ($needLogin)\n    {\n        Login-AzureRmAccount\n    }\n}\n`\n```",
      "solution": "Azure Portal cloud shell shows to be using AzCopy version 10.6.1 as of 2021.11.10. The ability to copy between tables has been removed after version 7.3.\n\nYou need to run the script from a machine where you can download the older version of AzCopy.",
      "question_score": 3,
      "answer_score": 1,
      "created_at": "2021-11-10T21:24:06",
      "url": "https://stackoverflow.com/questions/69919761/the-term-azcopy-is-not-recognized-as-a-name-of-a-cmdlet-function-script-file"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 79039266,
      "title": "Creating multiple function apps with one Flex Consumption plan",
      "problem": "I'm attempting to create some function apps using a flex consumption plan.\nCurrently, multiple of my function apps are deployed to a single \"consumption\" app service plan, so I thought I'd be able to do the same with FC.\nI'm able to create the first function app in the FC plan like this (which creates the plan):\n`az functionapp create --resource-group $rg --name $fnName --storage-account $sa --runtime dotnet-isolated --runtime-version 8.0 --flexconsumption-location \"uksouth\"`\nThen, I attempt to create the second function app in the same plan like this:\n`az functionapp create --resource-group $rg --name $fnNameTwo --storage-account $saTwo --runtime dotnet-isolated --runtime-version 8.0 --plan $flexConsumptionPlan`\nHowever, this fails with this error message:\n`There is already a site linked to the specified Flex Consumption Plan serverfarm [name_here]. There can only be one site per Flex Consumption serverfarm`.\nI can't find this anywhere in the documentation for Flex Consumption. Is this a bug? Or will I need to use a single server farm per function app? What about scaling?\nI get the same issue when I try to deploy with Bicep.\nAny help, advice or documentation links would be much appreciated.\nThanks!",
      "solution": "`There is already a site linked to the specified Flex Consumption Plan serverfarm. There can only be one site per Flex Consumption serverfarm`.\n\nThe above message is not exactly an error. It is a limitation of flex consumption plan.\nLimitation:\n```\n`Two or more function apps cannot share the same flex consumption app plan.\n`\n```\nAs detailed here in the video, Flex consumption plan doesn't share a plan with two function apps unlike standard consumption plan. You need a create a new flex consumption location every time you create a new function app.\nI have tried to achieve your requirement using bicep and CLI but could not be able to deploy another function app in the same flex plan as shown below.\n\n`Flex plan` has an advantage of scaling up the instances automatically based on the functions executing in an app and also added a special feature of `vnet integration` in this flex consumption plan. Flex consumption plan settings are also configured at the app level automatically.\nRefer MSDoc for the relevant information on flex consumption hosting.\nI have tried creating and deploying two function apps in different flex consumption plans and was able to perform the operation successfully.\n`az functionapp create --resource-group Jahnavi --name newapsj --storage-account jahnavia8c2 --runtime dotnet-isolated --runtime-version 8.0 --flexconsumption-location \"uksouth\"\n`\n\n`az functionapp create --resource-group Jahnavi --name newapsjah1 --storage-account storenewjhsd --runtime dotnet-isolated --runtime-version 8.0 --instance-memory 4096 --flexconsumption-location \"NorthEurope\"\n`\n\nNote: If you still want to deploy two or more apps in the same plan, you need to go with a specific app service farm rather than using the flex consumption.",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2024-09-30T13:58:12",
      "url": "https://stackoverflow.com/questions/79039266/creating-multiple-function-apps-with-one-flex-consumption-plan"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 75641421,
      "title": "Can&#39;t deploy public Docker hub image to Azure Container instances",
      "problem": "When deploying a new Container instance from the jaegertracing/all-in-one:latest image, using this simple test:\n```\n`az container create -g Observabilty --name test --image jaegertracing/all-in-one:latest \n`\n```\nI get this error\n```\n`(InaccessibleImage) The image 'jaegertracing/all-in-one:latest' in container group\n'test' is not accessible. Please check the image and registry credential.\nCode: InaccessibleImage\n`\n```\nWhen I do it locally, it works fine, using for example:\n```\n`docker pull jaegertracing/all-in-one:latest\n`\n```\nAnyone who can help me figure out why it does not work?\nDeploying other public Docker Hub images to ACI works fine, like:\n```\n`az container create -g Observabilty --name test2 --image grafana/grafana:latest\n`\n```",
      "solution": "You can follow below approach to push public Docker hub image to Azure Container Instances.\nI also getting same error when I tried to push the same image to Azure Container Instances.\n\nAs far I know, there is an issue with particular registry.\nIf you want to use same image, use below steps.\nStep 1: Pull the same image to local as below.\n```\n`docker pull jaegertracing/all-in-one:latest\ndocker images\n`\n```\n\nChange the Tag once you pull the image to local as below.\n```\n`docker tag jaegertracing/all-in-one venkatv1206/all-in-one:latest ```\n\n`\n```\n\nNote: venkatv1206 is my docker registry username.\n\nPublish same image to your personal Docker Hub as below.\n`docker push venkatv1206/all-in-one `\n\nOnce push image to Docker hub, verify the same in docker hub as below.\n\nNow I tried to push same image to Azure Container Instances using Azure CLI, it got deployed successfully.\n\n```\n`az container create -g  --name test --image venkatv1206/all-in-one:latest \n`\n```\n\nWhen I check the same in Azure portal, it got created.",
      "question_score": 3,
      "answer_score": 4,
      "created_at": "2023-03-05T11:00:09",
      "url": "https://stackoverflow.com/questions/75641421/cant-deploy-public-docker-hub-image-to-azure-container-instances"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 67654041,
      "title": "Issue with ) when using Azure CLI to set Azure Function app Configurations",
      "problem": "I published an app using Azure CLI with command\n```\n`func azure functionapp publish [my-app-name] --nozip\n`\n```\nNow I want to update the configuration of the app to connect to the Azure Key Vault and get secrets from the Vault. So, I am running this command\n```\n`az functionapp config appsettings set --name [my-app-name] --resource-group [my-app-res-group] --settings \"PublicKey=@Microsoft.KeyVault(VaultName=[vault-name];SecretName=[secret-name])\"\n`\n```\nthis returns an error like this\n```\n`request failed: Error occurred in request., RetryError: HTTPSConnectionPool(host='management.azure.com', port=443): Max retries exceeded with url: /subscriptions/[my-sub-guid]/resourceGroups/[my-app-res-group]/providers/Microsoft.Web/sites/[my-app-name]/config/appsettings?api-version=2019-08-01 (Caused by ResponseError('too many 500 error responses',))\n`\n```\nBut the command work fine and publish the setting to the Azure except it publish not\n```\n`PublicKey=@Microsoft.KeyVault(VaultName=[vault-name];SecretName=[secret-name])\n`\n```\nBut\n```\n`PublicKey=@Microsoft.KeyVault(VaultName=[vault-name];SecretName=[secret-name]\n`\n```\nWhats the problem with closing ) and what can I do to overcome this issue.\nP.S. I know I can do this both from Azure Portal, Visual Studio and VS Code but it's critical for me to do this using commandline tool!",
      "solution": "You can have a look at this wiki around quoting issues with PowerShell:\n\nAzure CLI - Quoting issues with PowerShell\n\nTo make it work you have few options:\n\nAdd additional double quotes for force powershell to treat the argument as a literal:\n```\n`az functionapp config appsettings set --name [my-app-name] --resource-group [my-app-res-group] --settings `\"\"PublicKey=@Microsoft.KeyVault(VaultName=[vault-name];SecretName=[secret-name])\"`\"\n`\n```\n\nUse `--%` to stop PowerShell from parsing the argument and escape double quotes\n```\n`az --% functionapp config appsettings set --name [my-app-name] --resource-group [my-app-res-group] --settings \"PublicKey=@Microsoft.KeyVault(VaultName=[vault-name];SecretName=[secret-name])\"\n`\n```",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2021-05-22T22:46:18",
      "url": "https://stackoverflow.com/questions/67654041/issue-with-when-using-azure-cli-to-set-azure-function-app-configurations"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 72832142,
      "title": "Azure CLI creating a new branch from a task",
      "problem": "I'm tring to automate task and branch creation on Azure boards- but am stuggling to programtically create a branch, once the task is created.\nI'm using the Azure/Azure Devops extensions in PowerShell, but can't see anything in the docs that would replicate the 'create branch' link pictured below:\n\nAny help appreciated",
      "solution": "To programmatically create a branch, here are two methods :\nAz CLI : run\n```\n`az repos ref create --name refs/heads/{branch name} --object-id {Id of the object to create the reference from} --organization https://dev.azure.com/{org name} --project {project name} --repository {repos name}\n`\n```\nRest API :\n\nGet the repository ID in project setting >> your repo or use REST API Repositories - List and use REST API Refs - List with `filter=` to get the `oldObjectId` for your specific branch:\n```\n`GET https://dev.azure.com/{organization}/{project}/_apis/git/repositories/{repositoryId}/refs?filter=heads/master&api-version=5.1\n`\n```\n\nUse the Initial commit (Create a new branch) to create a branch from a specific branch with the following Request Body.\n\n```\n`{\n  \"refUpdates\": [\n    {\n      \"name\": \"refs/heads/{DefineNewBranchName}\",\n      \"oldObjectId\": \"{oldObjectId}\"\n    }\n  ],\n  \"commits\": [\n    {\n      \"comment\": \"Initial commit.\",\n      \"changes\": [\n        {\n          \"changeType\": \"add\",\n          \"item\": {\n            \"path\": \"/readme.md\"\n          },\n          \"newContent\": {\n            \"content\": \"My first file!\",\n            \"contentType\": \"rawtext\"\n          }\n        }\n      ]\n    }\n  ]\n}\n`\n```\n\nNext, you could link the work item with the existing Branch by using the Rest API: Work Items - Update.\n```\n`PATCH https://dev.azure.com/{organization}/{project}/_apis/wit/workitems/{id}?api-version=5.1\n`\n```\nRequest Body:\n\n```\n`[\n  {\n    \"op\": \"add\",\n    \"path\": \"/relations/-\",\n    \"value\": {\n      \"rel\": \"ArtifactLink\",\n      \"url\": \"vstfs:///Git/Ref/{ProjectID}/{RepoId}/GB{BranchName}\",\n      \"attributes\": {\n        \"name\": \"Branch\",\n        \"comment\": \"test link branch\"\n      }\n    }\n  }\n]\n`\n```\n\nHere is a similar ticket about your question.",
      "question_score": 3,
      "answer_score": 4,
      "created_at": "2022-07-01T18:21:50",
      "url": "https://stackoverflow.com/questions/72832142/azure-cli-creating-a-new-branch-from-a-task"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 72564166,
      "title": "How to log in to Azure using az cli from a Gitlab CI runner?",
      "problem": "I have generated a zip file of a Node.JS-based web app in Gitlab, and I am trying to deploy it as an Azure \"web app\" using `az webapp deploy`. This works fine on my local machine where I am logged in, but I can't for the life of me figure out how I can log in to Azure from the Gitlab runner, so that I can run that same command. I've tried:\n\nUsing the Publish Profile (already need to be logged in for that!)\nCreating a managed identity with roles on the app (but I don't have access to AD)\nCreating the managed system identity in the app's \"Identity\" pane (can't find any associated password?!)\nGenerating a JWT token to store in Gitlab as described in this question (I don't have access to the App Registrations functionality)\n\nI don't want to use Azure to rebuild the application using the webhook system, I already have a known-working ZIP package that I want to deploy. My only hangup is logging in.\nHow can I log in to Azure -- i.e. what incantations do I have to provide to `az login` -- from a Gitlab CI runner, in order to deploy my website from a zipped Gitlab artifact to the App Service?\n(note: I am a teacher and trying to figure this out for my students; it is possible that I am working with a somehow-limited Azure but my local IT doesn't support us for this and of course neither will Microsoft.)",
      "solution": "If you cannot access the app registrations as discussed in a similar question and have no federation configured, your only options are to use a username and password (e.g. a user's username and password to authenticate to AAD), use a device code flow, or self-host your GitLab runner on Azure with a managed identity.\nUsing username and password\nTo use username is password is straightforward:\n```\n`az login --tenant $YOUR_TENANT_ID -u $YOUR_USERNAME -p $YOUR_PASSWORD\n`\n```\nHowever, this may not be possible if you normally do not login to Azure using a username and password (for example, you use OAuth or other federated login for the Azure portal and users have no passwords set). In which case, you will need to use the device code flow.\nUsing device code\nTo use device code flow, you will need to monitor the job output, copy the URL shown, and login from your browser every time your job runs. In your job, add the following:\n```\n`az login --tenant $YOUR_TENANT_ID --use-device-code\n`\n```\nIn the job output you will see a message similar to the following:\n\nTo sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code YOUR-CODE-WILL-APPEAR-HERE to authenticate\n\nCopy the code from the message, open your browser to the device login page and enter the code to allow your job to proceed.\nNote: It is possible for organizations to disable this login method, in which case you will see an error when trying to login this way.\nSelf-hosting GitLab runner on Azure with a managed identity\nLastly, if you're not able to use any of the above methods, you can deploy the GitLab runner to Azure itself as an application that uses a managed identity (for example on AKS, ACI, or on a VM with a managed identity).\nFor example, you can configure a shell runner on an Azure VM. Azure VMs with a managed identity will not require `az login` to perform az cli commands.\n\nCreating the managed system identity in the app's \"Identity\" pane (can't find any associated password?!)\n\nThe reason you can't find any associated password is because managed identities can only be leveraged from Azure services -- for example, Azure VMs using a managed identity are able to use az cli without logging in.",
      "question_score": 3,
      "answer_score": 4,
      "created_at": "2022-06-09T19:08:07",
      "url": "https://stackoverflow.com/questions/72564166/how-to-log-in-to-azure-using-az-cli-from-a-gitlab-ci-runner"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 70931843,
      "title": "az pipelines runs list - how to provide multiple pipeline-ids using a variable",
      "problem": "For `az pipelines` command, how do I provide multiple pipeline ids via variable?\nThis works:\n```\n`az pipelines runs list --branch master --pipeline-ids 95 96\n`\n```\nThis throws parser error since the ids are concatenated as a string, but the parameter expects integer values:\n```\n`$vals = \"95 96\"\naz pipelines runs list --branch master --pipeline-ids $vals\n`\n```\nError:\n```\n`argument --pipeline-ids: invalid int value: '95 96'\n`\n```\nWhat I am trying to do is get a list of all pipeline ids, and pass it all at once, like this:\n```\n`$pipelines = az pipelines list --query \"[].{Name:name, Id:id}\" | ConvertFrom-Json\n$pipelineIds = \"\"\nforeach ($row in $pipelines) {$pipelineIds = $pipelineIds + \" \" + $row.Id}\naz pipelines runs list --branch master --query-order FinishTimeAsc --pipeline-ids $pipelineIds\n`\n```",
      "solution": "I found a simpler solution using my code above - use the `--output tsv` parameter.\n```\n`$pipelineIds = az pipelines list --query \"[].{Id:id}\" --output tsv\naz pipelines runs list --branch master --query-order FinishTimeAsc --pipeline-ids $pipelineIds\n`\n```",
      "question_score": 3,
      "answer_score": 2,
      "created_at": "2022-01-31T20:36:19",
      "url": "https://stackoverflow.com/questions/70931843/az-pipelines-runs-list-how-to-provide-multiple-pipeline-ids-using-a-variable"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 74290131,
      "title": "Resetting and Appending to Client Secrets on Service Principals in Azure Active Directory using Azure CLI does not reflect in the Portal",
      "problem": "This is either a bug or there is a different place where I can access these records. Here is the scenario:\nI create a new app registration using the CLI:\n```\n`az ad sp create-for-rbac --name sp-name --role Contributor --years 2 --scope /subscriptions/xxx-xxx-xxx -o json\n`\n```\nI can now see this app registration along with the secret reflected in the Azure portal. Testing access with the provided credentials work as expected.\nHere is where things get strange...\nI append a new Client Secret to this Service Principal by using the --append flag and give it a custom display name along with a different expiration time:\n```\n`az ad sp credential reset --id xxx-xxx-xxx --end-date 2023-12-31 --display-name test-name --append \n`\n```\nI get back the record for this new Client Secret along with the password to use. I test access using this password and it works. So it does exist. I go to the Azure Portal > Active Directory > App Registrations > sp-name > Certificates & Secrets > Client Secrets and all I see is the original Client Secret created with the display name of rbac.\nThinking there may be a caching issue I waited over 12 hours and I still do not see this new Client Secret anywhere on this SP. But I can use it and it works!\nI also tried to reset the existing Client Secret (without the append flag) by calling:\n```\n`az ad sp credential reset --id xxx-xxx-xxx --end-date 2023-12-31 --display-name rbac\n`\n```\nAnd I get back a new password that works. But in the portal it still shows the password hint for the old password and the expiration data has not updated! Again I gave it 12+ hours and still no update.\nWhat is also strange is BOTH the original and the new password WORK! What if I needed to do a reset due to a leak?\nI have done this a number of times with the exact same results. Tried resetting existing Client Secrets as well as appending new ones. In both cases the data in the portal never reflects the new or updated info for Client Secrets created via the CLI.\nIt does not make sense that there would be no way to have a record of these secrets in the portal. Especially when we may need to find them years down the line. Can anyone enlighten me as to why this is the case?\nI may also submit this as a bug. Will update if I hear back from that pursuit.\nUPDATED\nUsing the CLI I can get back the correct info:\n```\n`az ad sp credential list --id xxx-xxx-xxx\n`\n```\nThe new as well as the reset Client Secrets are both there and they reflect the correct password hints as well as expirations. So perhaps this is a portal bug.\nBut this still does not explain why the original password still works over 12 hours later. That one is shown in the portal but not in the CLI.\nUPDATE 2\nI filed feedback/reports for both the Azure Portal (for the UI not refreshing) as well as with AAD (For the ability to use old passwords after being reset).\nHere are the links to both of these submissions. I could not find a proper bug reporting system so looks like these are more like \"feature requests\". If anyone can upvote these and/or provide additional comments maybe we can get some eyes on this from Microsoft:\nAzure Portal Bug\nActive Directory Request\nIf anyone has a better place to post these let me know",
      "solution": "You're creating service principal secrets. What Azure Portal displays are application secrets. They're the same type of object and serve the same purpose but are stored in different places. The application is mostly a data model while the service principal is the object that gets authenticated and authorized. The latter represents the application in any given tenant.\nIf you want to update Azure AD application secrets, you can use the AzureAD PowerShell module or the MS Graph API or one of its SDK.",
      "question_score": 3,
      "answer_score": 2,
      "created_at": "2022-11-02T14:39:10",
      "url": "https://stackoverflow.com/questions/74290131/resetting-and-appending-to-client-secrets-on-service-principals-in-azure-active"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 69283369,
      "title": "Deploying resources using bicep",
      "problem": "Trying to deploy resources on Azure for this we are using bicep from microsoft.\nFor the execution of the code I am  using visual studio code insider.\nNote This is an example which I am posting here.\nCode is as follows\n```\n`    resource stg 'Microsoft.Storage/storageAccounts@2019-06-01' = {\n  name: 'uniquestorage001' // must be globally unique\n  location: 'eastus'\n  kind: 'Storage'\n  sku: {\n    name: 'Standard_LRS'\n  }\n}\n`\n```\nat the terminal we use the following command to build it\nbicep build main.bicep\nI get the below error message\n```\n`bicep: The term 'bicep' is not recognized as a name of a cmdlet, function, script file, or executable program.\nCheck the spelling of the name, or if a path was included, verify that the path is correct and try again\n`\n```\nI have installed the bicep extension.\nI am really not sure what can be done further kindly help\n.",
      "solution": "You can follow this documentation to install bicep:\nInstall Bicep tools\nYou need to install Azure CLI then you will be able to install bicep:\n```\n`az bicep install\n`\n```\nTo build you bicep file you can then use:\n```\n`az bicep build --file main.bicep\n`\n```\nAlso you don't need to build your bicep file before deploying it, AZ CLI allow you to deploy directly your bicep file\n```\n`az deployment group create --resource-group \"my resource group name\" --template-file \".\\main.bicep\"\n`\n```",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2021-09-22T13:32:20",
      "url": "https://stackoverflow.com/questions/69283369/deploying-resources-using-bicep"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 69239102,
      "title": "OS Type Conflict running Azure CLI command from PowerShell",
      "problem": "I am running an Azure CLI command in a Windows 10 Professional PowerShell script and I receive this error:\n```\n`(Conflict) Run command OS type 'Windows' does not match the target OS Linux.\n`\n```\nPowerShell version:\n```\n`Major  Minor  Build  Revision\n-----  -----  -----  --------\n5      1      19041  1237\n`\n```\nThe failing PowerShell script:\n```\n`$ResourceGroup= \"Development\"\n$VmName = \"ubuntu-test\"\n\n az vm run-command invoke `\n--resource-group $ResourceGroup `\n--name $VmName `\n--command-id RunPowerShellScript `\n--scripts \"ufw disable\"\n`\n```\nNote: The ` character is the backtick. The one on the same key as the tilde ~\nThe same command without line continuation backticks works:\n```\n`az vm run-command invoke --resource-group Development --name ubuntu-test --command-id RunShellScript --scripts \"ufw disable\"\n`\n```\nIf I do a Write-Host the output is a single line with the correct arguments minus the quotes around the --script command.\n```\n`Write-Host az vm run-command invoke `\n--resource-group $ResourceGroup `\n--name $VmName `\n--command-id RunPowerShellScript `\n--scripts \"ufw disable\"\n\naz vm run-command invoke --resource-group Development --name ubuntu-test --command-id RunPowerShellScript --scripts ufw disable\n`\n```\nThe documentation for the AZ CLI invoke command mentions nothing about setting the OS Type.\naz VM run-command invoke",
      "solution": "I think the use of line-continuations (``` at the very end of lines) is incidental to your problem.\nApart from the use of variables vs. literals, the crucial difference between your multi-line command and your working single-line command is:\n`--command-id RunPowerShellScript` vs. `--command-id RunShellScript`.\nIt looks like the VM you're targeting is a Linux machine, and that `--command-id RunPowerShellScript` isn't supported there, whereas `--command-id RunShellScript` is.\n`az vm run-command list ...` can apparently be used to discover supported `--command-id` values.",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2021-09-19T01:01:57",
      "url": "https://stackoverflow.com/questions/69239102/os-type-conflict-running-azure-cli-command-from-powershell"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 67147720,
      "title": "What endpoint should I provide when updating advanced filters with &quot;az eventgrid system-topic event-subscription&quot;?",
      "problem": "I've tried to update advanced filter of a data factory blobevent trigger via `az eventgrid system-topic event-subscription update`.\nIt asks for an endpoint (actually this is facultative in the documentation), but if i don't put it i get :\n\nInvalid event subscription request: Supplied URL is invalid. It cannot\nbe null or empty and should be a proper HTTPS URL like\nhttps://www.example.com.\n\nThis is my command:\n```\n`az eventgrid system-topic event-subscription update \n--system-topic-name $systemtopicname \n--name $topicName \n-g $ResourceGroup \n--endpoint $endpoint \n--advanced-filter data.api StringIn CreateFile PutBlob CopyBlob\n`\n```\nI have checked the documentation about this endpoint and it is said to be the webhook endpoint (https://learn.microsoft.com/fr-fr/cli/azure/eventgrid/system-topic/event-subscription?view=azure-cli-latest)\n\nEndpoint where EventGrid should deliver events matching this event\nsubscription. For webhook endpoint type, this should be the\ncorresponding webhook URL. For other endpoint types, this should be\nthe Azure resource identifier of the endpoint. It is expected that the\ndestination endpoint to be already created and available for use\nbefore executing any Event Grid command.\n\nBut it does not work .\n\nDeployment failed. Correlation ID:\n95e4fab5-163e-48ab-8cb2-b23432516e53. Webhook validation handshake\nfailed for [webwook end point provided in the topic]. Http POST\nrequest failed with response code Unknown. For troublehooting, visit\nhttps://aka.ms/esvalidation.\n\nI've also tried `az eventgrid event-subscription update` without more success!\nAny observation or suggestion would be great, thanks in advance !",
      "solution": "the az command for updating an event subscription requires a full endpoint url included its query parameters.\nUse the  az eventgrid system-topic event-subscription show command with an optional argument [--include-full-endpoint-url {false, true}] to obtain the full endpoint url for your $endpoint variable.\nNote, that the REST APIs for updating (PATCH) an event subscription can be done only for advanced filtering properties.",
      "question_score": 3,
      "answer_score": 2,
      "created_at": "2021-04-18T12:53:02",
      "url": "https://stackoverflow.com/questions/67147720/what-endpoint-should-i-provide-when-updating-advanced-filters-with-az-eventgrid"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 77971561,
      "title": "How to Fix Azure CLI task that Used Github Actions and is giving me Resource Not Found Errors",
      "problem": "I'm trying to update a Github Actions Script that publishes to Azure Web Apps and I added a Private Link to the Web App in question - causing me to substantially update the Script. But I'm still seeing errors.\nI initially saw an error addressing the fact that my app uses a private link and as a result, I can no longer deploy the same way I previously been doing. The Article is here: https://azure.github.io/AppService/2021/03/01/deploying-to-network-secured-sites-2.html\nHere is a portion of the Github Actions Script:\n```\n`  deploy:\n    runs-on: ubuntu-latest\n    needs: build\n    environment:\n      name: 'Production'\n      url: ${{ steps.deploy-to-webapp.outputs.webapp-url }}\n    \n    steps:\n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n      - name: Download artifact from build job\n        uses: actions/download-artifact@v2\n        with:\n          name: java-app\n\n      - name: Zip the app contents\n        uses: papeloto/action-zip@v1\n        with:\n          files: app.jar\n          dest: app.zip\n\n      - name: Set SAS token expiration\n        run: echo \"expiry=`date -u -d \"$EXPIRY_TIME\" '+%Y-%m-%dT%H:%MZ'`\" >> $GITHUB_ENV\n\n      - name: Azure CLI script\n        uses: azure/CLI@v1\n        with:\n          azcliversion: 2.19.1\n          inlineScript: | \n            az extension add --name webapp\n            echo \"Added Extension\"\n            az storage container create -n $CONTAINER --account-name $ACCOUNT --resource-group $BASE_GROUP\n            echo \"Created Container\"\n            az storage blob upload      -f app.zip --resource-group $BASE_GROUP   --account-name $ACCOUNT -c $CONTAINER -n $ACCOUNT \n            echo \"Blob Upload Step Completed\"\n            ZIP_URL=$(az storage blob generate-sas --full-uri --permissions r --expiry ${{ env.expiry }} --resource-group $BASE_GROUP --account-name $ACCOUNT -c $CONTAINER -n $ACCOUNT | xargs)\n            echo \"ZIP_URL Created\"\n            az webapp deploy --name $WEBAPP --resource-group $TEST_GROUP --type zip --src-url  $ZIP_URL --async false\n            echo \"Deployment Completed\"\n            az storage container delete -n $CONTAINER --account-name $ACCOUNT\n`\n```\nAnd here is the output I'm currently seeing:\n```\n`Run azure/CLI@v1\nStarting script execution via docker image mcr.microsoft.com/azure-cli:2.19.1\nWARNING: The installed extension 'webapp' is in preview.\nAdded Extension\n\nWARNING: There are no credentials provided in your command and environment, we will query for the account key inside your storage account. \nPlease provide --connection-string, --account-key or --sas-token as credentials, or use `--auth-mode login` if you have required RBAC roles in your command. For more information about RBAC roles in storage, visit https://docs.microsoft.com/en-us/azure/storage/common/storage-auth-aad-rbac-cli. \nSetting the corresponding environment variables can avoid inputting credentials in your command. Please use --help to get more information.\nERROR: Client-Request-ID=a4d42790-c7ab-11ee-b92c-0242ac110002 Retry policy did not allow for a retry: Server-Timestamp=Sat, 10 Feb 2024 00:30:50 GMT, Server-Request-ID=b66b9e8f-901e-0075-6bb8-5bd530000000, HTTP status code=404, Exception=The specified resource does not exist. ErrorCode: ResourceNotFoundResourceNotFoundThe specified resource does not exist.RequestId:b66b9e8f-901e-0075-6bb8-5bd530000000Time:2024-02-10T00:30:51.5358190Z.\nERROR: The specified resource does not exist. ErrorCode: ResourceNotFound\nResourceNotFoundThe specified resource does not exist.\nRequestId:b66b9e8f-901e-0075-6bb8-5bd530000000\nTime:2024-02-10T00:30:51.5358190Z\nError: Error: az cli script failed.\ncleaning up container...\nMICROSOFT_AZURE_CLI_(number)_CONTAINER\n\nError: az cli script failed.\n`\n```\nThe issues occur in the final step. Could the messages on Credentials being missing as seen in the early lines of the output be related to the Resource Not Found Error? If so, How can I ensure that when the CLI Step Runs, authentication works correctly and I don't see the Credential message? If Not, why isn't it seeing the Storage Account? I'm confident it exists.\nNotes: The Storage Account is in one resource group and the web app is in a different resource group. I have a Service Principal created and referenced in the Azure Login step that has the contributor for both resource groups. In theory, the Azure Login step should help the Azure CLI Script step authenticate and verify the existence of that storage account. Clearly, at least one of these is not happening.\nI also added echo statements to the CLI Script, which is how I know the `az storage container create -n $CONTAINER --account-name $ACCOUNT --resource-group $BASE_GROUP` command is what is causing me issues.",
      "solution": "How to Fix Azure CLI Task That Uses GitHub Actions and Gives Resource Not Found Errors\n\nI agree with Azeem's comment. To use GitHub Action for Azure CLI, you need to use Azure's latest version.\nScript:\n` deploy:\n    runs-on: ubuntu-latest\n    needs: build\n    environment:\n      name: 'Production'\n      url: ${{ steps.deploy-to-webapp.outputs.webapp-url }}\n    \n    steps:\n      - name: Azure Login\n        uses: azure/login@v1\n        with:\n          creds: ${{ secrets.AZURE_CREDENTIALS }}\n\n      - name: Download artifact from build job\n        uses: actions/download-artifact@v2\n        with:\n          name: java-app\n\n      - name: Zip the app contents\n        uses: papeloto/action-zip@v1\n        with:\n          files: app.jar\n          dest: app.zip\n\n      - name: Set SAS token expiration\n        run: echo \"expiry=`date -u -d \"$EXPIRY_TIME\" '+%Y-%m-%dT%H:%MZ'`\" >> $GITHUB_ENV\n\n      - name: Azure CLI script\n        uses: azure/CLI@v1\n        with:\n          azcliversion: 2.56.0\n          inlineScript: | \n            az extension add --name webapp\n            echo \"Added Extension\"\n            az storage container create -n $CONTAINER --account-name $ACCOUNT --resource-group $BASE_GROUP\n            echo \"Created Container\"\n            az storage blob upload -f app.zip --resource-group $BASE_GROUP --account-name $ACCOUNT -c $CONTAINER -n $ACCOUNT \n            echo \"Blob Upload Step Completed\"\n            ZIP_URL=$(az storage blob generate-sas --full-uri --permissions r --expiry ${{ env.expiry }} --resource-group $BASE_GROUP --account-name $ACCOUNT -c $CONTAINER -n $ACCOUNT | xargs)\n            echo \"ZIP_URL Created\"\n            az webapp deploy --name $WEBAPP --resource-group $TEST_GROUP --type zip --src-url $ZIP_URL --async false\n            echo \"Deployment Completed\"\n            az storage container delete -n $CONTAINER --account-name $ACCOUNT\n`\nYou can use the `azcliversion: 2.56.0` or, if you remove the azcliversion argument, it will automatically take the latest CLI version.\nReference:\nRelease notes & updates \u2013 Azure CLI | Microsoft Learn",
      "question_score": 3,
      "answer_score": 1,
      "created_at": "2024-02-10T01:59:20",
      "url": "https://stackoverflow.com/questions/77971561/how-to-fix-azure-cli-task-that-used-github-actions-and-is-giving-me-resource-not"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 75875385,
      "title": "DevOps Azure CLI Task - Granting Admin Consent to App Registration throws error",
      "problem": "I'm hoping that someone can shed some light on this because I'm a little bit stuck.\n....\nI have an Azure CLI task in a DevOps Release Pipeline.\nThis is running using a Service Principal which is a member of the Application Administrators group.\nWhen I run the following command ...\n```\n`az ad app permission admin-consent --id $(Variables.SharePointAppRegAppId)\n`\n```\nI get an error message:\n```\n`ERROR: Forbidden({\"message\":\"Forbidden\",\"httpStatusCode\":\"Forbidden\",\"xMsServerRequestId\":null,\"clientData\":{\"errorCode\":\"MsaUserWithNoAccessToTenant\",\"localizedErrorDetails\":null,\"operationResults\":null,\"timeStampUtc\":\"AAAAA\",\"clientRequestId\":\"BBBBB\",\"internalTransactionId\":\"CCCCC\",\"tenantId\":null,\"userObjectId\":\"DDDDD\",\"exceptionType\":\"Exception\"},\"stackTrace\":null})\n`\n```\nI initially thought that it might be permissions based - that maybe it doesn't have sufficient permissions to perform this task, but according to this Microsoft article (https://learn.microsoft.com/en-us/azure/active-directory/manage-apps/grant-admin-consent?pivots=portal#prerequisites)\n\nTo grant tenant-wide admin consent, you need:\n\nAn Azure AD user account with one of the following roles:\n\nGlobal Administrator or Privileged Role Administrator, for granting consent\nfor apps requesting any permission, for any API.\nCloud Application Administrator or Application Administrator, for granting consent for apps requesting any permission for any API, except Azure AD Graph or\nMicrosoft Graph app roles (application permissions).\nA custom\ndirectory role that includes the permission to grant permissions to\napplications, for the permissions required by the application.\n\nNow - the error is otherwise saying \"MsaUserWithNoAccessToTenant\" but I'm already using this same Service Principal to actually create and deploy the entire environment using Pulumi - including creating and setting up new instances, and creating brand new AAD App registrations in the same tenant.\nFor reference - here is the YAML task definition\n```\n`- task: AzureCLI@2\n  displayName: 'Grant Admin Consent to AAD App Registration'\n  inputs:\n    azureSubscription: 'appreg-infra'\n    scriptType: bash\n    scriptLocation: inlineScript\n    inlineScript: |\n      az ad app permission admin-consent --id $(Variables.SharePointAppRegAppId)\n`\n```",
      "solution": "I tried to reproduce the same in my environment and got below results:\nI added DevOps service principal and one user account named `Sri` to Application Administrator Group like below:\n\nIn my case, I tried to grant admin consent to SharePoint permissions of below application via DevOps Azure CLI Task:\n\nWhen I ran DevOps Azure CLI Task to grant admin consent, I got same error as you like below:\n\nWhen I tried to run same commands by logging as service principal via CLI locally, I got same error like below:\n```\n`az login --service-principal -u  -p  --tenant  --allow-no-subscriptions\naz ad app permission admin-consent --id \n`\n```\nResponse:\n\nNote that, granting admin consent requires `Azure AD user account` with one of the Administrator roles.\n\nTo resolve the issue, you need to sign in with user account having admin privileges instead of service principal.\nNow, I signed in with Azure AD user account `Sri` which is a member of Application Administrator group by running below CLI commands and got response like this:\n```\n`az login -u  -p  --tenant  --allow-no-subscriptions\naz ad app permission admin-consent --id \n`\n```\nResponse:\n\nTo confirm that, I checked the same in Portal where admin consent is granted successfully in the application like below:",
      "question_score": 3,
      "answer_score": 1,
      "created_at": "2023-03-29T11:25:10",
      "url": "https://stackoverflow.com/questions/75875385/devops-azure-cli-task-granting-admin-consent-to-app-registration-throws-error"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 70154510,
      "title": "Azure CLI doesn&#39;t recognize resource group",
      "problem": "So I'm new on Azure and got some problems with the CLI on the portal. After creating an AKS service using the UI, I cannot find it in the CLI and get an error message as shown below. Am I missing an obscure setting that filters resources? I can't even find my resource group.\nChecked the spelling multiple times, obv.\nAlso checked this Resource not found..., which is again for very obscure queries, whereas mine is extremely simple.\nAny help would be appreciated!\n```\n`(ResourceGroupNotFound) Resource group 'WebPlatformResource' could not be found.\nCode: ResourceGroupNotFound\nMessage: Resource group 'WebPlatformResource' could not be found.\n`\n```",
      "solution": "Thank you @Niels Uitterdijk , As discussed i am posting it as an answer to help other community members for the similar issue .\n\nMessage: Resource group 'yourresourcegroup' could not be found.\n\nThe above error occurs if we have multiple subscriptions, set your subscription first and then try:\n\nTo list all subscriptions -  `az account list --output table`\nTo set your subscription -    `az account set --subscription \"My Demos\"`\n\nFor more information please refer this MS DOC .",
      "question_score": 2,
      "answer_score": 11,
      "created_at": "2021-11-29T13:16:37",
      "url": "https://stackoverflow.com/questions/70154510/azure-cli-doesnt-recognize-resource-group"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 69161904,
      "title": "Cannot assign Azure Role for cosmos db",
      "problem": "I am trying to assign an identity a role to read/write to cosmos db. I run this command:\n```\n`az role assignment create \\\n--assignee  \\\n--role \"00000000-0000-0000-0000-000000000002\" \\\n--scope \"/subscriptions//resourceGroups//providers/Microsoft.DocumentDB/databaseAccounts/\"\n`\n```\nThis is the error I get back:\n```\n`The specified role definition with ID '00000000000000000000000000000002' does not exist.\n`\n```\nI have tried with the role name to no avail. I have tried the GUI, but this role is not visible anywhere there.\nHow can I assign this role?",
      "solution": "The RBAC on Azure Cosmosdb is built similar to Azure RBAC where there is more granular control on the data operations instead of Azure resource management. The permission model describes in detail.\nDuring implementations where SDK are used to interact with the dataplane (e.g, writing data or reading data), the application should be provided with granular data level permissions. Data plane level permission cannot be given from the portal.\nFollowing command provides \"data contributor\" permissions on the \"container1\" within the database but only \"data reader\" on \"container2\" within the same database\n```\n`az cosmosdb sql role assignment create --account-name ${{ variables.cosmosdbAccountName }} --resource-group ${{ variables.resourceGroupName }} --role-definition-name \"Cosmos DB Built-in Data Contributor\" --scope \"/dbs/${{ variables.cosmosdbAccountDatabaseName }}/colls/${{ variables.cosmosdbContainerOneName }}\" --principal-id $(umiObjectId)\n\naz cosmosdb sql role assignment create --account-name ${{ variables.cosmosdbAccountName }} --resource-group ${{ variables.resourceGroupName }} --role-definition-name \"Cosmos DB Built-in Data Reader\" --scope \"/dbs/${{ variables.cosmosdbAccountDatabaseName }}/colls/${{ variables.cosmosdbContainerTwoName }}\" --principal-id $(umiObjectId)\n`\n```\nAgain above example only shows usage of built-in CosmosDB Data Plane RBAC, it is good practice to have custom roles for more fine grained access within each container.\n\nNOTE: Azure CosmosDB data containers are not Azure Resources, meaning cannot be created by Azure Resource Model (ARM). So this permission model fulfills the authorization need with many security benefits",
      "question_score": 2,
      "answer_score": 9,
      "created_at": "2021-09-13T13:32:15",
      "url": "https://stackoverflow.com/questions/69161904/cannot-assign-azure-role-for-cosmos-db"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 66025763,
      "title": "Azure.Security.KeyVault.Secrets: az is not recognized as an internal or external command",
      "problem": "I'm developing a web application using .Net Core and leveraging Azure services (Virtual Machine Windows Server 2016, Database PostgreSQL and Azure Key Vault). Below is my .csproj file:\n```\n`\n\n  \n    netcoreapp2.1\n    3.1\n    .......................................\n    1.2.5.0\n    1.2.5.0\n    1.2.5.0\n  \n\n  \n    none\n    false\n  \n\n  \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  \n\n`\n```\nLeveraging the Azure.Security.KeyVault.Secrets library I'm trying to retrieve a secret stored inside Azure Key Vault like this:\n```\n`string keyVaultUri = $\"https://{KeyVaultName}.vault.azure.net\";\n_secretClient = new SecretClient(new Uri(keyVaultUri), new DefaultAzureCredential());\nKeyVaultSecret secret = _secretClient.GetSecret(secretName);\n`\n```\nThe GetSecret method throws the following exception:\n```\n`Azure CLI authentication failed due to an unknown error. az is not recognized as an internal or external command,\n   at Azure.Identity.AzureCliCredential.RequestCliAccessTokenAsync(Boolean async, String[] scopes, CancellationToken cancellationToken)\n   at Azure.Identity.AzureCliCredential.GetTokenImplAsync(Boolean async, TokenRequestContext requestContext, CancellationToken cancellationToken)\n   at Azure.Identity.CredentialDiagnosticScope.FailWrapAndThrow(Exception ex)\n   at Azure.Identity.AzureCliCredential.GetTokenImplAsync(Boolean async, TokenRequestContext requestContext, CancellationToken cancellationToken)\n   at Azure.Identity.AzureCliCredential.GetToken(TokenRequestContext requestContext, CancellationToken cancellationToken)\n   at Azure.Identity.DefaultAzureCredential.GetTokenFromSourcesAsync(TokenCredential[] sources, TokenRequestContext requestContext, Boolean async, CancellationToken cancellationToken)\n   at Azure.Identity.DefaultAzureCredential.GetTokenImplAsync(Boolean async, TokenRequestContext requestContext, CancellationToken cancellationToken)\n   at Azure.Identity.CredentialDiagnosticScope.FailWrapAndThrow(Exception ex)\n   at Azure.Identity.DefaultAzureCredential.GetTokenImplAsync(Boolean async, TokenRequestContext requestContext, CancellationToken cancellationToken)\n   at Azure.Identity.DefaultAzureCredential.GetToken(TokenRequestContext requestContext, CancellationToken cancellationToken)\n   at Azure.Security.KeyVault.ChallengeBasedAuthenticationPolicy.AuthenticateRequestAsync(HttpMessage message, Boolean async, AuthenticationChallenge challenge)\n   at Azure.Security.KeyVault.ChallengeBasedAuthenticationPolicy.ProcessCoreAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\n   at Azure.Security.KeyVault.ChallengeBasedAuthenticationPolicy.Process(HttpMessage message, ReadOnlyMemory`1 pipeline)\n   at Azure.Core.Pipeline.HttpPipelinePolicy.ProcessNext(HttpMessage message, ReadOnlyMemory`1 pipeline)\n   at Azure.Core.Pipeline.RetryPolicy.ProcessAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\n   at Azure.Core.Pipeline.RetryPolicy.ProcessAsync(HttpMessage message, ReadOnlyMemory`1 pipeline, Boolean async)\n   at Azure.Core.Pipeline.RetryPolicy.Process(HttpMessage message, ReadOnlyMemory`1 pipeline)\n   at Azure.Core.Pipeline.HttpPipelinePolicy.ProcessNext(HttpMessage message, ReadOnlyMemory`1 pipeline)\n   at Azure.Core.Pipeline.HttpPipelineSynchronousPolicy.Process(HttpMessage message, ReadOnlyMemory`1 pipeline)\n   at Azure.Core.Pipeline.HttpPipelinePolicy.ProcessNext(HttpMessage message, ReadOnlyMemory`1 pipeline)\n   at Azure.Core.Pipeline.HttpPipelineSynchronousPolicy.Process(HttpMessage message, ReadOnlyMemory`1 pipeline)\n   at Azure.Core.Pipeline.HttpPipelinePolicy.ProcessNext(HttpMessage message, ReadOnlyMemory`1 pipeline)\n   at Azure.Core.Pipeline.HttpPipelineSynchronousPolicy.Process(HttpMessage message, ReadOnlyMemory`1 pipeline)\n   at Azure.Core.Pipeline.HttpPipeline.Send(HttpMessage message, CancellationToken cancellationToken)\n   at Azure.Core.Pipeline.HttpPipeline.SendRequest(Request request, CancellationToken cancellationToken)\n   at Azure.Security.KeyVault.KeyVaultPipeline.SendRequest(Request request, CancellationToken cancellationToken)\n   at Azure.Security.KeyVault.KeyVaultPipeline.SendRequest[TResult](RequestMethod method, Func`1 resultFactory, CancellationToken cancellationToken, String[] path)\n   at Azure.Security.KeyVault.Secrets.SecretClient.GetSecret(String name, String version, CancellationToken cancellationToken)\n   at Project.CloudAzureKeyVault.GetKeySecret(String secretName) in C:\\Project\\Project\\Project\\NetCoreWrappers\\CloudAzureKeyVault.cs:line 31\n`\n```\nHow can I solve the problem?",
      "solution": "I solved the problem by installing the Azure CLI and logging in as described here: https://learn.microsoft.com/cli/azure/install-azure-cli-windows?tabs=azure-cli",
      "question_score": 2,
      "answer_score": 6,
      "created_at": "2021-02-03T11:37:25",
      "url": "https://stackoverflow.com/questions/66025763/azure-security-keyvault-secrets-az-is-not-recognized-as-an-internal-or-external"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 77955224,
      "title": "WinError 193 %1 is not a valid Win32 application. az bicep",
      "problem": "When I try to run `az bicep version` I'm getting this\nerror\n```\n`The command failed with an unexpected error. Here is the traceback:\n[WinError 193] %1 is not a valid Win32 application\nTraceback (most recent call last):\n  File \"D:\\a\\_work\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\knack/cli.py\", line 233, in invoke\n  File \"D:\\a\\_work\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure/cli/core/commands/__init__.py\", line 664, in execute\n  File \"D:\\a\\_work\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure/cli/core/commands/__init__.py\", line 729, in _run_jobs_serially\n  File \"D:\\a\\_work\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure/cli/core/commands/__init__.py\", line 698, in _run_job\n  File \"D:\\a\\_work\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure/cli/core/commands/__init__.py\", line 334, in __call__\n  File \"D:\\a\\_work\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure/cli/core/commands/command_operation.py\", line 121, in handler\n  File \"D:\\a\\_work\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure/cli/command_modules/resource/custom.py\", line 4601, in show_bicep_cli_version\n  File \"D:\\a\\_work\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure/cli/command_modules/resource/_bicep.py\", line 94, in run_bicep_command\n  File \"D:\\a\\_work\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure/cli/command_modules/resource/_bicep.py\", line 267, in _get_bicep_installed_version\n  File \"D:\\a\\_work\\1\\s\\build_scripts\\windows\\artifacts\\cli\\Lib\\site-packages\\azure/cli/command_modules/resource/_bicep.py\", line 305, in _run_command\n  File \"subprocess.py\", line 548, in run\n  File \"subprocess.py\", line 1026, in __init__\n  File \"subprocess.py\", line 1538, in _execute_child\nOSError: [WinError 193] %1 is not a valid Win32 application\n`\n```\nAnd the same error I have running all `az bicep ***` commands.\nI tried to reinstall azure cli. Did not help.\nI deleted py related paths from PATH env variables. That was a suggestion from some github issue page.",
      "solution": "The most likely cause of your error is that the bicep executable installed by Azure CLI is corrupted. See Issue #2364 on their repository.\nAs described in this comment you can clean up the `%USERPROFILE\\.azure\\bin` directory and run `az bicep install` to get it working.",
      "question_score": 2,
      "answer_score": 7,
      "created_at": "2024-02-07T14:40:00",
      "url": "https://stackoverflow.com/questions/77955224/winerror-193-1-is-not-a-valid-win32-application-az-bicep"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 76907275,
      "title": "Switch az login from Windows Account Manager back to Web Access manager",
      "problem": "Does any know what the detailed process is to switch between the Windows Account Manager and WAM for logging into the `az` cli?\nWindows 11 has (what I believe to be called) a Windows Account Manager in the Settings app. It is possible to add multiple accounts used by other apps. I have seen the limit is 4 accounts can be added.\nThere is a feature in the `az` cli that allows users to select an account from at max 4 registered in this Windows setting. I used this feature once before and was unable to switch back to the Web Account Manager (WAM) for the `az` cli and would like to understand what the process is to switch between them.\n\nWhen logging into Azure with the WAM using the `az` cli, you will get this confirmation screen once your login is completed.",
      "solution": "I used this feature once before and was unable to switch back to the Web Account Manager (WAM) for the `az` cli and would like to understand what the process is to switch between them.\n\nTo switch from Windows Account Manager to Web Account Manager in PowerShell, here are the steps.\n\nIf you run the below command the default authentication goes to `Windows Account Manager`\n\nNote: If the value set to `True`, it indicates Windows-based authentication, which is registered in Windows Local Accounts\n\n```\n`  az config set core.allow_broker=true  \n     az account clear  \n     az login\n`\n```\nOutput of above command:\n\nEven if you set the authentication to `Windows Account Manager`, you can still log in with `Web-Based Authentication` by using `--use-device-code`.\n\n```\n`   az login --use-device-code\n`\n```\nOutput of above command:\n\nIf you want to permanently change the default authentication to `web account manager`, set the value to `false`.\n\n```\n`az config set core.allow_broker=false \naz account clear \naz login\n`\n```\nOutput of above command:",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2023-08-15T17:39:00",
      "url": "https://stackoverflow.com/questions/76907275/switch-az-login-from-windows-account-manager-back-to-web-access-manager"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 79569313,
      "title": "No such file or directory: &#39;/home/vsts/work/_temp/.azclitask/bin/bicep&#39; when doing az deployment mg in an Azure DevOps pipeline",
      "problem": "When running the following commands in a Shell script called by the AzureCLI@2 task of an Azure DevOps pipeline:\n```\n`az bicep install\naz deployment mg what-if --name ${NAME:0:63} --location $LOCATION --template-file $TEMPLATEFILE --parameters $PARAMETERS --management-group-id $MGID\n`\n```\nI have the following error:\n```\n`ERROR: [Errno 2] No such file or directory: '/home/vsts/work/_temp/.azclitask/bin/bicep'\n`\n```\nThe `az bicep install` command ran successfully. Does anybody know what could be wrong?",
      "solution": "It\u2019s a bug with latest Azure CLI (2.71) It\u2019s also broken with Github pipelines\n_binary_from_path by itself didn\u2019t work for me. This did:\n```\n`az bicep uninstall\naz config set bicep.use_binary_from_path=false\naz bicep install\n`\n```\nSource:\nhttps://github.com/Azure/azure-cli/issues/31189#issuecomment-2790370116",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2025-04-11T18:24:56",
      "url": "https://stackoverflow.com/questions/79569313/no-such-file-or-directory-home-vsts-work-temp-azclitask-bin-bicep-when-doi"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 73639797,
      "title": "Azure CLI IF on AZ Storage Blob Exists Results",
      "problem": "I have a usually reliable (but troublesome on one server) Azure Blob Storage automated backup process. I'd like my powershell script to retry the upload if for some reason it fails. I'm crafting an if statement (or a do while loop) when the file does not already exist in ABS. How do I capture the result of the Azure CLI call for AZ\nMy test attempt looks like this:\n```\n`if(az storage blob exists --account-name test --container-name test --name $name --sas-token $sasToken){\nEcho \"This is true\"\n}\nelse{\nEcho \"This is false\"\n}\n`\n```\nThe output of running the Azure CLI by itself is:\n```\n`{\n  \"exists\": true\n}\n`\n```\nI'm using too many languages these days, the syntax is always slightly different",
      "solution": "Capture the result of the Azure CLI call in a variable, something like `$answer = az storage blob exists ...`\nThen test the answer's 'exists' property after you have converted it from JSON\n```\n`if (($answer | ConvertFrom-Json).exists) {\n    Write-Host \"blob '$name' exists\"\n}\nelse {\n    Write-Host \"No blob called '$name' was found\"\n}\n`\n```",
      "question_score": 2,
      "answer_score": 4,
      "created_at": "2022-09-07T19:58:40",
      "url": "https://stackoverflow.com/questions/73639797/azure-cli-if-on-az-storage-blob-exists-results"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 79346057,
      "title": "how to install postgresql-client 17 on docker alpine (mcr.microsoft.com/azure-cli) using apk",
      "problem": "Im trying to install postgresql-client17\n```\n`FROM mcr.microsoft.com/azure-cli:2.9.1\n\nRUN apk update\nRUN apk add postgresql-client17\n`\n```\nI am getting the error:\n```\n` > [sa-cron 3/3] RUN apk add postgresql-client17:                                                                                                                    \n0.237 ERROR: unsatisfiable constraints:\n0.237   postgresql-client17 (missing):\n`\n```\nI have tried many combinations of `postgresql-client17` and `postgresql-client-17` and `postgresql-client17-2` and so...\nI get the same error. I must use this docer image:\n`mcr.microsoft.com/azure-cli:2.9.1`\nThanks",
      "solution": "You can change the Dockerfile as below:\n```\n`FROM mcr.microsoft.com/azure-cli:2.9.1\n\nRUN echo 'http://dl-cdn.alpinelinux.org/alpine/edge/main' > /etc/apk/repositories\nRUN apk update --allow-untrusted\nRUN apk upgrade --allow-untrusted\nRUN apk add postgresql17-client --allow-untrusted\n`\n```\nit should works.",
      "question_score": 2,
      "answer_score": 5,
      "created_at": "2025-01-10T15:39:37",
      "url": "https://stackoverflow.com/questions/79346057/how-to-install-postgresql-client-17-on-docker-alpine-mcr-microsoft-com-azure-cl"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 79090150,
      "title": "Use Az CLI without fetching subscriptions",
      "problem": "I need to log in via the Azure CLI with a predefined tenant (using either the tenant ID or tenant domain name, as shown in the example below). After logging in, I want to manually set the subscription in a pipeline or script, e.g:\n`az login --allow-no-subscriptions --tenant contoso.onmicrosoft.com\naz account set --subscription aabbccdd-1234-4567-8900-eb9ab9c0c010\n`\nThe problem is that I get the following output immediately after a successful login:\n`Retrieving subscriptions for the selection...\n\n[Tenant and subscription selection]\n`\nIt prompts the user to select a subscription. What I want is to continue without selecting a default subscription and let me set it with additional commands.\nSo far I have found this issue for the same purpose but I can't set any similar option in a PowerShell script, the solution is just for Azure CLI v2 pipelines:\nhttps://github.com/Azure/azure-cli/issues/17254",
      "solution": "Beginning with Azure CLI version 2.61.0, if you have access to multiple subscriptions, you're prompted to select an Azure subscription at time of login.\nIf want to disable the subscription selector feature, set the `core.login_experience_v2` configuration property to `off`(doc Subscription selector).\nIn addition, if you want no output other than errors and warnings, you can set `--output` as `none` for azure cli(doc None output format).\n```\n`az config set core.login_experience_v2=off\naz login --allow-no-subscriptions --tenant  --output none\naz account set --subscription aabbccdd-1234-4567-8900-eb9ab9c0c010\n`\n```\nThe output as below:\n\nThe `azure cli` above is interactive authentication method, it pops a web browser and ask to enter code. If you would like to run in DevOps pipeline, it requires non-interactive method, you can use service principal to login. Please refere to the doc content below:\n\n```\n`- task: PowerShell@2\n  inputs:\n    targetType: 'inline'\n    script: |\n      az login --service-principal -u  -p  --tenant  --output none\n      ......\n`\n```\nBTW, the AzureCLI@2 task in devops supports powershell script, besides the DevOps powershell task, it's recommended to use AzureCLI@2 task directly with option `visibleAzLogin: false`.",
      "question_score": 2,
      "answer_score": 5,
      "created_at": "2024-10-15T15:22:30",
      "url": "https://stackoverflow.com/questions/79090150/use-az-cli-without-fetching-subscriptions"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 79498128,
      "title": "Use same GUID in bicep templates and Azure Portal",
      "problem": "I'm deploying some RBAC roles for Service Principals and Users to access secrets from a Key Vault, at resource scope.\nWhen choosing the name, I build the GUID for the resource name using a combination of GUIDs that uniquely describes the assignment, that is, the roleId, the Service Principal Id, and the KeyVault's Id:\n`//# kvRoles.bicep\n@description('Assigns the Crypto Secrets user to the provided principal ID.')\nresource kvRoleAssignment 'Microsoft.Authorization/roleAssignments@2022-04-01' = {\n  name: guid(roleIds['Key Vault Secrets User'], principalId, keyVault.id)\n  scope: keyVault\n  properties: {\n    roleDefinitionId: roleIds['Key Vault Secrets User']\n    principalId: principalId\n    principalType: 'Service Principal'\n  }\n}\n`\nThis works well for first deployments and redeployments:\n`az deployment group create -g 'myGroup' -f 'kvRoles.bicep'\n`\nHowever, when these roles are already created via Azure Portal, the deployment of these RBAC roles fails with the usual `RoleAssignmentExists` error.\nAs explained in [AVM Question/Feedback]: Breaking Change - Role-Assignments name should be consistent & configurable #2008, this error is expected since Azure Portal deployed a RBAC assignment with the same scope, Service Principal and Role, but a different GUID in its `resource.name` property.\n\nExisting role assignments will run into errors of the type 'RoleAssignment already exists' IF the same combination of scope, principalId & roleDefinitionId was deployed using a different 'resource' name\n\nI want this template to be re-deployable even when the same role has been applied through command line or Azure Portal.\nWhat can I do so that this resource has the same GUID as those of Azure Portal or `azure-cli`?\nFor example, when I query the name of the resource I deploy with `azure-cli`, it's always the same:\n`az role assignment create \\\n  --assignee $userId \\\n  --role 'Key Vault Crypto User' \\\n  --scope \"/subscriptions/$subId/resourceGroups/$rgName/providers/Microsoft.KeyVault/vaults/$kvName\" \\\n  --query 'name'\n# name = \"0000404d-0000-0000-0000-0000b7b90000\"\n`",
      "solution": "I would suggest you create bicep similar as below:\n`resource kvRoleAssignment 'Microsoft.Authorization/roleAssignments@2022-04-01' = {\n  scope: keyVault\n  name: guid(.id, , kvSecretUserRole .id)\n  properties: {\n    roleDefinitionId: kvSecretUserRole.id\n    principalId: \n    principalType: 'ServicePrincipal'\n  }\n}\n\n@description('Key Vault Secrets User. see https://learn.microsoft.com/en-us/azure/role-based-access-control/built-in-roles/security#key-vault-secrets-user')\nresource kvSecretUserRole 'Microsoft.Authorization/roleDefinitions@2018-01-01-preview' existing = {\n  scope: subscription()\n  name: '4633458b-17de-408a-b874-0445c86b69e6'\n}\n`\nThe problem you are facing is because you re-generating guids and since the assignment already exists, it complains about it. However, your assignment previous and update can only work as update if the GUID (aka. name) is same.\nHandy reference MsDoc https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/scenarios-rbac#role-definition-id",
      "question_score": 2,
      "answer_score": 4,
      "created_at": "2025-03-10T14:23:54",
      "url": "https://stackoverflow.com/questions/79498128/use-same-guid-in-bicep-templates-and-azure-portal"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 74363084,
      "title": "Specify Revision weight for Azure Container Apps App during deployment",
      "problem": "right now i work on a pipeline to deploy our microservices to an azure-container-apps environment.\nThe deployment is done via azure-pipelines, since we use a TFS on prem i need to deploy new versions in a pipeline step with azure cli. For that i use the following command:\n```\n`az containerapp update \n   --name my-service \n   --resource-group  rg-sample \n   --image sample.azurecr.io/my-service:8440 \n   --min-replicas 1 \n   --max-replicas 10\n`\n```\nThis works perfectly new revisions get published and receive all the traffic, and that is exactly the problem im facing.\nI know i can activate revisions with the `az containerapp revision activate`, but the containerapp update command automatically activates the latest revision with a weight of 100%, at least that is what i can see when i review changes with the azure portal.\nIm looking for a way to deploy new revisions with azure cli, but with the limitation that the latest revision which was at 100% percent traffic before the deployment, stays there until i say via azure cli switch over to that revision.\nHas anyone an idea how to archive that?\nBest Erik",
      "solution": "If your app is in multiple revision mode, you can:\n`# Make sure your app is in multiple revision mode \n$ az containerapp revision set-mode \\\n  --name $APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --mode multiple\n\n# Get the current \"latestRevision\"\n$ LATEST_REVISION=$(az containerapp show \\\n  --name $APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --query properties.latestRevisionName)\n\n# Explicitly set 100% to the latestRevision by name\n$ az containerapp ingress traffic set \\\n  --name $APP_NAME \\\n  --resource-group $RESOURCE_GROUP \\\n  --revision-weight $LATEST_REVISION=100\n\n> [\n>   {\n>     \"latestRevision\": true, # New revisions will get 0% by default\n>     \"weight\": 0\n>   },\n>   {\n>     \"revisionName\": \"appname--84yjetr\",\n>     \"weight\": 100\n>   }\n> ]\n`",
      "question_score": 2,
      "answer_score": 4,
      "created_at": "2022-11-08T16:17:25",
      "url": "https://stackoverflow.com/questions/74363084/specify-revision-weight-for-azure-container-apps-app-during-deployment"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 73135803,
      "title": "Passing an Azure tag parameter to a Bicep template using Azure CLI",
      "problem": "I'm looking for a working example on how pass dynamic tags to a bicep deployment. I'm currently testing with a single tag, but if I can get it working, will move onto multiple tags per deployment.\nHere is the bicep file:\n```\n`param tagValues object = {}\nresource storageAccount 'Microsoft.Storage/storageAccounts@2021-09-01' = {\n  name: 'storage123x01'\n  location: westeurope\n  tags: tagValues\n  sku: {\n    name: 'Standard_LRS'\n  }\n  kind: 'StorageV2'\n  properties: {\n  allowBlobPublicAccess: false\n  networkAcls: {\n    defaultAction: 'Deny'\n    }\n  }\n}\n`\n```\nI can change the tagValues param on the bicep template to the following and it works:\n```\n`param tagValues object = {\n  commonTag1: 'commonValue1'\n}\n`\n```\nHowever, as the the tags are dependent on several factors during deployment, I need a way to dynamically assign when deploying the resource via Azure CLI on AzDO, rather than hardcoding it on the template. This is what my Azdo task looks like (For proof of concept purposes, I'm hardcoding the tag):\n```\n`- task: AzureCLI@2\n  displayName: \"Create Storage Account\" \n  inputs:\n    azureSubscription: $(SPN)\n    scriptType: 'ps'\n    scriptLocation: 'inlineScript'\n    inlineScript: |\n      az deployment group create `\n      --resource-group $(resourceGroup) `\n      --template-file $(storageAccountTemplate) `\n      --parameters `\n        tagValues=\"commonTag2`:` 'commonValue2'\"\n`\n```\nI've tried multiple things but I'm can't find any success and pretty much maxed out my knowledge.\nDoes anyone have any idea on how this can be achieved please?\nThanks.",
      "solution": "Thanks for confirming @Clumsyhands ,\nBased on this MICROSOFT DOCUMENTATION to add the multiple tags to the storage account/or any resource , For better approach we can specify them into a variable then pass the same in deployment in parameter as shown in below mentioned cli `cmdlts`;\n```\n`$tags=\"{'Owner':'Contoso','Cost Center':'2345-324'}\"\naz deployment group create --name addstorage  --resource-group myResourceGroup \\\n--template-file $bicepFile \\\n--parameters resourceName=abcdef4556 resourceTags=$tags\n`\n```",
      "question_score": 2,
      "answer_score": 4,
      "created_at": "2022-07-27T11:53:32",
      "url": "https://stackoverflow.com/questions/73135803/passing-an-azure-tag-parameter-to-a-bicep-template-using-azure-cli"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 67423741,
      "title": "Is there a way to filter by tier in azure blob storage",
      "problem": "I would like to list all the files stored in a particular tier. This is what I tried:\n```\n`az storage fs file list \\\n  --file-system 'cold-backup' \\\n  --query \"[?contains(properties.blobTier, 'Cold')==\\`true\\`].properties.blobTier\"\n`\n```\nBut it doesn't work. I also tried with \"blobTier\" only. No luck.\nThis is the error I get:\nInvalid jmespath query supplied for '--query': In function contains(), invalid type for value: None, expected one of: ['array', 'string'], received: \"null\"",
      "solution": "The command `az storage fs file list` is for ADLS Gen2 file system, there is no `blobTier` property in the output, so you could not query with it, also the `blobTier` should be `Cool` instead of `Cold`.\nIf you want to list the files filter with `blobTier`, you could use `az storage blob list`, it applies to blob storage, but it can also be used for ADLS Gen2 file system.\nSample:\n```\n`az storage blob list --account-name '' --account-key 'xxxxxx' --container-name 'cold-backup' --query \"[?properties.blobTier=='Cool']\"\n`\n```\n\nIf you want to output the `blobTier`, use `--query \"[?properties.blobTier=='Cool'].properties.blobTier\"` instead in the command.",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2021-05-06T20:06:53",
      "url": "https://stackoverflow.com/questions/67423741/is-there-a-way-to-filter-by-tier-in-azure-blob-storage"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 77897648,
      "title": "Use `az ssh vm` (AADSSHLoginForLinux) with Ansible",
      "problem": "I have deployed an Azure Linux VM and installed the AADSSHLoginForLinux VM extension.\nThis allows me to login to the VM using my Azure credentials, and allows me to configure role based access for my team using EntraID (Active Directory) groups. Any team member can log into the VM using the following command, without needing to mess with SSH keys, etc, and they will get the appropriate access (sudo or regular user) depending on what EntraID group they belong to, using the azure-cli ssh wrapper:\n`az ssh vm --ip 1.2.3.4\n`\n(Assuming they have previously run `az login` at some point.)\nNow I want to use this as the `ssh` command for Ansible, which will automatically allow anyone in the admin security group to deploy the playbook.\n`az ssh vm` will pass through ssh arguments supplied following `--`.\nFor example:\n`az ssh vm --ip 1.2.3.4 -- -p 23\n`\nSo it should be possible to wrap `az ssh vm` up in such a way that Ansible can use it.\nI have found the ssh_executable option for Ansible, but this expects a command, not a command with arguments, so I can't simply set it to `az ssh vm ...`.\nSo a wrapper script will be necessary.\nI have also determined that Microsoft do not supply an equivalent wrapper for `scp`, so this will need to be worked around.\nHow can I put all the pieces together to easily deploy Ansible playbooks using my Azure credentials and `az ssh`?",
      "solution": "Edit: PyPI release\nI've slightly adapted the Python wrapper below and published it on PyPI as az-ssh-wrapper. After installing, it provides the SSH wrapper command `az-ssh`, which can be used exactly like regular SSH, but will use `az ssh vm` behind the scenes.\nTL;DR:\n\n`pipx install az-ssh-wrapper`\nUse wrapper command `az-ssh`\n\nSee original answer below for details about using this with Ansible.\nOriginal answer\nThe first step is to create an SSH wrapper which will intercept the SSH arguments from Ansible and pass them through to `az ssh`.\nThis blog post describes how to do this for GCP IAP. I have adapted it to work with `az ssh`:\nI am using the following wrapper, adapted from the blog post above:\n`#!/bin/bash\n# ssh-wrapper.sh\n#\n# SSH Wrapper for az ssh\n#\n# We are using `az ssh vm --ip 1.2.3.4` to authenticate to VMs with\n# Azure Role Based Athentication. However, Ansible doesn't directly\n# support this.\n#\n# `az ssh vm` accepts additional SSH arguments, so this wrapper takes\n# arguments from Ansible, and passes them onto `az ssh vm`.\n\n# Wrapper adapted from here:\n# https://blg.robot-house.us/posts/ansible-and-iap/\n\n# Get last two arguments\nhost=\"${*: -2: 1}\"\ncmd=\"${*: -1: 1}\"\n\n# Filter out hard-coded Ansible SSH options.\n# At least one of these seems to break az ssh, but I haven't figured out which.\n# But it seems to work if you filter them all out as described in the blog linked above.\n# This may cause problems if you need to pass your own SSH arguments,\n# but for our use case it's OK.\n\n# Only accept the options starting with '--'\ndeclare -a opts\nfor s_arg in \"${@: 1: $# -2}\" ; do\n    if [[ \"${s_arg}\" == --* ]] ; then\n        opts+=(\"${s_arg}\")\n    fi\ndone\n\nexec az ssh vm --ip \"${host}\" -- \"${opts[@]}\" \"${cmd}\"\n`\nSave this script as `ssh-wrapper.sh` in the same directory as your Ansible playbook.\nNow, we need to configure the playbook to use the wrapper. We also need to configure Ansible to use `piped` transfer rather than `scp` or `sftp`. This will pipe files through SSH, so `scp` and `sftp` are not required.\nThe start of your playbook should look something like this:\n`---\n- name: Example\n  hosts: all\n  vars:\n    # Need piped transfer because az ssh vm doesn't support scp or sftp\n    ansible_ssh_transfer_method: piped\n    ansible_ssh_executable: ./ssh-wrapper.sh\n\n  tasks:\n    - name: Test\n      ansible.builtin.command: pwd\n`\nAssuming you have previously run `az login`, and are able to login to the VM with `az ssh login --ip 1.2.3.4`, you should be able to simply run the\nAnsible playbook as follows:\n`ansible-playbook playbook.yml -i 1.2.3.4,\n`\nEdit: Python version of wrapper\nThe following Python SSH wrapper has several advantages over the bash wrapper above:\n\nYou can wrap it in a Python package and pip install it\nIt knows what the valid SSH options are\nIt only removes options which are known to cause problems with `az ssh`.\n\n`#!/usr/bin/env python3\n\nimport getopt\nimport os\nimport shutil\nimport sys\n\ndef usage():\n    usage = \"\"\"\nSSH wrapper for az ssh\n\nUsage:\n\nThis wrapper emulates OpenSSH, but translates the arguments and\nsupplies them to az ssh so that it can be used by Ansible as the\nansible_ssh_executable.\n\nIt also filters out ControlMaster and ControlPersist options, as these\nappear to block for the duration of the specified ControlPersist value\nwhen passed to az ssh. See the following GitHub issue for details:\nhttps://github.com/Azure/azure-cli-extensions/issues/7285\n\nThis wrapper supports all arguments supported by OpenSSH 8.9p1:\n\n    az-ssh [-46AaCfGgKkMNnqsTtVvXxYy] [-B bind_interface]\n           [-b bind_address] [-c cipher_spec] [-D [bind_address:]port]\n           [-E log_file] [-e escape_char] [-F configfile] [-I pkcs11]\n           [-i identity_file] [-J [user@]host[:port]] [-L address]\n           [-l login_name] [-m mac_spec] [-O ctl_cmd] [-o option] [-p port]\n           [-Q query_option] [-R address] [-S ctl_path] [-W host:port]\n           [-w local_tun[:remote_tun]] destination [command [argument ...]]\n\nSee the ssh man page for details.\n\nExample:\n\n    az-ssh 1.2.3.4\n\"\"\"\n    print(usage)\n\ndef opt_filter(opt):\n    \"\"\"Filter out options which cause problems for az ssh\n\n    For some reason, setting the Control* options causes az ssh to hang\n    for the duration of ControlPersist\"\"\"\n    return not (opt[0] == \"-o\" and opt[1].startswith(\"Control\"))\n\ndef main():\n    options = \"46AaCfGgKkMNnqsTtVvXxYyB:b:c:D:E:e:f:I:i:J:L:l:m:O:o:p:Q:R:S:W:w:\"\n\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], options)\n        destination = args.pop(0)\n    except (getopt.GetoptError, IndexError) as err:\n        print(f\"Error: {err}\")\n        usage()\n        sys.exit(2)\n\n    az_path = shutil.which(\"az\")\n    # Work around quoting issue on Windows (still works on Linux)\n    az_path = f'\"{az_path}\"'\n\n    ssh_opts = []\n    for opt in filter(opt_filter, opts):\n        # Only keep truthy options. e.g.\n        # ('-t', '') --> ('t',)\n        # (Yes, this is important.)\n        ssh_opts += filter(lambda o: o, opt)\n\n    exec_args = [az_path, \"ssh\", \"vm\", \"--ip\", destination]\n    if ssh_opts or args:\n        exec_args.extend([\"--\", *ssh_opts, *args])\n\n    os.execvp(\"az\", exec_args)\n\nif __name__ == \"__main__\":\n    main()\n`",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2024-01-29T06:49:45",
      "url": "https://stackoverflow.com/questions/77897648/use-az-ssh-vm-aadsshloginforlinux-with-ansible"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 77419507,
      "title": "Trigger / queue build policy pipeline on ADO PR with Azure CLI",
      "problem": "In a repository on Azure DevOps (ADO), I have a build validation policy on my main branch that PRs which wish to merge into main must first complete a successful Azure pipeline run.\nI would like to use the Azure CLI to trigger this build validation pipeline.\nI know that I can trigger this pipeline with `az pipelines run` or `az pipelines build queue`, and point to my PR with the `--branch` argument as eg. `az pipelines build queue --branch \"refs/pull/123/merge\" --definition-id 456`.\nHowever, when I do so, the pipeline run doesn't count towards the PR's build validation. That is, even if my pipeline succeeds, it is not reflected in my PR, and I still can't merge my changes.\nHow can I trigger my pipeline with the Azure CLI, so that it counts towards my PR's build validation? I am looking for the Azure CLI equivalent to clicking the \"Queue\" button on my PR's pipeline (image taken from this comment):",
      "solution": "You need to use the `az repos pr policy` command group to achieve this.\nStart by determining the build validation evaluation ID associated with your PR. Note that this value changes on a per PR basis.\nYou can determine this value for your PR with:\n`az repos pr policy list --id  --query \"[?configuration.type.displayName=='Build'].evaluationId\"\n`\nYour evaluation ID will be a long alpha-numeric string, separated with hyphens. It'll look something like: `d2hr35yd-9fe0-y4t5-hb35-5een2cr04b2`.\nYou then need to pass this value to `az repos pr policy queue` as eg.\n`az repos pr policy queue --evaluation-id  --id \n`\nPutting these two steps together, and doing a little string manipulation to make things work, gives us:\n`# Your PR number here\npr_id=123\n\nbuild_pipeline_eval_id=$(\n  az repos pr policy list \\\n      --id $pr_id \\\n      --query \"[?configuration.type.displayName=='Build'].evaluationId | [0]\" \\\n      --out tsv\n)\naz repos pr policy queue --evaluation-id $build_pipeline_eval_id --id $pr_id\n`\nThis will now run your required build pipeline, against your PR, as if you had clicked the \"Queue\" button from the ADO UI, as desired.",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2023-11-03T21:22:51",
      "url": "https://stackoverflow.com/questions/77419507/trigger-queue-build-policy-pipeline-on-ado-pr-with-azure-cli"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 76884619,
      "title": "&#39;System&#39; is not a valid database edition in this version of SQL Server",
      "problem": "I'm trying to scale down an Azure SQL Database from `S0` to `Basic` but when I run:\n```\n` az sql db update -g MyResourceGroup -s MyServer -n MyDatabase --edition Basic --service-objective Basic\n`\n```\nI receive the error:\n```\n`(ProvisioningDisabled) 'System' is not a valid database edition in this version of SQL Server.\nCode: ProvisioningDisabled\nMessage: 'System' is not a valid database edition in this version of SQL Server.\n`\n```\nWhat is going on?",
      "solution": "If your are receiving that error then that database is associated with an Azure SQL Elastic Pool. The minimum service tier for a Basic Elastic Pool (DTU-model) is S0 as you can see in the pricing calculator and as you can see on Microsoft Documentation. You cannot have a basic tier database on a Basic Elastic Pool as the service tiers allowed for the type of pool are S0 to S12.",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2023-08-11T16:50:48",
      "url": "https://stackoverflow.com/questions/76884619/system-is-not-a-valid-database-edition-in-this-version-of-sql-server"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 74206100,
      "title": "Azure Availability test - A single &#39;hidden-link&#39; tag pointing to an existing AI component is required. Found none",
      "problem": "I am trying to create a url ping test for an app service hosted in azure through azure cli\n```\n`az monitor app-insights web-test create \n--location \"Australia East\" \n--tags 'hidden-link:/subscriptions/{subid}/resourceGroups/{rg}/providers/microsoft.insights/components/{appinsightname}'\n--description \"Ping web test alert for mytestwebapp\" \n--enabled true --frequency 900 \n--web-test-kind \"standard\" \n--locations Id=\"emea-au-syd-edge\" \n--defined-web-test-name \"my-webtest-my-component\" \n--http-verb \"GET\"  \n--request-url \"https://myurl.net/\" \n--retry-enabled true \n--synthetic-monitor-id \"my-webtest-my-component\" \n--timeout 120 \n--ssl-lifetime-check 100 \n--ssl-check true \n--resource-group \"{rgname}\" \n--name \"my-webtest-my-component\" \n`\n```\nI am getting \"(BadRequest) A single 'hidden-link' tag pointing to an existing AI component is required. Found none.\" I am not sure about how to format the hidden-link with resource id of app insight. not much documentations are found regarding this, any help would be appreciated",
      "solution": "Found the hidden-link property's format later, It should come under tags\n```\n`--tags hidden-link:/subscriptions/{subscriptionId}/resourceGroups/{ResourceGroupName}/providers/microsoft.insights/components/{appInsightName}=Resource\n`\n```",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2022-10-26T12:18:54",
      "url": "https://stackoverflow.com/questions/74206100/azure-availability-test-a-single-hidden-link-tag-pointing-to-an-existing-ai"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 73430089,
      "title": "Create Azure Web App fails saying it already exists",
      "problem": "I create resource-group :\n```\n`PS > az group create -l westus -n rg-appsvc\n`\n```\nThen I create app-service :\n```\n`PS > az appservice plan create --resource-group=rg-appsvc --name appsvc-plan-test --sku S1 \n`\n```\nThen I create web-service :\n```\n`PS > az webapp create --resource-group rg-appsvc  --plan appsvc-plan-test --name webapp-test            \n`\n```\n\nWebapp 'webapp-test' already exists. The command will use the existing\napp's settings. Unable to retrieve details of the existing app\n'webapp-test'. Please check that the app is a part of the current\nsubscription\n\n```\n`PS > az webapp list                                                                                     \n[]\n`\n```",
      "solution": "When you create a Web App, its name will be a subdomain of azurewebsites.net. Looks like the webapp-test name is already in use. Try using a different name.",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2022-08-20T22:52:05",
      "url": "https://stackoverflow.com/questions/73430089/create-azure-web-app-fails-saying-it-already-exists"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 73309758,
      "title": "Remove relation between Azure DevOps work items and commits programmatically",
      "problem": "I pushed an existing GIT repo to a new DevOps repo, inadvertently this linked all the commits with a #{number} on the message to the work item with that ID.\nI have successfully identified (via the REST API and the CLI) all the Work Items and the relationships to the commits but...\n\n`az boards work-item relation remove --id $workItemID --relation-type 'Artifact Link' --target-id $relationID --org $orgURL --yes` fails complaining that $relationID is not a valid work item, which is weird since relation type is Artifact Link so I don't understand why it's trying to fetch a work item.\n\nUsing the REST API seems rather risky because the request is done using the index of the relation; and not using an specific ID makes me very uncomfortable and I would need to validate all the changes, which is practically impossible for the amount of tickets that I'm touching.\n\nHow can I programmatically remove all these relationships with a sound approach? Preferably using the ID of the relationship",
      "solution": "Seems like the Azure Boards cli extension assumes that the targetId is a work item (like parent or child) and that other relationships are not supported). It does not say so flat out in the docs, but the only example given for relationship type is parent and child.\n\n--relation-type\nRelation type to create. Example: parent, child.\n\nI understand that the index based addressing is not ideal, but why would using the index of the relationship be a problem in practise?\nIf you start your script by fetching the workitem and checking for which index the relationship has you can then go ahead and remove that relationship with a workitem update.\nThe only reason I could see this would not work is if someone modifies the workitem in such a way that the index for the artifact link changes (like removing a relationship with a lower index) in between the get and update command, which seems highly unlikely given the short timeframe between the commands. Executing the script during off hours or an agreed time window where no other activity is allowed further lowers the risk.\nIf you still wish to validate that the change was carried out correct you could do that automatically as well in your script:\n\nAfter the first Get, save all relationships\nCarry out the update (removing the relationship to the commit)\nFetch the workitem again\nMake sure the only difference in relationship is that the commit relation has been removed. If not, issue a warning/exit the script etc.\n\nHere is a similar question which could give further insights: How to delete a work item relation (parent) from a child task work item via HTTP request to azure devops?",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2022-08-10T18:29:56",
      "url": "https://stackoverflow.com/questions/73309758/remove-relation-between-azure-devops-work-items-and-commits-programmatically"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 73276735,
      "title": "Unable to remove URL from Azure App Registrations",
      "problem": "I'm trying to remove a specific URL from Azure App Registrations. I tried the below command.\n```\n`az ad app update --id  --remove web-redirect-uris 0\n`\n```\nI used '0' (Index) as it doesn't allow us to delete the URL value. But it gives below error.\n```\n`Couldn't find 'web' in 'web.redirect'. Available options: []\n`\n```\nUPDATED\n```\n`az rest \\\n          --method PATCH \\\n          --uri \"https://graph.microsoft.com/v1.0/applications/\" \\\n          --headers 'Content-Type=application/json' \\\n          --body \u201c{web:{redirectUris: https://URL1}}\u201d\n\nunrecognized arguments: https://URL1}}\u201d\n`\n```\nNew\n```\n`az rest \\\n  --method \"delete\" \\\n  --uri \"https://graph.microsoft.com/v1.0/applications/\" \\\n  --headers \"{'Content-Type': 'application/json'}\" \\\n  --body \"{'web': 'redirectUris': [ 'https://URL1' ] }\"\n`\n```",
      "solution": "As per august 2022, it is not supported anymore (due to MS Graph Migration).\nFrom the documentation:\n\nGeneric update arguments `--add`, `--set` and `--remove` currently don't work. You may use `az rest` to directly call Microsoft Graph API for non-supported properties.\n\nYou can track the github issue here: Azure CLI cannot set values on nested properties.\nso in your case something like that should work\n```\n`az rest \\\n  --method \"patch\" \\\n  --uri \"https://graph.microsoft.com/v1.0/applications/\" \\\n  --headers \"{'Content-Type': 'application/json'}\" \\\n  --body \"{'web': 'redirectUris': [ 'https://URL1' ] }\"\n`\n```",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2022-08-08T12:52:39",
      "url": "https://stackoverflow.com/questions/73276735/unable-to-remove-url-from-azure-app-registrations"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 72792525,
      "title": "Unable to add key to Azure key-vault backed Databricks scope",
      "problem": "I am trying to create a keyvault backed scope in databricks. I am able to successfully create the scope but when I try to add a key to the scope I see the following error:\n```\n`Error: b'{\"error_code\":\"BAD_REQUEST\",\"message\":\"Cannot write secrets to Azure KeyVault-backed scope abc\"}'\n`\n```\nThese are steps I have followed and all commands were run on windows cmd:\n\nCreate key vault in Azure\nGenerate AAD token for databricks - `az account get-access-token --resource 2ff814a6-3304-4ab8-85cb-cd0e6f879c1d`\nAdd AAD token to environment variables on windows\nAdd AAD token to databricks cfg file on windows - `databricks configure --aad-token`\nCreate scope - `databricks secrets create-scope --scope abc --scope-backend-type AZURE_KEYVAULT --resource-id  --dns-name  --initial-manage-principal users`\nAdd key to scope - `databricks secrets put --scope abc --key abc-key`",
      "solution": "According to the documentation this is not possible:\n\nTo reference secrets stored in an Azure Key Vault, you can create a secret scope backed by Azure Key Vault. You can then leverage all of the secrets in the corresponding Key Vault instance from that secret scope. Because the Azure Key Vault-backed secret scope is a read-only interface to the Key Vault, the `PutSecret` and `DeleteSecret` Secrets API 2.0 operations are not allowed. To manage secrets in Azure Key Vault, you must use the Azure SetSecret REST API or Azure portal UI.\n\nUsing Az CLI, you could use the `az keyvault secret set` command.",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2022-06-28T22:04:04",
      "url": "https://stackoverflow.com/questions/72792525/unable-to-add-key-to-azure-key-vault-backed-databricks-scope"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 69003186,
      "title": "How can I specify an Azure app config value that contains an ampersand?",
      "problem": "I'm using Azure CLI to try to set an app config value to this URL:\n`az appconfig kv set --key \"mykey\" --value \"https://fake.com/action?param1=a&param2=b\" -n \"test\" --yes`\nI get the following result. Note that this is coming from the az command, not from the shell.\n```\n`Please specify config store name or connection string(suggested).\n'param2' is not recognized as an internal or external command,\noperable program or batch file.\n`\n```\nIs there some way to get az to take this URL as the value without having to resort to stupid stuff like URL encoding it? This seems broken to me.\nAlso note, the message `Please specify config store name or connection string(suggested).` is because it's failing to parse the command line properly because this is specified with -n. If I move the arguments around:\n`az appconfig kv set -n \"test\" --yes --key \"mykey\" --value \"https://fake.com/action?param1=a&param2=b\"`\nI now get this:\n```\n`{\n  \"contentType\": null,\n  \"etag\": \"zuspBqPBOHR1mXfcKCgORXHpAxB\",\n  \"key\": \"mykey\",\n  \"label\": null,\n  \"lastModified\": \"2021-08-31T17:39:14+00:00\",\n  \"locked\": false,\n  \"tags\": {},\n  \"value\": \"https://fake.com/action?param1=a\"\n}\n'param2' is not recognized as an internal or external command,\noperable program or batch file.\n`\n```\nWhich seems worse. It created the key value pair incorrectly then tried to run param2 as a command. WTF?",
      "solution": "Following one of the links from @d-m got me to this:\nhttps://github.com/Azure/azure-cli/blob/dev/doc/quoting-issues-with-powershell.md\nThat link fully explains it, but basically I need to use double quotes inside of single quotes because Powershell evaluates the arguments and then cmd evaluates them. So the single quotes are stripped off by powershell, then the double quotes are stripped by cmd and finally az gets the right argument.\nThis works:\n```\n`az appconfig kv set -n \"test\" --yes --key \"mykey\" --value '\"https://fake.com/action?param1=a&param2=b\"'\n{\n  \"contentType\": \"text/plain\",\n  \"etag\": \"XugiNgxa2I04w0gaG2OBh9Jcj75\",\n  \"key\": \"mykey\",\n  \"label\": null,\n  \"lastModified\": \"2021-08-31T18:20:44+00:00\",\n  \"locked\": false,\n  \"tags\": {},\n  \"value\": \"https://fake.com/action?param1=a&param2=b\"\n}\n`\n```\n```\n``\n```",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-08-31T19:42:54",
      "url": "https://stackoverflow.com/questions/69003186/how-can-i-specify-an-azure-app-config-value-that-contains-an-ampersand"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 68821054,
      "title": "How do you pass an object parameter into a json arm template as a hashtable?",
      "problem": "My variable is the following in powershell:\n```\n`$lcr=@{\"tierToCool\"=@{\"daysAfterModificationGreaterThan\"=1};\"tierToArchive\"=@{\"daysAfterModificationGreaterThan\"=2}}\n`\n```\nThen when I run the template using an az cli command to pass the variable as an object into my arm template:\n```\n`az deployment group create --subscription  --resource-group  --template-file  --parameters lcr=$lcr\n`\n```\nI get the following error:\n\nFailed to parse JSON: System.Collections.Hashtable\nError Detail: Expecting value: line 1 column 1 (char 0)\n\nIs there something wrong with the way I'm passing the parameter into the template or the way I'm formatting it? Any help is greatly appreciated.",
      "solution": "Building on the helpful comments:\n\n`az`, the Azure CLI, requires JSON as the `--parameters` arguments, i.e., a JSON string, not a hashtable.\n\nIt generally makes no sense to pass a hashtable as an argument to an external program, because doing so sends its string representation, which is - unhelpfully - the type name, `'System.Collections.Hashtable'`\n\nWhile `--parameters (@{ lcr = $lcr } | ConvertTo-Json -Compress)` should be enough to send the JSON representation of your hashtable, the sad reality is that, as of PowerShell 7.1, you additionally need to `\\`-escape the embedded `\"` characters, due to a long-standing bug in argument-passing to external programs.\n\nThe most robust way to do this is (if there are no escaped `\"` in the string, `-replace '\"', '\\\"'` is enough):\n```\n`--parameters ((@{ lcr = $lcr } | ConvertTo-Json -Compress) -replace '([\\\\]*)\"', '$1$1\\\"')\n`\n```\n\nIf you have a JSON string literal or JSON string stored in variable, use the following to pass it to an external program (if the string is stored in a variable `$var`, replace `'{ \"foo\": \"bar\" }'` with `$var`):\n```\n`someProgram ... ('{ \"foo\": \"bar\" }' -replace '([\\\\]*)\"', '$1$1\\\"')\n`\n```\n\nSee this answer for more information.\n\nTherefore:\n\n`az deployment group create --subscription  --resource-group  --template-file  --parameters ((@{ lcr = $lcr } | ConvertTo-Json -Compress) -replace '([\\\\]*)\"', '$1$1\\\"')\n`\nA general `ConvertTo-Json` pitfall: You may need to use the `-Depth` parameter for full to-JSON serialization, depending on how deeply nested your object graph is (not needed with your sample input) - see this post.",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2021-08-17T18:35:02",
      "url": "https://stackoverflow.com/questions/68821054/how-do-you-pass-an-object-parameter-into-a-json-arm-template-as-a-hashtable"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 68797647,
      "title": "Azure cli to filter Instances using tags",
      "problem": "I am trying to filter instances based on tags, but it is giving me all the instances present in the resource group. I need to list Instances which has a specific tag. I am using the below command to list instances that have `wknhscale == 'active'` tag, is there an issue with the command? Also is there any other efficient to achieve this?\n`az vm list --query '[?tags.wknhscale == 'active'].{Name:name, RG:resourceGroup}' -o table`\nI am looking for a simple query to fetch Instances with tags, like in gcp\n`gcloud compute instances list --project test --filter='labels.wknhscale:active AND name ~ .*wkn*' --sort-by=creationTimestamp --format='value(name,zone)'`",
      "solution": "I was able to query using az graph query.  Thanks, @azMantas\n```\n`az graph query -q \"Resources |  where type =~ 'Microsoft.Compute/virtualMachines' | where tags['wknhscale']=='active' |  where name startswith 'workernode' | project name | order by name asc\" | jq '.data[].name'\n`\n```",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2021-08-16T07:12:14",
      "url": "https://stackoverflow.com/questions/68797647/azure-cli-to-filter-instances-using-tags"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 68297251,
      "title": "Create Private Endpoint with Azure Cli in different resource group",
      "problem": "I have a resource group for my vnet (rg-private-vnet) and one for my webapp and sql server (rg-webapp). Now I want to create a private endpoint for my SQl server in the rg-webapp.\nThis works in case the private endpoint is created in the resource group from he vnet. But I want it to be located in the resource group of the sql server.\nI used:\n```\n` az network private-endpoint create --name $sqlPrivateEndpoint --resource-group $resourceGroupVnet --vnet-name $vnetName --subnet $sqlSubnetName --private-connection-resource-id $id --connection-name mySqlConnection  --group-id sqlServer\n`\n```\nIn case I use the rg-webapp I got the error:\n```\n`(InvalidResourceReference) Resource /subscriptions/XXX/[...} referenced by resource /subscriptions/XXX/[...] was not found. Please make sure that the referenced resource exists, and that both resources are in the same region.\n`\n```\nwith the rg-private-vnet it works. In the azure portal it is no problem to create the endpoint in the rg-webapp resource group. I don't see any more parameters to create it in a diffrent rg.",
      "solution": "According to the documentation you need to provide the resource id of the subnet to the `--subnet` parameter (instead of the subnet name) and skip the `--vnet-name` parameter if the subnet resides in a different resource group:\n\n`--subnet` Name or ID of an existing subnet. If name specified, also specify --vnet-name. If you want to use an existing subnet in other resource group or subscription, please provide the ID instead of the name of the subnet and do not specify the --vnet-name. (az network private-endpoint | Microsoft Docs)",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2021-07-08T09:23:24",
      "url": "https://stackoverflow.com/questions/68297251/create-private-endpoint-with-azure-cli-in-different-resource-group"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 68124147,
      "title": "Azure cli repository import fails with Operation returned a 400 status code",
      "problem": "What specific syntax and/or configuration needs to be changed below in order for an Azure CLI command to successfully import a private source repo from GitHub into a private destination repo in Azure Repos?\n\nCURRENT COMMAND AND ERROR RESPONSE:\n```\n`C:\\path\\to\\working\\directory>az repos import create --git-source-url https://github.com/ValidGitHubOrgName/valid-gh-repo-name --repository ValidAzureReposDestinationRepoName --organization https://dev.azure.com/ValidOrgName --project ValidProjectName --requires-authorization  \nGit Password / PAT:  \nConfirm Git Password / PAT:  \nClientRequestError: Operation returned a 400 status code.  \n`\n```\nWHAT WORKS:\nWhen we use the above to import a public repository from GitHub into a private Azure Repos repo, the above completes without error as along as we of course remove the `--requires-authorization` flag.\nWHAT FAILS:\nHowever the above fails when we try to import a private GitHub repository with the full syntax shown above.\nWe have tried this not only with a valid GitHub password but also with a valid Azure DevOps Personal Access token that we give when prompted as shown above.\n\nDo we need to add configuration in order for the import to work without error?\nAnd also, how can we make sure the import command executes without an interactive request of credentials?\n\nThis needs to run in automation without an interactive human user.\nThe documentation here does not seem to include the instructions we require.",
      "solution": "I can also reproduce your issue on my side, to use Azure CLI import a private GitHub repo to DevOps via a non-interactive way, please follow the steps below.\n1.Navigate to the `Project Settings` in the devops portal -> `Service connections` ->  `New service connection` -> `Other Git`(Not `GitHub`) -> create the connection with your github username and password.\n\n2.Use REST API - `Endpoints - Get Service Endpoints By Names` or CLI `az devops service-endpoint list` to get the service connection, then note down the `id`(there are not only one `id`, use the correct one as below).\n\n3.Then run the command as below, pass `id` in step 2 to `--git-service-endpoint-id`, also make sure you have created the devops repo and it is empty.\n```\n`az repos import create --git-source-url https://github.com/Joyw1/privaterepo.git --repository testrep6 --git-service-endpoint-id 3c04f8a9-43c8-40cb-baf5-90faf292b9ab --organization https://dev.azure.com/xxxx --project testpro1 --requires-authorization\n`\n```\n\nCheck the result:\n\nUpdate:\nTo create the `Other Git` service connection in an automatic way, you could powershell to call the REST API - Endpoints - Create directly.\nSample:\n```\n`$MyPat = ''\n$B64Pat = [Convert]::ToBase64String([System.Text.Encoding]::UTF8.GetBytes(\":$MyPat\"))\n\n$header = @{\n    'Authorization' = 'Basic ' + $B64Pat\n    'Content-Type' = 'application/json'\n}\n\n$body = '{\n  \"data\": {},\n  \"name\": \"MyNewServiceEndpoint\",\n  \"type\": \"git\",\n  \"url\": \"https://github.com/Joyw1/privaterepo.git\",\n  \"authorization\": {\n    \"parameters\": {\n      \"username\": \"joyw1\",\n      \"password\": \"xxxxxx\"\n    },\n    \"scheme\": \"UsernamePassword\"\n  },\n  \"isShared\": false,\n  \"isReady\": true,\n  \"serviceEndpointProjectReferences\": [\n    {\n      \"projectReference\": {\n        \"id\": \"53f719f7-2968-4035-8e56-163f239b4161\",\n        \"name\": \"testpro1\"\n      },\n      \"name\": \"MyNewServiceEndpoint\"\n    }\n  ]\n}'\n\nInvoke-RestMethod -Method Post -Uri https://dev.azure.com/v-joyw/_apis/serviceendpoint/endpoints?api-version=6.0-preview.4 -Headers $header -Body $body\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-06-25T02:40:56",
      "url": "https://stackoverflow.com/questions/68124147/azure-cli-repository-import-fails-with-operation-returned-a-400-status-code"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 79564610,
      "title": "Cannot update Azure DevOps wiki from pipeline",
      "problem": "I am attempting to update our Azure DevOps wiki from an Azure DevOps pipeline in the same project.\nEach time, I receive the following error: `Repository associated with wiki ID 'acf82e19-xxxx-xxxx-xxxx-xxxxxxxxxxxx' does not exist or you do not have permissions for the operation you are attempting.`\nNote that the `wiki show` command succeeds, but `wiki page create` fails.  Running the same command locally (following `az login`) does work, so this is about the permissions available to the DevOps pipeline.\nIn Wiki security, I have allowed Contribute access to the \"[Project name] Build Service ([Org name])\" user.\nI have also added the WikiGit repository as a resource in my yaml (see below), as recommended here.\nAdditionally, I have tried using `Invoke-RestMethod` to call the API via PowerShell, as per this question, but I receive the same error response.\nMy yaml code is as follows:\n`trigger: none\n\nresources:\n  repositories:\n    - repository: WikiGit\n      type: git\n      name: [Project name].wiki\n\nsteps:\n  - script: |\n      az devops wiki show --wiki \"[Project name].wiki\" --verbose\n      az devops wiki page create --path NewPage --wiki \"[Project name].wiki\" --comment \"added a new page\" --content \"# New Wiki Page Created!\" --verbose\n    env:\n      AZURE_DEVOPS_EXT_PAT: $(System.AccessToken)\n\n`\nHere is the full output:\n```\n`INFO: Detect: Url discovery took 0:00:00.002002\nINFO: received PAT from environment variable\nINFO: Creating connection with personal access token.\nINFO: Command ran in 0.660 seconds (init: 0.130, invoke: 0.530)\n{\n  \"id\": \"acf82e19-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n  \"mappedPath\": \"/\",\n  \"name\": \"[Project name].wiki\",\n  \"projectId\": \"5feec93a-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n  \"properties\": null,\n  \"remoteUrl\": \"https://dev.azure.com/[Org name]/5feec93a-xxxx-xxxx-xxxx-xxxxxxxxxxxx/_wiki/wikis/acf82e19-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n  \"repositoryId\": \"acf82e19-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n  \"type\": \"projectWiki\",\n  \"url\": \"https://dev.azure.com/[Org name]/5feec93a-xxxx-xxxx-xxxx-xxxxxxxxxxxx/_apis/wiki/wikis/acf82e19-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n  \"versions\": [\n    {\n      \"version\": \"wikiMaster\",\n      \"versionOptions\": null,\n      \"versionType\": null\n    }\n  ]\n}\nINFO: Detect: Url discovery took 0:00:00.001961\nINFO: received PAT from environment variable\nINFO: Creating connection with personal access token.\nERROR: Repository associated with wiki ID 'acf82e19-xxxx-xxxx-xxxx-xxxxxxxxxxxx' does not exist or you do not have permissions for the operation you are attempting.\nINFO: Command ran in 0.511 seconds (init: 0.131, invoke: 0.380)\n\n`\n```",
      "solution": "The solution, it seems, is to add `uses`:\n`trigger: none\n\nresources:\n  repositories:\n    - repository: WikiGit\n      type: git\n      name: [Project name].wiki\n\njobs:\n  - job:\n    uses: # This will not checkout the repo to the agent, but will add the repo to the agent PAT\n      repositories:\n        - WikiGit\n    steps:\n      - script: |\n          az devops wiki show --wiki \"[Project name].wiki\" --verbose\n          az devops wiki page create --path NewPage --wiki \"[Project name].wiki\" --comment \"added a new page\" --content \"# New Wiki Page Created!\" --verbose\n        env:\n          AZURE_DEVOPS_EXT_PAT: $(System.AccessToken)\n`\nThanks to this Visual Sudio Developer Community answer.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2025-04-09T16:29:17",
      "url": "https://stackoverflow.com/questions/79564610/cannot-update-azure-devops-wiki-from-pipeline"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 77322675,
      "title": "How can I add a log analytics workspace to an existing ampls through bicep",
      "problem": "Background\nWe have a hub-spoke topology. In the hub there is an ampls with already a log analytics workspace connected that also exists in the hub. This works. All resources are added through bicep.\nNew log analytics workspace\nIn a new spoke I've added a log analytics workspace. As the documentation says, you should add it to the existing ampls.\nBicep\nI've created a new bicep module which should do that\n```\n`resource law 'Microsoft.OperationalInsights/workspaces@2022-10-01' existing = {\n  scope: resourceGroup(lawSubId, lawRg)\n  name: lawName\n}\n\nresource ampls 'microsoft.insights/privatelinkscopes@2021-07-01-preview' existing = {\n  scope: resourceGroup(amplsSubscriptionId, amplsRg)\n  name: amplsName\n}\n\n// deploy ampls scoped resources\nresource amplsScope 'microsoft.insights/privatelinkscopes/scopedresources@2021-07-01-preview' = {\n  parent: ampls\n  name: amplsScopeName\n  properties: {\n    linkedResourceId: law.id\n  }\n}\n`\n```\nSo the law and the ampls resources already exists, and I want to add a new scope so the ampls and the law are connected.\nError\nWith the above setup I get the following error:\n```\n`Error BCP165: A resource's computed scope must match that of the Bicep file for it to be deployable. This resource's scope is computed from the \"scope\" property value assigned to ancestor resource \"ampls\". You must use modules to deploy resources to a different scope.\n`\n```\nBut when I tried to move the existing ampls resource so that the amplsScope now was the deploy in the module I got the error that the parent type was of string instead of \"privatelinkscopes\".\nRequest\nDoes anyone know how to achieve this in Bicep? As I'm deploying this through an Azure DevOps pipeline I would also be happy with an Azure CLI example, or powershell if there is no other option.\nLet me know if there's any information missing.",
      "solution": "the scope of your deployment needs to match the scope of the resource you are deploying: You can't specify the scope of the ampls in the module\n```\n`resource law 'Microsoft.OperationalInsights/workspaces@2022-10-01' existing = {\n  scope: resourceGroup(lawSubId, lawRg)\n  name: lawName\n}\n\nresource ampls 'microsoft.insights/privatelinkscopes@2021-07-01-preview' existing = {\n  name: amplsName\n}\n\n// deploy ampls scoped resources\nresource amplsScope 'microsoft.insights/privatelinkscopes/scopedresources@2021-07-01-preview' = {\n  parent: ampls\n  name: amplsScopeName\n  properties: {\n    linkedResourceId: law.id\n  }\n}\n`\n```\nThen you can invoke your module like that:\n```\n`az deployment group create --resource-group \n`\n```\nIf this module is part of bigger deployment, you can specify a scope when invoking the module:\n```\n`// main.bicep\n\nmodule approvePrivateEndpoint 'modules/ampls-scoped-resource.bicep' = {\n  name: 'ampls-scoped-resource'\n  scope: resourceGroup(amplsSubscriptionId, amplsRg)\n  params: {\n    amplsName: ''\n    amplsScopeName: ''\n    lawName: ''\n    lawRg: ''\n    lawSubId: ''\n  }\n}\n\n`\n```",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2023-10-19T11:45:59",
      "url": "https://stackoverflow.com/questions/77322675/how-can-i-add-a-log-analytics-workspace-to-an-existing-ampls-through-bicep"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 77287119,
      "title": "How to correctly parse arrays when using Azure CLI commands with Powershell variables",
      "problem": "Powershell Version: 5.1.22621.1778\nAzure CLI Version: 2.53.0\nI am using the Azure CLI to execute commands in a cloud subscription.\nMy issue is that I want to assign the JSON result to a PowerShell variable.\nWhen I do this for an array result, the PowerShell variable contains a string array, line by line, of the cli result, e.g.\n`$result = az group list -o json\"`\nReturns:\n`[ { \"id\": \"/subscriptions/xxx/resourceGroups/group1\", \"location\": \"xxx\", \"managedBy\": null, \"name\": \"group1\", \"properties\": { \"provisioningState\": \"Succeeded\" }, \"tags\": {}, \"type\": \"Microsoft.Resources/resourceGroups\" } ]`\nI would expect that $result contain an array of resource groups, if 1 group is returned like the example above, then:\n$result.count should equal 1\nHowever, in this case $result.count == 13\nFurthermore, $result.GetType() == System.Array\nIt appears that $result is an array of the string lines returned, rather than a JSON array of the data.\nI have a work around, that seems like a bit of hack:\n`$result = (az group list -o json | out-string) $groupList = ConvertTo-Json ($result)`\nBasically, convert the result to a string and then convert it back into JSON.\nAnyone know a better way or why this is happening?",
      "solution": "You want to use ConvertFrom-Json:\n```\n`$groupList=$(az group list -o json | ConvertFrom-Json)\n`\n```",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2023-10-13T12:47:47",
      "url": "https://stackoverflow.com/questions/77287119/how-to-correctly-parse-arrays-when-using-azure-cli-commands-with-powershell-vari"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 76928274,
      "title": "unable to execute the command the jq command in azure devops pipeline",
      "problem": "I have this command where I am trying to validate whether managed identity is already assigned to a particular resource or not. I am getting the managed identity dynamically so, I am keeping it as pipeline variable. when I run this command on azure portal by opening the cli, its running successfully.\n```\n`$test = \"name\"\naz vmss identity show -g group-name -n vmss-name -o json | jq '.userAssignedIdentities | with_entries(select(.key | contains(\"$test\")))'\n`\n```\nwhen I run the exact same command in the pipeline I am getting error.\n\njq: error: $test is not defined at , line 1:\n\nhere is the task\n```\n`- task: AzureCLI@2\n          inputs:\n            azureSubscription: $(sub)\n            scriptType: 'pscore'\n            scriptLocation: 'inlineScript'\n            inlineScript: |\n               az vmss identity show -g group-name -n vmss-name -o json | jq '.userAssignedIdentities | with_entries(select(.key | contains(\"$test\")))'\n\n        azurePowerShellVersion: 'latestVersion'\n`\n```",
      "solution": "Thanks @pmf. Here is the updated command.\n```\n`az vmss identity show -g group-name -n vmss-name -o json | jq --arg test \"$test\" '.userAssignedIdentities | with_entries(select(.key | contains($test)))' \n`\n```",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2023-08-18T11:58:06",
      "url": "https://stackoverflow.com/questions/76928274/unable-to-execute-the-command-the-jq-command-in-azure-devops-pipeline"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 76802619,
      "title": "How to check last time an Azure SQL Database went on Auto-Pause and for how long?",
      "problem": "I'm testing Azure SQL Database with the Serverless feature.\nI would like to understand if the SQL Database went into Auto-Pause mode yesterday and for how long.\nI asked to ChatGPT to give me a hint about what code I can use and it suggested PowerShell:\n```\n`az sql db show -g $resourceGroupName -s $serverName -n $databaseName --query \"automaticPauseTime\"\n`\n```\nBut it's returning the error:\n```\n`(ResourceGroupNotFound) Resource group 'MyResourceGroup' could not be found.\nCode: ResourceGroupNotFound\nMessage: Resource group 'MyResourceGroup' could not be found.\n`\n```\nEven if I put the right Resource Group name.\nSo I tried with T-SQL:\n```\n`USE master;\n\nDECLARE @databaseName NVARCHAR(128) = 'YourDatabaseName'; -- Replace with your database name\nDECLARE @lastConnectionTime DATETIME;\n\n-- Get the last connection time from the sys.dm_exec_sessions DMV\nSELECT @lastConnectionTime = MAX(login_time)\nFROM sys.dm_exec_sessions\nWHERE database_id = DB_ID(@databaseName);\n\nIF @lastConnectionTime IS NULL\nBEGIN\n    PRINT 'The database has never been connected since the last restart or creation.';\nEND\nELSE\nBEGIN\n    PRINT 'The database last had a connection at: ' + CONVERT(NVARCHAR, @lastConnectionTime);\nEND\n`\n```\nWhich returns `The database has never been connected since the last restart or creation.` which is a lie because I'm connected to it right now.\nSo how can I check the last time an Azure SQL Database went on Auto-Pause and for how long?",
      "solution": "I had the same question, but then I noticed Activity Log. It's possible to drill into the change details for the DB. \nin the Azure Portal, go to the DB > Activity Log > choose an event (pausing & resuming are events, I found out). look for Properties.Status, properties.pausedDate, properties.ResumedDAte or something similar to get the last time paused or resumed. These details are change activities logged to Azure itself in the DB config. if you don't have permissions to see what history and values that have changed, you may not have the ability to see that information.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2023-07-31T12:13:33",
      "url": "https://stackoverflow.com/questions/76802619/how-to-check-last-time-an-azure-sql-database-went-on-auto-pause-and-for-how-long"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 72911413,
      "title": "Azure Container Apps - App with multiple containers - azure cli command",
      "problem": "I am using Azure Container Apps to host our Containers. I want one instance of an Azure Container App to host two different containers (these are services that share a similar lifecycle). This is possible to do manually via the Azure portal, but I cannot see a way to automate it via the Azure CLI.\nI have been using the `az containerapp up` CLI command to create an App with a single container.\nhttps://learn.microsoft.com/en-us/cli/azure/containerapp?view=azure-cli-latest#az-containerapp-up\nBut is there a way with the CLI to create an app that manages 2 containers?\nThanks",
      "solution": "The az containerapp compose create command let you specify a Compose file.\nhttps://learn.microsoft.com/en-us/cli/azure/containerapp/compose?view=azure-cli-latest",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2022-07-08T14:27:01",
      "url": "https://stackoverflow.com/questions/72911413/azure-container-apps-app-with-multiple-containers-azure-cli-command"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 72273419,
      "title": "Use user assigned managed identity for Azure VM with proxy",
      "problem": "We created an Azure VM with a user-assigned managed identity as described\u00a0here. \nThe following environment variable was exported, so the Azure CLI uses a proxy (direct internet connection is blocked in our subnet).\n`export http_proxy=\"http://proxy.local:111\"\nexport https_proxy=\"http://proxy.local:111\"\n`\nNow I would like to use `az login --idenity` to login to Azure with the assigned managed identity. \nUnfortunately, I receive all the time the following message:\n```\n`Failed to connect to MSI. Please make sure MSI is configured correctly.\nGet Token request returned http error: 400, reason: Bad Request\n`\n```",
      "solution": "Using `az login --identity --verbose --debug` we observed, that `az login --identity` performers the following call:\n```\n`...\nurllib3.connectionpool: http://proxy.local:111 \"GET http://169.254.169.254/metadata/identity/oauth2/token?resource=https%3A%2F%2Fmanagement.core.windows.net%2F&api-version=2018-02-01 HTTP/1.1\" 400 68\n...\n`\n```\nBecause of the proxy settings, `az login --identity` is trying to connect to `169.254.169.254` over the configured proxy, which will not work. Setting `export no_proxy=\"169.254.169.254\"` resolved the issue.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2022-05-17T13:41:27",
      "url": "https://stackoverflow.com/questions/72273419/use-user-assigned-managed-identity-for-azure-vm-with-proxy"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 72208983,
      "title": "How to create a JSON body with PowerShell which is Deserializable by .NET6 when using az rest to call a .NET6 Azure Function",
      "problem": "We are using AzureCLI to be able to call an Azure Function endpoint upon a successful deployment.  The call to get token works and the call to our azure function makes it into MyFunction.\nThe problem is the format of the body when it arrives.\nIf we include the -Compress for ConvertTo-Json, the body arrives like `{ResourceId:3,BuildPipelineName:ResourceName}` and System.Text.Json.JsonSerializer.Deserialize throws `'R' is an invalid start of a property name. Expected a '\"'. LineNumber: 0 | BytePositionInLine: 1.`\nIf we don't include the -Compress for ConvertTo-Json, the body arrives like `{` and throws `Expected depth to be zero at the end of the JSON payload. There is an open JSON object or array that should be closed. LineNumber: 0 | BytePositionInLine: 1.`\n```\n`      runOnce:\n        deploy:\n          steps:\n            - template: ./deployment.yml    \n\n        on:  # On success or failure hook for runOnce deployment strategy\n          success:  # Runs on success of all of the steps\n            steps:\n              - task: AzureCLI@2\n                inputs:\n                  azureSubscription: 'MyServiceConnectionName'\n                  scriptType: ps\n                  scriptLocation: inlineScript\n                  inlineScript: |\n                    $functionKeys = az functionapp function keys list -g my-resource-group -n my-azure-function-name --function-name MyFunction | ConvertFrom-Json\n                    $defaultKey = $functionKeys.default\n                    \n                    $body = @{ \n                        ResourceId=\"$(Environment.ResourceId)\";\n                        ResourceName=\"$(Environment.ResourceName)\";\n                        } | ConvertTo-Json -Compress \n                    echo body: $body\n\n                    $url2 = \"https://my-azure-function-name.azurewebsites.net/api/MyFunction?code=$defaultKey\"\n\n                    $response = az rest --method post --uri $url2 --skip-authorization-header --verbose --body $body\n                    echo response: $response\n`\n```\nWe've tried adding the following json options to JsonSerializer.Deserialize but with no change in behavior\n```\n`        var jsonOptions = new JsonSerializerOptions\n        {\n            PropertyNameCaseInsensitive = true,\n            ReadCommentHandling = JsonCommentHandling.Skip,\n            AllowTrailingCommas = true,\n            NumberHandling = JsonNumberHandling.AllowReadingFromString\n        };\n`\n```\nWe've also tried changing the body creation to be a single line like:\n```\n`  $body = @{ResourceId=\"$(Environment.ResourceId)\";ResourceName=\"$(Environment.ResourceName)\" } | ConvertTo-Json -Compress\n`\n```\nWe are new to both PowerShell and .NET6.  We will gladly attempt changes on either side.  Anything that may make this request succeed will be much appreciated.\nThank you for sharing your hard earned knowledge.",
      "solution": "Az rest is very sensitive about the format of JSON input. For example, it requires double quotes to be escaped, even on Windows. It also doesn't like newlines, as you already noticed.\nTry this way:\n```\n`$body = (@{\n  ResourceId=\"$(Environment.ResourceId)\";\n  ResourceName=\"$(Environment.ResourceName)\";\n} | ConvertTo-Json -Compress).Replace('\"', '\\\"')\n`\n```\nThis will escape double quotes (bash style).\nI would also recommend changing `scriptType` to `pscore` in your pipeline (it's supported on both Windows and Linux agents).",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2022-05-12T02:50:50",
      "url": "https://stackoverflow.com/questions/72208983/how-to-create-a-json-body-with-powershell-which-is-deserializable-by-net6-when"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 68735202,
      "title": "Give Managed Identity permission to create app registration in Azure AD via ARM Template Deployment Script",
      "problem": "What we are trying to accomplish:\nWe are using Azure ARM Templates to deploy new applications. When we deploy these new applications, we need to register them with our Azure AD for authentication purposes. We would like to include this app registration in our template along with the deployment of the application resources.\nIt looks like Azure Deployment Scripts are the way to register new apps with Azure AD in our ARM template. In our Deployment Script, the \"scriptContent\" I am attempting to run is simply `az ad app create --display-name ${appName}`\nThe Problem\nPermissions. We are getting `DeploymentScriptError: Insufficient privileges to complete the operation`. I proceeded to create a Managed Identity and added `az login --identity -u ${managedIdentityId}` at the beggining of the script but the same error persisted. It seems the managed identity does not have permission to create an app registration and I am unsure how to give it this permission\nI found this article which provides a PowerShell script for granting the necessary permissions to the managed identity, however, the author does not explain what \"GraphAppId\" is or where it is coming from.\nAny help with this would be tremendously appreciated\nWe are pretty new to ARM templates but this is what we currently have:\nmain.bicep\n```\n`\ntargetScope = 'subscription'\n\nparam location string = 'eastus'\n\nresource myResourceGroup 'Microsoft.Resources/resourceGroups@2021-04-01' = {\n  name: 'rg-test1'\n  location: location\n}\n\nresource managedId 'Microsoft.ManagedIdentity/userAssignedIdentities@2018-11-30' existing = {\n  name: 'mi-deployscripttest'\n  scope: resourceGroup('DefaultResourceGroup-EUS')\n}\n\nmodule deploymentScript 'modules/deploymentScript.bicep' = {\n  scope: myResourceGroup\n  name: 'deploymentScript'\n  params: {\n    appName: 'testApp1'\n    location: location\n    managedIdentityId: managedId.id\n    managedIdentityPrincipalId: managedId.properties.principalId\n  }\n}\n`\n```\ndeploymentScript.bicep\n```\n`param location string \nparam appName string\nparam managedIdentityId string\nparam managedIdentityPrincipalId string\n\nvar scriptContent = format('''\n  az login --identity -u {0}\n  az ad app create --display-name {1}\n''', managedIdentityId, appName)\n\nresource deploymentScriptRoleDefinition 'Microsoft.Authorization/roleDefinitions@2018-01-01-preview' = {\n  name: guid('basicDeploymentScriptDefinition')\n  properties: {\n    roleName: 'deployment-script-minimum-privilege-for-deployment-principal'\n    description: 'Configure least privilege for the deployment principal in deployment script'\n    type: 'customRole'\n    permissions: [\n      {\n        actions: [\n          'Microsoft.Storage/storageAccounts/*'\n          'Microsoft.ContainerInstance/containerGroups/*'\n          'Microsoft.Resources/deployments/*'\n          'Microsoft.Resources/deploymentScripts/*'\n          'Microsoft.Storage/register/action'\n        ]\n      }\n    ]\n    assignableScopes: [\n      resourceGroup().id\n    ]\n  }\n}\n\nresource deploymentScriptRoleAssignment 'Microsoft.Authorization/roleAssignments@2015-07-01' = {\n  name: guid('basicDeploymentScriptAssignment')\n  properties: {\n    principalId: managedIdentityPrincipalId\n    roleDefinitionId: deploymentScriptRoleDefinition.id\n  }\n}\n\nresource deploymentScript 'Microsoft.Resources/deploymentScripts@2020-10-01' = {\n  name: 'deploymentScriptTest1'\n  location: location\n  kind: 'AzureCLI'\n  identity: {\n    type: 'UserAssigned'\n    userAssignedIdentities: {\n      '${managedIdentityId}': {}\n    }\n  }\n  properties: {\n    azCliVersion: '2.9.1'\n    retentionInterval: 'P1D'\n    scriptContent: scriptContent\n    cleanupPreference: 'Always'\n  }\n  dependsOn: [ \n    deploymentScriptRoleAssignment \n  ] \n}\n\n`\n```",
      "solution": "To find the ClientID/AppID, you need to check the request being sent to `https://login.microsoftonline.com` for authentication. ClientID/AppID is sent as a parameter in the request url as highlighted in sample request below:\nhttps://login.microsoftonline.com/xxxxxx.onmicrosoft.com/oauth2/v2.0/authorize?**client_id=d736a5a0-xxxx-xxxx-xxxx-d192b45e4aa7**&response_type=code&redirect_uri=https://jwt.ms&state=1234&response_mode=query&scope=openid\nTo add required permissions in the token, you need to first copy the Client ID (aka App ID) that you are using in your request to get the Access Token and then navigate to:\nAzure Portal > Azure Active Directory > App Registration > All Applications > Search with the ClientID/AppID copied earlier\nIn that application Navigate to:\nApi Permissions > Add a permission > Microsoft Graph > Delegated permissions > Expand User > Select required permissions as shown below. Once the permissions are added, click on Grant Admin Consent for your_tenant button.\n\nYou can refer to Insufficient privileges to complete the operation\" while using Graph API, Calling your APIs with Azure AD Managed Service Identity using application permissions and az ad app permission add - Insufficient privileges to complete the operation",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-08-11T04:02:05",
      "url": "https://stackoverflow.com/questions/68735202/give-managed-identity-permission-to-create-app-registration-in-azure-ad-via-arm"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 68696341,
      "title": "How to filter array of elements in JMESPath with Azure CLI",
      "problem": "I am total newbie in JMESPath parsing.\n`az network lb inbound-nat-rule list --resource-group MYRG --lb-name MYLB` is returning below output and I would like filter only `backendIpConfiguration.id` and `backendPort` in the response.\nBelow response in have array of elements.\n```\n`[\n  {\n    \"backendIpConfiguration\": {\n      \"applicationGatewayBackendAddressPools\": null,\n      \"applicationSecurityGroups\": null,\n      \"etag\": null,\n      \"gatewayLoadBalancer\": null,\n      \"id\": \"/subscriptions/XXXX/XXX/XXX/providers/Microsoft.Network/networkInterfaces/XXX/ipConfigurations/XXXX\",\n      \"loadBalancerBackendAddressPools\": null,\n      \"loadBalancerInboundNatRules\": null,\n      \"name\": null,\n      \"primary\": null,\n      \"privateIpAddress\": null,\n      \"privateIpAddressVersion\": null,\n      \"privateIpAllocationMethod\": null,\n      \"privateLinkConnectionProperties\": null,\n      \"provisioningState\": null,\n      \"publicIpAddress\": null,\n      \"resourceGroup\": \"MYRG01\",\n      \"subnet\": null,\n      \"type\": null,\n      \"virtualNetworkTaps\": null\n    },\n    \"backendPort\": 1367,\n    \"enableFloatingIp\": false,\n    \"enableTcpReset\": false,\n    \"etag\": \"W/\\\"XXXXX-1173-49ad-8d1f-40347c00d88a\\\"\",\n    \"frontendIpConfiguration\": {\n      \"id\": \"/subscriptions/XXXX/XXX/XXX/providers/Microsoft.Network/networkInterfaces/XXX/ipConfigurations/XXXX\",\n      \"resourceGroup\": \"MYRG01\"\n    },\n    \"frontendPort\": 1367,\n    \"id\": \"/subscriptions/XXXX/XXX/XXX/providers/Microsoft.Network/networkInterfaces/XXX/ipConfigurations/XXXX\",\n    \"idleTimeoutInMinutes\": 5,\n    \"name\": \"rule1\",\n    \"protocol\": \"Tcp\",\n    \"provisioningState\": \"Succeeded\",\n    \"resourceGroup\": \"MYRG01\",\n    \"type\": \"Microsoft.Network/loadBalancers/inboundNatRules\"\n  },\n  {\n    \"backendIpConfiguration\": {\n      \"applicationGatewayBackendAddressPools\": null,\n      \"applicationSecurityGroups\": null,\n      \"etag\": null,\n      \"gatewayLoadBalancer\": null,\n      \"id\": \"/subscriptions/XXXX/XXX/XXX/providers/Microsoft.Network/networkInterfaces/XXX/ipConfigurations/XXXX\",\n      \"loadBalancerBackendAddressPools\": null,\n      \"loadBalancerInboundNatRules\": null,\n      \"name\": null,\n      \"primary\": null,\n      \"privateIpAddress\": null,\n      \"privateIpAddressVersion\": null,\n      \"privateIpAllocationMethod\": null,\n      \"privateLinkConnectionProperties\": null,\n      \"provisioningState\": null,\n      \"publicIpAddress\": null,\n      \"resourceGroup\": \"MYRG02\",\n      \"subnet\": null,\n      \"type\": null,\n      \"virtualNetworkTaps\": null\n    },\n    \"backendPort\": 3006,\n    \"enableFloatingIp\": false,\n    \"enableTcpReset\": false,\n    \"etag\": \"W/\\\"XXXX-1173-49ad-8d1f-40347c00d88a\\\"\",\n    \"frontendIpConfiguration\": {\n      \"id\": \"/subscriptions/XXXX/XXX/XXX/providers/Microsoft.Network/networkInterfaces/XXX/ipConfigurations/XXXX\",\n      \"resourceGroup\": \"MYRG02\"\n    },\n    \"frontendPort\": 3006,\n    \"id\": \"/subscriptions/XXXX/XXX/XXX/providers/Microsoft.Network/networkInterfaces/XXX/ipConfigurations/XXXX\",\n    \"idleTimeoutInMinutes\": 5,\n    \"name\": \"rule2\",\n    \"protocol\": \"Tcp\",\n    \"provisioningState\": \"Succeeded\",\n    \"resourceGroup\": \"MYRG02\",\n    \"type\": \"Microsoft.Network/loadBalancers/inboundNatRules\"\n  }\n]\n`\n```",
      "solution": "Filtering in JMESPath is quite simple, and the documentation is pretty straight forward for filters and multiselect hashes.\nIn here, a simple query like:\n`[].{backendIpConfigurationId: backendIpConfiguration.id, backendPort: backendPort}\n`\nWill give you the filtered JSON:\n`[\n  {\n    \"backendIpConfigurationId\": \"/subscriptions/XXXX/XXX/XXX/providers/Microsoft.Network/networkInterfaces/XXX/ipConfigurations/XXXX\",\n    \"backendPort\": 1367\n  },\n  {\n    \"backendIpConfigurationId\": \"/subscriptions/XXXX/XXX/XXX/providers/Microsoft.Network/networkInterfaces/XXX/ipConfigurations/XXXX\",\n    \"backendPort\": 3006\n  }\n]\n`\nContaining only the informations you are looking for.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-08-07T23:41:34",
      "url": "https://stackoverflow.com/questions/68696341/how-to-filter-array-of-elements-in-jmespath-with-azure-cli"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 68060909,
      "title": "Interpolating strings in a file path in a DockerFile",
      "problem": "I have a Docker file which starts like this:\n```\n`ARG FILE_PATH\n\nFROM mcr.microsoft.com/dotnet/aspnet:3.1 AS base\nWORKDIR /app\nEXPOSE 80\nEXPOSE 443\n\nFROM mcr.microsoft.com/dotnet/sdk:3.1 AS build\nWORKDIR /src\n\nCOPY [\"${FILE_PATH}/src/NuGet.config\", \"src/\"]\n`\n```\nI call it using the azure-cli like this:\n```\n`$pathToSrc = \"$(Build.SourcesDirectory)/My folder\"\n\naz acr build --build-arg \"FILE_PATH=$pathToSrc\" ...\n`\n```\nThis always fails with the message:\n\nCOPY failed: file not found in build context or excluded by\n.dockerignore: stat src/NuGet.config: file does not exist\n\nI have tried variations such as:\n```\n`COPY [$FILE_PATH/src/NuGet.config, \"src/\"]\nCOPY [\"FILE_PATH/src/NuGet.config\", \"src/\"]\n`\n```\nand\n```\n`az acr build --build-arg \"FILE_PATH='$pathToSrc'\" ...\n`\n```\nbut always end up with the same message.\nIs there a way to do this. I am running on a hosted agent in Azure-devops pipeline. The task is task: AzureCLI@2 using a PowerShell Core script.",
      "solution": "This may be related: https://stackoverflow.com/a/56748289/4424236\n\n...after every `FROM` statements all the `ARG`s gets collected and are no longer available. Be careful with multi-stage builds.\n\nTry this:\n```\n`FROM mcr.microsoft.com/dotnet/aspnet:3.1 AS base\nWORKDIR /app\nEXPOSE 80\nEXPOSE 443\n\nFROM mcr.microsoft.com/dotnet/sdk:3.1 AS build\nWORKDIR /src\n\nARG FILE_PATH\n\nCOPY [\"${FILE_PATH}/src/NuGet.config\", \"src/\"]\n`\n```",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-06-21T01:46:39",
      "url": "https://stackoverflow.com/questions/68060909/interpolating-strings-in-a-file-path-in-a-dockerfile"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 67166770,
      "title": "powershell redirect error from az cli command",
      "problem": "I'm running an az CLI command `az mysql db show`. At first, the DB doesn't exist, but that case is handled in a try/catch block. There is an error message printed:\n\nERROR: The requested resource of type 'Microsoft.DBforMySQL/servers/databases' with name 'my_name' was not found.\n\nI would like to not print this message since I'm handling the error case. I tried different methods to redirect the error output stream to null. I didn't manage to do so. I tried:\n```\n`command 2> $null # not working\n`\n```\nand other approaches.\nWhat is the correct syntax?",
      "solution": "```\n`# from python in windows\naz mysql db show 2>nul\n\n# from powershell in windows - no space!\naz mysql db show 2>$null\n`\n```\nThis should work better for you. Powershell will eat your `$null`, so azure cli won't redirect. \nYou can also try checking for the db first with `az mysql db list`",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-04-19T19:39:25",
      "url": "https://stackoverflow.com/questions/67166770/powershell-redirect-error-from-az-cli-command"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 67099947,
      "title": "Recursively list all resource tags within Azure Resource Groups",
      "problem": "We have a large number of Azure Subscriptions which currently run into the hundreds.\nI'm looking to generate a report (ideally using Azure Powershell or Azure CLI) to recursively extract a list of all tags assigned to every single resource within every resource group, for between 40-50 of the subscriptions.\nCurrently, I can list all tags assigned at Resource Group level, but I simply can't find a way to list the tags assigned to the individual resources within each Resource Group. The list of subscriptions and resource groups on which I'd like to extract this report, are saved in a CSV file which includes two columns displaying the Subscription name and Resource Group respectively.\nAny tips on how to achieve the above would be fantastic and most appreciated.",
      "solution": "Not detailed code but the idea here.\n1.You should write a loop, in the loop, change the `subscription` each time by using this cmdlet:\n`Set-AzContext -Subscription $subscription_name`.\n2.Then get all the `resource group` in the specified `subscription` by using this cmdlet:\n```\n`$resource_groups = Get-AzResourceGroup\n`\n```\n3.Then write a nested loop(loop for each `resource group`), in this nested loop, use this cmdlet to get all `azure resources` within a `resource group`:\n```\n`foreach($rg in $resource_groups){\n   $azure_resources = Get-AzResource -ResourceGroupName $rg.ResourceGroupName\n}\n`\n```\n4.Write another nested loop in step 3, this loop is used to go though all the `azure resources` within the specified `resource group`. Then use the code below to fetch tags for each `azure resource` within the `resource group`:\n```\n`foreach($r in $azure_resources){\n     #the following code can get all the tags for one resource\n     $r.tags\n\n}\n`\n```",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-04-15T00:34:16",
      "url": "https://stackoverflow.com/questions/67099947/recursively-list-all-resource-tags-within-azure-resource-groups"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 79017264,
      "title": "Updating Azure Container app Startup Probe using CLI is not working",
      "problem": "I'm trying to update Azure container app startup probe using Az Cli. Below is the command\n```\n`az containerapp update --name $containerAppName --resource-group $resourceGroup --set `\n  properties.template.containers.probes.type=\"Startup\" `\n  properties.template.containers.probes.httpGet.path=\"/\" `\n  properties.template.containers.probes.httpGet.port=80 `\n  properties.template.containers.probes.initialDelaySeconds=20 `\n  properties.template.containers.probes.periodSeconds=3\n`\n```\nAfter running the above command, when we query the container app for changes\n```\n`az containerapp show --name $containerAppName --resource-group $resourceGroup --query \"properties.template.containers[0].probes\"\n`\n```\nwe still see the old configuration for the startup probes (even after allowing the revision to be up and running).\nCould you please suggest is there any way we can update the probes in Azure Container apps using cli.\nThanks in advance.",
      "solution": "Here is the command to update Azure Container App probe settings using Azure CLI.\n\nNote: Ensure that the container app is running. If it is not running, please start the application\n\n`az containerapp update --name \"venkat-container\" --resource-group \"Venkat-RG\" --set properties.template.containers.probes.type=\"Startup\" properties.template.containers.probes.httpGet.path=\"/\" properties.template.containers.probes.httpGet.port=80 properties.template.containers.probes.initialDelaySeconds=20 properties.template.containers.probes.periodSeconds=3\n`\nOutput\n```\n`az containerapp show --name \"venkat-container\" --resource-group \"Venkat-RG\" --query \"properties.template.containers[0]\"\n`\n```\nAfter running the command, the Azure Container App probe settings have been updated with given values.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2024-09-24T08:36:26",
      "url": "https://stackoverflow.com/questions/79017264/updating-azure-container-app-startup-probe-using-cli-is-not-working"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 78418466,
      "title": "azure cli - Retrieve and create webjobs for list of webapps in azure using azure CLI",
      "problem": "I am trying to do web job creation, if not exist.\nfor single webapp this line of command worked.\n`az webapp deployment source config-zip --resource-group \"rg1\" --name \"webapp1\" --src \"path\\file.zip\"\n`\nZip file structure was created as described as in\nhttps://github.com/projectkudu/kudu/wiki/WebJobs.\nI can see the webjob created, but when I am putting it in the loop I am getting error.\nhere is the code I have so far.\n`# Resource group name........\nresourceGroup=\"rg1\"\n\n# Path to the zip file containing the web job\nzipFilePath=\"zipfilepath/file.zip\"\n\n# Web job name\nwebJobName=\"webjob1\"\n\n# Get a list of all web apps within the resource group\nwebAppNames=$(az webapp list --resource-group $resourceGroup --query \"[].name\" -o tsv)\n\n# Loop over each web app name\nfor webAppName in $webAppNames; do\n    # Check if the web job already exists in the web app\n    if az webapp webjob triggered list --resource-group $resourceGroup --name $webAppName --query \"[?name=='$webJobName']\" -o tsv | grep -q \"$webJobName\"; then\n        echo \"Web job '$webJobName' already exists in web app '$webAppName'. Skipping deployment.\"\n    else\n        echo \"Deploying web job '$webJobName' to web app: $webAppName\"\n        az webapp deployment source config-zip --resource-group $resourceGroup --name $webAppName --src $zipFilePath\n    fi\ndone\n`\nError\n`At line:14 char:4\n+ for webAppName in \"${webAppNames[@]}\"; do\n+    ~ Missing opening '(' after keyword 'for'. At line:14 char:42\n+ for webAppName in \"${webAppNames[@]}\"; do\n+                                          ~ Missing statement body in do loop.\n    + CategoryInfo          : ParserError: (:) [], ParentContainsErrorRecordException\n    + FullyQualifiedErrorId : MissingOpenParenthesisAfterKeyword\n`",
      "solution": "Before running the script, I found an error when pasting your code into my PowerShell environment.\n\nAs the provided script by you is completely a CLI code format, it is properly executing in Cloud Shell environment as shown below.\n\nTo make it work as expected when you execute in Windows PowerShell ISE environment, run the below modified script with PowerShell syntax.\nHere I have used a `foreach` loop to loop over all the listed webapps and also used an `if`loop to check the existence.\n```\n`$resourceGroup = \"xxxx\"\n$zipFilePath = \"C:\\Users\\xxx\\source\\repos\\ConsoleApp7\\ConsoleApp7\\xxxx\"\n$webJobName = \"xxxx\"\n$webAppNames = (az webapp list --resource-group $resourceGroup --query \"[].name\" -o tsv)\nforeach ($webApp in $webAppNames) {\n    # Check if the web job already exists in the web app\n    $existing = az webapp webjob triggered list --resource-group $resourceGroup --name $webApp --query \"[?name=='$webJobName']\" -o tsv\n    if ($existing -contains $webJobName) {\n        Write-Host \"Web job '$webJobName' already exists in web app '$webApp'. Skipping deployment.\"\n    }\n    else {\n        Write-Host \"Deploying web job '$webJobName' to web app: $webApp\"\n        az webapp deployment source config-zip --resource-group $resourceGroup --name $webApp --src $zipFilePath\n    }\n}\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2024-05-02T12:21:52",
      "url": "https://stackoverflow.com/questions/78418466/azure-cli-retrieve-and-create-webjobs-for-list-of-webapps-in-azure-using-azure"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 77739283,
      "title": "The client with object id does not have authorization to perform action &#39;Microsoft.CognitiveServices/accounts/listKeys/action&#39; over scope",
      "problem": "I created a new Azure AI Services resource in a Resource Group. I have Contributor access in the Resource Group that contains this Azure AI Service resource.\nMy problem is I can't list keys with this az cli command. I'm already logged in with az login.\n`az cognitiveservices account keys list --name alper-azure-ai-service --resource-group alper-playground`\nI'm getting this error message:\n(AuthorizationFailed) The client 'alper.silistre@{myCompanyEmail}' with object id '{myObjectId}' does not have authorization to perform action 'Microsoft.CognitiveServices/accounts/listKeys/action' over scope '/subscriptions/{subscriptionObjectId}/resourceGroups/alper-playground/providers/Microsoft.CognitiveServices/accounts/alper-azure-ai-service' or the scope is invalid. If access was recently granted, please refresh your credentials.\nI can access Keys and Endpoint section from Azure Portal:\n\nWe can also see in the IAM that I am Contributor from RG (inherited):\n\nNow, it's clear that Contributor already has 'Microsoft.CognitiveServices/accounts/listKeys/action':\n\nSo, I'm not sure what I'm missing here, since I should be able to list keys with az cli command. I definitely have Contributor access inherited from the Resource Group.\nFor reference, I'm following this Microsoft Learn exercise: https://microsoftlearning.github.io/mslearn-ai-services/Instructions/Exercises/02-ai-services-security.html",
      "solution": "I found the problem here by trying different az cli commands under az cognitiveservices. For example, when I run this `az cognitiveservices account show --name alper-azure-ai-service --resource-group alper-playground'` it gives me this error:\n```\n`(ResourceGroupNotFound) Resource group 'alper-playground' could not be found.\nCode: ResourceGroupNotFound\nMessage: Resource group 'alper-playground' could not be found.\n`\n```\nThis gave me the idea to specifically put --subscription into my original command. So when I run the original cli command with this:\n`az cognitiveservices account keys list --subscription {mySubscriptionName} --name alper-azure-ai-service --resource-group alper-playground` it worked.\nThe interesting thing here is that while `az cognitiveservices account show` is giving ResourceGroupNotFound error, `az cognitiveservices account keys list` gives AuthorizationFailed error, which in my opinion is confusing.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2023-12-31T14:31:49",
      "url": "https://stackoverflow.com/questions/77739283/the-client-with-object-id-does-not-have-authorization-to-perform-action-microso"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 75925543,
      "title": "Unable to install Sqlcmd / mssql-tools on ubuntu 20.04",
      "problem": "I am following the `Sqlcmd` installation directions from the microsoft site here Install the SQL Server command-line tools sqlcmd and bcp on Linux. The target environment is `ubuntu-20.04` on Docker\nThe following installation does not work\n```\n`sudo apt-get install -y mssql-tools unixodbc-dev\n`\n```\n```\n`The following packages have unmet dependencies:\n mssql-tools : Depends: msodbcsql17 (>= 17.3.0.0) but it is not going to be installed\n unixodbc-dev : Depends: unixodbc (= 2.3.7) but it is not going to be installed\n                Depends: odbcinst1debian2 (= 2.3.7) but 2.3.6-0.1build1 is to be installed\nE: Unable to correct problems, you have held broken packages.\n`\n```\nNote that I started manually correcting the missing packages but after a few iterations it led to a non-installable package\n```\n`root@bb72040ed700:/usr/build# apt install -y mssql-tools unixodbc-dev unixodbc\n`\n```\n\nReading package lists... Done Building dependency tree Reading state\ninformation... Done Some packages could not be installed. This may\nmean that you have requested an impossible situation or if you are\nusing the unstable distribution that some required packages have not\nyet been created or been moved out of Incoming. The following\ninformation may help to resolve the situation:\nThe following packages have unmet dependencies:  unixodbc : Depends:\nodbcinst1debian2 (>= 2.3.7) but 2.3.6-0.1build1 is to be installed\nDepends: libodbc1 (>= 2.3.7) but 2.3.6-0.1build1 is to be installed  unixodbc-dev : Depends: odbcinst1debian2 (= 2.3.7) but\n2.3.6-0.1build1 is to be installed E: Unable to correct problems, you have held broken packages.\n\nThen later:\n\nlibodbc1 : PreDepends: multiarch-support but it is not installable\nodbcinst1debian2 : PreDepends: multiarch-support but it is not installable\n\nNote: I have already viewed the similar post  Intalling mssql-tools and unixodbc-dev on Ubuntu 20 . Since I had already updated the link to 20.04 the answer provided was already incorporated and did not resolve this error.\nPer request: here is output of `cat /etc/os-release`:\n```\n`# cat /etc/os-release\nNAME=\"Ubuntu\"\nVERSION=\"20.04.5 LTS (Focal Fossa)\"\nID=ubuntu\nID_LIKE=debian\nPRETTY_NAME=\"Ubuntu 20.04.5 LTS\"\nVERSION_ID=\"20.04\"\nHOME_URL=\"https://www.ubuntu.com/\"\nSUPPORT_URL=\"https://help.ubuntu.com/\"\nBUG_REPORT_URL=\"https://bugs.launchpad.net/ubuntu/\"\nPRIVACY_POLICY_URL=\"https://www.ubuntu.com/legal/terms-and-policies/privacy-policy\"\nVERSION_CODENAME=focal\nUBUNTU_CODENAME=focal\n`\n```\nAny ideas how to get Sqlcmd installed on ubuntu 20.04 ?",
      "solution": "Found out how to install `msodbcsql17` on `ubuntu`: this was the crux of the errors  Install msodbcsql17 on ubuntu\n```\n`curl https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -\necho \"deb [arch=amd64] https://packages.microsoft.com/ubuntu/20.04/prod focal main\" | tee /etc/apt/sources.list.d/mssql-release.list\nsudo apt update\nsudo apt-get install -y msodbcsql17\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2023-04-04T06:34:37",
      "url": "https://stackoverflow.com/questions/75925543/unable-to-install-sqlcmd-mssql-tools-on-ubuntu-20-04"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 71787716,
      "title": "How do I get past &quot;Could not queue the build because there were validation errors or warnings.&quot; while automating pipeline creation using az-cli",
      "problem": "I am trying to automate rsync pipeline creation using az-cli.\nThis is the command I am running from a local clone of my repository:\n```\n`az pipelines create --name my_pipeline --yml-path azure-pipeline.yml --project my_project --repository my_repo --repository-type tfsgit\n`\n```\nThe pipeline is created but it is not able to queue it. Here are the details from the --debug switch. Am I missing something?\nThe expected output was to not only create the pipeline but also run it.\n**WARNING: This command is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\nWARNING: cli.azext_devops.dev.pipelines.pipeline_create: Successfully created a pipeline with Name: my_pipeline, Id: 2019.**\nDEBUG: msrest.exceptions: Could not queue the build because there were validation errors or warnings.\nDEBUG: cli.azext_devops.dev.common.exception_handler: handling vsts service error\nDEBUG: cli.azure.cli.core.util: azure.cli.core.util.handle_exception is called with an exception:\nDEBUG: cli.azure.cli.core.util: Traceback (most recent call last):\nFile \"/usr/lib64/az/lib/python3.6/site-packages/azure/cli/core/commands/init.py\", line 691, in _run_job\nresult = cmd_copy(params)\nFile \"/usr/lib64/az/lib/python3.6/site-packages/azure/cli/core/commands/init.py\", line 328, in call\n*return self.handler(*args, *kwargs)\nFile \"/usr/lib64/az/lib/python3.6/site-packages/azure/cli/core/commands/command_operation.py\", line 121, in handler\n*return op(*command_args)\nFile \"/home/user/.azure/cliextensions/azure-devops/azext_devops/dev/pipelines/pipeline_create.py\", line 155, in pipeline_create\nproject=project)\nFile \"/home/user/.azure/cliextensions/azure-devops/azext_devops/devops_sdk/v5_1/build/build_client.py\", line 337, in queue_build\ncontent=content)\nFile \"/home/user/.azure/cliextensions/azure-devops/azext_devops/devops_sdk/client.py\", line 90, in _send\nresponse = self._send_request(request=request, headers=headers, content=content, media_type=media_type)\nFile \"/home/user/.azure/cliextensions/azure-devops/azext_devops/devops_sdk/client.py\", line 54, in _send_request\nself._handle_error(request, response)\nFile \"/home/user/.azure/cliextensions/azure-devops/azext_devops/devops_sdk/client.py\", line 233, in _handle_error\nraise AzureDevOpsServiceError(wrapped_exception)\nazext_devops.devops_sdk.exceptions.AzureDevOpsServiceError: Could not queue the build because there were validation errors or warnings.\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile \"/usr/lib64/az/lib/python3.6/site-packages/knack/cli.py\", line 231, in invoke\ncmd_result = self.invocation.execute(args)\nFile \"/usr/lib64/az/lib/python3.6/site-packages/azure/cli/core/commands/init.py\", line 657, in execute\nraise ex\nFile \"/usr/lib64/az/lib/python3.6/site-packages/azure/cli/core/commands/init.py\", line 720, in _run_jobs_serially\nresults.append(self._run_job(expanded_arg, cmd_copy))\nFile \"/usr/lib64/az/lib/python3.6/site-packages/azure/cli/core/commands/init.py\", line 712, in _run_job\nreturn cmd_copy.exception_handler(ex)\nFile \"/home/user/.azure/cliextensions/azure-devops/azext_devops/dev/common/exception_handler.py\", line 18, in azure_devops_exception_handler\nraise CLIError(ex)\nknack.util.CLIError: Could not queue the build because there were validation errors or warnings.\nERROR: cli.azure.cli.core.azclierror: Could not queue the build because there were validation errors or warnings.\nERROR: az_command_data_logger: Could not queue the build because there were validation errors or warnings.\nDEBUG: cli.knack.cli: Event: Cli.PostExecute []\nINFO: az_command_data_logger: exit code: 1\nINFO: cli.main: Command ran in 2.552 seconds (init: 0.200, invoke: 2.352)\nINFO: telemetry.save: Save telemetry record of length 3257 in cache\nWARNING: telemetry.check: Negative: The /home/user/.azure/telemetry.txt was modified at 2022-04-07 14:29:35.737231, which in less than 600.000000 s\nAdditional information: I am setting the AZURE_DEVOPS_EXT_PAT env variable to authenticate and use az-cli commands.",
      "solution": "The error message says it all, it can't queue the build because there are errors in the YAML.\nIt created pipeline `2019`, you need to review the YAML and correct the validation errors before it'll run:\n\nOpen a browser and navigate to `https://dev.azure.com///_build?definitionId=2019`\n\nClick on the `Edit` button\n\nIn the elipsis context menu, select validate:\n\nThe error message about the invalid syntax will be shown in a dialog box.\nAlternatively, the Azure DevOps REST API exposes an endpoint to do the same:\n\npreview pipeline\nor pipeline run with the previewRun parameter specified in the request body",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2022-04-07T21:09:36",
      "url": "https://stackoverflow.com/questions/71787716/how-do-i-get-past-could-not-queue-the-build-because-there-were-validation-error"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 68994648,
      "title": "Azure DevOps Azure CLI task with PowerShell script and parallel ForEach-Object execution: no output on failure",
      "problem": "In order to scale Function Apps quickly we want to be able to deploy them via IaC and then deploy a code package onto it. Unfortunately this is not possible dynamically with YAML pipelines in Azure DevOps so I had to resort to using the Azure CLI.\nBelow you see the PowerShell script I came up with to deploy the code into the pool of Function Apps that I deployed through Terraform before-hand. To speed things up I turned on parallel processing of the `ForEach-Object` loop since there are no dependencies between the single instances. This also works fine to a certain extent but I am having troubles due to the quirkiness of the Azure CLI. Writing non-error information to StdErr seems to be by design. This combined with some other strange behavior leads to the following scenarios:\n\nRunning sequentially usually works flawlessly and I see any error output if a problem occurs. Also I don't need to set `powerShellErrorActionPreference: 'continue'`. This of course is slowing down the deployment significantly.\nRunning in parallel fails always without setting `powerShellErrorActionPreference: 'continue'`. The reason for the failure is not output to the console. This seems to happen even if no real error occurs as with `continue` there is no error output to the console as well. This wouldn't be an issue if the pipeline fails in the case of a real error (which should be handled by checking the state of the `ChildJobs` - but it doesn't.\n\nSo here I am between a rock and a hard place. Does anyone see the flaw in my implementation? Any suggestions are highly appreciated.\n```\n`- task: AzureCLI@2\n  displayName: 'Functions deployment'\n  env:\n    AZURE_CORE_ONLY_SHOW_ERRORS: 'True'\n    AZURE_DEVOPS_EXT_PAT: $(System.AccessToken)\n    ARM_CLIENT_ID: $(AzureApplicationId)\n    ARM_CLIENT_SECRET: $(AzureApplicationSecret)\n    ARM_SUBSCRIPTION_ID: $(AzureSubscriptionId)\n    ARM_TENANT_ID: $(AzureTenantId)\n  inputs:\n    azureSubscription: 'MySubscription'\n    scriptType: 'pscore'\n    scriptLocation: 'inlineScript'\n    inlineScript: |\n      Write-Output -InputObject \"INFO: Get Function App names\"          \n      $appNames = terragrunt output -json all_functionapp_names | ConvertFrom-Json          \n      Write-Output -InputObject \"INFO: Loop over Function Apps\"\n      $jobs = $appNames | ForEach-Object -Parallel {          \n          $name = $_          \n          try              \n          {          \n              Write-Output -InputObject \"INFO: $name`: start slot\"        \n              az functionapp start --resource-group $(ResourceGroup) --name \"$name\" --slot Stage --verbose\n              Write-Output -InputObject \"INFO: $name`: deploy into slot\"        \n              az functionapp deploy --resource-group $(ResourceGroup) --name \"$name\" --slot Stage --src-path \"$(System.ArtifactsDirectory)/drop/MyCodePackage.zip\" --type zip --verbose\n              Write-Output -InputObject \"INFO: $name`: deploy app settings\"          \n              az functionapp config appsettings set --resource-group $(ResourceGroup) --name \"$name\" --slot Stage --settings \"@$(Build.ArtifactStagingDirectory)/appsettings.json\" --verbose\n              Write-Output -InputObject \"INFO: $name`: swap slot with production\"          \n              az functionapp deployment slot swap --resource-group $(ResourceGroup) --name \"$name\" --slot Stage --action swap --verbose\n          }\n          catch\n          {\n              Write-Output -InputObject \"ERROR: $name`: An error occured during deployment\"\n              Write-Output -InputObject ($_.Exception | Format-List -Force)\n          }\n          finally              \n          {\n            try\n            {\n                Write-Output -InputObject \"INFO: $name`: stop slot\"          \n                az functionapp stop --resource-group $(ResourceGroup) --name \"$name\" --slot Stage --verbose\n            }\n            catch\n            {\n                Write-Output -InputObject \"ERROR: $name`: could not stop slot\"\n            }\n          }          \n      } -AsJob\n                          \n      [int]$pollingInterval = 10          \n      [int]$elapsedSeconds = 0          \n      while ($jobs.State -eq \"Running\") {          \n          $jobs.ChildJobs |\u00a0ForEach-Object {          \n              Write-Output -InputObject \"---------------------------------\"          \n              Write-Output -InputObject \"INFO: $($_.Name) output [$($elapsedSeconds)s]\"          \n              Write-Output -InputObject \"---------------------------------\"          \n              $_ | Receive-Job          \n              Write-Output -InputObject \"---------------------------------\"          \n              Write-Output -InputObject \"\"          \n          }          \n          $elapsedSeconds += $pollingInterval          \n          [Threading.Thread]::Sleep($pollingInterval * 1000)          \n      }          \n      $jobs.ChildJobs | Where-Object { $_.JobStateInfo.State -eq \"Failed\" } | ForEach-Object {          \n          Write-Output -InputObject \"ERROR: At least one of the deployments failed with the following reason:\"          \n          Write-Output -InputObject $_.JobStateInfo.Reason          \n      }\n                          \n      if ($jobs.State -eq \"Failed\")          \n      {          \n          exit 1          \n      }          \n      else          \n      {          \n          exit 0          \n      }\n    powerShellErrorActionPreference: 'continue'\n    workingDirectory: './infrastructure/environments/$(TerraFormEnvironmentName)'\n`\n```\nEdit 1\nTo get all output from `ChildJobs` I had to alter the code like so:\n```\n`      [int]$pollingInterval = 10          \n      [int]$elapsedSeconds = 0          \n      $lastResultsRead = false\n      while ($jobs.State -eq \"Running\" -or !$lastResultsRead)\n      {          \n          $lastResultsRead = $jobs.State -ne \"Running\"\n          $jobs.ChildJobs |\u00a0ForEach-Object {          \n              Write-Output -InputObject \"---------------------------------\"          \n              Write-Output -InputObject \"INFO: $($_.Name) output [$($elapsedSeconds)s]\"          \n              Write-Output -InputObject \"---------------------------------\"          \n              $_ | Receive-Job          \n              Write-Output -InputObject \"---------------------------------\"          \n              Write-Output -InputObject \"\"          \n          }          \n          $elapsedSeconds += $pollingInterval          \n          if (!$lastResultsRead)\n          {\n              [Threading.Thread]::Sleep($pollingInterval * 1000)\n          }\n`\n```\nHope this helps everyone that wants to achieve something similar.",
      "solution": "So it seems that the mystery is solved.\nTLDR;\nIf you want proper error handling, remove the `--verbose` from all Azure CLI calls as the verbose output is always written to StdErr even when setting the environment variable `AZURE_CORE_ONLY_SHOW_ERRORS`.\nExplanation\nI stumbled over the solution by adding an unrelated functionality to this script and noticed that in certain situations the last output of the `ChildJobs` is not being collected. I initially took that for a quirk of the Azure DevOps task but discovered that this also happens when I debug the output locally in VSCode.\nThat led me to add another condition for the `while` loop that would ensure to give me the final output. I'll update the script in my initial post accordingly. Finally equipped with the whole picture of what is going on in the `ChildJobs` I set up a separate test pipeline where I would run different test cases to find the culprit. Soon enough I noticed that taking away `--verbose` prevents the task from failing. This happened with `AZURE_CORE_ONLY_SHOW_ERRORS` set or not. So I gave the `--only-show-errors` option a go, which should have the same result as the environment variable though only on a single Azure CLI call. Due to the full output now at my disposal I could finally see the message that `--verbose` and `--only-show-errors` can't be used in conjunction. That settled it. `--verbose` had to go. All it adds is the information of how long the command ran anyway. I think we can do without it.\nOn an additional side-note: at the same time I discovered that `ForEach-Object -Parallel {} -AsJob` is making heavy use of PowerShell runspaces. That means that it cannot be debugged from within VSCode in the typical way. I found a video that might help in situations like this: https://www.youtube.com/watch?v=O-dksknPQBw\nI hope this answer helps others that stumble over the same strange behavior. Happy coding.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-08-31T09:36:23",
      "url": "https://stackoverflow.com/questions/68994648/azure-devops-azure-cli-task-with-powershell-script-and-parallel-foreach-object-e"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 66672353,
      "title": "How to install Azure CLI Billing Account",
      "problem": "I am trying to run\n`az billing account list`\nHowever, when I run this I get:\n```\n`az billing: 'account' is not in the 'az billing' command group. See 'az billing --help'. If the command is from an extension, please make sure the corresponding extension is installed. To learn more about extensions, please visit https://learn.microsoft.com/en-us/cli/azure/azure-cli-extensions-overview\n`\n```\nI have installed the `account` extension but it still has not worked.\nIf I run it in the Cloud Shell I get:\n```\n`Command group 'billing account' is in preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\n[]\n`\n```\nso I do get a response here.\nI cannot find anything to install this extension or preview extentions. \nRepo doesn't have it https://github.com/Azure/azure-cli \nPython Repo doesn't have it https://pypi.org/user/microsoft/ \nNo information on the Documentation https://learn.microsoft.com/en-us/rest/api/billing/2019-10-01-preview/billingaccounts \nlisting the extensions doesn't show anyting https://learn.microsoft.com/en-us/cli/azure/azure-cli-extensions-overview",
      "solution": "The upgraded billing commands are shipped with Azure CLI 2.15.0 and the Cloud Shell you are using with Azure might be an older version, Try to update and see",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-03-17T12:40:43",
      "url": "https://stackoverflow.com/questions/66672353/how-to-install-azure-cli-billing-account"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 65910319,
      "title": "AzureBlobStorage AuthorizationPermissionMismatch error using User Managed Identities, Python SDK from AKS",
      "problem": "I'm running a Python app in AKS (as a Job, but doesn't matter), using the Azure Python SDK to access blob storage.  I'm using a User Managed Identity for auth, using `ManagedIdentityCredential` with the `client_id` kwarg (see https://learn.microsoft.com/en-us/python/api/azure-identity/azure.identity.managedidentitycredential?view=azure-python).  It is successfully able to query the IMDS endpoint and obtain a token, but I'm still hitting an error.  Anybody has any idea about what setup I might be missing?\nThere are precious little docs about user managed identities overall, esp in relation to AKS and the blob store, and this error.\nSuccessful IMDS token fetch:\n```\n`2021-01-26 05:26:05,944 - azure.core.pipeline.policies.http_logging_policy - INFO - Request URL: 'http://REDACTED/metadata/identity/oauth2/token?api-version=REDACTED&resource=REDACTED&client_id=REDACTED'\n2021-01-26 05:26:05,945 - azure.core.pipeline.policies.http_logging_policy - INFO - Request method: 'GET'\n2021-01-26 05:26:05,945 - azure.core.pipeline.policies.http_logging_policy - INFO - Request headers:\n2021-01-26 05:26:05,945 - azure.core.pipeline.policies.http_logging_policy - INFO -     'Metadata': 'REDACTED'\n2021-01-26 05:26:05,945 - azure.core.pipeline.policies.http_logging_policy - INFO -     'User-Agent': 'azsdk-python-identity/1.5.0 Python/3.7.7 (Linux-4.15.0-1103-azure-x86_64-with-debian-9.12)'\n2021-01-26 05:26:05,945 - azure.core.pipeline.policies.http_logging_policy - INFO - No body was attached to the request\n2021-01-26 05:26:05,956 - azure.core.pipeline.policies.http_logging_policy - INFO - Response status: 200\n2021-01-26 05:26:05,956 - azure.core.pipeline.policies.http_logging_policy - INFO - Response headers:\n2021-01-26 05:26:05,956 - azure.core.pipeline.policies.http_logging_policy - INFO -     'Content-Type': 'application/json; charset=utf-8'\n2021-01-26 05:26:05,956 - azure.core.pipeline.policies.http_logging_policy - INFO -     'Server': 'IMDS/150.870.65.486'\n2021-01-26 05:26:05,956 - azure.core.pipeline.policies.http_logging_policy - INFO -     'Date': 'Tue, 26 Jan 2021 05:26:05 GMT'\n2021-01-26 05:26:05,956 - azure.core.pipeline.policies.http_logging_policy - INFO -     'Content-Length': '1760'\n2021-01-26 05:26:05,957 - azure.identity._internal.decorators - INFO - ManagedIdentityCredential.get_token succeeded\n2021-01-26 05:26:05,957 - azure.identity._credentials.chained - INFO - ChainedTokenCredential acquired a token from ManagedIdentityCredential\n`\n```\nSubsequent API call to blob.core.windows.net/.... errors:\n```\n`  File \"/usr/local/lib/python3.7/site-packages/azure/storage/blob/_blob_client.py\", line 685, in upload_blob\n    return upload_block_blob(**options)\n  File \"/usr/local/lib/python3.7/site-packages/azure/storage/blob/_upload_helpers.py\", line 157, in upload_block_blob\n    process_storage_error(error)\n  File \"/usr/local/lib/python3.7/site-packages/azure/storage/blob/_shared/response_handlers.py\", line 150, in process_storage_error\n    error.raise_with_traceback()\n  File \"/usr/local/lib/python3.7/site-packages/azure/core/exceptions.py\", line 218, in raise_with_traceback\n    raise super(AzureError, self).with_traceback(self.exc_traceback)\n  File \"/usr/local/lib/python3.7/site-packages/azure/storage/blob/_upload_helpers.py\", line 105, in upload_block_blob\n    **kwargs)\n  File \"/usr/local/lib/python3.7/site-packages/azure/storage/blob/_generated/operations/_block_blob_operations.py\", line 233, in upload\n    raise HttpResponseError(response=response, model=error)\nazure.core.exceptions.HttpResponseError: This request is not authorized to perform this operation using this permission.\nRequestId:defcc13f-101e-006c-6aa3-f321cb000000\nTime:2021-01-26T05:26:06.0112926Z\nErrorCode:AuthorizationPermissionMismatch\nError:None\n`\n```\nThe blob storage resource in question has a role assignment to the user-managed identity, as a \"contributor\" to \"This resource\".\nCode:\n`    managed_identity = ManagedIdentityCredential(client_id=mi_client_id)\n    azure_cli = AzureCliCredential()\n    credential_chain = ChainedTokenCredential(managed_identity, azure_cli)\n    return BlobServiceClient(url_prefix, credential=credential_chain)\n`\nVersions:\nazure-identity 1.5, Python 3.7.7\nI'm not sure our AKS Cluster has granted the user managed identity a role, and I'm not sure if that matters, or what else needs to be set up.\nthanks",
      "solution": "It turns out the answer is that  \u201cStorage Blob Data Contributor\u201d and \u201cStorage Queue Data Contributor\u201d roles BOTH have to be assigned to resolve the issue.",
      "question_score": 1,
      "answer_score": 10,
      "created_at": "2021-01-26T23:40:20",
      "url": "https://stackoverflow.com/questions/65910319/azureblobstorage-authorizationpermissionmismatch-error-using-user-managed-identi"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 66467272,
      "title": "Get-AzApplicationInsights is not recognized",
      "problem": "I constructed a new Azure Pipeline and added this 'Azure CLI' task to try and run some Azure CLI Powershell scripting. Primarily, I want to do some checks on an existing AppInsights resources.\n(Azure CLI)\nhttps://github.com/microsoft/azure-pipelines-tasks/blob/master/Tasks/AzureCLIV2/Readme.md\nI get this error when runnin 'Get-AzApplicationInsights' inside the Azure CLI Task.\n```\n`'Get-AzApplicationInsights' : The term 'Get-AzApplicationInsights' is not recognized as the name of a cmdlet, function.\n`\n```\nThe whole yaml script looks like this:\n```\n`steps:\n- task: AzureCLI@2\n  displayName: 'Azure CLI Powershell'\n  inputs:\n    azureSubscription: ####\n    scriptType: ps\n    scriptLocation: inlineScript\n    inlineScript: |\n     Write-Output \"RESULTS:\"\n     az config set extension.use_dynamic_install=yes_without_prompt\n     Get-AzApplicationInsights -ResourceGroupName ############# -Name ############## Select-String -Pattern \"PricingPlan\"\n`\n```\nIs there something I am missing as to why the cmdlet is not being recognised? Should there be a module I need to first to import?",
      "solution": "To run the Azure powershell `Get-AzApplicationInsights`, just run it in the Azure PowerShell task.\nOr if you want to use the Azure CLI task, you could use CLI command `az monitor app-insights component show` directly instead of the powershell command.",
      "question_score": 1,
      "answer_score": 4,
      "created_at": "2021-03-04T02:25:24",
      "url": "https://stackoverflow.com/questions/66467272/get-azapplicationinsights-is-not-recognized"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 79099651,
      "title": "Azure CLI Errors - Certificate Verify Failed",
      "problem": "I am unable to run any `az` commands in the terminal, as I keep getting the following exception:\n`PS C:\\>az upgrade --verbose\nThis command is under preview and under development. Reference and support levels: https://aka.ms/CLI_refstatus\nFailed to get the latest version from 'https://raw.githubusercontent.com/Azure/azure-cli/main/src/azure-cli/setup.py'. HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /Azure/acure-cli/main/src/azure-cli/setup.py (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1006)')))\nFailed to get the latest azure-cli version.\nUpgrade finished.You can enable auto-upgrade with 'az config set auto-upgrade.enable=yes'. More details in https://docs.microsoft.com/cli/azure/update-azure-cli#automatic-update\nCommand ran in 1.208 seconds (init: 0.221, invoke: 0.986)\n`\nThis happens on any terminal I use on my Windows machine, and this error also occurs in the terminal in my WSL Ubuntu instance.\nThis happens for `az upgrade`, `az login`, and `az extension` commands, amongst others.  What can I do?",
      "solution": "I discovered that the office network I was on is protected behind a TLS proxy, so most TLS requests have a self-signed certificate injected into the certificate chain for each request.\nIf you visit a random site using the Chrome browser (e.g. https://portal.azure.com/) and view the SSL certificate \"Issued By\", and see that the common name (CN) is something unexpected (e.g. tlsProxy.myNetworkServer01.com), then you can safely assume there is a proxy server somewhere, at least for TLS requests.  If you see a normal issuer, maybe try a different random site that likely wouldn't be whitelisted?\nWhen viewing the certificate in Chrome, go to the Details tab and select the topmost cert in the hierarchy, then select the \"Export...\" button and save the file as a base64 single certificate.\nInstall CA Certificate\nFor Windows, right-click the saved certificate and select \"Install\".  It's more secure to store it just for the current user, but you can do the local machine if you want.  Install it to the \"Trusted Root Certification Authorities\" store.\nFor Ubuntu (in my case, in WSL), run the following:\n`sudo apt-get install -y ca-certificates  # Installs a cert management tool, might already be installed.\nsudo cp /mnt/c/Users/myUser/Desktop/myCertificate.crt /usr/local/share/ca-certificates  # Copies the saved certificate file from its saved location (in this case, the WSL host's C: drive, user's desktop folder) to the Ubuntu system.\nsudo update-ca-certificates  # Installs the copied certificate, will likely show \"1 added\".\n`\nConfigure Azure CLI Python\nThe Azure CLI uses some Python commands internally, which in turn by default will not make use of trusted system certificates.  Also, Azure CLI has its own Python runtime which has its own configuration.  You will need to update this Python instance to use a hook that tells the Certifi library to use trusted certificates.\nFor Windows, in a terminal, navigate to the installation directory for Azure CLI (default `C:\\Program Files\\Microsoft SDKs\\Azure\\CLI2\\` for 64-bit installs).  Execute `python.exe` here with the command:\n`PS C:\\Program Files\\Microsoft SDKs\\Azure\\CLI2>./python.exe -m pip install pip-system-certs\n`\nYou may need to run your terminal as an administrator.\nFor Ubuntu (in my case, in WSL), you would do the same.  Navigate to the install directory (default `/opt/az`) and run the following install command using the Python runtime in the `bin` folder:\n`myUser@machineName:~$ /opt/az/bin/python3.11 -m pip install pip-system-certs  # Python version may be different for your scenario.\n`\nRestart your terminal session, and try your `az` command again.",
      "question_score": 1,
      "answer_score": 6,
      "created_at": "2024-10-17T21:46:44",
      "url": "https://stackoverflow.com/questions/79099651/azure-cli-errors-certificate-verify-failed"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 78613488,
      "title": "Creating Azure DevOps Workload Identity Federation with Az CLI/Az PS",
      "problem": "does anyone know how to create an Azure DevOps \"Azure Resource Manager/Workload Identity federation with OpenID Connect\" Service Endpoint automated using Az CLI or Az PS terminals? Failing that even calling the Azure DevOPs REST API will do.\nHighlighted is what I'm looking to create:\n\nFrom investigation, at best they allow you to create only regular Service Principal endpoints? From what I can these WIF ARM Service Endpoints can be created only using the AzDO front end portal, and even Terraform, but neither fits my use. It seems crazy that MS have exposed WIF service endpoints to a third party solution (Terraform), but not their own internal cmdlet modules!\nAny advice will be greatly appreciated.",
      "solution": "As mentioned in this MS Doc, you must first define the configuration file to create a service endpoint of Workload Identity Federation type via Azure CLI.\ndevops.json:\n`{\n    \"data\": {\n      \"subscriptionId\": \"subId\",\n      \"subscriptionName\": \"subName\",\n      \"environment\": \"AzureCloud\",\n      \"scopeLevel\": \"Subscription\"\n    },\n    \"name\": \"WorkFederatedSE\",\n    \"type\": \"azurerm\",\n    \"url\": \"https://management.azure.com/\",\n    \"authorization\": {\n      \"scheme\": \"WorkloadIdentityFederation\",\n      \"parameters\": {\n        \"tenantid\": \"tenantId\",\n        \"serviceprincipalid\": \"appId\"\n      }\n    },\n    \"isShared\": false,\n    \"isReady\": true,\n    \"serviceEndpointProjectReferences\": [\n      {\n        \"projectReference\": {\n          \"id\": \"projectId\",\n          \"name\": \"projName\"\n        },\n        \"name\": \"WorkFederatedSE\"\n      }\n    ]\n  }\n`\nIn my case, I uploaded this .json file in Azure Cloud Shell and ran below CLI command to create service connection after connecting with `az login`:\n`az devops service-endpoint create --service-endpoint-configuration ./devops.json --org https://dev.azure.com/orgName/ --project projName\n`\nResponse:\n\nWhen I checked the same in Azure DevOps portal, new service connection created successfully like this:\n\nYou can check that service connection properties by clicking `Edit` button that has \"Workload Identity federation with OpenID Connect\" type as below:\n\nTo create the same using Azure DevOps REST API, make use of below request:\n`POST https://dev.azure.com/orgname/_apis/serviceendpoint/endpoints?api-version=7.1-preview.4\n\n{\n    \"data\": {\n      \"subscriptionId\": \"subId\",\n      \"subscriptionName\": \"subName\",\n      \"environment\": \"AzureCloud\",\n      \"scopeLevel\": \"Subscription\"\n    },\n    \"name\": \"WorkFederatedSE\",\n    \"type\": \"azurerm\",\n    \"url\": \"https://management.azure.com/\",\n    \"authorization\": {\n      \"scheme\": \"WorkloadIdentityFederation\",\n      \"parameters\": {\n        \"tenantid\": \"tenantId\",\n        \"serviceprincipalid\": \"appId\"\n      }\n    },\n    \"isShared\": false,\n    \"isReady\": true,\n    \"serviceEndpointProjectReferences\": [\n      {\n        \"projectReference\": {\n          \"id\": \"projectId\",\n          \"name\": \"projName\"\n        },\n        \"name\": \"WorkFederatedSE\"\n      }\n    ]\n  }\n`\nResponse:\n\nFor service connection of \"Azure Resource Manager using Workload Identity federation with OpenID Connect (automatic)\" type, add `\"creationMode\": \"Automatic\",` in data section and remove `serviceprincipalid` like this:\n`POST https://dev.azure.com/orgname/_apis/serviceendpoint/endpoints?api-version=7.1-preview.4\n\n{\n    \"data\": {\n      \"subscriptionId\": \"subId\",\n      \"subscriptionName\": \"subName\",\n      \"creationMode\": \"Automatic\", //Add this\n      \"environment\": \"AzureCloud\",\n      \"scopeLevel\": \"Subscription\"\n    },\n    \"name\": \"WorkFederatedSEAut\",\n    \"type\": \"azurerm\",\n    \"url\": \"https://management.azure.com/\",\n    \"authorization\": {\n      \"scheme\": \"WorkloadIdentityFederation\",\n      \"parameters\": {\n        \"tenantid\": \"tenantId\"\n      }\n    },\n    \"isShared\": false,\n    \"isReady\": true,\n    \"serviceEndpointProjectReferences\": [\n      {\n        \"projectReference\": {\n          \"id\": \"projectId\",\n          \"name\": \"projName\"\n        },\n        \"name\": \"WorkFederatedSEAut\"\n      }\n    ]\n  }\n`\nResponse:\n\nWhen I checked in DevOps Portal, new service connection of Automatic type created successfully:\n\nReference:\nEndpoints - Create - REST API (Azure DevOps Service Endpoint) | Microsoft",
      "question_score": 1,
      "answer_score": 6,
      "created_at": "2024-06-12T17:01:17",
      "url": "https://stackoverflow.com/questions/78613488/creating-azure-devops-workload-identity-federation-with-az-cli-az-ps"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 76388274,
      "title": "Updating web redirect uri of Azure AD app registration",
      "problem": "I have a scenario where my pipeline should update the app registration with an additional redirectUrl.\nI have managed to extract the current web.redirectUris with the following:\n` existing_urls=$(az ad app show --id '' --query \"[web.redirectUris]\" --output tsv)`\nI would like to achieve something like this\n```\n`existing_urls=$(az ad app show --id '' --query \"[web.redirectUris]\" --output tsv)\naz ad app update --id '' --web-redirect-uris \"$existing_urls https://hostname.com/newCallback\"\n`\n```\nI have tried updating the web.redirectUris in two ways and both of them have failed when I pass multiple redirect URIs.\nAttempt 1\n```\n`az ad app update --id '' --web-redirect-uris \"https://hostname.com/callbackx https://hostname.com/callbacky\"\n\nOne or more properties contains invalid values.\n`\n```\nHowever when having only one uri this worked fine\n```\n`az ad app update --id '' --web-redirect-uris \"https://hostname.com/callbackx\"\n`\n```\nAttempt 2\nThis one fails regardless of number of redirectUris that are passed\n```\n`az ad app update --id '' --set \"web.redirectUris=['https://hostname.com/callbackx', 'https://hostname.com/callbacky']\"\n\nCouldn't find 'web' in ''. Available options: []\n`\n```",
      "solution": "Tried as shown :But got the same error:\n```\n`az ad app show --id 1e7bxxx7830\n\nexisting_urls=$(az ad app show --id 1e7b8fxxxx830 --query \"[web.redirectUris]\")\n\naz ad app update --id 1e7xxx0a7830 --web-redirect-uris \"$existing_urls https://hostname.com/newCallback\"\n\n$updated_urls=\"$existing_urls https://hostname.com/newCallback\"\n\naz ad app update --id 1e7b8xxx0a7830  --set \"web.redirectUris='$updated_urls'\"\n\naz ad app update --id 1e7b8fxxxd0a7830  --set \"web.redirectUris='$updated_urls'\"\n`\n```\nError:\n```\n`Couldn't find 'web' in ''. Available options: []\n`\n```\n\nFollowing command worked foe me in azure cli in updating multiple Redirect Urls:\n`az ad app update --id '1e7bxxxa7830' --web-redirect-uris \"https://hostname.com/callback\"  \"https://jwt.ms\" \"https://myexampleapp.com\"`\nhere --id is `clientId` .\n\nSo  give the command with required urls as\naz ad app update --id '1e7bxxxa7830' --web-redirect-uris \"``\"  \"``\" \"``\"\nupon `az ad app show --id 1e7b8xxxx830`",
      "question_score": 1,
      "answer_score": 3,
      "created_at": "2023-06-02T10:05:03",
      "url": "https://stackoverflow.com/questions/76388274/updating-web-redirect-uri-of-azure-ad-app-registration"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 73110661,
      "title": "&#39;create&#39; is misspelled or not recognized by the system on az ml dataset create",
      "problem": "I'm trying to create a dataset on my azure ML workspace from a GitHub action\nI've created a datastore and uploaded data to that datastore\nwhen I try to create a dataset using the cli, I get this error:\n`'create' is misspelled or not recognized by the system.`\nthis is the command i use:\n```\n`> az ml dataset create \n          -n insurance_dataset \n          --resource-group rg-name \n          --workspace-name ml-ws-name \n          -p 'file:azureml/datastore/$(az ml datastore show-default -w ml-ws-name -g rg-name --query name -o tsv)/insurance/insurance.csv'\n`\n```\nany idea what am I doing wrong?",
      "solution": "in my case, the issue was solved by upgrading the ml extension to `azure-cli-ml v2`\nRemove any existing installation of the of `ml` extension and also the CLI v1 `azure-cli-ml` extension:\n```\n`az extension remove -n azure-cli-ml\naz extension remove -n ml\n`\n```\nNow, install the ml extension:\n```\n`az extension add -n ml -y\n`\n```\nwhich still doesn't explain why the `create` command wasn't recognized, but the v2 behavior works fine for me.",
      "question_score": 1,
      "answer_score": 6,
      "created_at": "2022-07-25T16:09:02",
      "url": "https://stackoverflow.com/questions/73110661/create-is-misspelled-or-not-recognized-by-the-system-on-az-ml-dataset-create"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 78611807,
      "title": "az role assignment delete: The request did not have a subscription or a valid tenant level resource provider",
      "problem": "I'm trying to do some cleanup (to solve other issues) within a yaml, and I've come up with this:\n```\n`    - task: AzureCLI@2\n      inputs:\n        azureSubscription: 'MYSUBSCRIPTION'\n        scriptType: pscore\n        scriptLocation: inlineScript\n        inlineScript: |\n          az role assignment delete --ids \"GUID1 GUID2 GUIDn\"\n      name: CleanupRoleAssignments\n`\n```\nAnd I'm getting this error:\n```\n`ERROR: (MissingSubscription) The request did not have a subscription or a valid tenant level resource provider.\nCode: MissingSubscription\nMessage: The request did not have a subscription or a valid tenant level resource provider.\n`\n```\nI tried adding `--scope` but that only got me an additional warning `WARNING: option '--scope' will be ignored due to use of '--ids'`. The error persisted.\nAny idea on what I'm doing wrong?\nTIA\nJim",
      "solution": "Try below in local pc: Replace with your own subscription and resource group\n```\n`az role assignment list --scope /subscriptions/xxxx-xxx-xxx-xxx-xxxx/resourceGroups/wb-test-rg\n`\n```\nwill return like\n```\n`[\n  {\n    \"condition\": null,\n    \"conditionVersion\": null,\n    \"createdBy\": \"492b05b3-bc6c-4497-8d3e-ab42366d3b9a\",\n    \"createdOn\": \"2024-06-06T08:33:53.807218+00:00\",\n    \"delegatedManagedIdentityResourceId\": null,\n    \"description\": null,\n    \"id\": \"/subscriptions/xxxx-xxx-xxx-xxx-xxxx/resourceGroups/wb-test-rg/providers/Microsoft.Authorization/roleAssignments/454c98bf-349a-4643-8f41-8bf45293440e\",\n    \"....\"\n  }\n]\n\n`\n```\nthen delete the assignment using the id:\n```\n`az role assignment delete --ids \"/subscriptions/xxxx-xxx-xxx-xxx-xxxx/resourceGroups/wb-test-rg/providers/Microsoft.Authorization/roleAssignments/454c98bf-349a-4643-8f41-8bf45293440e\"\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2024-06-12T11:36:10",
      "url": "https://stackoverflow.com/questions/78611807/az-role-assignment-delete-the-request-did-not-have-a-subscription-or-a-valid-te"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 77715043,
      "title": "how to list and find all the secrets in the keyvault which is to be expired in next 60 days?",
      "problem": "As Azure Runbook has some limitation to integrate with Azuredevops server pipeline, which is hosted in onprem, we were looking for a bash script to find the secret in a listed keyvault list and if the secrets in the keyvault is about to expire in next 60 days only, then trigger the release pipeline with the specific secret and kv to extend the date to next 2 years followed by the release approval.\nWe are struggling here to find the secret with its expire and to estimate the remaining days\n```\n`(az keyvault secret list  --vault-name kv-01  --query \"[?attributes.expires  ].{Id:id, expires:attributes.expires}\" | jq '.[].expires' '+%s'\n`\n```\nLooping through keyvaults failing\n```\n`             inlineScript: |\n                 #Azure Key Vault details\n                 keyvaults=$(az keyvault list --query \"[].{Name:name}\")\n                 echo \"keyvaults are as below $keyvaults\"\n                 #Iterate through the kvs\n                 for row in $(echo \"${keyvaults}\" | jq -c '.[]'); do\n                     keyVaultName=$(echo \"$row\" | jq -r '.Name') \n                     done             \n                     #Get the current date in UTC\n                     currentDate=$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\n                     echo \"currentDate is $currentDate\".....\n........................................\n`\n```\n.....................\n.",
      "solution": "how to list and find all the secrets in the keyvault which is to be expired in next 60 days?\n\nTo find secrets in an `Azure Key Vault` that are going to expire in the next 60 days and to estimate the remaining days for each secret, you can use the below bash script.\n`   \n#Azure Key Vault details\nkeyVaultName=\"Keyvault name\"\n\n#Get the current date in UTC\ncurrentDate=$(date -u +\"%Y-%m-%dT%H:%M:%SZ\")\n\n#Get a list of secrets in the Key Vault\nsecrets=$(az keyvault secret list --vault-name $keyVaultName --query \"[].{Name:name, Expires:attributes.expires}\")\n\n#Iterate through the secrets\nfor row in $(echo \"${secrets}\" | jq -c '.[]'); do\n    secretName=$(echo \"$row\" | jq -r '.Name')\n    expirationDate=$(echo \"$row\" | jq -r '.Expires')\n\n    # Check if the secret is already expired\n    if [ \"$(date -u +\"%s\")\" -gt \"$(date -u -d \"$expirationDate\" +\"%s\")\" ]; then\n        echo \"Output-------------------------------------\"\n        echo \"Expired: Secret $secretName has already expired on $expirationDate.\"\n\n    else\n        # Calculate the remaining days until expiration\n        remainingDays=$(( ($(date -u -d \"$expirationDate\" +\"%s\") - $(date -u -d \"$currentDate\" +\"%s\")) / 86400 ))\n\n        # Check if the secret is about to expire (within the next 60 days)\n        if [ $remainingDays -lt 60 ]; then\n            echo \"About to Expire in 60 days : Secret $secretName is about to expire in $remainingDays days. Expiration Date: $expirationDate\"\n\n            # Trigger Azure DevOps release pipeline\n            echo \"Triggering Azure DevOps release pipeline...\"\n            # add your script to trigger the Azure DevOps release pipeline\n\n        else\n            echo \"Not Expiring Soon: Secret $secretName is not expiring in 60 days. It's about to expire in $remainingDays days. Expiration Date: $expirationDate\"\n        fi\n    fi\ndone\n\n`\nThe above script will display already expired secrets, secrets about to expire in 60 days, and secrets that are not yet expired in the `Key Vault`.\nOutput:",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-12-25T22:45:19",
      "url": "https://stackoverflow.com/questions/77715043/how-to-list-and-find-all-the-secrets-in-the-keyvault-which-is-to-be-expired-in-n"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 77477840,
      "title": "Azure CLI command to resolve refresh token error",
      "problem": "What specific syntax or commands need to be added to the sequence of Azure CLI commands below in order to remove the root cause of the `AADSTS700082` error so that the commands can run without error?\nAnd what is going on behind the scenes to cause this seemingly senseless error?\n```\n`C:\\path\\to\\dir>az login --service-principal -u long-alpha-numeric-id -p long-pass-word --tenant 88888888-4444-4444-4444-121212121212  \n[  \n  {  \n    \"cloudName\": \"AzureCloud\",\n    \"homeTenantId\": \"88888888-4444-4444-4444-121212121212\",\n    \"id\": \"11111111-1111-1111-1111-111111111111\",\n    \"isDefault\": true,\n    \"managedByTenants\": [],\n    \"name\": \"SomeName\",\n    \"state\": \"Enabled\",\n    \"tenantId\": \"88888888-4444-4444-4444-121212121212\",\n    \"user\": {\n      \"name\": \"long-alpha-numeric-id\",\n      \"type\": \"servicePrincipal\"\n    }\n  },\n  {\n    \"cloudName\": \"AzureCloud\",\n    \"homeTenantId\": \"88888888-4444-4444-4444-121212121212\",\n    \"id\": \"22222222-2222-2222-2222-222222222222\",\n    \"isDefault\": false,\n    \"managedByTenants\": [],\n    \"name\": \"AnotherName\",\n    \"state\": \"Enabled\",\n    \"tenantId\": \"88888888-4444-4444-4444-121212121212\",\n    \"user\": {\n      \"name\": \"long-alpha-numeric-id\",\n      \"type\": \"servicePrincipal\"\n    }\n  }\n]  \n\nC:\\path\\to\\dir>az account set --subscription 12345678-1234-1234-1234-123456789012\n\nC:\\path\\to\\dir>az group create --name myRG --location eastus\nAADSTS700082: The refresh token has expired due to inactivity.\u00a0The token was issued on 2023-05-04T21:19:28.1452801Z and was inactive for 90.00:00:00. Trace ID: 87654321-4321-4321-4321-210987654321 Correlation ID: 80808080-4040-4040-4040-121212121212 Timestamp: 2023-11-14 01:23:55Z    \nInteractive authentication is needed. Please run:\naz login --scope https://management.core.windows.net//.default  \n`\n```\nThe secret `long-pass-word` is valid and up to date for the service principal with ID `long-alpha-numeric-id`.  I confirmed this in the Entra Directory in the Azure Portal.\nThe `az login --service-principal -u long-alpha-numeric-id -p long-pass-word --tenant 88888888-4444-4444-4444-121212121212` command seems to run successfully, as you can see above.\nThe `az account set --subscription 12345678-1234-1234-1234-123456789012` command also runs without error when a valid subscription ID is passed into it.\nBut the `az group create --name myRG --location eastus` command is throwing the `AADSTS700082` error as you can see if you scroll to the bottom of the output in the OP above.\nWhat gives?\nThis needs to be run completely in automation, so we cannot try the Interactive authentication that is suggested in the error message.",
      "solution": "AADSTS700082: The refresh token has expired due to inactivity. The token was issued on 2023-05-04T21:19:28.1452801Z and was inactive for 90.00:00:00. Trace ID: 87654321-4321-4321-4321-210987654321 Correlation ID: 80808080-4040-4040-4040-121212121212 Timestamp: 2023-11-14 01:23:55Z  Interactive authentication is needed. Please run: az login --scope https://management.core.windows.net//.default\n\nThe error usually occurs if the refresh token has been expired and to resolve the error, you need to re-run `az` login.\nIn your case, the error is due to the existing `az` session that needs to be logged out.\nHence to resolve the error, execute `az logout` and the re-run the commands:\n`az logout\n\naz login --service-principal -u ClientID -p ClientSecret --tenant TenantID\n\naz account set --subscription SubscriptionID\n\naz group create --name RukRG --location eastus\n`\n\nResource group created successfully:",
      "question_score": 1,
      "answer_score": 5,
      "created_at": "2023-11-14T03:15:51",
      "url": "https://stackoverflow.com/questions/77477840/azure-cli-command-to-resolve-refresh-token-error"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 72300751,
      "title": "Azure cli cant connect due to Invalid client secret provided",
      "problem": "Pipeline error code AADSTS7000215- Invalid client secret is provided. however, the  client secret  provided is correct because when I run the script locally and provide client secret in .env file it runs. However, creating a yaml file with azurecli I get the error.\n```\n`- task: AzureCLI@2\n  inputs:\n    azureSubscription: 'Subscription'\n    scriptType: 'pscore'\n    scriptLocation: 'inlineScript'\n    inlineScript: 'python script.py'\n    workingDirectory: 'workingdirectory'\n`\n```\nFull ERROR: AADSTS7000215: Invalid client secret provided. Ensure the secret being sent in the request is the client secret value, not the client secret ID, for a secret added to app",
      "solution": "Client secret error might be related to service connection you use.\nDid you verify that service connection and related SPN are properly configured?",
      "question_score": 1,
      "answer_score": 3,
      "created_at": "2022-05-19T09:58:27",
      "url": "https://stackoverflow.com/questions/72300751/azure-cli-cant-connect-due-to-invalid-client-secret-provided"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 77315904,
      "title": "Az login error: &quot;The ID token is not yet valid. Make sure your computer&#39;s time and time zone are both correct.&quot;",
      "problem": "When trying to use `az login` from WSL2 I got the following error:\nThe ID token is not yet valid. Make sure your computer's time and time zone are both correct.",
      "solution": "I discovered my WSL did not have the same system time as Windows, not sure why, but running `sudo hwclock -s` fixed this.",
      "question_score": 1,
      "answer_score": 4,
      "created_at": "2023-10-18T13:30:12",
      "url": "https://stackoverflow.com/questions/77315904/az-login-error-the-id-token-is-not-yet-valid-make-sure-your-computers-time-a"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 74792851,
      "title": "Azure CLI - Automation account replace-content is breaking on new line",
      "problem": "I've got a very frustrating situation using the Azure CLI and attempting to replace the content of an Automation Account.\nI am attempting to update it via a Azure DevOps pipeline AzureCLI@2 task. This is the script line i am calling\n```\n`az automation runbook replace-content --debug --automation-account-name \"${{ parameters.automationAccountName }}\" --resource-group \"${{ parameters.resourceGroup }}\" --name \"Schedule Summary\" --content \"`@temp.txt\"\n`\n```\nThe issue i am having is the automation account runbook is updated, but the text is truncated. The contents of temp.txt is this -\n```\n`Param(\n    [string]$resourceGroup ='',\n    [string]$UAMI ='',\n    [string]$serverInstance ='',\n`\n```\nBut the script that ends up in the runbook is simply\n```\n`Param(\n`\n```\nIts clearly breaking on CRLF but i can't figure out how to fix it. If i remove all CRLF then it appears as one line and the script then doesn't run.\nI can tell where the problem is? Is the AzureCLI, powershell? or the devops task.",
      "solution": "I run the script in windows hosted agent and reproduce your issue.Its clearly breaking on CRLF. Because windows can't identify the CRLF. You should run the script in Linux agent.\nbreaking on CRLF based on windows agent\n\nalter to linux agent in pipeline\n```\n`pool:\n  vmImage: ubuntu-22.04\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-12-14T03:03:55",
      "url": "https://stackoverflow.com/questions/74792851/azure-cli-automation-account-replace-content-is-breaking-on-new-line"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 74631702,
      "title": "Installation in Ubuntu Docker file getting failed",
      "problem": "I don't have any Ubuntu machines enabled with internet and I have requirement to have a docker image ready with some basic softwares enabled as this need to be configured as our Azuredevops build agent.\nSo in order to work my Dockerfile , I used one of aksnode itself to build my docker image as there I could see some of the apt-get commands working somehow (may be with default internet connectivity enabled there for aks functionalities).\nBelow is the source.list content of aks node and I tried to copy the same to my Ubuntu based Dockerfile\n```\n`deb http://azure.archive.ubuntu.com/ubuntu/ bionic main restricted\n# deb-src http://azure.archive.ubuntu.com/ubuntu/ bionic main restricted\n\n## Major bug fix updates produced after the final release of the\n## distribution.\ndeb http://azure.archive.ubuntu.com/ubuntu/ bionic-updates main restricted\n# deb-src http://azure.archive.ubuntu.com/ubuntu/ bionic-updates main restricted\n\n## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu\n## team. Also, please note that software in universe WILL NOT receive any\n## review or updates from the Ubuntu security team.\ndeb http://azure.archive.ubuntu.com/ubuntu/ bionic universe\n# deb-src http://azure.archive.ubuntu.com/ubuntu/ bionic universe\ndeb http://azure.archive.ubuntu.com/ubuntu/ bionic-updates universe\n# deb-src http://azure.archive.ubuntu.com/ubuntu/ bionic-updates universe\n\n## N.B. software from this repository is ENTIRELY UNSUPPORTED by the Ubuntu\n## team, and may not be under a free licence. Please satisfy yourself as to\n## your rights to use the software. Also, please note that software in\n## multiverse WILL NOT receive any review or updates from the Ubuntu\n## security team.\ndeb http://azure.archive.ubuntu.com/ubuntu/ bionic multiverse\n# deb-src http://azure.archive.ubuntu.com/ubuntu/ bionic multiverse\ndeb http://azure.archive.ubuntu.com/ubuntu/ bionic-updates multiverse\n# deb-src http://azure.archive.ubuntu.com/ubuntu/ bionic-updates multiverse\n\n## N.B. software from this repository may not have been tested as\n## extensively as that contained in the main release, although it includes\n## newer versions of some applications which may provide useful features.\n## Also, please note that software in backports WILL NOT receive any review\n## or updates from the Ubuntu security team.\ndeb http://azure.archive.ubuntu.com/ubuntu/ bionic-backports main restricted universe multiverse\n# deb-src http://azure.archive.ubuntu.com/ubuntu/ bionic-backports main restricted universe multiverse\n\n## Uncomment the following two lines to add software from Canonical's\n## 'partner' repository.\n## This software is not part of Ubuntu, but is offered by Canonical and the\n## respective vendors as a service to Ubuntu users.\n# deb http://archive.canonical.com/ubuntu bionic partner\n# deb-src http://archive.canonical.com/ubuntu bionic partner\n\ndeb http://azure.archive.ubuntu.com/ubuntu/ bionic-security main restricted\n# deb-src http://azure.archive.ubuntu.com/ubuntu/ bionic-security main restricted\ndeb http://azure.archive.ubuntu.com/ubuntu/ bionic-security universe\n# deb-src http://azure.archive.ubuntu.com/ubuntu/ bionic-security universe\ndeb http://azure.archive.ubuntu.com/ubuntu/ bionic-security multiverse\n# deb-src http://azure.archive.ubuntu.com/ubuntu/ bionic-security multiverse\n`\n```\nAfter copying the same file to my Docker image build step as below.\n```\n`COPY ./sources.list /etc/apt/\n`\n```\nI could successfully install the basic software's like, curl wget, jq, git, python, etc...\nBut I am not able to install softwares like, AzureCLI, Docker, dockerce-and nodejs, chrome-headless, etc..\nMy dockerfile parts for them as below  as below.\n```\n`#4-Install AzureCLI\nRUN curl -LsS https://aka.ms/InstallAzureCLIDeb | bash \\\n  && rm -rf /var/lib/apt/lists/*\n\n#7-install node\nRUN curl -sL https://deb.nodesource.com/setup_11.x  | bash -\nRUN apt-get -y install nodejs\nRUN npm install\n\n#9-install docker daemon inside docker\nRUN curl -fsSL https://download.docker.com/linux/ubuntu/gpg |  gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\nRUN echo \\\n   \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\\n   $(lsb_release -cs) stable\" | tee /etc/apt/sources.list.d/docker.list > /dev/null\nRUN apt-get update\nRUN apt-get install docker-ce docker-ce-cli containerd.io -y\n`\n```\nwhere all I am getting the error as below\n```\n`curl: (35) OpenSSL SSL_connect: SSL_ERROR_SYSCALL in connection to \n`\n```\nSo looking for a way to get succeeded with all the above softwares installed without internet or do we have any azure archive repo for the same like other softwares enabled?",
      "solution": "Another method to provide install deb is:\nIn a Ubuntu machine, can access internet,\n#9-install docker daemon inside docker\nrun:\n```\n`sudo apt-get install \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n`\n```\nrun:\n```\n`curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n`\n```\nrun:\n```\n`echo \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n`\n```\nrun:\n```\n`sudo apt-get update\n`\n```\nrun:\n```\n`sudo apt clean\n\nls /var/cache/apt/archives/\n\nsudo apt --download-only --assume-yes install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n`\n```\nrun\n```\n`$ ls /var/cache/apt/archives/\ncontainerd.io_1.6.10-1_amd64.deb\ndocker-ce_5%3a20.10.21~3-0~ubuntu-jammy_amd64.deb\ndocker-ce-cli_5%3a20.10.21~3-0~ubuntu-jammy_amd64.deb\ndocker-ce-rootless-extras_5%3a20.10.21~3-0~ubuntu-jammy_amd64.deb\ndocker-compose-plugin_2.12.2~ubuntu-jammy_amd64.deb\ndocker-scan-plugin_0.21.0~ubuntu-jammy_amd64.deb\nlibslirp0_4.6.1-1build1_amd64.deb\npigz_2.6-1_amd64.deb\nslirp4netns_1.0.1-2_amd64.deb\n`\n```\nNow you can COPY /var/cache/apt/archives/*.deb TO Your VM1 (no internet0\nand install deb files.\n2022/12/05 update\n```\n`#Internet Host:\n\nmkdir -p ~/WK/data\ncd ~/WK\ndocker run -it -v ~/WK/data:/data ubuntu:20.04 /bin/bash\n`\n```\ndo all steps in docker containers\n```\n`cp /var/cache/apt/archives/*.deb /data/\ncp /etc/apt/keyrings/docker.gpg /data/\ncp /etc/apt/sources.list.d/docker.list /data/\n# exit docker\nexit\n`\n```\ncopy ~/WK/data to INTRANET MACHINE ~/WK/data\n```\n`cd ~/WK\ndocker run -it -v ~/WK/data:/data ubuntu:20.04 /bin/bash\n# do all docker install step\n# if error is xxx , find xxx.deb is in /data folder\n# try to install xxx.deb\ndpkg -i xxx.deb\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-11-30T18:15:21",
      "url": "https://stackoverflow.com/questions/74631702/installation-in-ubuntu-docker-file-getting-failed"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 71674322,
      "title": "Get Azure Resources in AKS Node Resource Group from Script",
      "problem": "When deploying an AKS Cluster you get the AKS Cluster Resource itself and a bunch of separate resources controlled by AKS in a separate resource group.\nI need to get the name of the VNET AKS is created in to peer it with the network of Application Gateway.\nAll the Azure PowerShell or Azure CLI Commands to get any information about the resources in this Resource Group produce empty results though.\nI can not even get a List of Resources in this Resource Group.\nI tried the following commands\n```\n`az resource list\nGet-AzResource\naz network vnet list\n`\n```\nBut none of them produce any output.\nThis is also the reason why this tutorial fails at the peering of the virtual networks.\nAny idea why this is happening and how to get the name of this VNET?\nUpdate: It took about an hour for this resource group to be available via script although i could see it in the portal right after the deployment. Is there any trick to get access to these resources right after the deployment so i can automate subsequent steps building on the availability of those resources?",
      "solution": "```\n`nodeResourceGroup=$(az aks show -g AKS_RG -n AKS_NAME -o tsv --query nodeResourceGroup)\naz network vnet list -g $nodeResourceGroup -o tsv --query \"[0].name\"\n`\n```\nYou can also create the VNET and Subnet by yourself upfront and then place the AKS in this networks.\nThis is in my view the better solution instead of letting Azure manage all this resources and as benefit you are more flexible with peering etc.\nI would also re-commend to use an IaC tool like Terraform or Bicep for this.",
      "question_score": 1,
      "answer_score": 4,
      "created_at": "2022-03-30T10:56:56",
      "url": "https://stackoverflow.com/questions/71674322/get-azure-resources-in-aks-node-resource-group-from-script"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 69814304,
      "title": "Azure: Script or Command to delete instance and all its associated resources (disks, network interface)",
      "problem": "I am trying to find a way to delete an Instance in azure and all its associated resources. But I don't see any straightforward approach to accomplish it. I am using `az vm delete -g resourcegroup -n myinstancename--yes` command which currently only deletes instances. In my scenario, I can't use powershell.",
      "solution": "For testing ,I created a VM with `1 NIC, 1 Public IP and 2 Data disks`.\n\nThen, I used the below `az CLI` script :\n```\n`$osDisk =  (az vm show --resource-group ansumantest --name ansumantest --query \"storageProfile.osDisk.name\" --output tsv)\n$datadisks = (az vm show --resource-group ansumantest --name ansumantest --query \"storageProfile.dataDisks[].name\" --output tsv)\n$nics= (az vm show --resource-group ansumantest --name ansumantest --query \"networkProfile.networkInterfaces[].id\" --output tsv)\nforeach ($nic in $nics){\n   $publicIps=az network nic show --id $nic --query \"ipConfigurations[].publicIpAddress.id\" --output tsv\n}\naz vm delete --resource-group ansumantest --name ansumantest --yes\nif ($osDisk) { \n   az disk show --resource-group ansumantest --name $osDisk --yes\n}\nforeach ($datadisk in $Datadisks){\n  az disk delete --resource-group ansumantest --name $datadisk --yes\n}\nforeach ($nic in $nics){\n  az network nic delete --id $nic\n}\nforeach ($publicIp in $publicIps){\n  az network public-ip delete --id $publicIp\n}\n`\n```\nOutputs:\n\nOR\nYou can directly delete all the resources while the running the VM delete Command as well but there are some Prerequisites for this method i.e. While creating the VM using CLI you have to configure couple of features like below :\nAs per Microsoft Document in `az vm create` section:\n\n[--os-disk-delete-option {Delete, Detach}]\n\nSpecify the behavior of\nthe managed disk when the VM gets deleted i.e whether the managed\ndisk is deleted or detached.\naccepted values: Delete, Detach\n\n[--data-disk-delete-option]\n\nSpecify whether data disk should be deleted or detached upon VM deletion.\n\n[--nic-delete-option]\n\nSpecify what happens to the network interface when the VM is\ndeleted. Use a singular value to apply on all resources, or use = to\nconfigure the delete behavior for individual resources. Possible\noptions are Delete and Detach.\n\nIf the above 3 are configured to delete while creating the VM then , when you run the `az vm delete` it defaults to delete these resources when the VM is to be deleted.\nReference:\nGithub Support",
      "question_score": 1,
      "answer_score": 4,
      "created_at": "2021-11-02T18:01:27",
      "url": "https://stackoverflow.com/questions/69814304/azure-script-or-command-to-delete-instance-and-all-its-associated-resources-di"
    },
    {
      "tech": "azure",
      "source": "stackoverflow",
      "tag": "azure-cli",
      "question_id": 66107008,
      "title": "Generate Azure Storage Account SAS Key using PowerShell",
      "problem": "I am trying to generate an azure storage account shared access key so that i can use it with azcopy to retrieve files from all containers in my storage account.\nI have generated a key successfully using the Azure Portal and proven this works with azcopy\nBut i am struggling to get an equivalent key to generate using PowerShell that works.\nPowershell Query\n`az storage container generate-sas --account-name $SaName --account-key $accountKey --permissions 'rl' --start $start --expiry $expiry --name $SaName --https-only  --output tsv `\nAzure Portal (GUI) Result\n```\n`sv=2019-12-12\n&ss=b\n&srt=sco\n&sp=rl\n&se=2021-02-08T17:40:26Z\n&st=2021-02-08T09:40:26Z\n&spr=https\n&sig=REDACTED\n`\n```\nPowershell Result\n```\n`st=2021-02-08T17%3A17%3A47Z\n&se=2021-02-08T17%3A47%3A47Z\n&sp=rl\n&spr=https\n&sv=2018-11-09\n&sr=c\n&sig=REDACTED\n`\n```\nI guess the first problem is that i have not found a way of adding the missing and ss=b srt=sco (not sr) there doesn't seem to be those parameters available, perhaps if they were there the sig would have the correct hash.\nI have tried this in Azure Cloudshell as well as on my own machine with az 1.12.1",
      "solution": "The command az storage container generate-sas is not powershell command, it's azure cli command.\nBecause in Azure portal, you're generating an `account level sas-token`, but in azure cli, you're actually generating a `container level sas-token` by using az storage container generate-sas.\nTo generate an `account level sas-token`, you should use this azure cli command: az storage account generate-sas.\nThe sample like below:\n```\n`az storage account generate-sas --account-key \"xxxxx\"  --account-name your_storage_account_name --expiry 2020-02-10 --https-only --permissions rl --resource-types sco --services b\n`\n```\nHere is the test result, the `ss=b srt=sco` are generated:\n\nIf you want to use powershell to generate an `account level sas-token`, please use this powershell command: New-AzStorageAccountSASToken. The sample is as below(you can add other parameters as per your need):\n```\n`$account_name = \"yy1\"\n\n$account_key = \"xxxxxxx\"\n\n$context = New-AzStorageContext -StorageAccountName $account_name -StorageAccountKey $account_key\n\n#you can also add other parameter as per your need, like StartTime, ExpiryTime etc.\nNew-AzStorageAccountSASToken -Service Blob -ResourceType Service,Container,Object -Permission rl -Context $context\n`\n```\nHere is the test result:",
      "question_score": 1,
      "answer_score": 4,
      "created_at": "2021-02-08T19:08:35",
      "url": "https://stackoverflow.com/questions/66107008/generate-azure-storage-account-sas-key-using-powershell"
    }
  ]
}