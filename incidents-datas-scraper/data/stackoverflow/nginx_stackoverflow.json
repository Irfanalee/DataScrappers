{
  "tech": "nginx",
  "count": 355,
  "examples": [
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 72152446,
      "title": "WARNING: The requested image&#39;s platform (linux/amd64) does not match the detected host platform (linux/arm64/v8)",
      "problem": "WARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested\ndocker: Error response from daemon: could not select device driver \"\" with capabilities: [[gpu]].\n\nI am facing this error on mac while trying to run this command `docker run --rm --gpus all -v static_volume:/home/app/staticfiles/ -v media_volume:/app/uploaded_videos/ --name=deepfakeapplication abhijitjadhav1998/deefake-detection-20framemodel`\nHow to solve this error?",
      "solution": "Try changing the command as\n```\n`docker run --rm --gpus all --platform linux/amd64 -v static_volume:/home/app/staticfiles/ -v media_volume:/app/uploaded_videos/ --name=deepfakeapplication abhijitjadhav1998/deefake-detection-20framemodel\n`\n```\nPlease ensure that you have compatible Nvidia Drivers available as this application uses Nvidia CUDA.",
      "question_score": 65,
      "answer_score": 8,
      "created_at": "2022-05-07T14:22:17",
      "url": "https://stackoverflow.com/questions/72152446/warning-the-requested-images-platform-linux-amd64-does-not-match-the-detecte"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 65854933,
      "title": "Nginx SSL: error:141CF06C:SSL routines:tls_parse_ctos_key_share:bad key share",
      "problem": "I got this error in nginx error log:\n```\n`SSL_do_handshake() failed (SSL: error:141CF06C:SSL routines:tls_parse_ctos_key_share:bad key share) while SSL handshaking\n`\n```\nI use Let's Encrypt currently. Any ideas to solve this problem? Thank you, guys.",
      "solution": "This isn't your problem.\nThe best thing you can do in this situation is just to keep your server reasonably updated and secured.\nAt best for you, the client side of a request was running seriously outdated software, and at worst your server is simply being scanned for vulnerabilities by compromised devices connected to the internet.\nPersonally I lean in the direction of this being scanning, as I myself see these errors on a private development server, to which only I should ever have a legitimate reason to connect to, yet I see a ton of IP addresses mentioned by the error from around the world.\nSimilar question and answer has already been provided here:\nhttps://serverfault.com/questions/905011/nginx-ssl-do-handshake-failed-ssl-error1417d18cssl/905019\nStay safe.",
      "question_score": 38,
      "answer_score": 50,
      "created_at": "2021-01-23T02:43:03",
      "url": "https://stackoverflow.com/questions/65854933/nginx-ssl-error141cf06cssl-routinestls-parse-ctos-key-sharebad-key-share"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66558957,
      "title": "PHP message: PHP Fatal error: Uncaught TypeError: Cannot access offset of type string on string",
      "problem": "I get following error:\n```\n`PHP message: PHP Fatal error: Uncaught TypeError: Cannot access offset of type string on string\n`\n```\non this line:\n```\n`if ($uploadZoneData[1]['size'] != 0) {\n`\n```\nOn php 7.4 i had any troube but with php 8 i have.\nWhat can be the problem?\nEDIT: Full code of the related functions:\n```\n`function uploadSingleFile($zoneImage, $fileMoveTo, $fileAllowedExtensions, $fileAllowedSize, $zoneCustomer, $zone)\n{\n    global $config;\n\n    // define file upload settings\n    $errors = array();\n    $fileName = $zoneImage['name'];\n    $fileSize = $zoneImage['size'];\n    $fileTmp = $zoneImage['tmp_name'];\n    $fileType = $zoneImage['type'];\n    $fileExt = strtolower(end(explode('.', $zoneImage['name'])));\n    $MBtoByte = $fileAllowedSize * 1048576;\n    $extensions= $fileAllowedExtensions;\n\n    // define errors\n    if (in_array($fileExt, $extensions) === false) {\n        $errors[] = \"Dieser Datei-Typ ist nicht erlaubt\";\n    }\n\n    if ($fileSize > $MBtoByte) {\n        $errors[] = 'Die Datei ist zu gross';\n    }\n\n    // finally try to upload the file\n    if (empty($errors) == true) {\n        $temp = explode(\".\", $zoneImage[\"name\"]);\n        $newfilename = $zoneCustomer . '-' . strtoupper($zone) . '-' . uniqid() . '.' . end($temp);\n\n        move_uploaded_file($fileTmp, $_SERVER[\"DOCUMENT_ROOT\"] . $fileMoveTo . $newfilename);\n        $status = '1';\n    } else {\n        $status = '0';\n    }\n\n    // build array of the different outputs\n    $uploadStatus = array($status, $newfilename, $errors);\n\n    return $uploadStatus;\n}\n\nfunction updateZoneData($zoneFile, $zoneCustomer, $zone, $zoneLink, $maxWidth, $bannerID)\n{\n    global $db;\n\n    // get customer values\n    $getCustomerValues = getColumnValue('customers', \"WHERE `customerNr` = '\" . $zoneCustomer . \"'\");\n\n    // define redirect url\n    switch ($zone) {\n      case \"a1\":\n        $redirectZone = \"zones.php#zones-overview-a1-overview\";\n      break;\n      case \"a2\":\n        $redirectZone = \"zones.php#zones-overview-a2-overview\";\n      break;\n      case \"b1\":\n        $redirectZone = \"zones.php#zones-overview-b1-overview\";\n      break;\n      case \"b2\":\n        $redirectZone = \"zones.php#zones-overview-b2-overview\";\n      break;\n      case \"b3\":\n        $redirectZone = \"zones.php#zones-overview-b3-overview\";\n      break;\n      case \"b4\":\n        $redirectZone = \"zones.php#zones-overview-b4-overview\";\n      break;\n      case \"a9\":\n        $redirectZone = \"zones.php#zones-overview-a9-overview\";\n      break;\n      case \"a9-1\":\n        $redirectZone = \"zones.php#zones-overview-a9-1-overview\";\n      break;\n      case \"a11\":\n        $redirectZone = \"zones.php#zones-overview-a11-overview\";\n      break;\n      default:\n        $redirectZone = \"zones.php\";\n      }\n\n    // upload file to the server\n    $uploadZoneData = uploadSingleFile($zoneFile, '/adserver/banners/', array(\"jpg\", \"jpeg\", \"png\", \"gif\"), '3', $zoneCustomer, $zone);\n\n    if ($uploadZoneData[1]['size'] != 0) {\n        if ($uploadZoneData[0] == '1') {\n\n            // create ZIP-Backup (zone-banners) from '/adserver/banners' to '/cp/includes/files/zip-backups'\n            createZipBackup('/adserver/banners', '/cp/includes/files/zip-backups', 'adserver-banners.zip');\n\n            // get zone values & delete old bannerImg from file-system\n            $getZoneDeleteValues = getColumnValue('zones', \"WHERE `customerNr` = '\" . $zoneCustomer . \"' AND `zone` = '\" . $zone . \"' AND `id` = '\" . $bannerID . \"'\");\n            unlink($_SERVER[\"DOCUMENT_ROOT\"] . '/adserver/banners/' . $getZoneDeleteValues['0']['bannerImg']);\n\n            // execute action\n            $updateZoneData = $db->update(\"zones\", [\n                                                   \"customerNr\" => $zoneCustomer,\n                                                   \"customer\" => $getCustomerValues['0']['customer'],\n                                                   \"zone\" => $zone,\n                                                   \"bannerImg\" => $uploadZoneData[1],\n                                                   \"bannerLink\" => $zoneLink,\n                                                   \"maxWidth\" => $maxWidth,\n                                                   \"changeDate\" => date(\"Y-m-d H:i:s\")\n                                                   ], [\n                                                      \"id\" => $bannerID\n                                                      ]);\n\n            redirectTo($redirectZone, 1, \"\u00ab \" . strtoupper($zone) . \"-Banner (\" . $getCustomerValues['0']['customer'] . \" [K. N\u00b0: \" . $zoneCustomer . \"]) \u00bb wurde erfolgreich aktualisiert.\", 'ZONES');\n        } else {\n\n        // collect and save errors (file-upload)\n            $collectedErrors = array_flatten($uploadZoneData[2]);\n            setcookie(\"collectedErrors\", '1', time() + (1 * 5), \"/\"); // expire in 5 seconds\n            $_SESSION[\"collectedErrors\"] = $collectedErrors;\n\n            redirectTo($redirectZone, 0, \"\u00ab \" . strtoupper($zone) . \"-Banner (\" . $getCustomerValues['0']['customer'] . \" [K. N\u00b0: \" . $zoneCustomer . \"]) \u00bb konnte nicht aktualisiert werden.\", 'ZONES');\n        }\n    } else {\n\n        // execute action\n        $updateZoneData = $db->update(\"zones\", [\n                                               \"customerNr\" => $zoneCustomer,\n                                               \"customer\" => $getCustomerValues['0']['customer'],\n                                               \"zone\" => $zone,\n                                               \"bannerLink\" => $zoneLink,\n                                               \"maxWidth\" => $maxWidth,\n                                               \"changeDate\" => date(\"Y-m-d H:i:s\")\n                                               ], [\n                                                  \"id\" => $bannerID\n                                                  ]);\n\n        redirectTo($redirectZone, 1, \"\u00ab \" . strtoupper($zone) . \"-Banner (\" . $getCustomerValues['0']['customer'] . \" [K. N\u00b0: \" . $zoneCustomer . \"]) \u00bb wurde erfolgreich aktualisiert.\", 'ZONES');\n    }\n}\n`\n```",
      "solution": "This error means that you are trying to access the index [1]['size'] of the string, which is not valid. Be sure to check that `uploadSingleFile(...)` is returning you an array and not a string.\nI checked your code and I saw that the returned array of uploadSingleFile have these three items:\n`$uploadStatus = array($status, $newfilename, $errors);\n`\n`$newfilename` is not an array. It is a string, as you defined here:\n`$newfilename = $zoneCustomer . '-' . strtoupper($zone) . '-' . uniqid() . '.' . end($temp);\n`",
      "question_score": 27,
      "answer_score": 22,
      "created_at": "2021-03-10T06:38:28",
      "url": "https://stackoverflow.com/questions/66558957/php-message-php-fatal-error-uncaught-typeerror-cannot-access-offset-of-type-s"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 79372334,
      "title": "Blocked request. This host (&quot;frontend_web&quot;) is not allowed",
      "problem": "When building vite react in docker-compose application, a message appears when opening the web-site page\n\nBlocked request. This host (\"frontend_web\") is not allowed. To allow this host, add \"frontend_web\" to `server.allowedHosts` in vite.config.js.\n\nI tried to use `vite-plugin-allowed-hosts` but it gives me an error when building the docker-container\n\n[ERROR] Failed to resolve entry for package \"vite-plugin-allowed-hosts\". The package may have incorrect main/module/exports specified in its package.json. [plugin externalize-deps]",
      "solution": "A recent Vite update (6.0.11, to my knowledge) has introduced changes that \"break\" setups using proxies. To resolve this, you need to configure `allowedHosts` in your Vite configuration as told.\nIn your case this should work:\n`server: {\n  allowedHosts: ['frontend_web'],\n}\n`\nor\n`server: {\n  allowedHosts: true\n}\n`",
      "question_score": 26,
      "answer_score": 40,
      "created_at": "2025-01-20T19:29:46",
      "url": "https://stackoverflow.com/questions/79372334/blocked-request-this-host-frontend-web-is-not-allowed"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 70501974,
      "title": "Django returning &quot;CSRF verification failed. Request aborted. &quot; behind Nginx proxy locally",
      "problem": "I'm running a simple Django application without any complicated setup (most of the default, Django allauth & Django Rest Framework).\nThe infrastructure for running both locally and remotely is in a docker-compose file:\n```\n`version: \"3\"\n\nservices:\n  web:\n    image: web_app\n    build:\n      context: .\n      dockerfile: Dockerfile\n    command: gunicorn my_service.wsgi --reload  --bind 0.0.0.0:80 --workers 3\n    env_file: .env\n    volumes:\n      - ./my_repo/:/app:z\n    depends_on:\n      - db\n    environment:\n      - DOCKER=1\n\n  nginx:\n    image: nginx_build\n    build:\n      context: nginx\n      dockerfile: Dockerfile\n    volumes:\n      - ./my_repo/:/app:z\n    ports:\n      - \"7000:80\"\n\n... # db and so on\n`\n```\nas you see, I'm using Gunicorn the serve the application and Nginx as a proxy (for static files and Let's Encrypt setup. The Nginx container has some customizations:\n```\n`FROM nginx:1.21-alpine\n\nRUN rm /etc/nginx/conf.d/default.conf\nCOPY nginx.conf /etc/nginx/conf.d\n`\n```\nAnd the nginx.conf file is a reverse proxy with a static mapping:\n```\n`server {\n\n    listen 80;\n\n    location / {\n        proxy_pass http://web;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $host;\n        proxy_redirect off;\n    }\n    location /static/ {\n        alias /app/my_repo/static/;\n    }\n\n}\n`\n```\nRunning this on the server after setting up let's encrypt in the Nginx container works without any issue, but locally I get the \"CSRF verification failed. Request aborted.\" error every time I submit a form (e.g. create a dummy user in Django Admin). I exposed the web port and used it to submit the forms and it worked.\nBecause of that, I deduce that there is something missing in the Nginx config or something to \"tell\" Django how to handle it. So, what I'm missing and how should I investigate this?",
      "solution": "Since you're using a proxy that translates https requests into http, you need to configure Django to allow POST requests from a different scheme (since Django 4.0) by adding this to `settings.py`:\n```\n`CSRF_TRUSTED_ORIGINS = [\"https://yourdomain.com\", \"https://www.yourdomain.com\"]\n`\n```\nIf this does not solve your problem, you can temporarily set `DEBUG = True` in production and try again. On the error page, you will see a \"Reason given for failure\" that you can post here.",
      "question_score": 22,
      "answer_score": 42,
      "created_at": "2021-12-28T02:33:39",
      "url": "https://stackoverflow.com/questions/70501974/django-returning-csrf-verification-failed-request-aborted-behind-nginx-prox"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66076321,
      "title": "What&#39;s the purpose of ppa:ondrej/nginx?",
      "problem": "I've juste add `ppa:ondrej/php` on my ubuntu server, and it prompt me the message below.\nWhy am I advised to add `ppa:ondrej/nginx` (stable) too? What's the exact purpose of this?\nFor information I have already installed Nginx from the official doc.\n`$ sudo add-apt-repository ppa:ondrej/php\nNote: PPA publishes dbgsym\n  You need to add 'main/debug' component to install the ddebs,\n  but apt update will print warning if the PPA has no ddebs\nRepository: 'deb http://ppa.launchpad.net/ondrej/php/ubuntu/ groovy main'\nDescription:\nCo-installable PHP versions: PHP 5.6, PHP 7.x and most requested extensions are included. Only Supported Versions of PHP (http://php.net/supported-versions.php) for Supported Ubuntu Releases (https://wiki.ubuntu.com/Releases) are provided. Don't ask for end-of-life PHP versions or Ubuntu release, they won't be provided.\n\nDebian oldstable and stable packages are provided as well: https://deb.sury.org/#debian-dpa\n\nYou can get more information about the packages at https://deb.sury.org\n\nIMPORTANT: The -backports is now required on older Ubuntu releases.\n\nBUGS&FEATURES: This PPA now has a issue tracker:\nhttps://deb.sury.org/#bug-reporting\n\nCAVEATS:\n1. If you are using php-gearman, you need to add ppa:ondrej/pkg-gearman\n2. If you are using apache2, you are advised to add ppa:ondrej/apache2\n3. If you are using nginx, you are advised to add ppa:ondrej/nginx-mainline\n\u00a0\u00a0\u00a0or ppa:ondrej/nginx\n\nPLEASE READ: If you like my work and want to give me a little motivation, please consider donating regularly: https://donate.sury.org/\n\nWARNING: add-apt-repository is broken with non-UTF-8 locales, see\nhttps://github.com/oerdnj/deb.sury.org/issues/56 for workaround:\n\n# LC_ALL=C.UTF-8 add-apt-repository ppa:ondrej/php\nMore info: https://launchpad.net/~ondrej/+archive/ubuntu/php\nAdding repository.\nPress [ENTER] to continue or Ctrl-c to cancel.\n`\n\nI don't know very well the Personal Package Archives (PPA), so I would appreciate some help about how it works.",
      "solution": "According to the homepage for `ppa:ondrej/nginx`, here the PPA description:\n```\n`This branch follows latest NGINX Stable packages compiled against latest OpenSSL for HTTP/2 and TLS 1.3 support.\n\nBUGS&FEATURES: This PPA now has a issue tracker: https://deb.sury.org/#bug-reporting\n\nPLEASE READ: If you like my work and want to give me a little motivation, please consider donating: https://donate.sury.org\n`\n```\nSo yes, same purpose as `ppa:ondrej/php` but to install up to date Nginx (stable) versions.",
      "question_score": 22,
      "answer_score": 11,
      "created_at": "2021-02-06T12:25:13",
      "url": "https://stackoverflow.com/questions/66076321/whats-the-purpose-of-ppaondrej-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 72480039,
      "title": "Kubernetes nginx ingress controller cannot upload size more than 1mb",
      "problem": "I am fairly new to GCP and I have a rest URI to upload large files.\nI have a ngress-nginx-controller service and want to change it to upload files larger than 1mb and set a limit.\n```\n`apiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"v1\",\"kind\":\"Service\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/component\":\"controller\",\"app.kubernetes.io/instance\":\"ingress-nginx\",\"app.kubernetes.io/managed-by\":\"Helm\",\"app.kubernetes.io/name\":\"ingress-nginx\",\"app.kubernetes.io/version\":\"0.35.0\",\"helm.sh/chart\":\"ingress-nginx-2.13.0\"},\"name\":\"ingress-nginx-controller\",\"namespace\":\"ingress-nginx\"},\"spec\":{\"externalTrafficPolicy\":\"Local\",\"ports\":[{\"name\":\"http\",\"port\":80,\"protocol\":\"TCP\",\"targetPort\":\"http\"},{\"name\":\"https\",\"port\":443,\"protocol\":\"TCP\",\"targetPort\":\"https\"}],\"selector\":{\"app.kubernetes.io/component\":\"controller\",\"app.kubernetes.io/instance\":\"ingress-nginx\",\"app.kubernetes.io/name\":\"ingress-nginx\"},\"type\":\"LoadBalancer\"}}\n  creationTimestamp: \"2020-09-21T18:37:27Z\"\n  finalizers:\n  - service.kubernetes.io/load-balancer-cleanup\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/version: 0.35.0\n    helm.sh/chart: ingress-nginx-2.13.0\n  name: ingress-nginx-controller\n  namespace: ingress-nginx\n`\n```\nThis is the error it throws :\n```\n`\n413 Request Entity Too Large\n\n413 Request Entity Too Large\nnginx/1.19.2\n\n`\n```",
      "solution": "If you need to increase the body size of files you upload via the ingress controller, you need to add an annotation to your ingress resource:\n```\n`nginx.ingress.kubernetes.io/proxy-body-size: 8m\n`\n```\nDocumentation available here: https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#custom-max-body-size",
      "question_score": 18,
      "answer_score": 38,
      "created_at": "2022-06-02T19:20:46",
      "url": "https://stackoverflow.com/questions/72480039/kubernetes-nginx-ingress-controller-cannot-upload-size-more-than-1mb"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 70633841,
      "title": "Django + Docker: connection to server at &quot;localhost&quot; (127.0.0.1), port 5432 failed",
      "problem": "I am trying to run my Django app (Nginx, Gunicorn) in docker.\nBut for request http://167.99.137.32/admin/ I have error: (full log https://pastebin.com/0f8CqCQM)\n```\n`onnection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n    Is the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (::1), port 5432 failed: Address not available\n    Is the server running on that host and accepting TCP/IP connections?\n`\n```\nI was trying answers from Can't run the server on Django (connection refused) but didn't solve my problem\nsettings.py\n```\n`DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql_psycopg2',\n        'NAME': 'lk_potok_2',\n        'USER': 'postgres',\n        'PASSWORD': 'post222',\n        'HOST': 'localhost',\n        'PORT': 5432,\n    },\n`\n```\ndocker-compose.yml\n```\n`version: '3.9'\n\nservices:\n  django:\n    build: . # path to Dockerfile\n    command: sh -c \"gunicorn --bind 0.0.0.0:8000 potok.wsgi:application\"\n    volumes:\n      - .:/project\n      - static:/project/static\n    expose:\n      - 8000\n    environment:\n      - DATABASE_URL=postgres://postgres:post222@localhost:5432/lk_potok_2\"\n      - DEBUG=1\n\n  db:\n    image: postgres:13-alpine\n    volumes:\n      - pg_data:/var/lib/postgresql/data/\n    expose:\n      - 5432\n    environment:\n      - POSTGRES_USER=postgres\n      - POSTGRES_PASSWORD=post222\n      - POSTGRES_DB=lk_potok_2\n\n  nginx:\n    image: nginx:1.19.8-alpine\n    depends_on:\n      - django\n    ports:\n      - \"80:80\"\n    volumes:\n      - static:/var/www/html/static\n      - ./nginx-conf.d/:/etc/nginx/conf.d\n\nvolumes:\n    pg_data:\n    static:\n`\n```\nnginx-conf.nginx\n```\n`upstream app {\n    server django:8000;\n}\n\nserver {\n    listen 80;\n    server_name 167.99.137.32;\n\n    location / {\n        proxy_pass http://django:8000;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $host;\n        proxy_redirect off;\n    }\n\n    location /static/ {\n        alias /var/www/html/static/;\n    }\n}\n`\n```\nI was trying sudo systemctl start postgresql and sudo systemctl enable postgresql (the same error)",
      "solution": "The postgres database is no longer running at `localhost`. In your case (since you named the container `db`) it is `db`.\n`DATABASES = {\n    'default': {\n        'ENGINE': 'django.db.backends.postgresql_psycopg2',\n        'NAME': 'lk_potok_2',\n        'USER': 'postgres',\n        'PASSWORD': 'post222',\n        'HOST': 'db',\n        'PORT': 5432,\n    },\n`\nI don't really see why you would add this in here:\n`environment:\n      - DATABASE_URL=postgres://postgres:post222@localhost:5432/lk_potok_2\"\n`\nsince you don't use it in your `settings.py`. But here it wil also have to be `db` instead of `localhost`.\n--EDIT--\nExplanation as why `docker` can recognise the other containers can be found here.",
      "question_score": 18,
      "answer_score": 31,
      "created_at": "2022-01-08T16:34:39",
      "url": "https://stackoverflow.com/questions/70633841/django-docker-connection-to-server-at-localhost-127-0-0-1-port-5432-fail"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 68449947,
      "title": "Certbot failing acme-challenge (connection refused)",
      "problem": "I'm trying to set up a Django project with docker + nginx following the tutorial Nginx and Let's Encrypt with Docker in Less Than 5 Minutes.\nThe issue is when I run the script init-letsencrypt.sh I end up with failed challenges.\nHere is the content of my script:\n```\n`#!/bin/bash\n\nif ! [ -x \"$(command -v docker-compose)\" ]; then\n  echo 'Error: docker-compose is not installed.' >&2\n  exit 1\nfi\n\ndomains=(xxxx.yyyy.net www.xxxx.yyyy.net)\nrsa_key_size=4096\ndata_path=\"./data/certbot\"\nemail=\"myemail@example.com\" # Adding a valid address is strongly recommended\nstaging=1 # Set to 1 if you're testing your setup to avoid hitting request limits\n\nif [ -d \"$data_path\" ]; then\n  read -p \"Existing data found for $domains. Continue and replace existing certificate? (y/N) \" decision\n  if [ \"$decision\" != \"Y\" ] && [ \"$decision\" != \"y\" ]; then\n    exit\n  fi\nfi\n\nif [ ! -e \"$data_path/conf/options-ssl-nginx.conf\" ] || [ ! -e \"$data_path/conf/ssl-dhparams.pem\" ]; then\n  echo \"### Downloading recommended TLS parameters ...\"\n  mkdir -p \"$data_path/conf/\"\n  curl -s https://raw.githubusercontent.com/certbot/certbot/master/certbot-nginx/certbot_nginx/_internal/tls_configs/options-ssl-nginx.conf > \"$data_path/conf/options-ssl-nginx.conf\"\n  curl -s https://raw.githubusercontent.com/certbot/certbot/master/certbot/certbot/ssl-dhparams.pem > \"$data_path/conf/ssl-dhparams.pem\"\n  echo\nfi\n\necho \"### Creating dummy certificate for $domains ...\"\npath=\"/etc/letsencrypt/live/$domains\"\nmkdir -p \"$data_path/conf/live/$domains\"\ndocker-compose -f docker-compose-deploy.yml run --rm --entrypoint \"\\\n  openssl req -x509 -nodes -newkey rsa:$rsa_key_size -days 1\\\n    -keyout '$path/privkey.pem' \\\n    -out '$path/fullchain.pem' \\\n    -subj '/CN=localhost'\" certbot\necho\n\necho \"### Starting nginx ...\"\ndocker-compose -f docker-compose-deploy.yml up --force-recreate -d proxy\necho\n\necho \"### Deleting dummy certificate for $domains ...\"\ndocker-compose -f docker-compose-deploy.yml  run --rm --entrypoint \"\\\n  rm -Rf /etc/letsencrypt/live/$domains && \\\n  rm -Rf /etc/letsencrypt/archive/$domains && \\\n  rm -Rf /etc/letsencrypt/renewal/$domains.conf\" certbot\necho\n\necho \"### Requesting Let's Encrypt certificate for $domains ...\"\n#Join $domains to -d args\ndomain_args=\"\"\nfor domain in \"${domains[@]}\"; do\n  domain_args=\"$domain_args -d $domain\"\ndone\n\n# Select appropriate email arg\ncase \"$email\" in\n  \"\") email_arg=\"--register-unsafely-without-email\" ;;\n  *) email_arg=\"--email $email\" ;;\nesac\n\n# Enable staging mode if needed\nif [ $staging != \"0\" ]; then staging_arg=\"--staging\"; fi\n\ndocker-compose  -f docker-compose-deploy.yml run --rm --entrypoint \"\\\n  certbot -v certonly --webroot -w /var/www/certbot \\\n    $staging_arg \\\n    $email_arg \\\n    $domain_args \\\n    --rsa-key-size $rsa_key_size \\\n    --agree-tos \\\n    --force-renewal\" certbot\necho\n\necho \"### Reloading nginx ...\"\ndocker-compose  -f docker-compose-deploy.yml exec proxy nginx -s reload\n`\n```\nAnd my nginx configuration file:\n```\n`server {\n    listen 80;\n    server_name xxxx.yyyy.net;\n       \n    location ^~ /.well-known/acme-challenge/ {\n        root /var/www/certbot;\n    }\n    \n    location / {\n        return 301 https://$server_name$request_uri;\n    }\n\n}\n\nserver {\n    listen 443 ssl;\n    server_name xxxx.yyyy.net;\n    \n    ssl_certificate /etc/letsencrypt/live/xxxx.yyyy.net/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/xxxx.yyyy.net/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; \n    \n    location /static {\n        alias /vol/static;\n    }\n\n    location / {\n        uwsgi_pass web:8000;\n        include /etc/nginx/uwsgi_params;\n    }\n\n}\n\n`\n```\nThe output of the part that fails:\n```\n`Requesting a certificate for xxxx.yyyy.net and www.xxxx.yyyy.net\nPerforming the following challenges:\nhttp-01 challenge for xxxx.yyyy.net\nhttp-01 challenge for www.xxxx.yyyy.net\nUsing the webroot path /var/www/certbot for all unmatched domains.\nWaiting for verification...\nChallenge failed for domain xxxx.yyyy.net\nChallenge failed for domain www.xxxx.yyyy.net\nhttp-01 challenge for xxxx.yyyy.net\nhttp-01 challenge for www.xxxx.yyyy.net\n\nCertbot failed to authenticate some domains (authenticator: webroot). The Certificate Authority reported these problems:\n  Domain: xxxx.yyyy.net\n  Type:   connection\n  Detail: Fetching http://xxxx.yyyy.net/.well-known/acme-challenge/XJw9w39lRSSbPf-4tb45RLtTnSbjlUEi1f0Cqwsmt-8: Connection refused\n\n  Domain: www.xxxx.yyyy.net\n  Type:   connection\n  Detail: Fetching http://www.xxxx.yyyy.net/.well-known/acme-challenge/b47s4WJARyOTS63oFkaji2nP7oOhiLx5hHp4kO9dCGI: Connection refused\n\nHint: The Certificate Authority failed to download the temporary challenge files created by Certbot. Ensure that the listed domains serve their content from the provided --webroot-path/-w and that files created there can be downloaded from the internet.\n\nCleaning up challenges\nSome challenges have failed.\nAsk for help or search for solutions at https://community.letsencrypt.org. See the logfile /var/log/letsencrypt/letsencrypt.log or re-run Certbot with -v for more details.\nERROR: 1\n`\n```\nOne of the comments said:\n\nBut there's no further explanation as to how to solve it.\nCheck the certbot commit",
      "solution": "Problem is nginx configuration file. The container fails to start up correctly because of missing certification files. I commented out the ssl server portion, rebuilt the image and executed the script again. Everything worked out just fine. After certificates were generated I just uncommented the ssl configuration, rebuilt the image and composed up the services.",
      "question_score": 16,
      "answer_score": 24,
      "created_at": "2021-07-20T07:29:37",
      "url": "https://stackoverflow.com/questions/68449947/certbot-failing-acme-challenge-connection-refused"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 68293718,
      "title": "Return a string using the Nginx container",
      "problem": "I am using the Nginx container to host a SPA application in Kubernetes.\nAside from the static files hosted for the SPA app, I also need to host the routes for health checks.  So, the route `/health/startup` needs to return the text `healthy` when a GET request is sent to it.\nI suppose I could just make a folder called \"health\" and then put a file in it called startup with the text `healthy` in it.  But that seems a bit odd to me.  And I worry that if the file structure may get changed and that then my health checks will start failing.\nIs there a way, using the Nginx container to return a given value (ie \"healthy\")when a request comes to a specific route?  (And not mess up the rest of my static file serving that is going on.)",
      "solution": "Yes you can, in the configuration you are importing for the server, you can just do this:\n```\n`location /health/startup {\n    add_header Content-Type text/plain;\n    return 200 'healthy';\n}\n`\n```",
      "question_score": 16,
      "answer_score": 28,
      "created_at": "2021-07-08T00:43:52",
      "url": "https://stackoverflow.com/questions/68293718/return-a-string-using-the-nginx-container"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69178211,
      "title": "How do I run multiple sites on the same server using docker and nginx?",
      "problem": "I'm trying to run two sites on django on the same server under different ip, an error occurs that the port is busy, I fixed the ports, but the site does not start. Tell me where is the error please? Ip work, when I go to the second ip I get redirects to the first site. All settings were specified for the second site. At the end, I added the nginx setting of the first site\nThis is the second docker-compose file and its settings. I would be very grateful for your help\n.env\n```\n`#Django\n# Should be one of dev, prod\nMODE=prod\nPORT=8008\n\n#postgres\nDB_NAME=xxx\nDB_USER=xxx\nDB_HOST=xxx\nDB_PASSWORD=xxxx\nDB_PORT=5432\nPOSTGRES_PASSWORD=mysecretpassword\n\n#WSGI\nWSGI_PORT=8008\nWSGI_WORKERS=4\nWSGI_LOG_LEVEL=debug\n\n# Celery\nCELERY_NUM_WORKERS=2\n\n# Email\nEMAIL_HOST_USER=xxxx\nEMAIL_HOST_PASSWORD=xxxx\n`\n```\ndocker-compose.yml\n```\n`version: '3'\n\nservices:\n\n  backend:\n    build: ./\n    container_name: site_container\n    restart: always\n    command: ./commands/start_server.sh\n    ports:\n      - \"${PORT}:${WSGI_PORT}\"\n    volumes:\n      - ./src:/srv/project/src\n      - ./commands:/srv/project/commands\n      - static_content:/var/www/site\n    env_file:\n      - .env\n    depends_on:\n      - postgres\n\n  postgres:\n    image: postgres:12\n    volumes:\n      - pg_data:/var/lib/postgresql/data\n    env_file:\n      - .env\n#    environment:\n#      - DJANGO_SETTINGS_MODULE=app.settings.${MODE}\n\n  nginx:\n    image: nginx:1.19\n    volumes:\n      - ./nginx:/etc/nginx/conf.d\n      - static_content:/var/www/site\n    ports:\n      - 81:80\n      - 444:443\n    env_file:\n      - .env\n    depends_on:\n      - backend\n\nvolumes:\n  pg_data: {}\n  static_content: {}\n`\n```\ndefault.conf\n```\n`server {\n    listen 80 default_server;\n\n    server_name 183.22.332.12;\n\n    location /static/ {\n        root /var/www/site;\n    }\n\n    location /media/ {\n        root /var/www/site;\n    }\n\n    location / {\n        proxy_set_header Host $host;\n        proxy_pass http://backend:8010;\n    }\n}\n`\n```\ndefault.conf for first site\n```\n`server {\n    #listen 80 default_server;\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n\n    server_name site1 ip_site1;\n\n    ssl_certificate /etc/letsencrypt/live/site1/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/site1/privkey.pem;\n    ssl_trusted_certificate /etc/letsencrypt/live/site1/chain.pem;\n\n    location /static/ {\n        root /var/www/artads;\n    }\n\n    location /media/ {\n        root /var/www/artads;\n    }\n\n    location / {\n        proxy_set_header Host $host;\n        proxy_pass http://backend:8008;\n    }\n}\n\nserver {\n    listen 80 default_server;\n\n    server_name ip_site2 site2;\n\n    location /static/ {\n        root /var/www/gdr_mr;\n    }\n\n    location /media/ {\n        root /var/www/gdr_mr;\n    }\n\n    location / {\n        proxy_set_header Host $host;\n        proxy_pass http://backend:8013;\n    }\n}\n\nserver {\n        listen 80;\n        listen [::]:80;\n\n        server_name www.site1 site1;\n\n        location / {\n                return 301 https://site1$request_uri;\n        }\n}\n`\n```",
      "solution": "Thanks to @Roman Tokaren and @Oleksandr\nHere the english translated version submitted by @Roman Tokaren here\n\nYou can always argue a lot about the \"correct\" launch - after all, how many people, so many opinions, but I will describe an example + - of a \"convenient\" and scalable configuration. For the \"convenience\" of working in such a configuration, I would suggest installing nginxproxymanager as a reverse proxy and combining containers and nginxproxymanager into one network - after which it will be possible to forward container ports via http (s), tcp, udp to an external interface using the GUI as well as a number of other goodies, such as the generation of SSL certificates and their auto renewal\n\nFirst, let's create the network itself\n```\n`docker network create --driver bridge --subnet 172.26.0.0/24 testnet\n`\n```\n\nLet's configure NPM (nginxproxymanager) - by default we will consider the reverse proxy as the last network node, as a result we will get\n```\n`version: \"3\"\nservices:\n  app:\n    image: 'jc21/nginx-proxy-manager:latest'\n    networks:\n      testnet:\n        ipv4_address: 172.26.0.254\n    restart: always\n    ports:\n      # Public HTTP Port:\n      - '80:80'\n      # Public HTTPS Port:\n      - '443:443'\n      # Admin Web Port:\n      - '81:81'\n    environment:\n      # These are the settings to access your db\n      DB_MYSQL_HOST: \"172.26.0.253\"\n      DB_MYSQL_PORT: 3306\n      DB_MYSQL_USER: \"user\"\n      DB_MYSQL_PASSWORD: \"pwd\"\n      DB_MYSQL_NAME: \"npm\"\n    volumes:\n      - ./data/nginx-proxy-manager:/data\n      - ./letsencrypt:/etc/letsencrypt\n    depends_on:\n      - db\n  db:\n    image: yobasystems/alpine-mariadb:latest\n    restart: always\n    networks:\n      testnet:\n        ipv4_address: 172.26.0.253\n    environment:\n      MYSQL_ROOT_PASSWORD: \"pwd\"\n      MYSQL_DATABASE: \"npm\"\n      MYSQL_USER: \"user\"\n      MYSQL_PASSWORD: \"pwd\"\n    volumes:\n      - ./data/mariadb:/var/lib/mysql\nnetworks:\n  testnet:\n    external: true\n`\n```\n\nAnd configure the container itself\n```\n`version: '3'\nservices:\n  backend:\n    build: ./\n    container_name: site_container\n    restart: always\n    command: ./commands/start_server.sh\n    networks:\n      testnet:\n        ipv4_address: 172.26.0.2\n    volumes:\n      - ./src:/srv/project/src\n      - ./commands:/srv/project/commands\n      - static_content:/var/www/site\n    env_file:\n      - .env\n    depends_on:\n      - postgres\n\n  postgres:\n    image: postgres:12\n    volumes:\n      - pg_data:/var/lib/postgresql/data\n    env_file:\n      - .env\n#    environment:\n#      - DJANGO_SETTINGS_MODULE=app.settings.${MODE}\n\nnetworks:\n  testnet:\n    external: true\nvolumes:\n  pg_data: {}\n  static_content: {}\n`\n```\n\nAfter that, we carry out the initial configuration of NPM according to the instructions and add the host",
      "question_score": 16,
      "answer_score": 8,
      "created_at": "2021-09-14T14:56:05",
      "url": "https://stackoverflow.com/questions/69178211/how-do-i-run-multiple-sites-on-the-same-server-using-docker-and-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 70111791,
      "title": "Nginx (13: Permission denied) while connecting to upstream",
      "problem": "I'm deploying my Djano application on a VPS and I'm following the steps in the below link to configure my app with Gunicorn and Nginx.\nHow To Set Up Django with Postgres, Nginx, and Gunicorn on Ubuntu 16.04\n\nEverything went well with the tutorial (gunicorn and nginx are running) but the issue is that when Im' visiting the VPS through the static IP its showing a white screen that is always reloading.\nAfter checking nginx log I found the following:\n\n(13: Permission denied) while connecting to upstream, client: , server: , request: \"GET / HTTP/1.1, upstream: \"http://unix:/root/myproject/myproject.sock:/\", host: \"\", referrer: \"http:///\"",
      "solution": "After searching for roughly 7 hours, I was finally able to find a solution to this issue in the Nginx forum:\nNginx connet to .sock failed (13:Permission denied) - 502 bad gateway\nWhat I simply did was changing the name of the user on the first line in `/etc/nginx/nginx.conf` file.\nIn my case the default user was `www-data` and I changed it to my `root` machine username.",
      "question_score": 15,
      "answer_score": 40,
      "created_at": "2021-11-25T14:15:20",
      "url": "https://stackoverflow.com/questions/70111791/nginx-13-permission-denied-while-connecting-to-upstream"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69244766,
      "title": "Nginx giving out a 413 Request entity too large",
      "problem": "I have a Django app serving React static files powered by Nginx running in Docker containers. As I'm trying to upload some larger files via my web app I keep receiving `413 Request entity too large` from Nginx directly\n\nHere is my Nginx config\n```\n`/ # nginx -T\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nnginx: configuration file /etc/nginx/nginx.conf test is successful\n# configuration file /etc/nginx/nginx.conf:\n\nuser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log warn;\npid        /var/run/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log  /var/log/nginx/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\n# configuration file /etc/nginx/mime.types:\n\ntypes {\n    text/html                                        html htm shtml;\n    text/css                                         css;\n    text/xml                                         xml;\n    image/gif                                        gif;\n    image/jpeg                                       jpeg jpg;\n    application/javascript                           js;\n    application/atom+xml                             atom;\n    application/rss+xml                              rss;\n\n    text/mathml                                      mml;\n    text/plain                                       txt;\n    text/vnd.sun.j2me.app-descriptor                 jad;\n    text/vnd.wap.wml                                 wml;\n    text/x-component                                 htc;\n\n    image/png                                        png;\n    image/svg+xml                                    svg svgz;\n    image/tiff                                       tif tiff;\n    image/vnd.wap.wbmp                               wbmp;\n    image/webp                                       webp;\n    image/x-icon                                     ico;\n    image/x-jng                                      jng;\n    image/x-ms-bmp                                   bmp;\n\n    font/woff                                        woff;\n    font/woff2                                       woff2;\n\n    application/java-archive                         jar war ear;\n    application/json                                 json;\n    application/mac-binhex40                         hqx;\n    application/msword                               doc;\n    application/pdf                                  pdf;\n    application/postscript                           ps eps ai;\n    application/rtf                                  rtf;\n    application/vnd.apple.mpegurl                    m3u8;\n    application/vnd.google-earth.kml+xml             kml;\n    application/vnd.google-earth.kmz                 kmz;\n    application/vnd.ms-excel                         xls;\n    application/vnd.ms-fontobject                    eot;\n    application/vnd.ms-powerpoint                    ppt;\n    application/vnd.oasis.opendocument.graphics      odg;\n    application/vnd.oasis.opendocument.presentation  odp;\n    application/vnd.oasis.opendocument.spreadsheet   ods;\n    application/vnd.oasis.opendocument.text          odt;\n    application/vnd.openxmlformats-officedocument.presentationml.presentation\n                                                     pptx;\n    application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\n                                                     xlsx;\n    application/vnd.openxmlformats-officedocument.wordprocessingml.document\n                                                     docx;\n    application/vnd.wap.wmlc                         wmlc;\n    application/x-7z-compressed                      7z;\n    application/x-cocoa                              cco;\n    application/x-java-archive-diff                  jardiff;\n    application/x-java-jnlp-file                     jnlp;\n    application/x-makeself                           run;\n    application/x-perl                               pl pm;\n    application/x-pilot                              prc pdb;\n    application/x-rar-compressed                     rar;\n    application/x-redhat-package-manager             rpm;\n    application/x-sea                                sea;\n    application/x-shockwave-flash                    swf;\n    application/x-stuffit                            sit;\n    application/x-tcl                                tcl tk;\n    application/x-x509-ca-cert                       der pem crt;\n    application/x-xpinstall                          xpi;\n    application/xhtml+xml                            xhtml;\n    application/xspf+xml                             xspf;\n    application/zip                                  zip;\n\n    application/octet-stream                         bin exe dll;\n    application/octet-stream                         deb;\n    application/octet-stream                         dmg;\n    application/octet-stream                         iso img;\n    application/octet-stream                         msi msp msm;\n\n    audio/midi                                       mid midi kar;\n    audio/mpeg                                       mp3;\n    audio/ogg                                        ogg;\n    audio/x-m4a                                      m4a;\n    audio/x-realaudio                                ra;\n\n    video/3gpp                                       3gpp 3gp;\n    video/mp2t                                       ts;\n    video/mp4                                        mp4;\n    video/mpeg                                       mpeg mpg;\n    video/quicktime                                  mov;\n    video/webm                                       webm;\n    video/x-flv                                      flv;\n    video/x-m4v                                      m4v;\n    video/x-mng                                      mng;\n    video/x-ms-asf                                   asx asf;\n    video/x-ms-wmv                                   wmv;\n    video/x-msvideo                                  avi;\n}\n\n# configuration file /etc/nginx/conf.d/nginx.conf:\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n        error_log /var/log/nginx/info_error.log;\n        access_log /var/log/nginx/info_access.log;\n\n    client_max_body_size 0;\n\n        location / {\n                proxy_redirect          off;\n                proxy_set_header        Host            $host;\n                proxy_set_header        X-Real-IP       $remote_addr;\n                proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;\n                client_body_buffer_size 128k;\n                proxy_connect_timeout   90;\n                proxy_send_timeout      90;\n                proxy_read_timeout      90;\n                proxy_buffers           32 4k;\n\n                proxy_pass http://pristupni_app:8000;\n        }\n\n        location /static {\n                autoindex on;\n                alias /static;\n        }\n}\n`\n```\nI've set `client_max_body_size` to 0 (unlimited) as the Docker docs suggest\nhttps://docs.docker.com/registry/recipes/nginx/\nAfter completely rebuilding images with docker-compose the error is still there.",
      "solution": "I got an answer in the end. Turns out I didn't configure my https config with the `client_max_body_size 0;`. Adding that to the config allowed for larger files to be uploaded.\n```\n`http {\n    client_max_body_size 20M;\n}\n`\n```",
      "question_score": 15,
      "answer_score": 31,
      "created_at": "2021-09-19T17:42:35",
      "url": "https://stackoverflow.com/questions/69244766/nginx-giving-out-a-413-request-entity-too-large"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 72020904,
      "title": "Minio console not accessible behind nginx reverse proxy",
      "problem": "I am trying to redirect a `example.com/minio` location to minio console, which is run behind a nginx proxy both run by a docker compose file. My problem is that, when I'm trying to reverse proxy the minio endpoint to a path, like `/minio` it does not work, but when I run the `minio` reverse proxy on root path in the nginx reverse proxy, it works. I seriously cannot findout what the problem might be.\nThis is my compose file:\n`services:\n  nginx:\n    container_name: nginx\n    image: nginx\n    restart: unless-stopped\n    ports:\n      - 80:80\n      - 443:443\n    volumes:\n      - ./nginx.conf:/etc/nginx/conf.d/default.conf\n      - ./log/nginx:/var/log/nginx/\n  minio:\n    image: minio/minio\n    container_name: minio\n    volumes:\n      - ./data/minio/:/data\n    command: server /data --address ':9000' --console-address ':9001'\n    environment:\n      MINIO_ROOT_USER: minio_admin\n      MINIO_ROOT_PASSWORD: minio_123456\n    ports:\n      - 9000\n      - 9001\n    restart: always\n    logging:\n      driver: \"json-file\"\n      options:\n        max-file: \"10\"\n        max-size: 20m\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://127.0.0.1:9000/minio/health/live\"]\n      interval: 30s\n      timeout: 20s\n      retries: 3\n`\nMy nginx configuration is like this:\n```\n`server {\n    listen 80;\n    server_name example.com;\n\n    # To allow special characters in headers\n    ignore_invalid_headers off;\n    # Allow any size file to be uploaded.\n    # Set to a value such as 1000m; to restrict file size to a specific value\n    client_max_body_size 0;\n    # To disable buffering\n    proxy_buffering off;\n\n    access_log /var/log/nginx/service-access.log;\n    error_log /var/log/nginx/service-error.log debug;\n\n    location / {\n        return 200 \"salam\";\n        default_type text/plain;\n    }\n    location /minio {\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header Host $http_host;\n\n        proxy_connect_timeout 300;\n        # Default is HTTP/1, keepalive is only enabled in HTTP/1.1\n        proxy_http_version 1.1;\n        proxy_set_header Connection \"\";\n        chunked_transfer_encoding off;\n\n        proxy_pass http://minio:9001;\n    }\n}\n`\n```\nThe picture I'm seeing of minio console at the domain is this:\n\nAnd the response of curling the endpoint (`$ curl -k http://example.com/minio`):\n`\n    \n        \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n            MinIO Console\n            \n            \n        \n        \n            You need to enable JavaScript to run this app.\n            \n                \n                    \n                    \n                \n                \n                    \n                \n            \n        \n    \n    %\n`",
      "solution": "I also struggled with this for a long time and was finally able to resolve it.\nAs far as I can tell, the key changes to make this work for me where:\n\nManually specifying a `rewrite` directive (instead of relying on the Nginx proxy_pass+URI behaviour which didn't seem to work for me).\nSetting the `resolver` directive with short timeouts (so that rescheduling of services onto other nodes gets resolved).\nSetting `$upstream` to prevent DNS caching.\n\nI had to change your setup a little bit so that now the Minio S3 API is served behind `minio.example.com` while the UI Web Console is accessible at `minio.example.com/console/`.\nI have edited your config files below:\ndocker-compose.yml:\n```\n`services:\n  nginx:\n    container_name: nginx\n    image: nginx\n    restart: unless-stopped\n    ports:\n      - 80:80\n      - 443:443\n    volumes:\n      - ./nginx.conf:/etc/nginx/conf.d/default.conf\n      - ./log/nginx:/var/log/nginx/\n  minio:\n    image: minio/minio\n    container_name: minio\n    volumes:\n      - ./data/minio/:/data\n    command: server /data --address ':9000' --console-address ':9001'\n    environment:\n      MINIO_SERVER_URL: \"http://minio.example.com/\"\n      MINIO_BROWSER_REDIRECT_URL: \"http://minio.example.com/console/\"    \n      MINIO_ROOT_USER: minio_admin\n      MINIO_ROOT_PASSWORD: minio_123456\n    ports:\n      - 9000\n      - 9001\n    restart: always\n    logging:\n      driver: \"json-file\"\n      options:\n        max-file: \"10\"\n        max-size: 20m\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://127.0.0.1:9000/minio/health/live\"]\n      interval: 30s\n      timeout: 20s\n      retries: 3\n`\n```\nnginx.conf:\n```\n`server {\n    listen 80;\n    server_name minio.example.com;\n\n    # To allow special characters in headers\n    ignore_invalid_headers off;\n    # Allow any size file to be uploaded.\n    # Set to a value such as 1000m; to restrict file size to a specific value\n    client_max_body_size 0;\n    # To disable buffering\n    proxy_buffering off;\n\n    access_log /var/log/nginx/service-access.log;\n    error_log /var/log/nginx/service-error.log debug;\n\n    # Use Docker DNS\n    # You might not need this section but in case you need to resolve\n    # docker service names inside the container then this can be useful.\n    resolver 127.0.0.11 valid=10s;\n    resolver_timeout 5s;\n\n    # Apparently the following line might prevent caching of DNS lookups\n    # and force nginx to resolve the name on each request via the internal\n    # Docker DNS.\n    set $upstream \"minio\";\n\n    # Minio Console (UI)\n    location /console/ {\n\n        # This was really the key for me. Even though the Nginx docs say \n        # that with a URI part in the `proxy_pass` directive, the `/console/`\n        # URI should automatically be rewritten, this wasn't working for me.\n        rewrite ^/console/(.*)$ /$1 break;\n\n        proxy_pass http://$upstream:9001;\n\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header Host $http_host;\n\n        proxy_connect_timeout 300;\n\n        # To support websocket\n        # Default is HTTP/1, keepalive is only enabled in HTTP/1.1\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        chunked_transfer_encoding off;    \n    }\n\n    # Proxy requests to the Minio API on port 9000\n    location / {\n\n        proxy_pass http://$upstream:9000;\n\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header Host $http_host;\n\n        proxy_connect_timeout 300;\n\n        # To support websocket\n        # Default is HTTP/1, keepalive is only enabled in HTTP/1.1\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        chunked_transfer_encoding off;\n    }\n\n}\n`\n```\nHTH!",
      "question_score": 14,
      "answer_score": 11,
      "created_at": "2022-04-26T23:49:31",
      "url": "https://stackoverflow.com/questions/72020904/minio-console-not-accessible-behind-nginx-reverse-proxy"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 71204607,
      "title": "Why does a variable not work in NGINX `proxy_pass`?",
      "problem": "Why does a variable not work in `proxy_pass`?\nThis works perfectly:\n```\n`location /foo/ {\n  proxy_pass http://127.0.0.1/;\n}\n`\n```\nThis doesn't work at all:\n```\n`location /foo/ {\n  set $FOO http://127.0.0.1/;\n  proxy_pass $FOO;\n  add_header x-debug $FOO;\n}\n`\n```\nI see the `x-header: http://127.0.0.1/` but the result is 404 so I don't know where it's proxying to but it's not identical to the first example.\nSource where it is explained that using a variable in proxy_pass will prevent NGINX startup errors when the upstream is not available.\nUPDATE: The issue is the upstream path rewriting. I expect it to rewrite `/foo/blah` to the upstream at `/blah` removing the `/foo` prefix. It works fine with static host/uri entries but not with a variable.",
      "solution": "The final answer, much aided by @MSalters was more complicated than I could imagine. The reason is that NGINX works differently with variables than with statically entered hostnames - it does not even use the same DNS mechanism.\nThe main issue is that path handling and prefix stripping does not work the same with variables. You have to strip path prefixes yourself. In my original example:\n```\n`location /foo/ {\n  set $FOO 127.0.0.1;\n  rewrite /foo/(.*) /$1 break;\n  proxy_pass http://$FOO/$1$is_args$args;\n}\n`\n```\nIn my example I use an IP address so no resolver is required. However, if you use a host name a `resolver` is required so add your DNS IP there. Shrugs.\nFor full disclosure, we are using NGINX inside Kubernetes so it gets even more complicated. The special points of interest are:\n\nAdd a `resolver` directive with the IP of the cluster's DNS service (in my case 10.43.0.10). This is the ClusterIP of the `kube-dns` service in the `kube-system` namespace.\nUse a FQDN even if your NGINX is in the same namespace since the DNS can only resolve FQDN apparently.\n\n```\n`location /foo/ {\n  set $MYSERVICE myservice.mynamespace.svc.cluster.local;\n  rewrite /foo/(.*) /$1 break;\n  proxy_pass http://$MYSERVICE/$1$is_args$args;\n  resolver 10.43.0.10 valid=10s;\n}\n`\n```\nNOTE: Due to a BUG (which is unfortunately not acknowledged by NGINX maintainers) in NGINX, using $1 in URLs will break if the path contains a space. So `/foo%20bar/` will be passed upstream as `/foo bar/` and just break.",
      "question_score": 14,
      "answer_score": 16,
      "created_at": "2022-02-21T11:21:36",
      "url": "https://stackoverflow.com/questions/71204607/why-does-a-variable-not-work-in-nginx-proxy-pass"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69601377,
      "title": "How to parse logs ( nginx/apache access.log ) with mix of delimiters i.e. square bracket, space and double quotes? and optionally convert to json",
      "problem": "nginx access.log. It is delimited by 1) white space 2) [ ] and 3) double quotes.\n```\n`::1 - - [12/Oct/2021:15:26:25 +0530] \"GET / HTTP/1.1\" 200 1717 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\"\n::1 - - [12/Oct/2021:15:26:25 +0530] \"GET /css/custom.css HTTP/1.1\" 200 202664 \"https://localhost/\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\"\n`\n```\nafter parsing it supposed to look like\n`$1 =  ::1`\n`$4 = [12/Oct/2021:15:26:25 +0530] or 12/Oct/2021:15:26:25 +0530`\n`$5 = \"GET / HTTP/1.1\"`\n`$6 = 200`\n`$7 = 1717`\n`$8 = \"-\"`\n`$9 = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko)  Chrome/94.0.4606.81 Safari/537.36\"`\nI tried some options like `awk -F'[],] *'` `awk -f [][{}] `, but they doesn't work with full line.\nnginx access.log shared here is just an example. I am trying to understand how to parse with mix of such delimiters for usages in other complex logs.",
      "solution": "If you can use `gnu-awk` you can make use of FPAT to specify the column data:\n```\n`awk -v FPAT='\\\\[[^][]*]|\"[^\"]*\"|\\\\S+' '{\n  for(i=1; iThe pattern matches:\n\n`\\\\[[^][]*]` Match from an opening `[` till closing `]` using a negated character class\n`|` Or\n`\"[^\"]*\"` Match from an opening till closing double quote\n`|` Or\n`\\\\S+` 1 or more non whitespace chars\n\nOutput\n```\n`$1 =  ::1\n$2 =  -\n$3 =  -\n$4 =  [12/Oct/2021:15:26:25 +0530]\n$5 =  \"GET / HTTP/1.1\"\n$6 =  200\n$7 =  1717\n$8 =  \"-\"\n$9 =  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.81 Safari/537.36\"\n`\n```",
      "question_score": 13,
      "answer_score": 8,
      "created_at": "2021-10-17T06:45:03",
      "url": "https://stackoverflow.com/questions/69601377/how-to-parse-logs-nginx-apache-access-log-with-mix-of-delimiters-i-e-square"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67176678,
      "title": "cant create a second ingress controller using helm with custom class in Azure k8s cluster",
      "problem": "I have created an ingress controller using Helm with default configuration\n```\n`default        nginx-ingress-controller        LoadBalancer   10.0.182.128   xx.xxx.xx.90     80:32485/TCP,443:31756/TCP   62m\ndefault        nginx-ingress-default-backend   ClusterIP      10.0.12.39                80/TCP                       62m\n`\n```\nusing Helm:\n```\n`helm install nginx-ingress stable/nginx-ingress \\         \n--set controller.replicaCount=2 \\     \n--set controller.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n--set defaultBackend.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n--set controller.service.loadBalancerIP=\"Created static IP\" \\\n--set controller.service.annotations.\"service\\.beta\\.kubernetes\\.io/azure-dns-label-name\"=\"XXX-aks-ingress\"\n`\n```\nthis ingress is running in the default namespace.\nNow, I wanted to add a second ingress controller, from the official doc I have specific Ingress class\n```\n`helm install nginx-ingress stable/nginx-ingress \\     \n--namespace ingress-nginx-devices \\ #I create this namespace first \n--set controller.ingressClass=\"nginx-devices\" \\   # custom class to use for different ingress resources  \n--set controller.replicaCount=2 \\     \n--set controller.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n--set defaultBackend.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n--set controller.service.loadBalancerIP=\"A second static Ip address created before\" \\\n--set controller.service.annotations.\"service\\.beta\\.kubernetes\\.io/azure-dns-label-name\"=\"serviceIot-aks-ingress-iot\"\n`\n```\nbut I keep getting this error:\n```\n`Error: rendered manifests contain a resource that already exists. Unable to continue with install: ClusterRole \"nginx-ingress\" in namespace \"\" exists and cannot be imported into the current release: invalid ownership metadata; annotation validation error: key \"meta.helm.sh/release-namespace\" must equal \"ingress-nginx-devices\": current value is \"default\"\n`\n```\nWhat could be wrong here ?\nAny help is appreciated :)",
      "solution": "Update :\nController-value of the controller that is processing this ingressClass\nWith recent update you might have to use the controller.ingressClassByName\nOfficial doc : https://github.com/kubernetes/ingress-nginx/tree/main/charts/ingress-nginx#values\n```\n`helm install nginx-ingress-devices stable/nginx-ingress \\     \n    --namespace ingress-nginx-devices \\ #I create this namespace first \n    --set controller.ingressClass=\"nginx-devices\" \\   # custom class to use for different ingress resources  \n    --set controller.ingressClassResource.name=\"nginx-devices\" \\\n    --set controller.replicaCount=2 \\     \n    --set controller.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n    --set defaultBackend.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n    --set controller.service.loadBalancerIP=\"A second static Ip address created before\" \\\n    --set controller.service.annotations.\"service\\.beta\\.kubernetes\\.io/azure-dns-label-name\"=\"serviceIot-aks-ingress-iot\"\n`\n```\nOld answer\nyou can try, what we are changing is name : nginx-ingress-devices instead of nginx-ingress\n```\n`helm install nginx-ingress-devices stable/nginx-ingress \\     \n--namespace ingress-nginx-devices \\ #I create this namespace first \n--set controller.ingressClass=\"nginx-devices\" \\   # custom class to use for different ingress resources  \n--set controller.replicaCount=2 \\     \n--set controller.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n--set defaultBackend.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n--set controller.service.loadBalancerIP=\"A second static Ip address created before\" \\\n--set controller.service.annotations.\"service\\.beta\\.kubernetes\\.io/azure-dns-label-name\"=\"serviceIot-aks-ingress-iot\"\n`\n```\nerror you are getting is due to already there is cluster role with same name : nginx-ingress due to that you are getting the error.\n\nClusterRoleBindings grant a user, group, or service account a\nClusterRole\u2019s power across the entire cluster.\n\nYou can get the reference file here : https://github.com/helm/charts/blob/master/stable/nginx-ingress/templates/clusterrole.yaml",
      "question_score": 13,
      "answer_score": 3,
      "created_at": "2021-04-20T12:00:30",
      "url": "https://stackoverflow.com/questions/67176678/cant-create-a-second-ingress-controller-using-helm-with-custom-class-in-azure-k8"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 72548750,
      "title": "Docker Nginx reverse proxy to Vue Vite and backend containers unexpected result",
      "problem": "As shown below, I have set up the environment with docker containers. The reason for this is because I only have a single VPS where I can run both frontend and backend on.\nThe way I want to tackle the problem is to put Nginx inside a docker container, using certbot for the verification (which already works) and then to reverse proxy into the frontend or backend based on what location the user is requesting.\n\nAs shown I am not sure how Nginx should communicate with the frontend or backend.\nWhen I tried to do\n```\n`upstream docker-frontend {\n    server frontend:8081;\n}\n\nupstream docker-backend {\n    server backend:8080;\n}\n`\n```\nGave me a `502 bad gateway` error. I somewhere on Stackoverflow found that instead of running the backend or frontend purely on 8080->8080/tcp or 8081->8081/tcp, I should run both on 80/tcp.\nI also made sure to put all the containers on the same network, which seemed to have helped slightly.\nThen as follows write the Nginx configuration\n```\n`upstream docker-frontend {\n    server frontend:80;\n}\n\nupstream docker-backend {\n    server backend:80;\n}\n`\n```\nHowever by doing so I now have a completely blank page with nothing showing up. I can assure you that there's no blank page in the frontend (which is built with Vue 3.0 vite).\nnginx.conf\n```\n`user nginx;\nworker_processes 1;\n\nerror_log /var/log/nginx/error.log warn;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    log_format main '$remote_addr - $remote_user [$time_local] :$request\" '\n        '$status $body_bytes_sent \"$http_referer\" '\n        '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log /var/log/nginx/access.log main;\n    sendfile on;\n    keepalive_timeout 65;\n\n    upstream docker-frontend {\n        server frontend:80;\n    }\n\n    upstream docker-backend {\n        server backend:80;\n    }\n \n    server {\n        listen 8081;\n \n        location / {\n            proxy_pass         http://docker-frontend/;\n            proxy_redirect     off;\n            proxy_set_header   Host $host;\n            proxy_set_header   X-Real-IP $remote_addr;\n            proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header   X-Forwarded-Host $server_name;\n        }\n    }\n \n    server {\n        listen 8080;\n \n        location / {\n            proxy_pass         http://docker-backend/example/;\n            proxy_redirect     off;\n            proxy_set_header   Host $host;\n            proxy_set_header   X-Real-IP $remote_addr;\n            proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header   X-Forwarded-Host $server_name;\n        }\n    }\n\n    server {\n        listen 80;\n        listen [::]:80;\n        server_name www.example.com;\n\n        include letsencrypt-acme-challenge.conf;\n\n        return 301 https://www.example.com;\n    }\n\n    server {\n        listen 443 ssl;\n        listen [::]:443 ssl;\n        server_name example.com;\n\n        ssl_certificate fullchain.pem;\n        ssl_certificate_key privkey.pem;\n        ssl_trusted_certificate chain.pem;\n        return 301 https://www.example.com;\n    }\n\n    server {\n        listen 443 ssl default_server;\n        listen [::]:443 ssl default_server;\n        server_name www.example.com;\n        ssl_certificate fullchain.pem;\n        ssl_certificate_key privkey.pem;\n        ssl_trusted_certificate chain.pem;\n        root /usr/share/nginx/html/;\n\n        location / {\n            gzip off;\n            root /usr/share/nginx/html/;\n            index index.html;\n            try_files $uri $uri/ /index.html;\n\n            add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains; preload\";\n            add_header X-Frame-Options DENY;\n            add_header X-Content-Type-Options nosniff;\n            add_header X-XSS-Protection \"1; mode=block\";\n            add_header Referrer-Policy \"origin\";\n\n            proxy_pass http://docker-frontend/;\n            proxy_redirect off;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Host $server_name;\n        }\n\n        location /example/ {\n            add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains; preload\";\n            add_header X-Frame-Options DENY;\n            add_header X-Content-Type-Options nosniff;\n            add_header X-XSS-Protection \"1; mode=block\";\n            add_header Referrer-Policy \"origin\";\n\n            proxy_pass http://docker-backend/example/;\n            proxy_redirect off;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Host $server_name;\n        }\n    }\n}\n`\n```\nThe nginx.conf created in the process of trying to learn how reverse proxy works, but I cannot seem to figure out why it is still showing a blank page. Any help would be appreciated.\nEDIT: It does seem like it shows the index.html, but I don't see any of the css or javascript within the page. Right now the dockerfile of the Vue app is configured as follows\nDockerfile\n```\n`FROM node:lts-alpine as build-stage\nRUN mkdir -p /app\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nRUN npm run build\nFROM nginx:stable-alpine as production-stage\nCOPY ./nginx.conf /etc/nginx/nginx.conf\nRUN rm -rf /usr/share/nginx/html/*\nCOPY --from=build-stage /app/dist /usr/share/nginx/html\nEXPOSE 80\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n`\n```\nHowever I am still not sure why it does not load the javascript or css. Is there a special way of setting up a reverse proxy for Vue? Or is my nginx.conf not set up properly?\nEDIT: Even after adding hot reload\n```\n`proxy_http_version 1.1;\nproxy_set_header Upgrade $http_upgrade;\nproxy_set_header Connection \"upgrade\";\n`\n```\nIt still does not want to show anything but a blank page.\nWhen I inspect the docker container of the Vue application with\n\ndocker exec -it example /bin/sh\n\nIn the `/html` folder it shows with the favicon, assets and the index.html, but there's no css or js folder? Within the assets folder however there's a weird `index.a6f56555.js` and `index.1212255f.css`. Did anyone else experience this before or is it just me?\nEDIT: I found out that Vue isn't correctly building itself with the Dockerfile to the `/html` folder, for some reason it only puts the index.html there but not the javascript or css?\nvite.config.js\n```\n`import { fileURLToPath, URL } from 'url'\nimport vue from '@vitejs/plugin-vue'\nimport { defineConfig } from 'vite'\nimport svgLoader from 'vite-svg-loader'\n\nexport default defineConfig({\n  server: {\n    port: 8081\n  },\n  plugins: [vue(), svgLoader()],\n  resolve: {\n    alias: {\n      '@': fileURLToPath(new URL('./src', import.meta.url)),\n    },\n  },\n  publicPath: process.env.NODE_ENV === 'production'\n    ? ''\n    : '/',\n  css: {\n    loaderOptions: {\n      sass: {\n        prependData: `@import \"@/styles/_variables.scss\";`\n      },\n    },\n    preprocessorOptions: {\n      scss: {\n        implementation: require('sass'),\n        additionalData: `\n            @import \"./src/assets/scss/main.scss\";\n        `\n      }\n    }\n  },\n  base: './'\n})\n`\n```\nEven with setting up the Vite config file as recommended by multiple sources  and the package.json containing the\n\nnpm run build && vite preview --port 8081 --host\n\ncommand, it still shows up with a blank page, can anyone tell me what I've been doing wrong? Because I have no clue at this point...",
      "solution": "I managed to fix the problem myself. It took me quite some time to figure out, but by chance I stumbled on this page: https://dev.to/programmingdecoded/docker-configuration-with-nginx-routing-for-vue-and-laravel-49e9\nfolder/file structure frontend\n```\n`/node_modules \n/src\nnginx.conf\nDockerfile\nvite.config.js\n`\n```\nnew nginx.conf\n```\n`upstream docker-frontend {\n    server example-frontend:8081;\n}\n\nupstream docker-backend {\n    server example-backend:8080;\n}\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name www.example.com;\n\n    include letsencrypt-acme-challenge.conf;\n\n    return 301 https://$host;\n}\n\nserver {\n    listen 443 ssl;\n    listen [::]:443 ssl;\n    server_name example.com;\n\n    ssl_certificate fullchain.pem;\n    ssl_certificate_key privkey.pem;\n    ssl_trusted_certificate chain.pem;\n    return 301 https://$host;\n}\n\nserver {\n    listen 443 ssl default_server;\n    listen [::]:443 ssl default_server;\n    server_name www.example.com;\n    ssl_certificate fullchain.pem;\n    ssl_certificate_key privkey.pem;\n    ssl_trusted_certificate chain.pem;\n\n    location / {\n        gzip off;\n        index index.html;\n        root /usr/share/nginx/html/;\n        error_log  /var/log/nginx/error.log;\n        access_log /var/log/nginx/access.log main;\n\n        add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains; preload\";\n        add_header X-Frame-Options DENY;\n        add_header X-Content-Type-Options nosniff;\n        add_header X-XSS-Protection \"1; mode=block\";\n        add_header Referrer-Policy \"origin\";\n\n        proxy_pass http://docker-frontend;\n        proxy_redirect off;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Host $server_name;\n        proxy_cache_bypass $http_upgrade;\n    }\n\n    location /example/ {\n        add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains; preload\";\n        add_header X-Frame-Options DENY;\n        add_header X-Content-Type-Options nosniff;\n        add_header X-XSS-Protection \"1; mode=block\";\n        add_header Referrer-Policy \"origin\";\n\n        proxy_pass http://docker-backend/example;\n        proxy_redirect off;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Host $server_name;\n    }\n}\n`\n```\nAs you can see above, I also made the upstream to 8081 and 8080. You can also see that I removed the `http` tag, `workers` tag, etc. This is because instead of replacing the nginx.conf inside the `/etc/nginx`, I replaced the `/etc/nginx/conf.d/default.conf` with my custom nginx.conf above.\nThen as followed I configured the Dockerfile\n```\n`FROM node:lts-alpine as build-stage\nRUN mkdir -p /app\nWORKDIR /app\nCOPY package*.json ./\nRUN npm install\nCOPY . .\nRUN npm run build\n\nFROM nginx:stable-alpine as production-stage\nEXPOSE 8081\nCOPY nginx.conf /etc/nginx/conf.d/default.conf\nRUN rm -rf /usr/share/nginx/html/*\nCOPY --from=build-stage /app/dist /usr/share/nginx/html\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n`\n```\nHere I made sure to expose the 8081 port instead of the 80 port and I also made sure that here as well, I should not replace the nginx.conf inside the `/etc/nginx` but the `/etc/nginx/conf.d/default.conf` with the nginx.conf below.\nThen the Vue application needs it's own nginx.conf as well\nVue nginx.conf\n```\n`server {\n    listen 8081;\n    root /usr/share/nginx/html;\n    include /etc/nginx/mime.types;\n\n    location / {\n        root /usr/share/nginx/html;\n        index index.html index.htm;\n        try_files $uri $uri/ /index.html;\n    }\n}\n`\n```\nThen running the following commands to start it up\n\ndocker run -it -d -p 8081:8081 --network=example --name example-frontend example\n\nThe command above runs the frontend or backend\n\ndocker run -it --rm --name nginx -v ${PWD}/example/nginx.conf:/etc/nginx/conf.d/default.conf -v ${PWD}/example/letsencrypt-acme-challenge.conf:/etc/nginx/snippets/letsencrypt-acme-challenge.conf -v ${PWD}/example:/letsencrypt -v ${PWD}/example/letsencrypt/certs:/etc/letsencrypt --network=example -p 80:80 -p 443:443 nginx\n\nThis command runs the nginx and makes sure to store the external files that are in the Ubuntu server inside the docker container. For this as well, make sure that you configure towards `/etc/nginx/conf.d/default.conf` and not replace the actual nginx.conf from `/etc/nginx`.\nTo me this was a very strange solution, but it also made sense.",
      "question_score": 13,
      "answer_score": 12,
      "created_at": "2022-06-08T17:53:23",
      "url": "https://stackoverflow.com/questions/72548750/docker-nginx-reverse-proxy-to-vue-vite-and-backend-containers-unexpected-result"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 65551212,
      "title": "Using CSP in NextJS, nginx and Material-ui(SSR)",
      "problem": "TLDR: I'm having trouble with setting up CSP for NextJS using Material-UI (server side rendering) and served by Nginx (using reverse proxy).\nCurrently I have issues with loading Material-UI stylesheet, and loading my own styles\nusing `makeStyles` from `@material-ui/core/styles`\nNOTE:\n\nfollowed https://material-ui.com/styles/advanced/#next-js to enable SSR\n\nhttps://github.com/mui-org/material-ui/tree/master/examples/nextjs\n\nI looked at https://material-ui.com/styles/advanced/#how-does-one-implement-csp but I'm not sure how I can get nginx to follow the `nonce` values, since nonce are generated as unpredictable string.\n\ndefault.conf (nginx)\n```\n`# https://www.acunetix.com/blog/web-security-zone/hardening-nginx/\n\nupstream nextjs_upstream {\n  server localhost:3000;\n\n  # We could add additional servers here for load-balancing\n}\n\nserver {\n  listen $PORT default_server;\n\n  # redirect http to https. use only in production\n  # if ($http_x_forwarded_proto != 'https') {\n  #   rewrite ^(.*) https://$host$request_uri redirect;\n  # }\n\n  server_name _;\n\n  server_tokens off;\n\n  proxy_http_version 1.1;\n  proxy_set_header Upgrade $http_upgrade;\n  proxy_set_header Connection 'upgrade';\n  proxy_set_header Host $host;\n  proxy_cache_bypass $http_upgrade;\n\n  # hide how is app powered. In this case hide NextJS is running behind the scenes.\n  proxy_hide_header X-Powered-By;\n\n  # set client request body buffer size to 1k. Usually 8k\n  client_body_buffer_size 1k;\n  client_header_buffer_size 1k;\n  client_max_body_size 1k;\n  large_client_header_buffers 2 1k;\n\n  # ONLY respond to requests from HTTPS\n  add_header Strict-Transport-Security \"max-age=31536000; includeSubdomains; preload\";\n\n  # to prevent click-jacking\n  add_header X-Frame-Options \"DENY\";\n\n  # don't load scripts or CSS if their MIME type as indicated by the server is incorrect\n  add_header X-Content-Type-Options nosniff;\n\n  add_header 'Referrer-Policy' 'no-referrer';\n\n  # Content Security Policy (CSP) and X-XSS-Protection (XSS)\n  add_header Content-Security-Policy \"default-src 'none'; script-src 'self'; object-src 'none'; style-src 'self' https://fonts.googleapis.com/css?family=Roboto:300,400,500,700&display=swap ; form-action 'none'; frame-ancestors 'none'; base-uri 'none';\" always;\n  add_header X-XSS-Protection \"1; mode=block\";\n\n  ssl_protocols TLSv1.2 TLSv1.3;\n  ssl_prefer_server_ciphers on;\n\n  location / {\n    # limit request types to HTTP GET\n    # ignore everything else\n    limit_except GET { deny all; }\n\n    proxy_pass http://nextjs_upstream;\n  }\n}\n`\n```",
      "solution": "The solution I found was to add nonce value to the inline js and css in _document.tsx\n_document.tsx\nGenerate a nonce using uuid v4 and convert it to base64 using crypto nodejs module.\nThen create Content Security Policy and add the generated nonce value.\nCreate a function to accomplish to create a nonce and generate CSP and return the CSP string along with the nonce\nAdd the generated CSP in the HTML Head and add meta tags.\n`import React from 'react';\nimport Document, { Html, Head, Main, NextScript } from 'next/document';\nimport { ServerStyleSheets } from '@material-ui/core/styles';\nimport crypto from 'crypto';\nimport { v4 } from 'uuid';\n\n// import theme from '@utils/theme';\n\n/**\n * Generate Content Security Policy for the app.\n * Uses randomly generated nonce (base64)\n *\n * @returns [csp: string, nonce: string] - CSP string in first array element, nonce in the second array element.\n */\nconst generateCsp = (): [csp: string, nonce: string] => {\n  const production = process.env.NODE_ENV === 'production';\n\n  // generate random nonce converted to base64. Must be different on every HTTP page load\n  const hash = crypto.createHash('sha256');\n  hash.update(v4());\n  const nonce = hash.digest('base64');\n\n  let csp = ``;\n  csp += `default-src 'none';`;\n  csp += `base-uri 'self';`;\n  csp += `style-src https://fonts.googleapis.com 'unsafe-inline';`; // NextJS requires 'unsafe-inline'\n  csp += `script-src 'nonce-${nonce}' 'self' ${production ? '' : \"'unsafe-eval'\"};`; // NextJS requires 'self' and 'unsafe-eval' in dev (faster source maps)\n  csp += `font-src https://fonts.gstatic.com;`;\n  if (!production) csp += `connect-src 'self';`;\n\n  return [csp, nonce];\n};\n\nexport default class MyDocument extends Document {\n  render(): JSX.Element {\n    const [csp, nonce] = generateCsp();\n\n    return (\n      \n        \n          {/* PWA primary color */}\n          {/*  */}\n          \n          \n          \n        \n        \n          \n          \n        \n      \n    );\n  }\n}\n\n// `getInitialProps` belongs to `_document` (instead of `_app`),\nMyDocument.getInitialProps = async (ctx) => {\n  const sheets = new ServerStyleSheets();\n  const originalRenderPage = ctx.renderPage;\n\n  ctx.renderPage = () =>\n    originalRenderPage({\n      enhanceApp: (App) => (props) => sheets.collect(),\n    });\n\n  const initialProps = await Document.getInitialProps(ctx);\n\n  return {\n    ...initialProps,\n    // Styles fragment is rendered after the app and page rendering finish.\n    styles: [...React.Children.toArray(initialProps.styles), sheets.getStyleElement()],\n  };\n};\n\n`\nsource: https://github.com/vercel/next.js/blob/master/examples/with-strict-csp/pages/_document.js\nnginx config\nmake sure to remove adding header regarding Content Security Policy. It might override the CSP in _document.jsx file.\n\nalternative solutions\nCreating a custom server and injecting nonce and Content Security Policy that can be accessed in _document.tsx\n\nhttps://bitgate.cz/content-security-policy-inline-scripts-and-next-js/\nhttps://nextjs.org/docs/advanced-features/custom-server\nhttps://medium.com/weekly-webtips/next-js-on-the-server-side-notes-to-self-e2170dc331ff",
      "question_score": 12,
      "answer_score": 15,
      "created_at": "2021-01-03T15:57:15",
      "url": "https://stackoverflow.com/questions/65551212/using-csp-in-nextjs-nginx-and-material-uissr"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66688329,
      "title": "Request Line is too large (8192 &gt; 4094)",
      "problem": "I am using nginx and gunicorn to deploy my django project, when I use GET funcation posted data to server I get the error:\n```\n`Bad Request\n\nRequest Line is too large (8192 > 4094)\n`\n```\nOn nginx.conf I have:\n```\n`client_max_body_size 100g;\nclient_header_buffer_size 512k;\nlarge_client_header_buffers 4 512k;\n`\n```\nMany methods on the Internet are changing \"large_client_header_buffers\" from 4 512k; but didn't fix the problem.\nAny help or explanation is welcome! Thank you.",
      "solution": "it is gunicorn issue, not Nginx\nyou can change the limit\n```\n`--limit-request-line \n`\n```\nhttps://docs.gunicorn.org/en/stable/settings.html#limit-request-line",
      "question_score": 12,
      "answer_score": 23,
      "created_at": "2021-03-18T10:36:13",
      "url": "https://stackoverflow.com/questions/66688329/request-line-is-too-large-8192-4094"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 65627946,
      "title": "How to start Nginx server within alpine image using rc-service command",
      "problem": "I am trying to create my own `Nginx` image, using `apline:3.12.0` image, after fixing a lot of errors, thanks to the internet, I managed to do it and everything works fine, but the problem is when I run the following command :\n```\n`rc-service nginx status\n * status: stopped\n`\n```\nand when I try to start the service this is what it gives me as shown below :\n```\n`rc-service nginx start\n * WARNING: nginx is already starting\n`\n```\neven though the service is stopped the output of the second command tells it is already started?!\nso I opened the localhost of my docker-machine to verify whether the service is on or off, and the nginx html page appears successfully.\nI tried to run `rc-service nginx reload` and this is the result:\n```\n`rc-service nginx reload\n/lib/rc/sh/openrc-run.sh: line 100: can't create /sys/fs/cgroup/blkio/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 100: can't create /sys/fs/cgroup/cpu/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 100: can't create /sys/fs/cgroup/cpuacct/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 100: can't create /sys/fs/cgroup/cpuset/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 100: can't create /sys/fs/cgroup/devices/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 100: can't create /sys/fs/cgroup/freezer/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 100: can't create /sys/fs/cgroup/hugetlb/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 100: can't create /sys/fs/cgroup/memory/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 100: can't create /sys/fs/cgroup/net_cls/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 100: can't create /sys/fs/cgroup/net_prio/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 100: can't create /sys/fs/cgroup/perf_event/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 100: can't create /sys/fs/cgroup/pids/tasks: Read-only file system\n * nginx: cannot `reload' as it has not been started\n`\n```\nhere is the output of `nginx -t` :\n```\n`nginx -t\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nnginx: configuration file /etc/nginx/nginx.conf test is successful\n`\n```\nand here is the output of `less /var/log/nginx/error.log` as shown below there is no error :\n```\n`less: can't open '/var/log/nginx/error.log': No such file or directory\n`\n```\nthis is my dockerfile :\n```\n`From alpine:latest\n\nCOPY nginx.conf ./tmp\nCOPY index.html ./tmp\nCOPY run.bash ./tmp\nCOPY run2.bash ./tmp\n\nRUN apk update && \\\n    apk add nginx && \\\n    adduser -D -g 'www' www && \\\n    mkdir /www && \\\n    chown -R www:www /var/lib/nginx && \\\n    chown -R www:www /www && \\\n    mv /etc/nginx/nginx.conf /etc/nginx/nginx.conf.orig && \\\n    apk add openrc --no-cache && \\\n    sh tmp/run.bash\n\ncmd sh tmp/run2.bash\n`\n```\nrun.bash :\n```\n`mv tmp/nginx.conf /etc/nginx/nginx.conf\nmv tmp/index.html  /www/index.html\n`\n```\nrun2.bash :\n```\n`mkdir /run/openrc\ntouch /run/openrc/softlevel\nmkdir -p /run/nginx\nnginx\nsh\n`\n```\nand this is the guide that I followed :\nhttps://wiki.alpinelinux.org/wiki/Nginx\nI want to know why `rc-service nginx reload` doesn't work even that my nginx service is running perfectly on my docker machine, and also why `rc-service nginx status` tells that the nginx service is stopped even that it is not ?\nand thanks in advance.\nBy the way when I run this command `nginx -s reload`, it works without any errors.",
      "solution": "After debugging and lots of trial and error, I found a perfect solution at least for me, David Maze answer is very helpful, But I need to be able to restart the nginx service within the container.\nwhatever when I start my container using the following command :\n```\n`docker run -it -p 80:80 -p 443:443 alpine:3.12.0\n`\n```\nwe access the container shell, and we need to download `nginx` server , and `openrc` to be able to use `rc-service` command line.\n```\n`/ # apk update\n/ # apk add nginx openrc\n`\n```\n#ANSWER 1\nnow we'll test If there is an error in nginx server by using the following command :\n```\n`/ # nginx -t\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nnginx: [emerg] open() \"/run/nginx/nginx.pid\" failed (2: No such file or directory)\nnginx: configuration file /etc/nginx/nginx.conf test failed\n`\n```\nas you can see from the output that we get, It tells you that a missing file or directory shall be created, so let's create that directory :\n```\n`/ # ls -la run/\ntotal 8\ndrwxr-xr-x    2 root     root          4096 Dec 16 10:31 .\ndrwxr-xr-x    1 root     root          4096 Jan 16 08:12 ..\n\n/ # mkdir /run/nginx/\n`\n```\nand we give that directory that we created some permissions :\n```\n`/ # chown -R nginx:nginx /run/nginx/\n/ # chmod 775 /run/nginx/\n/ # ls -la /run/\ntotal 12\ndrwxr-xr-x    1 root     root          4096 Jan 16 08:15 .\ndrwxr-xr-x    1 root     root          4096 Jan 16 08:12 ..\ndrwxrwxr-x    2 nginx    nginx         4096 Jan 16 08:15 nginx\n`\n```\nnow we are good with nginx :\n```\n`/ # nginx -t\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nnginx: configuration file /etc/nginx/nginx.conf test is successful\n`\n```\nLet's test our nginx service is it started or not with `rc-service` command :\n```\n`/ # rc-service nginx status\n * You are attempting to run an openrc service on a\n * system which openrc did not boot.\n * You may be inside a chroot or you may have used\n * another initialization system to boot this system.\n * In this situation, you will get unpredictable results!\n * If you really want to do this, issue the following command:\n * touch /run/openrc/softlevel\n`\n```\nSo from the above output we see that we have two problems, `openrc` did not boot, and there is a missing file `softlevel` :\n```\n`/ # ls -la /run/\ntotal 12\ndrwxr-xr-x    1 root     root          4096 Jan 16 08:15 .\ndrwxr-xr-x    1 root     root          4096 Jan 16 08:12 ..\ndrwxrwxr-x    2 nginx    nginx         4096 Jan 16 08:22 nginx\n`\n```\nLet's start by booting our system with `openrc` simply by typing it itself :\n```\n`/ # openrc\n * Caching service dependencies ...\nService `hwdrivers' needs non existent service `dev'\n\n/ # ls -la /run/\ntotal 16\ndrwxr-xr-x    1 root     root          4096 Jan 16 08:29 .\ndrwxr-xr-x    1 root     root          4096 Jan 16 08:12 ..\ndrwxrwxr-x    2 nginx    nginx         4096 Jan 16 08:22 nginx\ndrwxr-xr-x   14 root     root          4096 Jan 16 08:29 openrc\n\n/ # ls -la /run/openrc/\ntotal 64\ndrwxr-xr-x   14 root     root          4096 Jan 16 08:29 .\ndrwxr-xr-x    1 root     root          4096 Jan 16 08:29 ..\ndrwxr-xr-x    2 root     root          4096 Jan 16 08:29 daemons\n-rw-r--r--    1 root     root            11 Jan 16 08:29 depconfig\n-rw-r--r--    1 root     root          2895 Jan 16 08:29 deptree\ndrwxr-xr-x    2 root     root          4096 Jan 16 08:29 exclusive\ndrwxr-xr-x    2 root     root          4096 Jan 16 08:29 failed\ndrwxr-xr-x    2 root     root          4096 Jan 16 08:29 hotplugged\ndrwxr-xr-x    2 root     root          4096 Jan 16 08:29 inactive\ndrwxr-xr-x    2 root     root          4096 Jan 16 08:29 options\ndrwxr-xr-x    2 root     root          4096 Jan 16 08:29 scheduled\ndrwxr-xr-x    2 root     root          4096 Jan 16 08:29 started\ndrwxr-xr-x    2 root     root          4096 Jan 16 08:29 starting\ndrwxr-xr-x    2 root     root          4096 Jan 16 08:29 stopping\ndrwxr-xr-x    2 root     root          4096 Jan 16 08:29 tmp\ndrwxr-xr-x    2 root     root          4096 Jan 16 08:29 wasinactive\n`\n```\nnow we create the missing file :\n```\n`/ # touch /run/openrc/softlevel\n`\n```\nnow our `rc-service` command works perfectly :\n```\n`/ # rc-service nginx status\n * status: stopped\n`\n```\nlet's start our server :\n```\n` / # rc-service nginx start\n * Starting nginx ...          [ ok ]\n`\n```\ncheck if it is started or not :\n```\n`/ # rc-service nginx status\n * status: started\n`\n```\n#ANSWER 2\nOr you can simply call those two command lines instead :\n```\n`/ # openrc\n * Caching service dependencies ...\nService `hwdrivers' needs non existent service `dev'    [ ok ]\n\n/ # touch /run/openrc/softlevel\n`\n```\nNow you can start your nginx server :)\n```\n`/ # rc-service nginx status\n * status: stopped\n\n/ # rc-service nginx start\n * /run/nginx: creating directory\n * /run/nginx: correcting owner\n * Starting nginx ...         [ ok ]\n\n/ # rc-service nginx status\n * status: started\n`\n```\nHope I was clear.",
      "question_score": 11,
      "answer_score": 29,
      "created_at": "2021-01-08T12:13:41",
      "url": "https://stackoverflow.com/questions/65627946/how-to-start-nginx-server-within-alpine-image-using-rc-service-command"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 65944578,
      "title": "How to get NGINX running in Docker to reload nginx.conf configuration",
      "problem": "I am trying to get a NGINX based reverse proxy to work in Windows/WSL2 environment. I am very new to Docker and NGINX world. I am able to get the following command to work\n`docker run --name nginx-test -p 8080:80 -v /home/skotekar/nginx.conf:/etc/nginx/nginx.conf:ro -v /mnt/d/site1/wwwroot:/usr/share/nginx/html:ro -d nginx:alpine\n`\nI can then browse http://localhost:8080 and view my static content just fine. As you see from the command I have a default nginx.conf in my local /home folder which gets mapped into NGINX Docker when running. It works fine the first time.\nNow if I stop the container using:\n`docker container stop nginx-test\n`\nThen make changes to the nginx.conf file in my /home directory and want to start the container with updated configuration using following command:\n`docker container start nginx-test\n`\nBut this command fails gives me a very confusing message:\n\nError response from daemon: OCI runtime create failed: container_linux.go:370: starting container process caused: process_linux.go:459: container init caused: rootfs_linux.go:59: mounting \"/run/desktop/mnt/host/wsl/docker-desktop-bind-mounts/Ubuntu-20.04/c0d0caa87ff063ee46265048f5b1ee489a8945669d39c6f6110cd578b8cda1ed\" to rootfs at \"/var/lib/docker/overlay2/4e6b279945acb06200b3677272774f4b5fbb6a619214decbca8c594dbbe3b8ec/merged/etc/nginx/nginx.conf\" caused: no such file or directory: unknown\n\nOnly way to get it back running is to delete the container and use the first command again. Any idea how to get this working. It will be easier if I could just restart my container after making changes to config until I figure out the correct reverse proxy settings I need.\nThanks",
      "solution": "You do not need to restart container to reload new config. Nginx can hot-reload config without restarting.\nOnce you have mounted volume, you can make changes and they will be reflected in container immediately.\nTo test your config just execute this command:\n```\n`docker exec nginx-test nginx -t\n`\n```\nTo reload new config:\n```\n`docker exec nginx-test nginx -s reload\n`\n```\nEdit! Access Windows host from Docker running in the WSL2\nAs per comments i am very curious about your issues, because i haven't seen them in my career.\nSo my steps to reproduce your use case is:\n1. Download any web application for windows\nI chose caddy web server as it is single binary and I know it. It is similar application to Nginx\nhttps://caddyserver.com/download\n2. Setup simple webpage on Windows Host\nI prepared `Caddyfile` - Config for Caddy Web Server:\n```\n`:80\n\nrespond \"Hello, world from Caddy on Windows!\"\n`\n```\nThen i put this `Caddyfile` in the same directory, where I have Caddy Server binary:\n```\n`PS C:\\Users\\Daniel\\Downloads\\caddy> ls\n\n    Directory: C:\\Users\\Daniel\\Downloads\\caddy\n\nMode                 LastWriteTime         Length Name\n----                 -------------         ------ ----\n-a----        29.01.2021     11:59             52 Caddyfile\n-a----        29.01.2021     11:55       34081792 caddy_windows_amd64.exe\n`\n```\n3. Start Web Server on Windows and verify it.\nTo start web server run: `./caddy.exe run`\nExample:\n```\n`PS C:\\Users\\Daniel\\Downloads\\caddy> .\\caddy_windows_amd64.exe run\n2021/01/29 11:01:27.520 \u2190[34mINFO\u2190[0m   using adjacent Caddyfile\n2021/01/29 11:01:27.528 \u2190[34mINFO\u2190[0m   admin   admin endpoint started  {\"address\": \"tcp/localhost:2019\", \"enforce_origin\": false, \"origins\": [\"localhost:2019\", \"[::1]:2019\", \"127.0.0.1:2019\"]}\n2021/01/29 11:01:27.529 \u2190[34mINFO\u2190[0m   tls.cache.maintenance   started background certificate maintenance      {\"cache\": \"0xc000497490\"}\n2021/01/29 11:01:27.529 \u2190[34mINFO\u2190[0m   http    server is listening only on the HTTP port, so no automatic HTTPS will be applied to this server {\"server_name\": \"srv0\", \"http_port\": 80}\n2021/01/29 11:01:27.530 \u2190[34mINFO\u2190[0m   tls     cleaned up storage units\n2021/01/29 11:01:27.532 \u2190[34mINFO\u2190[0m   autosaved config        {\"file\": \"C:\\\\Users\\\\Daniel\\\\AppData\\\\Roaming\\\\Caddy\\\\autosave.json\"}\n2021/01/29 11:01:27.532 \u2190[34mINFO\u2190[0m   serving initial configuration\n`\n```\nNow verify if it is working. Go to your browser and visit the `http://localhost/` page:\n\n4. Now verify you have WSL2 running on the windows host:\n```\n`PS C:\\Users\\Daniel> wsl.exe --list --all -v\n  NAME            STATE           VERSION\n* Ubuntu-20.04    Running         2\n`\n```\nIf yes shell there with command `wsl`\n5. Start docker daemon\n```\n`daniel@DESKTOP-K8UQA2E:~$ sudo service docker start\n * Starting Docker: docker\n`\n```\n6. Check your IPv4 address for WSL Network adapter in the Windows and Linux\nOpen `powershell` and execute the `ifconfig` command, then find WSL network adapter:\n```\n`Ethernet adapter vEthernet (WSL):\n\n   Connection-specific DNS Suffix  . :\n   Link-local IPv6 Address . . . . . : fe80::e96c:c3d6:464e:2a3b%72\n   IPv4 Address. . . . . . . . . . . : 172.20.240.1\n   Subnet Mask . . . . . . . . . . . : 255.255.240.0\n   Default Gateway . . . . . . . . . :\n`\n```\nYour Windows IP is `172.20.240.1`\nThen go to WSL and execute `curl 172.20.240.1`, to check if your hosts are connected.\n```\n`daniel@DESKTOP-K8UQA2E:~$ curl 172.20.240.1\nHello, world from Caddy on Windows!d\n`\n```\nNow figure out the Linux Host IP with the `ip a` command and see IP in the same network as Windows:\n```\n`5: eth0:  mtu 1500 qdisc mq state UP group default qlen 1000\n    link/ether 00:15:5d:ce:28:8e brd ff:ff:ff:ff:ff:ff\n    inet 172.20.252.177/20 brd 172.20.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::215:5dff:fece:288e/64 scope link\n       valid_lft forever preferred_lft forever\n`\n```\n7. Prepare simple nginx configuration\n```\n`worker_processes  5;  ## Default: 1\nworker_rlimit_nofile 8192;\n\nevents {\n  worker_connections  4096;  ## Default: 1024\n}\n\nhttp {\n  index    index.html index.htm index.php;\n\n  default_type application/octet-stream;\n  sendfile     on;\n  tcp_nopush   on;\n  server_names_hash_bucket_size 128; # this seems to be required for some vhosts\n\n  server { # simple load balancing\n    listen          80;\n\n     location / {\n      return  200 \"Hello World from Nginx in Linux\";\n    }\n\n    location /windows {\n      proxy_pass      http://172.20.240.1/;\n    }\n  }\n}\n`\n```\nThis is very simple config\n8. Start the docker with `host` networking mode.\nIf you do not want to use the `host` networking, you have to do forwarding packets from docker network to the wsl network because your docker will not have access to windows host directly.\nBut let's say you can start container with `host` networking.\nRun this command:\n```\n`daniel@DESKTOP-K8UQA2E:~/nginx-test$ sudo docker run -v $(pwd)/nginx.conf:/etc/nginx/nginx.conf --name=\"nginx-local\" --network=host  -d nginx:latest\n`\n```\nVerify your docker is working fine:\n```\n`daniel@DESKTOP-K8UQA2E:~/nginx-test$ sudo docker logs nginx-local\n/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\ndaniel@DESKTOP-K8UQA2E:~/nginx-test$ sudo docker ps | grep nginx\n\nde9873314b77        nginx:latest           \"/docker-entrypoint.\u2026\"   20 seconds ago      Up 19 seconds\n`\n```\n8. Try to get response from linux and windows\n```\n`daniel@DESKTOP-K8UQA2E:~/nginx-test$ curl localhost\nHello World from Nginx in Linux\ndaniel@DESKTOP-K8UQA2E:~/nginx-test$ curl localhost/windows\nHello, world from Caddy on Windows!\ndaniel@DESKTOP-K8UQA2E:~/nginx-test$\n`\n```",
      "question_score": 11,
      "answer_score": 24,
      "created_at": "2021-01-28T21:15:53",
      "url": "https://stackoverflow.com/questions/65944578/how-to-get-nginx-running-in-docker-to-reload-nginx-conf-configuration"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 76348128,
      "title": "Enabling QUIC / http/3 on multiple domains with NGINX 1.25",
      "problem": "NGINX 1.25 introduced support for http/3 (over QUIC). To enable it, one can add\n```\n`listen 443 quic reuseport;\n`\n```\nto the `server` block, alongside the likely existing\n```\n`listen 443 ssl http2;\n`\n```\nHowever, if I add the `quic` listen for more than one server block (which all have a different `server_name` set), then NGINX rejects the config with the following error:\n```\n`[emerg] 2611#2611: duplicate listen options for 0.0.0.0:443 in /etc/nginx/sites-enabled/site.conf\n`\n```\nIt is possible to listen on different ports for different domains, but that doesn\u2019t seem to be user-friendly \u2014 Firefox will display the port number in the url, even if it loaded the page over http/2 first and then got the http/3 port from an `Alt-Svc` header. It\u2019s also tedious to manually allocate ports and to configure the firewall for this.\nAll my `server` blocks are using the same certificate. All domains that I have a `server` block for are subject alternative names in the single certificate. RFC9114 says that http/3 clients must support Server Name Indication, but even without it, because all my domains use the same certificate, it should be possible in theory to establish a connection and then decide what content to serve based on the `Host` header. This is not what happens though, when I send a request over QUIC, NGINX serves from the `server` block that the `listen 443 quic` is in, it seems to ignore the server name.\nIs it possible with NGINX 1.25 to serve multiple domains over http/3 all on port 443?",
      "solution": "Yes, nginx can serve http/3 on multiple virtual hosts, but `reuseport` option is supported only for 1 virtual host per the same `listen IP:PORT` directive.\nSo, you should use different IPs for your virtual hosts or remove `reuseport` option.",
      "question_score": 11,
      "answer_score": 4,
      "created_at": "2023-05-27T19:20:14",
      "url": "https://stackoverflow.com/questions/76348128/enabling-quic-http-3-on-multiple-domains-with-nginx-1-25"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 70028324,
      "title": "nginx permission denied accessing puma socket that does exist in the correct location",
      "problem": "On a Digital Ocean droplet running Ubuntu 21.10 impish I am deploying a bare bones Rails 7.0.0.alpha2 application to production. I am setting up nginx as the reverse proxy server to communicate with Puma acting as the Rails server.\nI wish to run puma as a service using systemctl without sudo root privileges. To this effect I have a puma service setup in the users home folder located at `~/.config/systemd/user`, the service is enabled and runs as I would expect it to run.\n```\n`systemctl status --user puma_master_cms_production\n`\n```\nreports the following\n```\n`\u25cf puma_master_cms_production.service - Puma HTTP Server for master_cms (production)\n     Loaded: loaded (/home/comtechmaster/.config/systemd/user/puma_master_cms_production.service; enabled; vendor preset: enabled)\n     Active: active (running) since Thu 2021-11-18 22:31:02 UTC; 1h 18min ago\n   Main PID: 1577 (ruby)\n      Tasks: 10 (limit: 2338)\n     Memory: 125.1M\n        CPU: 2.873s\n     CGroup: /user.slice/user-1000.slice/user@1000.service/app.slice/puma_master_cms_production.service\n             \u2514\u25001577 puma 5.5.2 (unix:///home/comtechmaster/apps/master_cms/shared/tmp/sockets/puma_master_cms_production.sock)\n\nNov 18 22:31:02 master-cms systemd[749]: Started Puma HTTP Server for master_cms (production).\n`\n```\nThe rails production.log is empty.\nThe puma error log shows the following\n```\n`cat log/puma_error.log \n=== puma startup: 2021-11-18 22:31:05 +0000 ===\n`\n```\nThe pid files exist in the application roots shared/tmp/pids folder\n```\n`ls tmp/pids\npuma.pid  puma.state\n`\n```\nand the socket that nginx needs but is unable to connect to due to permission denied exists\n```\n`ls -l ~/apps/master_cms/shared/tmp/sockets/\ntotal 0\nsrwxrwxrwx 1 comtechmaster comtechmaster 0 Nov 18 22:31 puma_master_cms_production.sock\n`\n```\nnginx is up and running and providing a\n\n502 bad gateway\n\nresponse. The nginx error log reports the following error\n```\n`2021/11/18 23:18:43 [crit] 1500#1500: *25 connect() to unix:/home/comtechmaster/apps/master_cms/shared/tmp/sockets/puma_master_cms_production.sock failed (13: Permission denied) while connecting to upstream, client: 86.160.191.54, server: 159.65.50.229, request: \"GET / HTTP/2.0\", upstream: \"http://unix:/home/comtechmaster/apps/master_cms/shared/tmp/sockets/puma_master_cms_production.sock:/500.html\"\n`\n```\nsudo nginx -t reports the following\n```\n`sudo nginx -t\nnginx: [warn] could not build optimal proxy_headers_hash, you should increase either proxy_headers_hash_max_size: 512 or proxy_headers_hash_bucket_size: 64; ignoring proxy_headers_hash_bucket_size\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nnginx: configuration file /etc/nginx/nginx.conf test is successfu\n`\n```\njust to be pedantic both an `ls` and a `sudo ls` to the path reported in the error shows\n```\n`ls /home/comtechmaster/apps/master_cms/shared/tmp/sockets/\npuma_master_cms_production.sock\n`\n```\nas expected so I am stumped to understand why nginx running as root using `sudo service nginx start` is being denied access to a socket that exists, that is owned by the local user rather than root.\nI expect the solution is going to be something totally obvious but I can not see what",
      "solution": "This problem ended up being related to the folder permissions for the users home folder and specifically a change in the way Ububntu 20.10 sets permissions differently to previous versions of ubuntu, or at least a difference in the way the DigitalOcean setup scripts behave.\nThis was resolved with a simple command line `chmod o=rx` from the `/home` against the user folder concerned e.g.\n```\n`cd /home\nchmod o=rx the_home_folder_for_user\n`\n```",
      "question_score": 10,
      "answer_score": 40,
      "created_at": "2021-11-19T01:13:25",
      "url": "https://stackoverflow.com/questions/70028324/nginx-permission-denied-accessing-puma-socket-that-does-exist-in-the-correct-loc"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 75114472,
      "title": "502 Bad Gateway in production with Nextjs next-auth with url &#39;/api/auth/callback/cognito&#39;",
      "problem": "I'm trying to publish a nextjs app that uses 'next-auth' with aws Cognito.\nWhen I run it locally, either using `next dev` OR `next start` it works completely fine.\nWhen I run it on the production server (ubuntu, with nginx) it does not.\nExact Error:\nAfter accessing the Cognito built in sign in page the redirect url `https://...../api/auth/callback/cognito?code=......&state=.....` displays nginx's default 502 error page.\nWhat I've checked:\n\nEvery possible google result, github issue, and stackoverflow question about this topic\nThe error logs of the production next server, as well as the nginx server, nothing there.\nBrowser console logs, nothing there\n\nAnd YES the `Callback URL(s)` setting for the app in AWS Cognito itself is set to the correct url (`https:// ....... /api/auth/callback/cognito`).\nDetails:\nCODE:\n`middleware.ts`\n```\n`export { default } from \"next-auth/middleware\";\n\nexport const config = { matcher: [\"/dashboard/:path*\"] };\n`\n```\n`next.config.js`\n```\n`/** @type {import('next').NextConfig} */\nconst nextConfig = {\n  reactStrictMode: true,\n  swcMinify: true,\n  compiler: {\n    styledComponents: true,\n   \n  },\n};\n\nmodule.exports = nextConfig;\n\n`\n```\n`pages/api/auth/[...nextauth].ts`\n```\n`import CognitoProvider from \"next-auth/providers/cognito\";\nimport NextAuth, { NextAuthOptions, Session } from \"next-auth\";\nimport {\n  AuthFlowType,\n  CognitoIdentityProviderClient,\n  InitiateAuthCommand,\n} from \"@aws-sdk/client-cognito-identity-provider\";\nimport { JWT } from \"next-auth/jwt\";\n\nconst COGNITO_AWS_REGION = process.env.COGNITO_AWS_REGION;\nconst COGNITO_POOL_ID = process.env.COGNITO_POOL_ID;\nconst COGNITO_CLIENT_ID = process.env.COGNITO_CLIENT_ID;\nconst COGNITO_CLIENT_SECRET = process.env.COGNITO_CLIENT_SECRET;\nconst NEXTAUTH_SECRET = process.env.NEXTAUTH_SECRET;\nconst NEXTAUTH_URL = process.env.NEXTAUTH_URL;\nif (!COGNITO_AWS_REGION) throw new Error(\"REGION is not set\");\nif (!COGNITO_CLIENT_ID) throw new Error(\"COGNITO_CLIENT_ID is not set\");\nif (!COGNITO_POOL_ID) throw new Error(\"COGNITO_USER_POOL_ID is not set\");\nif (!COGNITO_CLIENT_SECRET) throw new Error(\"COGNITO_CLIENT_SECRET is not set\");\nif (!NEXTAUTH_SECRET) throw new Error(\"NEXTAUTH_SECRET is not set\");\nif (!NEXTAUTH_URL) throw new Error(\"NEXTAUTH_URL is not set\");\n\nconst refreshCognitoAccessToken = async (token: JWT) => {\n  const client = new CognitoIdentityProviderClient({\n    region: COGNITO_AWS_REGION,\n  });\n  const command = new InitiateAuthCommand({\n    AuthFlow: AuthFlowType.REFRESH_TOKEN_AUTH,\n    ClientId: COGNITO_CLIENT_ID,\n    AuthParameters: {\n      REFRESH_TOKEN: token.refreshToken as string,\n    },\n  });\n  const response = await client.send(command);\n  return response.AuthenticationResult;\n};\n\nexport const authOptions: NextAuthOptions = {\n  secret: NEXTAUTH_SECRET,\n  // @ts-expect-error -- this property is not documented properly\n  site: NEXTAUTH_URL,\n  providers: [\n    CognitoProvider({\n      clientId: COGNITO_CLIENT_ID!,\n      issuer: `https://cognito-idp.${COGNITO_AWS_REGION}.amazonaws.com/${COGNITO_POOL_ID!}`,\n      clientSecret: process.env.COGNITO_CLIENT_SECRET!,\n      \n    }),\n  ],\n  callbacks: {\n    jwt: async ({ token, account, user }) => {\n      // Initial sign in\n      if (account && user) {\n        return {\n          // save token to session for authenticating to AWS\n          // https://next-auth.js.org/configuration/callbacks#jwt-callback\n          accessToken: account.access_token,\n          accessTokenExpires: account.expires_at\n            ? account.expires_at * 1000\n            : 0,\n          refreshToken: account.refresh_token,\n          user,\n        };\n      }\n\n      // Return previous token if the access token has not expired yet\n      if (Date.now()  {\n      if (!session?.user || !token?.accessToken) {\n        console.error(\"No accessToken found on token or session\");\n        return session;\n      }\n      session.user = token.user as Session[\"user\"];\n      session.accessToken = token.accessToken as string;\n      session.error = token.error as string | undefined;\n\n      return session;\n    },\n    redirect: async ({ url, baseUrl }) => {\n      // allows any url\n      if (url.startsWith(\"/\")) return `${baseUrl}${url}`;\n      return url;\n    },\n  },\n};\n\nexport default NextAuth(authOptions);\n`\n```",
      "solution": "Well I figured it out myself eventually, turns out I wasn't reading my nginx logs correctly, once I did it wasn't anything too hard... here is what I did:\nMost Important:\nThe 502 error is most likely corresponding with a `upstream sent too big header while reading response header from upstream` error in the nginx error logs for that request. To solve this add this to your config, under `/etc/nginx/nginx.conf` in the `http {... } ` section ...\n```\n`proxy_buffers 8 16k;\nproxy_buffer_size 32k;\n`\n```\n(found this solution here: https://stackoverflow.com/a/38758325/4205839)\nAdditional Things To Try:\nThe above should solve the 502 error, but you may still be getting errors with next-auth, here are a few other things to try which I discovered while trying to solve this problem...\nIn AWS Cognito, try making, and then using, a new \"App Client\" in AWS Cognito WITHOUT a client secret.\nIf you run it now you will get errors such as `signin?error=OAuthCallback` and `client_secret_basic client authentication method requires a client_secret`. So you will also need to update the config of cognito in  `pages/api/auth/[...nextauth].ts` to be ...\n```\n`CognitoProvider({\nclientId: COGNITO_CLIENT_ID,\n      issuer: `https://cognito-idp.${COGNITO_AWS_REGION}.amazonaws.com/${COGNITO_POOL_ID!}`,\n      clientSecret: \"someString\",\n      client: {\n           token_endpoint_auth_method: \"none\",\n      },\n})\n`\n```\nwhich I discovered from this discussion: https://github.com/nextauthjs/next-auth/issues/2524\nNote: If you receive something like a `redirect_mismatch` error from Cognito it means you haven't updated the urls correctly in your AWS Cognito client app settings, which is a frequent occurrence I've found when switching between local and live for debugging.",
      "question_score": 10,
      "answer_score": 25,
      "created_at": "2023-01-13T22:07:16",
      "url": "https://stackoverflow.com/questions/75114472/502-bad-gateway-in-production-with-nextjs-next-auth-with-url-api-auth-callback"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 68828128,
      "title": "Not able to connect to websocket using Nginx and Uvicorn",
      "problem": "I built a docker container with Django, Uvicorn, Nginx and Redis, and am using django-channels but when I run this it says it cannot connect to the websocket and this is seen in the browser console:\n\n`WebSocket connection to 'ws://127.0.0.1:8080/ws/notifications/' failed`\n\nIt is working fine when I use Django's runserver command for development but when I include Nginx and Uvicorn it breaks.\nEntrypoint.sh:\n```\n`gunicorn roomway.asgi:application --forwarded-allow-ips='*' --bind 0.0.0.0:8000 -k uvicorn.workers.UvicornWorker\n`\n```\nNginx config:\n```\n`upstream django {\n    server app:8000;\n}\n\nmap $http_upgrade $connection_upgrade {\n    default upgrade;\n    '' close;\n}\n\nserver {\n    listen 8080;\n\n    location /static {\n        alias /vol/static;\n    }\n\n    location /ws/ {\n        proxy_pass http://0.0.0.0:8000;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $connection_upgrade;\n    }\n\n    location / {\n        proxy_pass http://django;\n        proxy_set_header Host $http_host;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $connection_upgrade;\n        proxy_redirect off;\n        proxy_buffering off;\n    }\n}\n`\n```\nsettings.py:\n```\n`CHANNEL_LAYERS={\n    'default': {\n        'BACKEND': 'channels_redis.core.RedisChannelLayer',\n        'CONFIG': {\n            'hosts': [('redis', 6379)],  #Redis port\n        }\n    }\n}\n`\n```\nThe JS file which handles the socket:\n```\n`var wsStart = \"ws://\"    \nvar webSocketEndpoint =  wsStart + window.location.host + '/ws/notifications/'\nconst notificationSocket = new WebSocket(webSocketEndpoint)\n`\n```\nasgi.py:\n```\n`application = ProtocolTypeRouter({\n    \"http\": django_asgi_app,\n    \"websocket\": AuthMiddlewareStack(\n        URLRouter([\n            url(r'^ws/notifications/', NotificationConsumer.as_asgi()),\n            path(\"ws//\", ChatConsumer.as_asgi())            \n        ])\n    )\n})\n`\n```\nNginx throws this error with the above code:\n```\n`[error] 23#23: *4 connect() failed (111: Connection refused) while connecting to upstream, server: , request: \"GET /ws/notifications/ HTTP/1.1\", upstream: \"http://0.0.0.0:8000/ws/notifications/\", host: \"127.0.0.1:8080\"\n`\n```\nWhen I change the `proxy_pass` to `http://django` instead of `0.0.0.0`, Nginx does not throw that error anymore but I get the same error on the console. Also this time Django throws these warnings:\n```\n`[WARNING] Unsupported upgrade request.       \n[WARNING] No supported WebSocket library detected. Please use 'pip install uvicorn[standard]', or install 'websockets' or 'wsproto' manually.\n`\n```",
      "solution": "As noted in a comment by Iain Shelvington, it seems like websockets are not included in the base install of uvicorn\n`pip uninstall uvicorn\npip install 'uvicorn[standard]'\n`",
      "question_score": 10,
      "answer_score": 21,
      "created_at": "2021-08-18T09:27:24",
      "url": "https://stackoverflow.com/questions/68828128/not-able-to-connect-to-websocket-using-nginx-and-uvicorn"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 78111453,
      "title": "Yahoo Finance API file_get_contents 429 Too Many Requests",
      "problem": "I am using Yahoo Finance's API at https://query1.finance.yahoo.com/v8/finance/chart/Ticker with php's file_get_contents and getting \"failed to open stream: HTTP request failed! HTTP/1.0 429 Too Many Requests\" but when I use curl to the same URL from the command line of the server I get an actual response! I verified that both of the requests are coming from the same IP.\nI am not sending many requests - I sent maybe 40 get requests last night and then my first request today failed. My question is - has anyone seen the same type of problem? I read that the limit was 100 requests per hour - which I was well under!\nAny advice would be appreciated.",
      "solution": "Since you noticed that curl works, try adding a user agent to your request to mimic curl.\n` [\n        'method' => \"GET\",\n        'header' => \"User-Agent: curl/7.68.0\\r\\n\"\n    ]\n];\n$context = stream_context_create($options);\n$response = file_get_contents($url, false, $context);\n\nif ($response !== false) {\n    echo \"Response: \" . $response;\n} else {\n    echo \"Request failed\";\n}\n\n?>\n`\nI was running into the same issue in Rust and adding a similar user-agent to the request fixed it. You can also try a browser user agent such as `Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36`.",
      "question_score": 10,
      "answer_score": 12,
      "created_at": "2024-03-06T03:04:54",
      "url": "https://stackoverflow.com/questions/78111453/yahoo-finance-api-file-get-contents-429-too-many-requests"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 72405739,
      "title": "How to deploy Next.js static export with Nginx? (deep links not working)",
      "problem": "I made a next.js export into the `out` folder.\nFolder structure is:\n\nout\n\nindex.html\nterms.html\nprivacy.html\n\nI set up nginx to serve files from this folder:\n```\n`server {\n    root /var/www/myproject/out;\n    index index.html index.htm index.nginx-debian.html;\n\n    server_name myproject.com;\n\n    location / {\n        try_files $uri $uri/ /index.html;\n    }\n}\n`\n```\nThe main page (index) opens fine. Navigation from within the app to urls like `myproject.com/privacy` works fine. The problem is if I try to open these links directly, it will serve the main page (index) instead of the actual pages, since those urls don't exist in the folder. The only way to open the privacy page directly is adding the html extension to the url: `myproject.com/privacy.html`.\nHow to configure nginx to serve the actual page `myproject.com/privacy.html` when someone enters the `myproject.com/privacy` url?",
      "solution": "Issue is in `try_files`.\nAs current configuration includes:\n\n/ (which default route to index.html at root path)\nindex.html\n/index.html\ntest/*.html\n\nTo access pages route path name without extension i.e., `/privacy` that format should be included in `try_files` insdie `location /`\nTry this:\n```\n`try_files $uri $uri.html /$uri /index.html\n`\n```\nLittle explanation\nThe `try_files` directive in the `nginx.conf` file is used to specify how Nginx should handle requests for files. The directive attempts to serve files in the order they are listed, and if none of the specified files are found, it falls back to the last option.\nIn the provided code, `try_files $uri $uri.html /$uri /index.html;`, Nginx will follow these steps when a request is made:\nIt first tries to serve the file that matches the requested URI (`$uri`). For example, if the request is for `/about`, Nginx will look for a file named about.\nIf the file is not found, it then tries to serve a file with the `.html` extension appended to the requested URI (`$uri.html`). So, for the `/about` request, it will look for `about.html`.\nIf neither of the above files is found, it tries to serve the file by prepending a `/` to the requested URI (`/$uri`). This step is somewhat redundant in this context and might be a misconfiguration.\nFinally, if none of the previous files are found, it falls back to serving index.html. This is a common practice in single-page applications (SPAs) where all routes are handled by a single HTML file.\nThis configuration is particularly useful for SPAs built with frameworks like React, where client-side routing is used, and all routes should be served by the same index.html file.",
      "question_score": 9,
      "answer_score": 20,
      "created_at": "2022-05-27T14:51:25",
      "url": "https://stackoverflow.com/questions/72405739/how-to-deploy-next-js-static-export-with-nginx-deep-links-not-working"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 70908774,
      "title": "Nginx-ingress-controller fails to start after AKS upgrade to v1.22",
      "problem": "We performed our kubernetes cluster upgrade from v1.21 to v1.22. After this operation we discovered that our nginx-ingress-controller deployment\u2019s pods are failing to start with the following error message:\n`pkg/mod/k8s.io/client-go@v0.18.5/tools/cache/reflector.go:125: Failed to list *v1beta1.Ingress: the server could not find the requested resource`\nWe have found out that this issue is tracked over here: https://github.com/bitnami/charts/issues/7264\nBecause azure doesn't let to downgrade the cluster back to the 1.21 could you please help us fixing the nginx-ingress-controller deployment? Could you please be specific with what should be done and from where (local machine or azure cli, etc) as we are not very familiar with `helm`.\nThis is our deployment current yaml:\n```\n`kind: Deployment\napiVersion: apps/v1\nmetadata:\n  name: nginx-ingress-controller\n  namespace: ingress\n  uid: 575c7699-1fd5-413e-a81d-b183f8822324\n  resourceVersion: '166482672'\n  generation: 16\n  creationTimestamp: '2020-10-10T10:20:07Z'\n  labels:\n    app: nginx-ingress\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/managed-by: Helm\n    chart: nginx-ingress-1.41.1\n    heritage: Helm\n    release: nginx-ingress\n  annotations:\n    deployment.kubernetes.io/revision: '2'\n    meta.helm.sh/release-name: nginx-ingress\n    meta.helm.sh/release-namespace: ingress\n  managedFields:\n    - manager: kube-controller-manager\n      operation: Update\n      apiVersion: apps/v1\n      fieldsType: FieldsV1\n      fieldsV1:\n        f:spec:\n          f:replicas: {}\n      subresource: scale\n    - manager: Go-http-client\n      operation: Update\n      apiVersion: apps/v1\n      time: '2020-10-10T10:20:07Z'\n      fieldsType: FieldsV1\n      fieldsV1:\n        f:metadata:\n          f:annotations:\n            .: {}\n            f:meta.helm.sh/release-name: {}\n            f:meta.helm.sh/release-namespace: {}\n          f:labels:\n            .: {}\n            f:app: {}\n            f:app.kubernetes.io/component: {}\n            f:app.kubernetes.io/managed-by: {}\n            f:chart: {}\n            f:heritage: {}\n            f:release: {}\n        f:spec:\n          f:progressDeadlineSeconds: {}\n          f:revisionHistoryLimit: {}\n          f:selector: {}\n          f:strategy:\n            f:rollingUpdate:\n              .: {}\n              f:maxSurge: {}\n              f:maxUnavailable: {}\n            f:type: {}\n          f:template:\n            f:metadata:\n              f:labels:\n                .: {}\n                f:app: {}\n                f:app.kubernetes.io/component: {}\n                f:component: {}\n                f:release: {}\n            f:spec:\n              f:containers:\n                k:{\"name\":\"nginx-ingress-controller\"}:\n                  .: {}\n                  f:args: {}\n                  f:env:\n                    .: {}\n                    k:{\"name\":\"POD_NAME\"}:\n                      .: {}\n                      f:name: {}\n                      f:valueFrom:\n                        .: {}\n                        f:fieldRef: {}\n                    k:{\"name\":\"POD_NAMESPACE\"}:\n                      .: {}\n                      f:name: {}\n                      f:valueFrom:\n                        .: {}\n                        f:fieldRef: {}\n                  f:image: {}\n                  f:imagePullPolicy: {}\n                  f:livenessProbe:\n                    .: {}\n                    f:failureThreshold: {}\n                    f:httpGet:\n                      .: {}\n                      f:path: {}\n                      f:port: {}\n                      f:scheme: {}\n                    f:initialDelaySeconds: {}\n                    f:periodSeconds: {}\n                    f:successThreshold: {}\n                    f:timeoutSeconds: {}\n                  f:name: {}\n                  f:ports:\n                    .: {}\n                    k:{\"containerPort\":80,\"protocol\":\"TCP\"}:\n                      .: {}\n                      f:containerPort: {}\n                      f:name: {}\n                      f:protocol: {}\n                    k:{\"containerPort\":443,\"protocol\":\"TCP\"}:\n                      .: {}\n                      f:containerPort: {}\n                      f:name: {}\n                      f:protocol: {}\n                  f:readinessProbe:\n                    .: {}\n                    f:failureThreshold: {}\n                    f:httpGet:\n                      .: {}\n                      f:path: {}\n                      f:port: {}\n                      f:scheme: {}\n                    f:initialDelaySeconds: {}\n                    f:periodSeconds: {}\n                    f:successThreshold: {}\n                    f:timeoutSeconds: {}\n                  f:resources:\n                    .: {}\n                    f:limits: {}\n                    f:requests: {}\n                  f:securityContext:\n                    .: {}\n                    f:allowPrivilegeEscalation: {}\n                    f:capabilities:\n                      .: {}\n                      f:add: {}\n                      f:drop: {}\n                    f:runAsUser: {}\n                  f:terminationMessagePath: {}\n                  f:terminationMessagePolicy: {}\n              f:dnsPolicy: {}\n              f:restartPolicy: {}\n              f:schedulerName: {}\n              f:securityContext: {}\n              f:serviceAccount: {}\n              f:serviceAccountName: {}\n              f:terminationGracePeriodSeconds: {}\n    - manager: kube-controller-manager\n      operation: Update\n      apiVersion: apps/v1\n      time: '2022-01-24T01:23:22Z'\n      fieldsType: FieldsV1\n      fieldsV1:\n        f:status:\n          f:conditions:\n            .: {}\n            k:{\"type\":\"Available\"}:\n              .: {}\n              f:type: {}\n            k:{\"type\":\"Progressing\"}:\n              .: {}\n              f:type: {}\n    - manager: Mozilla\n      operation: Update\n      apiVersion: apps/v1\n      time: '2022-01-28T23:18:41Z'\n      fieldsType: FieldsV1\n      fieldsV1:\n        f:spec:\n          f:template:\n            f:spec:\n              f:containers:\n                k:{\"name\":\"nginx-ingress-controller\"}:\n                  f:resources:\n                    f:limits:\n                      f:cpu: {}\n                      f:memory: {}\n                    f:requests:\n                      f:cpu: {}\n                      f:memory: {}\n    - manager: kube-controller-manager\n      operation: Update\n      apiVersion: apps/v1\n      time: '2022-01-28T23:29:49Z'\n      fieldsType: FieldsV1\n      fieldsV1:\n        f:metadata:\n          f:annotations:\n            f:deployment.kubernetes.io/revision: {}\n        f:status:\n          f:conditions:\n            k:{\"type\":\"Available\"}:\n              f:lastTransitionTime: {}\n              f:lastUpdateTime: {}\n              f:message: {}\n              f:reason: {}\n              f:status: {}\n            k:{\"type\":\"Progressing\"}:\n              f:lastTransitionTime: {}\n              f:lastUpdateTime: {}\n              f:message: {}\n              f:reason: {}\n              f:status: {}\n          f:observedGeneration: {}\n          f:replicas: {}\n          f:unavailableReplicas: {}\n          f:updatedReplicas: {}\n      subresource: status\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx-ingress\n      app.kubernetes.io/component: controller\n      release: nginx-ingress\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app: nginx-ingress\n        app.kubernetes.io/component: controller\n        component: controller\n        release: nginx-ingress\n    spec:\n      containers:\n        - name: nginx-ingress-controller\n          image: us.gcr.io/k8s-artifacts-prod/ingress-nginx/controller:v0.34.1\n          args:\n            - /nginx-ingress-controller\n            - '--default-backend-service=ingress/nginx-ingress-default-backend'\n            - '--election-id=ingress-controller-leader'\n            - '--ingress-class=nginx'\n            - '--configmap=ingress/nginx-ingress-controller'\n          ports:\n            - name: http\n              containerPort: 80\n              protocol: TCP\n            - name: https\n              containerPort: 443\n              protocol: TCP\n          env:\n            - name: POD_NAME\n              valueFrom:\n                fieldRef:\n                  apiVersion: v1\n                  fieldPath: metadata.name\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  apiVersion: v1\n                  fieldPath: metadata.namespace\n          resources:\n            limits:\n              cpu: 300m\n              memory: 512Mi\n            requests:\n              cpu: 200m\n              memory: 256Mi\n          livenessProbe:\n            httpGet:\n              path: /healthz\n              port: 10254\n              scheme: HTTP\n            initialDelaySeconds: 10\n            timeoutSeconds: 1\n            periodSeconds: 10\n            successThreshold: 1\n            failureThreshold: 3\n          readinessProbe:\n            httpGet:\n              path: /healthz\n              port: 10254\n              scheme: HTTP\n            initialDelaySeconds: 10\n            timeoutSeconds: 1\n            periodSeconds: 10\n            successThreshold: 1\n            failureThreshold: 3\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n          imagePullPolicy: IfNotPresent\n          securityContext:\n            capabilities:\n              add:\n                - NET_BIND_SERVICE\n              drop:\n                - ALL\n            runAsUser: 101\n            allowPrivilegeEscalation: true\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 60\n      dnsPolicy: ClusterFirst\n      serviceAccountName: nginx-ingress\n      serviceAccount: nginx-ingress\n      securityContext: {}\n      schedulerName: default-scheduler\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 25%\n      maxSurge: 25%\n  revisionHistoryLimit: 10\n  progressDeadlineSeconds: 600\nstatus:\n  observedGeneration: 16\n  replicas: 3\n  updatedReplicas: 2\n  unavailableReplicas: 3\n  conditions:\n    - type: Available\n      status: 'False'\n      lastUpdateTime: '2022-01-28T22:58:07Z'\n      lastTransitionTime: '2022-01-28T22:58:07Z'\n      reason: MinimumReplicasUnavailable\n      message: Deployment does not have minimum availability.\n    - type: Progressing\n      status: 'False'\n      lastUpdateTime: '2022-01-28T23:29:49Z'\n      lastTransitionTime: '2022-01-28T23:29:49Z'\n      reason: ProgressDeadlineExceeded\n      message: >-\n        ReplicaSet \"nginx-ingress-controller-59d9f94677\" has timed out\n        progressing.\n`\n```",
      "solution": "Kubernetes 1.22 is supported only with NGINX Ingress Controller 1.0.0 and higher = https://github.com/kubernetes/ingress-nginx#supported-versions-table\nYou need tu upgrade your `nginx-ingress-controller` Bitnami Helm Chart to Version 9.0.0 in `Chart.yaml`. Then run a `helm upgrade nginx-ingress-controller bitnami/nginx-ingress-controller`.\nYou should also regularly update specially your ingress controller, as the version v0.34.1 is very very old bcs the ingress is normally the only entry appoint from outside to your cluster.",
      "question_score": 9,
      "answer_score": 12,
      "created_at": "2022-01-29T20:01:20",
      "url": "https://stackoverflow.com/questions/70908774/nginx-ingress-controller-fails-to-start-after-aks-upgrade-to-v1-22"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69231743,
      "title": "Nginx returns 426",
      "problem": "When I am accessing a istio gateway NodePort from the Nginx server using curl, I am getting response properly, like below:\n```\n`curl -v \"http://52.66.195.124:30408/status/200\"\n*   Trying 52.66.195.124:30408...\n* Connected to 52.66.195.124 (52.66.195.124) port 30408 (#0)\n> GET /status/200 HTTP/1.1\n> Host: 52.66.195.124:30408\n> User-Agent: curl/7.76.1\n> Accept: */*\n> \n* Mark bundle as not supporting multiuse\nThe same when I am configuring through Nginx proxy like below, I am getting `HTTP ERROR 426` through the domain.\nNote: my domain is HTTPS - https://dashboard.example.com\n```\n`server {\n        server_name dashboard.example.com;\n        location / {\n               proxy_pass       http://52.66.195.124:30408;\n        }\n}\n`\n```\nCan anyone help me to understand the issue ?",
      "solution": "HTTP 426 error means upgrade required:\n\nThe server refuses to perform the request using the current protocol but might be willing to do so after the client upgrades to a different protocol.\n\nor another info:\n\nThe HTTP `426 Upgrade Required` client error response code indicates that the server refuses to perform the request using the current protocol but might be willing to do so after the client upgrades to a different protocol.\n\nIn your situation, you need to check what version of the HTTP protocol you are using. It seems too low. Look at this thread. In that case, you had to upgrade from `1.0` to `1.1`.\nYou need to upgrade your HTTP protocol version in NGINX config like there:\n\nThis route is for a legacy API, which enabled NGINX cache for performance reason, but in this route's proxy config, it missed a shared config  `proxy_http_version 1.1`, which default to use HTTP 1.0 for all NGINX upstream.\nAnd Envoy will return  `HTTP 426`  if the request is  `HTTP 1.0`.",
      "question_score": 9,
      "answer_score": 11,
      "created_at": "2021-09-18T07:02:41",
      "url": "https://stackoverflow.com/questions/69231743/nginx-returns-426"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66594111,
      "title": "Why does nginx think my root directory is /usr/share/nginx and not /var/www/html as my configuration states?",
      "problem": "I am new to nginx and trying to get the hang of it. I've been reading the docs, and they say if use the directive `root` it should tell nginx where to find requests. For example, from my understanding, `root /var/www/html` should tell nginx to find requests in the directory `/var/www/html`, but my instance of nginx is not doing that. I am trying to load a file in that directory called `test.html`, but instead it is trying to look for the file in `/usr/share/nginx`. Note that this is a pretty fresh install of nginx and I have made few changes to the default config files. I also want to note the path prefix is set to `/usr/share/nginx`, but my understanding is using the `root` directive should override that. I am running Ubuntu 18.04 and installed nginx through apt. Let me know if you need any more information. Thanks!\nnginx.conf - Please note this file has no uncommented root directives\n```\n`user www-data;\nworker_processes auto;\npid /run/nginx.pid;\ninclude /etc/nginx/modules-enabled/*.conf;\n\nevents {\n    worker_connections 768;\n    # multi_accept on;\n}\n\nhttp {\n\n    ##\n    # Basic Settings\n    ##\n\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 65;\n    types_hash_max_size 2048;\n    # server_tokens off;\n\n    # server_names_hash_bucket_size 64;\n    # server_name_in_redirect off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    ##\n    # SSL Settings\n    ##\n\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE\n    ssl_prefer_server_ciphers on;\n\n    ##\n    # Logging Settings\n    ##\n\n    access_log /var/log/nginx/access.log;\n    error_log /var/log/nginx/error.log;\n\n    ##\n    # Gzip Settings\n    ##\n\n    gzip on;\n\n    # gzip_vary on;\n    # gzip_proxied any;\n    # gzip_comp_level 6;\n    # gzip_buffers 16 8k;\n    # gzip_http_version 1.1;\n    # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;\n\n    ##\n    # Virtual Host Configs\n    ##\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*;\n\n    map $http_upgrade $connection_upgrade {\n      default upgrade;\n      ''      close;\n    }\n\n    server {\n      listen 80;\n\n      server_name kramericaindustries.hopto.org;\n      rewrite ^/rstudio$ $scheme://$http_host/rstudio/ permanent;\n\n      location /rstudio/ {\n        rewrite ^/rstudio/(.*)$ /$1 break;\n        proxy_pass http://localhost:8787;\n        proxy_redirect http://localhost:8787/ $scheme://$http_host/rstudio/;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection $connection_upgrade;\n        proxy_read_timeout 20d;\n      }\n\n      location /heatmap/ {\n        proxy_pass http://127.0.0.1:8050;\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n      }\n\n      }\n\n      # location /test/ {\n      #   root /home/grant/test;\n      #   index index.html;\n      # }\n    }\n\n    # server {\n    #   listen 8050;\n\n    #   server_name kramericaindustries.hopto.org;\n\n    #   location /heatmap/ {\n    #     proxy_pass http://127.0.0.1:8050;\n    #     proxy_set_header Host $host;\n    #     proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    #   }\n    #   location /test/ {\n    #   }\n    # }\n\n    # server {\n    #   location /test {\n    #     root /home/grant/www;\n    #   }\n    # }\n}\n\n#mail {\n#   # See sample authentication script at:\n#   # http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript\n#\n#   # auth_http localhost/auth.php;\n#   # pop3_capabilities \"TOP\" \"USER\";\n#   # imap_capabilities \"IMAP4rev1\" \"UIDPLUS\";\n#\n#   server {\n#       listen     localhost:110;\n#       protocol   pop3;\n#       proxy      on;\n#   }\n#\n#   server {\n#       listen     localhost:143;\n#       protocol   imap;\n#       proxy      on;\n#   }\n#}\n`\n```\n/etc/nginx/sites-available/default - Please note this file has been unchanged since I installed it and is where the `root` directive I'm referring to is.\n```\n`##\n# You should look at the following URL's in order to grasp a solid understanding\n# of Nginx configuration files in order to fully unleash the power of Nginx.\n# https://www.nginx.com/resources/wiki/start/\n# https://www.nginx.com/resources/wiki/start/topics/tutorials/config_pitfalls/\n# https://wiki.debian.org/Nginx/DirectoryStructure\n#\n# In most cases, administrators will remove this file from sites-enabled/ and\n# leave it as reference inside of sites-available where it will continue to be\n# updated by the nginx packaging team.\n#\n# This file will automatically load configuration files provided by other\n# applications, such as Drupal or Wordpress. These applications will be made\n# available underneath a path with that package name, such as /drupal8.\n#\n# Please see /usr/share/doc/nginx-doc/examples/ for more detailed examples.\n##\n\n# Default server configuration\n#\nserver {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n\n    # SSL configuration\n    #\n    # listen 443 ssl default_server;\n    # listen [::]:443 ssl default_server;\n    #\n    # Note: You should disable gzip for SSL traffic.\n    # See: https://bugs.debian.org/773332\n    #\n    # Read up on ssl_ciphers to ensure a secure configuration.\n    # See: https://bugs.debian.org/765782\n    #\n    # Self signed certs generated by the ssl-cert package\n    # Don't use them in a production server!\n    #\n    # include snippets/snakeoil.conf;\n\n    root /var/www/html;\n\n    # Add index.php to the list if you are using PHP\n    index index.html index.htm index.nginx-debian.html;\n\n    server_name _;\n\n    location / {\n        # First attempt to serve request as file, then\n        # as directory, then fall back to displaying a 404.\n        try_files $uri $uri/ =404;\n    }\n\n    # pass PHP scripts to FastCGI server\n    #\n    #location ~ \\.php$ {\n    #   include snippets/fastcgi-php.conf;\n    #\n    #   # With php-fpm (or other unix sockets):\n    #   fastcgi_pass unix:/var/run/php/php7.0-fpm.sock;\n    #   # With php-cgi (or other tcp sockets):\n    #   fastcgi_pass 127.0.0.1:9000;\n    #}\n\n    # deny access to .htaccess files, if Apache's document root\n    # concurs with nginx's one\n    #\n    #location ~ /\\.ht {\n    #   deny all;\n    #}\n}\n\n# Virtual Host configuration for example.com\n#\n# You can move that to a different file under sites-available/ and symlink that\n# to sites-enabled/ to enable it.\n#\n#server {\n#   listen 80;\n#   listen [::]:80;\n#\n#   server_name example.com;\n#\n#   root /var/www/example.com;\n#   index index.html;\n#\n#   location / {\n#       try_files $uri $uri/ =404;\n#   }\n#}\n`\n```\nEDIT: There is a soft symlink in `/etc/nginx/sites-enabled/default` which points to `/etc/nginx/sites-available/default`.",
      "solution": "OK I've solved the issue by learning something new about nginx. The problem is the server block for port 80 in `nginx.conf` and `/etc/nginx/sites-enabled/default` were in conflict which I was unaware of. Though `/etc/nginx/sites-enabled/default` is listed as the default server (`listen 80 default_server`), nginx was using the server block in `nginx.conf` because this server block has the server name directive (`server_name kramericaindustries.hopto.org;`) which took precedence over the default_server. (Yes, I was using this domain name for testing.) nginx only uses one server block to fulfill the request.\nBecause the server block in `nginx.conf` did not specify a root, it used the nginx path prefix by default which is `/usr/share/nginx` which does not contain `test.html`. Therefore, the request failed. I added `root /var/www/html;` to `nginx.conf` and everything is now working as expected.",
      "question_score": 9,
      "answer_score": 10,
      "created_at": "2021-03-12T05:16:46",
      "url": "https://stackoverflow.com/questions/66594111/why-does-nginx-think-my-root-directory-is-usr-share-nginx-and-not-var-www-html"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 73596956,
      "title": "nginx &quot;connect() failed (111: Unknown error) while connecting to upstream&quot; error",
      "problem": "I have an nginx server that's giving me an error that I can't find any information on. The server is up and running and I believe the underlying site (a Flask app) is also running, but clients receive a generic 500 error. When I look at `/var/log/nginx/error.log`, I see this:\n```\n`2022/09/04 04:59:52 [error] 1523#1523: *1 connect() failed (111: Unknown error) while connecting to upstream, client: [clients ip], server: mysite.com, request: \"GET / HTTP/1.1\", upstream: \"http://[::1]:8000/\", host: \"mysite.com\"\n`\n```\nI have no idea what to do with this. I've searched around and can't find any info on how to dig in deeper or where to look to resolve the issue.\nHow I got into this state\nI'm running the server on Ubuntu on a Linode and wanted to upgrade the OS. To do so, I spun up a new Linode with the latest version of Ubuntu (22.04) and recreated the server from scratch. After getting everything installed, I swapped the IP addresses of the old and new servers to avoid having to redo the DNS records. I'm using CertBot to manage https certificates, so I ran that again and then restarted everything.\nAt this point, nginx was up and running and happy with my config. Everything looks the same as it did on the old server. But every request is a 500 with the error above.\nAny help / pointers to get me back to a working state is very much appreciated!\nEDIT: nginx config\n```\n`server {\n    server_name = www.mysite.com;\n    return 301 $scheme://mysite.com$request_uri;\n\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/mysite.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/mysite.com/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n}\n\nserver {\n    server_name mysite.com;\n\n    location ^~ /static/ {\n        include /etc/nginx/mime.types;\n        root  /home/my_username/path/to/code/;\n    }\n\n    location / {\n        proxy_pass http://localhost:8000;\n        include /etc/nginx/proxy_params;\n        proxy_redirect off;\n        proxy_read_timeout 300s;\n    }\n\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/mysite.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/mysite.com/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n}\nserver {\n    if ($host = www.mysite.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n    if ($host = mysite.com) {\n        return 301 https://$host$request_uri;\n    } # Manually added by me\n\n    server_name = mysite.com;\n    listen 80;\n    return 404; # managed by Certbot\n}\n`\n```",
      "solution": "Ugh. I was a dummy. It was not an nginx error.\nI misconfigured something in my Flask site, causing it to throw 500 errors. Because of the misconfiguration, they weren't being logged to the right file, so I didn't realize that was the problem. Fixed the Flask config and the server went back to normal.\nPosting my stupidity in case it helps any future searchers who hit the same nginx error.",
      "question_score": 9,
      "answer_score": 6,
      "created_at": "2022-09-04T07:20:46",
      "url": "https://stackoverflow.com/questions/73596956/nginx-connect-failed-111-unknown-error-while-connecting-to-upstream-error"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 72476714,
      "title": "Global load balancer (HTTPS Loadbalancer) in front of GKE Nginx Ingress Controller",
      "problem": "I have a GKE cluster which uses Nginx Ingress Controller as its ingress engine. Currently, when I setup the Nginx Ingress Controller I define a service `kind: LoadBalancer` and point it to an external static IP previously reserved on GCP. The problem with that is it only binds to a regional static IP address (L4 Load Balancer if I'm not mistaken). I want to have a Global Load Balancer instead.\nI know that I can achieve that by using GKE ingress controller instead of Nginx Ingress Controller. But I still want to use Nginx Ingress due to its powerful annotations like rewriting headers based on conditions etc; things not available for GKE Ingress annotations.\nFinally, is there any way to combine a Global Load Balancer with nginx ingress controller or put an Global Load Balancer in front of a L4 Load Balancer created By Nginx?\nWe need to have Global Load Balancer in order to be protected by Cloud Armor.",
      "solution": "I finally managed to make Nginx Ingress Controller and L7 HTTP(S) Load Balancer work together.\nBased on the @rrob repply with his own question I managed to make it work. The only difference is that his solution will install a classic HTTP(S) LoadBalancer, instead of the new version and also I cover the creation of the IP Address, the self-signed Certificate, and the HTTP Proxy redirect from HTTP to HTTPS. I will plcae here the detailed steps that worked for me.\nThis steps assume we already have a Cluster created with `VPC-native traffic routing` enabled.\nBefore the need of the HTTP(S) LoadBalancer, I would just apply the manifests provided by the NGINX DOCS page for the installation of the Nginx Ingress Controller and It would create a service of type `LoadBalancer` which would, then, create a regional L4 LoadBalancer automatically.\nBut now that I need need to have Cloud Armor and WAF, the L4 Loadbalancer doesn't support it. A HTTPS(S) Load Balancer is needed in order for Cloud Armor to work.\nIn order to have Nginx Ingress controller working with the new HTTPS(S) LoadBalancer we need to change the `type: LoadBalancer` on the Nginx Ingress Controller service to `ClusterIP` instead, and add the NEG annotation to it `cloud.google.com/neg: '{\"exposed_ports\": {\"80\":{\"name\": \"ingress-nginx-80-neg\"}}}'`. With this net annotation, GCP will automatically create a Network Endpoint Group that will point to the Nginx Ingress Controller service running in GKE. This Network Endpoint Group will serve as the backend of our HTTPS Load Balancer.\n\nNOTE: When using the cloud.google.com/neg annotation, GCP will create one Network Endpoint Group for each region containing nodes with Nginx Ingress Controller pods. For exmple, if you set your NodePool to spread across us-central1-a, us-central1-b and us-central1-f, GCP will create three Network Endpoint Groups if you have one Ingress Controller replica in each node. So when you set the Load Balancer's back end, you need to add all of them as backends as It's explained in STEP 5.\n\n```\n`apiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n  labels:\n    helm.sh/chart: ingress-nginx-4.0.15\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/version: 1.1.1\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/component: controller\n  name: ingress-nginx-controller\n  namespace: ingress-nginx\n  annotations:\n    cloud.google.com/neg: '{\"exposed_ports\": {\"80\":{\"name\": \"ingress-nginx-80-neg\"}}}'\nspec:\n  type: ClusterIP\n  ipFamilyPolicy: SingleStack\n  ipFamilies:\n    - IPv4\n  ports:\n    - name: http\n      port: 80\n      protocol: TCP\n      targetPort: http\n      appProtocol: http\n    - name: https\n      port: 443\n      protocol: TCP\n      targetPort: https\n      appProtocol: https\n  selector:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/component: controller\n`\n```\n\nIf you install the Nginx Ingress Controller using HELM you need to overwrite the config to add the NEG annotation to the service. So the `values.yaml` would look something like this:\n\n```\n`controller:\n  service:\n    type: ClusterIP\n    annotations:\n      cloud.google.com/neg: '{\"exposed_ports\": {\"80\":{\"name\": \"ingress-nginx-80-neg\"}}}'\n`\n```\nTo install it, add the ingress-nginx to the helm repository:\n```\n`helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\nhelm repo update\n`\n```\nThen install it:\n```\n`helm install -f values.yaml ingress-nginx ingress-nginx/ingress-nginx\n`\n```\nThe next steps will be:\n```\n`PROJECT_ID=\nZONE=us-central1-a\nCLUSTER_NAME=\nHEALTH_CHECK_NAME=nginx-ingress-controller-health-check\nNETWORK_NAME=\nCERTIFICATE_NAME=self-managed-exp---\nGKE_NODE_METADATA=$(kubectl get nodes -o jsonpath='{.items[0].metadata}')\nGKE_SAMPLE_NODE_NAME=$(echo $GKE_NODE_METADATA | jq -r .name)\nGKE_SAMPLE_NODE_ZONE=$(echo $GKE_NODE_METADATA | jq -r .labels | jq -r '.\"topology.kubernetes.io/zone\"')\nNETWORK_TAGS=$(gcloud compute instances describe \\\n    $GKE_SAMPLE_NODE_NAME --project $PROJECT_ID \\\n    --zone=$GKE_SAMPLE_NODE_ZONE --format=\"value(tags.items[0])\")\n`\n```\n\nCreate an Static IP Address (skip if you already have):\n\nHas to be Premium tier and Global\n\n```\n`gcloud compute addresses create ${CLUSTER_NAME}-loadbalancer-ip \\\n    --global \\\n    --ip-version IPV4\n`\n```\n\nCreate a Firewall rule allowing the L7 HTTP(S) Load Balancer to access our cluster\n\n```\n`gcloud compute firewall-rules create ${CLUSTER_NAME}-allow-tcp-loadbalancer \\\n    --allow tcp:80 \\\n    --source-ranges 130.211.0.0/22,35.191.0.0/16 \\\n    --target-tags $NETWORK_TAGS \\\n    --network $NETWORK_NAME\n`\n```\n\nCreate a Health Check for our to-be-created Backend Service\n\n```\n`gcloud compute health-checks create http ${CLUSTER_NAME}-nginx-health-check \\\n  --port 80 \\\n  --check-interval 60 \\\n  --unhealthy-threshold 3 \\\n  --healthy-threshold 1 \\\n  --timeout 5 \\\n  --request-path /healthz\n`\n```\n\nCreate a Backend Service which is used to inform the LoadBalancer how to connect and distribute trafic to the pods.\n\n```\n`gcloud compute backend-services create ${CLUSTER_NAME}-backend-service \\\n    --load-balancing-scheme=EXTERNAL \\\n    --protocol=HTTP \\\n    --port-name=http \\\n    --health-checks=${CLUSTER_NAME}-nginx-health-check \\\n    --global\n`\n```\n\nNow it's the time we add the Nginx NEG service (the one annotated earlier) to the back end service created on the previous step:\n\nAs explained earlier, a Network Endpoint Group will be created for each zone that contains Nginx Ingress Controller pods. So the current layout of my setup is:\n```\n`a. **Node Pool** configured to span across **us-central1-a** and **us-central1-c**.\nb. **Nginx Ingress Controller** configured to have 4 replicas.\nc. **Node 1** in **us-central1-a** will have 2 replicas.\nd. **Node 2** in **us-central1-c** will have 2 replicas.\ne. GCP generated two Network Endpoint Groups. One for **us-central1-a** and other for **us-central1-c**.\n`\n```\nSo for the example bellow, I bind the two NEGs for each zone, as backend services to my Load Balancer.\n```\n`# us-central1-a\ngcloud compute backend-services add-backend ${CLUSTER_NAME}-backend-service \\\n  --network-endpoint-group=ingress-nginx-80-neg \\\n  --network-endpoint-group-zone=us-central1-a \\\n  --balancing-mode=RATE \\\n  --capacity-scaler=1.0 \\\n  --max-rate-per-endpoint=100 \\\n  --global\n\n# us-central1-c\ngcloud compute backend-services add-backend ${CLUSTER_NAME}-backend-service \\\n  --network-endpoint-group=ingress-nginx-80-neg \\\n  --network-endpoint-group-zone=us-central1-c \\\n  --balancing-mode=RATE \\\n  --capacity-scaler=1.0 \\\n  --max-rate-per-endpoint=100 \\\n  --global\n  \n`\n```\n\nCreate the load balancer itself (URL MAPS)\n\n```\n`gcloud compute url-maps create ${CLUSTER_NAME}-loadbalancer \\\n    --default-service ${CLUSTER_NAME}-backend-service\n\n`\n```\n\nCreate a Self Managed Certificate (it may be a Google-managed certificate but here we will cover the self-managed). Can also create from Console HERE.\n\n```\n`gcloud compute ssl-certificates create $CERTIFICATE_NAME \\\n    --certificate=my-cert.pem \\\n    --private-key=my-privkey.pem \\\n    --global\n`\n```\nFinally, I will setup the Loadbalancer frontend through the Console interface which is way easier.\n\nTo create the LoadBalancer front end, enter the Loadbalancer on Console and click on \"Edit\".\n\nThe Frontend configuration tab will be incomplete. Go there \n\nClick on \"ADD FRONTEND IP AND PORT\"\n\nGive it a name and select HTTPS on the field Protocol.\n\nOn IP Address change from Ephemeral to your previously allocated static IP\n\nSelect your certificate and mark Enable HTTP to HTTPS redirect if you want. (I did)\n\nSave the LoadBalancer.\nThe entering the LoadBalancer page we should see our nginx instance(s) healthy and green. In my case I've setup the Nginx Ingress Controller to have 4 replicas:\n\nFinally, we just need to point our domains to the LoadBalancer IP and create our Ingress file.\n\nNOTE: The Ingress now won't handle the certificate. The certificate will now be managed by the LoadBalancer externally. So the Ingress won't have the tls definition:\n\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/upstream-fail-timeout: \"1200\"\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      set $http_origin \"${scheme}://${host}\";\n      more_set_headers \"server: hide\";\n      more_set_headers \"X-Content-Type-Options: nosniff\";\n      more_set_headers \"Referrer-Policy: strict-origin\";\n  name: ingress-nginx\n  namespace: prod\n\nspec:\n  rules:\n  - host: app.mydomain.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: frontend\n            port:\n              number: 80\n`\n```",
      "question_score": 9,
      "answer_score": 8,
      "created_at": "2022-06-02T15:00:43",
      "url": "https://stackoverflow.com/questions/72476714/global-load-balancer-https-loadbalancer-in-front-of-gke-nginx-ingress-controll"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69753332,
      "title": "Running Nginx Docker with SSL self signed certificate",
      "problem": "I am trying to run a UI application with Docker using nginx image I am able to access the service on port 80 without any problem but whenever I am trying access it via https on 443 port I am not able to access the applications the site keeps loading and eventually results in not accessible I have updated the nginx.conf file in default.conf to allow access over port 443\nFollowing is my nginx.conf\n```\n`charset utf-8;\n\nserver {\n    listen 80;\n    server_name localhost;\n    root /usr/nginx/html;\n}\n\nserver {\n    listen 443;\n    server_name localhost;\n    root /usr/nginx/html; \n}\n`\n```\nI have added the SSL self-signed certificate in the /usr/nginx folder and exposed port 443 via Dockerfile\nThe following is my Dockerfile\n```\n`FROM nginx\n\nCOPY dist /usr/nginx/html\nRUN chmod -R 777 /usr/nginx/html/*\n\nCOPY nginx.conf /etc/nginx/conf.d/default.conf\nCOPY domain.crt /usr/nginx\n\nEXPOSE 80:443\nENTRYPOINT nginx -g 'daemon off;'\n`\n```\nCan anyone please explain me is port 443 not allowing any access",
      "solution": "For nginx server to allow SSL encryption you need to provide ssl flag while listening in nginx.conf\nand only ssl certificate will not be sufficient, you will need the ssl certificate key and password as well and they must be configured.\n```\n`charset utf-8;\n\nserver {\n    listen 80;\n    server_name localhost;\n    root /usr/share/nginx/html;\n}\n\nserver {\n    listen 443 ssl;\n    ssl_certificate /usr/nginx/ssl.crt;\n    ssl_certificate_key /usr/nginx/ssl.key;\n    ssl_password_file /usr/nginx/ssl.pass;\n    server_name localhost;\n    root /usr/nginx/html;\n}\n`\n```\nAnd you need to put the ssl certificate, key and password via volumes or via embedding in docker container. If you are running container over kubernetes cluster, adding them via kubernetes secrets will be better option.\nFor Dockerfile you can add like\n```\n`FROM nginx\n\nCOPY dist /usr/nginx/html\nRUN chmod -R 777 /usr/nginx/html/*\n\nCOPY nginx.conf /etc/nginx/conf.d/default.conf\nCOPY ssl.crt /usr/nginx/\nCOPY ssl.pass /usr/nginx/\nCOPY ssl.key /usr/nginx/\n\nEXPOSE 80:443\nENTRYPOINT nginx -g 'daemon off;'\n`\n```\nFor further info you can refer the Nginx Docker article https://medium.com/@agusnavce/nginx-server-with-ssl-certificates-with-lets-encrypt-in-docker-670caefc2e31",
      "question_score": 9,
      "answer_score": 8,
      "created_at": "2021-10-28T13:32:20",
      "url": "https://stackoverflow.com/questions/69753332/running-nginx-docker-with-ssl-self-signed-certificate"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69968072,
      "title": "Can I use Nginx Certbot to put ssl in an aws default ec2 domain?",
      "problem": "I tried to put the command to get the certificate but it gave me this error:\nAn unexpected error occurred:\nThe server will not issue certificates for the identifier :: Error creating new order :: Cannot issue for \"ec2-34-237-242-160.compute-1.amazonaws.com\": The ACME server refuses to issue a certificate for this domain name, because it is forbidden by policy",
      "solution": "Let's Encrypt blocks Amazon AWS domains because the domain names are transient and are subject to change.\nhttps://community.letsencrypt.org/t/policy-forbids-issuing-for-name-on-amazon-ec2-domain/12692/4",
      "question_score": 9,
      "answer_score": 4,
      "created_at": "2021-11-15T00:38:19",
      "url": "https://stackoverflow.com/questions/69968072/can-i-use-nginx-certbot-to-put-ssl-in-an-aws-default-ec2-domain"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 68636725,
      "title": "Docker Error response from daemon: OCI runtime create failed container_linux.go:380: starting container process caused",
      "problem": "I have this error after running this command in PowerShell\n`docker-compose up`\nMy Docker Version\n`Docker version 20.10.7, build f0df350`\nMy Docker Info\n```\n`Client:\n Context:    default\n Debug Mode: false\n Plugins:\n  buildx: Build with BuildKit (Docker Inc., v0.5.1-docker)\n  compose: Docker Compose (Docker Inc., v2.0.0-beta.6)\n  scan: Docker Scan (Docker Inc., v0.8.0)\n\nServer:\n Containers: 0\n  Running: 0\n  Paused: 0\n  Stopped: 0\n Images: 0\n Server Version: 20.10.7\n Storage Driver: overlay2\n  Backing Filesystem: extfs\n  Supports d_type: true\n  Native Overlay Diff: true\n  userxattr: false\n Logging Driver: json-file\n Cgroup Driver: cgroupfs\n Cgroup Version: 1\n Plugins:\n  Volume: local\n  Network: bridge host ipvlan macvlan null overlay\n  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog\n Swarm: inactive\n Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc\n Default Runtime: runc\n Init Binary: docker-init\n containerd version: d71fcd7d8303cbf684402823e425e9dd2e99285d\n runc version: b9ee9c6314599f1b4a7f497e1f1f856fe433d3b7\n init version: de40ad0\n Security Options:\n  seccomp\n   Profile: default\n Kernel Version: 5.10.16.3-microsoft-standard-WSL2\n Operating System: Docker Desktop\n OSType: linux\n Architecture: x86_64\n CPUs: 12\n Total Memory: 12.43GiB\n Name: docker-desktop\n ID: 65YS:IH5I:4VI6:ZBXX:SB7J:NAR5:OSHP:OQ3S:ZGHX:653Z:KSFS:3CKX\n Docker Root Dir: /var/lib/docker\n Debug Mode: false\n Registry: https://index.docker.io/v1/\n Labels:\n Experimental: false\n Insecure Registries:\n  127.0.0.0/8\n Live Restore Enabled: false\n\nWARNING: No blkio throttle.read_bps_device support\nWARNING: No blkio throttle.write_bps_device support\nWARNING: No blkio throttle.read_iops_device support\nWARNING: No blkio throttle.write_iops_device support\n`\n```\nError\n```\n`[+] Running 5/6\n - Network project_default          Created                                                                        0.7s\n - Volume \"project_mongo-db\"        Created                                                                        0.0s\n - Container project_mongo_1        Started                                                                       12.4s\n - Container project_node-app_1     Starting                                                                      12.9s\n - Container project_react-app_1    Created                                                                        8.9s\n - Container project_nginx-proxy_1  Created                                                                        0.1s\nError response from daemon: OCI runtime create failed: container_linux.go:380: starting container process caused: process_linux.go:545: container init caused: rootfs_linux.go:76: mounting \"/var/lib/docker/volumes/4b1671442c7499623e352a827a29d54b514fd4f186b937181a90ab497d12995c/_data\" to rootfs at \"/usr/src/server/node_modules\" caused: mkdir /var/lib/docker/overlay2/c11386ffc7cd58452b395472bb289e20df441f5b59e1082d6d055de466b81a4e/merged/usr/src/server/node_modules: read-only file system: unknown\n`\n```\nThis project I get from my friend. My friend didn't have Dockerfile in project folder but have just:\n\nSo I find so many tutorials and I find how to use docker-compose. It's like going well but I have this error. I find this error in google but no one can help me even in the StackOverflow. Thanks For Helping!!! :)\ndocker-compose.yml:\n```\n`version: '3.4'\n\nservices:\n    nginx-proxy:\n        restart: always\n        build:\n            context: ./\n            dockerfile: ./nginx-proxy/Dockerfile\n        ports:\n            - '${NGINX_PROXY_PORT}:${NGINX_PROXY_PORT}'\n        environment:\n            - NGINX_LE_PLACEHOLDER_1=${PORT}\n            - NGINX_LE_PLACEHOLDER_2=${SERVER_PORT}\n            - NGINX_LE_PLACEHOLDER_3=${NGINX_PROXY_PORT}\n            - NGINX_LE_TZ\n        depends_on:\n            - node-app\n            - react-app\n\n    react-app:\n        build:\n            context: ./\n            dockerfile: ./client/Dockerfile\n        volumes: \n            - ./client:/usr/src/client:ro\n            - /usr/src/client/node_modules\n        depends_on: \n            - node-app\n        environment: \n            - NODE_ENV=development\n            - CHOKIDAR_USEPOLLING=true\n        ports:\n            - '${PORT}:${PORT}'\n  \n    node-app:\n        build: \n            context: ./\n            dockerfile: ./server/Dockerfile\n        volumes:\n            - ./server:/usr/src/server:ro\n            - /usr/src/server/node_modules\n        environment:\n            - NODE_ENV=development\n        env_file:\n            - ./.env\n        ports:\n            - '${SERVER_PORT}:${SERVER_PORT}'\n        depends_on:\n            - mongo\n  \n    mongo:\n        image: mongo:latest\n        volumes:\n            - mongo-db:/data/db\n        ports: \n            - \"27017:27017\"\n        environment: \n            - MONGO_INITDB_ROOT_USERNAME=\n            - MONGO_INITDB_ROOT_PASSWORD=\nvolumes:\n    mongo-db:\n`\n```\nReact Project Dockerfile (client):\n```\n`FROM node:16-alpine3.11\n\nRUN apk add --update git\nWORKDIR /usr/src/client\nENV PATH /usr/src/client/node_modules/.bin:$PATH\n\nCOPY ./client/package.json ./\nRUN npm install --legacy-peer-deps --silent\n\nCOPY ./client ./\n\nCMD [ \"npm\", \"start\" ]\n`\n```\nnginx proxy folder Docker:\n```\n`FROM 0x8861/nginx-le:v2.0.0\nCOPY ./nginx-proxy/templates/no-ssl.service.conf.dev /etc/nginx/no-ssl.service.conf\n`\n```\nNode.js App Dockerfile (server):\n```\n`FROM node:lts-buster\nWORKDIR /usr/src/server\nCOPY ./server/package*.json ./\nRUN npm install\nCOPY ./.env ../.env\nCMD [\"npm\", \"run\", \"dev\"]\n`\n```\nMy Dockerfile Name:\n\nThanks again to those who can help! :)\nand if this is duplicate am so sorry but I can't find how to fix it thanks again :)\nAnother thing I tried doing it by a single project folder it can but have another error. and my friend suggest using docker-compose.",
      "solution": "It looks like you're trying to replace the application code in the image with different code using Docker bind mounts.  Docker's general model is that a container runs a self-contained image; you shouldn't need to separately install the application code on the host.\nIn particular, these two `volumes:` blocks cause the error you're seeing, and can safely be removed:\n`services:\n  react-app:\n    build:             # \nMechanically, the first `volumes:` line replaces the image's code with different code from the host, but with a read-only mount.  The second `volumes:` line then further tries to replace the `node_modules` directory with an old copy from an anonymous volume.  This will create the `node_modules` directory if it doesn't exist yet; but the parent directory is a read-only volume mount, resulting in the error you're seeing.",
      "question_score": 9,
      "answer_score": 7,
      "created_at": "2021-08-03T15:13:09",
      "url": "https://stackoverflow.com/questions/68636725/docker-error-response-from-daemon-oci-runtime-create-failed-container-linux-go"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67049573,
      "title": "Could not find a usable &#39;nginx&#39; binary. Ensure nginx exists, the binary is executable",
      "problem": "I'm trying to install certbot on my digital ocean droplet. I'm using ubuntu 20.04 and following instructions from https://certbot.eff.org/lets-encrypt/ubuntufocal-nginx.\nThe error occurs when I run `sudo certbot --nginx`. The error I get is:\n```\n`The nginx plugin is not working; there may be problems with your existing configuration.\nThe error was: NoInstallationError(\"Could not find a usable 'nginx' binary. \nEnsure nginx exists, the binary is executable, and your PATH is set correctly.\")\n`\n```\nThis is my first time using digital ocean and such so please explain the solution. Thank you.",
      "solution": "you can use options to specify the path to the 'nginx' binary and conf directory (it seems that certbot expects `nginx.conf` file in nginx's installation directory if you do not specify it manually)\n```\n`certbot certonly --nginx --nginx-ctl /usr/local/openresty/nginx/sbin/nginx --nginx-server-root /usr/local/openresty/nginx/conf\n`\n```",
      "question_score": 8,
      "answer_score": 16,
      "created_at": "2021-04-11T21:53:49",
      "url": "https://stackoverflow.com/questions/67049573/could-not-find-a-usable-nginx-binary-ensure-nginx-exists-the-binary-is-execu"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66720740,
      "title": "Homestead and NGINX error: emerg] invalid number of arguments in &quot;proxy_set_header&quot;",
      "problem": "I'm trying to add a location block to the default config of NGINX. I've duplicated the homestead/scripts/site-types/laravel.sh and added the code block below:\n```\n`location ^~ /mysocket {\n    #your proxy directives\n    proxy_pass https://127.0.0.1:1234;\n    proxy_redirect off;\n    proxy_ssl_session_reuse on;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forward-For $proxy_add_x_forwarded_for;\n    proxy_set_header Host $http_host;\n    proxy_set_header X-NginX-Proxy false;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n}\n`\n```\nAs result:\n```\n`nginx: [emerg] invalid number of arguments in \"proxy_set_header\" directive\n`\n```\nWhole code:\n```\n`#!/usr/bin/env bash\n\ndeclare -A params=$6       # Create an associative array\ndeclare -A headers=${9}    # Create an associative array\ndeclare -A rewrites=${10}  # Create an associative array\nparamsTXT=\"\"\nif [ -n \"$6\" ]; then\n   for element in \"${!params[@]}\"\n   do\n      paramsTXT=\"${paramsTXT}\n      fastcgi_param ${element} ${params[$element]};\"\n   done\nfi\nheadersTXT=\"\"\nif [ -n \"${9}\" ]; then\n   for element in \"${!headers[@]}\"\n   do\n      headersTXT=\"${headersTXT}\n      add_header ${element} ${headers[$element]};\"\n   done\nfi\nrewritesTXT=\"\"\nif [ -n \"${10}\" ]; then\n   for element in \"${!rewrites[@]}\"\n   do\n      rewritesTXT=\"${rewritesTXT}\n      location ~ ${element} { if (!-f \\$request_filename) { return 301 ${rewrites[$element]}; } }\"\n   done\nfi\n\nif [ \"$7\" = \"true\" ]\nthen configureXhgui=\"\nlocation /xhgui {\n        try_files \\$uri \\$uri/ /xhgui/index.php?\\$args;\n}\n\"\nelse configureXhgui=\"\"\nfi\n\nblock=\"server {\n    listen ${3:-80};\n    listen ${4:-443} ssl http2;\n    server_name .$1;\n    root \\\"$2\\\";\n\n    index index.html index.htm index.php;\n\n    charset utf-8;\n\n    $rewritesTXT\n    \n    location / {\n        try_files \\$uri \\$uri/ /index.php?\\$query_string;\n        $headersTXT\n    }\n\n    location ^~ /mysocket {\n        #your proxy directives\n        proxy_pass https://127.0.0.1:1234;\n        proxy_redirect off;\n        proxy_ssl_session_reuse on;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forward-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $http_host;\n        proxy_set_header X-NginX-Proxy false;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection upgrade;\n    }\n    \n    $configureXhgui\n\n    location = /favicon.ico { access_log off; log_not_found off; }\n    location = /robots.txt  { access_log off; log_not_found off; }\n\n    access_log off;\n    error_log  /var/log/nginx/$1-error.log error;\n\n    sendfile off;\n\n    location ~ \\.php$ {\n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n        fastcgi_pass unix:/var/run/php/php$5-fpm.sock;\n        fastcgi_index index.php;\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME \\$document_root\\$fastcgi_script_name;\n        $paramsTXT\n\n        fastcgi_intercept_errors off;\n        fastcgi_buffer_size 16k;\n        fastcgi_buffers 4 16k;\n        fastcgi_connect_timeout 300;\n        fastcgi_send_timeout 300;\n        fastcgi_read_timeout 300;\n    }\n\n    location ~ /\\.ht {\n        deny all;\n    }\n\n    ssl_certificate     /etc/nginx/ssl/$1.crt;\n    ssl_certificate_key /etc/nginx/ssl/$1.key;\n}\n\"\n\necho \"$block\" > \"/etc/nginx/sites-available/$1\"\nln -fs \"/etc/nginx/sites-available/$1\" \"/etc/nginx/sites-enabled/$1\"\n\n`\n```\nCan someone spot the error I'm making? When I remove the the 'location' block the code is working fine. This code is also running on a live server without any problemen.",
      "solution": "The problem was that I did not escape the variables inside the new block.\n```\n`location ^~ /mysocket {\n    #your proxy directives\n    proxy_pass https://127.0.0.1:1234;\n    proxy_redirect off;\n    proxy_ssl_session_reuse on;\n    proxy_set_header X-Real-IP \\$remote_addr;\n    proxy_set_header X-Forward-For \\$proxy_add_x_forwarded_for;\n    proxy_set_header Host \\$http_host;\n    proxy_set_header X-NginX-Proxy false;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade \\$http_upgrade;\n    proxy_set_header Connection upgrade;\n}\n`\n```",
      "question_score": 8,
      "answer_score": 15,
      "created_at": "2021-03-20T11:53:53",
      "url": "https://stackoverflow.com/questions/66720740/homestead-and-nginx-error-emerg-invalid-number-of-arguments-in-proxy-set-head"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66769510,
      "title": "Blazor WASM styling missing when hosted in docker using nginx",
      "problem": "I have a strange issue, where my styling is broken when I try to host my blazor WASM project using Nginx. I tried to follow a couple of different guides and they were similar and had same issue for me.\nI have the code here: https://github.com/TopSwagCode/Dotnet.IdentityServer/tree/master/src/BlazorClient\nWhen I debug locally or publish locally and serve from dotnet serve I get the following:\n\nBut when I publish and try to run it within docker using Nginx I get this:\n\nMy buttons are still there, but I can't see them since they are white.\nMy dockerfile is pretty simple:\n```\n`FROM mcr.microsoft.com/dotnet/sdk:5.0 AS build-env\nWORKDIR /app\nCOPY . ./\nRUN dotnet publish -c Release -o output\nFROM nginx:alpine\nWORKDIR /var/www/web\nCOPY --from=build-env /app/output/wwwroot .\nCOPY nginx.conf /etc/nginx/nginx.conf\nEXPOSE 80\n`\n```\nMy nginx config\n```\n`events { }\nhttp {\n    include mime.types;\n    types {\n        application/wasm wasm;\n    }\n\n    server {\n        listen 80;\n\n        # Here, we set the location for Nginx to serve the files\n        # by looking for index.html\n        location / {\n            root /var/www/web;\n            try_files $uri $uri/ /index.html =404;\n        }\n    }\n}\n`\n```\nI can't find any \"not found\" or similar in network tab.\nEdit:\nWhen comparing both running side by side, I was not able to find CSS for linear-gradient, which is the purple side of the menu. Digging a bit deeper, it seems all CSS in MainLayout.razor.css was not being found.\nhttps://github.com/TopSwagCode/Dotnet.IdentityServer/blob/master/src/BlazorClient/Shared/MainLayout.razor.css\nWhen running locally:\n\nWhen running using Docker+Nginx\n\nSo seems to me, the CSS is missing somehow???\nEdit 2:\nThe build hash for CSS seems to not match after deploy.\nSo I found the CSS file linked on my Page to be like the following:\n\nBut my HTML doesn't match that. It looks like this:\n\nDon't know how that can break during build and deploy for Docker+Nginx??? Is there something I am doing wrong in my dockerfile???",
      "solution": "After way to long time spending debugging this issue, I finally got it working.\nI found this project: https://github.com/waelkdouh/DockerizedClientSideBlazor/ and started comparing. Only thing different I could see, what he had a .dockerignore\nI made a copy of it and it all started working. Have no idea what was the issue. Can't see how any of the files listed could break the CSS.....",
      "question_score": 8,
      "answer_score": 4,
      "created_at": "2021-03-23T19:50:47",
      "url": "https://stackoverflow.com/questions/66769510/blazor-wasm-styling-missing-when-hosted-in-docker-using-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69322032,
      "title": "AWS App Runner &quot;Create Failed&quot; on health check",
      "problem": "I'm creating my first app on AWS App Runner. I have a simple nginx Docker image that works locally by serving html on localhost:8080.\nWhen I try to deploy it, the result is \"Create Failed\". Upon digging into the CloudWatch logs, I see that the health check failed. The health check is configured to ping the root of the service \"/\" at port 8080.",
      "solution": "I was able to resolve this by deleting my App Runner app (this is currently the only way to change the configuration-- see this issue), then creating a new one and specifying the health check to ping port 80.",
      "question_score": 8,
      "answer_score": 4,
      "created_at": "2021-09-25T01:42:20",
      "url": "https://stackoverflow.com/questions/69322032/aws-app-runner-create-failed-on-health-check"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66592057,
      "title": "How to correct configuration for firewalld and docker/nginx?",
      "problem": "I have a CentOS 7 server which was running happily for 600+ days until it was rebooted recently, after which incoming web requests were receiving HTTP523 (Origin Is Unreachable) error codes (via Cloudflare, if that makes a difference?) unless I stopped the `firewalld` service. Things run fine without `firewalld`, but I'd rather not leave it disabled!\nI've tried stopping `docker` and `firewalld` and restarting them in various sequences, but the same `523` error occurs unless I stop `firewalld`.\n`/var/log/firewalld` contains a few warnings that might help:\n\n`WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -D FORWARD -i br-8acb606a3b50 -o br-8acb606a3b50 -j DROP' failed: iptables: Bad rule (does a matching rule exist in that chain?).`\n`WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -D FORWARD -i docker0 -o docker0 -j DROP' failed: iptables: Bad rule (does a matching rule exist in that chain?).`\n`WARNING: AllowZoneDrifting is enabled. This is considered a n insecure configuration option. It will be removed in a future release. Please consider disabling it now.`\n`WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t nat -D PREROUTING -m addrtype --dst-type LOCAL -j DOCKER' failed: iptables v1.4.21: Couldn't load target 'DOCKER':No such file or directory`\n`WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t nat -D PREROUTING' failed: iptables: Bad rule (does a matching rule exist in that chain?).`\n`WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t nat -D OUTPUT' failed: iptables: Bad rule (does a matching rule exist in that chain?)`\n`WARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -t nat -F DOCKER' failed: iptables: No chain/target/match by that name.`\n\nI've found seemingly conflicting advice around the place regarding any manual configuration/commands required:\n\n`firewall-cmd --permanent --zone=trusted --add-interface=docker0` on a CentOS forum\n`firewall-cmd --zone=trusted --remove-interface=docker0 --permanent` on the offical Docker docs -- surely that's the opposite of the above?\na bunch of manual `firewall-cmd` commands on a Docker github issue -- surely all of that isn't required?\nthis one looks promising -- `nmcli`, `NetworkManager` and `firewall-cmd --permanent --zone=trusted --change-interface=docker0`\n\nI don't fully understand where the `br-8acb606a3b50` interface comes from, or whether I need to do anything to configure it as well as `docker0` if I use a solution like `4.` above? It was all working fine automatically for years until the reboot!\nAre some magic `firewalld` incantations now required (and why?!) or is there some way I can get the system to get back into the correct auto/default configuration it was in prior to rebooting?\n```\n`$ docker -v\nDocker version 20.10.5, build 55c4c88\n$ firewall-cmd --version\n0.6.3\n$ firewall-cmd --get-zones\nblock dmz docker drop external home internal public trusted work\n`\n```",
      "solution": "To recap the chat investigation, this particular problem wasn't related to Docker and containers. The problem was in `firewalld` not having rules for `NGINX` running as a proxy for containers on the host. The solution was to add permanent firewalld rules for HTTP and HTTPS traffic:\n```\n`sudo firewall-cmd --permanent --zone=public --add-service=http\nsudo firewall-cmd --permanent --zone=public --add-service=https\nsudo firewall-cmd --reload\n`\n```\nWarning messages like this one:\n\nWARNING: COMMAND_FAILED: '/usr/sbin/iptables -w10 -D FORWARD -i br-8acb606a3b50 -o br-8acb606a3b50 -j DROP' failed: iptables: Bad rule (does a matching rule exist in that chain?)\n\n... can appear during normal operation, when Docker attempts to delete a rule without checking its existence first. In other words, containers can be running smoothly even when there are warnings like this.",
      "question_score": 8,
      "answer_score": 9,
      "created_at": "2021-03-12T00:29:19",
      "url": "https://stackoverflow.com/questions/66592057/how-to-correct-configuration-for-firewalld-and-docker-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66904585,
      "title": "nginx reverse proxy cookie forwarding",
      "problem": "i have 3 heroku apps\n\nfrontend react\nbackend node\nreverse-proxy nginx\n\ncalls to reverse-proxy/api/?(.*) are frowarded to backend\nrest all calls to reverse-proxy are forwarded to frontend\n\nthe `/etc/nginx/conf.d/default.conf` code\n```\n`upstream frontend {\n    server $FRONTEND_URL;\n}\n\nupstream backend {\n    server $BACKEND_URL;\n}\n\nserver {\n    listen $PORT;\n\n    location / {\n        proxy_pass http://frontend;\n        proxy_set_header Host $FRONTEND_URL;\n    }\n\n    location /api {\n        rewrite /api/(.*) /$1 break;\n        proxy_pass http://backend;\n        proxy_set_header Host $BACKEND_URL;\n    }\n\n}\n`\n```\n\nissue\ni am using cookie for authentication but the cookie being set by backend is not being 'forwarded'\nmy code\n\nnow it works, changes i made:\n\nchanging to `secure: false` in my node app did it for me (will add tls certificate later maybe)\nsuggested fix by @mariolu\n\nnow it looks like\n```\n`location /api {\n    rewrite /api/(.*) /$1 break;\n    proxy_pass http://backend;\n    proxy_set_header Host $BACKEND_URL;\n    proxy_set_header Cookie $http_cookie;\n}\n`\n```\n\n`app.set(\"trust proxy\", true);`",
      "solution": "You need add\n```\n`proxy_set_header Cookie $http_cookie;\n`\n```\nin location config.\nVariable $http_cookie is user request cookie.",
      "question_score": 8,
      "answer_score": 9,
      "created_at": "2021-04-01T14:33:29",
      "url": "https://stackoverflow.com/questions/66904585/nginx-reverse-proxy-cookie-forwarding"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69148955,
      "title": "react-router + nginx ingress refresh causes white screen when path is not &quot;/&quot;",
      "problem": "So I've been trying to fix this for days now and I'm beyond stuck.\nMy app is running, and I can access the site when I go to the default url (example.com). I can refresh on this url without issues, and I can navigate through the pages being rendered through react router as long as I don't refresh on any other page. (e.g.) refreshing on example.com/path1 doesn't work, I get a 404 error.\nMy current ingress file looks like:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myApp-ingress\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\nspec:\n  tls:\n    - hosts:\n        - my.app.com\n      secretName: myApp-tls\n  rules:\n    - host: \"my.app.com\"\n      http:\n        paths:\n          - pathType: Prefix\n            path: /.*\n            backend:\n              service:\n                name: myApp\n                port:\n                  number: 80\n`\n```\nI've added many of the most common replies to issues such as this, but it only makes matters worse, such as white screen with \"Unexpected token '\nFor example, I've tried:\n```\n`    nginx.ingress.kubernetes.io/rewrite-target: /\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      try_files $uri $uri/ /index.html;\n`\n```\nI've tried adding additional paths to the controller for each route available in the app, I've tried setting the path to just \"/\" or \"/(.*)\", nothing is working.\nAny help would be greatly appreciated! thank you!\nEDIT:\n```\n`# latest active node image\nFROM node:14-alpine\n\n# Create app directory\nRUN mkdir /app\nRUN mkdir -p /app/node_modules && chown -R node:node /app\n\nWORKDIR /app\n\nCOPY package.json /app\nCOPY tsconfig.json /app\nCOPY webpack.config.js /app\nCOPY .env.prod .env\nADD src /app/src\nADD dist /app/dist\nRUN mkdir -p /app/dist/js && chown -R node:node /app/dist/js\n\nADD server /app/server\nADD assets /app/assets\nADD config /app/config\n\nARG NPM_TOKEN\nCOPY .npmrc_docker .npmrc\nRUN npm cache verify\nRUN npm install\nRUN npm run build:prod\nRUN rm -f .npmrc\n\n# Expose necessary port\nEXPOSE 3000\n\n# Compile typescript and start app\nCMD [\"cross-env\", \"NODE_ENV=production\", \"PORT=3000\", \"ts-node\", \"server/server\"]\n`\n```\nI've also tried doing it with `CMD [\"npx\", \"http-server\", \"./dist\", \"-p\", \"3000\"]` since the server part is only doing the following:\n```\n`      this.app.use(express.static(path.resolve(__dirname, \"../dist\")));\n      this.app.get(\"*\", (request: express.Request, response: express.Response) => {\n        response.sendFile(path.resolve(__dirname, \"../dist/index.html\"));\n      });\n`\n```",
      "solution": "Alright, so I found the real problem.\nMy domain uses both DigitalOcean and Microsoft name servers. I had the A record added on DO, but I guess it needs to be on both. So I added the A record to the other and now my config in my question works perfectly.",
      "question_score": 8,
      "answer_score": 2,
      "created_at": "2021-09-12T08:18:15",
      "url": "https://stackoverflow.com/questions/69148955/react-router-nginx-ingress-refresh-causes-white-screen-when-path-is-not"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66051867,
      "title": "Starlette&#39;s url_for doesn&#39;t create links with https scheme behind Nginx (via uvicorn)",
      "problem": "I've tried everything:\n@Starlette:\n```\n`routes = [\n    Mount(\"/static/\", StaticFiles(directory=parent+fs+\"decoration\"+fs+\"static\"), name=\"static\"),\n    Route(....),\n    Route(....),\n]\n`\n```\n@Uvicorn:\n```\n`--forwarded-allow-ips=domain.com\n--proxy-headers\n`\n```\n@url_for:\n```\n`_external=True\n_scheme=\"https\"\n`\n```\n@nginx:\n```\n`proxy_set_header Subdomain $subdomain;\nproxy_set_header Host $http_host;\nproxy_pass http://localhost:7000/;\nproxy_set_header X-Forwarded-For $remote_addr;\nproxy_set_header   X-Real-IP $remote_addr;\nproxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_set_header   X-Forwarded-Proto $scheme;\nproxy_set_header   X-Forwarded-Host $server_name;\nproxy_redirect     http://$http_host/ https://$http_host/;\ninclude proxy_params;\nserver {\n    if ($host = sub.domain.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n    listen 80 ;\n    listen [::]:80 ;\n    server_name sub.domain.com;\n    return 404; # managed by Certbot\n\n}\n`\n```\nIf I open a .css or .js link, nginx renders it to https.\nWhen I allow Firefox to ignore the unsafe content, the whole page is rendered correctly at the production server.\nLet's encrypt works perfectly with the whole domain, no issues with the certificate.",
      "solution": "The problem after all was the usage of * instead of \"*\" through bash.\nThe result was to have all the filenames returned at the FORWARDED_ALLOW_IPS parameter instead of the character \"*\".",
      "question_score": 8,
      "answer_score": 2,
      "created_at": "2021-02-04T19:44:14",
      "url": "https://stackoverflow.com/questions/66051867/starlettes-url-for-doesnt-create-links-with-https-scheme-behind-nginx-via-uvi"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 68010880,
      "title": "Is Passenger Deprecated for Nginx versions above 1.14?",
      "problem": "I updated nginx from version `1.14` to `1.18 (Ubuntu)` on `Ubuntu 18.04`.\nDoing so appeared to break passenger.  So I uninstalled and attempted to reinstall the Open Source Passenger version via the Passenger installation Ubuntu 18.04 instructions.\nI got to this line:\n```\n`sudo apt-get install -y libnginx-mod-http-passenger\n`\n```\nWhich throws this error\n\nlibnginx-mod-http-passenger : Depends: nginx-common (\n\nUpdate I also attempted with the enterprise version. Following the enterprise version installation instructions, I received a similar error message:\n\nlibnginx-mod-http-passenger-enterprise : Depends: nginx-common (\n\nI did attempt to research the issue and I found this issue on Phusion's GitHub as well as this more recent issue. It appears that what most people are doing is rolling back their nginx version to `1.14`.",
      "solution": "It is not deprecated, no. The problem is that the packaged module you are trying to install was made for an older Nginx version that is distributed through the system default repository. This appears in the installation guide that you've mentioned:\n\nAt this point we assume that you already have Nginx installed from your system repository.\n\nWhat this means is that it is assumed that you have a specific version of Nginx (`1.14.0` in your case) installed, for which the packaged module was built. This is emphasized in the new passenger documentation:\n\nIf you want to use our packaged Nginx module, you must use your distro's provided Nginx package. If for example you have the repo provided by NGINX setup, you will instead need to compile a dynamic module compatible with that Nginx.\n\nThe link in the last quote will bring you to the guide on how to compile a dynamic passenger module and enable it in Nginx configuration. I will not repeat the whole process to keep the answer short but the general approach is this:\n\nGet passenger module for Nginx source code.\nGet Nginx source code for the version you have installed.\nCompile Nginx with the passenger module:\n\n`cd /path-to-nginx-source-dir\n./configure --prefix=/opt/nginx \\\n  --with-some-configure-flag \\\n  --add-dynamic-module=$(passenger-config --nginx-addon-dir) \\\n  --add-module=/path-to-some-other-nginx-module\nmake\nsudo make install\n`\n\nMake Nginx to load the module by adding this line to `nginx.conf`:\n\n```\n`load_module modules/ngx_http_passenger_module.so;\n`\n```\nPersonally, I'd rather chosen the 'nginx-behind-nginx' approach than building the module. That is you have Nginx any version you like but it runs as a reverse proxy for another Nginx with passenger enabled (Passenger Standalone). With an unnoticeable penalty to performance this will be much easier to maintain (install, update). See this guide for details.",
      "question_score": 8,
      "answer_score": 5,
      "created_at": "2021-06-17T00:47:52",
      "url": "https://stackoverflow.com/questions/68010880/is-passenger-deprecated-for-nginx-versions-above-1-14"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 70937709,
      "title": ".NET 6.0: new Blazor project throws Websocket error",
      "problem": "I am running currently a webserver with ASP.NET Core 3.1 and a Blazor project.\nRecently when upgrading to .NET 6.0 I encountered (even with a blank Blazor project) some problems with a websocket error message in the browser only when deployed on my webserver (see message below).\nLocally (on Windows 11 x64, VS 22 Preview 4) there are no error messages...\nWebserver: Debian 10 x64, .NET 6.0 SDK installed, running on NGINX with websockets enabled (reverse proxy).\nDo I miss out on something or is it a problem with the current state of .NET 6.0 and NGINX? I already tried to access the webpage locally on the debian server and the same error message occurs.\nHelp would be much appreciated!\nGreetings!\nError messages within order:\n```\n`Information: Normalizing '_blazor' to 'http://192.168.178.35/_blazor'.\n`\n```\n\n```\n`blazor.server.js:1 WebSocket connection to 'ws://192.168.178.35/_blazor?id=wnPt_fXa9H4Jpia530vPWQ' failed:\n`\n```\n\n```\n`Information: (WebSockets transport) There was an error with the transport.\n`\n```\n\n```\n`Error: Failed to start the transport 'WebSockets': Error: WebSocket failed to connect. The connection could not be found on the server, either the endpoint may not be a SignalR endpoint, the connection ID is not present on the server, or there is a proxy blocking WebSockets. If you have multiple servers check that sticky sessions are enabled.\n`\n```\n\n```\n`Warning: Failed to connect via WebSockets, using the Long Polling fallback transport. This may be due to a VPN or proxy blocking the connection. To troubleshoot this, visit https://aka.ms/blazor-server-using-fallback-long-polling.\n`\n```",
      "solution": "Here is the solution described again, maybe a little bit more convenient:\nTo fix this problem, I changed in the site-configuration (/etc/nginx/sites-available) of nginx the following variables:\n```\n`proxy_set_header Connection $connection_upgrade;\n`\n```\nto\n```\n`proxy_set_header Connection $http_connection;\n`\n```\nFor me this solved the problem.",
      "question_score": 8,
      "answer_score": 2,
      "created_at": "2022-02-01T09:50:55",
      "url": "https://stackoverflow.com/questions/70937709/net-6-0-new-blazor-project-throws-websocket-error"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66859178,
      "title": "nginx return file not found with nginx-proxy and doesn&#39;t load static files",
      "problem": "I'm using nginx-proxy-automation to run my php application which is written using `CodeIgniter 4` and the app structure is the following:\n```\n`php-application\n   docker\n       php-fpm\n            config\n                php.ini\n           Dockerfile\n   src\n       node_modules\n       app\n       public\n       tests\n       vendor\n       writable\n       .env\n       composer.json\n       package.json\n       spark\n   docker-comopse.yml\n`\n```\nthe `index.php` file is available inside the `public` folder.\nThe `docker-compose.yml` of `php-application` contains the following stuff:\n```\n`nginx\n    nginx-proxy\n       docker-compose.yml\n    php-application\n       docker-compose.yml\n`\n```\nInside the `php-application/docker-compose.yml` I have this:\n```\n`version: '3.7'\n\nservices:\n  php-fpm:\n    container_name: boilerplate_app\n    restart: always\n    build:\n      context: .\n      dockerfile: ./docker/php-fpm/Dockerfile\n    volumes:\n      - ./src:/var/www/html\n    environment:\n      # NGINX-PROXY ENVIRONMENT VARIABLES: UPDATE ME\n      - VIRTUAL_HOST=mysite.com\n      - VIRTUAL_ROOT=/var/www/html/public\n      - VIRTUAL_PORT=9000\n      - VIRTUAL_PROTO=fastcgi\n      - LETSENCRYPT_HOST=mysite.com\n      - LETSENCRYPT_EMAIL=info@mysite.com\n      - NETWORK=proxy\n      # /END NGINX-PROXY ENVIRONMENT VARIABLES\n    ports:\n      - '9000:80'\n    expose:\n      - 9000\n    networks:\n      - proxy\n\n  database:\n    container_name: boilerplate_db\n    restart: always\n    build:\n      context: ./docker/database\n    environment:\n      - MYSQL_DATABASE=boilerplate\n      - MYSQL_USER=user\n      - MYSQL_PASSWORD=secret\n      - MYSQL_ROOT_PASSWORD=secret\n    volumes:\n      - ./docker/database/data.sql:/docker-entrypoint-initdb.d/data.sql\n\n  phpmyadmin:\n    container_name: boilerplate_phpmyadmin\n    image: phpmyadmin/phpmyadmin\n    restart: always\n    ports:\n      - 8088:80\n    environment:\n      - PMA_HOST=database\n      - MYSQL_USER=user\n      - MYSQL_PASSWORD=secret\n      - MYSQL_ROOT_PASSWORD=secret\n    depends_on:\n      - database\n\nnetworks:\n  proxy:\n    external:\n      name: proxy\n`\n```\nessentially I have three services:\n\nphp-fpm: which mount the application files in the `/var/www/html` folder, and in the `environment` section, I have specified the `VIRTUAL_PORT` as 9000 'cause `php-fpm` runs over `fastcgi`. Then I linked the `proxy` network which is the network of your image.\ndatabase: runs within the app network\nphpmyadmin: runs within the app network\n\nThe `Dockerfile` content of `php-fpm` contains the following stuff:\n```\n`FROM php:8.0.2-fpm-alpine\nWORKDIR /var/www/html\n\nRUN docker-php-ext-install pdo_mysql\nRUN docker-php-ext-install mysqli\nRUN apk add icu-dev\n\n# Install intl\nRUN docker-php-ext-configure intl && docker-php-ext-install intl\n\n# Install curl\nRUN apk add --update libzip-dev curl-dev &&\\\n    docker-php-ext-install curl && \\\n    apk del gcc g++ &&\\\n    rm -rf /var/cache/apk/*\n\nCOPY docker/php-fpm/config/php.ini /usr/local/etc/php/\n\n# Install composer\nCOPY --from=composer:latest /usr/bin/composer /usr/local/bin/composer\n\n# Install nodejs\nRUN apk add --update nodejs nodejs-npm\nRUN npm install gulp-cli -g\nRUN npm install\n\nCOPY src src/\n\nCMD [\"php-fpm\"]\n\nEXPOSE 9000\n`\n```\nwhen I start the container using `docker-compose up --build -d` I get this message when I visit `mysite.com` (I have hidden the real domain for privacy):\n\nFile not found.\n\nInspecting the `nginx` log using `sudo docker logs -f nginx` I get:\n```\n`[error] 30#30: *39 FastCGI sent in stderr: \"Primary script unknown\" while reading response header from upstream, client: 2.38.140.109, server: mysite.com, request: \"GET / HTTP/2.0\", upstream: \"fastcgi://172.28.0.7:9000\", host: \"mysite.com\"\nmysite.com 2.38.140.109 - - [29/Mar/2021:17:52:31 +0000] \"GET / HTTP/2.0\" 404 16 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36 Edg/89.0.774.63\"\n`\n```\nFor fix this problem, I have update the `nginx.tmpl` with this one.\nThe problem now is that when I load my site all the static files such js / image / css return 404.\nWhat can I do for fix this?",
      "solution": "In order to serve the static files from a container using the nginx proxy, the nginx proxy must have access to files statically... it would not 'proxy' but 'read' and serve the files... which means you must mount the app files into the proxy...\nI would recommend you put up a new, light and clean nginx behind the nginx proxy along with your php-fpm service so you can have full management of your routes/locations,\nFirst of all I have created a `docker-compose.yml` in my app that contains the following:\n```\n`version: '3.9'\n\nservices:\n\nphp-fpm:\n    container_name: boilerplate_app\n    restart: always\n    build:\n    context: .\n    dockerfile: ./docker/php-fpm/Dockerfile\n    volumes:\n    - ./src:/var/www/html\n\nnginx:\n    image: nginx:stable-alpine\n    container_name: boilerplate_nginx\n    restart: always\n    volumes:\n    - ./src:/var/www/html\n    - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf\n    - ./docker/nginx/sites/:/etc/nginx/sites-available\n    - ./docker/nginx/conf.d/:/etc/nginx/conf.d\n    depends_on:\n    - php-fpm\n    environment:\n    VIRTUAL_HOST: example.com\n    LETSENCRYPT_HOST: example.com\n    LETSENCRYPT_EMAIL: info@example.com\n    \ndatabase:\n    container_name: boilerplate_db\n    restart: always\n    build:\n    context: ./docker/database\n    environment:\n    - MYSQL_DATABASE=boilerplate\n    - MYSQL_USER=user\n    - MYSQL_PASSWORD=secret\n    - MYSQL_ROOT_PASSWORD=secret\n    volumes:\n    - ./docker/database/data.sql:/docker-entrypoint-initdb.d/data.sql\n\nphpmyadmin:\n    container_name: boilerplate_phpmyadmin\n    image: phpmyadmin/phpmyadmin\n    restart: always\n    ports:\n    - 8088:80\n    environment:\n    - PMA_HOST=database\n    - MYSQL_USER=user\n    - MYSQL_PASSWORD=secret\n    - MYSQL_ROOT_PASSWORD=secret\n    depends_on:\n    - database\n    \nnetworks:\ndefault:\n    external:\n    name: proxy\n`\n```\nthen, inside my app directory I have created the nginx configurations structure:\n```\n`app\n   docker\n       nginx\n           conf.d\n              default.conf\n           sites\n              default.conf\n        nginx.conf\n`\n```\nwhere I have `conf.d`:\n```\n`upstream php-upstream {\n    server php-fpm:9000;\n}\n`\n```\nthen I have `sites`:\n```\n`server {\n    root   /var/www/html/public;\n    index index.php;\n\n    location ~ [^/]\\.php(/|$) {\n    fastcgi_split_path_info ^(.+?\\.php)(/.*)$;\n\n    include fastcgi_params;\n    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n    fastcgi_param PATH_INFO       $fastcgi_path_info;\n    fastcgi_param PATH_TRANSLATED $document_root$fastcgi_path_info;\n\n    fastcgi_pass   php-upstream;\n    fastcgi_index  index.php;\n    }\n}\n`\n```\nand `nginx.conf`:\n```\n`user  nginx;\nworker_processes  4;\n\nerror_log  /var/log/nginx/error.log warn;\npid        /var/run/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    access_log  /var/log/nginx/access.log;\n    # Switch logging to console out to view via Docker\n    #access_log /dev/stdout;\n    #error_log /dev/stderr;\n\n    sendfile        on;\n    keepalive_timeout  65;\n    \n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-available/*.conf;\n}\n`\n```\nthe site load now but there are some issues:\n\nPerformance issue: we have two nginx layer here and the load time is increased a lot\nIf I browse some url like example.com/admin I get 404 from nginx, guess it's a configuration issue on my own",
      "question_score": 8,
      "answer_score": 1,
      "created_at": "2021-03-29T19:54:27",
      "url": "https://stackoverflow.com/questions/66859178/nginx-return-file-not-found-with-nginx-proxy-and-doesnt-load-static-files"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67989620,
      "title": "Error pinging docker server on &quot;terraform apply&quot;",
      "problem": "I am doing the terraform tutorial and reach the step to execute `terraform apply`.\nAfter executing that command I get this error:\n```\n`WARNING: cgroup v2 is not fully supported yet, proceeding with partial confinement\n\nError: Error pinging Docker server: Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get \"http://%2Fvar%2Frun%2Fdocker.sock/_ping\": dial unix /var/run/docker.sock: connect: permission denied\n\n  on main.tf line 9, in provider \"docker\":\n   9: provider \"docker\" {\n`\n```\nThis is what I have in my configuration `main.tf`file:\n```\n`terraform {\n  required_providers {\n    docker = {\n      source = \"kreuzwerker/docker\"\n    }\n  }\n}\n\nprovider \"docker\" {\n  \n}\n\nresource \"docker_image\" \"nginx\" {\n  name         = \"nginx:latest\"\n  keep_locally = false\n}\n\nresource \"docker_container\" \"nginx\" {\n  image = docker_image.nginx.latest\n  name  = \"tutorial\"\n  ports {\n    internal = 80\n    external = 8000\n  }\n}\n`\n```\nI have tried adding `host = \"unix:///var/run/docker.sock\"` in the provider function but still get that error. I have docker and NGINX configured in my pc too.\nDoes anyone know what is causing it?",
      "solution": "When you run docker run hello-world with your user id you will see the same error that you are getting.\nThis is happening because your user doesn't have access to execute the commands of docker. Please do the following steps.\n\n`cat /etc/group`  --> There should be a docker group available if you installed docker correctly.\nAdd your userid to docker group `sudo usermod -aG docker $User_Name`\nLogout from the session and login again\n`docker run hello-world`  --> This should run error free now.\n\nNow try to apply Terraform again and everything will work.",
      "question_score": 7,
      "answer_score": 3,
      "created_at": "2021-06-15T17:54:19",
      "url": "https://stackoverflow.com/questions/67989620/error-pinging-docker-server-on-terraform-apply"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 76259258,
      "title": "OpenSSL Wrong version number on Ubuntu SSH",
      "problem": "I'm setting my nginx to listen to port 8080 here's my config file and it works on when I'm accessing with `http` e.g `http://myweb.com:8080/api/`.\n```\n`server {\n    listen 8080;\n\n    location / {\n        proxy_pass http://localhost:8080;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_ssl_server_name on;\n    }\n}\n`\n```\nHowever when I try to access it with `https` on Insomnia it returns `SSL connect error`.\nWhen I try ` curl https://myweb.com:8080 --verbose`\nIt returns something like this:\n```\n`*   Trying {myipadress}:8080...\n* Connected to myweb.com (ipaddress) port 8080 (#0)\n* ALPN: offers h2,http/1.1\n* TLSv1.3 (OUT), TLS handshake, Client hello (1):\n*  CAfile: /etc/ssl/certs/ca-certificates.crt\n*  CApath: none\n* OpenSSL/3.0.8: error:0A00010B:SSL routines::wrong version number\n* Closing connection 0\ncurl: (35) OpenSSL/3.0.8: error:0A00010B:SSL routines::wrong version number\n`\n```\nI've been configuring for two days and IDK what's wrong, does anybody have similar issue?",
      "solution": "This error is due to simply using `https://` on a target and port, which is configured for plain `http://`.\nHTTPS and HTTP are different protocols, which need to be configured on different ports and also need different configuration. Specially support for HTTPS needs also the configuration of certificates on the server side. See nginx documentation for how to configure HTTPS.",
      "question_score": 7,
      "answer_score": 23,
      "created_at": "2023-05-16T05:42:11",
      "url": "https://stackoverflow.com/questions/76259258/openssl-wrong-version-number-on-ubuntu-ssh"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 72097776,
      "title": "duplicate extension &quot;woff&quot;, content type: &quot;font/woff2&quot;, previous content type: &quot;font/woff&quot; in /etc/nginx/mime.types",
      "problem": "After the latest Nginx update (currently nginx/1.21.6), the following warning started to appear when I do a `nginx -t`:\n\nnginx: [warn] duplicate extension \"woff\", content type: \"font/woff2\", previous content type: \"font/woff\" in /etc/nginx/mime.types:29\n\nThe same issue is happening on all my servers, with Ubuntu 18.04 or 20.04 + latest nginx mainline\nI never edited the `mime.types` files, which has the following:\n```\n`types {\n    [...]\n    font/woff                             woff;\n    font/woff2                            woff;\n}\n`\n```\nFrom what I understand it doesn't like these two lines having the same value, but which one should I delete?",
      "solution": "I found out where the issue was, If you have the same issue you're probably using the `ppa:ondrej/nginx-mainline` repository, and you have:\n```\n`font/woff                             woff;\nfont/woff2                            woff;\n`\n```\nInstead of:\n```\n`font/woff                                        woff;\nfont/woff2                                       woff2;\n`\n```\nSee the file on the nginx/nginx master branch for reference.",
      "question_score": 7,
      "answer_score": 15,
      "created_at": "2022-05-03T12:02:46",
      "url": "https://stackoverflow.com/questions/72097776/duplicate-extension-woff-content-type-font-woff2-previous-content-type"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 65703968,
      "title": "Kubernetes Ingress: nginx, use-regex to match exact URL path",
      "problem": "I have a few pods that I am trying to match URLs for their respective services.\nPlease note that I need to use `nginx.ingress.kubernetes.io/rewrite-target` to solve this and not `nginx.ingress.kubernetes.io/rewrite-target`\nMy ingress config file looks like this. Notice the `/api/tile-server/` does not have any regex pattern\n```\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: ingress-service\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    kubernetes.io/ingress.class: \"nginx\"\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n  namespace: default\nspec:\n  tls:\n    - hosts:\n        - example.com\n      secretName: tls-secret\n  rules:\n    - host: example.com\n      http:\n        paths:\n          - path: /?(.*)\n            backend:\n              serviceName: client\n              servicePort: 80\n          - path: /api/auth/?(.*)\n            backend:\n              serviceName: auth\n              servicePort: 8000\n          - path: /api/data/?(.*)\n            backend:\n              serviceName: data\n              servicePort: 8001\n          - path: /api/tile-server/\n            backend:\n              serviceName: tile-server\n              servicePort: 7800\n`\n```\n\n`client` pod is a react app built inside nginx docker image working fine\n`nginx.conf` looks like this (if it's helpful)\n\n```\n`server {\n    # listen on port 80\n    listen 80;\n    # where the root here\n    root /usr/share/nginx/html;\n    # what file to server as index\n    index index.html index.htm;\n\n    location / {\n        # First attempt to serve request as file, then\n        # as directory, then fall back to redirecting to index.html\n        try_files $uri $uri/ /index.html;\n    }\n\n    # Media: images, icons, video, audio, HTC\n    location ~* \\.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm|htc)$ {\n        expires 1M;\n        access_log off;\n        add_header Cache-Control \"public\";\n    }\n\n    # Javascript and CSS files\n    location ~* \\.(?:css|js)$ {\n        try_files $uri =404;\n        expires 1y;\n        access_log off;\n        add_header Cache-Control \"public\";\n    }\n\n    # Any route containing a file extension (e.g. /devicesfile.js)\n    location ~ ^.+\\..+$ {\n        try_files $uri =404;\n    }\n}\n`\n```\n\n`auth` and `data` are Flask API pods working fine\n`tile-server` is also a Flask pod but need not do any pattern matching. I need to match the exact `/api/tile-server/` URL\n\nI have tried the following patterns but failed:\n\n`/api/tile-server/`\n`/api/tile-server/?(.*)`\n`/api/tile-server(/|$)?(.*)`\n\nI can confirm that the pods/services are running on their proper ports and I am able to access them through node ports but not through load balancer/domain.\nWhat would be the right pattern to exactly match `/api/tile-server/` URL?",
      "solution": "First solution - create separate ingress object for tile-server with rewrite-target annotation. This will work because ingress rules with the same host are merged together by ingress controller and separate ingress object allow for use of different annotations per object:\n```\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: tile-ingress-service\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: \"/$2\"\n    kubernetes.io/ingress.class: \"nginx\"\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n  namespace: default\nspec:\n  tls:\n    - hosts:\n        - example.com\n      secretName: tls-secret\n  rules:\n    - host: example.com\n      http:\n        paths:\n          - path: /api/tile-server(/|$)(.*)\n            backend:\n              serviceName: tile-server\n              servicePort: 7800\n`\n```\nSecond solution - rewrite current ingress to work with rewrite-path. Some regex changes are necessary.\nNotice the non-capturing group notation: `(?:)`. This allows to skip numbering for these groups since I need everything relevant to be in the first group in order for it to work, because `rewrite-target: \"/$1\"`.\n```\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: ingress-service\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: \"/$1\"\n    kubernetes.io/ingress.class: \"nginx\"\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n  namespace: default\nspec:\n  tls:\n    - hosts:\n        - example.com\n      secretName: tls-secret\n  rules:\n    - host: example.com\n      http:\n        paths:\n          - path: /(.*)\n            backend:\n              serviceName: client\n              servicePort: 80\n          - path: /(api/auth(?:/|$).*)\n            backend:\n              serviceName: auth\n              servicePort: 8000\n          - path: /(api/data(?:/|$).*)\n            backend:\n              serviceName: data\n              servicePort: 8001\n          - path: /api/tile-server(?:/|$)(.*)\n            backend:\n              serviceName: tile-server\n              servicePort: 7800\n`\n```\nHere is how the rewrites will work for:\n\nauth service (same applies to data service)\n\n```\n`    /api/auth      --->  /api/auth\n    /api/auth/     --->  /api/auth/\n    /api/auth/xxx  --->  /api/auth/xxx\n`\n```\n\ntile-server service:\n\n```\n`    /api/tile-server      --->  /\n    /api/tile-server/     --->  /\n    /api/tile-server/xxx  --->  /xxx\n`\n```\n\nclient service\n\n```\n`    /xxx  --->  /xxx\n`\n```\nNotice that the following paths will be forwarded to client service (where xxx is any alphanumerical string):\n```\n`    /api/authxxx\n    /api/dataxxx\n    /api/tile-serverxxx\n`\n```\nIf you want them to be forwaded to other/matching services, add `?` after `(?:/|$)` in path.",
      "question_score": 7,
      "answer_score": 8,
      "created_at": "2021-01-13T15:30:48",
      "url": "https://stackoverflow.com/questions/65703968/kubernetes-ingress-nginx-use-regex-to-match-exact-url-path"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69399672,
      "title": "How to have an AWS ELB forward the actual host name to the target group instead of the ELB&#39;s host name?",
      "problem": "We have a Ruby/Rails website we're migrating from Heroku to AWS. The original dev is not available. I'm now trying to complete the migration. My background is in the Windows / .NET world. This Linux / Ruby/Rails environment is quite foreign to me...\nHere's the current environment I've set-up:\nRoute 53\n\nRecord Name\nRecord Type\nAlias\nAlias Route Traffic To\n\nfoo.example.com\nA\nyes\ncloudfront: xyz.cloudfront.net\n\nCloudFront\n\nDomain Name\nAlternate Domain Names\nOrigin Domain\nOrigin Protocol\nBehavior Protocol\n\nxyz.cloudfront.net\nfoo.example.com\nfoo.us-west-2.elb.amazonaws.com\nHTTP only\nRedirect HTTP to HTTPS\n\nThe CloudFront distribution:\n\nuses an AWS issued SSL cert\nhandles the http to https redirect\nforwards the request to the ELB over http (not https)\n\nLoad Balancer\n\nDNS Name\nListener Rule\nForward To\n\nfoo.us-west-2.elb.amazonaws.com\nHTTP 80: default action\nTarget Group: foo-ec2\n\n`Target Group: foo-ec2` contains a single Ubuntu ec2 instance running nginx/1.18.0 + Phusion Passenger 6.0.10 to serve up the Ruby/Rails site.\nnginx config\n```\n`server {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n\n    # SSL Config - we should NEVER receive 443/https traffic; \n    # CloudFront manages https traffic => AWS ELB => http to this server\n    #listen 443 ssl default_server;\n    #listen [::]:443 ssl default_server;\n\n    server_name foo.example.com\n                foo.us-west-2.elb.amazonaws.com;\n\n    # Tell Nginx and Passenger where the app's 'public' directory is\n    root /var/www/foo_example/public;\n\n    # Turn on Passenger\n    passenger_enabled on;\n    passenger_app_env production;\n    passenger_ruby /home/ubuntu/.rbenv/versions/2.6.8/bin/ruby;\n}\n`\n```\nIssue\nThe rails app starts up without error and is served over https. However, when a user attempts to log in / authenticate, the Devise gem sends back a redirect using http and the ELB's DNS name.\nExample\nsign_in request\n```\n`Request URL: https://foo.example.com/users/sign_in\nRequest Method: POST\nStatus Code: 302 \n`\n```\nsign_in response\n```\n`location: http://foo.us-west-2.elb.amazonaws.com/users\nserver: nginx/1.18.0 + Phusion Passenger(R) 6.0.10\nstatus: 302 Found\n`\n```\nNotice the request was over https and our domain:\n\n`https://foo.example.com`\n\nBut now we're over http and the ELB's domain:\n\n`http://foo.us-west-2.elb.amazonaws.com`\n\nMy assumption\nThe `devise` gem is seeing the host from the ELB and then generates the URL from the ELB host, creating two issues:\n\nwe are now on http since the ELB communicates with the ec2 instance over http\nwe are now on the ELB's host name, foo.us-west-2.elb.amazonaws.com, instead of our name, foo.example.com\n\nI've looked into the `devise` documentation to see if we can just pass in the http protocol and domain to use when creating the post back, but my ruby knowledge is limited. Plus, I think this would be the \"bad\" path; where the \"good\" path would be to have the AWS ELB forward the actual domain name, instead of it's own.\nI've reviewed several SO and related stack sites with similar questions, but I've either ended up with an infinite loop redirect, or the various config changes have resulted in the same behavior of the `devise` gem creating the wrong URL post back.\nThese two questions seem to be the closest, but I'm not quite able to make the \"connection\" between the answers and my limited knowledge of this ecosystem.\n\nAWS Cloudfront + Load Balancer, url changes from main domain to load balancer subdomain\ncloudfront domain replaced by application load balancer dns name when redirecting from http to https\n\nQuestion\nHow can I get the AWS ELB to forward our domain, foo.example.com, to the ec2 target group and not the ELB's domain?",
      "solution": "After more experimentation with AWS settings, the solution is actually rather simple. The other answers I posted in the question were vague in the actual settings, so here's the concrete solution.\nIn CloudFront, you need to create a new `origin request policy`, not a `cache policy`:\n\nOpen up CloudFront\ngo to Policies (left nav)\nclick the \"Origin Request\" tab\nclick the \"create origin request policy\" button\nname the policy whatever you want, i.e., \"my origin request policy\"\nunder \"Origin request settings\" > Headers: select \"Include the following headers\"\nunder \"Add header\": check the \"Host\" option\nclick the \"Create\" button\n\nThe policy will look like this:\n\nOnce the new origin request policy has been created:\n\nhead back to the CloudFront distributions\nclick your distribution's Id so you can edit it\nclick the \"Behaviors\" tab\nselect your behavior and edit\nscroll down to \"Cache key and origin requests\"\nmake sure the \"Cache policy and origin request policy (recommended)\" is selected\nunder the \"Origin request policy - optional\", select your new policy, i.e., \"my origin request policy\"\nsave changes\n\nThe behavior will look like this (I'm using no caching for now to verify the ec2 instance is getting all the requests):\n\nThat's it. The host header is now correctly passed through to the ELB and ec2 instance. Nothing else needs to be done with the ELB.\nI verified the host header was being used in all requests by modifying the nginx logging option to include the `$host` variable in the log file (and did a bit more customization to the OOB format):\n```\n`# prefixed log with '[my-log]', but it's not needed; remove.\nlog_format my-log '[my-log] $http_x_forwarded_for - $remote_user [$time_local] '\n                  '\"$request_method $scheme://$host$request_uri $server_protocol\" '\n                  '$status $body_bytes_sent \"$http_referer\" \"$http_user_agent\" $request_time';\n\nserver {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n\n    # SSL Config - we should NEVER receive 443/https traffic; \n    # CloudFront manages https traffic => AWS ELB => http to this server\n    #listen 443 ssl default_server;\n    #listen [::]:443 ssl default_server;\n\n    server_name foo.example.com\n                foo.us-west-2.elb.amazonaws.com;\n\n    # create the our log file\n    access_log /var/log/nginx/my-log.access.log my-log;\n\n    # Tell Nginx and Passenger where the app's 'public' directory is\n    root /var/www/foo_example/public;\n\n    # Turn on Passenger\n    passenger_enabled on;\n    passenger_app_env production;\n    passenger_ruby /home/ubuntu/.rbenv/versions/2.6.8/bin/ruby;\n}\n`\n```\nSurely this will help future me as well as others.",
      "question_score": 7,
      "answer_score": 10,
      "created_at": "2021-10-01T01:10:35",
      "url": "https://stackoverflow.com/questions/69399672/how-to-have-an-aws-elb-forward-the-actual-host-name-to-the-target-group-instead"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 75192411,
      "title": "Cors in capacitor for android",
      "problem": "I want to convert my `angular` web app to mobile app.\nI understand how CORS works in web; it just needs to set the same port and URL as it is in backend's `allowedOrigins` settings. But I can't understand how CORS works in mobile app because IP will be different in each mobile device, and not static like in frontend.\nI can config something like this in my computer:\nIn server:\n```\n`app:\n  auth:\n  cors:\n    allowedOrigins: http://127.0.0.1:8100,\n`\n```\nIn mobile app (capacitor.config.ts):\n```\n`import { CapacitorConfig } from '@capacitor/cli';\n\nconst config: CapacitorConfig = {\n  appId: 'com.my.app',\n  appName: 'my-mobile',\n  webDir: 'dist/my-mobile',\n  bundledWebRuntime: false,\n  server: {\n    cleartext: true,\n    hostname: '127.0.0.1:8100',\n  }\n};\n\nexport default config;\n`\n```\nAnd this works, but in local, how to do it in prod and on real android devices?",
      "solution": "I got answer here https://forum.ionicframework.com/t/how-works-cors-in-capasitor-on-real-devices/230474\nIn prod, the apps run at the following URL/origin by default:\niOS: capacitor://localhost\nAndroid: http://localhost\nSo, both of those need to be configured in your backend as allowed origins. You could also use Capacitor\u2019s HTTP plugin to get around CORS all together.",
      "question_score": 7,
      "answer_score": 3,
      "created_at": "2023-01-21T10:44:13",
      "url": "https://stackoverflow.com/questions/75192411/cors-in-capacitor-for-android"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67533169,
      "title": "missing http headers in web server",
      "problem": "Am using BaseHTTPRequestHandler http server and copy/pasted the code from the interwebs.\nHere's the part where the response/header is set\n```\n`class S(BaseHTTPRequestHandler):    \n    def _set_response(self):\n        self.send_response(200)\n        self.send_header('Content-type', 'text/html')\n        self.end_headers()\n`\n```\nBut when calling the server with curl the response is:\n\ncurl: (1) Received HTTP/0.9 when not allowed\n\nWhen calling through browser:\n\nERR_INVALID_HTTP_RESPONSE\n\nprotocol_version is http/1.0\nThe web server is called through nginx reverse proxy, which just does\n```\n`   location / {\n       proxy_http_version 1.1;\n       proxy_pass  http://${NODE_NAME}:9000/;\n   }\n`\n```\nAre there more headers needed for this? How do we set correct http headers in BaseHTTPRequestHandler or nginx?",
      "solution": "Just sharing as a solution. I ran into the same issue, and ignoring this warning will result in some probe requestors not to run correctly. After some research, I found that the following order of response formation will fix the issue:\n```\n`self.protocol_version = 'HTTP/1.0'\nself.send_response(200)\nself.send_header(\"Content-type\", \"text/html\")\nself.send_header(\"Content-length\", body_size)\nself.end_headers()\nself.wfile.write(bytes(item, \"utf-8\"))\n`\n```\nThe important part is to specify the body size in bytes - it is a protocol requirement from 1.0 on. After this error disappears and code starts to function as it should.",
      "question_score": 7,
      "answer_score": 5,
      "created_at": "2021-05-14T12:54:43",
      "url": "https://stackoverflow.com/questions/67533169/missing-http-headers-in-web-server"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66911499,
      "title": "Nginx Font Cashing",
      "problem": "I'm desperately trying to figure out a way to set an expiry date on fonts in nginx to optimize on mobile.\nI'm interested for ttf fonts.\nI have mime.types as fallows:\n```\n`application/font-woff                 woff;\napplication/vnd.ms-fontobject         eot;\napplication/x-font-ttf                ttc ttf;\nfont/opentype                         otf;\nimage/svg+xml                         svg svgz;\n`\n```\nAnd on Nginx I have tried every solution I found on the web to no avail:\nTry #1:\n```\n`location ~* \\.(?:eot|woff|woff2|ttf|svg|otf) {\naccess_log        off;\nlog_not_found     off;\nexpires           365d;\nadd_header        Cache-Control \"public\";\nadd_header        Access-Control-Allow-Origin *;\ntypes     {font/truetype ttf;}\n}\n`\n```\nFail NO Expiry:\n```\n`Request URL: http://localhost:3001/static/media/Poppins-Regular.8081832f.ttf\nRequest Method: GET\nStatus Code: 200 OK\nRemote Address: [::1]:3001\nReferrer Policy: strict-origin-when-cross-origin\nConnection: keep-alive\nContent-Encoding: gzip\nContent-Type: application/x-font-ttf\nDate: Thu, 01 Apr 2021 18:33:55 GMT\nETag: W/\"60660e52-269f0\"\nLast-Modified: Thu, 01 Apr 2021 18:17:54 GMT\nServer: nginx/1.15.2\nTransfer-Encoding: chunked\nVary: Accept-Encoding\nAccept: */*\nAccept-Encoding: gzip, deflate, br\nAccept-Language: en-US,en;q=0.9\nConnection: keep-alive\nHost: localhost:3001\nOrigin: http://localhost:3001\nReferer: http://localhost:3001/static/css/main.06159cd9.chunk.css\nSec-Fetch-Dest: font\nSec-Fetch-Mode: cors\nSec-Fetch-Site: same-origin\nSec-GPC: 1\nUser-Agent: Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36\n`\n```\nTry #2:\n```\n`location ~* \\.(woff|ttf|otf|woff2|eot)$ {\nexpires 365d;\naccess_log off;\nadd_header Pragma public;\nadd_header Cache-Control \"public, max-age=86400\";\nadd_header X-Asset \"yes\";\n}\n`\n```\nFailed: Same result\nTry: 3\nhttps://io.24hoursmedia.com/tech-notes/nginx-send-browser-cache-headers-for-static-files\nFailed: Same result\nTry: 4\n```\n`location ~* \\.(?:jpg|jpeg|gif|png|ico|woff2)$ {\nexpires 1M;\nadd_header Cache-Control \"public\";\n}\n`\n```\nFailed: Same result\nWhat I am missing? Please help.",
      "solution": "Keep it simple. My NGINX looks like:\n```\n`location ~* \\.(js|css|png|jpg|jpeg|gif|svg|ico|woff|woff2|ttf)$ {\n        ....\n        expires max;\n        add_header Cache-Control \"public, no-transform\";\n}\n`\n```\nAnd the response:\n```\n`cache-control: max-age=315360000\ncache-control: public, no-transform\ncontent-length: 84508\ncontent-type: font/woff2\ndate: Mon, 05 Apr 2021 19:08:55 GMT\netag: \"603562a6-14a1c\"\nexpires: Thu, 31 Dec 2037 23:55:55 GMT\nlast-modified: Tue, 23 Feb 2021 20:16:38 GMT\nserver: nginx\n`\n```\nI have two different configurations for my fonts ...\n```\n`types { application/x-font-ttf ttf}\nAND\ntypes {font/ttf ttf}\n`\n```\nThe second one is based on the new `font` standard released back in 2017.\nhttps://www.iana.org/assignments/media-types/media-types.xhtml#font\n... but I haven't seen `font/truetype`.\nMore Information: http://nginx.org/en/docs/http/ngx_http_core_module.html#types\nIf you want to fine-tune your `expires` value take a look here:\nhttps://nginx.org/en/docs/http/ngx_http_headers_module.html#expires\n```\n`{\nmap $sent_http_content_type $expires {\n    default         off;\n    application/pdf 42d;\n    ~image/         max;\n}\n\n  server {\n    ...\n\n    location ~*\\.(woff|woff2...)$ {\n     ...\n     expires $expires;\n     }\n  }\n}\n\n`\n```",
      "question_score": 7,
      "answer_score": 7,
      "created_at": "2021-04-01T23:00:25",
      "url": "https://stackoverflow.com/questions/66911499/nginx-font-cashing"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66042897,
      "title": "Docker build fails at npm install",
      "problem": "Hi im trying to use docker with an Angular application but it fails at npm install while \"locally\" when I run npm install I don't get those dependency errors/warnings.\nHere is the error log from docker build:\n```\n` > [node 4/6] RUN npm install:\n#12 9.943 npm notice\n#12 9.943 npm notice New patch version of npm available! 7.5.1 -> 7.5.2\n#12 9.944 npm notice Changelog: \n#12 9.944 npm notice Run `npm install -g npm@7.5.2` to update!\n#12 9.944 npm notice\n#12 9.950 npm ERR! code ERESOLVE\n#12 9.956 npm ERR! ERESOLVE unable to resolve dependency tree\n#12 9.956 npm ERR!\n#12 9.956 npm ERR! While resolving: hotel-manager@0.0.0\n#12 9.956 npm ERR! Found: typescript@4.1.3\n#12 9.956 npm ERR! node_modules/typescript\n#12 9.956 npm ERR!   dev typescript@\"^4.1.3\" from the root project\n#12 9.957 npm ERR!   peer typescript@\"~4.0.0 || ~4.1.0\" from @angular-devkit/build-angular@0.1101.2\n#12 9.957 npm ERR!   node_modules/@angular-devkit/build-angular\n#12 9.957 npm ERR!     dev @angular-devkit/build-angular@\"^0.1101.2\" from the root project\n#12 9.957 npm ERR!   2 more (@angular/compiler-cli, ng-packagr)\n#12 9.957 npm ERR!\n#12 9.957 npm ERR! Could not resolve dependency:\n#12 9.957 npm ERR! peer typescript@\"~3.9.5\" from tsickle@0.39.1\n#12 9.957 npm ERR! node_modules/tsickle\n#12 9.957 npm ERR!   peerOptional tsickle@\"~0.39.0\" from ng-packagr@11.1.3\n#12 9.958 npm ERR!   node_modules/ng-packagr\n#12 9.958 npm ERR!     peerOptional ng-packagr@\"^11.0.0 || ^11.1.0-next\" from @angular-devkit/build-angular@0.1101.2\n#12 9.958 npm ERR!     node_modules/@angular-devkit/build-angular\n#12 9.958 npm ERR!       dev @angular-devkit/build-angular@\"^0.1101.2\" from the root project\n#12 9.958 npm ERR!\n#12 9.958 npm ERR! Fix the upstream dependency conflict, or retry\n#12 9.958 npm ERR! this command with --force, or --legacy-peer-deps\n#12 9.959 npm ERR! to accept an incorrect (and potentially broken) dependency resolution.\n#12 9.959 npm ERR!\n#12 9.959 npm ERR! See /root/.npm/eresolve-report.txt for a full report.\n#12 9.967\n#12 9.967 npm ERR! A complete log of this run can be found in:\n#12 9.967 npm ERR!     /root/.npm/_logs/2021-02-04T09_16_48_306Z-debug.log\n`\n```\nHere is the log from npm install in vscode:\n```\n`npm WARN @angular/http@2.4.10 requires a peer of rxjs@^5.0.1 but none is installed. You must install peer dependencies yourself.\nnpm WARN @angular/http@2.4.10 requires a peer of @angular/core@2.4.10 but none is installed. You must install peer dependencies yourself.\nnpm WARN @angular/http@2.4.10 requires a peer of @angular/platform-browser@2.4.10 but none is installed. You must install peer dependencies yourself.\nnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.3.1 (node_modules\\chokidar\\node_modules\\fsevents):\nnpm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.3.1: wanted {\"os\":\"darwin\",\"arch\":\"any\"} (current: {\"os\":\"win32\",\"arch\":\"x64\"})\nnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.3 (node_modules\\fsevents):\nnpm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {\"os\":\"darwin\",\"arch\":\"any\"} (current: {\"os\":\"win32\",\"arch\":\"x64\"})\nnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.13 (node_modules\\watchpack-chokidar2\\node_modules\\fsevents):\nnpm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.13: wanted {\"os\":\"darwin\",\"arch\":\"any\"} (current: {\"os\":\"win32\",\"arch\":\"x64\"})\nnpm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.13 (node_modules\\webpack-dev-server\\node_modules\\fsevents):\nnpm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.13: wanted {\"os\":\"darwin\",\"arch\":\"any\"} (current: {\"os\":\"win32\",\"arch\":\"x64\"})\n`\n```\nAs I understood the optional lines are for mac users, I'm using windows 10 build 18363\nI don't use any `@angular/http` but \"@angular/commons/http\" instead and I could not get rid of those warnings but i don`t think that could cause the error.\nHere is the package.json file:\n```\n`{\n  \"name\": \"hotel-manager\",\n  \"version\": \"0.0.0\",\n  \"scripts\": {\n    \"ng\": \"ng\",\n    \"start\": \"ng serve\",\n    \"build\": \"ng build\",\n    \"test\": \"ng test\",\n    \"lint\": \"ng lint\",\n    \"e2e\": \"ng e2e\"\n  },\n  \"private\": true,\n  \"dependencies\": {\n    \"@angular/animations\": \"^11.1.2\",\n    \"@angular/cdk\": \"^11.1.1\",\n    \"@angular/common\": \"^11.1.2\",\n    \"@angular/compiler\": \"^11.1.2\",\n    \"@angular/core\": \"^11.1.2\",\n    \"@angular/forms\": \"^11.1.2\",\n    \"@angular/localize\": \"^11.1.2\",\n    \"@angular/material\": \"^11.1.1\",\n    \"@angular/platform-browser\": \"^11.1.2\",\n    \"@angular/platform-browser-dynamic\": \"^11.1.2\",\n    \"@angular/router\": \"^11.1.2\",\n    \"@ng-bootstrap/ng-bootstrap\": \"^9.0.2\",\n    \"@types/jquery\": \"^3.5.5\",\n    \"angular-font-awesome\": \"^3.1.2\",\n    \"animate.css\": \"^4.1.1\",\n    \"bootstrap\": \"^4.6.0\",\n    \"font-awesome\": \"^4.7.0\",\n    \"jquery\": \"^3.5.1\",\n    \"ng-editable-table\": \"^0.3.15\",\n    \"popper.js\": \"^1.16.1\",\n    \"rxjs\": \"~6.6.3\",\n    \"tslib\": \"^2.0.0\",\n    \"zone.js\": \"~0.10.2\"\n  },\n  \"devDependencies\": {\n    \"@angular-devkit/build-angular\": \"^0.1101.2\",\n    \"@angular/cli\": \"^11.1.2\",\n    \"@angular/compiler-cli\": \"^11.1.2\",\n    \"@angular/language-service\": \"^11.1.2\",\n    \"@types/jasmine\": \"~3.6.0\",\n    \"@types/jasminewd2\": \"~2.0.3\",\n    \"@types/node\": \"^12.19.16\",\n    \"codelyzer\": \"^6.0.0\",\n    \"jasmine-core\": \"~3.6.0\",\n    \"jasmine-spec-reporter\": \"~5.0.0\",\n    \"karma\": \"~5.2.3\",\n    \"karma-chrome-launcher\": \"~3.1.0\",\n    \"karma-coverage-istanbul-reporter\": \"~3.0.2\",\n    \"karma-jasmine\": \"~4.0.0\",\n    \"karma-jasmine-html-reporter\": \"^1.5.0\",\n    \"protractor\": \"~7.0.0\",\n    \"ts-node\": \"~7.0.0\",\n    \"tslint\": \"~6.1.0\",\n    \"typescript\": \"^4.1.3\"\n  }\n}\n\n`\n```\nand the nginx.prod.dockerfile:\n```\n`# Stage 1\nFROM node:latest as node\nLABEL  author = 'Sunflame'\nWORKDIR /app\nCOPY package.json package.json\nRUN npm install\nCOPY . .\nRUN npm run build -- --prod\n\n# Stage 2\nFROM nginx:latest\nVOLUME /var/cache/nginx\nCOPY --from=node /app/dist /usr/share/nginx/html\nCOPY  nginx.conf /etc/nginx/conf.d/default.conf\n\n`\n```\nI build with the following command:\n`docker build -t nginx-angular -f nginx.prod.dockerfile .`\nCan you please help what did I do wrong?",
      "solution": "As mentioned in the comment, add a step in the docker file to copy the `package-lock.json` file over to the destination.\nThe reason why it works on your local machine is because `package-lock.json` tells npm exactly which versions to install. For example, `Typescript` is listed as `^4.1.3` in `package.json`. In your local machine, it could have been installed as exactly `4.1.3` (check your `package-lock.json`) file. However, in the production machine, it might have installed version `4.2.1` or something. So even though you listed `4.1.3`, it actually pulls in a higher version because of the `^` prefix, which means you are good with having higher minor and patch versions installed. Therefore, you might be expecting `4.1.3` or whatever version it is on your local machine, the production server might have installed a much newer version because it did not refer to the `package-lock.json` file that's created in your local machine.\nCheck out what `^` and `~` means here in this answer - What's the difference between tilde(~) and caret(^) in package.json?",
      "question_score": 7,
      "answer_score": 5,
      "created_at": "2021-02-04T10:34:43",
      "url": "https://stackoverflow.com/questions/66042897/docker-build-fails-at-npm-install"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 75241243,
      "title": "How to use Nginx (deployed with Docker) reverse proxy Gitlab (deployed with Docker too)",
      "problem": "I installed Gitlab according to the official documentation.\n`sudo docker run --detach \\\n  --hostname git.xxx.com \\\n  --publish 8443:443 --publish 880:80 --publish 822:22 \\\n  --name gitlab \\\n  --restart always \\\n  --volume $GITLAB_HOME/config:/etc/gitlab \\\n  --volume $GITLAB_HOME/logs:/var/log/gitlab \\\n  --volume $GITLAB_HOME/data:/var/opt/gitlab \\\n  --shm-size 256m \\\n  gitlab/gitlab-ee:latest\n`\nNow I want to use Nginx (installed by myself) to reverse proxy Gitlab instead of the Nginx that comes with the Gitlab container.\nAccording to official documentation I added some code in `gitlab.rb`\n```\n`# Define the external url\nexternal_url 'http://git.stupidpz.com'\n\n# Disable the built-in nginx\nnginx['enable'] = false\n\n# Disable the built-in puma\npuma['enable'] = false\n\n# Set the internal API URL\ngitlab_rails['internal_api_url'] = 'http://git.stupidpz.com'\n\n# Define the web server process user (ubuntu/nginx)\nweb_server['external_users'] = ['nginx']\n`\n```\nThen gitlab cannot be accessed, I found some error logs in this file `/var/log/gitblab/gitlab_workhorse/current`\n`{\"correlation_id\":\"\",\"duration_ms\":0,\"error\":\"badgateway: failed to receive response: dial tcp 127.0.0.1:8080: connect: connection refused\",\"level\":\"error\",\"method\":\"GET\",\"msg\":\"\",\"time\":\"2023-01-25T20:57:21Z\",\"uri\":\"\"}\n{\"correlation_id\":\"\",\"duration_ms\":0,\"error\":\"badgateway: failed to receive response: dial tcp 127.0.0.1:8080: connect: connection refused\",\"level\":\"error\",\"method\":\"GET\",\"msg\":\"\",\"time\":\"2023-01-25T20:57:31Z\",\"uri\":\"\"}\n{\"correlation_id\":\"\",\"duration_ms\":0,\"error\":\"badgateway: failed to receive response: dial tcp 127.0.0.1:8080: connect: connection refused\",\"level\":\"error\",\"method\":\"GET\",\"msg\":\"\",\"time\":\"2023-01-25T20:57:41Z\",\"uri\":\"\"}\n{\"correlation_id\":\"\",\"duration_ms\":0,\"error\":\"badgateway: failed to receive response: dial tcp 127.0.0.1:8080: connect: connection refused\",\"level\":\"error\",\"method\":\"GET\",\"msg\":\"\",\"time\":\"2023-01-25T20:57:51Z\",\"uri\":\"\"}\n`\nDid nothing else except for adding some code in `gitlab.rb`.\nI wonder where this `dial tcp 127.0.0.1:8080` comes from?",
      "solution": "Now i figure out why i could not make it works,I mixed up Using an existing Passenger/NGINX installation and Using a non-bundled web-server\nIf you just need to use your own nginx to proxy gitlab(both of them was installed on docker)\nyou just need to add two lines to `gitlab.rb`.\n`# Disable the built-in nginx\nnginx['enable'] = false\n# Define the web server process user (ubuntu/nginx)\nweb_server['external_users'] = ['nginx']\n`\nand here is nginx's conf\n`upstream gitlab-workhorse {\n  server unix://var/opt/gitlab/gitlab-workhorse/sockets/socket fail_timeout=0;\n}\n\nserver {\n  listen *:80;\n  server_name git.example.com;\n  server_tokens off;\n  root /opt/gitlab/embedded/service/gitlab-rails/public;\n\n  client_max_body_size 250m;\n\n  access_log  /var/log/gitlab/nginx/gitlab_access.log;\n  error_log   /var/log/gitlab/nginx/gitlab_error.log;\n\n  # Ensure Passenger uses the bundled Ruby version\n  passenger_ruby /opt/gitlab/embedded/bin/ruby;\n\n  # Correct the $PATH variable to included packaged executables\n  passenger_env_var PATH \"/opt/gitlab/bin:/opt/gitlab/embedded/bin:/usr/local/bin:/usr/bin:/bin\";\n\n  # Make sure Passenger runs as the correct user and group to\n  # prevent permission issues\n  passenger_user git;\n  passenger_group git;\n\n  # Enable Passenger & keep at least one instance running at all times\n  passenger_enabled on;\n  passenger_min_instances 1;\n\n  location ~ ^/[\\w\\.-]+/[\\w\\.-]+/(info/refs|git-upload-pack|git-receive-pack)$ {\n    # 'Error' 418 is a hack to re-use the @gitlab-workhorse block\n    error_page 418 = @gitlab-workhorse;\n    return 418;\n  }\n\n  location ~ ^/[\\w\\.-]+/[\\w\\.-]+/repository/archive {\n    # 'Error' 418 is a hack to re-use the @gitlab-workhorse block\n    error_page 418 = @gitlab-workhorse;\n    return 418;\n  }\n\n  location ~ ^/api/v3/projects/.*/repository/archive {\n    # 'Error' 418 is a hack to re-use the @gitlab-workhorse block\n    error_page 418 = @gitlab-workhorse;\n    return 418;\n  }\n\n  # Build artifacts should be submitted to this location\n  location ~ ^/[\\w\\.-]+/[\\w\\.-]+/builds/download {\n      client_max_body_size 0;\n      # 'Error' 418 is a hack to re-use the @gitlab-workhorse block\n      error_page 418 = @gitlab-workhorse;\n      return 418;\n  }\n\n  # Build artifacts should be submitted to this location\n  location ~ /ci/api/v1/builds/[0-9]+/artifacts {\n      client_max_body_size 0;\n      # 'Error' 418 is a hack to re-use the @gitlab-workhorse block\n      error_page 418 = @gitlab-workhorse;\n      return 418;\n  }\n\n  # Build artifacts should be submitted to this location\n  location ~ /api/v4/jobs/[0-9]+/artifacts {\n      client_max_body_size 0;\n      # 'Error' 418 is a hack to re-use the @gitlab-workhorse block\n      error_page 418 = @gitlab-workhorse;\n      return 418;\n  }\n\n  # For protocol upgrades from HTTP/1.0 to HTTP/1.1 we need to provide Host header if its missing\n  if ($http_host = \"\") {\n  # use one of values defined in server_name\n    set $http_host_with_default \"git.example.com\";\n  }\n\n  if ($http_host != \"\") {\n    set $http_host_with_default $http_host;\n  }\n\n  location @gitlab-workhorse {\n\n    ## https://github.com/gitlabhq/gitlabhq/issues/694\n    ## Some requests take more than 30 seconds.\n    proxy_read_timeout      3600;\n    proxy_connect_timeout   300;\n    proxy_redirect          off;\n\n    # Do not buffer Git HTTP responses\n    proxy_buffering off;\n\n    proxy_set_header    Host                $http_host_with_default;\n    proxy_set_header    X-Real-IP           $remote_addr;\n    proxy_set_header    X-Forwarded-For     $proxy_add_x_forwarded_for;\n    proxy_set_header    X-Forwarded-Proto   $scheme;\n\n    proxy_pass http://gitlab-workhorse;\n\n    ## The following settings only work with NGINX 1.7.11 or newer\n    #\n    ## Pass chunked request bodies to gitlab-workhorse as-is\n    # proxy_request_buffering off;\n    # proxy_http_version 1.1;\n  }\n\n  ## Enable gzip compression as per rails guide:\n  ## http://guides.rubyonrails.org/asset_pipeline.html#gzip-compression\n  ## WARNING: If you are using relative urls remove the block below\n  ## See config/application.rb under \"Relative url support\" for the list of\n  ## other files that need to be changed for relative url support\n  location ~ ^/(assets)/ {\n    root /opt/gitlab/embedded/service/gitlab-rails/public;\n    gzip_static on; # to serve pre-gzipped version\n    expires max;\n    add_header Cache-Control public;\n  }\n\n  ## To access Grafana\n  location /-/grafana/ {\n    proxy_pass http://localhost:3000/;\n  }\n\n  error_page 502 /502.html;\n}\n`\nlast but not least,you need to add another bash to your nginx's container,\n`-v /var/opt/gitlab:/var/opt/gitlab\n`\nThis will let your nginx container connect to gitlab container.Otherwise you will get \"cannot find var/opt/gitlab/gitlab-workhorse/sockets/socket\".",
      "question_score": 7,
      "answer_score": 3,
      "created_at": "2023-01-26T01:22:36",
      "url": "https://stackoverflow.com/questions/75241243/how-to-use-nginx-deployed-with-docker-reverse-proxy-gitlab-deployed-with-dock"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 77011224,
      "title": "oauth2 proxy with Ingress nginx not passing X-Auth-Request headers during standard auth flow",
      "problem": "I'm facing an issue with oauth2 proxy and Ingress Nginx (with the latest versions) in a Kubernetes cluster where the `X-Auth-Request` headers are not being passed through to the client during the standard oauth authentication flow. I'm specifically using Azure as the auth provider.\nHere's the relevant portion of my oauth Proxy configuration:\n```\n`pass_access_token = true\npass_authorization_header = true\npass_user_headers = true\nset_xauthrequest = true\n`\n```\nWhen I explicitly call `/oauth2/auth`, I get the headers as expected. However, during the standard OAuth2 auth flow, none of the headers are returned with any request.\nThis situation is somewhat similar to another question here: Oauth2-Proxy do not pass X-Auth-Request-Groups header, but in my case, I'm not receiving any of the `X-Auth-Request` headers, except when I call `/oauth2/auth` directly.\nI've also tried adding the following snippet to my application Ingress configuration with no luck:\n```\n`nginx.ingress.kubernetes.io/configuration-snippet: |\n    auth_request_set $email $upstream_http_x_auth_request_email;\n    access_by_lua_block {\n      if ngx.var.email ~= \"\" then\n        ngx.req.set_header(\"X-Auth-Request-Email\", ngx.var.email)\n      end\n    }\n`\n```\nI've gone through multiple configurations, read numerous blog posts, and scoured GitHub issues, but haven't been able to resolve this issue. Does anyone have any insights into what could be causing this behavior?",
      "solution": "This way will work\n```\n`nginx.ingress.kubernetes.io/configuration-snippet: |\n      auth_request_set $email $upstream_http_x_auth_request_email;\n      \n      add_header X-Auth-Request-Email $email;\n`\n```\nThe only downside is that it will add the header to all the http requests, even for css/js files",
      "question_score": 7,
      "answer_score": 1,
      "created_at": "2023-08-30T22:04:31",
      "url": "https://stackoverflow.com/questions/77011224/oauth2-proxy-with-ingress-nginx-not-passing-x-auth-request-headers-during-standa"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67344108,
      "title": "websocket issue on blazor with CentOS and Nginx",
      "problem": "I am triying to deploy my blazor app (server side) into my VPS with CentOS.\nAnd the deployment went fine, i can access my website, but in the console i see the following errors:\n```\n`blazor.server.js:1 WebSocket connection to 'wss://website.com/_blazor?id=bMDvWwyNa5R5y9KsTVUS6A' failed: \n(anonymous) @ blazor.server.js:1\nblazor.server.js:1 [2021-05-01T07:33:36.170Z] Error: Failed to start the transport 'WebSockets': Error: There was an error with the transport.\ne.log @ blazor.server.js:1\n/_blazor?id=l_DDVIXzIu1Ro3zd9stUsA&_=1619854490093:1 Failed to load resource: the server responded with a status of 504 ()\nblazor.server.js:1 [2021-05-01T07:35:50.195Z] Error: Connection disconnected with error 'Error'.\n\n`\n```\nand I have no idea how to deal with them.\nAs i understand, the websocket/signalR is not being open, which means that once the website is loaded the connection is \"cut\" the problem here is that blazor does that call every minute, so i get a message saying `attempting to reconnect to the server` and it does it. but the website is unusable for 5-secods ish.\nIn order to fix this i tried multiple solutions I saw online:\nin the project: set up `services.AddSignalR()` and `app.UseWebSockets()` and it didnt work.\nI thought as well that it could be nginx (and probably is) then i found this:\nhttps://www.nginx.com/blog/websocket-nginx/\nand\nhttps://learn.microsoft.com/en-us/aspnet/core/blazor/host-and-deploy/server?view=aspnetcore-5.0#linux-with-nginx\nbut it seems not to be working:\n```\n`map $http_upgrade $connection_upgrade {\n        default upgrade;\n        '' close;\n    }\n\nserver {\n    server_name website.com;\n\n    location / {\n        proxy_pass         http://localhost:5201;\n        proxy_http_version 1.1; # added from ms documentation\n        proxy_set_header   Upgrade $http_upgrade;\n        proxy_set_header   Connection $http_upgrade;\n        proxy_set_header   Host $host;\n        proxy_cache_bypass $http_upgrade;\n        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header   X-Forwarded-Proto $scheme;\n    }\n\n    listen 443 http2 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/website.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/website.com/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n}\n`\n```\nEDIT:\nI have this as well in the nginx file\n```\n`server{\nif ($host = website.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n    server_name website.com ;\n    listen 80 ;\n    return 404;\n}\n\n`\n```\nEDIT2: I am runnning the version 1.20 on nginx\nAny idea which part of the connection can be wrong?\nThanks.",
      "solution": "Found the issue, in the line of `proxy_set_header   Connection $http_upgrade;`\nChange it for:\n`proxy_set_header Connection \"upgrade\";`\nNot sure why it works when hardcoding the value, but it does.",
      "question_score": 6,
      "answer_score": 13,
      "created_at": "2021-05-01T10:00:37",
      "url": "https://stackoverflow.com/questions/67344108/websocket-issue-on-blazor-with-centos-and-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66261553,
      "title": "Nginx logs are not shown",
      "problem": "I have a docker running nginx with port forward to 8080\nAll I want is to see the logs in nginx when I hit\n```\n`curl http://localhost:8080\n`\n```\n(I get an answer but I want to see logs)\nBoth access.log and error.log and enabled from /etc/nginx/nginx.conf\n```\n`user  nginx;\nworker_processes  1;\n\nerror_log  /var/log/nginx/error.log warn;\npid        /var/run/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log  /var/log/nginx/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n`\n```\nNeither tail -f  access.log nor cat access.log works. All I get is an empty line:\n```\n`root@fe0f47477548:/var/log/nginx# cat access.log\n\n^C\nroot@fe0f47477548:/var/log/nginx#\n`\n```",
      "solution": "The NGINX docker distribution redirects (`soft links`) logging to the stdout/stderr\n```\n`lrwxrwxrwx 1 root root 11 Feb 17 19:20 access.log -> /dev/stdout\nlrwxrwxrwx 1 root root 11 Feb 17 19:20 error.log -> /dev/stderr\n`\n```\nFrom Docker host\nYou can access the logs using Docker logs\n```\n`docker logs nginx\n`\n```\nFrom inside the Docker container\nIt is possible to remove the log forwarding which is defined in the standard NGINX Docker Image.\nThis requires creating a custom Dockerfile (ie `mynginx`) but it is a simple change\n```\n`FROM nginx:latest\n\n# drop symlinks\nRUN unlink /var/log/nginx/access.log\nRUN unlink /var/log/nginx/error.log\n`\n```\nWhen running the newly defined container the log files can be seen in `/var/logs/nginx`\n```\n`-rw-r--r-- 1 root root 491 Feb 19 13:14 access.log\n-rw-r--r-- 1 root root 0 Feb 19 13:14 error.log\n\nroot@ca2472f28be5:/var/log/nginx# cat access.log\n72.25.0.1 - - [19/Feb/2021:13:15:55 +0000] \"GET \n/static/js/main.f81cbe58.chunk.js HTTP/1.1\" 304 0 \"http://localhost/\" \n\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 \n(KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36\" \"-\"\n`\n```",
      "question_score": 6,
      "answer_score": 16,
      "created_at": "2021-02-18T15:01:49",
      "url": "https://stackoverflow.com/questions/66261553/nginx-logs-are-not-shown"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 68761944,
      "title": "Using Element and Split Gets First Item Rather than Last Item in Terraform",
      "problem": "We're trying to apply a dynamic name to a firewall rule for opening 8089 and 8843 in GCP using terraform based on the list of instance group urls. Instead of taking that result and giving us the last item in the url, it gives us https:\ntf:\n```\n`#This is to resolve an error when deploying to nginx\n  resource \"google_compute_firewall\" \"ingress\" {\n  for_each      = toset(google_container_cluster.standard-cluster.instance_group_urls)\n  description   = \"Allow traffic on ports 8843, 8089 for  nginx ingress\"\n  direction     = \"INGRESS\"\n  name          = element(split(\"/\", each.key), length(each.key))\n  network       = \"https://www.googleapis.com/compute/v1/projects/${local.ws_vars[\"project-id\"]}/global/networks/${local.ws_vars[\"environment\"]}\"\n  priority      = 1000\n  source_ranges = google_container_cluster.standard-cluster.private_cluster_config.*.master_ipv4_cidr_block\n  target_tags = [\n    element(split(\"/\", each.key), length(each.key))\n  ]\n\n  allow {\n    ports = [\n      \"8089\",\n    ]\n    protocol = \"tcp\"\n  }\n  allow {\n    ports = [\n      \"8443\",\n    ]\n    protocol = \"tcp\"\n  }\n}\n`\n```\nResult:\n```\n`    Error: \"name\" (\"https:\") doesn't match regexp \"^(?:[a-z](?:[-a-z0-9]{0,61}[a-z0-9])?)$\"\n\n  on main.tf line 133, in resource \"google_compute_firewall\" \"ingress\":\n 133:   name          = element(split(\"/\", each.key), length(each.key))\n`\n```\nWhat is the solution here? Why is it not giving the last item in the array? Is there a better way?",
      "solution": "Like with many languages, Terraform/HCL uses zero based indexing so if you want the last element in an array you need to subtract one from the length like this:\n```\n`locals {\n  list = [\"foo\", \"bar\", \"baz\"]\n}\n\noutput \"last_element\" {\n  value = element(local.list, length(local.list) - 1)\n}\n`\n```\nThe `element` function is causing this confusion because instead of getting an out of bounds/range error when you attempt to access beyond the length of the list it wraps around and so you are getting the first element:\n\nThe index is zero-based. This function produces an error if used with\nan empty list. The index must be a non-negative integer.\nUse the built-in index syntax list[index] in most cases. Use this\nfunction only for the special additional \"wrap-around\" behavior\ndescribed below.\n\nTo get the last element from the list use length to find the size of\nthe list (minus 1 as the list is zero-based) and then pick the last\nelement:\n```\n`> element([\"a\", \"b\", \"c\"], length([\"a\", \"b\", \"c\"])-1)\nc\n`\n```\n\nUnfortunately, at the time of writing, Terraform doesn't currently support negative indexes in the built-in index syntax:\n```\n`locals {\n  list = [\"foo\", \"bar\", \"baz\"]\n}\n\noutput \"last_element\" {\n  value = local.list[-1]\n}\n`\n```\nthrows the following error:\n```\n`Error: Invalid index\n\n  on main.tf line 6, in output \"last_element\":\n   6:   value = local.list[-1]\n    |----------------\n    | local.list is tuple with 3 elements\n\nThe given key does not identify an element in this collection value.\n`\n```\nAs suggested in the comments, a better approach here would be to first reverse the list and then take the first element from the reversed list using the `reverse` function:\n```\n`output \"last_element\" {\n  value = reverse(local.list)[0]\n}\n`\n```",
      "question_score": 6,
      "answer_score": 14,
      "created_at": "2021-08-12T19:33:53",
      "url": "https://stackoverflow.com/questions/68761944/using-element-and-split-gets-first-item-rather-than-last-item-in-terraform"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69774596,
      "title": "Ingress not binding to Load Balancer",
      "problem": "I have my A record on Netlify mapped to my Load Balancer IP Address on Digital Ocean, and it's able to hit the nginx server, but I'm getting a 404 when trying to access any of the apps APIs. I noticed that the status of my Ingress doesn't show that it is bound to the Load Balancer.\n\nDoes anybody know what I am missing to get this setup?\nApplication Ingress:\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: d2d-server\nspec:\n  rules:\n    - host: api.cloud.myhostname.com\n      http:\n        paths:\n          - backend:\n              service:\n                name: d2d-server\n                port:\n                  number: 443\n            path: /\n            pathType: ImplementationSpecific\n`\nApplication Service:\n`apiVersion: v1\nkind: Service\nmetadata:\n  name: d2d-server\nspec:\n  selector:\n    app: d2d-server\n  ports:\n    - name: http-api\n      protocol: TCP\n      port: 443\n      targetPort: 8080\n  type: ClusterIP\n`\nIngress Controller:\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: ingress-nginx-controller\n  namespace: ingress-nginx\n  uid: fc64d9f6-a935-49b2-9d7a-b862f660a4ea\n  resourceVersion: '257931'\n  generation: 1\n  creationTimestamp: '2021-10-22T05:31:26Z'\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/version: 1.0.4\n    helm.sh/chart: ingress-nginx-4.0.6\n  annotations:\n    deployment.kubernetes.io/revision: '1'\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/instance: ingress-nginx\n      app.kubernetes.io/name: ingress-nginx\n  template:\n    metadata:\n      creationTimestamp: null\n      labels:\n        app.kubernetes.io/component: controller\n        app.kubernetes.io/instance: ingress-nginx\n        app.kubernetes.io/name: ingress-nginx\n    spec:\n      volumes:\n        - name: webhook-cert\n          secret:\n            secretName: ingress-nginx-admission\n            defaultMode: 420\n      containers:\n        - name: controller\n          image: >-\n            k8s.gcr.io/ingress-nginx/controller:v1.0.4@sha256:545cff00370f28363dad31e3b59a94ba377854d3a11f18988f5f9e56841ef9ef\n          args:\n            - /nginx-ingress-controller\n            - '--publish-service=$(POD_NAMESPACE)/ingress-nginx-controller'\n            - '--election-id=ingress-controller-leader'\n            - '--controller-class=k8s.io/ingress-nginx'\n            - '--configmap=$(POD_NAMESPACE)/ingress-nginx-controller'\n            - '--validating-webhook=:8443'\n            - '--validating-webhook-certificate=/usr/local/certificates/cert'\n            - '--validating-webhook-key=/usr/local/certificates/key'\n          ports:\n            - name: http\n              containerPort: 80\n              protocol: TCP\n            - name: https\n              containerPort: 443\n              protocol: TCP\n            - name: webhook\n              containerPort: 8443\n              protocol: TCP\n          env:\n            - name: POD_NAME\n              valueFrom:\n                fieldRef:\n                  apiVersion: v1\n                  fieldPath: metadata.name\n            - name: POD_NAMESPACE\n              valueFrom:\n                fieldRef:\n                  apiVersion: v1\n                  fieldPath: metadata.namespace\n            - name: LD_PRELOAD\n              value: /usr/local/lib/libmimalloc.so\n          resources:\n            requests:\n              cpu: 100m\n              memory: 90Mi\n          volumeMounts:\n            - name: webhook-cert\n              readOnly: true\n              mountPath: /usr/local/certificates/\n          livenessProbe:\n            httpGet:\n              path: /healthz\n              port: 10254\n              scheme: HTTP\n            initialDelaySeconds: 10\n            timeoutSeconds: 1\n            periodSeconds: 10\n            successThreshold: 1\n            failureThreshold: 5\n          readinessProbe:\n            httpGet:\n              path: /healthz\n              port: 10254\n              scheme: HTTP\n            initialDelaySeconds: 10\n            timeoutSeconds: 1\n            periodSeconds: 10\n            successThreshold: 1\n            failureThreshold: 3\n          lifecycle:\n            preStop:\n              exec:\n                command:\n                  - /wait-shutdown\n          terminationMessagePath: /dev/termination-log\n          terminationMessagePolicy: File\n          imagePullPolicy: IfNotPresent\n          securityContext:\n            capabilities:\n              add:\n                - NET_BIND_SERVICE\n              drop:\n                - ALL\n            runAsUser: 101\n            allowPrivilegeEscalation: true\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 300\n      dnsPolicy: ClusterFirst\n      nodeSelector:\n        kubernetes.io/os: linux\n      serviceAccountName: ingress-nginx\n      serviceAccount: ingress-nginx\n      securityContext: {}\n      schedulerName: default-scheduler\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxUnavailable: 25%\n      maxSurge: 25%\n  revisionHistoryLimit: 10\n  progressDeadlineSeconds: 600\n\n`\nLoad Balancer:\n`apiVersion: v1\nkind: Service\nmetadata:\n  name: ingress-nginx-controller\n  namespace: ingress-nginx\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/version: 1.0.4\n    helm.sh/chart: ingress-nginx-4.0.6\n  annotations:\n    kubernetes.digitalocean.com/load-balancer-id: \n    service.beta.kubernetes.io/do-loadbalancer-enable-proxy-protocol: 'true'\n    service.beta.kubernetes.io/do-loadbalancer-name: ingress-nginx\n    service.beta.kubernetes.io/do-loadbalancer-protocol: https\nstatus:\n  loadBalancer:\n    ingress:\n      - ip: \nspec:\n  ports:\n    - name: http\n      protocol: TCP\n      appProtocol: http\n      port: 80\n      targetPort: http\n      nodePort: 31661\n    - name: https\n      protocol: TCP\n      appProtocol: https\n      port: 443\n      targetPort: https\n      nodePort: 32761\n  selector:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/name: ingress-nginx\n  clusterIP: \n  clusterIPs:\n    - \n  type: LoadBalancer\n  sessionAffinity: None\n  externalTrafficPolicy: Local\n  healthCheckNodePort: 30477\n  ipFamilies:\n    - IPv4\n  ipFamilyPolicy: SingleStack\n\n`",
      "solution": "I just needed to add the field `ingressClassName` of `nginx` to the ingress spec.",
      "question_score": 6,
      "answer_score": 11,
      "created_at": "2021-10-29T22:46:27",
      "url": "https://stackoverflow.com/questions/69774596/ingress-not-binding-to-load-balancer"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66951971,
      "title": "How to get Puma and Nginx to run in Rails production?",
      "problem": "Fighting for months with this, another new career path blooming every week, it seems, I look down.\nSo, that said. Here's the closest I've come. I had it working several times, but it's so brittle as I'm more a developer than a devops (?) person.\nI am running Ubuntu 20.04.\n```\n`be puma -C config/puma.rb config.ru -e production \\\n  --pidfile /run/puma.pid \\\n  --control-url 'unix:///root/mysite/tmp/sockets/mysite-puma.sock' \\\n  --control-token 'app' \\\n  --state tmp/puma.state \\\n  -b 'tcp://mysite.com'\n`\n```\nI can run `pumactl` as so: `bundle exec pumactl -T 'app' -C 'unix:///root/mysite/tmp/sockets/mysite-puma.sock' -S tmp/puma.state [pumactl switch]`\nMy nginx config.\n/etc/nginx/nginx.conf\n```\n`user www-data;\nworker_processes auto;\n\npid /run/nginx.pid;\n\ninclude /etc/nginx/modules-enabled/*.conf;\n\nevents {\n    worker_connections 1024;\n    multi_accept on;\n}\n\nhttp {\n\n    ##\n    # Basic Settings\n    ##\n\n        sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 65;\n    types_hash_max_size 2048;\n    # server_tokens off;\n\n    # server_names_hash_bucket_size 64;\n    # server_name_in_redirect off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    ##\n    # SSL Settings\n    ##\n\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE\n    ssl_prefer_server_ciphers on;\n\n    ##\n    # Logging Settings\n    ##\n\n    access_log /var/log/nginx/access.log;\n    error_log /var/log/nginx/error.log;\n\n    ##\n    # Gzip Settings\n    ##\n\n    gzip off;\n\n    gzip_vary off;\n    #gzip_proxied any;\n    #gzip_comp_level 6;\n    #gzip_buffers 16 8k;\n    #gzip_http_version 1.1;\n    #gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;\n\n    ##\n    # Virtual Host Configs\n    ##\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/mysite.com;\n}\n`\n```\n/etc/nginx/sites-enabled/mysite.com\n```\n`# This configuration uses Puma. If using another rack server, substitute appropriate values throughout.\nupstream puma {\n  server unix:///root/mysite/tmp/sockets/mysite.sock;\n}\n\n# We need to be listing for port 80 (HTTP traffic). \n# The force_ssl option will redirect to port 443 (HTTPS)\nserver {\n\n  # Update this\n  server_name mysite.com www.mysite.com;\n\n  # Don't forget to update these, too.\n  # For help with setting this part up, see:\n  # http://localhost:4000/2018/09/18/deploying-ruby-on-rails-for-ubuntu-1804.html\n  root        /root/mysite/public;\n  access_log  /root/mysite/log/nginx.access.log;\n  error_log   /root/mysite/log/nginx.error.log info;\n\n  location ^~ /assets/ {\n    gzip_static on;\n    expires max;\n    add_header Cache-Control public;\n  }\n\n  try_files $uri/index.html $uri @puma;\n\n  location @puma {\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header Host $http_host;\n    proxy_redirect off;\n\n    proxy_pass http://puma;\n  }\n\n}\n\n  # This is the configuration for port 443 (HTTPS)\n  server {\n\n    listen [::]:443 ssl ipv6only=on; # managed by Certbot\n\n    server_name mysite.com www.mysite.com;\n    \n    ssl_certificate       /etc/letsencrypt/live/mysite.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key   /etc/letsencrypt/live/mysite.com/privkey.pem;   # managed by Certbot\n    include               /etc/letsencrypt/options-ssl-nginx.conf;          # managed by Certbot\n    ssl_dhparam           /etc/letsencrypt/ssl-dhparams.pem;                # managed by Certbot\n\n    # Don't forget to update these, too.\n    # I like to update my log files to include 'ssl' in the name.\n    # If there's ever any need to consult the logs, it's handy to have HTTP and HTTPS traffic separated.\n    root        /root/mysite/public;\n    access_log  /root/mysite/log/nginx.ssl.access.log;      # Updated file name\n    error_log   /root/mysite/log/nginx.ssl.error.log info;  # Updated file name\n\n    error_page 500 502 503 504 /500.html;\n    client_max_body_size 10M;   \n    \n    location ^~ /assets/ {\n      gzip_static off;\n      expires max;\n      add_header Cache-Control public;\n    }\n\n    try_files $uri/index.html $uri @puma;\n    location @puma {\n       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n       # This is an important line to help fix some redirect issues.\n       proxy_set_header X-Forwarded-Proto https; \n    \n       proxy_set_header Host $http_host;\n       proxy_redirect off;\n\n       proxy_pass http://puma;\n     }\n  }\n\n  # If you chose Certbot to redirect all traffic to HTTPS, this will be in your current config. \n  # Remove it or you'll run into redirection errors:\n  server {\n   if ($host = example.com) {\n      return 301 https://www.example.com$request_uri;\n   } # managed by Certbot\n \n \n    listen [::]:80 default_server deferred;\n    server_name example.com;\n    return 404; # managed by Certbot\n \n}\n\n`\n```",
      "solution": "First thing first, in your /etc/nginx/sites-enabled/mysite.com\nFirst step\nchange\n```\n`upstream puma {\n  server unix:///root/mysite/tmp/sockets/mysite.sock;\n}\n`\n```\nto\n```\n`upstream puma {\n  server 0.0.0.0:9838; # port number in which your puma server starts\n}\n`\n```\nAfter changing your /etc/nginx/sites-enabled/mysite.com It should look like the following.\n```\n`upstream puma {\n  server 0.0.0.0:9838;\n}\n\nserver {\n    server_name  mysite.com www.mysite.com;\n    client_max_body_size 200m;\n    gzip             on;\n    gzip_comp_level  4;\n    gzip_min_length  1000;\n    gzip_proxied     expired no-cache no-store private auth;\n    gzip_types       text/plain application/javascript application/json application/x-javascript text/xml text/css application/xml text/javascript;\n\n    root /root/mysite/public;\n\n    location / {\n      try_files $uri/index.html $uri @app;\n    }\n\n    location  ~* ^/assets {\n      root /root/mysite/public;\n      expires 1y;\n      add_header Cache-Control public;\n      add_header Last-Modified \"\";\n      add_header ETag \"\";\n      break;\n    }\n\n    error_page 500 502 503 504 /500.html;\n\n    location @app {\n      proxy_pass http://puma;\n\n      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n      proxy_set_header X-Forwarded-Proto $scheme;\n      proxy_set_header X-Forwarded-Proto https;\n      proxy_set_header Host $http_host;\n      proxy_redirect off;\n    }\n\n    location ~ /.well-known {\n      allow all;\n    }\n\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/mysite.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/mysite.com/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n}\n\nserver {\n    if ($host = mysite.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n    if ($host = www.mysite.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n    server_name  mysite.com www.mysite.com;\n    listen 80;\n    return 404; # managed by Certbot\n}\n`\n```\nSecond step\nThen run `gem install foreman` to install foreman library. To know more about foreman click here.\nThird step\nCreate `Procfile` in your project root directory and paste the below content\n```\n`web: RAILS_ENV=production bundle exec puma -e  production -p 9838 -d -S  ~/puma -C config/puma.rb\n`\n```\nFinal step\nRun `foreman start` to start the puma server and there you go, you will be able to see your application running.",
      "question_score": 6,
      "answer_score": 9,
      "created_at": "2021-04-05T13:01:55",
      "url": "https://stackoverflow.com/questions/66951971/how-to-get-puma-and-nginx-to-run-in-rails-production"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 73874334,
      "title": "Kubernetes Ingress-nginx CORS: How to allow multiple Origins?",
      "problem": "It's currently possible to allow a single domain or subdomain but I would like to allow multiple origins. I have tried many things like adding headers with snipets but had no success.\nThis is my current ingress configuration:\n```\n`kind: Ingress\napiVersion: extensions/v1beta1\nmetadata:\n  name: nginx-ingress\n  namespace: default\n  selfLink: /apis/extensions/v1beta1/namespaces/default/ingresses/nginx-ingress\n  uid: adcd75ab-b44b-420c-874e-abcfd1059592\n  resourceVersion: '259992616'\n  generation: 7\n  creationTimestamp: '2020-06-10T12:15:18Z'\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    ingress.kubernetes.io/enable-cors: 'true'\n    ingress.kubernetes.io/force-ssl-redirect: 'true'\n    kubernetes.io/ingress.class: nginx\n    kubernetes.io/tls-acme: 'true'\n    nginx.ingress.kubernetes.io/cors-allow-credentials: 'true'\n    nginx.ingress.kubernetes.io/cors-allow-headers: 'Authorization, X-Requested-With, Content-Type'\n    nginx.ingress.kubernetes.io/cors-allow-methods: 'GET, PUT, POST, DELETE, HEAD, OPTIONS'\n    nginx.ingress.kubernetes.io/cors-allow-origin: 'https://example.com'\n    nginx.ingress.kubernetes.io/enable-cors: 'true'\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    nginx.ingress.kubernetes.io/secure-backends: 'true'\n`\n```\nI also would like to extend the cors-allow-origin like:\n```\n`nginx.ingress.kubernetes.io/cors-allow-origin: 'https://example.com, https://otherexample.com'\n`\n```\nIs it possible to allow multiple domains in other ways?",
      "solution": "A some time ago, ingress-nginx allows multiple origins. See issue https://github.com/kubernetes/ingress-nginx/issues/5496\nExample of usage:\n```\n`nginx.ingress.kubernetes.io/cors-allow-origin: \"https://example.com, https://another.com, http://localhost:8000\"\n`\n```",
      "question_score": 6,
      "answer_score": 6,
      "created_at": "2022-09-28T00:22:49",
      "url": "https://stackoverflow.com/questions/73874334/kubernetes-ingress-nginx-cors-how-to-allow-multiple-origins"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67894298,
      "title": "Verify Keycloak token from two different URLs",
      "problem": "I have a `Docker compose` based system with back-end and front-end components. The back-end is written in `Python Flask` and run in several docker containers and front-end is written in `TypeScript` with `Angular`. The front-end communicates with back-end via Restful APIs. The proxy is created with `Nginx`. But the `Keycloak` Token verification doesn't work between front-end and back-end.\nMy `KeyCloak` (and `MySQL`) section of `docker-compose.yml` file:\n```\n`  mysql:\n    image: mysql:5.7.31\n    ports:\n      - 9988:3306\n    volumes:\n      - keycloak_data:/var/lib/mysql\n    environment:\n      MYSQL_ROOT_PASSWORD: root\n      MYSQL_DATABASE: keycloak\n      MYSQL_USER: keycloak\n      MYSQL_PASSWORD: password\n    networks:\n      - auth_net\n\n  keycloak:\n    image: jboss/keycloak:13.0.1\n    environment:\n      DB_VENDOR: MYSQL\n      DB_ADDR: mysql\n      DB_DATABASE: keycloak\n      DB_USER: keycloak\n      DB_PASSWORD: password\n      KEYCLOAK_USER: admin\n      KEYCLOAK_PASSWORD: admin\n      PROXY_ADDRESS_FORWARDING: \"true\"\n    ports:\n      - 8080:8080\n      - 8443:8443\n    depends_on:\n      - mysql\n    networks:\n      - auth_net\n`\n```\nRelated `Nginx` config part:\n```\n`    location /api/auth/verify {\n        internal;\n        proxy_method POST;\n        proxy_intercept_errors on;\n        proxy_pass http://keycloak:8080/auth/realms/master/protocol/openid-connect/userinfo;\n        error_page 400 =401 /401.html;\n    }\n`\n```\nI use the above `/api/auth/verify` URL for every endpoints as verification. Eg.:\n```\n`    location /api/users {\n        auth_request /api/auth/verify;\n        rewrite ^/api/(.*) /$1  break;\n        proxy_pass http://users:6000;\n        proxy_pass_request_headers on;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n`\n```\nMy `Keycloak` config for `TypeScript`/`Angular`:\n```\n`export const environment = {\n  production: false,\n  keycloakConfig: {\n    url: 'http://localhost:8080/auth/',\n    realm: 'master',\n    clientId: 'frontend'\n  }\n};\n`\n```\n`app-init.ts`:\n```\n`import { KeycloakService, KeycloakOptions } from 'keycloak-angular';\nimport { environment } from 'src/environments/environment';\n\nexport function initializer(keycloak: KeycloakService): () => Promise {\n  const options: KeycloakOptions = {\n    config: environment.keycloakConfig\n  };\n\n  return (): Promise => keycloak.init(options);\n}\n`\n```\nMy `app.module.ts` file contains the following section:\n```\n`  providers: [\n    KeycloakService,\n    {\n      provide: APP_INITIALIZER,\n      useFactory: initializer,\n      multi: true,\n      deps: [KeycloakService]\n    }\n  ]\n`\n```\nThe getting error:\n\nConfig of `frontend` client in `Keycloak`:\n\nMy problem in points:\n\nThe `Nginx` uses the `http://keycloak:8080` URL which is the network inside the docker system (The `Nginx` doesn't see the `localhost` from `Docker`).\nThe front-end (`TS`/`Angular`) uses the `http://localhost:8080` URL which is visible from outside (from the users' browser) (In theory the front-end doesn't see the `keycloak` network from user's browser)\nWhen I send a request from front-end which calls my API (which want to verify the token based on above `Nginx` example), I get `Invalid Token` error\nBased on my investigation I get this error because I get the token on `http://localhost:8080` URL and I want to verify it on `http://keycloak:8080` URL.\n\nSummarize of my used URLs:\n\nAPI's URL: `http://localhost`\nKeycloak URL inside Docker: `http://keycloak:8080`\nKeycloak on front-end side: `http://localhost:8080`\nFornt-end's URL : `http://localhost:4200`\n\nMy question:\n\nHow can I solve the above problem? I am very open for ideas.\n\n1. EDIT:\nIf I have tried to set the front-end URL to `http://localhost:8080`, and `http://localhost:4200` but I got the below issue in both cases:",
      "solution": "I have just found the solution!\nThe `Frontend URL` parameter is a quite misleading in the `Keycloak` general configuration. My front-end is on `http://localhost:4200` URL but as I mentioned in my question that URL wasn't working as front-end URL parameter in Keycloak (I have tested is many times).\nAs you can see in my question in the configuration of `keycloak-angular` module the `Keycloak` URL is set as `url: 'http://localhost:8080/auth/'`. If I set that URL as `Frontend URL` parameter in the `Keycloak` general configuration (or as input parameter in `docker-compose.yml` file) my system works as charm.\n\nNote:\n\nThe base URL (`http://localhost:8080`) is not enough so the `/auth` suffix is also needed (The full URL which is working: `http://localhost:8080/auth/`).",
      "question_score": 6,
      "answer_score": 6,
      "created_at": "2021-06-08T22:40:39",
      "url": "https://stackoverflow.com/questions/67894298/verify-keycloak-token-from-two-different-urls"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67737069,
      "title": "How to host a Flask app on a subfolder / URL prefix with Nginx?",
      "problem": "I have a flask app which I want to host it on a subfolder of a website, like `example.com/cn`.\nI configured my nginx like\n```\n`location /cn {\n    proxy_pass http://localhost:8000/;\n}\n`\n```\nSo if I access `example.com/cn`, It will redirect to the index page of flask.\nHowever, I have wrote the routes of other pages on flask like `app.route('/a')`. So if I click the link of page `a`, the URI is `example.com/a`, then `nginx` cannot redirect it to the right \u200bpage.\n\u200bI think I can rewrite all the routes on flask like `app.route('/cn/a')`, but it's complex. And if someday I want to deploy it on `example.com/en`, I think I need to rewrite all the routes again.\nDoes anyone have other methods?",
      "solution": "You need to add APPLICATION_ROOT params to your flask app:\n```\n`from flask import Flask, url_for\nfrom werkzeug.serving import run_simple\nfrom werkzeug.wsgi import DispatcherMiddleware\n\napp = Flask(__name__)\napp.config['APPLICATION_ROOT'] = '/cn'\n`\n```\nif you need to host more than one application on your server, you can configure nginx to redirect all request to your specific flask app served by gunicorn like this. (it is not necessary if your server hosts only one application) Find out more about gunicorn and nginx here: https://docs.gunicorn.org/en/stable/deploy.html\n```\n`server {\n    listen 8000;\n    server_name example.com;\n\n    proxy_intercept_errors on;\n    fastcgi_intercept_errors on;\n\n    location / {\n        include proxy_params;\n        proxy_pass http://unix:/path_to_example_flask_app_1/app.sock;\n    }\n\n    location /cn/{\n        include proxy_params;\n        proxy_pass http://unix:/path_to_example_flask_app_cn/app.sock;\n    }\n}\n\n`\n```\nserve flask app with gunicorn:\nA complete exmaple here: https://www.digitalocean.com/community/tutorials/how-to-serve-flask-applications-with-gunicorn-and-nginx-on-ubuntu-18-04\n```\n`#move into project directory\n/path_to_gunicorn/gunicorn --workers 3 --bind unix:app.sock -m 007 run:app\n`\n```\nIf you are using flask_restful instead, you can specify the root path also in the following way:\n```\n`from flask import Flask\nfrom flask_restful import Api\n\napp = Flask(__name__)\napp.debug = False\napi = Api(app, prefix='/cn')\n\napi.add_resource(ResourceClass, '/example_path') #will be served when the resource is requested at path /cn/example_path\n\nif __name__ == '__main__':\n    app.run(host=\"0.0.0.0\", port=8000)\n`\n```",
      "question_score": 6,
      "answer_score": 3,
      "created_at": "2021-05-28T12:19:13",
      "url": "https://stackoverflow.com/questions/67737069/how-to-host-a-flask-app-on-a-subfolder-url-prefix-with-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66312816,
      "title": "NGINX shows &quot;bad gateway&quot; when upstream server restart and not back to normal",
      "problem": "Every time when I'm restart the upstream server, my NGINX shows \"bad gateway\" which is ok, but later, when the upstream server restarts nginx not recover automatically and I need to restart it (the nginx) manually.\nIs there an option to make nginx to check every few seconds if the upstream backed to normal?\n```\n`    upstream core {\n\n    server core:3001;\n}\n\nserver {\n    server_name core.mydomain.com corestg.mydomain.com www.core.mydomain.com;\n\n    #listen 80;\n    #listen [::]:80;\n\n    gzip on;\n    gzip_static on;    \n    gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript application/javascript;\n    gzip_proxied  any;\n    #gzip_vary on;\n    gzip_comp_level 6;\n    gzip_buffers 16 8k;\n    gzip_http_version 1.1;    \n     listen 443 ssl http2;\n     listen [::]:443 ssl http2;\n\n    resolver 8.8.8.8 8.8.4.4 valid=300s;\n    resolver_timeout 5s;\n\n    server_tokens off;\n    ssl_certificate /etc/ssl/domain.crt;\n    ssl_certificate_key /etc/ssl/domain.rsa; \n\n    error_log  /var/log/nginx/error.log;\n    access_log /var/log/nginx/access.log;\n\n    location / {\n        proxy_ssl_session_reuse off;\n        proxy_pass http://core;\n        proxy_buffers 8 24k;\n        proxy_buffer_size 2k;\n        proxy_http_version 1.1;\n        proxy_ignore_headers X-Accel-Expires Expires Cache-Control;\n        proxy_ignore_headers Set-Cookie;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto https;\n        proxy_set_header X-NginX-Proxy true;\n#       proxy_set_header Host $http_host;\n        proxy_set_header Host $host;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_cache_bypass $http_upgrade;\n        proxy_redirect off;\n    }\n}\n`\n```",
      "solution": "Seems that NGINX does not do the auto recovery by default.\nChanging the config part from:\n```\n`upstream core {\n    server core:3001;\n}\n`\n```\nto:\n```\n`{\n    server core:3001  max_fails=1 fail_timeout=1s;\n    server core:3001  max_fails=1 fail_timeout=1s;\n}\n`\n```\ndid the trick. the duplication is not mistake. Nginx tries to resolve the first line, on failure it will try the second one (circularly).",
      "question_score": 6,
      "answer_score": 6,
      "created_at": "2021-02-22T10:13:05",
      "url": "https://stackoverflow.com/questions/66312816/nginx-shows-bad-gateway-when-upstream-server-restart-and-not-back-to-normal"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 65761874,
      "title": "How do I configure proxy_pass on NGINX for PostgreSQL?",
      "problem": "I have a PostgreSQL server started at a remote machine on the port 15432. I want to configure NGINX to make the database available remotely by host db.domain.my and port 5432. The configuration I tried is:\n```\n`server {\n    listen 5432;\n    server_name db.domain.my;\n\n    location / {\n        proxy_pass http://127.0.0.1:15432/;\n    }\n}\n`\n```\nWhen I try to connect the database remotely with psql I get the error:\n```\n`$ psql -h db.domain.my -U myuser\npsql: received invalid response to SSL negotiation: H\n`\n```\nI also tried to add ssl word after `listen 5432` without any success.\nHow do I configure NGINX correctly?",
      "solution": "Maybe remove `http://` because it is a TCP connection (not a HTTP connection) and add `so_keepalive=on` to `listen 5432;` so the connection stays open.\nMaybe you have to use `stream` instead of `http` block: https://docs.nginx.com/nginx/admin-guide/load-balancer/tcp-udp-load-balancer/",
      "question_score": 6,
      "answer_score": 6,
      "created_at": "2021-01-17T15:32:10",
      "url": "https://stackoverflow.com/questions/65761874/how-do-i-configure-proxy-pass-on-nginx-for-postgresql"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67029960,
      "title": "HTTPS with nginx, fastAPI, docker",
      "problem": "I'm using nginx for my FARM stack app. I'm running into an issue with my APIs not going through HTTPS it works on HTTP. I've tried removing the server 80 block still getting the same issue.\nHere's the error\n```\n`docker-fastapi    | [2021-04-10 01:02:36 +0000] [9] [WARNING] Invalid HTTP request received. proxy-app         | 2021/04/10 01:02:36 [error] 22#22: *15 peer closed connection in SSL handshake while SSL handshaking to upstream, client: 192.168.249.11, server: xxxx, request: \"GET /api/ HTTP/1.1\", upstream: \"https://192.168.160.2:8080/api/\", host: \"xxx\"\n`\n```\nHeres the nginx conf file\n```\n`upstream docker_fastapi {\n    server docker-fastapi:8080;\n}\n\nserver {\n    listen 80;\n\n    location ~ /api/ {\n        proxy_pass http://docker_fastapi;\n        proxy_set_header   Host $host;\n        proxy_set_header   X-Real-IP $remote_addr;\n        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header   X-Forwarded-Host $server_name;\n    }\n\n    location / {\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n        try_files $uri $uri/ /index.html;\n    }\n\n    error_page   500 502 503 504  /50x.html;\n\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n}\n\nserver {\n    listen 443 ssl default_server;\n    server_name xxxx;\n    client_max_body_size 12m;\n    listen [::]:443 ssl http2;\n    ssl_certificate /etc/ssl/nginx.crt;\n    ssl_certificate_key /etc/ssl/nginx.key;\n    server_tokens off;\n    add_header X-Frame-Options sameorigin always;\n    add_header X-Content-Type-Options nosniff;\n    add_header Cache-Control \"no-cache\";\n    add_header X-XSS-Protection \"1; mode=block\";\n    add_header Set-Cookie \"lcid=1043; Max-Age=60\";\n\n    ssl_protocols TLSv1.2;\n    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384;\n    ssl_prefer_server_ciphers off;\n\n    location / {\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n        try_files $uri $uri/ /index.html;\n    }\n\n    location ~ /api/ {\n        proxy_pass https://docker_fastapi;\n        proxy_set_header   Host $host;\n        proxy_set_header   X-Real-IP $remote_addr;\n        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header   X-Forwarded-Host $server_name;\n        proxy_ssl_server_name on;\n    }\n\n    error_page   500 502 503 504  /50x.html;\n\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n}\n`\n```\nI pretty much copied this repo to try to get HTTPS to work\nhttps://github.com/geekyjaat/fastapi-react",
      "solution": "Currently, your proxy passes the request to your API at https://192.168.160.2:8080/api/. However, the HTTPS certificate relies on the domain name. When you use an IP address, there will be an error about SSL connection between Nginx and upstream as you can see in the log :\n```\n`closed connection in SSL handshake while SSL handshaking to upstream\n`\n```\nYou can run your API in HTTP.  To pass the request to your API from the nginx proxy, change your configuration in the server 443 block from :\n```\n`  proxy_pass https://docker_fastapi;\n`\n```\nto :\n```\n`  proxy_pass http://docker_fastapi;\n`\n```",
      "question_score": 6,
      "answer_score": 5,
      "created_at": "2021-04-10T03:15:50",
      "url": "https://stackoverflow.com/questions/67029960/https-with-nginx-fastapi-docker"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67152581,
      "title": "CloudFlare Invalid SSL certificate",
      "problem": "I have a Laravel 8 application.\nI have no idea what I missed. I'm trying to deploy a site in my server.\nI kept getting :\nInvalid SSL certificate\nhttps://mybabies.app/\n\n```\n`server {\n    listen 443;\n    ssl_certificate /etc/nginx/ssl/mybabies.app.crt;\n    ssl_certificate_key /etc/nginx/ssl/mybabies.app.key; \n\n    server_name mybabies.app www.mybabies.app;\n\n    root /home/bheng/mybabies/public;\n\n    index index.html index.htm index.php;\n\n    charset utf-8;\n\n    location ~ \\.php$ {\n        try_files $uri =404;\n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n        fastcgi_pass unix:/var/run/php/php7.3-fpm.sock;\n        fastcgi_index index.php;\n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        include /etc/nginx/fastcgi_params;\n    }\n\n    client_max_body_size 500M;\n\n    location = /favicon.ico { access_log off; log_not_found off; }\n    location = /robots.txt  { access_log off; log_not_found off; }\n\n    access_log on;\n    access_log /var/log/nginx/access.log;\n    error_log  /var/log/nginx/error.log error;\n    error_page 404 /index.php;\n\n    # Media: images, icons, video, audio, HTC\n    location ~* \\.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|mp3|ogg|ogv|webm|htc|woff2|woff)$ {\n        expires 1M;\n        access_log off;\n        add_header Cache-Control \"public\";\n    }\n\n    # CSS and Javascript\n    location ~* \\.(?:css|js)$ {\n        expires 1y;\n        access_log off;\n        add_header Cache-Control \"public\";\n    }\n\n    location / {\n        #limit_req zone=one burst=2 nodelay;\n        try_files $uri $uri/ /index.php?$query_string;\n        add_header 'Access-Control-Allow-Origin' '*';\n    }\n\n}\n`\n```\nI already create `crt` + `pem` key in CloudFlare and configure in these 2 lines :\n```\n`ssl_certificate /etc/nginx/ssl/mybabies.app.crt;\nssl_certificate_key /etc/nginx/ssl/mybabies.app.key; \n`\n```\n\nEdit\nWhen I paused it\n\nWhen I clicked `View Certificate`, I see\n\nUpdated\nI created the cert from",
      "solution": "To setup secure connection between Cloudflare and your server you need to generate Origin CA Certificate in page Origin Certificates, but you did this in Client Certificates instead, so that's why you are getting error.\nThey are completelly different things with different purpose. Read descriptions.\nClient Certificates\n\nSecure and authenticate your APIs and web\napplications with client certificates. Block traffic from devices that\ndo not have a valid client SSL/TLS certificate with mTLS rules.\n\nOrigin Certificates\n\nGenerate a free TLS certificate signed by Cloudflare to install on\nyour origin server. Origin Certificates are only valid for encryption\nbetween Cloudflare and your origin server.\n\nAfter generating PEM an KEY you need to put them in .crt and .key and load in nginx config, like you did before.\n```\n`listen 443;\nssl_certificate /etc/nginx/ssl/mybabies.app.crt;\nssl_certificate_key /etc/nginx/ssl/mybabies.app.key; \n`\n```\nNow connection Full (strict) should work.\nIf you want to use self-signed certificate instead, but still leverage secure connection between CF and server, then use option Full instead (without strict). By using Flexible your visitor will be still using HTTPS, but there will be no SSL connection between CF and server, and server will see this as HTTP connection, so this option is not recommended.\nRad more: https://support.cloudflare.com/hc/en-us/articles/200170416-What-do-the-SSL-options-mean-",
      "question_score": 6,
      "answer_score": 4,
      "created_at": "2021-04-18T21:25:51",
      "url": "https://stackoverflow.com/questions/67152581/cloudflare-invalid-ssl-certificate"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 74509259,
      "title": "react-native java.security.cert.CertPathValidatorException: Trust anchor for certification path not found",
      "problem": "My React Native mobile application suddenly cannot connect with the backend.\n(only android version, iOS works without any problem).\nAlso I can request the API without problem by using the browser.\nThis just suddenly happened, when the problem start where were no changes in the server side or in the mobile application, but all android apps stop to connect to the server.\nThe exception in the mobile application says:\n`java.security.cert.CertPathValidatorException: Trust anchor for certification path not found.`\nI have reviewed every answer in Stack Overflow but nothing works so far.\nThese are the main points:\n\nMy mobile app is made with react-native and Expo, the SSL certificated is issued by LetsEncrypt.\nThe certificate from my API is correct, it works perfectly with iOS and any web browser.\nThe backend is a `react-js` application running with an `nginx 1.22.1` server.\n\nIn the mobile:\n\nI tried another app (api tester) for android and I get the same error trying to communicate with my API. (but again, my ssl certificate seems to be OK).\nIn my mobile app, I tied to fetch data from a random open API in internet and it works without problem.\nI also tried to use `fetch` instead of `axios` but also fails to connect.\nI also look how to do an ssl certificate `pinning` as a temporary solution but the problem is that I'm using expo and I didn't find the way to do it with it.\n\nSome relevant dependencies version are:\n```\n`\"dependencies\": {\n    ...\n    \"axios\": \"^1.1.3\",\n    \"expo\": \"^44.0.0\",\n    \"expo-cli\": \"^5.4.3\",\n    \"react\": \"17.0.1\",\n    \"react-native\": \"0.64.3\",\n    \"react-native-gesture-handler\": \"~2.1.0\",\n    ...\n  },\n`\n```\nIn the server:\n\nI tried with a certificate issued by ZeroSSL but still have the same problem.\nI also tried add the certificate issuer to the \"trusted credentials\" in android, but this issuer already was in there.\nI also tried renew the certificate using `certbot` with the flag `--preferred-chain=\"ISRG Root X1\"`\n\nGiven all this test it seems to be a server side problem, but no other device have problem with it, only android; Also I test the certificate and its OK\nI also test the certificate with this website\nhttps://www.ssllabs.com/sstest\nAnd this was the result\nSSL Test\nI will be grateful for any clue you can give me.\nRegards!",
      "solution": "I managed to make the application connect with my API successfully, but I'm still researching the origin of the problem.\nMore context:\n\nMy mobile application is made by React Native + Expo.\nI compiled a version for iOS and another for Android.\nThe problem just suddenly happened only in the Android\n(In all the android devices without have made any change in the mobile app or the server)\niOS can connect with the API without problem\nThe website can communicate with the API without problem\n\nIt seems to be a problem of the library `axios` (specifically `axiosinstance`).\nIts weird because I didn't change anything in the android app, it just suddenly stopped to work.\n(in all the android devices at the same time).\nAnd just doing tests I realized that `axiosinstance` fail by doing the request (with the exception that I already showed you), but in an inexplicable way if the first request pointing to my API that I do in the app is by using `axios` it works perfectly, and after that `axiosinstance` is capable to perform any request to my API without fail.\nI know it sounds weird, but now my app is working again.\nBy other Side, just to let you know, I also tested an android app called `API Tester v5.6` and it fails connecting to my API giving me the same exception, but it last version `API Tester 5.7` (which was released just some days ago) works without problem.\nI also tried to connect to my API with `ApiClient v2.4.7` and it fails with the same exception.\nAgain, I don't understand what is the real problem but definitely is not the certificate.\nAnyway, now you know, maybe I should post this problem to the axios guys?\nRegards!",
      "question_score": 6,
      "answer_score": 1,
      "created_at": "2022-11-20T16:06:35",
      "url": "https://stackoverflow.com/questions/74509259/react-native-java-security-cert-certpathvalidatorexception-trust-anchor-for-cer"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66469385,
      "title": "After the first reload: &quot;nginx: [error] open() &quot;/var/run/nginx.pid&quot; failed (2: No such file or directory)&quot;",
      "problem": "Using Salt I applied states that install and run NGINX (1.14.0-0ubuntu1.7) as a service. Service's status is active but `systemctl reload nginx` keeps failing thus an updated config cannot be applied.\nFull logs:\n```\n`systemd[1]: nginx.service: Can't open PID file /run/nginx.pid (yet?) after reload: No such file or directory\nsystemd[1]: Reloaded A high performance web server and a reverse proxy server.\nsystemd[1]: Reloading A high performance web server and a reverse proxy server.\nnginx[18095]: nginx: [error] open() \"/var/run/nginx.pid\" failed (2: No such file or directory)\nsystemd[1]: nginx.service: Control process exited, code=exited status=1\nsystemd[1]: Reload failed for A high performance web server and a reverse proxy server.\nsystemd[1]: Reloading A high performance web server and a reverse proxy server.\nnginx[1209]: nginx: [error] invalid PID number \"\" in \"/var/run/nginx.pid\"\nsystemd[1]: nginx.service: Control process exited, code=exited status=1\nsystemd[1]: Reload failed for A high performance web server and a reverse proxy server.\n`\n```",
      "solution": "I solved this by restarting nginx instead of reloading:\n```\n`service nginx restart\nservice nginx status\n`\n```\nafter this, also a reload worked fine and the pid number is stored in\n```\n` /var/run/nginx.pid\n`\n```",
      "question_score": 6,
      "answer_score": 2,
      "created_at": "2021-03-04T06:56:23",
      "url": "https://stackoverflow.com/questions/66469385/after-the-first-reload-nginx-error-open-var-run-nginx-pid-failed-2-n"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 77368933,
      "title": "NextJS app behind nginx proxy is doing full page refresh instead of soft-navigation",
      "problem": "Whenever a link is clicked and navigation is fired, the browser does a full refresh instead of soft-navigation. However, this only happens when using nginx and App Router, if the app is accessed locally (App or Pages router), through (App or pages router) Vercel or with nginx and Pages router, the soft navigation of the SPA works.\nI can confirm it still fails with latest canary and also since at least v13.\nThis is my nginx config:\n```\n`location / {\n    proxy_pass \n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection 'upgrade';\n    proxy_set_header Host ;\n    proxy_ssl_server_name on;\n    proxy_cache_bypass $http_upgrade;\n}\n`\n```\nYou can check both behaviours with this sample project:\n\u274c Reverse proxy to Vercel project using App Router -> doing full page refresh\nhttps://sample-project-app-router.javimartinez.es/\n\u2705 Reverse proxy to Vercel project using Pages Router -> working (soft-navigation)\nhttps://sample-project-pages-router.javimartinez.es/\n\u274c Reverse proxy to self-hosted project using App router (NextJS built-in server) -> doing full refresh\nhttps://sample-self-hosted-app-router.javimartinez.es/\n\u2705 Reverse proxy to self-hosted project using Pages router (NextJS built-in server) -> working (soft-navigation)\nhttps://sample-self-hosted-pages-router.javimartinez.es/\n\u2705 Vercel vanity url to Vercel project using App Router -> working (soft-navigation)\nhttps://sample-project-javiermartinz.vercel.app/\n\u2705 Vercel vanity url to Vercel project using Pages Router -> working (soft-navigation)\nhttps://sample-project-pages-router-javiermartinz.vercel.app/\n\u2705 NextJS built-in production server running in local (Pages or App router) -> working (soft-navigation)\n`next build && next start` and access to http://localhost:3000",
      "solution": "I finally found out the culprit of this whole issue. Nginx configuration has some goodies from `h5bp`, this repository to be specific https://github.com/h5bp/server-configs-nginx\nIt looks like NextJS App Router does something under the hood with headers, so it a MIME type was messing with it. I just commented out this line and everything started working as it should https://github.com/h5bp/server-configs-nginx/blob/862527003373d66e5da3147b9fd42fd24fe2442f/h5bp/media_types/character_encodings.conf#L27",
      "question_score": 6,
      "answer_score": 1,
      "created_at": "2023-10-26T18:46:41",
      "url": "https://stackoverflow.com/questions/77368933/nextjs-app-behind-nginx-proxy-is-doing-full-page-refresh-instead-of-soft-navigat"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69991202,
      "title": "How do I set up docker and nginx for local development",
      "problem": "Context\nI am trying to build out a local development environment and I am struggling to get it to work. I want docker and docker compose to run nginx as a reverse proxy and a postgresql database\nProject Structure\n```\n`my-app/\n\u251c\u2500 server/ (fastify node server)\n\u251c\u2500 client/ (sveltekit dev server)\n\u251c\u2500 nginx/\n\u2502  \u251c\u2500 Dockerfile\n\u2502  \u251c\u2500 default.conf\n\u251c\u2500 docker-compose.yml\n`\n```\nI want the only prerequisites to be Node, git and docker. I to be able to clone the project, start docker compose, and then start the two projects individually\nPrior Research\nI've read through the nginx Beginners guide and several pieces of the nginx documentation but I find their docs fairly unapproachable. I also have found several guides that have my client and server running inside docker containers and set up as separate services within docker compose. That is not the end goal, but unfortunately I have not gotten those to work either.\nThis question seems close and I found it helpful. But it\u2019s still not working.\nTo start, I'm just trying to get everything to work on http://localhost:4000 in order to remove some of the complexity\nThis is my best attempt thus far:\n```\n`\n    ##########################\n    # docker-compose.yml\n    ##########################\n    \n    version: '3.9'\n    services:\n      reverse-proxy:\n        build: ./nginx\n        ports:\n          - 8080:8080\n    \n    ##########################\n    # nginx/Dockerfile\n    ##########################\n    FROM nginx:1.21.3\n    COPY ./default.conf /etc/nginx/conf.d/default.conf/\n    \n    ##########################\n    # nginx/default.conf\n    ##########################\n    \n    server {\n      listen 8080;\n    \n      location / {\n        proxy_pass http://host.docker.internal:8080;\n      }\n    \n      location /api/ {\n        proxy_pass http://host.docker.internal:3000;\n      }\n    }\n`\n```\nWith this set up, I can hit http://localhost:3000/api/ and get my json response from the server, but when I try and hit http://localhost:8080/api/, I get the standard nginx 502 response and nginx does not successfully reach my node server. The nginx logs give me this error:\n```\n`     2021/11/16 12:38:39 [error] 34#34: *1 connect() failed (111: Connection refused) while connecting to upstream, client: 172.19.0.1, server: , request: \"GET /api/ HTTP/1.1\", upstream: \"http://192.168.65.2:3000/api/\", host: \"localhost:8080\"\n`\n```\nI don't know where the IP address comes from up above, but if I hit http://192.168.65.2:3000/api/ locally, then the browser just spins and spins.\nEnd Goal\nI am looking for a properly configured `docker-compose.yml` and a single, relatively simple nginx file for the moment that gets mapped into the default. HTTPS and a custom URL are really later problems. For now, I just want to be able to hit my nginx reverse proxy within a docker container and properly route to my two locally running node servers (one an API server and one a sveltekit dev server - neither inside docker containers).\nThank you in advance for any help!\nEdit (After changes suggested by Robert-Jan Kuyper)\nI'm now running basically this:\n```\n`##########################\n# docker-compose.yml\n##########################\n\nversion: '3.8'\nservices:\n  nginx:\n    image: nginx:1.19.4\n    depends_on:\n      - api\n    volumes:\n      - ./nginx/default.local.conf:/etc/nginx/conf.d/default.conf\n    ports:\n      - '8080:8080'\n  api:\n    build: ./api\n    hostname: api\n    command: node src/app.js\n    volumes:\n      - ./server/src:/app/src\n\n##########################\n# nginx/default.conf\n##########################\n\nupstream api_server {\n    server api:3000;\n}\n\nserver {\n  listen 8080;\n\n  location /api/ {\n    proxy_pass http://api_server;\n  }\n}\n\n##########################\n# api/Dockerfile\n##########################\n\nFROM node:16.9.0\n\n# docker workdir\nWORKDIR /home/usr/app\n\n# copy files\nCOPY . .\n\n# build the app\nRUN npm ci\n\n# expose at port 3000\nEXPOSE 3000\n\nCMD [\"node\", \"src/app.js\"]\n`\n```\nUnfortunately, it is still failing with this:\n```\n`[error] 29#29: *1 connect() failed (111: Connection refused) while connecting to upstream, client: 172.18.0.1, server: , request: \"GET /api/ HTTP/1.1\", upstream: \"http://172.18.0.2:3000/api/\", host: \"localhost:8080\"\n`\n```",
      "solution": "There a couple of things you have to keep in mind:\n\nDocker compose by default uses the service name as hostname for inter container networking\nNginx need to know the upstream first\nYou don't need Nginx in a Dockerfile, use it directly in `docker-compose.yml` instead. And mount your config file into the container.\nYou need to dockerize your front-end and back-end to connect them to nginx\nAlways expose on `0.0.0.0` instead of `127.0.0.1` or `localhost` inside your docker container, see this answer.\n\nAn example repo where I use nginx, docker and docker-compose: https://gitlab.com/datails/api .\nExample `default.conf`:\n```\n`upstream api_server {\n    server api:3000;\n}\n\nupstream frontend {\n    server frontend:3000;\n}\n\nserver {\n    listen 80;\n\n    location /api {\n        proxy_pass http://api_server;\n    }\n\n    location / {           \n        proxy_pass http://frontend/;\n    }\n}\n`\n```\nExample `docker-compose.yml`\n```\n`version: '3.8'\nservices:\n  nginx:\n    image: nginx:1.19.4\n    depends_on:\n      - server\n      - frontend\n    volumes:\n      - ./nginx.conf:/etc/nginx/conf.d/default.conf\n    ports:\n      - '8080:80'\n`\n```\nThen make sure you have your front-end dockerized and called `frontend` as a service in your docker-compose like:\n```\n`version: '3.8'\nservices:    \n  nginx:\n    image: nginx:1.19.4\n    depends_on:\n      - server\n      - frontend\n    volumes:\n      - ./default.conf:/etc/nginx/conf.d/default.conf\n    ports:\n      - '8080:80'\n\n  frontend:\n    build: ./frontend\n    command: npm run start\n    volumes:\n      - ./frontend/src:/home/usr/app/src\n\n  api:\n    build: ./api\n    command: npm run start\n    volumes:\n      - ./api/src:/home/usr/app/src\n`\n```\nNote you don't need a port because you use inter container communication.",
      "question_score": 5,
      "answer_score": 13,
      "created_at": "2021-11-16T15:43:47",
      "url": "https://stackoverflow.com/questions/69991202/how-do-i-set-up-docker-and-nginx-for-local-development"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 71210935,
      "title": "Remove a part of a log in Loki",
      "problem": "I have installed Grafana, Loki, Promtail and Prometheus with the `grafana/loki-stack`.\nI also have Nginx set up with the Nginx helm chart.\nPromtail is ingesting logs fine into Loki, but I want to customise the way my logs look. Specifically I want to remove a part of the log because it creates errors when trying to parse it with either `logfmt` or `json` (`Error: LogfmtParserErr` and `Error: JsonParserErr` respectively).\nThe logs look like this:\n```\n`2022-02-21T13:41:53.155640208Z stdout F timestamp=2022-02-21T13:41:53+00:00 http_request_method=POST http_response_status_code=200 http_response_time=0.001 http_version=HTTP/2.0 http_request_body_bytes=0 http_request_bytes=63\n`\n```\nand I want to remove the part where it says `stdout F` so the log will look like this:\n```\n`2022-02-21T13:41:53.155640208Z timestamp=2022-02-21T13:41:53+00:00 http_request_method=POST http_response_status_code=200 http_response_time=0.001 http_version=HTTP/2.0 http_request_body_bytes=0 http_request_bytes=63\n`\n```\nI have figured out that on the ingestion side it could be something with Promtail, but ist it also possible to make a LogQL query in Loki to just replace that string? And how would one set up the Promtail configuration for the wanted behaviour?",
      "solution": "Promtail should be configured to replace the string with the `replace` stage.\nHere is a sample config that removes the `stdout F` part of the log for all logs coming from the namespace ingress.\n`promtail:\n  enabled: true\n  pipelineStages:\n  - docker: {}\n  - match:\n      selector: '{namespace=\"ingress\"}'\n      stages:\n      - replace:\n          expression: \"(stdout F)\"\n          replace: \"\"\n`\nSpecifically this example works for the `grafana/loki-stack` chart.",
      "question_score": 5,
      "answer_score": 2,
      "created_at": "2022-02-21T18:57:38",
      "url": "https://stackoverflow.com/questions/71210935/remove-a-part-of-a-log-in-loki"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 68729983,
      "title": "Django admin interface missing css styling in production",
      "problem": "The user interface is working well, and all CSS styling and static files are served correctly, but the admin interface is missing CSS styling. I looked at similar posts but in those posts people had the issue with both the user and the admin interface. My issue is only with the admin interface.\nPlease see my static file settings below from `settings.py`:\n```\n`STATIC_URL = '/static/'\n\n#Location of static files\nSTATICFILES_DIRS = [os.path.join(BASE_DIR, 'static'), ]\n\nSTATIC_ROOT  = os.path.join(BASE_DIR, 'staticfiles')\n`\n```\nAnd this is my nginx configuration:\n```\n`server {\n    listen 80;\n    server_name MY_SERVER_IP;\n\n    location = /favicon.ico { access_log off; log_not_found off; }\n    location /static/ {\n        root /home/MYUSERNAME/myproject;\n    }\n\n    location /media/ {\n        root /home/MYUSERNAME/myproject;\n    }\n`\n```\nI already executed `python manage.py collectstatic` on the server and got this message:\n```\n`0 static files copied to '/home/MYUSERNAME/myproject/staticfiles', 255 unmodified.\n`\n```\nI restarted nginx after that and also tried emptying my browser cache, but the issue persisted.\nMore info as requested by @Omar Siddiqui.\nUsing Django 3.2\nMy mysite/urls.py contains:\n```\n`from django.contrib import admin\nfrom django.urls import path, include\n\n# Imports to configure media files for summernote editor\nfrom django.conf import settings\nfrom django.conf.urls.static import static\n\nurlpatterns = [\n    path('admin/', admin.site.urls),\n    path('', include('qa.urls')),\n    path('summernote/', include('django_summernote.urls')),\n    path('chatbot/', include('chatbot.urls')),\n]\n\n# Enable media files for summernote editor\nif settings.DEBUG:\n    urlpatterns += static(settings.MEDIA_URL,\n                          document_root=settings.MEDIA_ROOT)\n`\n```",
      "solution": "Could you please try below steps and let me know if it's working or not?\nApply below changes in settings.py file:\n```\n`STATIC_URL = '/static/'\nSTATIC_ROOT = os.path.join(BASE_DIR, 'static')\n`\n```\nRemove below line from your settings.py:\n```\n`STATICFILES_DIRS = [os.path.join(BASE_DIR, 'static'), ]\n`\n```\nExecute below command in production:\n```\n`python manage.py collectstatic\n`\n```\nUpdate nginx file like below one:\n```\n`# prevent css, js files sent as text/plain objects\ninclude /etc/nginx/mime.types;\n\nserver {\n    listen 80;\n    server_name MY_SERVER_IP;\n\n    location = /favicon.ico { access_log off; log_not_found off; }\n    location /static/ {\n        autoindex on;\n        autoindex_exact_size off;\n        root /home/MYUSERNAME/myproject;\n    }\n\n    location /media/ {\n        autoindex on;\n        autoindex_exact_size off;\n        root /home/MYUSERNAME/myproject;\n    }\n}\n`\n```\nExplanations:\n\n`STATIC_ROOT` is the folder where static files will be stored after\nusing `python manage.py collectstatic`\n`STATICFILES_DIRS` is the list of folders where django will search for additional static files aside from the `static` folder of each app installed.\n\nIn this case our concern was Admin related CSS files that why we use `STATIC_ROOT` instead of `STATICFILES_DIRS`",
      "question_score": 5,
      "answer_score": 11,
      "created_at": "2021-08-10T17:55:21",
      "url": "https://stackoverflow.com/questions/68729983/django-admin-interface-missing-css-styling-in-production"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 72360665,
      "title": "How to activate nginx sub_filter when it is present in configuration?",
      "problem": "I have downloaded nginx windows image in version 1.21.6 (https://nginx.org/en/download.html), the `nginx -V` output contains `--with-http_sub_module`:\n```\n`PS C:\\Utils\\nginx-1.21.6> .\\nginx.exe -V\nnginx version: nginx/1.21.6\nbuilt by cl 16.00.40219.01 for 80x86\nbuilt with OpenSSL 1.1.1m  14 Dec 2021\nTLS SNI support enabled\nconfigure arguments: --with-cc=cl --builddir=objs.msvc8 --with-debug --prefix= --conf-path=conf/nginx.conf --pid-path=logs/nginx.pid --http-log-path=logs/access.log --error-log-path=logs/error.log --sbin-path=nginx.exe --http-client-body-temp-path=temp/client_body_temp --http-proxy-temp-path=temp/proxy_temp --http-fastcgi-temp-path=temp/fastcgi_temp --http-scgi-temp-path=temp/scgi_temp --http-uwsgi-temp-path=temp/uwsgi_temp --with-cc-opt=-DFD_SETSIZE=1024 --with-pcre=objs.msvc8/lib/pcre2-10.39 --with-zlib=objs.msvc8/lib/zlib-1.2.11 --with-http_v2_module --with-http_realip_module --with-http_addition_module --with-http_sub_module --with-http_dav_module --with-http_stub_status_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_auth_request_module --with-http_random_index_module --with-http_secure_link_module --with-http_slice_module --with-mail --with-stream --with-openssl=objs.msvc8/lib/openssl-1.1.1m --with-openssl-opt='no-asm no-tests -D_WIN32_WINNT=0x0501' --with-http_ssl_module --with-mail_ssl_module --with-stream_ssl_module\n`\n```\nUnfortunatelly, I am not able to make the substitution work :( I tried to get some inspiration here: https://samanbaboli.medium.com/modify-html-pages-on-the-fly-using-nginx-2e7a2d069086\nHere is my config\n```\n`worker_processes 1;\nworker_rlimit_nofile 8192;\npid nginx.pid;\n\nevents {\n    worker_connections 24;\n}\nhttp {\n  server {\n    listen 80;\n    server_name  localhost;\n\n    location / {\n      proxy_pass      https://example.org;\n      sub_filter '' 'alert(\"Hi\")';\n      sub_filter_once on;\n    }\n\n    location /test {\n      return 200 'OKAY';\n      sub_filter 'OKAY' 'OK';\n      sub_filter_once on;\n    }\n  }\n}\n`\n```\nAny ideas, what I am doing wrong?\nhttp://localhost/ won't throw alert \"Hi\", http://localhost/test returns \"OKAY\", not expected \"OK\".\nAccording to this answer, there should not be any parameters or additional config required :( Nginx, how to start service with ngx_http_sub_module enabled",
      "solution": "The `Content-Type` HTTP header, unless being specified explicitly via the `default_type` directive (at the location or any level up) will be equal to `text/plain` by default. The `sub_filter` directive works only with on content with the `text/html` MIME type, unless additional types are specified using the `sub_filter_types` directive. So, to make your substitution work in the `/test` location, use either\n`location /test {\n    default_type text/html;\n    return 200 'OKAY';\n    sub_filter 'OKAY' 'OK';\n}\n`\nor, if you didn't have `default_type` directive specifying some other type than `text/plain` somewhere else,\n`location /test {\n    return 200 'OKAY';\n    sub_filter_types text/plain;\n    sub_filter 'OKAY' 'OK';\n}\n`\nI don't see any reason the substitution does not work in your main location. Check the actual MIME type returned from the `https://example.org` and the used upper/lower case for the HTML tags. Is it really `` and not the ``?\nUpdate\nAs being noticed by OP the `sub_filter` module didn't work with compressed upstream responses, so if upstream is able to compress its response, the `Accept-Encoding` header should not be passed to the upstream:\n`location / {\n    proxy_pass https://example.org;\n    proxy_set_header Accept-Encoding \"\";\n    sub_filter '' 'alert(\"Hi\")';\n    sub_filter_once on;\n}\n`",
      "question_score": 5,
      "answer_score": 8,
      "created_at": "2022-05-24T11:42:55",
      "url": "https://stackoverflow.com/questions/72360665/how-to-activate-nginx-sub-filter-when-it-is-present-in-configuration"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 68039059,
      "title": "How to change php-fpm default port?",
      "problem": "I'm using `php-fpm` which runs for default on the port `9000`. The problem's that I have other docker container based on `php-fpm`, so I need to change the default port to another one, in order to not confuse `nginx`.\nThis is my `Dockerfile`:\n```\n`FROM php:8.0.2-fpm-alpine\nRUN sed -i 's/9000/9001/' /usr/local/etc/php-fpm.d/zz-docker.conf\n\nWORKDIR /var/www/html\n\nCMD [\"php-fpm\"]\n\nEXPOSE 9001\n`\n```\nI tried to use the `sed` command to replace the port `9000` with `9001`.\nInside my `docker-compose` file I have this configuration:\n```\n`version: '3.9'\n\nservices:\n\n  php-fpm:\n    container_name: app\n    restart: always\n    build:\n      context: .\n      dockerfile: ./docker/php-fpm/Dockerfile\n    ports:\n      - \"9001:9000\"\n    volumes:\n      - ./src:/var/www/html\n      - ./docker/php-fpm/config/www.conf:/usr/local/etc/php-fpm.d/www.conf\n      - ./src/public:/app/public\n      - ./src/writable:/app/writable\n\n  nginx:\n    image: nginx:stable-alpine\n    container_name: nginx\n    restart: always\n    volumes:\n      - ./src:/var/www/html\n      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf\n      - ./docker/nginx/sites/:/etc/nginx/sites-available\n      - ./docker/nginx/conf.d/:/etc/nginx/conf.d\n    depends_on:\n      - php-fpm\n    environment:\n      VIRTUAL_HOST: ${HOST}\n      LETSENCRYPT_HOST: ${HOST}\n      LETSENCRYPT_EMAIL: ${EMAIL}\n`\n```\nas you can see I have exposed the port `9001` also in the `docker-compose` file.\nThe file `default.conf` available within `conf.d` folder contains this:\n```\n`upstream php-upstream {\n    server php-fpm:9001;\n}\n`\n```\nthe problem's that for some reason, when I load my site I get the error 500. So this means that the stream doesn't send any signal. If I change to port `9000` everything works, but the stream is wrong 'cause it's the content of another application.\nHow can I correctly change the default port?",
      "solution": "I think the problem is not the sed command itself, it's related to the wrong file you mentioned for it.\n```\n`/usr/local/etc/php-fpm.d/zz-docker.conf\n`\n```\nthis is the file you are trying to change the port in it but inside your docker-compose file you are mapping something else\n```\n`./docker/php-fpm/config/www.conf:/usr/local/etc/php-fpm.d/www.conf\n`\n```",
      "question_score": 5,
      "answer_score": 5,
      "created_at": "2021-06-18T19:08:13",
      "url": "https://stackoverflow.com/questions/68039059/how-to-change-php-fpm-default-port"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67248220,
      "title": "Django doesn&#39;t serve static files with NGINX + GUNICORN",
      "problem": "Everything worked very well before gunicorn and nginx, static files were served to the website.\nBut now, it doesn't work anymore.\nSettings.py\n```\n`STATICFILES_DIRS = [\n'/root/vcrm/vcrm1/static/'\n]\n\nSTATIC_ROOT = os.path.join(BASE_DIR, 'vcrm/static')\nSTATIC_URL = '/static/'\n\nMEDIA_ROOT = '/root/vcrm/vcrm1/vcrm/media/'\nMEDIA_URL = '/media/'\n`\n```\n/etc/nginx/sites-available/vcrm\n```\n`server {\nlisten 80;\nserver_name 195.110.58.168;\n\nlocation = /favicon.ico { access_log off; log_not_found off; }\nlocation /static {\n    root /root/vcrm/vcrm1/vcrm;\n}\n\nlocation = /media {\n    root /root/vcrm/vcrm1/vcrm;\n}\n\nlocation / {\n    include proxy_params;\n    proxy_pass http://unix:/run/gunicorn.sock;\n}\n`\n```\n}\nWhen I run collectstatic:\n```\n`You have requested to collect static files at the destination\nlocation as specified in your settings:\n\n/root/vcrm/vcrm1/vcrm/static\n\nThis will overwrite existing files!\nAre you sure you want to do this?\n`\n```\nand then:\n```\n`Found another file with the destination path 'admin/js/vendor/jquery/jquery.min.js'. It will be \nignored since only the first encountered file is collected. If this is not what you want, make sure \nevery static file has a unique path.\n\n0 static files copied to '/root/vcrm/vcrm1/vcrm/static', 251 unmodified.\n`\n```",
      "solution": "NGINX + Gunicorn + Django\nDjango project:\n```\n` djangoapp\n - ...\n - database\n - djangoapp\n   - settings.py\n   - urls.py\n   - ...\n - media\n - static\n - manage.py\n - requirements.txt\n`\n```\nServer: install venv, requirements.txt:\n```\n`sudo apt-get update\nsudo apt-get install -y git python3-dev python3-venv python3-pip supervisor nginx vim libpq-dev\n--> cd djangoapp\npathon3 -m venv venv\nsource venv/bin/activate\n(venv) pip3 install -r requirements.txt \n`\n```\nServer: install NGINX:\n```\n`sudo apt-get install nginx\nsudo vim /etc/nginx/sites-enabled/default\n`\n```\nServer: NGINX config:\n```\n`   server {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n        location /static/ {\n            alias /home/ubuntu/djangoapp/static/; \n        }\n\n        location /media/ {\n            alias /home/ubuntu/djangoapp/media/; \n        }\n\n        location / {\n            proxy_pass http://127.0.0.1:8000;\n            proxy_set_header X-Forwarded-Host $server_name;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_redirect off;\n            add_header P3P 'CP=\"ALL DSP COR PSAa OUR NOR ONL UNI COM NAV\"';\n            add_header Access-Control-Allow-Origin *;\n        }\n}\n`\n```\nServer: setup supervisor:\n```\n`cd /etc/supervisor/conf.d/\nsudo vim djangoapp.conf\n`\n```\nServer: supervisor config:\n```\n`[program:djangoapp]\ncommand = /home/ubuntu/djangoapp/venv/bin/gunicorn djangoapp.wsgi  -b 127.0.0.1:8000 -w 4 --timeout 90\nautostart=true\nautorestart=true\ndirectory=/home/ubuntu/djangoapp \nstderr_logfile=/var/log/game_muster.err.log\nstdout_logfile=/var/log/game_muster.out.log\n`\n```\nServer: update supervisor with the new process:\n```\n`sudo supervisorctl reread\nsudo supervisorctl update\n\nsudo supervisorctl restart djangoapp\n`\n```",
      "question_score": 5,
      "answer_score": 6,
      "created_at": "2021-04-25T01:03:29",
      "url": "https://stackoverflow.com/questions/67248220/django-doesnt-serve-static-files-with-nginx-gunicorn"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66375380,
      "title": "Kubectl proxy behind NGINX: invalid upgrade response",
      "problem": "I'm trying to add a local Kubernates cluster to my GitLab group for CI/CD deployments. I've started with running the following command:\n`kubectl proxy --address 0.0.0.0 --accept-hosts '.*'`\nI've tested it executing `curl http://localhost:8001/api` and running `curl http://192.168.1.2:8001/api` from another machine in the same network. Proxy was available in my local network.\nThe next step was to make the proxy available on the internet behind `kubernates.example.com`. For that I've configured NGINX as the following:\n```\n`server {\n    server_name kubernates.example.com;\n    listen 443 ssl;\n    listen 80;\n\n    include ssl_standart_conf;\n\n    location / {\n        proxy_pass http://192.168.1.2:8001/;\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_redirect off;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n    }\n}\n`\n```\nExecuting `curl https://kubernates.example.com/api` returned the following error:\n```\n`invalid upgrade response: status code 200\n`\n```\nKubernates proxy logs\n```\n`E0225 22:33:50.944018 1642369 upgradeaware.go:312] Proxy upgrade error: invalid upgrade response: status code 200\nE0225 22:33:50.944060 1642369 proxy_server.go:144] Error while proxying request: invalid upgrade response: status code 200\n`\n```",
      "solution": "Okay, I've managed to resolve the issue. The following nginx configuration made a trick\n```\n`server {\n    server_name kubernates.example.com;\n    listen 443 ssl;\n    listen 80;\n\n    include ssl_standart_conf;\n\n    location / {\n        proxy_pass http://192.168.1.2:8001/;\n        proxy_set_header Host $host;\n    }\n}\n`\n```",
      "question_score": 5,
      "answer_score": 3,
      "created_at": "2021-02-25T20:39:51",
      "url": "https://stackoverflow.com/questions/66375380/kubectl-proxy-behind-nginx-invalid-upgrade-response"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 65838013,
      "title": "Python 3.2 - uWSGI process got Segmentation Fault",
      "problem": "INTRODUCTION:\nIt is a web application environment using Python 3.2, NGINX and uWSGI.\nPython 3.2, NGINX and uWSGI components was installed via build and installation (\"./configure\", \"make\" and \"make install\") and they use OpenSSL 1.0.X also installed via build and installation.\nThe application is running on Ubuntu 20.04 LTS.\nPROBLEM:\nThe application cannot start and the uWSGI log shows the information below...\n```\n`Thu Jan 21 21:44:37 2021 - Respawned uWSGI worker 4 (new pid: 99572)\nThu Jan 21 21:44:37 2021 - worker 3 buried after 0 seconds\nThu Jan 21 21:44:37 2021 - worker 7 buried after 0 seconds\nThu Jan 21 21:44:37 2021 - worker 1 buried after 0 seconds\nThu Jan 21 21:44:37 2021 - worker 8 buried after 0 seconds\nThu Jan 21 21:44:37 2021 - worker 5 buried after 0 seconds\nThu Jan 21 21:44:37 2021 - received message 0 from emperor\nThu Jan 21 21:44:37 2021 - SIGINT/SIGQUIT received...killing workers...\nThu Jan 21 21:44:37 2021 - mem-collector thread started for worker 4\nThu Jan 21 21:44:37 2021 - !!! uWSGI process 99543 got Segmentation Fault !!!\nThu Jan 21 21:44:37 2021 - *** backtrace of 99543 ***\n/usr/local/lb/uwsgi_ve32/bin/uwsgi(uwsgi_backtrace+0x2e) [0x556d323f077e]\n/usr/local/lb/uwsgi_ve32/bin/uwsgi(uwsgi_segfault+0x27) [0x556d323f0b67]\n/lib/x86_64-linux-gnu/libc.so.6(+0x46210) [0x7f60a0f33210]\n/lib/x86_64-linux-gnu/libc.so.6(+0x186b7e) [0x7f60a1073b7e]\n/usr/local/ssl/lib/libcrypto.so.1.0.0(+0x12254c) [0x7f60a147054c]\n/usr/local/ssl/lib/libcrypto.so.1.0.0(lh_insert+0x56) [0x7f60a14707e6]\n/usr/local/ssl/lib/libcrypto.so.1.0.0(OBJ_NAME_add+0x74) [0x7f60a13bbc84]\n/lib/x86_64-linux-gnu/libssl.so.1.1(+0x36392) [0x7f60a0067392]\n/lib/x86_64-linux-gnu/libpthread.so.0(+0x1247f) [0x7f60a181547f]\n/lib/x86_64-linux-gnu/libcrypto.so.1.1(CRYPTO_THREAD_run_once+0xd) [0x7f609ff3d78d]\n/lib/x86_64-linux-gnu/libssl.so.1.1(OPENSSL_init_ssl+0x5b) [0x7f60a006757b]\n/lib/x86_64-linux-gnu/libpq.so.5(+0x26304) [0x7f60a00ea304]\n/lib/x86_64-linux-gnu/libpq.so.5(PQconnectPoll+0xe80) [0x7f60a00d4ec0]\n/lib/x86_64-linux-gnu/libpq.so.5(+0x11fd7) [0x7f60a00d5fd7]\n/lib/x86_64-linux-gnu/libpq.so.5(PQconnectdb+0x38) [0x7f60a00d9048]\n/usr/local/lb/lbg_ve32/lib/python3.2/site-packages/psycopg2/_psycopg.cpython-32m.so(+0x10939) [0x7f60a012e939]\n/usr/local/lb/lbg_ve32/lib/python3.2/site-packages/psycopg2/_psycopg.cpython-32m.so(+0x117a2) [0x7f60a012f7a2]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(+0xab58c) [0x7f60a11c558c]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyObject_Call+0x5b) [0x7f60a1174dcb]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(_PyObject_CallFunction_SizeT+0xd2) [0x7f60a1175192]\n/usr/local/lb/lbg_ve32/lib/python3.2/site-packages/psycopg2/_psycopg.cpython-32m.so(+0xbace) [0x7f60a0129ace]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x76e3) [0x7f60a1210b53]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalCodeEx+0x733) [0x7f60a12115e3]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(+0x81f92) [0x7f60a119bf92]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyObject_Call+0x5b) [0x7f60a1174dcb]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0xfb9) [0x7f60a120a429]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalCodeEx+0x733) [0x7f60a12115e3]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(+0x81f92) [0x7f60a119bf92]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyObject_Call+0x5b) [0x7f60a1174dcb]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0xfb9) [0x7f60a120a429]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalCodeEx+0x733) [0x7f60a12115e3]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x65f1) [0x7f60a120fa61]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x670c) [0x7f60a120fb7c]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalCodeEx+0x733) [0x7f60a12115e3]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(+0x81eaf) [0x7f60a119beaf]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyObject_Call+0x5b) [0x7f60a1174dcb]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(+0x7033c) [0x7f60a118a33c]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyObject_Call+0x5b) [0x7f60a1174dcb]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(+0xacf47) [0x7f60a11c6f47]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(+0xab58c) [0x7f60a11c558c]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyObject_Call+0x5b) [0x7f60a1174dcb]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x4106) [0x7f60a120d576]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x670c) [0x7f60a120fb7c]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x670c) [0x7f60a120fb7c]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalCodeEx+0x733) [0x7f60a12115e3]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x65f1) [0x7f60a120fa61]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalCodeEx+0x733) [0x7f60a12115e3]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x65f1) [0x7f60a120fa61]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x670c) [0x7f60a120fb7c]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalCodeEx+0x733) [0x7f60a12115e3]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x65f1) [0x7f60a120fa61]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x670c) [0x7f60a120fb7c]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalCodeEx+0x733) [0x7f60a12115e3]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x65f1) [0x7f60a120fa61]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalCodeEx+0x733) [0x7f60a12115e3]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(+0x81f92) [0x7f60a119bf92]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyObject_Call+0x5b) [0x7f60a1174dcb]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0xfb9) [0x7f60a120a429]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalCodeEx+0x733) [0x7f60a12115e3]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x65f1) [0x7f60a120fa61]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalFrameEx+0x670c) [0x7f60a120fb7c]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyEval_EvalCodeEx+0x733) [0x7f60a12115e3]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(+0x81eaf) [0x7f60a119beaf]\n/usr/local/lb/py32/lib/libpython3.2m.so.1.0(PyObject_Call+0x5b) [0x7f60a1174dcb]\n*** end of backtrace ***\n`\n```\nIMPORTANT:\nAppears that the application is \"mixing\" OpenSSL 1.0.X components with OpenSSL 1.1.X components...\n```\n`/usr/local/ssl/lib/libcrypto.so.1.0.0(+0x12254c) [0x7f60a147054c]\n/usr/local/ssl/lib/libcrypto.so.1.0.0(lh_insert+0x56) [0x7f60a14707e6]\n/usr/local/ssl/lib/libcrypto.so.1.0.0(OBJ_NAME_add+0x74) [0x7f60a13bbc84]\n/lib/x86_64-linux-gnu/libssl.so.1.1(+0x36392) [0x7f60a0067392]\n/lib/x86_64-linux-gnu/libcrypto.so.1.1(CRYPTO_THREAD_run_once+0xd) [0x7f609ff3d78d]\n/lib/x86_64-linux-gnu/libssl.so.1.1(OPENSSL_init_ssl+0x5b) [0x7f60a006757b]\n`\n```\n\nI really need help with this question... I have tried everything!\nThanks! =D",
      "solution": "CAUSE: Most modern versions of Ubuntu Server have PostgreSQL 9.4 configured to use ssl - tls actually - in a version above version 1.0 which is incompatible with Python 3.2 that uses OpenSSL to have the ssl resource. When Python 3.2 tries to connect to PostgreSQL 9.4 using ssl, some library in use by the first (psycopg2?) tries to load a more modern version of OpenSSL compatible with the client, then the application starts to operate with two different versions of OpenSSL - one of which is incompatible with Python 3.2 - which causes a segmentation fault error in the application load.\nSOLUTION:  We can use PostgreSQL 9.4 with a 1.0 version of ssl or disable this feature. We chose disable \"ssl\". The procedure below configures PostgreSQL 9.4 to do not use ssl to establish connections as was done in the older versions of distros that use PostgreSQL 9.4.\nPROCEDURE:\nOpen the file `/var/lib/pgsql/9.4/data/postgresql.conf` - the path may vary - and comment out these lines:\n`ssl = on                                # (change requires restart)`\n... , ...\n`ssl_cert_file = '/etc/ssl/certs/ssl-cert-snakeoil.pem'          # (change requires restart)`\n... and...\n`ssl_key_file = '/etc/ssl/private/ssl-cert-snakeoil.key'         # (change requires restart)`\nRestart the Python 3.2 application and PostgreSQL 9.4.\nFor PostgreSQL 9.4 the following commands can be used to restart it...\n```\n`systemctl stop postgresql\nsleep 2\nsystemctl start postgresql\n`\n```\nDone!\nThanks! =D",
      "question_score": 5,
      "answer_score": 5,
      "created_at": "2021-01-22T02:08:00",
      "url": "https://stackoverflow.com/questions/65838013/python-3-2-uwsgi-process-got-segmentation-fault"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 71973771,
      "title": "Socket.io error with NGINX when deploying a MERN app with Docker",
      "problem": "I have a MERN app deployed on digitalocean with docker. Backend and frontend seem good but for some reason the Websocket, socket.io connection fails on the deployed application.\nerror message:\n\nI use http-proxy-middleware, my setupProxy.js file: (main-be is the name of container)\n```\n`const { createProxyMiddleware } = require('http-proxy-middleware');\n\nmodule.exports = function (app) {\n  app.use(\n    '/api',\n    createProxyMiddleware({\n      target: 'http://main-be:5001',\n      changeOrigin: true,\n    })\n  );\n};\n`\n```\nfrontend/src/utils/axios.js:\n```\n`import axios from 'axios';\nexport const baseURL = 'https://example.com';\nexport default axios.create({ baseURL });\n`\n```\nfrontend/src/utils/constants.js:\n```\n`const API_BASE_ORIGIN = 'wss://46.111.119.161';\nexport { API_BASE_ORIGIN };\n`\n```\n...here i tried these but none worked:\n```\n`const API_BASE_ORIGIN = 'https://example.com';\nconst API_BASE_ORIGIN = 'ws://46.111.119.161:5001';\nconst API_BASE_ORIGIN = 'ws://46.111.119.161'; \nconst API_BASE_ORIGIN = 'wss://46.111.119.161'; \nconst API_BASE_ORIGIN = 'wss://46.111.119.161:5001';\n`\n```\npart of socketContext.js:\n```\n`  //* socket connection\n  useEffect(() => {\n\n    const newSocket = socketIo.connect(API_BASE_ORIGIN, {\n      transports: ['websocket'],\n    });\n    setSocket(newSocket);\n    if (!newSocket) return;\n    newSocket.on('connect', () => {\n      console.log(`Hurrah Socket ${newSocket.id} Connected`);\n    });\n  }, []);\n`\n```\nNGINX default.conf config file:\n```\n`upstream api {\n    server main-be:5001;\n}\n\nupstream client {\n    server main-fe:3000;\n}\n\nserver {\n  listen 80;\n  listen [::]:80;\n  server_name _;\n  return 301 https://$host$request_uri;\n}\n\n# main server block\nserver {\n  listen 443 ssl http2 default_server;\n  listen [::]:443 ssl http2 default_server;\n\n  server_name _;\n\n  # enable subfolder method reverse proxy confs\n  include /config/nginx/proxy-confs/*.subfolder.conf;\n\n  # all ssl related config moved to ssl.conf\n  include /config/nginx/ssl.conf;\n\n  client_max_body_size 0;\n\n   \n     location / {\n        proxy_pass http://client;\n\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n\n     location /api {\n        proxy_pass http://api;\n\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n\n    }\n      location /ws/ {\n        proxy_pass http://client;\n            \n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"Upgrade\";\n        proxy_set_header Host $host;\n    }\n}\n`\n```",
      "solution": "Solution:\n\nadd `WDS_SOCKET_PORT=0` to the React frontend .env file. (so it will not add an unnecessary additional port)\n\nedit the nginx default.conf config file to this (it's not the whole file):\n```\n`location /socket.io {\n  proxy_pass http://api;\n\n  proxy_http_version 1.1;\n  proxy_set_header Upgrade $http_upgrade;\n  proxy_set_header Connection \"Upgrade\";\n  proxy_set_header Host $host; }\n`\n```\n\nsetupProxy.js file:\n```\n`const { createProxyMiddleware } = require('http-proxy-middleware');\n\nmodule.exports = function (app) {\n  app.use(\n    '/api',\n    createProxyMiddleware({\n      target: 'http://main-be:5001',\n      changeOrigin: true,\n    })\n  );\n};\n`\n```\nfrontend/src/utils/axios.js:\n```\n`import axios from 'axios';\nexport const baseURL = 'https://example.com';\nexport default axios.create({ baseURL });\n`\n```\nfrontend/src/utils/constants.js:\n```\n`const API_BASE_ORIGIN = 'https://example.com';\nexport { API_BASE_ORIGIN };\n`\n```",
      "question_score": 5,
      "answer_score": 3,
      "created_at": "2022-04-22T21:31:49",
      "url": "https://stackoverflow.com/questions/71973771/socket-io-error-with-nginx-when-deploying-a-mern-app-with-docker"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 74423918,
      "title": "How can I get the remote IP / Client IP using NGINX in Docker ?? Also using Laravel",
      "problem": "I am running NGINX as part of a Docker package.  It is both a webserver and a reverse proxy, and the container has PHP bundled in with it.  The front-end web application is built with Laravel.  There are some instances where I want to get the client's IP address, and this seems to a little problematic in some cases.  This isn't for the proxy, but for the web application served with NGINX and PHP.\nOn my development system at home I am getting an IP for the docker network when connecting with a browser from my local machine.\n```\n`$_SERVER['SERVER_ADDR'] = 172.19.0.10\n$_SERVER['REMOTE_ADDR'] = 172.19.0.1\n`\n```\nOn a Digital Ocean Dev server it has:\n```\n`$_SERVER['SERVER_ADDR'] 172.27.0.16\n$_SERVER['REMOTE_ADDR'] 213.225.x.xx, which is Austria, my IP\n`\n```\nand on a Production server elsewhere I think it has:\n```\n`$_SERVER['SERVER_ADDR'] ???\n$_SERVER['REMOTE_ADDR'] = The WAN IP for the office where the server is installed.\n`\n```\nThis isn't the client IP, but the WAN address for the office itself.\nThe server at that office is behind I think a WatchGuard or Fortigate router / Firewall.\nSo, the Digital Ocean Dev server is actually \"OK\".  I have access to what I need, but the office setup probably isn't setup to forward the client ip to the server that runs on their internet ?\nIt isnt' critical currently, but it would be nice to be able to capture to public client IP in all cases.\nI could do a little more investigation with log files, etc., but pretty sure I'll have to:\n\nPossibly configure something in my NGINX config\n\nand/or\n\nHave someone configure the firewall to pass through the client IP because it seems like it isn't doing that currently, or I'm not capturing what it is sending.",
      "solution": "The nginx proxy at the office can be configured to pass the client's IP address using the `proxy_set_header` directive.\nThe nginx reverse proxy docs here show an example:\n```\n`location /some/path/ {\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_pass http://localhost:8000;\n}\n`\n```\nIn the config block where the reverse proxy `proxy_pass` directive is set, adding `proxy_set_header X-Real-IP $remote_addr;` tells the proxy to inject a new HTTP header, `X-Real-IP`, with the IP address of the client. In the Laravel app, you can use this to get the actual client IP. In your application, make sure only to use this header when it can be trusted1.\nThis is necessary because the proxy is taking and re-sending the client's request via the proxy server from its own network address. The only way the application can get the original client IP for the request being proxied is if that IP address is passed in the headers by the proxy.\n1 https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-For#security_and_privacy_concerns",
      "question_score": 5,
      "answer_score": 3,
      "created_at": "2022-11-13T20:06:20",
      "url": "https://stackoverflow.com/questions/74423918/how-can-i-get-the-remote-ip-client-ip-using-nginx-in-docker-also-using-lara"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 68510733,
      "title": "Dart http.MultipartRequest not sending data to Lumen after relocating server to a different apache server, Postman works fine",
      "problem": "I have a multipart request I'm trying to send from my Flutter app to my remote Lumen/Apache server. This code was working fine when I was hosting my Lumen server in Homestead locally, which runs nginx.\nThe Lumen server itself responds accurately when sending the request via Postman. I doubt the Flutter application is sending nothing at all, as it was working before the server move. Since it's not the Lumen app, as it works with Postman, then I presume it has something to do with apache.\nThe header I set, using `http.MultipartRequest()` is (in Postman I used `form-data`):\n```\n`headers['Content-Type'] = 'multipart/form-data';\n`\n```\nI also have an `Authorization Bearer: token` header which works fine, as the app would've presented an Unauthorized response before running the route.\nI have the following code:\n```\n`    ...\n    print(\"Multipart request fields: \" + request.fields.toString());\n    print(\"Multipart request files: \" + request.files.toString());\n    var streamedResponse = await request.send();\n    response = await http.Response.fromStream(streamedResponse);\n    if (response.statusCode == 200) print('Uploaded!');\n`\n```\nI get the following output in debug:\n```\n`I/flutter ( 7073): Multipart request fields: {productName: new, description: new, price: 30.0, currency: USD, quantity: -1.0, mass: 0.0, massUnit: lb, isData: true}\nI/flutter ( 7073): Multipart request files: [Instance of 'MultipartFile']\n`\n```\nIn my Lumen application, I have a function that simply does:\n```\n`    var_dump($request->all());\n    die;\n`\n```\nI get the following result:\n```\n`I/flutter ( 7073): array(1) {\nI/flutter ( 7073):   [\"_method\"]=>\nI/flutter ( 7073):   string(4) \"POST\"\nI/flutter ( 7073): }\n`\n```\nThis arrived from the request not passing validation checks. Before this, I had the longer function:\n```\n` $validator = Validator::make($request->all(), [\n            'productName' => 'required',\n            'description' => 'required',\n            'image' => 'sometimes|image|mimetypes:image/jpeg,image/png|max:600',// TODO remove sometimes from this\n            'price' => 'required',\n            'currency' => 'required|string',\n            'quantity' => 'required',\n            'mass' => 'numeric',\n            'massUnit' => 'required|string',\n            'isData' => 'present|string|nullable',\n        ]);\n`\n```\nAnd it was failing the validation tests, even though the data was apparently being sent (and it used to pass before the server move).\nWhat could the reason be? It seems the only difference is moving from an nginx local Homestead server to a remote apache server. I thought maybe I need a different header, possibly.\nUpdate\nWith some more testing, I found that the request works without error if there is no image in the multipart/form-data request. The issue seems to rely on there being a file attached. Apparently, when and only when there is a file attached, the server reports that no data was sent.\nI have two very similar requests, one that is POST and one that is PATCH. I found that with Postman, using the request that is a PATCH, sending it as a PATCH requests results in the same issue -- no data sent. Sending it as a POST request with the field \"_method\" set to \"PATCH\" does work, however. The request that is a POST request (to add a new item) works fine without the \"_method\" field, when set to a POST request.\nThe POST endpoint is responding as if `http` is not sending a \"POST\" request (empty data). With the PATCH endpoint, Lumen is responding as if it was a \"POST\" request.\nHere's the difference between Postman and `http.MultipartRequest`:\n```\n`With POST request:\nPostman: POST request + \"_method: POST\": Works\nhttp: POST request + \"_method: POST\": No data sent\n\nWith PATCH request:\nPostman: POST request + \"_method: PATCH\": Works\nPostman: PATCH request without \"_method\": No data sent\nhttp: POST request + \"_method: PATCH\": 405 Method Not Allowed (as if it was a PATCH request)\n`\n```\nAgain, the properly formed requests work if there is no file attached (and everything else is the same). It's when the http request has a file that it suddenly works unexpectedly.\nIn the last server, I could not fully test the http functionality as I was using localtunnel.js to forward requests to my phone from Homestead, but it has a file size limit that I didn't want to work with. I did know that dart's `http` was sending the file, however, due to the `413 Request Entity Too Large` responses that didn't occur without the image.\nHere's the output of the request object in Flutter's DevTools (sorry it's a picture -- it doesn't permit selecting the text):\n\nWhen not including a file, the request looks identical except for that files list is empty. Despite this, a request without a file is received by the server with data, while the other results in no data apparently sent.\nThe headers field of the request object looks fine too, with `Content-Type` being present. The authorization field clearly works, too, otherwise I would be getting unauthorized errors. Since the request object looks fine, something between `request.send();` and the Lumen app is dropping all of the data if there is a file attached. Where it's coming from -- the Flutter app or the server -- is difficult to be sure about. (Considering the Flutter app was definitely sending something large when a file was attached when I was using localtunnel.js, it seems likely to be on the server side, as it seems the Flutter app is sending data, just the server is dropping it if there is a file. However, Postman works without hiccup, which suggests the server is functioning correctly.)\nUpdate\nMy answer was a bit early. PHP was throwing away all of the data because the file was too large. After editing php.ini for `post_max_size` and `upload_max_filesize`, the data did start making it through, and, at first, I thought that indicated it was working.\nHowever, it turns out that while now the non-file data is making it through, and using `mod_dumpio`, I see that the file is being sent, when the request comes from Flutter's `http.multipartRequest`, the server is dropping the file, specifically. When the request comes from Postman, everything works fine. I made sure to test with the exact same image, as well, and there seems to be no difference in the requests.",
      "solution": "Recently I was working with sending MultipartFile to our server on MongoDB/HapiJS server. While it worked in postman and with vue web app, I struggled on Flutter to find out why it didn't work.\nIn our case the solution was rather silly, but it worked:\nWhen sending the file I used MultipartFile.fromBytes(byteData), and after changing it to MultipartFile.fromFile(filePath) it worked.\nCould you check this (or other way around) and tell if it works?",
      "question_score": 5,
      "answer_score": 1,
      "created_at": "2021-07-24T16:03:06",
      "url": "https://stackoverflow.com/questions/68510733/dart-http-multipartrequest-not-sending-data-to-lumen-after-relocating-server-to"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67402767,
      "title": "Can&#39;t see FastAPI documentation with 2 main.py and 1 nginx reverse proxy",
      "problem": "I'm using fastAPI together with nginx, as a reverse proxy. I split APIs into 2 different main.py with different endpoints:\n\nmain.py -> main location/endopoint of APIs: `/`  (port 5010)\nmain_slow.py -> main location/endopoint of APIs: `/slow_api`  (port 5011)\n\nto run them on different ports (5010,5011). This because one API is very slow and requesting APIs in series i need one to be separate from the others (in main_slow.py). Using nginx as a reverse proxy, I can call the APIs with their own endpoints under a single port (8000), then nginx will take care of passing them to the correct port of fastAPI.\nAll works well, the only problem is that i can't see all API documentations in /docs, but only endpoints of the first main.py (location `/`).\nin `/nginx/conf.d/` i have `py_api.conf` and i have configured it like this:\n```\n`server {\n\n        listen 8000;\n\n        location / {\n\n                proxy_redirect off;\n                proxy_set_header Host $host;\n                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n                proxy_http_version 1.1;\n                proxy_set_header Connection \"\";\n\n                add_header 'Access-Control-Allow-Origin' '*';\n                add_header 'Access-Control-Allow-Methods' 'GET, POST, PATCH, PUT, DELETE, OPTIONS';\n                add_header 'Access-Control-Allow-Headers' 'Authorization,Content-Type,Origin,X-Auth-Token';\n                add_header 'Access-Control-Allow-Credentials' 'true';\n\n                if ($request_method = OPTIONS ) {\n                        return 200;\n                }\n\n                proxy_pass http://localhost:5010;\n                proxy_set_header Connection \"Keep-Alive\";\n                proxy_set_header Proxy-Connection \"Keep-Alive\";\n\n                auth_basic \"Restricted\";                                #For Basic Auth\n                auth_basic_user_file /etc/nginx/.htpasswd-pyapi;  #For Basic Auth\n        }\n        location /slow_api{\n\n                proxy_redirect off;\n                proxy_set_header Host $host;\n                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n                proxy_http_version 1.1;\n                proxy_set_header Connection \"\";\n\n                add_header 'Access-Control-Allow-Origin' '*';\n                add_header 'Access-Control-Allow-Methods' 'GET, POST, PATCH, PUT, DELETE, OPTIONS';\n                add_header 'Access-Control-Allow-Headers' 'Authorization,Content-Type,Origin,X-Auth-Token';\n                add_header 'Access-Control-Allow-Credentials' 'true';\n\n                if ($request_method = OPTIONS ) {\n                        return 200;\n                }\n\n                proxy_pass http://localhost:5011;\n                proxy_set_header Connection \"Keep-Alive\";\n                proxy_set_header Proxy-Connection \"Keep-Alive\";\n\n                auth_basic \"Restricted\";                                #For Basic Auth\n                auth_basic_user_file /etc/nginx/.htpasswd-pyapi;  #For Basic Auth\n        }\n}\n\n`\n```\nDid I do something wrong to be able to see the documentation of both locations? Or do I have to do something about python and fastAPI?\nSOLVED\nTo see all two documentation (for now in two different path) i added in my fastAPI project main_slow.py\n```\n`app = FastAPI(  title='slow API',\n                docs_url='/slow_api/docs', \n                redoc_url='/slow_api/redoc',\n                openapi_url='/slow_api/openapi.json')\n`\n```\ninstead only\n```\n`app = FastAPI()\n`\n```",
      "solution": "You may want to check out these:\n\nhttps://stackoverflow.com/a/67435809/15229101\nhttps://fastapi.tiangolo.com/advanced/behind-a-proxy/\n\nDo you want to see documentations of the both API at the same route? Then have a look at Behind a Proxy: Additional Servers\nIf you are okay with setting different routes for each API documentation, then you can pass the docs_url, redoc_url and openapi_url arguments to FastAPI class and handle the situation I guess. Have a look at this.",
      "question_score": 5,
      "answer_score": 3,
      "created_at": "2021-05-05T15:56:29",
      "url": "https://stackoverflow.com/questions/67402767/cant-see-fastapi-documentation-with-2-main-py-and-1-nginx-reverse-proxy"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67440861,
      "title": "NGINX add two variable/arguments numbers",
      "problem": "I'm trying to set up an Nginx, where I want to add two numbers together.\n```\n`server {\n        server_name \"~^pr-(\\d*).review-apps.example.com$\";\n        \n        location / {\n            set $port 50000+$1;\n            proxy_pass \"http://localhost:$port/test\";\n        }\n    } \n`\n```\nBut this doesn't work \ud83d\ude44. (Result is in string. For example \"50000+125\")\nHow can I add two numbers in nginx.conf? Is it even possible?",
      "solution": "If you use fixed length numbers, for example only three digits, for this particular case you can use string concatenation instead of adding numbers:\n`server {\n    server_name \"~^pr-(\\d{3}).review-apps.example.com$\";\n        \n    location / {\n        set $port 50$1;\n        proxy_pass \"http://localhost:$port/test\";\n    }\n}\n`\nThis will give you exactly `50145` for the `pr-125.review-apps.example.com` hostname.\nFor variable count of port number digits you can use named regex capture group:\n```\n`server {\n    server_name  \"~^pr-(?\\d).review-apps.example.com$\"\n                 \"~^pr-(?\\d{2}).review-apps.example.com$\"\n                 \"~^pr-(?\\d{3}).review-apps.example.com$\";\n\n    location / {\n        if ($pr1) { set $port 5000$pr1; }\n        if ($pr2) { set $port 500$pr2; }\n        if ($pr3) { set $port 50$pr3; }\n        proxy_pass \"http://localhost:$port/test\";\n    }\n}\n`\n```",
      "question_score": 5,
      "answer_score": 2,
      "created_at": "2021-05-07T21:45:16",
      "url": "https://stackoverflow.com/questions/67440861/nginx-add-two-variable-arguments-numbers"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 65981289,
      "title": "Connect React App served on dockerized Nginx to Express server",
      "problem": "For production, I have a `Dockerfile` which serves a React app using Nginx:\n```\n`# Stage 1\n\nFROM node:15.6.0-alpine3.10 as react-build\nWORKDIR /app/client/\nCOPY package*.json ./\nRUN npm install\nCOPY ./ ./\nRUN npm run build\n\n# Stage 2 - the production environment\n\nFROM nginx:1.19.6\nCOPY nginx.conf /etc/nginx/conf.d/default.conf\nCOPY --from=react-build /app/client/build /usr/share/nginx/html\nEXPOSE 80\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n`\n```\nWhile for the backend written in Node / Express, I have the following `Dockerfile`:\n```\n`FROM node:15.6.0-alpine3.10\nWORKDIR /app/server/\nCOPY package*.json ./\nRUN npm install\nCOPY ./ ./\nEXPOSE 8080\nCMD [\"npm\", \"start\"]\n`\n```\nThese containers are managed with this `docker-compose.yml`:\n```\n`version: \"3.0\"\n\nservices:\n  # React Client\n  web:\n    image: xxx.dkr.ecr.eu-west-2.amazonaws.com/client:latest\n    ports:\n      - \"80:80\"\n\n  # Node Server\n  server:\n    image: xxx.dkr.ecr.xxx.amazonaws.com/server:latest\n    command: npm start\n    ports:\n      - \"8080:8080\"\n`\n```\nHere the `nginx.conf`:\n```\n`server {\n  listen 80;\n  \n  location / {\n    root /usr/share/nginx/html;\n    index index.html index.htm;\n    try_files $uri $uri/ /index.html =404;\n  }\n  \n  include /etc/nginx/extra-conf.d/*.conf;\n}\n`\n```\nPREMISES\n\nOn local everything works fine, I run React through `react-scripts` and the backend with `docker-compose` (and so without the React client)\nBoth images have been pushed to `AWS ECR`, their content is the equivalent of the `Dockerfile` above\nWhen fetching the server, endpoints look like `fetch(\"/users/:id\", {..})`\nOn `package.json`, I've set `\"proxy\": \"http://localhost:8080/\"`\nBoth images have both been tested and are working, both on dev and prod\n\nPROBLEM\nWhen hitting an api endpoint from the client, I get a `405 (Not Allowed)`.\nThat's actually expected, as I'm not really telling the client (Nginx) where to redirect these calls to.\nInspecting the network tab I can see the request is made against `xxx.xxx.xxx.xxx:80` (which represents the client), when it should be redirected to same address but port `8080` instead (where the Express server stands).\nOn development it works since there's `proxy` set on `package.json`, but that's for development only, so it won't affect production.\nWHAT I TRIED\n\nUsing `links` on `docker-compose`, not supported from `AWS`\nUsing `driver networks` on `docker-compose`, not supported from `AWS`\nAdding `proxy_pass` on `nginx.conf`, but haven't been able to make it working\n\nCONCLUSIONS\nSo premised all this, how can I connect a React build served with Nginx (client) to a Node server when both dockerized and on production?\nI believe it should need some configuration on `nginx.conf`, but what I tried didn't land me that far.\nThank you in advance for your help!",
      "solution": "First you need to specify proxy pass directive for your api calls - I would propose to add `/api` in your fetch calls. Than provide upstream using the same name for your backend service as specified in docker-compose.yml. It is important that backend service proceed the web service in docker-compose.yml, otherwise you would get connection error in nginx like this `nginx: [emerg] host not found in upstream \"backend:8080\"` You can update your nginx.conf as follows:\n```\n`upstream backend {\n  server backend:8080;\n}\n\nserver {\n  listen 80;\n  \n  location / {\n    root /usr/share/nginx/html;\n    index index.html index.htm;\n    try_files $uri $uri/ /index.html =404;\n  }\n\n  location /api {\n    rewrite /api/(.*) /$1 break;\n    proxy_pass http://backend;\n  }\n  \n  include /etc/nginx/extra-conf.d/*.conf;\n}\n`\n```\nOr simply in your case provide a proxy pass to localhost as follows:\n```\n`server {\n   listen 80;\n      \n   location / {\n     root /usr/share/nginx/html;\n     index index.html index.htm;\n     try_files $uri $uri/ /index.html =404;\n   }\n  \n   location /api {\n     rewrite /api/(.*) /$1 break;\n     proxy_pass http://localhost:8080;\n   }\n      \n   include /etc/nginx/extra-conf.d/*.conf;\n}\n`\n```",
      "question_score": 5,
      "answer_score": 2,
      "created_at": "2021-01-31T17:09:16",
      "url": "https://stackoverflow.com/questions/65981289/connect-react-app-served-on-dockerized-nginx-to-express-server"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 75175985,
      "title": "502 / 503 / 404 HTTP error : GKE ingress-nginx serving traffic to the wrong services, from other namespaces",
      "problem": "I have this kind of routing in each namespace :\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-ingress\n  annotations:\n    janitor/expires: ${EXPIRY_DATE}\n    nginx.ingress.kubernetes.io/ssl-redirect: \"false\" # Set to true once SSL is set up.\nspec:\n  ingressClassName: nginx\n  rules:\n    - host: api.${KUBE_DEPLOY_HOST}\n      http:\n        paths:\n        - pathType: Prefix\n          path: /\n          backend:\n            service:\n              name: api-js\n              port:\n                number: 111\n`\n```\nServed by ingress-nginx (!= nginx-ingress) 1.2.1 (same issue with 1.5.1) with Kube 1.22 (or 1.23), one deployment in the ingress-nginx namespace, two replicas in the deployment.\nWhen I check my logs I see that sometimes, I think especially when I deploy new ingress rules in new namespaces (during and after the ingress-nginx reload event) I get 502 / 503 / 404 HTTP error responses from the ingress-nginx controller.\nWhen I look into the detailed log, I see :\n```\n`IP - - [time] \"GET API_ROUTE HTTP/1.1\" 503 592 \"master.frontend.url\" UA 449 0.000 [development-branch-api] [] - - - - ID\n`\n```\nWhich makes me think the request goes wrong because the master frontend is being served a development API response by the ingress-nginx controller, sometimes when the new api service is not even ready.\nWhen I check the ingress from GKE's view it looks like it is serving 3 pods, corresponding to 3 namespaces that should not overlap / mix requests, instead of the one api pod in the namespace corresponding to the ingress :\n\nSo the error is seen here, all the ingresses for each 3 namespsace serve 3 pods instead of one pod, which means it is all mixed up, right.\nI am sure there is one pod per deployment in my namespaces :\n\nSo if I understand correctly, it seems that the situation is ingress A, ingress B and ingress C, all three of them, serve api A AND api B AND api C instead of serving just the one api pod from their namespace (A, B, C).\nBut what I don't know is how is it possible that the ingress matches pods from other namespaces, when I am not using externalname, it is the opposite of what an ingress does by default.\nI believe the issue is at the ingress level and not at the service level, as when I look into each service, I see that it just serve the one pod corresponding to its namespace and not 3.\nThe controller is the default ingress-nginx installation edited to use 2 replicas instead of one.\nExample service and deployment (issue happens for all of them) :\n```\n`apiVersion: v1\nkind: Service\nmetadata:\n  name: api-js\n  labels:\n    component: api-js\n    role: api-js\n  annotations:\n    janitor/expires: ${EXPIRY_DATE}\nspec:\n  type: ClusterIP\n  selector:\n    role: perfmaker-api-js\n  ports:\n    - name: httpapi\n      port: 111\n      targetPort: 111\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-js\n  annotations:\n    janitor/expires: ${EXPIRY_DATE}\nspec:\n  replicas: 1\n  strategy:\n    type: Recreate\n  selector:\n    matchLabels:\n      app: api-js\n  template:\n    metadata:\n      annotations:\n        cluster-autoscaler.kubernetes.io/safe-to-evict: \"false\"\n      labels:\n        app: api-js\n        role: api-js\n    spec:\n      containers:\n        - name: api-js\n          image: registry/api\n`\n```\nWhen I change the api name / selectors on one branch, it \"untangles\" the situation and each branch / namespace's ingress only serves the pod it should serve.\nBut the errors happen during and after 'reload' event on the ingress-controller, not all the time, an event which is fired when ingress resources are added / removed / updated. In my case it is when there is a new branch in the CI/CD which makes a new namespace and deployment + ingress, or when a finished pipeline triggers a namespace deletion.",
      "solution": "Alas I must admit I just discovered the error does not originate from the kubernetes / ingress-nginx part of the setup but from the testing system, which includes a collision between services at deploy time, because of bad separation in the CI / CD job. Sorry for your time !\nSo in fact the logs from ingress nginx that stunned me :\n```\n`IP - - [time] \"GET API_ROUTE HTTP/1.1\" 503 592 \"master.frontend.url\" UA 449 0.000 [development-branch-api] [] - - - - ID\n`\n```\nShows that a service I deploy is overwritten by another environment deployment with different variables, which makes it start to make request to another namespace. The ingress routing is correct.",
      "question_score": 5,
      "answer_score": 1,
      "created_at": "2023-01-19T18:19:12",
      "url": "https://stackoverflow.com/questions/75175985/502-503-404-http-error-gke-ingress-nginx-serving-traffic-to-the-wrong-serv"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 68649773,
      "title": "Compilation of nginx fails due to struct &#39;crypt_data&#39; has no member named &#39;current_salt&#39;",
      "problem": "I am trying to compile nginx on Ubuntu machine with GCC. My Glibc version is 2.31.\n```\n`m@feynman:~/Junk/nginx-1.9.9\n$ /lib/x86_64-linux-gnu/libc.so.6 --version\nGNU C Library (Ubuntu GLIBC 2.31-0ubuntu9.2) stable release version 2.31.\n`\n```\nI have downloaded a bunch of different versions from https://nginx.org/download/ and tried with them and fails every time.\n```\n`./configure --with-threads --with-http_ssl_module --with-cc-opt=\"-Wno-error\"\nmake\n`\n```\n./configure generates following file in `objs/Makefile`:\n```\n`CC =    cc\nCFLAGS =  -pipe  -O -W -Wall -Wpointer-arith -Wno-unused -Werror -g -Wno-error\nCPP =   cc -E\nLINK =  $(CC)\n\n...\n`\n```\nThis gives me this error below.\n```\n`cc -c -pipe  -O -W -Wall -Wpointer-arith -Wno-unused -Werror -g -Wno-error -I src/core -I src/event -I src/event/modules -I src/os/unix -I objs \\\n    -o objs/src/os/unix/ngx_posix_init.o \\\n    src/os/unix/ngx_posix_init.c\ncc -c -pipe  -O -W -Wall -Wpointer-arith -Wno-unused -Werror -g -Wno-error -I src/core -I src/event -I src/event/modules -I src/os/unix -I objs \\\n    -o objs/src/os/unix/ngx_user.o \\\n    src/os/unix/ngx_user.c\nsrc/os/unix/ngx_user.c: In function \u2018ngx_libc_crypt\u2019:\nsrc/os/unix/ngx_user.c:36:7: error: \u2018struct crypt_data\u2019 has no member named \u2018current_salt\u2019\n   36 |     cd.current_salt[0] = ~salt[0];\n      |       ^\nmake[1]: *** [objs/Makefile:749: objs/src/os/unix/ngx_user.o] Error 1\nmake[1]: Leaving directory '/home/m/Junk/nginx-1.9.9'\nmake: *** [Makefile:8: build] Error 2\n`\n```\nI tried installing SSL lib and others like that and thought it would help and nothing worked.\n```\n`sudo apt install libpcre3-dev libssl-dev\n`\n```",
      "solution": "In case anyone was looking for a solution to the problem itself:\nThe field `current_salt` is no longer the name of the field where the result is stored and needs to be updated.\nInstead, the field name is `output`, as defined in `/usr/include/crypt.h` on such a system:\n```\n`/* Memory area used by crypt_r.  */\nstruct crypt_data\n{\n  /* crypt_r writes the hashed password to this field of its 'data'\n     argument.  crypt_rn and crypt_ra do the same, treating the\n     untyped data area they are supplied with as this struct.  */\n  char output[CRYPT_OUTPUT_SIZE];\n`\n```",
      "question_score": 5,
      "answer_score": 1,
      "created_at": "2021-08-04T12:39:31",
      "url": "https://stackoverflow.com/questions/68649773/compilation-of-nginx-fails-due-to-struct-crypt-data-has-no-member-named-curre"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66134708,
      "title": "Nginx-ingress worker processes constantly restarting",
      "problem": "I recently upgraded my ingress controller to kubernetes-ingress  v1.10.0. The ingresses seem to route traffic correctly but after checking the pods logs, I noticed a huge amount of notice were generated:\n```\n`2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2748\n2021/02/10 09:40:23 [notice] 19#19: worker process 2748 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2745\n2021/02/10 09:40:23 [notice] 19#19: worker process 2745 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\nW0210 09:40:23.416499       1 listers.go:79] can not retrieve list of objects using index : Index with name namespace does not exist\nW0210 09:40:23.416812       1 listers.go:79] can not retrieve list of objects using index : Index with name namespace does not exist\nW0210 09:40:23.416912       1 listers.go:79] can not retrieve list of objects using index : Index with name namespace does not exist\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2735\n2021/02/10 09:40:23 [notice] 19#19: worker process 2735 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2737\n2021/02/10 09:40:23 [notice] 19#19: worker process 2737 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: worker process 2742 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2746\n2021/02/10 09:40:23 [notice] 19#19: worker process 2746 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2744\n2021/02/10 09:40:23 [notice] 19#19: worker process 2744 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2740\n2021/02/10 09:40:23 [notice] 19#19: worker process 2740 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2736\n2021/02/10 09:40:23 [notice] 19#19: worker process 2736 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2741\n2021/02/10 09:40:23 [notice] 19#19: worker process 2734 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: worker process 2741 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2739\n2021/02/10 09:40:23 [notice] 19#19: worker process 2739 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2738\n2021/02/10 09:40:23 [notice] 19#19: worker process 2738 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2743\n2021/02/10 09:40:23 [notice] 19#19: worker process 2743 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2749\n2021/02/10 09:40:23 [notice] 19#19: worker process 2749 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2747\n2021/02/10 09:40:23 [notice] 19#19: worker process 2747 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [warn] 2718#2718: *6697105 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/6/79/0000214796 while reading upstream, client: xxxx, server: xxxx, request: \"GET /xxxx HTTP/1.1\", upstream: \"xxxx\", host: \"xxxx\", referrer: \"xxxx\"\n2021/02/10 09:40:23 [notice] 2769#2769: signal process started\n2021/02/10 09:40:23 [notice] 19#19: signal 1 (SIGHUP) received from 2769, reconfiguring\n2021/02/10 09:40:23 [notice] 19#19: reconfiguring\n2021/02/10 09:40:23 [notice] 19#19: using the \"epoll\" event method\n2021/02/10 09:40:23 [notice] 19#19: start worker processes\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2770\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2771\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2772\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2773\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2774\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2775\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2776\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2777\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2778\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2779\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2780\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2781\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2782\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2783\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2784\n2021/02/10 09:40:23 [notice] 19#19: start worker process 2785\n90.114.22.230 - - [10/Feb/2021:09:40:23 +0000] \"GET /xxxx HTTP/1.1\" 200 352910 \"xxxx\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:84.0) Gecko/20100101 Firefox/84.0\" \"-\"\n2021/02/10 09:40:23 [notice] 2753#2753: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2755#2755: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2760#2760: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2755#2755: exiting\n2021/02/10 09:40:23 [notice] 2753#2753: exiting\n2021/02/10 09:40:23 [notice] 2762#2762: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2760#2760: exiting\n2021/02/10 09:40:23 [notice] 2766#2766: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2762#2762: exiting\n2021/02/10 09:40:23 [notice] 2766#2766: exiting\n2021/02/10 09:40:23 [notice] 2759#2759: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2759#2759: exiting\n2021/02/10 09:40:23 [notice] 2763#2763: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2761#2761: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2767#2767: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2763#2763: exiting\n2021/02/10 09:40:23 [notice] 2767#2767: exiting\n2021/02/10 09:40:23 [notice] 2761#2761: exiting\n2021/02/10 09:40:23 [notice] 2760#2760: exit\n2021/02/10 09:40:23 [notice] 2753#2753: exit\n2021/02/10 09:40:23 [notice] 2766#2766: exit\n2021/02/10 09:40:23 [notice] 2764#2764: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2764#2764: exiting\n2021/02/10 09:40:23 [notice] 2752#2752: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2752#2752: exiting\n2021/02/10 09:40:23 [notice] 2763#2763: exit\n2021/02/10 09:40:23 [notice] 2762#2762: exit\n2021/02/10 09:40:23 [notice] 2764#2764: exit\n2021/02/10 09:40:23 [notice] 2759#2759: exit\n2021/02/10 09:40:23 [notice] 2755#2755: exit\n2021/02/10 09:40:23 [notice] 2752#2752: exit\n2021/02/10 09:40:23 [notice] 2767#2767: exit\n2021/02/10 09:40:23 [notice] 2761#2761: exit\n2021/02/10 09:40:23 [notice] 2758#2758: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2758#2758: exiting\n2021/02/10 09:40:23 [notice] 2756#2756: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2756#2756: exiting\n2021/02/10 09:40:23 [notice] 2758#2758: exit\n2021/02/10 09:40:23 [notice] 2756#2756: exit\n2021/02/10 09:40:23 [notice] 2765#2765: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2765#2765: exiting\n2021/02/10 09:40:23 [notice] 2757#2757: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2757#2757: exiting\n2021/02/10 09:40:23 [notice] 2754#2754: gracefully shutting down\n2021/02/10 09:40:23 [notice] 2754#2754: exiting\n2021/02/10 09:40:23 [notice] 2754#2754: exit\n2021/02/10 09:40:23 [notice] 2765#2765: exit\n2021/02/10 09:40:23 [notice] 2757#2757: exit\nI0210 09:40:23.604803       1 event.go:282] Event(v1.ObjectReference{Kind:\"Ingress\", Namespace:\"xxxx\", Name:\"xxxx\", UID:\"82a71705-194e-4919-a7e2-a511d52c1a7a\", APIVersion:\"networking.k8s.io/v1beta1\", ResourceVersion:\"77919848\", FieldPath:\"\"}): type: 'Normal' reason: 'AddedOrUpdated' Configuration for xxxx/xxxx was added or updated \nI0210 09:40:23.604873       1 event.go:282] Event(v1.ObjectReference{Kind:\"Ingress\", Namespace:\"xxxx\", Name:\"xxxx\", UID:\"10246997-07ae-41e1-b811-0ec630647f3b\", APIVersion:\"networking.k8s.io/v1beta1\", ResourceVersion:\"182677830\", FieldPath:\"\"}): type: 'Normal' reason: 'AddedOrUpdated' Configuration for xxxx/xxxx was added or updated \nI0210 09:40:23.605520       1 event.go:282] Event(v1.ObjectReference{Kind:\"Ingress\", Namespace:\"xxxx\", Name:\"xxxx\", UID:\"d628825f-1b06-4719-b4b0-4d971b8c0a54\", APIVersion:\"networking.k8s.io/v1beta1\", ResourceVersion:\"182677778\", FieldPath:\"\"}): type: 'Normal' reason: 'AddedOrUpdated' Configuration for xxxx/xxxx was added or updated \nI0210 09:40:23.605557       1 event.go:282] Event(v1.ObjectReference{Kind:\"Ingress\", Namespace:\"xxxx\", Name:\"xxxx\", UID:\"4b7b1fa1-1d7d-41a5-9d97-5f5aee52ade7\", APIVersion:\"networking.k8s.io/v1beta1\", ResourceVersion:\"182678922\", FieldPath:\"\"}): type: 'Normal' reason: 'AddedOrUpdated' Configuration for xxxx/xxxx was added or updated \nI0210 09:40:23.605569       1 event.go:282] Event(v1.ObjectReference{Kind:\"Ingress\", Namespace:\"xxxx\", Name:\"xxxx\", UID:\"b86b8b8e-82b9-40d0-b02d-073db557c0e1\", APIVersion:\"networking.k8s.io/v1beta1\", ResourceVersion:\"182678955\", FieldPath:\"\"}): type: 'Normal' reason: 'AddedOrUpdated' Configuration for xxxx/xxxx was added or updated \nI0210 09:40:23.605577       1 event.go:282] Event(v1.ObjectReference{Kind:\"Ingress\", Namespace:\"xxxx\", Name:\"xxxx\", UID:\"585ccdee-9807-442e-9b4f-7d1a97264216\", APIVersion:\"networking.k8s.io/v1beta1\", ResourceVersion:\"182677754\", FieldPath:\"\"}): type: 'Normal' reason: 'AddedOrUpdated' Configuration for xxxx/xxxx was added or updated \nW0210 09:40:23.614001       1 listers.go:79] can not retrieve list of objects using index : Index with name namespace does not exist\nW0210 09:40:23.614213       1 listers.go:79] can not retrieve list of objects using index : Index with name namespace does not exist\nW0210 09:40:23.614304       1 listers.go:79] can not retrieve list of objects using index : Index with name namespace does not exist\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2763\n2021/02/10 09:40:23 [notice] 19#19: worker process 2755 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: worker process 2763 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: worker process 2767 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2766\n2021/02/10 09:40:23 [notice] 19#19: worker process 2752 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: worker process 2753 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: worker process 2766 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2756\n2021/02/10 09:40:23 [notice] 19#19: worker process 2756 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: worker process 2758 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: worker process 2759 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: worker process 2760 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: worker process 2761 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: worker process 2762 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: worker process 2764 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2754\n2021/02/10 09:40:23 [notice] 19#19: worker process 2754 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n2021/02/10 09:40:23 [notice] 19#19: signal 17 (SIGCHLD) received from 2765\n2021/02/10 09:40:23 [notice] 19#19: worker process 2765 exited with code 0\n2021/02/10 09:40:23 [notice] 19#19: signal 29 (SIGIO) received\n`\n```\nThis seem to be looping forever and very quickly, on all the pods.\nI deployed my controller using these manifests and recreated the default server secret as mentioned in the release note.\nThe controller arguments are:\n`args:\n  - -nginx-configmaps=$(POD_NAMESPACE)/nginx-config\n  - -default-server-tls-secret=$(POD_NAMESPACE)/default-server-secret\n  - -global-configuration=$(POD_NAMESPACE)/nginx-configuration\n  - -report-ingress-status\n  - -enable-prometheus-metrics\n  - -enable-snippets\n`\nAnd here is the content of my `nginx-config` CM:\n`data:\n  client-max-body-size: 50m\n  proxy-read-timeout: 5m\n  server-tokens: \"False\"\n`\nAny idea what is happening there and how to solve this issue?\nEdit:\nAfter some more research I found out that two of my ingresses are constantly being updated:\n`Name:             xxxx\nNamespace:        xxxx\nAddress:          \nDefault backend:  default-http-backend:80 ()\nTLS:\n  xxxx terminates xxxx\nRules:\n  Host  Path  Backends\n  ----  ----  --------\n  *     *     default-http-backend:80 ()\nAnnotations:\n  ingress.kubernetes.io/ssl-redirect:                true\n  kubectl.kubernetes.io/last-applied-configuration:  {\"apiVersion\":\"extensions/v1beta1\",\"kind\":\"Ingress\",\"metadata\":{\"annotations\":{\"ingress.kubernetes.io/ssl-redirect\":\"true\",\"kubernetes.io/ingress.class\":\"nginx\",\"nginx.org/mergeable-ingress-type\":\"master\"},\"labels\":{\"app.kubernetes.io/component\":\"xxxx\",\"app.kubernetes.io/instance\":\"xxxx\",\"app.kubernetes.io/name\":\"xxxx\",\"app.kubernetes.io/part-of\":\"xxxx\",\"argocd.argoproj.io/instance\":\"xxxx\"},\"name\":\"xxxx\",\"namespace\":\"xxxx\"},\"spec\":{\"rules\":[{\"host\":\"xxxx\"}],\"tls\":[{\"hosts\":[\"xxxx\"],\"secretName\":\"xxxx\"}]}}\n\n  kubernetes.io/ingress.class:       nginx\n  nginx.org/mergeable-ingress-type:  master\nEvents:\n  Type    Reason          Age                       From                      Message\n  ----    ------          ----                      ----                      -------\n  Normal  AddedOrUpdated  3m5s (x2600127 over 6d)   nginx-ingress-controller  Configuration for xxxx/xxxx was added or updated\n  Normal  AddedOrUpdated  2m12s (x2599793 over 6d)  nginx-ingress-controller  Configuration for xxxx/xxxx was added or updated\n  Normal  AddedOrUpdated  66s (x2600182 over 6d)    nginx-ingress-controller  Configuration for xxxx/xxxx was added or updated\n`\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    ingress.kubernetes.io/ssl-redirect: \"true\"\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"extensions/v1beta1\",\"kind\":\"Ingress\",\"metadata\":{\"annotations\":{\"ingress.kubernetes.io/ssl-redirect\":\"true\",\"kubernetes.io/ingress.class\":\"nginx\",\"nginx.org/mergeable-ingress-type\":\"master\"},\"labels\":{\"app.kubernetes.io/component\":\"xxxx\",\"app.kubernetes.io/instance\":\"xxxx\",\"app.kubernetes.io/name\":\"xxxx\",\"app.kubernetes.io/part-of\":\"xxxx\",\"argocd.argoproj.io/instance\":\"xxxx\"},\"name\":\"xxxx\",\"namespace\":\"xxxx\"},\"spec\":{\"rules\":[{\"host\":\"xxxx\"}],\"tls\":[{\"hosts\":[\"xxxx\"],\"secretName\":\"xxxx\"}]}}\n    kubernetes.io/ingress.class: nginx\n    nginx.org/mergeable-ingress-type: master\n  creationTimestamp: \"2021-01-18T09:55:07Z\"\n  generation: 1\n  labels:\n    app.kubernetes.io/component: xxxx\n    app.kubernetes.io/instance: xxxx\n    app.kubernetes.io/name: xxxx\n    app.kubernetes.io/part-of: xxxx\n    argocd.argoproj.io/instance: xxxx\n  name: xxxx\n  namespace: xxxx\n  resourceVersion: \"182677754\"\n  selfLink: /apis/extensions/v1beta1/namespaces/xxxx/ingresses/xxxx\n  uid: 585ccdee-9807-442e-9b4f-7d1a97264216\nspec:\n  rules:\n  - host: xxxx\n  tls:\n  - hosts:\n    - xxxx\n    secretName: xxxx\nstatus:\n  loadBalancer:\n    ingress:\n    - {}\n`\nMy environment is managed by ArgoCD but after checking the logs it doesn't look like the updates are coming from ArgoCD. I wonder if the updates are related to the `-report-ingress-status` option.\nEdit II:\nI removed the `-report-ingress-status` and it didn't change anything.",
      "solution": "I don't know the actual root cause but I deleted all the TLS secrets, certificates and ingresses that were being constantly being updated and recreated them. It solved this issue.\nDifferent incidents happened prior to this issue and might have been related to it: 2 of my 3 ingress nodes failed, during the upgrade the wrong CRDs were applied before being quickly fixed.\nThat's all I can say at the moment, but deleting the resources related to the ingresses being constantly updated and recreating them do solve the issue.",
      "question_score": 5,
      "answer_score": 1,
      "created_at": "2021-02-10T11:03:07",
      "url": "https://stackoverflow.com/questions/66134708/nginx-ingress-worker-processes-constantly-restarting"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 72600765,
      "title": "Catch-all nginx server blocks for invalid subdomains",
      "problem": "I have multiple domains on a single host, and nginx manages all of them. Each domain has it's own SSL certificate (which I get from certbot, using the \"webroot\" plugin).\nI have a server block at the end of each config file, as a \"catch-all\" (from here and here), to return 404 for invalid subdomains.\nDefault nginx config file `default.conf`:\n`# ...other config...\ninclude /path/to/domain1.conf;\ninclude /path/to/domain2.conf;\n# ...other config...\n`\n`domain1.conf`:\n`# redirect http to https\nserver {\n  listen      80;\n  listen      [::]:80;\n  server_name domain1.com www.domain1.com\n  return      301 https://$host$request_uri;\n}\n\n# redirect naked to www\nserver {\n  listen      443 ssl http2;\n  listen      [::]:443 ssl http2;\n  server_name domain1.com\n  include     path/to/ssl_config.conf\n  return      301 https://www.$host$request_uri;\n}\n\n# serve subdomain www\nserver {\n  listen      443 ssl http2;\n  listen      [::]443 ssl http2;\n  server_name www.domain1.com\n  include     path/to/ssl_config.conf\n  location    / { proxy_pass http://$app; }\n}\n\n# catch-all for invalid subdomains (e.g. foo.domain1.com)\nserver {\n  listen       443 ssl http2 default_server;\n  listen       [::]:443 ssl http2 default_server;\n  server_name: _.domain1.com\n  include      path/to/ssl_config.conf\n  return       404;\n}\n`\n`domain2.conf`:\n`# same as above, but uses \"domain2.com\" instead of \"domain1.com\"\n`\nBut that causes an error:\n\n[emerg] a duplicate default server for xxx.xxx.xxx.xxx:443\n\nIf I remove those `default_server` directives, then it doesn't route properly: a request to `foo.example1.com` redirects to `www.foo.example1.com`, then to `www.www.foo.example1.com`, etc.\nEverything works, except for the invalid subdomain logic. How can I fix it?",
      "solution": "You need only the single default server block to catch everything else that is undefined in other server blocks. You don't need to expose any of your real certificates in that block; use the dummy self-signed certificate/key instead for the security purposes. You don't need to use any `server_name` at all in that block; moreover, that `_` doesn't act as a wildcard at all. You can see that\n```\n`server_name _;\n`\n```\nin some nginx configurations from time to time due to the historical reasons because before nginx 0.7.12 you was required to specify something as `server_name`, which isn't required nowadays anymore. More information provided by the official documentation:\n\nIn catch-all server examples the strange name `\"_\"` can be seen:\n`server {\n    listen       80  default_server;\n    server_name  _;\n    return       444;\n}\n`\nThere is nothing special about this name, it is just one of a myriad of invalid domain names which never intersect with any real name. Other invalid names like `\"--\"` and `\"!@#\"` may equally be used.\n\nUpdate @ 2024.11.06\nSince Nginx 1.19.4, released on Oct 27, 2020, we can greatly simplify the catch-all block by using the `ssl_reject_handshake` directive. This way, we don't need any keys or certificates, and an HTTPS request with the wrong server name passed through the TLS SNI extension will be terminated at a very early phase of the TLS handshake:\n`server {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n    listen 443 default_server ssl;\n    listen [::]:443 default_server ssl;\n    ssl_reject_handshake on;\n    return 444;\n}\n`\nCaution! Using this snippet will effectively block any client that does not support the extended ClientHello message with the SNI extension. If you need to maintain connectivity for legacy client applications or want to support something as ancient as Internet Explorer on Windows XP or Android 2.x, use the solution below instead.\n\nFor nginx versions before 1.19.4, an example of a catch-all block can be as follows:\n`server {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n    listen 443 default_server ssl;\n    listen [::]:443 default_server ssl;\n    ssl_certificate /some/path/any.crt;\n    ssl_certificate_key /some/path/any.key;\n    return 444; # silently drop the connection\n    # or you can define some landing page here\n}\n`\nFor generating a pair of self-signed key/cert in one line you can use the following command:\n```\n`openssl req -nodes -new -x509 -subj \"/CN=localhost\" -keyout /some/path/any.key -out /some/path/any.crt\n`\n```\nA good practice is to put this stub server block as the `/etc/nginx/conf.d/default.conf` or `/etc/nginx/sites-enabled/default` file contents, depending on the vhosts serving style you are actually using (a long read discussion on this subject can be found here at the ServerFault).\nIf you are using certbot, don't allow it to auto-generate redirect server blocks for you in case of using such a stub server block. Since everything with a non valid request hostname will be handled by the stub block, instead of something like\n`server {\n    if ($host = example.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n    if ($host = www.example.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n    listen 80;\n    listen [::]:80;\n\n    server_name example.com www.example.com;\n    return 404; # managed by Certbot\n}\n`\nuse the following one:\n`server {\n    listen 80;\n    listen [::]:80;\n    server_name example.com www.example.com;\n    return 301 https://$host$request_uri;\n}\n`\nTo redirect non-www to www and HTTP to HTTPS, use three server blocks for each hosted vhost:\n```\n`server {\n    listen 80;\n    listen [::]:80;\n    listen 443 ssl;\n    listen [::]:443 ssl;\n    server_name example.com;\n    # ssl certificate/key for 'example.com' domain here\n    return 301 https://www.example.com$request_uri;\n}\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name www.example.com;\n    return 301 https://www.example.com$request_uri;\n}\nserver {\n    listen 443 ssl;\n    listen [::]:443 ssl;\n    server_name www.example.com;\n    # ssl certificate/key for 'www.example.com' domain here\n    # the main configuration part\n    ...\n}\n`\n```\n(If you want to do the opposite, redirect www to non-www, just replace `example.com` with `www.example.com` and vise versa.)",
      "question_score": 4,
      "answer_score": 11,
      "created_at": "2022-06-13T11:42:38",
      "url": "https://stackoverflow.com/questions/72600765/catch-all-nginx-server-blocks-for-invalid-subdomains"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 70831890,
      "title": "website down after installing ssl certificate through certbot in nginx",
      "problem": "Below is my nginx configuration. I modified the 'default' file (which is placed at 'sites-available). I am able to access the website when it's through 'http'. But when I try through 'https', there is a connection time out and the page cannot be reached. Nginx is strangely not making any entries to the logs(both access.log and error.log). I am seeking for help since I am completely new to this.\n```\n`# Please see /usr/share/doc/nginx-doc/examples/ for more detailed examples.\n\n##\n\n# Default server configuration\n#\nserver {\n    listen 80;\n    listen [::]:80;\n\n    root /var/www/main.x.com/html;\n\n    \n    index index.html\n\n    server_name main.x.com;\n\n    location / {\n        # First attempt to serve request as file, then\n        # as directory, then fall back to displaying a 404.\n        try_files $uri $uri/ =404;\n    }\n\n}\n\nserver {\n    listen 443 ssl;\n\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n    ssl_certificate /etc/letsencrypt/live/main.x.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/main.x.com/privkey.pem;\n\n    server_name main.x.com;\n    access_log /var/log/nginx/access.log;\n    error_log /var/log/nginx/error.log;\n\n    location / {\n        root /var/www/main.x.com/html;\n        index index.html;\n    }\n}\n`\n```",
      "solution": "443 port opened in aws ec2\nAfter two days of never ending debegging, I understood the problem. I had not opened 443 port in EC2 security group. Things to keep in mind whomever struggling with a similar issue -> Ensure that your OS firewall allows connections through 443 also ensure that your instance allows connections through 443.",
      "question_score": 4,
      "answer_score": 11,
      "created_at": "2022-01-24T10:51:52",
      "url": "https://stackoverflow.com/questions/70831890/website-down-after-installing-ssl-certificate-through-certbot-in-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 65731044,
      "title": "client intended to send too large body EB Nginx",
      "problem": "I'm trying to increase the size of uploadable files to the server. However it seems there's a cap that prevents anything over 1MB of being uploaded.\nI've read a lot of answers and none have worked for me.\nI've done everything in this question\nStackoverflow question\nI did everything here as well.\nAWS resource\nHere's what I have as the full error\n```\n`2021/01/15 05:08:35 [error] 24140#0: *150 client intended to send too large body: 2695262 bytes, client: [ip-address-removed], server: , request: \"PATCH /user HTTP/1.1\", host: \"host.domain.com\", referrer: \"host.domain.com\"\n`\n```\nI've made a file in this directory (which is at the root of my source code)\n```\n`.ebextensions/nginx/conf.d/myconf.conf\n`\n```\nIn it I have\n```\n`client_max_body_size 40M;\n`\n```\nI know that EB is acknowledging it because if there's an error it won't deploy it.\nOther than that I have no idea what to do\nDoes anybody know what might be the issue here?\nEdit: backend is nodejs v12\nEdit: Also tried this inside of a .conf file in .ebextensions\n```\n`files:\n    \"/etc/nginx/conf.d/myconf.conf\":\n        mode: \"000755\"\n        owner: root\n        group: root\n        content: |\n          client_max_body_size 20M;\n`\n```",
      "solution": "Update:\nBeanstalk on Amazon Linux 2 AMI has a little different path for NGINX config extensions:\n```\n`.platform/nginx/conf.d\n`\n```\nThere you can place NGINX config extension files with `*.conf` extension, for example:\n.platform/nginx/conf.d/upload_size.conf:\n```\n`client_max_body_size 20M;\n`\n```\nDocumentation for this is here.\nOriginal answer:\nNginx normally does not read config from where is serves the content. By default all config nginx read is `/etc/nginx/nginx.conf` and this file includes other files from `/etc/nginx/conf.d/` with `*.conf` extension.\nYou need to place `client_max_body_size 40M;` there.",
      "question_score": 4,
      "answer_score": 11,
      "created_at": "2021-01-15T06:40:32",
      "url": "https://stackoverflow.com/questions/65731044/client-intended-to-send-too-large-body-eb-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 67518393,
      "title": "Symfony and nginx - 502 Bad Gateway error when calling APIs",
      "problem": "I use docker (php7.4 and nginx) for running my Symfony 5 application, I implemented Bearer authentication using `firebase/php-jwt`, and can get a token successfully, but when I try to call the APIs using the token in the header, I get `502 Bad Gateway` (See the Error) from nginx.\nI am sure that the problem comes from my nginx configs, because when I use Symfony Local Web Server, it works.\nnginx configuration:\n```\n`server {\n    listen 80;\n    server_name my.local;\n    root /home/my/public;\n\n    location / {\n    try_files $uri /index.php$is_args$args;\n    }\n\n    location ~ ^/index\\.php(/|$) {\n        fastcgi_pass my-app:9000;\n        fastcgi_split_path_info ^(.+\\.php)(/.*)$;\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;\n        fastcgi_param DOCUMENT_ROOT $realpath_root;\n        internal;\n    }\n\n    location ~ \\.php$ {\n        return 404;\n    }\n\n    location ~ \\.php$ {\n        return 404;\n    }\n\n    error_log /var/log/nginx/my_error.log;\n    access_log /var/log/nginx/my_access.log;\n}\n`\n```",
      "solution": "I increased the buffer size and solved the problem:\n```\n`server {\n    server_name my.local;\n    root /home/my/public;;\n\n    location / {\n    try_files $uri $uri/ /index.php$is_args$args;\n    }\n\n    location ~ ^/index\\.php(/|$) {\n        fastcgi_pass my-app:9000;\n        fastcgi_split_path_info ^(.+\\.php)(/.*)$;\n        fastcgi_buffer_size 128k;\n        fastcgi_buffers 4 256k;\n        fastcgi_busy_buffers_size 256k;\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;\n        fastcgi_param DOCUMENT_ROOT $realpath_root;\n        internal;\n    }\n\n    error_log /var/log/nginx/my_error.log;\n    access_log /var/log/nginx/my_access.log;\n}\n`\n```",
      "question_score": 4,
      "answer_score": 10,
      "created_at": "2021-05-13T13:23:41",
      "url": "https://stackoverflow.com/questions/67518393/symfony-and-nginx-502-bad-gateway-error-when-calling-apis"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66111292,
      "title": "Nginx `proxy_ssl_trusted_certificate` with letsencrypt upstream",
      "problem": "I'm trying to use a `proxy_pass` with nginx where the connection to the upstream server is encrypted. The certificate of the upstream server has been created by a letsencrypt certbot.\n```\n`# upstream server: nginx.conf\n\nstream {\n  server {\n    listen 636 ssl;\n\n    ssl_certificate /etc/letsencrypt/live/upstream.example.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/upstream.example.com/privkey.pem; # managed by Certbot\n\n    # ...\n  }\n}\n`\n```\nWhen not verifying the proxy certificate in the downstream server, everything works fine.\n```\n`# downstream server: nginx.conf\n\nstream {\n  server {\n    listen 636 ssl;\n\n    ssl_certificate /etc/letsencrypt/live/downstream.example.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/downstream.example.com/privkey.pem; # managed by Certbot\n\n    proxy_ssl on;\n    proxy_ssl_verify off;\n\n    proxy_pass upstream.example.com:636;\n\n    # ...\n\n  }\n}\n`\n```\nHowever, if I'm trying to verify the upstream certificate on the downstream server, I'm getting an upstream SSL certificate verify error: (2:unable to get issuer certificate) while SSL handshaking to upstream in the nginx error log.\n```\n`# downstream server: nginx.conf\n\nstream {\n  server {\n    listen 636 ssl;\n\n    ssl_certificate /etc/letsencrypt/live/downstream.example.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/downstream.example.com/privkey.pem; # managed by Certbot\n\n    proxy_ssl on;\n    proxy_ssl_verify on;\n    proxy_ssl_trusted_certificate /etc/nginx/ssl/upstream.example.com/chain.pem;\n    proxy_ssl_verify_depth 2;\n\n    proxy_pass upstream.example.com:636;\n\n    # ...\n\n  }\n}\n`\n```\nWhich settings for `proxy_ssl_trusted_certificate` and `proxy_ssl_verify_depth` do I need if the upstream server I'm trying to connect to has a letsencrypt certificate?\nI've varied `proxy_ssl_verify_depth` from 0 to 5, and I've used the upstream server's `fullchain.pem`, `chain.pem`, and `cert.pem` for `proxy_ssl_trusted_certificate`, but each was unsuccessful.\nAdditional info\nVerifying the CA certificate with `openssl` works:\n```\n`# openssl verify -verify_depth 2 chain.pem\nchain.pem: OK\n`\n```\nVerifying the certificate from the upstream server, `fullchain.pem`, against the CA certificate works:\n```\n`# openssl verify -CAfile chain.pem fullchain.pem\nfullchain.pem: OK\n`\n```\nFurther references\n\nhttps://docs.nginx.com/nginx/admin-guide/security-controls/securing-http-traffic-upstream/\nhttps://nginx.org/en/docs/http/ngx_http_proxy_module.html",
      "solution": "The CA certificate required for `proxy_ssl_trusted_certificate` is not provided by letsencrypt or the upstream server. It is already installed on the downstream server.\nOn Ubuntu, the location of the CA certificate(s) is `/etc/ssl/certs/ca-certificates.crt`.\n```\n`# downstream server: nginx.conf\n\nstream {\n  server {\n    listen 636 ssl;\n\n    ssl_certificate /etc/letsencrypt/live/downstream.example.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/downstream.example.com/privkey.pem; # managed by Certbot\n\n    proxy_ssl on;\n    proxy_ssl_verify on;\n    proxy_ssl_trusted_certificate /etc/ssl/certs/ca-certificates.crt;\n\n    proxy_pass upstream.example.com:636;\n\n    # ...\n\n  }\n}\n`\n```\nDocumentation\nhttps://nginx.org/en/docs/http/ngx_http_proxy_module.html\n\nproxy_ssl_verify on | off;\nEnables or disables verification of the proxied HTTPS server certificate.\nproxy_ssl_verify_depth number;\nSets the verification depth in the proxied HTTPS server certificates chain.\nproxy_ssl_trusted_certificate file;\npecifies a file with trusted CA certificates in the PEM format used to verify the certificate of the proxied HTTPS server.\n\nSee also\n\nhttps://unix.stackexchange.com/a/484938/91720\nhttps://serverfault.com/a/1052976/167331",
      "question_score": 4,
      "answer_score": 10,
      "created_at": "2021-02-09T01:23:28",
      "url": "https://stackoverflow.com/questions/66111292/nginx-proxy-ssl-trusted-certificate-with-letsencrypt-upstream"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 73294167,
      "title": "Livewire image upload fails on production server",
      "problem": "I've deployed my laravel project to vps server(ubuntu) on top of LEMP stack. Everything works fine with livewire, except image uploading.\n\nImage uploading itself works fine on my local environment\n\nWhen I try to upload image Livewire throws validation error saying `The icon failed to upload.`\nThis is becuse of Livewire can't create `livewire-tmp` folder. I've created that folder myself and gave it 755 permission, but still it's not working. I've also published livewire config file and changed some configurations, but still the same.\nI don't know why Livewire can not create `livewire-temp` folder and store temporary files in it. Maybe it's something to do with nginx server configuration. So I am sharing my ngnix configuration:\n```\n`server {\n    listen 80 default_server;\n    #listen [::]:80 default_server;\n\n    root /var/www/html/west-hospital-admin/public;\n    #root /home/west/west-hospital-admin/public;\n\n    # Add index.php to the list if you are using PHP\n    index index.html index.htm index.nginx-debian.html index.php;\n    server_name _;\n\n    location / {\n        try_files $uri $uri/ /index.php$query_string;\n    }\n    # pass PHP scripts to FastCGI server\n\n    location ~ \\.php$ {\n        include snippets/fastcgi-php.conf;\n        fastcgi_pass unix:/var/run/php/php8.1-fpm.sock;\n        fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;\n    }\n}\n`\n```\nI'm placing my project's folder and file permissions if in case is needed. It's likely to be a permission issue.\n\n```\n`storage/app/public folder\n`\n```\n\nNote, that Livewire itself didn't create the `livewire-tmp` folder. I\ncreated it and gave 755 permission to it.\n\n`public` folder, with symbolic link to `storage/app/public` folder\n\nI would very appreciate it if someone who knows why Livewire can not handle uploading can share their knowledge with me. \ud83d\ude42",
      "solution": "Solution\n\nGo to the `vendor/livewire/livewire/src/Controllers/FileUploadHandler.php` and comment this line `abort_unless(request()->hasValidSignature(), 401);`\n\nGo to the `vendor/livewire/livewire/src/TemporaryUploadedFile.php` and instead of this `$tmpfile = tmpfile();`, write this:\n```\n` $tmpfname = tempnam(sys_get_temp_dir(), '');\n $tmpFile = fopen($tmpfname, 'w');\n`\n```\n\nGo to `public` folder of your application and create `livewire` folder.(`mkdir livewire`) After that, go to that directory and from there you will create a symbolic link, pointing from `public/livewire/preview-file` to your application's `storage/app/public/livewire-tmp` folder:\n\n`ln -s preview-file ../../storage/app/public/livewire-tmp`\nAnd remember, you need to give 755 permissions to folders, that are inside `storage/app/public` folder.\n\nExplanation\n\nWe need to comment that line, because it checks whether you have a `ssl certificate` or not. If not, it will abort the request. If you have a ssl certificate, you can skip this step.\n\nIn this step, we create `temporary file` and give write access.\n\nFinal step is just creating a `symbolic link`. We need to create this `symbolic link` because, when uploading a file, Livewire creates a temporary file with that url.",
      "question_score": 4,
      "answer_score": 3,
      "created_at": "2022-08-09T17:12:05",
      "url": "https://stackoverflow.com/questions/73294167/livewire-image-upload-fails-on-production-server"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 76182972,
      "title": "How to serve Vite development server behind an Nginx reverse proxy",
      "problem": "I'm working on a `Typescript` monorepo using `turborepo` that holds multiple microservices (`nextjs`, `expressjs`, `create-react-app`).\neach of these microservices is served in its own `PORT`.\nIn order to make the development experience more fluid, we decided to add a `Nginx` server (in a `docker` image) that will collect all the ports from each Microservice and reserve them all under one `PORT`.\nWhen I tried to add a `Vite react app` and put it behind the same Nginx server, it didn't work because it is trying to access the files in node_modules in my local machine.\nDoes anyone have a workaround?\nBelow is a sample of my configs:\nNginx config file :\n```\n`upstream imgproxy {\n    server imgproxy:3000;\n}\n\nserver {\n    listen 80;\n\n    location / {\n        return 301 https://$host:3000$request_uri;\n    }\n}\n\nserver {\n    listen 443 ssl;\n    client_max_body_size 240M;\n    ssl_certificate    cert/localhost3000.crt;\n    ssl_certificate_key    cert/localhost3000.key;\n\n    location /api/v1/auth {\n          proxy_pass http://host.docker.internal:4001;\n    }\n\n    location /dashboard {\n          proxy_pass https://host.docker.internal:3001;\n    }\n\n    location /api/v1/blogs {\n          proxy_pass http://host.docker.internal:4010;\n    }\n\n    location / {\n          proxy_pass http://host.docker.internal:4200;\n    }\n\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header Host $host;\n\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n    include h5bp/tls/policy_balanced.conf;\n    # Custom error pages\n    include h5bp/errors/custom_errors.conf;\n\n    # Include the basic h5bp config set\n    include h5bp/basic.conf;\n\n}\n`\n```\nMy vite.conf.ts\n```\n`import { defineConfig, loadEnv } from \"vite\";\nimport react from \"@vitejs/plugin-react-swc\";\nimport fs from \"fs\";\nimport tsconfigPaths from \"vite-tsconfig-paths\";\n// https://vitejs.dev/config/\nexport default defineConfig(({ mode }) => {\n  return {\n    base: \"/dashboard\",\n    server: {\n      port: 3001,\n      https: {\n        cert: fs.readFileSync(\"../../nginx/cert/localhost3000.crt\"),\n        key: fs.readFileSync(\"../../nginx/cert/localhost3000.key\"),\n      },\n    },\n    plugins: [react(), tsconfigPaths()],\n  };\n});\n`\n```\nNginx's errors :\n```\n`2023/05/05 13:54:02 [error] 33#33: *2 open() \"/etc/nginx/html/dashboard/node_modules/.vite/deps/react_jsx-dev-runtime.js\" failed (2: No such file or directory), client: 172.20.0.1, server: , request: \"GET /dashboard/node_modules/.vite/deps/react_jsx-dev-runtime.js?v=12d55949 HTTP/1.1\", host: \"localhost:3000\", referrer: \"https://localhost:3000/dashboard/src/index.tsx\"\n172.20.0.1 - - [05/May/2023:13:54:02 +0000] \"GET /dashboard/node_modules/.vite/deps/react_jsx-dev-runtime.js?v=12d55949 HTTP/1.1\" 404 178 \"https://localhost:3000/dashboard/src/index.tsx\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\" \"-\"\n172.20.0.1 - - [05/May/2023:13:54:02 +0000] \"GET /dashboard/@react-refresh HTTP/1.1\" 200 3393 \"https://localhost:3000/dashboard\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\" \"-\"\n2023/05/05 13:54:03 [error] 33#33: *2 open() \"/etc/nginx/html/dashboard/node_modules/.vite/deps/react.js\" failed (2: No such file or directory), client: 172.20.0.1, server: , request: \"GET /dashboard/node_modules/.vite/deps/react.js?v=12d55949 HTTP/1.1\", host: \"localhost:3000\", referrer: \"https://localhost:3000/dashboard/src/index.tsx\"\n172.20.0.1 - - [05/May/2023:13:54:03 +0000] \"GET /dashboard/node_modules/.vite/deps/react.js?v=12d55949 HTTP/1.1\" 404 178 \"https://localhost:3000/dashboard/src/index.tsx\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\" \"-\"\n2023/05/05 13:54:03 [error] 35#35: *6 open() \"/etc/nginx/html/dashboard/node_modules/.vite/deps/react-redux.js\" failed (2: No such file or directory), client: 172.20.0.1, server: , request: \"GET /dashboard/node_modules/.vite/deps/react-redux.js?v=12d55949 HTTP/1.1\", host: \"localhost:3000\", referrer: \"https://localhost:3000/dashboard/src/index.tsx\"\n172.20.0.1 - - [05/May/2023:13:54:03 +0000] \"GET /dashboard/node_modules/.vite/deps/react-redux.js?v=12d55949 HTTP/1.1\" 404 178 \"https://localhost:3000/dashboard/src/index.tsx\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\" \"-\"\n172.20.0.1 - - [05/May/2023:13:54:03 +0000] \"GET /dashboard/@fs/C:/Users/nader/Documents/devProjects/boilerplate/packages/browser/core-ui/DarkModeProvider/index.tsx HTTP/1.1\" 200 2026 \"https://localhost:3000/dashboard/src/index.tsx\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36\" \"-\"\n`\n```",
      "solution": "On first glance, it seems like the react app that you are trying to deploy has not been dockerized properly. Even if you are only trying to forward the development port, you would still need the dockerfile to have all the necessary steps of setting up the react app like 'npm install' or 'yarn install' etc. If that is all clear, a smart solution to resolving it would be to create a volume inside the nginx container and giving it the files it needs from outside the container on the same path like this, if inside a docker compose file:\n```\n`volume:\n    -  react_app/node_modules : /etc/nginx/html/dashboard/node_modules\n`\n```",
      "question_score": 4,
      "answer_score": 2,
      "created_at": "2023-05-05T15:56:41",
      "url": "https://stackoverflow.com/questions/76182972/how-to-serve-vite-development-server-behind-an-nginx-reverse-proxy"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 74927448,
      "title": "Grafana behind an Nginx from a Different Domain returns &quot;Origin not allowed&quot; on Panels",
      "problem": "Grafana (version 9) is running without proxy on a domainA. I would like to add an Nginx proxy from another domainB.\nAccording to this post, Grafana doesn't support multiples domains and need smart proxy.\nBased on official documentation, this first post and this second post, Nginx configuration should looks like\n```\n`# this is required to proxy Grafana Live WebSocket connections.\nmap $http_upgrade $connection_upgrade {\n  default upgrade;\n  '' close;\n}\n\nupstream grafana {\n  server domainA;\n}\n\nserver {\n  listen 8080;\n  server_name domainB;\n\n  location / {\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header Host domainA;\n    proxy_pass https://grafana-prj-sso-monitoring.apps.okd.svc.elca.ch;\n  }\n\n  # Proxy Grafana Live WebSocket connections.\n  location /api/live/ {\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection $connection_upgrade;\n    proxy_set_header Host domainA;\n    proxy_pass https://domainA;\n  }\n}\n`\n```\nI can reach Grafana through the proxy but panels return \"Origin not allowed\". I tried to add standard CORS header on both location with no luck\n```\n`add_header 'Access-Control-Allow-Origin' '*';\nadd_header 'Access-Control-Allow-Methods' 'GET, POST';\nadd_header 'Access-Control-Allow-Headers' 'Authorization, Content-Type';\nadd_header 'Access-Control-Allow-Credentials' 'true';\n`\n```",
      "solution": "Finally this works with a single location\n```\n`location / {\n  proxy_set_header Host domainA;\n  proxy_set_header Origin https://domainA;\n  proxy_pass https://domainA;\n}\n`\n```\nThe trick was to change both Host and Origin headers.",
      "question_score": 4,
      "answer_score": 8,
      "created_at": "2022-12-27T10:08:16",
      "url": "https://stackoverflow.com/questions/74927448/grafana-behind-an-nginx-from-a-different-domain-returns-origin-not-allowed-on"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 70205968,
      "title": "Can I block request by Cookie value in Nginx?",
      "problem": "I want to block exact cookie value like PHPSESSID in Nginx. Does this possible?\nMy site under DDoS but I can't block by IP due to shared addresses. Attackers use same value of Cookies so I try to block by cookie value.\nThanks",
      "solution": "```\n`server {\n  ...\n\n  if ($cookie_PHPSESSID = \"XXXXXXXXXXXX\") {\n    return 403;\n  }\n}\n`\n```",
      "question_score": 4,
      "answer_score": 8,
      "created_at": "2021-12-02T21:17:53",
      "url": "https://stackoverflow.com/questions/70205968/can-i-block-request-by-cookie-value-in-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 76966845,
      "title": "NGINX Ingress with Helm - configure rate limiting response code",
      "problem": "I'm trying to set the `limit-req-status-code` for my nginx ingress, but I'm failing to do so. According to the docs, this setting belongs in a ConfigMap (as opposed to other rate limiting settings that are annotations). I created a configmap, but the setting doesn't get respected. How do I know? I've used fortio to run into the rate limit and it's still returning 503.\nI've tried finding out how to name the map correctly and tried a lot of different names like suggested in these answers, no effect. I also tried to manually pass the configmap name to the helm call, no luck either. That's what I have right now:\ningress-configmap.yaml\n```\n`apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: nginx-ingress-config\ndata:\n  limit-req-status-code: \"429\"\n\n`\n```\ningress.yaml\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: {{ include \"fullname\" . }}-ingress\n  labels:\n    app.kubernetes.io/name: {{ include \"name\" . }}\n    app.kubernetes.io/instance: {{ .Release.Name }}\n    app.kubernetes.io/version: \"{{ .Release.Revision }}\"\n    app.kubernetes.io/managed-by: {{ .Release.Service }}\n    helm.sh/chart: {{ .Chart.Name }}-{{ .Chart.Version | replace \"+\" \"_\" }}\n  annotations:\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/limit-rpm: \"1000\"\n    nginx.ingress.kubernetes.io/limit-rps: \"100\"\nspec:\n  ingressClassName: \"nginx-public\"\n  rules:\n    - host: {{ .Values.ingress.host }}\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: {{ include \"fullname\" . }}-service\n                port:\n                  name: http\n`\n```\ndeploy call\n```\n`helm upgrade ${{ inputs.release-name }} ${{ inputs.working-directory }} \\\n          --install \\\n          --namespace=${{ inputs.aws-role-name }} \\\n          --wait \\\n          --timeout=5m0s \\\n          --atomic \\\n          --values=${{ inputs.working-directory }}/values.yaml \\\n          --values=${{ inputs.working-directory }}/values-${{ inputs.stage-name }}.yaml \\\n          --set controller.config.name=nginx-ingress-config \\\n          --set-string deployment.image.registry=\"${{ secrets.mgmt-aws-account-id }}.dkr.ecr.${{ inputs.mgmt-aws-region }}.amazonaws.com\" \\\n          --set-string deployment.image.repository=\"${{ inputs.image-name }}\" \\\n          --set-string deployment.image.digest=\"${{ inputs.image-digest }}\" \\\n          --set-string database.user='${{ steps.fetch-secret-postgres-username.outputs.aws-secret-value }}' \\\n          --set-string database.password='${{ steps.fetch-secret-postgres-password.outputs.aws-secret-value }}'\n`\n```\nWhat am I doing wrong?",
      "solution": "Ok so I found a solution in another question: I can pass the setting as a configuration snippet in an annotation:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: {{ include \"fullname\" . }}-ingress\n  labels:\n    app.kubernetes.io/name: {{ include \"name\" . }}\n    app.kubernetes.io/instance: {{ .Release.Name }}\n    app.kubernetes.io/version: \"{{ .Release.Revision }}\"\n    app.kubernetes.io/managed-by: {{ .Release.Service }}\n    helm.sh/chart: {{ .Chart.Name }}-{{ .Chart.Version | replace \"+\" \"_\" }}\n  annotations:\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/limit-rpm: \"{{ .Values.ingress.requestsPerMinute }}\"\n    nginx.ingress.kubernetes.io/limit-rps: \"{{ .Values.ingress.requestsPerSecond }}\"\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      limit_req_status 429;                                      The configmap and the configured controller.config.name are not necessary.",
      "question_score": 4,
      "answer_score": 7,
      "created_at": "2023-08-24T08:54:26",
      "url": "https://stackoverflow.com/questions/76966845/nginx-ingress-with-helm-configure-rate-limiting-response-code"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 73596677,
      "title": "Uwsgi Locking Up After a Few Requests with Nginx/Traefik/Flask App Running over HTTPS/TLS and Docker",
      "problem": "Problem\nI have an app that uses `nginx` to serve my `Python Flask` app in production that only after a few requests starts locking up and timing out (will serve the first request or two quickly then start timing out and locking up afterwards). The `Nginx` app is served via `Docker`, the `uwsgi Python` app is served on `barebones macOS` (this Python app interfaces with the Docker instance running on the OS itself), the routing occurs via `Traefik`.\nFindings\nThis problem only occurs in production and the only difference there is I'm using Traefik's LetsEncrypt SSL certs to use HTTPS to protect the API. I've narrowed the problem down to the following two `docker-compose` config lines (when present the problem persists, when removed the problem is corrected but SSL no longer is enabled):\n`      - \"traefik.http.routers.harveyapi.tls=true\"\n      - \"traefik.http.routers.harveyapi.tls.certresolver=letsencrypt\"\n`\nOnce locked up, I must restart the uwsgi processes to fix the problem just to have it lock right back up. Restarting nginx (Docker container) doesn't fix the problem which leads me to believe that uwsgi doesn't like the SSL config I'm using? Once I disable SSL support, I can send 2000 requests to the API and have it only take a second or two. Once enabled again, uwsgi can't even respond to 2 requests.\nDesired Outcome\nI'd like to be able to support SSL certs to enforce HTTPS connections to this API. I can currently run HTTP with this setup fine (thousands of concurrent connections) but that breaks when trying to use HTTPS.\nConfigs\nI host dozens of other PHP sites with near identical setups. The only difference between those projects and this one is that they run PHP in Docker and this runs Python Uwsgi on barebones macOS. Here is the complete dump of configs for this project:\ntraefik.toml\n`# Traefik v2 Configuration\n# Documentation: https://doc.traefik.io/traefik/migration/v1-to-v2/\n\n[entryPoints]\n  # http should be redirected to https\n  [entryPoints.web]\n    address = \":80\"\n    [entryPoints.web.http.redirections.entryPoint]\n      to = \"websecure\"\n      scheme = \"https\"\n  [entryPoints.websecure]\n    address = \":443\"\n  [entryPoints.websecure.http.tls]\n    certResolver = \"letsencrypt\"\n\n# Enable ACME (Let's Encrypt): automatic SSL\n[certificatesResolvers.letsencrypt.acme]\n  email = \"email@example.com\"\n  storage = \"/etc/traefik/acme/acme.json\"\n  [certificatesResolvers.letsencrypt.acme.httpChallenge]\n    entryPoint = \"web\"\n\n[log]\n  level = \"DEBUG\"\n\n# Enable Docker Provider\n[providers.docker]\n  endpoint = \"unix:///var/run/docker.sock\"\n  exposedByDefault = false # Must pass `traefik.enable=true` label to use Traefik\n  network = \"traefik\"\n\n# Enable Ping (used for healthcheck)\n[ping]\n`\ndocker-compose.yml\n`version: \"3.8\"\nservices:\n  harvey-nginx:\n    build: .\n    restart: always\n    networks:\n      - traefik\n    labels:\n      - traefik.enable=true\n    labels:\n      - \"traefik.http.routers.harveyapi.rule=Host(`project.com`, `www.project.com`)\"\n      - \"traefik.http.routers.harveyapi.tls=true\"\n      - \"traefik.http.routers.harveyapi.tls.certresolver=letsencrypt\"\n\nnetworks:\n  traefik:\n    name: traefik\n`\nuwsgi.ini\n`[uwsgi]\n; uwsgi setup\nmaster = true\nmemory-report = true\nauto-procname = true\nstrict = true\nvacuum = true\ndie-on-term = true\nneed-app = true\n\n; concurrency\nenable-threads = true\ncheaper-initial = 5   ; workers to spawn on startup\ncheaper = 2           ; minimum number of workers to go down to\nworkers = 10          ; highest number of workers to run\n\n; workers\nharakiri = 60               ; Restart workers if they have hung on a single request\nmax-requests = 500          ; Restart workers after this many requests\nmax-worker-lifetime = 3600  ; Restart workers after this many seconds\nreload-on-rss = 1024        ; Restart workers after this much resident memory\nreload-mercy = 3            ; How long to wait before forcefully killing workers\nworker-reload-mercy = 3     ; How long to wait before forcefully killing workers\n\n; app setup\nprotocol = http\nsocket = 127.0.0.1:5000\nmodule = wsgi:APP\n\n; daemonization\n; TODO: Name processes `harvey` here\ndaemonize = /tmp/harvey_daemon.log\n`\nnginx.conf\n```\n`server {\n    listen 80;\n    error_log  /var/log/nginx/error.log;\n    access_log /var/log/nginx/access.log;\n\n    location / {\n        include uwsgi_params;\n        # TODO: Please note this only works for macOS: https://docs.docker.com/desktop/networking/#i-want-to-connect-from-a-container-to-a-service-on-the-host\n        # and will require adjusting for your OS.\n        proxy_pass http://host.docker.internal:5000;\n    }\n}\n`\n```\nDockerfile\n```\n`FROM nginx:1.23-alpine\n\nRUN rm /etc/nginx/conf.d/default.conf\nCOPY nginx.conf /etc/nginx/conf.d\n`\n```\nAdditional Context\nI've added additional findings on the GitHub issue where I've documented my journey for this problem: https://github.com/Justintime50/harvey/issues/67",
      "solution": "This is no longer a problem and the solution is real frustrating - it was Docker's fault. For ~6 months there was a bug in Docker that was dropping connections (ultimately leading to the timeouts mentioned above) which was finally fixed in Docker Desktop 4.14.\nThe moment I upgraded Docker (it had just come out at the time and I thought I would try the hail Mary upgrade having already turned every dial and adjusted every config param without any luck), it finally stopped timing out and dropping connections. I was suddenly able to send through tens of thousands of concurrent requests without issue.\nTLDR: uWSGI, Nginx, nor my config were at fault here. Docker had a bug that has been patched. If others on macOS are facing this problem, try upgrading to at least `Docker Dekstop 4.14`.",
      "question_score": 4,
      "answer_score": 6,
      "created_at": "2022-09-04T05:52:21",
      "url": "https://stackoverflow.com/questions/73596677/uwsgi-locking-up-after-a-few-requests-with-nginx-traefik-flask-app-running-over"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 70832556,
      "title": "Kubernetes nginx ingress configuration for wildcard rule",
      "problem": "I am struggling with the following issues. I have 2 services running. I am using a wildcard for handling subdomains. See the example conf below:\n```\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    ingress.kubernetes.io/ssl-redirect: \"false\"\n    kubernetes.io/ingress.class: nginx\n    kubernetes.io/ingress.global-static-ip-name: web-static-ip\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\n    nginx.ingress.kubernetes.io/server-alias: www.foo.bar\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n  name: foo-bar-ingress\n  namespace: test\nspec:\n  rules:\n  - host: '*.foo.bar'\n    http:\n      paths:\n      - backend:\n          serviceName: legacy-service\n          servicePort: 80\n        path: /(.*)\n        pathType: ImplementationSpecific\n  - host: foo.bar\n    http:\n      paths:\n      - backend:\n          serviceName: new-service\n          servicePort: 8080\n        path: /(.*)\n        pathType: ImplementationSpecific\n`\n```\nUsing the app in the way that abc.foo.bar -> legacy-service and foo.bar -> new-service work perfectly fine. However, when I access the app with www prefix, it gets under the wildcard subdomain path, meaning www.foo.bar goes into legacy-service, which is what I want to avoid. AFAIU this \"www\" is caught by this asterisk regexp and goes in the wrong way. I would like it go to new-service.\nIs there any way I can achieve this with the nginx ingress configuration?",
      "solution": "Also redirecting requests from `www.foo.bar` can be achieved by also specifying the hostname. Please note that the order of the hosts does matter as they are translated into the Envoy filter chain. Therefore, the wildcard host should be the last host.\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    ingress.kubernetes.io/ssl-redirect: \"false\"\n    kubernetes.io/ingress.class: nginx\n    kubernetes.io/ingress.global-static-ip-name: web-static-ip\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\n    nginx.ingress.kubernetes.io/server-alias: www.foo.bar\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n  name: foo-bar-ingress\n  namespace: test\nspec:\n  rules:\n  - host: 'foo.bar'\n    http:\n      paths:\n      - backend:\n          serviceName: new-service\n          servicePort: 8080\n        path: /(.*)\n        pathType: ImplementationSpecific\n  - host: 'www.foo.bar'\n    http:\n      paths:\n      - backend:\n          serviceName: new-service\n          servicePort: 8080\n        path: /(.*)\n        pathType: ImplementationSpecific\n  - host: '*.foo.bar'\n    http:\n      paths:\n      - backend:\n          serviceName: legacy-service\n          servicePort: 80\n        path: /(.*)\n        pathType: ImplementationSpecific\n`",
      "question_score": 4,
      "answer_score": 6,
      "created_at": "2022-01-24T11:46:21",
      "url": "https://stackoverflow.com/questions/70832556/kubernetes-nginx-ingress-configuration-for-wildcard-rule"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 70795048,
      "title": "Kubernetes Multiple Path Rewrites",
      "problem": "Alright, various permutations of this question have been asked and I feel terrible asking; I'm throwing the towel in and was curious if anyone could point me in the right direction (or point out where I'm wrong). I went ahead and tried a number of examples from the docs, but to no avail (see below).\nI'm trying to route traffic to the appropriate location under Kubernetes using an Ingress controller.\nServer Setup\nI have a server, `myserver.com` and three services running at:\n`myserver.com/services/`\n`myserver.com/services/service_1/`\n`myserver.com/services/service_2/`\nNote that I'm not doing anything (purposefully) to `myserver.com/`.\nAt each of the three locations, there's a webapp running. For example, `myserver.com/services/service_2` needs to load css files at `myserver.com/services/service_2/static/css`, etc...\nKubernetes Ingress\nTo manage the networking, I'm using a Kubernetes Ingress controller, which I've defined below. The CORS annotations aren't super relevant, but I've included them to clear up any confusion.\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myServices\n  namespace: myServices\n  annotations:\n    nginx.ingress.kubernetes.io/enable-cors: \"true\"\n    nginx.ingress.kubernetes.io/cors-allow-methods: \"GET, POST, OPTIONS\"\n    nginx.ingress.kubernetes.io/cors-allow-origin: '$http_origin'\n    nginx.ingress.kubernetes.io/cors-allow-credentials: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n      - myserver.com\n  rules:\n  - host: myserver.com\n    http:\n      paths:\n      - path: /services\n        pathType: Prefix\n        backend:\n          service:\n            name: web-service\n            port:\n              number: 80\n      - path: /services/service_1(/|$)\n        pathType: Prefix\n        backend:\n          service:\n            name: web-service-1\n            port:\n              number: 80\n      - path: /services/service_2(/|$)\n        pathType: Prefix\n        backend:\n          service:\n            name: web-service-2\n            port:\n              number: 80\n`\n```\nTargets\nI noticed that one helpful thing to do is give some path examples. From the examples below it looks like the paths aren't that complicated. I think this is what I'm after. Note that I'd like each service to be able to resolve its css and image files.\n```\n`myserver.com/services -> myserver.com/services\nmyserver.com/services/xxx/xxx -> myserver.com/services/xxx/xxx\nmyserver.com/services/service_1 -> myserver.com/services/service_1\nmyserver.com/services/service_1/xxx/xxx -> myserver.com/services/service_1/xxx/xxx\nmyserver.com/services/service_2/xxx/xxx -> myserver.com/services/service_2/xxx/xxx\n\n`\n```\nAttempts\nI know that this issue has to do a lot with the `nginx.ingress.kubernetes.io/rewrite-target` rule and its interaction with the paths I've defined.\nI know that I don't want `nginx.ingress.kubernetes.io/rewrite-target: $1` because that gives a 500 when visiting `myserver.com/services`\nI know that I don't want `nginx.ingress.kubernetes.io/rewrite-target: $1/$2` because when I visit `myserver.com/services/service_1` I actually get part of the content at `myserver.com/services` rendered on the page.\nSO Attempt 1\nI also attempted to replicate the accepted solution from this question.\nIn this attempt I set\n`nginx.ingress.kubernetes.io/rewrite-target: \"/$1\"` and one of the service paths to\n`- path: /(services/service_1(?:/|$).*)`\nWhen I visit `myserver.com/services/service_1/xyz`, the HTML from `myserver.com/services/service_1` gets rendered.\nConcluding Thoughts\nSomething ain't quite right with the path rewrite and paths rules. Any suggestions?",
      "solution": "The problem you reported in your most recent comment is resolved by looking at the rewrite example in the nginx-ingress documentation.\nThe `rewrite-target` annotation configures the ingress such that matching paths will be rewritten to that value. Since you've specified a static value of `/`, anything matching your ingress rules will get rewritten to `/`, which is exactly the behavior you're seeing.\nThe solution is to capture the portion of the path we care about, and then use that in the `rewrite-target` annotation.  For example:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myservices\n  annotations:\n    nginx.ingress.kubernetes.io/enable-cors: \"true\"\n    nginx.ingress.kubernetes.io/cors-allow-methods: \"GET, POST, OPTIONS\"\n    nginx.ingress.kubernetes.io/cors-allow-origin: '$http_origin'\n    nginx.ingress.kubernetes.io/cors-allow-credentials: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"false\"\n\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: myserver.com\n    http:\n      paths:\n      - path: /services/service_1(/|$)(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: webservice-service1\n            port:\n              number: 80\n      - path: /services/service_2(/|$)(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: webservice-service2\n            port:\n              number: 80\n      - path: /services(/|$)(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: webservice\n            port:\n              number: 80\n\n`\n```\nHere, we've modified the match expression so that they look like:\n```\n`      - path: /services/service_1(/|$)(.*)\n`\n```\nThe second capture group `(.*)` captures everything after the path\nportion that matches literally. We then use that capture group (`$2`,\nbecause it's the second group) in the `rewrite-target` annotation:\n```\n`    nginx.ingress.kubernetes.io/rewrite-target: /$2\n`\n```\nWith this configuration in place, a request to `/services/service_2`\nresults in:\n```\n`This is service2.\n`\n```\nBut a request to `/services/service_2/foo/bar` results in:\n```\n`404 Not Found\nNot Found\nThe URL you requested (/foo/bar) was not found.\n\n`\n```\nAnd looking at the backend server logs, we see:\n```\n`10.42.0.32 - - [21/Jan/2022:20:33:23 +0000] \"GET / HTTP/1.1\" 200 211 \"\" \"curl/7.79.1\"\n10.42.0.32 - - [21/Jan/2022:20:33:45 +0000] \"GET /foo/bar HTTP/1.1\" 404 311 \"\" \"curl/7.79.1\"\n`\n```\nI've updated my example repository to match this configuration.",
      "question_score": 4,
      "answer_score": 6,
      "created_at": "2022-01-21T01:34:22",
      "url": "https://stackoverflow.com/questions/70795048/kubernetes-multiple-path-rewrites"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 70771859,
      "title": "How to use nginx to direct traffic to two different ports on the same device?",
      "problem": "I am currently working on a FPV robotics project that has two servers, flask/werkzeug and streamserver, serving http traffic and streaming video to an external web server, located on a different machine.\nThe way it is currently configured is like this:\n\nhttp://1.2.3.4:5000 is the \"web\" traffic (command and control) served by flask/werkzeug\nhttp://1.2.3.4:5001 is the streaming video channel served by streamserver.\n\nI want to place them behind a https reverse proxy so that I can connect to this via https://example.com where \"example.com\" is set to 1.2.3.4 in my external system's hosts file.\nI would like to:\n\nPass traffic to the internal connection at 1.2.3.4:5000 through as a secure connection. (certain services, like the gamepad, won't work unless it's a secure connection.)\nPass traffic to 1.2.3.4:5001 as a plain-text connection on the inside as \"streamserver\" does not support HTTPS connections.\n\n. . . such that the \"external\" connection (to ports 5000 and 5001 are both secure connections as far as the outside world is concerned, such that:\n```\n`[external system]-https://example.com:5000/5001----nginx----https://example.com:5000\n                                                        \\---http://example.com:5001\n\nhttp://example.com:5000 or 5001 redirects to https.\n`\n```\nAll of the literature I have seen so far talks about:\n\nRouting/load-balancing to different physical servers.\nDoing everything within a Kubernates and/or Docker container.\n\nMy application is just an every-day plain vanilla server type configuration, and the only reason I am even messing with https is because of the really annoying problems with things not working except in a secure context which prevents me from completing my project.\nI am sure this is possible, but the literature is either hideously confusing or appears to talk to a different use case.\nA reference to a simple how-to would be the most usefull choice.\nClear and unambiguous steps would also be appreciated.\nThanks in advance for any help you can provide.",
      "solution": "First, credit where credit is due: @AnthumChris's answer is essentially correct.\u00a0 However, if you've never done this before, the following additional information may be useful:\n\nThere is actually too much information online, most of which is contradictory, possibly wrong, and unnecessarily complicated.\n\nIt is not necessary to edit the nginx.conf file.\u00a0 In fact, that's probably a bad idea.\nThe current open-source version of nginx can be used as a reverse proxy, despite the comments on the nginx web-site saying you need the Pro version.\u00a0 As of this instant date, the current version for the Raspberry Pi is 1.14.\nAfter sorting through the reams of information, I discovered that setting up a reverse proxy to multiple backend devices/server instances is remarkably simple.\u00a0 Much simpler than the on-line documentation would lead you to believe.\n\u00a0\n\nInstalling nginx:\n\nWhen you install nginx for the first time, it will report that the installation has failed.\u00a0 This is a bogus warning.\u00a0 You get this warning because the installation process tries to start the nginx service(s) and there isn't a valid configuration yet - so the startup of the services fails, however the installation is (likey) correct and proper.\n\u00a0\n\nConfiguring the systems using nginx and connecting to it:\n\u00a0\nNote:  This is a special case unique to my use-case as this is running on a stand-alone robot for development purposes and my domain is not a \"live\" domain on a web-facing server.\u00a0 It is a \"real\" domain with a \"real\" and trusted certificate to avoid browser warnings while development progresses.\n\nIt was necessary for me to make entries in the robot's and remote system's HOSTS file to automagically redirect references to my domain to the correct device, (the robot's fixed IP address), instead of directnic's servers where the domain is parked.\n\u00a0\n\nConfiguring nginx:\n\nThe correct place to put your configuration file, (on the raspberry pi), is `/etc/nginx/sites-available` and create a symlink to that file in `/etc/nginx/sites-enabled`\nIt does not matter what you name it as nginx.conf blindly imports whatever is in that directory.\u00a0 The other side of that is if there is anything already in that directory, you should remove it or rename it with a leading dot.\n`nginx -T` is your friend!\u00a0 You can use this to \"test\" your configuration for problems before you try to start it.\n`sudo systemctl restart nginx` will attempt to restart nginx, (which as you begin configuration, will likely fail.)\n`sudo systemctl status nginx.service > ./[path]/log.txt 2>&1` is also your friend.\u00a0 This allows you to collect error messages at runtime that will prevent the service from starting.\u00a0 In my case, the majority of the problems were caused by other services using ports I had selected, or silly mis-configurations.\nOnce you have nginx started, and the status returns no problems, try `sudo netstat -tulpn | grep nginx` to make sure it's listening on the correct ports.\n\u00a0\n\nTroubleshooting nginx after you have it running:\n\nMost browsers, (Firefox and Chrome at least) support a \"developer mode\" that you enter by pressing F-12.\u00a0 The console messages can be very helpful.\n\u00a0\n\nSSL certificates:\n\nUnlike other SSL servers, nginx requires the site certificate to be combined with the intermediate certificate bundle received from the certificate authority by using `cat mycert.crt bundle.file > combined.crt` to create it.\n\u00a0\n\nUltimately I ended up with the following configuration file:\n\nNote that I commented out the HTTP redirect as there was a service using port 80 on my device.\u00a0 Under normal conditions, you  will want to automatically re-direct port 80 to the secure connection.\nAlso note that I did not use hard-coded IP addresses in the config file.\u00a0 This allows you to reconfigure the target IP address if necessary.\nA corollary to that is - if you're redirecting to an internal secure device configured with the same certificates, you have to pass it through as the domain instead of the IP address, otherwise the secure connection will fail.\n\u00a0\n\n```\n`#server {\n#   listen example.com:80;\n#   server_name example.com;\n#   return 301 https://example.com$request_uri;\n# }\n\n# This is the \"web\" server (command and control), running Flask/Werkzeug\n# that must be passed through as a secure connection so that the\n# joystick/gamepad works.\n#\n# Note that the internal Flask server must be configured to use a\n# secure connection too. (Actually, that may not be true, but that's\n# how I set it up. . .)\n#\nserver {\n   listen example.com:443 ssl;\n   server_name example.com;\n   ssl_certificate  /usr/local/share/ca-certificates/extra/combined.crt;\n   ssl_certificate_key  /usr/local/share/ca-certificates/extra/example.com.key; \n   ssl_prefer_server_ciphers on;\n\n   location / {\n        proxy_pass https://example.com:5000;\n\n        proxy_set_header        Host $host;\n        proxy_set_header        X-Real-IP $remote_addr;\n        proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header        X-Forwarded-Proto $scheme;\n   }\n}\n\n# This is the video streaming port/server running streamserver\n# which is not, and cannot be, secured.  However, since most\n# modern browsers will not mix insecure and secure content on\n# the same page, the outward facing connection must be secure.\n#\nserver {\n   listen example.com:5001 ssl;\n   server_name example.com;\n   ssl_certificate  /usr/local/share/ca-certificates/extra/combined.crt;\n   ssl_certificate_key  /usr/local/share/ca-certificates/extra/www.example.com.key; \n   ssl_prefer_server_ciphers on;\n\n# After securing the outward facing connection, pass it through\n# as an insecure connection so streamserver doesn't barf.\n\n   location / {\n        proxy_pass http://example.com:5002;\n\n        proxy_set_header        Host $host;\n        proxy_set_header        X-Real-IP $remote_addr;\n        proxy_set_header        X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header        X-Forwarded-Proto $scheme;\n   }\n}\n`\n```\n\n\u00a0\nHopefully this will help the next person who encounters this problem.",
      "question_score": 4,
      "answer_score": 3,
      "created_at": "2022-01-19T14:54:23",
      "url": "https://stackoverflow.com/questions/70771859/how-to-use-nginx-to-direct-traffic-to-two-different-ports-on-the-same-device"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 70677183,
      "title": "NGINX 404 not found but file exists",
      "problem": "I want to call the index.html from the folder /var/www/fileUpload/html. The index.html file exists in that folder.\nThe / router works. the uploadFiles route as well. But when I open the upload route I get a 404 error.\n```\n`    server{\n    listen 80;\n    server_name xx.xx.xxx.xxx;\n\n    location / {\n        root /var/www/kioskJPE/html;\n        index index.html;\n    }\n    location /upload {\n        root /var/www/fileUpload/html;\n        index index.html;\n    }\n    location /uploadFiles {\n        proxy_pass http://localhost:8080;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n}\n`\n```\nDo you have any suggestions?\nThank you!",
      "solution": "That should be `alias /var/www/fileUpload/html;` otherwise Nginx is looking for the file in `/var/www/fileUpload/html/upload/index.html`. See this document for details.\nFor example:\n```\n`location /upload {\n    alias /var/www/fileUpload/html;\n}\n`\n```",
      "question_score": 4,
      "answer_score": 6,
      "created_at": "2022-01-12T07:24:24",
      "url": "https://stackoverflow.com/questions/70677183/nginx-404-not-found-but-file-exists"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 66051624,
      "title": "Generate wildcard certificate on Kubernetes cluster with DigitalOcean for my Nginx-Ingress",
      "problem": "I followed this DigitalOcean guide https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nginx-ingress-with-cert-manager-on-digitalocean-kubernetes, and I came across something quite strange. When in the hostnames I set a wildcard, then `letsencrypt` fails in issuing a new certificate. While when I only set defined sub-domains, then it works perfectly.\nThis is my \"working\" configuration for the domain and its api (and this one works perfectly):\n```\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: my-ingress\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-staging\"\nspec:\n  tls:\n  - hosts:\n    - example.com\n    - api.example.com\n    secretName: my-tls\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - backend:\n          serviceName: example-frontend\n          servicePort: 80\n  - host: api.example.com\n    http:\n      paths:\n      - backend:\n          serviceName: example-api\n          servicePort: 80\n`\n```\nAnd this is, instead, the wildcard certificate I'm trying to issue, but that fails to do leaving the message \"Issuing\".\n```\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: my-ingress\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-staging\"\nspec:\n  tls:\n  - hosts:\n    - example.com\n    - *.example.com\n    secretName: my-tls\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - backend:\n          serviceName: example-frontend\n          servicePort: 80\n  - host: api.example.com\n    http:\n      paths:\n      - backend:\n          serviceName: example-api\n          servicePort: 80\n      \n`\n```\nThe only difference is the second line of the hosts. Is there a trivial well known solution I am not aware of? I am new to Kubernetes, but not to DevOps.",
      "solution": "Generating wildcard certificate with `cert-manager` (`letsencrypt`) requires the usage of `DNS-01` challenge instead of `HTTP-01` used in the link from the question:\n\nDoes Let\u2019s Encrypt issue wildcard certificates?\nYes. Wildcard issuance must be done via ACMEv2 using the DNS-01 challenge. See this post for more technical information.\n\nThere is a documentation about generating the `wildcard` certificate with `cert-manager`:\n\nCert-manager.io: Docs: Configuration: ACME: DNS-01\n\nFrom the perspective of DigialOcean, there is a guide specifically targeted at it:\n\nThis provider uses a Kubernetes `Secret` resource to work. In the following\nexample, the `Secret` will have to be named `digitalocean-dns` and have a\nsub-key `access-token` with the token in it. For example:\n`apiVersion: v1\nkind: Secret\nmetadata:\n  name: digitalocean-dns\n  namespace: cert-manager\ndata:\n  # insert your DO access token here\n  access-token: \"base64 encoded access-token here\"\n`\nThe access token must have write access.\nTo create a Personal Access Token, see DigitalOcean documentation.\nHandy direct link: https://cloud.digitalocean.com/account/api/tokens/new\nTo encode your access token into base64, you can use the following\n`echo -n 'your-access-token' | base64 -w 0\n`\n`apiVersion: cert-manager.io/v1\nkind: Issuer\nmetadata:\n  name: example-issuer\nspec:\n  acme:\n    ...\n    solvers:\n    - dns01:\n        digitalocean:\n          tokenSecretRef:\n            name: digitalocean-dns\n            key: access-token\n`\n-- Cert-manager.io: Docs: Configuration: ACME: DNS-01: Digitalocean\n\nI'd reckon this additional resources could also help:\n\nStackoverflow.com: Questions: Wilcard SSL certificate with subdomain redirect in Kubernetes\nItnext.io: Using wildcard certificates with cert-manager in Kubernetes",
      "question_score": 4,
      "answer_score": 4,
      "created_at": "2021-02-04T19:26:14",
      "url": "https://stackoverflow.com/questions/66051624/generate-wildcard-certificate-on-kubernetes-cluster-with-digitalocean-for-my-ngi"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 73551471,
      "title": "Deploying Django Channels with nginx",
      "problem": "I am trying to deploy the Django application in AWS ubuntu os with Django channels, Using Nginx.\nI had configured the Django server in Nginx.\nBut I don't know how to configure channels or Redis-server in Nginx.\n\nMy nginx config is as follows:\n```\n`server {\n    listen 80;\n    server_name 52.77.215.218;\n\n    location / {\n        include proxy_params;\n        proxy_pass http://localhost:8000/\n    }\n}\n`\n```\nMy settings.py:\n```\n`CHANNEL_LAYERS = {\n    \"default\": {\n        \"BACKEND\": \"channels_redis.core.RedisChannelLayer\",\n        \"CONFIG\": {\n            \"hosts\": [(\"127.0.0.1\", 6379)],\n        },\n    },\n}\n`\n```\nMy requirements.txt:\n```\n`aioredis==1.3.1\nasgiref==3.5.2\nasync-timeout==4.0.2\nattrs==22.1.0\nautobahn==22.7.1\nAutomat==20.2.0\ncertifi==2022.6.15\ncffi==1.15.1\nchannels==3.0.5\nchannels-redis==2.4.2\ncharset-normalizer==2.1.1\nconstantly==15.1.0\ncoreapi==2.3.3\ncoreschema==0.0.4\ncryptography==37.0.4\ndaphne==3.0.2\ndefusedxml==0.7.1\nDjango==4.1\ndjango-cors-headers==3.13.0\ndjango-templated-mail==1.1.1\ndjangorestframework==3.13.1\ndjangorestframework-simplejwt==4.8.0\ndjoser==2.1.0\ngunicorn==20.1.0\nhiredis==2.0.0\nhyperlink==21.0.0\nidna==3.3\nincremental==21.3.0\nitypes==1.2.0\nJinja2==3.1.2\nMarkupSafe==2.1.1\nmsgpack==0.6.2\nmysql==0.0.3\nmysqlclient==2.1.1\noauthlib==3.2.0\npyasn1==0.4.8\npyasn1-modules==0.2.8\npycparser==2.21\nPyJWT==2.4.0\npyOpenSSL==22.0.0\npython3-openid==3.2.0\npytz==2022.2.1\nrequests==2.28.1\nrequests-oauthlib==1.3.1\nservice-identity==21.1.0\nsix==1.16.0\nsocial-auth-app-django==4.0.0\nsocial-auth-core==4.3.0\nsqlparse==0.4.2\nTwisted==22.4.0\ntwisted-iocpsupport==1.0.2\ntxaio==22.2.1\ntyping_extensions==4.3.0\ntzdata==2022.2\nuritemplate==4.1.1\nurllib3==1.26.12\nzope.interface==5.4.0\n\n`\n```\nWhen I run server with `python3 manage.py runserver 0.0.0.0:8000`\nServer running good and also connecting with redis-server but when\nI run server with `gunicorn app.wsgi -b 0.0.0.0:800` then failed to\nconnect with webbsocket.\n\nI also tried Hostinger VPS as well, but Same Issue.",
      "solution": "You will need to download Daphne.\nDaphne is a high-performance websocket server for Django channels.\nhttps://docs.djangoproject.com/en/4.1/howto/deployment/asgi/daphne/\nhttps://github.com/django/daphne\nhttps://channels.readthedocs.io/en/stable/deploying.html\nHow you can run daphne:\n`daphne -b 0.0.0.0 -p 8070 django_project.asgi:application`\nHere is my Nginx conf for channels:\n```\n`upstream django {\n    server 127.0.0.1:8080;\n}\nupstream websockets{\n    server 127.0.0.1:8070;\n}\n\nserver {\n    ...\n    ...\n   \n\n    location /ws {\n        proxy_pass http://websockets;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"Upgrade\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        ...\n    }\n\n    location / {\n        proxy_pass http://django; \n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"Upgrade\";\n        proxy_set_header X-Real-IP $remote_addr;\n        ...\n    }\n\n}\n\n`\n```",
      "question_score": 4,
      "answer_score": 5,
      "created_at": "2022-08-31T08:01:55",
      "url": "https://stackoverflow.com/questions/73551471/deploying-django-channels-with-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 72115633,
      "title": "Cors problem with nginx/django from react app on docker",
      "problem": "I have a question about cors implementation in django.\nHaving a problem with setting the correct cors values.\nMy deployment is on docker.\nI have a deployed 3 containers:\n\nbackend: Django + DRF as backend (expose 8000 port)\nNginx to server my backend (use exposed 8000 port and set it to 1338)\nfrontend React app used with nginx (uses port 1337)\n\nEverything is on localhost.\nI use axios from frontend to call get/post requests. (I call to 1338 port then I think it is redirected to internal service on 8000 port)\nFor backend I had to install django-cors-headers package to work with CORS.\nI think I set up it correctly. But there are scenarios where it does not work.\nIn settings.py\n```\n`INSTALLED_APPS = [\n...\n\"corsheaders\",\n]\n...\nMIDDLEWARE = [\n...\n\"corsheaders.middleware.CorsMiddleware\",\n\"django.middleware.common.CommonMiddleware\",\n...\n]\n`\n```\nNginx.conf for nginx image:\n```\n`upstream backend {\n    server backend:8000;\n}\n\nserver {\n\n    listen 80;\n\n    add_header Access-Control-Allow-Origin *;\n\n    \n\n    location / {\n\n        proxy_pass http://backend;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $host:1337;\n        proxy_redirect off;\n    }\n\n    location /static/ {\n        alias /home/app/web/staticfiles/;\n    }\n}\n`\n```\nFirst scenario\nIn settings.py\n```\n`CORS_ALLOW_ALL_ORIGINS = True\n`\n```\nNo get/post requests work. Get message:\nCORS Multiple Origin Not Allowed\nSecond scenario\nIn settings.py\n```\n`CORS_ALLOWED_ORIGINS = [\"http://localhost:1337\"]\n`\n```\nWorks with get requests, but does not work with post requests.\nFor post requests:\n\noptions with error: CORS Missing Allow Header\npost with error: NS_ERROR_DOM_BAD_URI\n\nIt works if I am not using nginx for backend.\nAdding request headers as requested in the comment.\n\nI am not sure what else could I add here. So my deployed project is here (it also is easy to launch if you have docker on your machine:\nhttps://gitlab.com/k.impolevicius/app-001",
      "solution": "I have come across this issue a while back, and I think the issue is with the headers.\nIn the MDN docs, it is stated here that other than for the simple requests, we'll get preflighted requests with OPTIONS method. There are 3 main headers that we need to send in response in your case\n```\n`Access-Control-Allow-Origin: http://localhost:1337\nAccess-Control-Allow-Methods: POST, GET, OPTIONS\nAccess-Control-Allow-Headers: Content-Type\n`\n```\nFrom the looks of it you have configured the first header and you should be seeing it in the network tab too, and since the error is about missing allow headers, you need to add `Access-Control-Allow-Methods` header\nto your nginx file\n```\n`add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS';\n`\n```\nSeeing your network tab on the requested headers will give more context here, generally you should be seeing `Access-Control-Request-Method` and `Access-Control-Request-Headers` headers in the `OPTIONS` request. If there are some headers that you aren't allowing, please write an nginx rule for the same. You can look into this solution for more reference",
      "question_score": 4,
      "answer_score": 5,
      "created_at": "2022-05-04T17:30:24",
      "url": "https://stackoverflow.com/questions/72115633/cors-problem-with-nginx-django-from-react-app-on-docker"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69235005,
      "title": "React router and Apache + Nginx giving Unexpected Token &lt;",
      "problem": "I have React website where routing was done with react-router-dom and with localhost everything works fine. But on my production server it doesn't matter which web server I use (Nginx or Apache2 or Apache2 + Nginx) with nested links like https://example.com/admin/list I am getting a error:\n```\n`Uncaught SyntaxError: Unexpected token 'When you go to the nested link through the button everything works fine.\n```\n` \n`\n```\nBut after refresh or going directly I getting this error.\nWith single links like https://example.com/admin everything works good.\nThat how nested routing done\nApp.js\n```\n`\n  \n    \n    \n    \n    \n    \n  \n\n`\n```\nAdmin.js\n```\n`\n  \n    \n    \n    \n    \n  \n\n`\n```\nI was thinking that maybe problem in web server, so I tried Apache2 with .htaccess\n```\n`RewriteEngine on \n# Don't rewrite files or directories \nRewriteCond %{REQUEST_FILENAME} -f [OR] \nRewriteCond %{REQUEST_FILENAME} -d \nRewriteRule ^ - [L] \n# Rewrite everything else to index.html to allow html5 state links \nRewriteRule ^ index.html [L] \n`\n```\nAnd also Nginx with this code in conf\n```\n`try_files $uri /index.html;\n`\n```\nBoth works the same.",
      "solution": "The problem was in package.json where in homepage field was a dot\n```\n`\"homepage\": \".\"\n`\n```\nAnd you need to change it to a slash\n```\n`\"homepage\": \"/\"\n`\n```",
      "question_score": 4,
      "answer_score": 5,
      "created_at": "2021-09-18T15:15:11",
      "url": "https://stackoverflow.com/questions/69235005/react-router-and-apache-nginx-giving-unexpected-token"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx",
      "question_id": 69211110,
      "title": "Nginx Container: no &quot;ssl_certificate_key&quot; is defined for certificate",
      "problem": "I am trying to run a private docker registry using this tutorial. But after I did everything and run the docker-compose, I get the following error from the `nginx` container\n\nno \"ssl_certificate_key\" is defined for certificate\n\"/home/user/registry/nginx/ssl/key.pem\"\n\nHere is the registry.conf file:\n```\n`upstream docker-registry {\n    server registry:5000;\n}\n\nserver {\n    listen 80;\n    server_name example.com;\n    return 301 https://example.com$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name privatesecurereg.netspan.com;\n\n    ssl_certificate /home/user/registry/nginx/ssl/csr.pem;\n    ssl_certificate /home/user/registry/nginx/ssl/key.pem;\n\n    # Log files for Debug\n    error_log  /var/log/nginx/error.log;\n    access_log /var/log/nginx/access.log;\n\n    location / {\n        # Do not allow connections from docker 1.5 and earlier\n        # docker pre-1.6.0 did not properly set the user agent on ping, catch \"Go *\" user agents\n        if ($http_user_agent ~ \"^(docker\\/1\\.(3|4|5(?!\\.[0-9]-dev))|Go ).*$\" )  {\n            return 404;\n        }\n\n        proxy_pass                          http://docker-registry;\n        proxy_set_header  Host              $http_host;\n        proxy_set_header  X-Real-IP         $remote_addr;\n        proxy_set_header  X-Forwarded-For   $proxy_add_x_forwarded_for;\n        proxy_set_header  X-Forwarded-Proto $scheme;\n        proxy_read_timeout                  900;\n    }\n\n}\n`\n```\nWhat is the rpobelom and how to fix it ?\nUPDATE:\nHere is my docker-compose:\n```\n`nginx:\n    image: nginx:alpine\n    container_name: nginx\n    restart: unless-stopped\n    tty: true\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/conf.d/:/etc/nginx/conf.d/\n      - ./nginx/ssl/:/etc/nginx/ssl/\n    networks:\n      - mynet\n`\n```",
      "solution": "I think you had missed something in `docker-compose` file. This is working sample we use.\n```\n`nginx:\n  image: \"nginx:alpine\"\n  ports:\n    - 5000:443\n  links:\n    - registry:registry\n  volumes:\n    - ./auth:/etc/nginx/conf.d\n    - ./auth/nginx.conf:/etc/nginx/nginx.conf:ro\n\nregistry:\n  image: registry:2.7.0\n  volumes:\n    - ./data:/var/lib/registry\n`\n```\nKeep an eye on this part\n```\n`volumes:\n    - ./auth:/etc/nginx/conf.d\n    - ./auth/nginx.conf:/etc/nginx/nginx.conf:ro\n`\n```\nHere `auth` folder has certificate and key file. Also httpd file for docker registry login.\nIn `nginx.conf` we directly refered inside the `nginx` container.\n```\n`# SSL\nssl_certificate /etc/nginx/conf.d/csr.pem;\nssl_certificate_key /etc/nginx/conf.d/csr.key;\n`\n```",
      "question_score": 4,
      "answer_score": 1,
      "created_at": "2021-09-16T17:20:29",
      "url": "https://stackoverflow.com/questions/69211110/nginx-container-no-ssl-certificate-key-is-defined-for-certificate"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 67344835,
      "title": "How to properly debug sentry and find cause for 502 nginx error",
      "problem": "I'm new to sentry and Nginx, I'm having a lot of trouble finding out what is happening in my instance, and why I'm getting 502 from Nginx.\nWhere I can find the root of the problem? I try using `tail -100 /var/log/nginx/error.log` but I don't see where the problem is...\noutput from `tail /var/log/nginx/error.log`:\n```\n`2021/04/30 17:08:55 [error] 68825#68825: *7 upstream timed out (110: Connection timed out) while connecting to upstream, client: 172.28.132.95, server: mydomain.com, request: \"GET / HTTP/1.1\", upstream: \"https://myip:9000/\", host: \"mydomain.com\"\n2021/04/30 17:09:08 [alert] 68825#68825: *17 open socket #9 left in connection 3\n2021/04/30 17:09:08 [alert] 68825#68825: *16 open socket #8 left in connection 4\n2021/04/30 17:09:08 [alert] 68825#68825: *15 open socket #13 left in connection 5\n2021/04/30 17:09:08 [alert] 68825#68825: aborting\n\n`\n```\nThe only thing weird that I found was that `upstream` use my instance IP address and the host is being solved as `mydomain.com`\nmy Nginx `/etc/nginx/sites-available/default`:\n```\n`    server {\n      server_name mydomain.com;\n      location / {\n        proxy_pass         http://localhost:9000;\n        proxy_redirect     off;\n        proxy_set_header   Host              $host;\n        proxy_set_header   X-Forwarded-For   $proxy_add_x_forwarded_for;\n        proxy_set_header   X-Forwarded-Proto $scheme;\n      }\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/mydomain/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/mydomain/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n}\n    server {\n    if ($host = mydom) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n      listen 80;\n      server_name mydomain.com;\n    return 404; # managed by Certbot\n}\n`\n```\ndocker-compose.yml (nginx):\n```\n`      nginx:\n    system.internal-url-prefix:\n`system.internal-url-prefix: 'https://mydomain:9000'`\nsentry.conf.py :\n```\n`##############\n# Web Server #\n##############\n\nSENTRY_WEB_HOST = \"0.0.0.0\"\nSENTRY_WEB_PORT = 9000\nSENTRY_WEB_OPTIONS = {\n    \"http\": \"%s:%s\" % (SENTRY_WEB_HOST, SENTRY_WEB_PORT),\n    \"protocol\": \"uwsgi\",\n    # This is needed in order to prevent https://git.io/fj7Lw\n    \"uwsgi-socket\": None,\n    \"so-keepalive\": True,\n    # Keep this between 15s-75s as that's what Relay supports\n    \"http-keepalive\": 15,\n    \"http-chunked-input\": True,\n    # the number of web workers\n    \"workers\": 3,\n    \"threads\": 4,\n    \"memory-report\": False,\n    # Some stuff so uwsgi will cycle workers sensibly\n    \"max-requests\": 100000,\n    \"max-requests-delta\": 500,\n    \"max-worker-lifetime\": 86400,\n    # Duplicate options from sentry default just so we don't get\n    # bit by sentry changing a default value that we depend on.\n    \"thunder-lock\": True,\n    \"log-x-forwarded-for\": False,\n    \"buffer-size\": 32768,\n    \"limit-post\": 209715200,\n    \"disable-logging\": True,\n    \"reload-on-rss\": 600,\n    \"ignore-sigpipe\": True,\n    \"ignore-write-errors\": True,\n    \"disable-write-exception\": True,\n}\n\n###########\n# SSL/TLS #\n###########\n\n# If you're using a reverse SSL proxy, you should enable the X-Forwarded-Proto\n# header and enable the settings below\n\nSECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')\nSESSION_COOKIE_SECURE = True\nCSRF_COOKIE_SECURE = True\nSOCIAL_AUTH_REDIRECT_IS_HTTPS = True\n\n`\n```\nAny ideas what I can be missing?\nThanks in advance and kind regards",
      "solution": "You can try `docker-compose logs web relay`\nthis topic can be of your interst:\nforum sentry",
      "question_score": 4,
      "answer_score": 3,
      "created_at": "2021-05-01T11:43:24",
      "url": "https://stackoverflow.com/questions/67344835/how-to-properly-debug-sentry-and-find-cause-for-502-nginx-error"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 69818474,
      "title": "How can I get the content of all cookies in &quot;Set-Cookie&quot; header returned by upstream in nginx",
      "problem": "Similar to the issue mentioned here https://forum.openresty.us/d/6503-get-content-of-second-set-cookie-header\nI have an NGINX configuration that gets the cookies stored in Set-Cookie by the upstream auth_request and I need to return those set-cookie to the client, however whenever I try to return those cookies only the first set-cookie is returned to the client.\nBelow is an example configuration to demonstrate the issue\n```\n` location /auth/ {\n    proxy_pass         http://auth/;\n    proxy_pass_request_body off;\n    proxy_redirect     off;\n  }\n\n  location / {\n    auth_request       /auth/loggedin;\n    auth_request_set $auth_cookie $upstream_http_set_cookie;\n    add_header Set-Cookie $auth_cookie;\n    proxy_set_header Cookie \"$http_cookie; $auth_cookie\";\n    proxy_pass         http://someservice/;\n  }\n`\n```\nIn my above example I expect that multiple cookies could be returned in a Set-Cookie header `a=12; PATH:\"/\", b=2; PATH:/\"` and I want to pass whatever set-cookies come from the upstream service to clients browser via add_header. Currently only the cookie `a` is making it to the client and `b` is always missing.\nNote:\nI want it to be generic and so I can't grab the exact cookie names from a header.\nThank you for any help you can provide!",
      "solution": "Unfortunately it is impossible to do it the way you want to. Setting cookies using multiple `Set-Cookie` header is a common approach, the MDN documentation on `Set-Cookie` header explicitly says that:\n\nTo send multiple cookies, multiple `Set-Cookie` headers should be sent in the same response.\n\nWhen multiple headers with the same name are received from the upstream, only the first one is accessible using `$upstream_http_` variable (with a few exceptions, e.g. `Cache-Control` one, if I remember correctly). There is a ticket for that on nginx bug tracker (although I did't consider it a bug). `Set-Cookie` header is really a special case that can't be folded in opposite to many other headers, check this answer and comments below it to see why is it so. (Of course, you are still free to use any `$upstream_cookie_` per-cookie variable).\nHowever it is possible to do it using OpenResty (mentioned in your question) or `lua-nginx-module`. The bad news, it will be incompatible with the `auth_request` directive since it is impossible to add those `lua_...` handlers to the auth location (or any other subrequest location that can be used, e.g., by `add_before_body` or `add_after_body` directives from the `ngx_http_addition_module`). You didn't get an error, but those handlers won't be fired on a subrequest. The good news, functionality similar to `auth_request` can be implemented using `ngx.location.capture` API call.\nSo if using `nginx-lua-module` is suitable for you (and if it isn't, maybe the solution will help some others), this can be done the following way:\n`location /auth/ {\n    internal;\n    proxy_pass http://auth/;\n    proxy_redirect off;\n}\n\nlocation / {\n    # -- this one is taken from the official lua-nginx-module documentation example\n    # -- see https://github.com/openresty/lua-nginx-module#access_by_lua\n    access_by_lua_block {\n        local res = ngx.location.capture(\"/auth/loggedin\", {body = \"\"})\n        if res.status == ngx.HTTP_OK then\n            ngx.ctx.auth_cookies = res.header[\"Set-Cookie\"]\n            return\n        end\n        if res.status == ngx.HTTP_FORBIDDEN then\n            ngx.exit(res.status)\n        end\n        ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)\n    }\n\n    # -- it doesn't matter where the 'proxy_pass' line actually would be, it doesn't change the workflow\n    # -- see https://cloud.githubusercontent.com/assets/2137369/15272097/77d1c09e-1a37-11e6-97ef-d9767035fc3e.png\n    proxy_pass http://someservice/;\n\n    header_filter_by_lua_block {\n        local function merge_cookies(a, b)\n            local c = a or b\n            -- if either \"a\" or \"b\" is empty, \"c\" already has the required result\n            if (a and b) == nil then return c end\n            -- neither \"a\" nor \"b\" are empty, result will be a table, \"c\" now equals to \"a\"\n            -- if \"c\" is a string, lets made it a table instead\n            if type(c) == \"string\" then c = {c} end\n            -- append \"b\" to \"c\"\n            if type(b) == \"string\" then table.insert(c, b) else\n                for _, v in ipairs(b) do table.insert(c, v) end\n            end\n            return c\n        end\n        ngx.header[\"Set-Cookie\"] = merge_cookies(ngx.header[\"Set-Cookie\"], ngx.ctx.auth_cookies)\n    }\n}\n`\nThis code does not check possible cookie names intersection, or it will be much more complex. However I think (not checked this on practice) that it doesn't really matter because even if a two `Set-Cookie` requests with the same cookie name but different values will be returned to the client, the last one will be used. This code makes `Set-Cookie` requests from the auth server arriving after the `Set-Cookie` requests from the main upstream. To do the opposite you'd need to change the\n```\n`ngx.header[\"Set-Cookie\"] = merge_cookies(ngx.header[\"Set-Cookie\"], ngx.ctx.auth_cookies)\n`\n```\nline to the\n```\n`ngx.header[\"Set-Cookie\"] = merge_cookies(ngx.ctx.auth_cookies, ngx.header[\"Set-Cookie\"])\n`\n```\nSpecial thanks to the @wilsonzlin for the extremely helpful answer on working with the `ngx.header[\"Set-Cookie\"]` table.\nUpdate\nThough you didn't mention it in your question, looking at your example I saw you not only want to pass the `Set-Cookie` headers to the client but also to send those cookies to the `someservice` upstream. Again, you are trying to do it a wrong way. Using `proxy_set_header Cookie \"$http_cookie; $auth_cookie\";` you are appending those cookies including their attributes like `Path`, `Max-Age`, etc. while the `Cookie` header should contain only the `name=value` pairs. Well, using the `lua-nginx-module` this is also posible. You'd need to change the above `access_by_lua_block` to the following one.\n`access_by_lua_block {\n\n    local res = ngx.location.capture(\"/auth/loggedin\", {body = \"\"})\n    if res.status == ngx.HTTP_OK then\n        ngx.ctx.auth_cookies = res.header[\"Set-Cookie\"]\n\n        if ngx.ctx.auth_cookies then\n\n            -- helper functions\n            -- strip all Set-Cookie attributes, e.g. \"Name=value; Path=/; Max-Age=2592000\" => \"Name=value\"\n            local function strip_attributes(cookie)\n                return string.match(cookie, \"[^;]+\")\n            end\n            -- iterator for use in \"for in\" loop, works both with strings and tables\n            local function iterate_cookies(cookies)\n                local i = 0\n                return function()\n                    i = i + 1\n                    if type(cookies) == \"string\" then\n                        if i == 1 then return strip_attributes(cookies) end\n                    elseif type(cookies) == \"table\" then\n                        if cookies[i] then return strip_attributes(cookies[i]) end\n                    end\n                end\n            end\n\n            local cookies = ngx.req.get_headers()[\"Cookie\"]\n            -- at the first loop iteration separator should be an empty string if client browser send no cookies or \"; \" otherwise\n            local separator = cookies and \"; \" or \"\"\n            -- if there are no cookies in original request, make \"cookies\" variable an empty string instead of nil to prevent errors\n            cookies = cookies or \"\"\n\n            for cookie in iterate_cookies(ngx.ctx.auth_cookies) do\n                cookies = cookies .. separator .. cookie\n                -- next separator definitely should be a \"; \"\n                separator = \"; \"\n            end\n\n            ngx.req.set_header(\"Cookie\", cookies)\n\n        end\n\n        return\n    end\n    if res.status == ngx.HTTP_FORBIDDEN then\n        ngx.exit(res.status)\n    end\n    ngx.exit(ngx.HTTP_INTERNAL_SERVER_ERROR)\n}\n`\nAll the above examples are tested (using OpenResty 1.17.8.2) and confirmed to be workable.",
      "question_score": 3,
      "answer_score": 6,
      "created_at": "2021-11-03T01:46:27",
      "url": "https://stackoverflow.com/questions/69818474/how-can-i-get-the-content-of-all-cookies-in-set-cookie-header-returned-by-upst"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 70741577,
      "title": "Nginx cache size not growing above 344GB",
      "problem": "I have Nginx cache server built on Ubuntu 18 and with docker image nginx:1.19.10-alpine.\nUbuntu 18 disk usage details given below for reference\n```\n`ubuntu@host_name:~$ df -h\nFilesystem                  Size  Used Avail Use% Mounted on\nudev                        126G     0  126G   0% /dev\ntmpfs                        26G  1.4M   26G   1% /run\n/dev/mapper/vg_system-root  193G  8.9G  176G   5% /\ntmpfs                       126G     0  126G   0% /dev/shm\ntmpfs                       5.0M     0  5.0M   0% /run/lock\ntmpfs                       126G     0  126G   0% /sys/fs/cgroup\n/dev/mapper/vg_data-srv      24T  369G   24T   2% /srv\n/dev/sda1                   453M  364M   62M  86% /boot\noverlay                     193G  8.9G  176G   5% /var/lib/docker/overlay2/64_characters_random/merged\ntmpfs                        26G     0   26G   0% /run/user/1646269961\n`\n```\nDocker container details\n```\n`ubuntu@host_name:~$ sudo docker ps\nCONTAINER ID   IMAGE                  COMMAND                  CREATED      STATUS       PORTS     NAMES\ncontnr_idxyz   nginx:1.19.10-alpine   \"/docker-entrypoint.\u2026\"   5 days ago   Up 9 hours             contnr_name\n`\n```\nNginx Configuration for reference\n```\n`user@host-name:/srv/mytool/nginx/config$ cat proxy.conf\naccess_log          off;\nroot                /var/log/nginx;\nopen_log_file_cache max=100;\n\nlog_format mytoollogformat\n    '$time_iso8601 $remote_addr $status $request_time $body_bytes_sent '\n    '$upstream_cache_status \"$request\" \"$http_user_agent\"';\n\nproxy_http_version 1.1;\nclient_max_body_size 10g;\n\n# R/W timeout for origin server\nproxy_read_timeout 15m;\nproxy_send_timeout 15m;\n\n# R/W timeout for clients\nclient_body_timeout   15m;\nclient_header_timeout 15m;\nsend_timeout          15m;\n\n# TODO: ssl_stapling and ssl_ciphers\nssl_prefer_server_ciphers on;\nssl_session_cache         shared:SSL:10m;\n\nproxy_set_header Connection \"\";\nproxy_set_header Host $host;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_set_header X-mytool-Cache-Host $scheme://$host;\n\nproxy_redirect         off;\n\nproxy_cache_path       /var/cache/nginx levels=1:2 keys_zone=mytool:10m max_size=22000g inactive=180d;\nproxy_cache_key        $host$uri$is_args$args$slice_range;\nproxy_set_header       Range $slice_range;\nproxy_cache_valid      200 206 2y;\nproxy_cache_revalidate on;\n\nadd_header X-Cache-Status $upstream_cache_status;\n\nproxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504 http_429;\n`\n```\nRemoved server block as it comes out of context for the current issue and also due to security reason.\nLet me explain my issue in detail. We have main server(proxy_passed server) which has hundreds of TBs of file which are static resources. When we set up cache server it was filling cache and serving files from cache well. But over time noticed that cache size is not increasing above 344GB\n```\n`user@host_name:/srv/mytool/nginx$ sudo du -sh ./*\n344G    ./cache\n52K     ./config\n1004K   ./log\nuser@host_name:/srv/mytool/nginx$\n`\n```\nI have wrote a script to download about 500GB's of files. But It never increased the size of cache above 344GB.\nExperiments done so far\nAdded `max_size=100000g` (along with old value min_free=1000g)\nModified `max_size=22000g` (set less value than /srv size which is 24TB)\nremoved `min_free=1000g` (Assuming min_free is somehow clearing cache)\nModified\n`proxy_cache_valid 200 206 1h;`  to  `proxy_cache_valid 200 206 2y;`\nFor all above experiments, after configuration change i have restarted docker container and ran script of downloading 500GB of files through the cache server. But even though cache size was reaching 380 to 400 GB, but within an hour it was suddenly dropping to 344GB.\nI left with no clue, why cache is not filling up completely even though i have allocated 24TB for /srv\nIs it issue with Nginx? I mean for free version of Nginx there might be any limitations.. Should i go with Nginx plus. Or there might be configuration mistake.\nAny guess would help me. Thanks in advance\nUpdate\n\nWhat are the soft and hard limits for max open files on the cache server?\n\n```\n`$ cat /proc/sys/fs/file-max\n26375980\n$ ulimit -Hn\n1048576\n$ ulimit -Sn\n1024\n`\n```\n\nhave you set limits in your nginx conf using worker_rlimit_nofile?\n\nCurrently no settings of worker_rlimit_nofile\n```\n`/ # cat /etc/nginx/nginx.conf\n\nuser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log warn;\npid        /var/run/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log  /var/log/nginx/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n`\n```\n\nDo you have anything in the error logs?\n\nBelow given filtered/distinct logs\n```\n`$ cat /srv/mytool/nginx/log/error.log\n2022/01/09 05:56:35 [warn] 22#22: *10 an upstream response is buffered to a temporary file /var/cache/nginx/proxy_temp/1/00/0000000001 while reading upstream, client: masked_IPv6_address, server: dev.mytool-region.mycompany.com, request: \"GET /dists/58.2.A.0.409/semc/binary-arm/Packages HTTP/1.1\", upstream: \"https://[IPv6_address]:443/masked_path/Packages\", host: \"dev.mytool-region.mycompany.com\"\n2022/01/09 06:09:21 [warn] 22#22: *35 a client request body is buffered to a temporary file /var/cache/nginx/client_temp/0000000006, client: masked_IPv6_address, server: dev.mytool-region.mycompany.com, request: \"POST /masked_path/all HTTP/1.1\", host: \"dev.mytool-region.mycompany.com\"\n2022/01/09 08:19:01 [error] 22#22: *120 etag mismatch in slice response while reading response header from upstream, client: masked_IPv6_address, server: dev.mytool-region.mycompany.com, request: \"GET /masked_path/xyz.zip HTTP/1.1\", subrequest: \"/masked_path/xyz.zip\", upstream: \"https://[IPv6_address]:443/masked_path/xyz.zip\", host: \"dev.mytool-region.mycompany.com\"\n2022/01/09 18:19:12 [warn] 22#22: *1566 upstream server temporarily disabled while reading response header from upstream, client: masked_IPv6_address, server: dev.mytool-region.mycompany.com, request: \"GET /masked_path/xyz.zip HTTP/1.1\", upstream: \"https://[masked_IPv6_address]:443/masked_path/xyz.zip\", host: \"dev.mytool-region.mycompany.com\"\n2022/01/10 01:23:20 [error] 22#22: *2920 etag mismatch in slice response while reading response header from upstream, client: masked_IPv6_address, server: dev.mytool-region.mycompany.com, request: \"GET /masked_path/xyz.zip HTTP/1.1\", subrequest: \"/masked_path/xyz.zip\", upstream: \"https://[IPv6_address]:443/masked_path/xyz.zip\", host: \"dev.mytool-region.mycompany.com\"\n2022/01/21 07:43:47 [error] 36#36: *441913 upstream timed out (110: Operation timed out) while SSL handshaking to upstream, client: masked_IPv6_address, server: dev.mytool-region.mycompany.com, request: \"GET /masked_path/xyz.zip HTTP/1.1\", upstream: \"https://[IPv6_address]:443/masked_path/xyz.zip\", host: \"dev.mytool-region.mycompany.com\"\n2022/01/21 07:46:17 [warn] 37#37: *442070 upstream server temporarily disabled while SSL handshaking to upstream, client: masked_IPv6_address, server: dev.mytool-region.mycompany.com, request: \"GET /masked_path/xyz.zip HTTP/1.1\", upstream: \"https://[IPv6_address]:443/masked_path/xyz.zip\", host: \"dev.mytool-region.mycompany.com\"\n\nTotal 25k rows same as below within 10 days of logs\n2022/01/11 05:36:58 [alert] 70#70: ignore long locked inactive cache entry 55a25a5037f198bbec6cd49100bb1b76, count:1\n2022/01/11 05:36:58 [alert] 70#70: ignore long locked inactive cache entry e996d5e104f405444a579cd491faf3a8, count:1\n2022/01/11 05:36:58 [alert] 70#70: ignore long locked inactive cache entry 394517a8ed8e43949003b3f7538dc471, count:1\n2022/01/11 05:37:08 [alert] 70#70: ignore long locked inactive cache entry 4f92d3a72f64b7bafdbb3f0b66d8e638, count:1\n2022/01/11 05:37:08 [alert] 70#70: ignore long locked inactive cache entry be41b259a3e8f9698e0976639883a423, count:1\n2022/01/11 05:37:08 [alert] 70#70: ignore long locked inactive cache entry 1da19b571ea4bce1428251689f0a7c69, count:1\n2022/01/11 05:37:08 [alert] 70#70: ignore long locked inactive cache entry 2a4cac0c28ea430e7eef3f808cf1e06f, count:1\n2022/01/11 05:37:18 [alert] 70#70: ignore long locked inactive cache entry 53a826f6931cf0f16020bcae100af347, count:1\n`\n```\nUpdate 2:\nTried the same with nginx:perl docker container. It also didn't work and cache size observed that even though it grows beyond 392GB but within couple hours suddenly dropped to 344GB. Command used to start container given below\n```\n`sudo docker run \\\n--detach \\\n--restart unless-stopped \\\n--volume /srv/mytool/nginx/config:/etc/nginx/conf.d:ro \\\n--volume /srv/mytool/nginx/cache:/var/cache/nginx \\\n--volume /srv/mytool/nginx/log:/var/log/nginx \\\nnginx:perl\n`\n```\nUpdate Again\nAvoided docker container nginx:1.19.10-alpine\nAnd did simple Nginx configuration as given below\n```\n`sudo apt install nginx\nsystemctl status nginx\n\n$ sudo ufw app list\nAvailable applications:\n  Nginx Full\n  Nginx HTTP\n  Nginx HTTPS\n  OpenSSH\n$ sudo ufw allow 'Nginx Full'\nRules updated\nRules updated (v6)\n`\n```\nModify default.conf in /etc/nginx/sites-available\n```\n`proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=custom_cache:10m inactive=180d;\n\nupstream origin_server {\n    server dev.mytool-region.mycompany.com;\n}\nserver {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n        server_name _;\n\n        location / {\n            include proxy_params;\n            proxy_pass http://origin_server;\n        }\n\n        location ~ ^/(path1|path2|path3|path4)/ {\n            slice       5m;\n            proxy_cache custom_cache;\n\n            proxy_pass http://origin_server;\n            proxy_cache_valid 200 206 2y;\n            add_header X-Proxy-Cache $upstream_cache_status;\n        }\n}\n`\n```\nDownloaded about ~500GB. It worked and cache filled as expected\n```\n`ubuntu@host_name:/var/cache$ sudo du -sh ./*\n128K    ./apparmor\n82M     ./apt\n4.8M    ./debconf\n20K     ./ldconfig\n1.2M    ./man\n0       ./motd-news\n518G    ./nginx\n4.0K    ./pollinate\n20K     ./snapd\nubuntu@host_name:/var/cache$\n`\n```\nBut still don't know the exact reason or what is wrong with my configuration. Still trial is going on.\nOne more trial\nUsed old configuration(docker nginx:1.19.10-alpine\nAnd moved `proxy_cache_valid      200 206 2y;` inside\n```\n`location ~ ^/(path1|path2|path3|path4)/ {\n`\n```\nBut this also not worked.",
      "solution": "Problem with nginx cache slicing is when you configure cache slicing of say 5 MB.\nIt will end up in creating sliced cache files in cache directory.\nNumber of files that can be cached up is directly propotional to keys_zone size\n`keys_zone=mytool:10m`\nSince i had 10m(10 mega byte) for cache keys it was allowing maximum 71203 files.\nDocument says\n\nIn addition, all active keys and information about data are stored in\na shared memory zone, whose name and size are configured by the\nkeys_zone parameter. One megabyte zone can store about 8 thousand\nkeys.\nAs part of commercial subscription, the shared memory zone also stores\nextended cache information, thus, it is required to specify a larger\nzone size for the same number of keys. For example, one megabyte zone\ncan store about 4 thousand keys.\n\nSo modifying keys_zone to larger value `keys_zone=mytool:1000m` Fixed issue.\nYou can observe cache file count was not growing after 71203 for `keys_zone=mytool:10m`\n```\n`user@host_name:/srv/mytool/nginx$ sudo du -sh ./*\n326G    ./cache\n52K     ./config\n406M    ./log\nuser@host_name:/srv/mytool/nginx$ sudo find cache/ -type f | wc -l\n71203\n`\n```\nBut it started growing in size by allowing cached file count seamlessly for `keys_zone=mytool:1000m`\n```\n`user@host_name:/srv/mytool/nginx$ sudo du -sh ./*\n518G    ./cache\n52K     ./config\n4.6M    ./log\nuser@host_name:/srv/mytool/nginx$ sudo find cache/ -type f | wc -l\n107243\n`\n```",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2022-01-17T13:44:51",
      "url": "https://stackoverflow.com/questions/70741577/nginx-cache-size-not-growing-above-344gb"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 69996244,
      "title": "Kubernetes NGINX Ingress Controller 404 Not found / Object not found",
      "problem": "I am taking a course in Udemy and I am new to the world of Kubernetes and I am trying to configure ingress nginx controller in Kubernetes but it returns 404 not found when i send a request at specified URL, it has been 10 days that I am trying to fix it, i've looked at similar questions but none of their answers are working for me. I am also using Skaffold to do build/deploy image on docker hub automatically when i change something in files.\n\nMy express app server:\n```\n`app.get('/api/users/currentuser', (req, res) => {\n  res.send('Hi there');\n});\n\napp.listen(3000, () => {\n  console.log('[Auth] - Listening on port 3000');\n});\n`\n```\ningress-srv.yaml\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-srv\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/use-regex: 'true'\nspec:\n  rules:\n    - host: ticketing.com\n      http:\n        paths:\n          - path: /api/users/?(.*)\n            pathType: Prefix\n            backend:\n              service:\n                name: auth-srv\n                port:\n                  number: 3000\n`\n```\nauth-depl.yaml (Auth deployment & srv)\n```\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: auth-depl\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: auth\n  template:\n    metadata:\n      labels:\n        app: auth\n    spec:\n      containers:\n        - name: auth\n          image: myusername/auth:latest\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: auth-srv\nspec:\n  type: ClusterIP\n  selector:\n    app: auth\n  ports:\n    - name: auth\n      protocol: TCP\n      port: 3000\n      targetPort: 3000\n`\n```\nskaffold.yaml file:\n```\n`apiVersion: skaffold/v2beta25\nkind: Config\ndeploy:\n  kubectl:\n    manifests:\n      - ./infra/k8s/*\nbuild:\n  local:\n    push: false\n  artifacts:\n    - image: username/auth\n      context: auth\n      docker:\n        dockerfile: Dockerfile\n      sync:\n        manual:\n          - src: 'src/**/*.ts'\n            dest: .\n`\n```\nDockerfile:\n```\n`FROM node:alpine\n\nWORKDIR /app\nCOPY package.json .\nRUN npm install\nCOPY . . \n\nCMD [\"npm\", \"start\"]\n`\n```\nI also executed command from NGINX Ingress Controller docs:\n```\n`kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.0.5/deploy/static/provider/cloud/deploy.yaml\n`\n```\nI also changed hosts.file in the system:\n127.0.0.1 ticketing.com\nLogs:\nkubectl get pods\n```\n`NAME                         READY   STATUS    RESTARTS   AGE\nauth-depl-5f89899d9f-wtc94   1/1     Running   0          6h33m\n`\n```\nkubectl get svc\n```\n`NAME         TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)    AGE\nauth-srv     ClusterIP   10.96.23.71           3000/TCP   23h\nkubernetes   ClusterIP   10.96.0.1             443/TCP    25h\n`\n```\nkubectl get pods --namespace=ingress-nginx\n```\n`NAME                                        READY   STATUS      RESTARTS   AGE\ningress-nginx-admission-create-7fm56        0/1     Completed   0          23h\ningress-nginx-admission-patch-5vflr         0/1     Completed   1          23h\ningress-nginx-controller-5c8d66c76d-89zhp   1/1     Running     0          23h\n`\n```\nkubectl get ing\n```\n`NAME          CLASS    HOSTS           ADDRESS     PORTS   AGE\ningress-srv      ticketing.com   localhost   80      23h\n`\n```\nkubectl describe ing ingress-srv\n```\n`Name:             ingress-srv\nNamespace:        default\nAddress:          localhost\nDefault backend:  default-http-backend:80 ()\nRules:\n  Host           Path  Backends\n  ----           ----  --------\n  ticketing.com\n                 /api/users/?(.*)   auth-srv:3000 (10.1.0.10:3000)\nAnnotations:     kubernetes.io/ingress.class: nginx\n                 nginx.ingress.kubernetes.io/use-regex: true\nEvents:\n  Type    Reason  Age                 From                      Message\n  ----    ------  ----                ----                      -------\n  Normal  Sync    22m (x18 over 23h)  nginx-ingress-controller  Scheduled for sync\n`\n```\nCould there be a problem with the Windows IIS web server? since I previously configured something for another project, and in the screenshot above I see:\n```\n`Requested URL      http://ticketing.com:80/api/users/currentuser\nPhysical Path      C:\\inetpub\\wwwroot\\api\\users\\currentuser\n`\n```\nAlso the screenshot shows the port :80 at the requested URL but I have the server port 3000? + when i request at https it returns:\n```\n`502 Bad Gateway\nnginx\n`\n```\nalso C:\\inetpub\\wwwroot is strange to me.\nAny ideas would help me a lot with continuing the course.",
      "solution": "After a few days of research I finally solved the problem, the problem was with IIS Web Server which I had enabled when I was working on a project in ASP.NET core, I uninstalled it and the problem was solved.\nHow to uninstall IIS from Windows 10:\n\nGo to Control Panel > Programs and Features\nClick Turn Windows features on or off\nScroll down to Internet Information Services\nClick on the square next to Internet Information Services so it becomes empty\nClick OK and restart the PC (required).",
      "question_score": 3,
      "answer_score": 5,
      "created_at": "2021-11-16T22:29:09",
      "url": "https://stackoverflow.com/questions/69996244/kubernetes-nginx-ingress-controller-404-not-found-object-not-found"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 68658678,
      "title": "Nginx as reverse proxy: How to display a custom error page for upstream errors, UNLESS the upstream says not to?",
      "problem": "I have an Nginx instance running as a reverse proxy. When the upstream server does not respond, I send a custom error page for the 502 response code. When the upstream server sends an error page, that gets forwarded to the client, and I'd like to show a custom error page in that case as well.\nIf I wanted to replace all of the error pages from the upstream server, I would set `proxy_intercept_errors on` to show a custom page on each of them. However, there are cases where I'd like to return the actual response that the upstream server sent: for example, for API endpoints, or if the error page has specific user-readable text relating to the issue.\nIn the config, a single `server` is proxying multiple applications that are behind their own proxy setups and their own rules for forwarding requests around, so I can't just specify this per each `location`, and it has to work for any URL that matches a `server`.\nBecause of this, I would like to send the custom error page, unless the upstream application says not to. The easiest way to do this would be with a custom HTTP header. There is a similar question about doing this depending on the request headers. Is there a way to do this depending on the response headers?\n(It appears that somebody else already had this question and their conclusion was that it was impossible with plain Nginx. If that's true, I would be interested in some other ideas on how to solve this, possibly using OpenResty like that person did.)\nSo far I have tried using OpenResty to do this, but it doesn't seem compatible with `proxy_pass`: the response that the Lua code generates seems to overwrite the response from the upstream server.\nHere's the `location` block I tried to use:\n```\n`location / {\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_pass http://localhost:65000;\n\n        content_by_lua_block{\n          ngx.say(\"This seems to overwrite the content from the proxy?!\")\n        }        \n\n        body_filter_by_lua_block {\n          ngx.arg[1]=\"Truncated by code!\"\n          ngx.arg[2]=false\n          if ngx.status >= 400 then\n            if not ngx.resp.get_headers()[\"X-Verbatim\"] then\n              local file = io.open('/usr/share/nginx/error.html', 'w')\n              local html_text = file:read(\"*a\")\n              ngx.arg[1] = html_text\n              ngx.arg[2] = true\n              return\n            end\n          end\n    }\n}\n`\n```",
      "solution": "I don't think that you can send custom error pages based on the response header since the only way, as per my knowledge, you could achieve that was using either `map` or `if` directive. Since both of these directives don't have scope after the request is sent to the upstream, they can't possibly read the response header.\nHowever, you could do this using openresty and writing your own lua script. The lua script to do such a thing would look something like:\n```\n`location / {\n  body_filter_by_lua '\n     if ngx.resp.get_headers()[\"Cust-Resp-Header\"] then\n         local file = io.open('/path/to/file.html', 'r')\n         local html_text = f:read()\n         ngx.arg[1] = html_text\n         ngx.arg[2] = true\n         return\n     end\n  ';\n\n  #\n  .\n  .\n  .\n}\n`\n```\nYou could also use `body_filter_by_lua_block` (you could enclose your lua code inside curly brances instead writing as nginx string) or `body_filter_by_lua_file` (you could write your lua code in a separate file and provide the file path).\nYou can find how to get started with openresty here.\nP.S.: You can read the response status code from the upstream using `ngx.status`. As far as reading the body is concerned, the variable `ngx.arg[1]` would contain the response body after the response from the upstream which we're modifying here. You can save the `ngx.arg[1]` in a local variable and try to read the error message from that using some regexp and appending later in the `html_text` variable. Hope that helps.\nEdit 1: Pasting here a sample working lua block inside a location block with proxy_pass:\n```\n`location /hello {\n    proxy_pass          http://localhost:3102/;\n    body_filter_by_lua_block {\n        if ngx.resp.get_headers()[\"erratic\"] == \"true\" then                          \n                ngx.arg[1] = \"Hi\"\n        end\n    }\n}\n`\n```\nEdit 2: You can't use `content_by_lua_block` with `proxy_pass` or else your proxy wouldn't work. Your location block should look like this (assuming `X-Verbatim` header is set to \"false\" (a string) if you've to override the error response body from the upstream).\n```\n`location / {\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_pass http://localhost:65000;        \n\n    body_filter_by_lua_block {\n      if ngx.status >= 400 then\n        if ngx.resp.get_headers()[\"X-Verbatim\"] == \"false\" then\n          local file = io.open('/usr/share/nginx/error.html', 'w')\n          local html_text = file:read(\"*a\")\n          ngx.arg[1] = html_text\n          ngx.arg[2] = true\n        end\n      end\n}\n`\n```\n}",
      "question_score": 3,
      "answer_score": 4,
      "created_at": "2021-08-05T00:35:02",
      "url": "https://stackoverflow.com/questions/68658678/nginx-as-reverse-proxy-how-to-display-a-custom-error-page-for-upstream-errors"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 68104807,
      "title": "How to correctly deploy/setup NestJS backend using Nginx?",
      "problem": "I'm trying to deploy my webapplication using Angular and NestJs using Nginx on an Ubuntu remote server.\nI got the frontend working on https://ikse.fransenit.nl/products but cannot get the backend to work. It was working fine locally. When I try to go to /api/products I get a 502 bad gateway.\nWhen starting the NestJS backend:\n\nnginx config\n```\n`server {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n\n    root /var/www/ikse/html;\n\n    server_name ikse.fransenit.nl www.ikse.fransenit.nl;\n    \n    index index.html index.htm;\n\n        location / {\n                # First attempt to serve request as file, then\n                # as directory, then fall back to displaying a 404.\n                try_files $uri $uri/ /index.html;\n                # proxy_pass http://localhost:8080;\n                # proxy_http_version 1.1;\n                # proxy_set_header Upgrade $http_upgrade;\n                # proxy_set_header Connection 'upgrade';\n                # proxy_set_header Host $host;\n                # proxy_cache_bypass $http_upgrade;\n        }\n\n        location /api/ {\n            proxy_pass https://localhost:3000;\n        }\n\n    listen [::]:443 ssl; # managed by Certbot\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/ikse.fransenit.nl/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/ikse.fransenit.nl/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n}\n`\n```\nWhat am I missing and/or doing wrong?",
      "solution": "I don't know if you resolved it, but I think you should add `/api/` at the end of `https://localhost:3000` in the `proxy_pass` option. Because with the current configuration you need to make `https://doma.in.com/api/api/profile`",
      "question_score": 3,
      "answer_score": 4,
      "created_at": "2021-06-23T19:44:59",
      "url": "https://stackoverflow.com/questions/68104807/how-to-correctly-deploy-setup-nestjs-backend-using-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 78527486,
      "title": "My nginx config resets automatically from time to time erasing all customization",
      "problem": "I am a layman in this field. My problem is that my nginx customizations work good for 3 or 4 days then suddenly all the customizations are removed and the configuration is reverted to its previous form. If I update the customization again, it stays for 3, 4 days then again it gets erased and reverted to default.\nMy Nginx is setup as Reverse Proxy, with PHP-FPM, Redis cache, gzip, HTTP/2\nMy server is Easyapache4 with WHM/Cpanel\nI use the following command to edit and update my nginx configuration:\n`sudo nano /etc/nginx/conf.d/users/homemadecircuits.conf`\nI want to ensure that once updated the customizations should remain permanently as is, until I edit them myself.\nAny help to solve this issue will be greatly appreciated.",
      "solution": "It seems like you are using Nginx in Cpanel. In this case, your Ngnix configuration will be automatically updated based on Cpanl Configuration Cron job.\nThe reason is that Cpanel support automatic reset function for Nginx configuration for security and consistency and compatibility and etc...\nTo prevent the automatic update, you need to follow guide of Cpanel Ngnix configuration.\nhttps://docs.cpanel.net/knowledge-base/web-services/nginx-with-reverse-proxy/#overview\nOr you can use default configuration file but you can adjust some default configuration parameters such as CPANEL_APACHE_PROXY_PASS.\nTo do this, you can find the solution here",
      "question_score": 3,
      "answer_score": 2,
      "created_at": "2024-05-24T10:57:56",
      "url": "https://stackoverflow.com/questions/78527486/my-nginx-config-resets-automatically-from-time-to-time-erasing-all-customization"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 74548105,
      "title": "Hosting Blazor Standalone WASM on NGINX",
      "problem": "I'm having some issues hosting blazor WASM standalone (without an asp.net core project as host) behind nginx as a reverse proxy.\nHere is my Nginx default config file:\n\r\n\r\n`server {\n        listen 80;\n        listen [::]:80;\n\n        server_name localhost;\n\n        location / {\n                root /var/www/web/BlazorApp/wwwroot;\n                try_files $uri $uri/ index.html =404;\n\n                include /etc/nginx/mime.types;\n                types {\n                        application/wasm wasm;\n                }\n                default_type application/octet-stream;\n        }\n\n        location /service1/ {\n                proxy_pass http://localhost:5001/;\n                proxy_http_version 1.1;\n                proxy_set_header   Upgrade $http_upgrade;\n                proxy_set_header   Connection keep-alive;\n                proxy_set_header   Host $host;\n                proxy_cache_bypass $http_upgrade;\n                proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n                proxy_set_header   X-Forwarded-Proto $scheme;\n        }\n\n        location /service2/ {\n                proxy_pass http://localhost:5002/;\n                proxy_http_version 1.1;\n                proxy_set_header   Upgrade $http_upgrade;\n                proxy_set_header   Connection keep-alive;\n                proxy_set_header   Host $host;\n                proxy_cache_bypass $http_upgrade;\n                proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n                proxy_set_header   X-Forwarded-Proto $scheme;\n        }\n\n        location /service3/ {\n                proxy_pass http://localhost:5003/;\n                proxy_http_version 1.1;\n                proxy_set_header   Upgrade $http_upgrade;\n                proxy_set_header   Connection keep-alive;\n                proxy_set_header   Host $host;\n                proxy_cache_bypass $http_upgrade;\n                proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n                proxy_set_header   X-Forwarded-Proto $scheme;\n        }\n}`\r\n\r\n\r\n\nThis Configuration works in the sense that I can access my blazor app using\n```\n`http://{server-ip-address}\n`\n```\nand my other services using\n```\n`http://{server-ip-address}/serviceX\n`\n```\nwhere X would refer to service 1,2 and 3 respectively\nFirst issue: when I navigate in my blazor app for example to `http://{server-ip-address}/My-Blazor-Page` and I refresh the page I get a 404 not found error.\nfor it to work back again I need to go back to the base address `http://{server-ip-address}` and navigate back to `My-Blazor-Page`.\nI cannot refresh a page and go back to the same page.\nSecond issue: I would like my blazor app to have a different location. I would like to use `http://{server-ip-address}/Blazor` rather than `http://{server-ip-address}/`.\nI tried everything to get it right but this is the only config that semi-works\nMany thanks for your help!",
      "solution": "From the ASP.NET documentation:\n\nThe following nginx.conf file is simplified to show how to configure\nNginx to send the index.html file whenever it can't find a\ncorresponding file on disk.\nWhen setting the NGINX burst rate limit with limit_req, Blazor\nWebAssembly apps may require a large burst parameter value to\naccommodate the relatively large number of requests made by an app.\nInitially, set the value to at least 60:\nIncrease the value if browser developer tools or a network traffic tool indicates that requests are receiving a 503 - Service\nUnavailable status code.\nFor more information on production Nginx web server configuration, see\nCreating NGINX Plus and NGINX Configuration Files.\n\nThe above will try the URL, and if no file matches, it'll serve index.html instead. This is the way.\nFor your second issue, you should set the base attribute value to \"Blazor\" and put all files in the Blazor directory (the config needs to match this). You can also route differently, but this is the easiest.",
      "question_score": 3,
      "answer_score": 2,
      "created_at": "2022-11-23T15:07:14",
      "url": "https://stackoverflow.com/questions/74548105/hosting-blazor-standalone-wasm-on-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 66964010,
      "title": "Purpose of backslash in nginx map configuration",
      "problem": "I'm using a map configuration to block IP addresses with nginx + fail2ban\nThe sample configuration genrator code in fail2ban repo looks like this :\n```\n`...\n_echo_blck_row = printf '\\%%s 1;\\n' \"\"\nactionban = %(_echo_blck_row)s >> '%(blck_lst_file)s'; %(blck_lst_reload)s\n...\n`\n```\nNote the leading backslash in `\\%%s 1;\\n`. It creates a file with IP addresses that have a leading backslash before each IP address i.e. it dumps a file like this\n```\n`\\127.0.0.1    1;\n`\n```\ninstead of simply\n```\n`127.0.0.1    1;\n`\n```\nBoth the configurations are correct. What's the purpose of the backslash at the start of the IP address in this file ?",
      "solution": "From the manual page:\n\nIf a source value matches one of the names of special parameters\ndescribed below, it should be prefixed with the \u201c\\\u201d symbol.\n\nSo it's unnecessary (but harmless) for values such as `127.0.0.1`, but it defends against using hostnames such as `default`, `hostnames`, `volatile` or `include`, which are considered \"special parameters\" within the `map` block.",
      "question_score": 3,
      "answer_score": 2,
      "created_at": "2021-04-06T08:57:29",
      "url": "https://stackoverflow.com/questions/66964010/purpose-of-backslash-in-nginx-map-configuration"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 65948239,
      "title": "Nginx How do i route to reverse proxy by location",
      "problem": "Currently i'm using nginx server and using nodejs server as reverse proxy.\nI want to make the nginx server proxy_pass different server by location.\nSo, lets say my domain is `subdomain.domain.com`.\nWhen loading `subdomain.domain.com/`, this should serve static files.\nWhen loading `subdomain.domain.com/example1/req1/req2`, this should route to `127.0.0.1:3000/req1/req2`.\nWhen loading `subdomain.domain.com/example2/req1/req2`, this should route to `127.0.0.1:8080/req1/req2`.\nBut my configuration routes `subdomain.domain.com/example1/req1/req2` to `127.0.0.1:3000/example1/req1/req2` resulting error. (nodejs returns Cannot GET /example1)\nHow should I write this nginx conf file properly?",
      "solution": "Try use rewrite directive in location block.\nSomething like:\n```\n`location /example1/ {\n  rewrite     ^/example1/(.*)$ /$1 break;\n  proxy_pass  http://xxxxxx;\n}\n`\n```\nYou can check documents related to rewrite module at http://nginx.org/en/docs/http/ngx_http_rewrite_module.html",
      "question_score": 2,
      "answer_score": 4,
      "created_at": "2021-01-29T04:05:06",
      "url": "https://stackoverflow.com/questions/65948239/nginx-how-do-i-route-to-reverse-proxy-by-location"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 75477904,
      "title": "NextJS 500 internal server error on deployed website. But build works PERFECTLY on local",
      "problem": "Build is working perfectly on my local PC with pm2, no errors at all. Every page loads perfectly, there are no 404 or 500 errors in fetching files. It's great! This is EXACTLY how I want it to run.\nBut when I try and deploy this on Ubuntu with pm2 I am getting two sets of errors:\nI'll put screenshots here:\nhttps://i.sstatic.net/3XybJ.png\nWritten form:\n```\n` Script_app-a44cfb7405f734c3.js\n\n Script_buildManifest.js\n\n Script_ssgManifest.js\n\n Script_middlewareManifest.js\n`\n```\n(And others) all are giving me a 500 Internal Server Error no matter what I do.\nAttempted Solutions\n\nI've tried many approaches and all of them end with this error/failure when I am navigating to my deployed website.\n\nUpload manually with filezilla.\n\nGit clone from my repository, build on the server (no build errors) and then deploy with pm2. No errors with pm2 either! But then I am given 404/500 errors.\n\nI've tried this in different folders, I've tried it with a host of different commands. I am completely out of ideas and I've uploaded and tried to get my files on there and install packages and more.\nNginx error?\n\nThis might be nginx error? But the nginx settings work perfectly fine for a brand new \"npx create-next-app@latest\" Following this exact tutorial to the letter: https://www.youtube.com/watch?v=x6ci2iCckWc&t=658s&ab_channel=DigitalCEO\nMy nginx file\n```\n`\"server {\n        server_name specialservername.com;\n\n        gzip on;\n        gzip_proxied any;\n        gzip_types application/javascript application/x-javascript text/css text/javascript;\n        gzip_comp_level 5;\n        gzip_buffers 16 8k;\n        gzip_min_length 256;\n\n        location /_next/static/ {\n                alias /var/www/frontend/.next/static/;\n                expires 365d;\n                access_log off;\n        }\n\n#EDITS\n   location ~ ^/_next/static/(.*)$ {\n      root /.next;\n      try_files \"/static/$1\" \"/server/static/o$1\" @proxy_pass;\n   }\n\n#END EDITS\n\n        location / {\n                proxy_pass http://127.0.0.1:3000; #change to 3001 for second app, but make sure second nextjs app starts on new port in packages.json \"start\": \"next start -p 3001\",\n                proxy_http_version 1.1;\n                proxy_set_header Upgrade $http_upgrade;\n                proxy_set_header Connection 'upgrade';\n                proxy_set_header Host $host;\n                proxy_cache_bypass $http_upgrade;\n                add_header Access-Control-Allow-Origin *;\n        }\n\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/specialservername.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/specialservername.com/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n}\n\nserver {\n    if ($host =specialservername.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n        listen 80;\n        server_name specialservername.com;\n    return 404; # managed by Certbot\n\n}\"\n`\n```\nWhat I was Expecting\n\nThe NextJS build to be deployed on this server no different than it is on my local machine. On my local machine it's BEAUTIFUL!",
      "solution": "If you're seeing an \"Internal Server Error\" when trying to access your Next.js application on Ubuntu with nginx, it's likely that there's an issue with your configuration.\nHere are a few things you can try:\nCheck your nginx error logs: Look in your nginx error logs (typically located in /var/log/nginx/error.log) for any error messages that might indicate what's causing the issue.\nCheck your Next.js logs: You should also check your Next.js logs (usually located in the .next directory of your application) for any error messages that might indicate what's causing the issue.\nCheck your Next.js configuration: Make sure your Next.js configuration is set up correctly for production deployment. You should make sure that your next.config.js file has the necessary settings for production deployment, such as setting target: 'server', configuring your build options, and setting your asset prefix if necessary.\nCheck your environment variables: Make sure any environment variables that your application depends on are set correctly on your Ubuntu server.\nCheck for permission: Make sure file, build files on server has enough permissions.\nAlso, if everything from above works fine, try dockerizing your application with nginx and run on local, then simply mimic the same on server(ubuntu) as that would definitely give you some clue.\nAnd...lastly, don't panic. \ud83d\ude03",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2023-02-16T22:03:56",
      "url": "https://stackoverflow.com/questions/75477904/nextjs-500-internal-server-error-on-deployed-website-but-build-works-perfectly"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 74911022,
      "title": "How to Use a Single Custom Error Page for all 404 Requests",
      "problem": "I have created a custom 404 page for resources that dont exist.\nIt works with all endpoints except the ones which have `/api/v1/`, where I get the default NGINX 404 page.\nI have `domain.name.conf` file in `/etc/nginx/conf.d/`:\n```\n`server {\n    listen 80;\n    listen [::]:80;\n    server_name domain.name www.domain.name;\n\n    root /var/www/domain.name/public_html;\n    error_page 404 /not_found.html;\n\n    location /api/v1/ {\n        proxy_pass http://localhost:8080/;\n        limit_except GET HEAD { deny all; }\n    }\n\n    location / {\n        index index.html;\n        try_files $uri $uri/ =404;\n    }\n\n    location = /not_found.html {\n        internal;\n    }\n}\n`\n```\nOn adding the `$try_files` directive inside `/api/v1/`, \"Hello, World!\" from the backend REST API is not displayed at `/api/v1/hello`, even though its a valid endpoint. Instead I get the custom 404 error page:\n```\n`server {\n    listen 80;\n    listen [::]:80;\n    server_name domain.name www.domain.name;\n\n    root /var/www/domain.name/public_html;\n    error_page 404 /not_found.html;\n\n    location /api/v1/ {\n        proxy_pass http://localhost:8080/;\n        try_files $uri =404;\n        limit_except GET HEAD { deny all; }\n    }\n\n    location / {\n        index index.html;\n        try_files $uri $uri/ =404;\n    }\n\n    location = /not_found.html {\n        internal;\n    }\n}\n`\n```\nHow can I use a single custom error page for all non existing resources ?",
      "solution": "Thanks to Richard Smith's comment, the `conf` file look like:\n```\n`server {\n    listen 80;\n    listen [::]:80;\n    server_name domain.name www.domain.name;\n\n    root /var/www/domain.name/public_html;\n    error_page 404 /not_found.html;\n\n    proxy_intercept_errors on;\n\n    location /api/v1/ {\n        proxy_pass http://localhost:8080/;\n        limit_except GET HEAD { deny all; }\n    }\n\n    location / {\n        index index.html;\n        try_files $uri $uri/ =404;\n    }\n\n    location = /not_found.html {\n        internal;\n    }\n}\n`\n```",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2022-12-25T01:35:11",
      "url": "https://stackoverflow.com/questions/74911022/how-to-use-a-single-custom-error-page-for-all-404-requests"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 74238832,
      "title": "nginx: [warn] conflicting server name &quot;&quot; on 0.0.0.0:80, ignored",
      "problem": "I have three nginx server blocks and when i run nginx -t get error \"nginx: [warn] conflicting server name \"\" on 0.0.0.0:80, ignored\"\nI have three nginx server blocks:\nOne: /etc/nginx/sites-available/default\n```\n`server {\n        listen 80 default_server;\n        listen [::]:80 default_server;   \n\n        root /var/www/html;\n\n        server_name _;\n\n        location / {\n                # First attempt to serve request as file, then\n                # as directory, then fall back to displaying a 404.\n                try_files $uri $uri/ =404;\n        }\n\n}\n\n`\n```\nTwo: /etc/nginx/sites-available/example.com\n```\n`server {\n    listen         80;\n    return 301 https://$host$request_uri;\n}\nserver {\n# Document Root\nroot /var/www/example.com;\nindex index.php index.html index.htm;\nserver_name .example.com;\nclient_max_body_size 0;\n\n    listen [::]:443 ssl http2 ipv6only=on;\n    listen 443 ssl http2;\n        ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3;\n        ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;\n        ssl_prefer_server_ciphers on;\n        ssl_session_cache   shared:SSL:20m;\n        ssl_session_timeout 20m;\n        ssl_ciphers 'TLS13+AESGCM+AES128:EECDH+AES128';\n\nerror_page 404 /404.html;\nerror_page 500 502 503 504 /50x.html;\n\n# Rocket-Nginx configuration\n  include rocket-nginx/conf.d/default.conf;\n\n# security\n    include             nginxconfig.io/security.conf;\n\n# Block XMLRPC\nlocation = /xmlrpc.php {\n    deny all;\n}\n\nlocation / {\n    try_files $uri $uri/ /index.php$is_args$args;\n}\n\nlocation ~* \\.php$ {\nif ($uri !~ \"^/uploads/\") {\nfastcgi_pass unix:/run/php/php8.1-fpm.sock;\n}\ninclude fastcgi_params;\nfastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\nfastcgi_param SCRIPT_NAME $fastcgi_script_name;\n}\nlocation = /favicon.ico {\nlog_not_found off;\naccess_log off;\n}\n\nlocation = /robots.txt {\nlog_not_found off;\naccess_log off;\nallow all;\n}\n\nlocation ~* .(css|gif|svg|ico|woff2|eot|jpeg|webp|jpg|js|png)$ {\nexpires 1y;\nlog_not_found off;\n}\n\n# Enable Gzip compression.\ngzip on;\n\n# Disable Gzip on IE6.\ngzip_disable \"msie6\";\n\n# Allow proxies to cache both compressed and regular version of file.\n# Avoids clients that don't support Gzip outputting gibberish.\ngzip_vary on;\n\n# Compress data, even when the client connects through a proxy.\ngzip_proxied any;\n\n# The level of compression to apply to files. A higher compression level increases\n# CPU usage. Level 5 is a happy medium resulting in roughly 75% compression.\ngzip_comp_level 5;\n\n# Compress the following MIME types.\ngzip_types\n application/atom+xml\n application/javascript\n application/json\n application/ld+json\n application/manifest+json\n application/rss+xml\n application/vnd.geo+json\n application/vnd.ms-fontobject\n application/x-font-ttf\n application/x-web-app-manifest+json\n application/xhtml+xml\n application/xml\n font/opentype\n image/bmp\n image/svg+xml\n image/x-icon\n text/cache-manifest\n text/css\n text/plain\n text/vcard\n text/vnd.rim.location.xloc\n text/vtt\n text/x-component\n text/x-cross-domain-policy;\n}\n\n`\n```\nThree: /etc/nginx/sites-available/example1.com\n```\n`server {\n    listen         80;\n    return 301 https://$host$request_uri;\n}\nserver {\n# Document Root\nroot /var/www/example1.com;\nindex index.php index.html index.htm;\nserver_name .example1.com;\nclient_max_body_size 0;\n\n    listen [::]:443 ssl http2;\n    listen 443 ssl http2;\n        ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3;\n        ssl_certificate /etc/letsencrypt/live/example1.com/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/example1.com/privkey.pem;\n        ssl_prefer_server_ciphers on;\n        ssl_session_cache   shared:SSL:20m;\n        ssl_session_timeout 20m;\n        ssl_ciphers 'TLS13+AESGCM+AES128:EECDH+AES128';\n\nerror_page 404 /404.html;\nerror_page 500 502 503 504 /50x.html;\n\n# Rocket-Nginx configuration\n  include rocket-nginx/conf.d/default.conf;\n\n# security\n    include             nginxconfig.io/security.conf;\n\n# Block XMLRPC\nlocation = /xmlrpc.php {\n    deny all;\n}\n\nlocation / {\n    try_files $uri $uri/ /index.php$is_args$args;\n}\n\nlocation ~* \\.php$ {\nif ($uri !~ \"^/uploads/\") {\nfastcgi_pass unix:/run/php/php8.1-fpm.sock;\n}\ninclude fastcgi_params;\nfastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\nfastcgi_param SCRIPT_NAME $fastcgi_script_name;\n}\nlocation = /favicon.ico {\nlog_not_found off;\naccess_log off;\n}\n\nlocation = /robots.txt {\nlog_not_found off;\naccess_log off;\nallow all;\n}\n\nlocation ~* .(css|gif|svg|ico|woff2|eot|jpeg|webp|jpg|js|png)$ {\nexpires 1y;\nlog_not_found off;\n}\n\n# Enable Gzip compression.\ngzip on;\n\n# Disable Gzip on IE6.\ngzip_disable \"msie6\";\n\n# Allow proxies to cache both compressed and regular version of file.\n# Avoids clients that don't support Gzip outputting gibberish.\ngzip_vary on;\n\n# Compress data, even when the client connects through a proxy.\ngzip_proxied any;\n\n# The level of compression to apply to files. A higher compression level increases\n# CPU usage. Level 5 is a happy medium resulting in roughly 75% compression.\ngzip_comp_level 5;\n\n# Compress the following MIME types.\ngzip_types\n application/atom+xml\n application/javascript\n application/json\n application/ld+json\n application/manifest+json\n application/rss+xml\n application/vnd.geo+json\n application/vnd.ms-fontobject\n application/x-font-ttf\n application/x-web-app-manifest+json\n application/xhtml+xml\n application/xml\n font/opentype\n image/bmp\n image/svg+xml\n image/x-icon\n text/cache-manifest\n text/css\n text/plain\n text/vcard\n text/vnd.rim.location.xloc\n text/vtt\n text/x-component\n text/x-cross-domain-policy;\n}\n\n`\n```\nWhen i run: $ sudo nginx -t\nThis answer appears:\n```\n`nginx: [warn] conflicting server name \"\" on 0.0.0.0:80, ignored\n`\n```\nHow do i solve this?\n```\n``\n```",
      "solution": "example.com and example1.com both are identical, you have to add server_name on the listen 80 of both blocks.\nCorrected Server blocks is:\nTwo: /etc/nginx/sites-available/example.com\n```\n`server {\n    listen         80;\n    server_name .example.com;\n    return 301 https://example.com$request_uri;\n}\nserver {\n# Document Root\nroot /var/www/example.com;\nindex index.php index.html index.htm;\nserver_name .example.com;\nclient_max_body_size 0;\n\n    listen [::]:443 ssl http2 ipv6only=on;\n    listen 443 ssl http2;\n        ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3;\n        ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;\n        ssl_prefer_server_ciphers on;\n        ssl_session_cache   shared:SSL:20m;\n        ssl_session_timeout 20m;\n        ssl_ciphers 'TLS13+AESGCM+AES128:EECDH+AES128';\n\nerror_page 404 /404.html;\nerror_page 500 502 503 504 /50x.html;\n\n# Rocket-Nginx configuration\n  include rocket-nginx/conf.d/default.conf;\n\n# security\n    include             nginxconfig.io/security.conf;\n\n# Block XMLRPC\nlocation = /xmlrpc.php {\n    deny all;\n}\n\nlocation / {\n    try_files $uri $uri/ /index.php$is_args$args;\n}\n\nlocation ~* \\.php$ {\nif ($uri !~ \"^/uploads/\") {\nfastcgi_pass unix:/run/php/php8.1-fpm.sock;\n}\ninclude fastcgi_params;\nfastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\nfastcgi_param SCRIPT_NAME $fastcgi_script_name;\n}\nlocation = /favicon.ico {\nlog_not_found off;\naccess_log off;\n}\n\nlocation = /robots.txt {\nlog_not_found off;\naccess_log off;\nallow all;\n}\n\nlocation ~* .(css|gif|svg|ico|woff2|eot|jpeg|webp|jpg|js|png)$ {\nexpires 1y;\nlog_not_found off;\n}\n\n# Enable Gzip compression.\ngzip on;\n\n# Disable Gzip on IE6.\ngzip_disable \"msie6\";\n\n# Allow proxies to cache both compressed and regular version of file.\n# Avoids clients that don't support Gzip outputting gibberish.\ngzip_vary on;\n\n# Compress data, even when the client connects through a proxy.\ngzip_proxied any;\n\n# The level of compression to apply to files. A higher compression level increases\n# CPU usage. Level 5 is a happy medium resulting in roughly 75% compression.\ngzip_comp_level 5;\n\n# Compress the following MIME types.\ngzip_types\n application/atom+xml\n application/javascript\n application/json\n application/ld+json\n application/manifest+json\n application/rss+xml\n application/vnd.geo+json\n application/vnd.ms-fontobject\n application/x-font-ttf\n application/x-web-app-manifest+json\n application/xhtml+xml\n application/xml\n font/opentype\n image/bmp\n image/svg+xml\n image/x-icon\n text/cache-manifest\n text/css\n text/plain\n text/vcard\n text/vnd.rim.location.xloc\n text/vtt\n text/x-component\n text/x-cross-domain-poli\n}\n`\n```\nThree: /etc/nginx/sites-available/example1.com\n```\n`server {\n    listen         80;\nserver_name .example1.com;\n    return 301 https://example1.com$request_uri;\n}\nserver {\n# Document Root\nroot /var/www/example1.com;\nindex index.php index.html index.htm;\nserver_name .example1.com;\nclient_max_body_size 0;\n\n    listen [::]:443 ssl http2;\n    listen 443 ssl http2;\n        ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3;\n        ssl_certificate /etc/letsencrypt/live/example1.com/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/example1.com/privkey.pem;\n        ssl_prefer_server_ciphers on;\n        ssl_session_cache   shared:SSL:20m;\n        ssl_session_timeout 20m;\n        ssl_ciphers 'TLS13+AESGCM+AES128:EECDH+AES128';\n\nerror_page 404 /404.html;\nerror_page 500 502 503 504 /50x.html;\n\n# Rocket-Nginx configuration\n  include rocket-nginx/conf.d/default.conf;\n\n# security\n    include             nginxconfig.io/security.conf;\n\n# Block XMLRPC\nlocation = /xmlrpc.php {\n    deny all;\n}\n\nlocation / {\n    try_files $uri $uri/ /index.php$is_args$args;\n}\n\nlocation ~* \\.php$ {\nif ($uri !~ \"^/uploads/\") {\nfastcgi_pass unix:/run/php/php8.1-fpm.sock;\n}\ninclude fastcgi_params;\nfastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\nfastcgi_param SCRIPT_NAME $fastcgi_script_name;\n}\nlocation = /favicon.ico {\nlog_not_found off;\naccess_log off;\n}\n\nlocation = /robots.txt {\nlog_not_found off;\naccess_log off;\nallow all;\n}\n\nlocation ~* .(css|gif|svg|ico|woff2|eot|jpeg|webp|jpg|js|png)$ {\nexpires 1y;\nlog_not_found off;\n}\n\n# Enable Gzip compression.\ngzip on;\n\n# Disable Gzip on IE6.\ngzip_disable \"msie6\";\n\n# Allow proxies to cache both compressed and regular version of file.\n# Avoids clients that don't support Gzip outputting gibberish.\ngzip_vary on;\n\n# Compress data, even when the client connects through a proxy.\ngzip_proxied any;\n\n# The level of compression to apply to files. A higher compression level increases\n# CPU usage. Level 5 is a happy medium resulting in roughly 75% compression.\ngzip_comp_level 5;\n\n# Compress the following MIME types.\ngzip_types\n application/atom+xml\n application/javascript\n application/json\n application/ld+json\n application/manifest+json\n application/rss+xml\n application/vnd.geo+json\n application/vnd.ms-fontobject\n application/x-font-ttf\n application/x-web-app-manifest+json\n application/xhtml+xml\n application/xml\n font/opentype\n image/bmp\n image/svg+xml\n image/x-icon\n text/cache-manifest\n text/css\n text/plain\n text/vcard\n text/vnd.rim.location.xloc\n text/vtt\n text/x-component\n text/x-cross-domain-policy;\n}\n`\n```\nno need to do changes on default one.",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2022-10-28T19:19:59",
      "url": "https://stackoverflow.com/questions/74238832/nginx-warn-conflicting-server-name-on-0-0-0-080-ignored"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 65726106,
      "title": "Nginx -- Error 400: Origin is not allowed to make this request",
      "problem": "I'm setting up a reverse proxy for MeiliSearch with Nginx. When sending a POST request from an origin, I get a `400: Origin is not allowed to make this request` error. However, if the request does not have an origin, everything works correctly.\nInterestingly, the response also includes different headers whether or not the origin is present.\nRequests/responses\nWorking request\n\nHeader\nValue\n\nContent-Type\napplication/json\n\nX-Meili-API-Key\nasfasdfasdfasdfsafsdfasdfadsfsadff\n\nWorking response\n\nHeader\nValue\n\nServer\nnginx/1.18.0\n\nDate\nThu, 14 Jan 2021 19:49:02 GMT\n\nContent-Type\napplication/json\n\nContent-Length\n252\n\nConnection\nkeep-alive\n\nAccess-Control-Allow-Origin\n*\n\nAs you can see, `Access-Control-Allow-Origin` is a wildcard as it should be.\nFailing request\n\nHeader\nValue\n\nContent-Type\napplication/json\n\nX-Meili-API-Key\nasfasdfasdfasdfsafsdfasdfadsfsadff\n\nOrigin\nhttps://example.com\n\nFailing response\n\nHeader\nValue\n\nServer\nnginx/1.18.0\n\nDate\nThu, 14 Jan 2021 19:49:02 GMT\n\nContent-Length\n252\n\nConnection\nkeep-alive\n\n`Access-Control-Allow-Origin` is now missing.\nConfiguration\nThis is the full configuration file.\n```\n`server {\nserver_name example.com;\nlocation / {\n    if ($request_method ~* \"(GET|POST)\") {\n      add_header \"Access-Control-Allow-Origin\" *;\n    }\n\n    if ($request_method = OPTIONS ) {\n      add_header 'Access-Control-Max-Age' 1728000;\n      add_header \"Access-Control-Allow-Origin\"  *;\n      add_header \"Access-Control-Allow-Methods\" \"GET, POST, OPTIONS, HEAD\";\n      add_header \"Access-Control-Allow-Headers\" \"Authorization, Origin, X-Requested-With, Content-Type, Accept, X-Meili-API-Key\";\n      return 204;\n    }\n\n    proxy_pass  http://127.0.0.1:7700;\n}\n\n    listen [::]:443 ssl ipv6only=on; # managed by Certbot\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n}\nserver {\n    if ($host = example.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\nlisten 80 default_server;\nlisten [::]:80 default_server;\nserver_name example.com;\n`\n```\nAny ideas?",
      "solution": "This problem was reported for the v0.18.0, there was an problem with actix-cors\nhttps://github.com/meilisearch/MeiliSearch/pull/1185\nA new version was released with the fix: v0.18.1\nhttps://github.com/meilisearch/MeiliSearch/releases/tag/v0.18.1\nDownload the new MeiliSearch version and the problem will go away :)",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2021-01-14T21:01:03",
      "url": "https://stackoverflow.com/questions/65726106/nginx-error-400-origin-is-not-allowed-to-make-this-request"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 75335394,
      "title": "Install Nginx on ubuntu 22.04.1 from source and then use package manager",
      "problem": "I'm using Nginx repository to make and make install Nginx from source on server. But in some articles they ran `apt install nginx` at least!\nMy steps:\n```\n` wget http://nginx.org/download/nginx-${NGINX_VERSION}.tar.gz && \\\n    tar xzf /usr/src/nginx-${NGINX_VERSION}.tar.gz\n`\n```\nAnd then:\n```\n`cd /usr/src/nginx-${NGINX_VERSION} && \\\n    ./configure \\\n    --prefix=/etc/nginx \\\n    --sbin-path=/usr/bin/nginx \\\n    --conf-path=/etc/nginx/nginx.conf \\\n    --error-log-path=/var/log/nginx/error.log \\\n    --http-log-path=/var/log/nginx/access.log \\\n    --add-module=/usr/src/nginx-modules/incubator-pagespeed-ngx-${NPS_VERSION}-stable \\\n    --with-pcre \\\n    --pid-path=/var/run/nginx.pid \\\n    --with-http_ssl_module \\\n    --user=nginx \\\n    --group=nginx \\\n    --with-http_gunzip_module \\\n    --with-http_gzip_static_module \\\n    --with-http_v2_module \\\n    --with-http_flv_module \\\n    --with-http_mp4_module \\\n    --with-compat \\\n    --with-http_slice_module \\\n    --with-stream_ssl_module \\\n    --modules-path=/usr/lib/nginx/modules\n`\n```\nand run\n```\n`make && make install\n`\n```\nDefine a user:\n```\n`  adduser --system --no-create-home --shell /bin/false --group --disabled-login nginx\n`\n```\nTill now everything is perfect.\nIn my case before install the nginx from package manager my nginx version was 1.23.1 (stable version) and after install it from package manager `apt install nginx` it goes (1.18)\n\nWhy we need to install Nginx from package managers(like apt in this case) when we did it from source?\nHow can I set some specific options when I use package manager to install the Nginx?",
      "solution": "Nginx maintenairs publish compiled nginx binaries with some predefined options.\nhttps://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/#prebuilt\nThose binaries may not fit for everyone or every usage. One can compile nginx from source code and use it as you do.\n\nBut in some articles they ran `apt install nginx` at least!\n\nTutorials does not tend to complicate the learning process.\n\nWhy we need to install Nginx from package managers (like apt in this case) when we did it from source?\n\nYou don't have to use any package manager at all. But if you install `nginx` by using `apt` it will try to remove your custom binary. This is why you get a different nginx version.\n\nHow can I set some specific options when I use package manager to install the Nginx?\n\nNginx has `mainline` and `stable` binaries published at different repositories.\n`Mainline - Includes the latest features and bug fixes and is always up to date.`\nhttps://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/#installing-a-prebuilt-ubuntu-package-from-the-official-nginx-repository\nYou can specify a package version when using `apt`\n`apt update\napt list -a nginx\napt install nginx=\n`\nhttps://askubuntu.com/questions/92019/how-to-install-specific-ubuntu-packages-with-exact-version\n`nginx -V` shows a nginx binary's configure arguments. You may use it to compile your custom nginx binary.\nHope, this helps.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2023-02-03T12:56:31",
      "url": "https://stackoverflow.com/questions/75335394/install-nginx-on-ubuntu-22-04-1-from-source-and-then-use-package-manager"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 72718333,
      "title": "nginx gives error &quot;server&quot; directive is not allowed here in /etc/nginx/nginx.conf:1",
      "problem": "Nginx no longer starts. This error started happening after running out of storage. This error was not happening before, and I have not change the config. I know there are many other questions with the same error, but none of them helped.\nhere is my nginx config\n`server {\n    listen 80;\n    listen [::]:80;\n\n    server_name ;\n\n    root /var/www/pterodactyl/public;\n    index index.html index.htm index.php;\n    charset utf-8;\n\n    location / {\n        try_files $uri $uri/ /index.php?$query_string;\n    }\n\n    location = /favicon.ico { access_log off; log_not_found off; }\n    location = /robots.txt  { access_log off; log_not_found off; }\n\n    access_log off;\n    error_log  /var/log/nginx/pterodactyl.app-error.log error;\n\n    # allow larger file uploads and longer script runtimes\n    client_max_body_size 100m;\n    client_body_timeout 120s;\n\n    sendfile off;\n\n    location ~ \\.php$ {\n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n        fastcgi_pass unix:;\n        fastcgi_index index.php;\n        include fastcgi_params;\n        fastcgi_param PHP_VALUE \"upload_max_filesize = 100M \\n post_max_size=100M\";\n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        fastcgi_param HTTP_PROXY \"\";\n        fastcgi_intercept_errors off;\n        fastcgi_buffer_size 16k;\n        fastcgi_buffers 4 16k;\n        fastcgi_connect_timeout 300;\n        fastcgi_send_timeout 300;\n        fastcgi_read_timeout 300;\n    }\n\n    location ~ /\\.ht {\n        deny all;\n    }\n}\n`\nHere is the output of `nginx -T`\n`nginx: [emerg] \"server\" directive is not allowed here in /etc/nginx/nginx.conf:1\nnginx: configuration file /etc/nginx/nginx.conf test failed\n`",
      "solution": "This isn't an nginx configuration file but a vhost configuration file that should be placed at the `/etc/nginx/conf.d` (or `/etc/nginx/sites-enabled` if you prefer that type of vhost configuration files organization; see the Difference in sites-available vs sites-enabled vs conf.d directories thread at ServerFault to find out the difference) directory. You can check the whole nginx configuration file example at the nginx GitHub mirror.\nThose vhost configuration files are usually being included from the main configuration file at the `http` configuration level:\n`http {\n    ...\n    include /etc/nginx/conf.d/*.conf;\n}\n`\nand the Debian-based packages (or any other packages using those `sites-enabled`/`sites-available` directories) have an additional line there:\n`http {\n    ...\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*;\n}\n`\nTo find an original `nginx.conf` file for your particular Ubuntu distro, download the appropriate `nginx-common` package and check its contents.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2022-06-22T17:37:07",
      "url": "https://stackoverflow.com/questions/72718333/nginx-gives-error-server-directive-is-not-allowed-here-in-etc-nginx-nginx-con"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 69626534,
      "title": "nginx to serve static file but instead when i go to the route it downloads the .html",
      "problem": "I am trying to serve a health status page for a particular route in my nginx configuration.\nI have a docker file that copies the `html` into the correct location and have confirmed it was there.\nBut when I navigate to the route `/en/health` then i do not see the basic html page on screen when the site is up and running but it downloads the file to my desktop.\nMy HML file:\n```\n`\n\n  \n    \n    \n    Sample site\n  \n  \n    I am a healthy page>\n  \n\n`\n```\nMy nginx config:\n```\n`server {\n    listen 8080;\n    server_name  localhost;\n\n    location / {\n        root /usr/share/nginx/html;\n        index index.html index.htm;\n        try_files $uri $uri/ /index.html =404;\n    }\n    error_page   500 502 503 504  /50x.html;\n\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n    \n    location /en/health {\n        alias /usr/share/nginx/html/en/health/;\n        index health.html; \n    }\n\n    location /nginx_status {\n        stub_status;\n\n        access_log off;\n        allow 127.0.0.1;\n        deny all;\n    }\n}\n`\n```\nHow do I serve `health.html` as a web page in its own right from the nginx configuration?",
      "solution": "First, you should move `root /usr/share/nginx/html;` to the `server` block context, as most of your `location` blocks are using the same document root. Even the `location /en/health` block appears to be using the same document root.\nRather than relying on `alias` and `index` to find the correct file, use `try_files` to explicitly define the file you want to return.\nFor example:\n```\n`location /en/health {\n    try_files /en/health/index.html =404;\n}\n`\n```",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-10-19T09:18:58",
      "url": "https://stackoverflow.com/questions/69626534/nginx-to-serve-static-file-but-instead-when-i-go-to-the-route-it-downloads-the"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 68791116,
      "title": "NGINX try_files can not find the &quot;$1&quot; in directory",
      "problem": "I am hitting a problem with NGINX try_files and $1\nI want NGINX to serve a file if it is already in a folder. If it is not in a folder, then the request should be sent to Django.\nHere is the file in NGINX:\n```\n`ls /app/processed/instagramwhite.svg \n/app/processed/instagramwhite.svg\n`\n```\nHere is the nginx location config:\n```\n`location ~* ^\\/media\\/(.*\\.svg)$ {\n    # return 200 $1; # This statement returns the name of the file when enabled, so regex works\n    root /app/processed/;\n    try_files $1 @djangoapp; # This always calls django\n  }\n`\n```\nHere is how I send the request:\n`curl -s https://my_domain_here.com/media/instagramwhite.svg`\nI expect NGINX to return the file without going to django since the file name from the parameter is in the folder. Instead it invokes django for every request.\nWhat am I doing wrong? Why does try_files keep calling django even when the file is there?\nThanks in advance.",
      "solution": "Here is the solution:\n```\n`location ~* ^\\/media\\/(.*\\.svg)$ {\n    # return 200 $1;\n    root /app/processed/;\n    try_files /$1 @djangoapp;\n  }\n`\n```\nYou have to add \"/\" in front of \"$1\" to make it work. So \"/$1\" works but \"$1\" does not.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-08-15T13:33:30",
      "url": "https://stackoverflow.com/questions/68791116/nginx-try-files-can-not-find-the-1-in-directory"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 78639833,
      "title": "How to redirect a web page with a Hash in URL NGINX Ubuntu Server",
      "problem": "I have an issue to make my reset password service functionally, I send via API a hash         in the URL, so the client receive a URL like `https://mydomain.com.mx/?hash=hash_code`\nI need to set a redirect for this URL, so when the client click on it the site must redirect to   `https://mydomain.com.mx/recovery/?hash=hash_code`\nI already try different settings as rewrite or try file. The closest to working was\n```\n`if ($arg_hash) {\n      return 301 https://mydomain.com.mx/recovery/?hash=$arg_hash;\n  }\n`\n```\nBut I get an error, too many to redirects, please if you can help me, I'll be grateful\nThis is my conf file, I use wordpress for this website\nImportant I can't edit the url that comes to the user should be kept as https://mydomain.com.mx\n```\n`# Default server configuration\n#\n\n      log_format custom '$remote_addr - $remote_user [$time_local] '\n                           '\"$request\" $status $body_bytes_sent '\n                           '\"$http_referer\" \"$http_user_agent\" \"$gzip_ratio\"';\n\nserver {\n        root /var/www/html/mydomain.com.mx;\n        access_log /var/log/nginx/mydomain.com.mx.access.log custom;\n        error_log /var/log/nginx/mydomain.com.mx.error.log debug;\n\n        # Add index.php to the list if you are using PHP\n        index index.html index.htm index.nginx-debian.html index.php;\n        server_name www.mydomain.com.mx mydomain.com.mx;\n\n        # BEGIN Converter for Media\n        set $ext_avif \".avif\";\n        if ($http_accept !~* \"image/avif\") {\n            set $ext_avif \"\";\n        }\n\n        set $ext_webp \".webp\";\n        if ($http_accept !~* \"image/webp\") {\n            set $ext_webp \"\";\n        }\n        # nginx block xmlrpc.php requests\n        location /xmlrpc.php {\n        deny all;\n        }\n        location ~ /wp-content/(?.+)\\.(?jpe?g|png|gif|webp)$ {\n            add_header Vary Accept;\n            add_header Cache-Control \"private\";\n            expires 365d;\n            try_files\n                /wp-content/uploads-webpc/$path.$ext$ext_avif\n                /wp-content/uploads-webpc/$path.$ext$ext_webp\n                $uri =404;\n        }\n        # END Converter for Media\n\n        location / {\n                # First attempt to serve request as file, then\n                # as directory, then fall back to displaying a 404.\n                #try_files $uri $uri/ =404;\n                try_files $uri $uri/ /index.php?$args;\n        }\n\n        # pass PHP scripts to FastCGI server\n        #\n        location ~ \\.php$ {\n                include snippets/fastcgi-php.conf;\n        #\n        #       # With php-fpm (or other unix sockets):\n                fastcgi_pass unix:/run/php/php8.3-fpm.sock;\n                fastcgi_read_timeout 120;\n        #       # With php-cgi (or other tcp sockets):\n        #       fastcgi_pass 127.0.0.1:9000;\n        }\n        gzip on;\n        gzip_comp_level 6;\n        gzip_min_length 1000;\n        gzip_proxied any;\n        gzip_disable \"msie6\";\n#  gzip_types text/plain text/css text/xml application/json application/javascript application/xml+rss application/atom+xml image/svg+xml;\n        gzip_types application/atom+xml application/geo+json application/javascript application/x-javascript application/json application/ld+json application/manifest+json application/rdf+xml application/rss+xml application/xhtml+xml application/xml font/eot font/otf font/ttf image/svg+xml text/css text/javascript text/plain text/xml;\n  # Enable Brotli compression\n        brotli on;\n        brotli_comp_level 6;\n        brotli_types text/xml image/svg+xml application/x-font-ttf image/vnd.microsoft.icon application/x-font-opentype application/json font/eot application/vnd.ms-fontobject application/javascript font/otf application/xml application/xhtml+xml text/javascript  application/x-javascript text/plain application/x-font-truetype application/xml+rss image/x-icon font/opentype text/css image/x-win-bitmap;\n\n        location ~*\\.(?:css(\\.map)?|js(\\.map)?|ico|cur|heic|tiff?|mp3|m4a|aac|ogg|midi?|wav|mp4|mov|webm|mpe?g|avi|ogv|flv|wmv)$ {\n         expires 90d;\n         access_log off;\n         }\n\n        location ~*\\.(?:svgz?|ttf|ttc|otf|eot|woff2?)$ {\n         add_header Access-Control-Allow-Origin \"*\";\n         expires 90d;\n         access_log off;\n         }\n\n        # deny access to .htaccess files, if Apache's document root\n        # concurs with nginx's one\n        #\n        location ~ /\\.ht {\n                deny all;\n        }\n\n        location ~ /\\.user.ini {\n                deny all;\n        }\n\n        location /wp-json/ {\n        try_files $uri $uri/ /index.php?$is_args$args;\n        }\n\n        # if ($arg_hash) {\n        #    return 301 https://mydomain.com.mx/recovery/?hash=$arg_hash;\n        #}\n\n    listen [::]:443 ssl http2;# managed by Cer tbot\n    listen 443 ssl http2; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/mydomain.com.mx/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/mydomain.com.mx/privkey.pem; # managed by Certbot\n    #include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    include perfect-forward-secrecy.conf;\n    #ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n}\n\nserver {\n    if ($host = mydomain.com.mx) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n    server_name www.mydomain.com.mx mydomain.com.mx;\n    listen [::]:80;\n    listen 80;\n#   return 404; # managed by Certbot\n\n}\n`\n```",
      "solution": "You get a redirection loop because `if ($arg_hash)` matches both `//example.com/?hash=xxx` and `//example.com/recovery/?hash=xxx`\nOne solution is to modify your `if` statement to only match the first case.\nFor example:\n```\n`if ($request_uri ~* \"^/\\?hash=\") {\n    return 301 /recovery/?hash=$arg_hash;\n}\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2024-06-19T00:08:31",
      "url": "https://stackoverflow.com/questions/78639833/how-to-redirect-a-web-page-with-a-hash-in-url-nginx-ubuntu-server"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 73764405,
      "title": "NGINX Only path equals to without trailing slash and starts with path with trailing slash",
      "problem": "I'm encountering an annoying error when it comes to my current NGINX app configuration.\nI have a static web app which I am indexing on the path `/admin/*`. I want the index to be available on `/admin`, with and without a trailing slash, as well as available on a wildcard `/admin/*` (anything after the trailing slash).\nThe issue I am facing is that the index is accessable when appending anything after the `admin` path, for example `/adminA/example`.\nThe original NGINX configuration was as follows:\n```\n`location /admin {\n    alias /home/user/app/static;\n    index index.html;\n    try_files $uri $uri/ /index.html;\n}\n`\n```\nThe best I've been able to implement to stop this at the moment is as follows, however i'm sure it can be done more efficiently:\n```\n`location = /admin {\n    alias /home/user/app/static;\n    index index.html;\n    try_files $uri $uri/ /index.html;\n}\n\nlocation /admin/ {\n    alias /home/user/app/static/;\n    index index.html;\n    try_files $uri $uri/ /admin/index.html;\n}\n`\n```",
      "solution": "The two location blocks are already efficient, but you could eliminate the redundant code in the first block by redirecting to the second.\nUsing an internal redirect will be invisible to the browser. For example:\n```\n`location = /admin {\n    rewrite ^ /admin/ last;\n}\n\nlocation /admin/ {\n    ...\n}\n`\n```\nOr use `permanent` instead of `last` for an external redirect, which will change the browser's address bar from `/admin` to `/admin/`. See the `rewrite` documentation.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2022-09-18T18:16:32",
      "url": "https://stackoverflow.com/questions/73764405/nginx-only-path-equals-to-without-trailing-slash-and-starts-with-path-with-trail"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 72184862,
      "title": "What is difference between using $uri and $uri$args in try_files directive",
      "problem": "For my other Angular apps, I am using the below config and everything seems to work fine.\n```\n`location / {\n     try_files $uri$args $uri$args/ /index.html;\n}\n`\n```\nNow the one which I am working has nested folders within the dist folder.\nAnd folder structure is something like:\n```\n`dist \\\n  -- assets\n  -- folder1\n     -- folder2\n        -- folder3\n        -- folder4\n        -- folder5\n        index.html\n  index.html\n`\n```\nAnd the inner index.html is called with query params, and the url will be like - `/folder1/folder2/index.html?a=1&b=2&c=3`. But this is returning the fallback index.html at the root location. Later, I changed the above location block like this and it started working properly.\n```\n`location / {\n     try_files $uri $uri/ /index.html;\n}\n`\n```\nSo I am not clear why the first location block didn't work. And I can't find anything in docs - try_files",
      "solution": "All of the parameters of a `try_files` statement except the last parameter are looking for filenames in the local file system.\nSo given the URI `/foo/bar`, the term `$uri$args` will search for a local file at `/path/to/root/foo/bar`, and if it does not exist will move on to the next term or the default clause at the end of the statement.\nIn the above case, `$args` is empty. However, given the URI `/foo/bar?baz`, the term `$uri$args` will search for a local file at `/path/to/root/foo/barbaz`.\nI don't know why anyone would use `$uri$args` or `$uri$args/` as file terms on a `try_files` statement, but there may well be a legitimate use case.\nThe last parameter of a `try_files` statement is special. It can be a status code (for example `=404`), a named location to branch to, or a URI.\nIn the case of a URI, Nginx will internally redirect to that URI. A typical example might be `/index.php$isargs$args` - in this case it is perfectly legitimate to append the `$args` parameter, as we are creating a new URI and keeping the original argument string.\nSee this document for details.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2022-05-10T12:41:13",
      "url": "https://stackoverflow.com/questions/72184862/what-is-difference-between-using-uri-and-uriargs-in-try-files-directive"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 69480359,
      "title": "Serve a folder for a parameter",
      "problem": "I have a question regarding parameter after root url:\n```\n`URL is : https://test/?version=12.1.0\n`\n```\nWhat I want there is a parameter starting with version=numner.number.number\nTo serve a folder under the root dir \"v12.1.0\"\n```\n`location ~ ^\\?version=v(\\d+\\.\\d+\\.\\d+)  {\n     root           /var/www/test/htdocs/v$2;\n\n}\n`\n```\nIs that possible? I've been trying wiith try files and root, but I cannot manage to make it work. Should I use map in this situation?",
      "solution": "Nginx normalises the URI before processing it. The part of the URI before the `?` is available as the `$uri` variable, and the part of the URI after the `?` is available as the `$args` variable.\nThe `location` and `rewrite` directives operate on the value of the `$uri` variable, so your present approach will not work, as the query string has already been remove.\nThe `$args` variable is further split into other individual variables, so that the value of your `version=` parameter is available as `$arg_version`.\n\nOne solution is to use a `map` block to decode `$arg_version` and use the mapped variable in a `try_files` statement as required.\nFor example:\n```\n`map $arg_version $mypath {\n    ~*^(v\\d+\\.\\d+\\.\\d+)$ $1/;\n    default              \"\";\n}\n\nserver {\n    ...\n\n    root /var/www/test/htdocs;\n\n    location ... {\n        try_files $mypath$uri =404;\n    }\n}\n`\n```\nWe could use `$arg_version` as is, but the `map` ensures that the path prefix is sanitised and contains the necessary `/` separator.\nNote that the `map` block lives outside of the `server` block. See this document for details.\n\nDepending on your specific requirements, you could also use the mapped variable directly with `root`. For example:\n```\n`root /var/www/test/htdocs/$mypath;\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-10-07T13:30:55",
      "url": "https://stackoverflow.com/questions/69480359/serve-a-folder-for-a-parameter"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 69137372,
      "title": "NGINX why does my redirection from subfolder to ip address not work?",
      "problem": "I have following network situation:\nRouter 192.168.1.1 (portforwarding 80 to 192.168.1.20 Raspberry)\nRaspberry 192.168.1.20 with nginx running.\nSynology NAS 192.168.1.10 with \"synology drive\" service running.\nOn the Raspberry 192.168.1.20 nginx conf file I have a redirection for the subfolder /drive. Because I want to redirect to the Synology NAS to be able to use the \"synology drive\" service.\nTherefore I've created following entry on the Raspberry nginx server in the conf file:\n```\n`    location ^~ /drive {\n    rewrite ^/drive/?(.*)$ 192.168.1.10/$1 permanent;\n}\n`\n```\nThis redirection kind of works. But only when I'm on the same local network.\nMy problem is now that I have a domain name pointing to my router (static ip).\nBut if i use mydomain.tld/drive then the redirection doesn't work.\nDoes anyone know how to achieve this?",
      "solution": "You need to use the proxy_pass directive",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-09-10T21:49:56",
      "url": "https://stackoverflow.com/questions/69137372/nginx-why-does-my-redirection-from-subfolder-to-ip-address-not-work"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 68752903,
      "title": "NGINX pointing different docker compose containers",
      "problem": "I am new to docker and I ran into an architectural problem:\nI have two sets of container (CUSTOMER1, CUSTOMER2) running in my computer by the same docker-compose file which, both, contains two same applications (APP1, APP2).\nMy question is: Is there a way, using an nginx server in the same host, to access to the desired app in the desired container (ex: APP1 into CUSTOMER1 container by browser link (ex: CUSTOMER1.MYPC.IT/APP1) through my computer using Windows containers?\nHere I attach a graphical representation for better explaination:\nimage showing an host called \"my_computer\" which is running two different container, both with two applications running (APP1, APP2) with an external nginx server\nHere, is the nginx.conf file from the nginx container:\n```\n`worker_processes  auto;\nevents {\n    worker_connections  4096;\n}\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    sendfile        on;\n\n    keepalive_timeout  99999;\n\n     server {\n            listen 80;\n            server_name localhost 127.0.0.1;\n            resolver 127.0.0.11;\n            location /APP1 {\n                proxy_pass          http://test_app1/......;\n                proxy_set_header    X-Forwarded-For $remote_addr; \n                proxy_read_timeout 300;\n                proxy_connect_timeout 300;\n                proxy_send_timeout 300;\n            }\n\n            location /APP2 {\n                include  /etc/nginx/mime.types;\n                proxy_pass          http://test_app2/......;\n                proxy_set_header    X-Forwarded-For $remote_addr;\n            }\n        }\n    }\n`\n```\nHere, is my Docker-compose file:\n```\n`version: '3.9'\nservices:\n    app1basecontainer:\n        image: app1baseimg\n        build: ./APP1BASEIMG\n        volumes:\n            - apps1hared:C:\\DEFAULT\\APPPortal\n        expose:\n            - 8080\n    app2basecontainer:\n        depends_on: \n            - \"appbasecontainer\"\n        image: app2baseimg\n        build: ./APP2BASEIMG\n        volumes:\n            - apps2hared:C:\\DEFAULT\\APPPortal\n        expose:\n            - 80\n\nvolumes:\n    apps1hared:\n    apps2shared:\n`\n```\nThanks so much",
      "solution": "2 Options:\n1- Bind container ports to outside, then proxy to them:\n`services:\n    app1basecontainer:\n        ...\n        ports:\n            - 8080:8080\n    app2basecontainer:\n        ...\n        ports:\n            - 80:80\n`\nThen, in your Nginx conf:\n```\n`server{\n    location /APP1 {\n        proxy_pass          http://localhost:8080;\n    }\n    location /APP2 {\n        proxy_pass          http://localhost:80;\n    }\n}\n`\n```\n2- Nginx container to your docker-compose, then apps and nginx are in the same network, and nginx can see apps containers. Then your nginx conf changes to :\n```\n`server{\n    location /APP1 {\n        proxy_pass          http://CONTAINER_NAME:8080;\n    }\n    location /APP2 {\n        proxy_pass          http://CONTAINER_NAME:80;\n    }\n}\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-08-12T08:56:26",
      "url": "https://stackoverflow.com/questions/68752903/nginx-pointing-different-docker-compose-containers"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 68167077,
      "title": "How to Correct &#39;nginx: [emerg] &quot;stream&quot; directive is not allowed here&#39;",
      "problem": "The Question\nWhy does the following Nginx configuration return `nginx: [emerg] \"stream\" directive is not allowed here in /etc/nginx/sites-enabled/default:1`?\nNginx Configuration...\n```\n`stream {\n  map $ssl_preread_server_name $upstream {\n    example.com 1051;\n  }\n  upstream 1051 {\n    server 127.0.0.1:1051;\n  }\n  server {\n    listen 443;\n    proxy_pass $upstream;\n    ssl_preread on;\n  }\n}\n`\n```\nVersion / Build information...\nOS: Debian 10\nHere is the stripped down `nginx -V` output confirming the presence of the modules I understand I need...\n```\n`nginx version: nginx/1.14.2\nTLS SNI support enabled\nconfigure arguments: ... --with-stream=dynamic --with-stream_ssl_module --with-stream_ssl_preread_module ...\n`\n```\nThe Context\nI have a single static IP address. At the static IP address, I am setting up a reverse proxy Nginx server to forward traffic to a variety of backend services. Several of the services are websites with unique domain names.\n```\n`+-----+        +----------------------+        +---------+\n| WAN |  | Nginx Reverse Proxy  |  | Service |\n+-----+        +----------------------+        +---------+\n`\n```\nAt boot, the service uses systemd to run this port forwarding `ssh` command to connect to the reverse proxy: `ssh -N -R 1051:localhost:443 tunnel@example.com` (That is working well.)\nI want the certificate to reside on the service - not the reverse proxy. From what I understand I need to leverage SNI on Nginx to passthrough the SSL connections bases on domain name. But I cannot get the Nginx reverse proxy to passthrough SSL.\nResources\nHere are a few of the resources I have pored over...\n\nhttps://serverfault.com/questions/625362/can-a-reverse-proxy-use-sni-with-ssl-pass-through\nhttps://nginx.org/en/docs/stream/ngx_stream_core_module.html\nhttps://nginx.org/en/docs/stream/ngx_stream_ssl_preread_module.html\nhttps://www.amitnepal.com/nginx-ssl-passthrough-reverse-proxy\nhttps://serverfault.com/questions/1049158/nginx-how-to-combine-ssl-preread-protocol-with-ssl-preread-server-name-ssh-mul",
      "solution": "The problem was I tried to embed a `stream` block inside an `http` block. I was not properly accounting for the `include` in `/etc/nginx/nignx.conf` file.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-06-28T18:39:48",
      "url": "https://stackoverflow.com/questions/68167077/how-to-correct-nginx-emerg-stream-directive-is-not-allowed-here"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 67875287,
      "title": "Failed to start nginx.service: Unit nginx.service not found",
      "problem": "I have installing Nginx from source binary with this options:\n`/configure --sbin-path=/usr/bin/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log \\\n    --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --with-pcre --with-http_ssl_module\n`\neverything work well,\n`$ sudo nginx -V\nnginx version: nginx/1.21.0\nbuilt by gcc 9.3.0 (Ubuntu 9.3.0-17ubuntu1~20.04) \nbuilt with OpenSSL 1.1.1f  31 Mar 2020\nTLS SNI support enabled\nconfigure arguments: --sbin-path=/usr/bin/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --with-pcre --with-http_ssl_module\n\n$ ps aux | grep nginx\namookhs+    1793  1.0  0.0   8160   736 pts/0    S+   03:58   0:00 grep --color=auto nginx\n`\nBut, when I run the `sudo systemctl reload nginx` command, I get this error:\n`Failed to reload nginx.service: Unit nginx.service not found.\n`\nHow can I solve it?",
      "solution": "I saved this file as `/lib/systemd/system/nginx.service`\n```\n`[Unit]\nDescription=The NGINX HTTP and reverse proxy server\nAfter=syslog.target network-online.target remote-fs.target nss-lookup.target\nWants=network-online.target\n\n[Service]\nType=forking\nPIDFile=/var/run/nginx.pid\nExecStartPre=/usr/bin/nginx -t\nExecStart=/usr/bin/nginx\nExecReload=/usr/bin/nginx -s reload\nExecStop=/bin/kill -s QUIT $MAINPID\nPrivateTmp=true\n\n[Install]\nWantedBy=multi-user.target\n`\n```\nNote. The location of the PIDFile and the NGINX binary may be different depending on how NGINX was compiled.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-06-07T18:20:32",
      "url": "https://stackoverflow.com/questions/67875287/failed-to-start-nginx-service-unit-nginx-service-not-found"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 67824017,
      "title": "Nginx refuses to read custom nginx.config when dockerized",
      "problem": "I have created a custom nginx.conf file with simple proxy and I have put it in the root of my project.\nnginx.conf\n```\n`user www-data;\nworker_processes auto;\ninclude /etc/nginx/modules-enabled/*.conf;\n\nevents {\n    worker_connections 768;\n    # multi_accept on;\n}\n\nhttp {\n\n    ##\n    # Basic Settings\n    ##\n\n    sendfile on;\n    tcp_nopush on;\n    types_hash_max_size 2048;\n    # server_tokens off;\n\n    # server_names_hash_bucket_size 64;\n    # server_name_in_redirect off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    ##\n    # SSL Settings\n    ##\n\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE\n    ssl_prefer_server_ciphers on;\n\n    ##\n    # Logging Settings\n    ##\n\n    access_log /var/log/nginx/access.log;\n    error_log /var/log/nginx/error.log;\n\n    ##\n    # Gzip Settings\n    ##\n\n    gzip on;\n\n    # gzip_vary on;\n    # gzip_proxied any;\n    # gzip_comp_level 6;\n    # gzip_buffers 16 8k;\n    # gzip_http_version 1.1;\n    # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;\n\n    ##\n    # Virtual Host Configs\n    ##\n\n    include /etc/nginx/conf.d/*.conf;\n    #include /etc/nginx/sites-enabled/*;\n\n      server { # simple reverse-proxy\n      root /var/www/html;\n    listen       80;\n\n    # pass requests for dynamic content to rails/turbogears/zope, et al\n    location /test1/ {\n      proxy_pass      http://dumy/test1/;\n    }\n\n    location /test2/ {\n      proxy_pass      http://dumy/test2/;\n    }\n  }\n}\n\n#mail {\n#   # See sample authentication script at:\n#   # http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript\n#\n#   # auth_http localhost/auth.php;\n#   # pop3_capabilities \"TOP\" \"USER\";\n#   # imap_capabilities \"IMAP4rev1\" \"UIDPLUS\";\n#\n#   server {\n#       listen     localhost:110;\n#       protocol   pop3;\n#       proxy      on;\n#   }\n#\n#   server {\n#       listen     localhost:143;\n#       protocol   imap;\n#       proxy      on;\n#   }\n#}\n`\n```\nWhen I run my nginx server locally (ubuntu) everything works perfect. The proxies work as they should.\nWhen I try to run it through docker container, no matter what I do, the proxies do not work.\nmy Dockerfile:\n```\n`FROM node:alpine AS builder\nWORKDIR '/app'\nCOPY package.json .\nRUN npm install\nCOPY . .\nRUN npm run prod\n\nFROM nginxinc/nginx-unprivileged\nCOPY --from=builder /app/dist /usr/share/nginx/html\n\nCOPY nginx.conf /etc/nginx/nginx.conf\n\nEXPOSE 8080\nCMD [\"nginx\",\"-g\", \"daemon off;\", \"-c\", \"/etc/nginx/nginx.conf\"]\n`\n```\nI have to use nginxinc/nginx-unprivileged because the app will eventually deployed in openshift.\nThe above docker file will create the docker image.\nWhen I run:\n```\n` docker run -p 8080:8080 \n`\n```\nThe container will be created and start. But no matter what I do , it will start with the default configuration.\nThis is what I get if I run\n```\n`nginx -T \n`\n```\ninside the container :\n```\n`# configuration file /etc/nginx/conf.d/default.conf:\nserver {\n    listen       8080;\n    server_name  localhost;\n\n    #charset koi8-r;\n    #access_log  /var/log/nginx/host.access.log  main;\n\n    location / {\n        root   /usr/share/nginx/html;\n        index  index.html index.htm;\n    }\n\n    #error_page  404              /404.html;\n\n    # redirect server error pages to the static page /50x.html\n    #\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n        root   /usr/share/nginx/html;\n    }\n\n    # proxy the PHP scripts to Apache listening on 127.0.0.1:80\n    #\n    #location ~ \\.php$ {\n    #    proxy_pass   http://127.0.0.1;\n    #}\n\n    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000\n    #\n    #location ~ \\.php$ {\n    #    root           html;\n    #    fastcgi_pass   127.0.0.1:9000;\n    #    fastcgi_index  index.php;\n    #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;\n    #    include        fastcgi_params;\n    #}\n\n    # deny access to .htaccess files, if Apache's document root\n    # concurs with nginx's one\n    #\n    #location ~ /\\.ht {\n    #    deny  all;\n    #}\n}\n`\n```\nAs you can see, my nginx.conf file is completely ignored.  It's like\n```\n` \"-c\", \"/etc/nginx/nginx.conf\"\n`\n```\nfrom cmd inside the Dockerfile never runs.\nI have tried to pass the command in docker run with no luck.\nCould you please help me?",
      "solution": "After A LOT of trial and error I have finally managed to make this work. First of all change image inside Dockerfile from: nginxinc/nginx-unprivileged to nginx:alpine\nSecond, give the right privileges to the user inside the openshift. Run :\n```\n`oc adm policy add-scc-to-user anyuid system:serviceaccount:>:default\n`\n```\nNext a default.conf file should be created inside the root of the project and have the same contents inside the server {} object as the custom nginx.conf file. Finally the correct configuration on all files should be made.\ndefault.conf:\n```\n`    server { # simple reverse-proxy\n    root /usr/share/nginx/html;\n    listen       80;\n\n    # pass requests for dynamic content to rails/turbogears/zope, et al\n    location /test1/ {\n      proxy_pass      http://dumy/test1/;\n    }\n\n    location /test2/ {\n      proxy_pass      http://dumy/test2/;\n    }\n  }\n`\n```\nnginx.conf:\n```\n`events {\n    worker_connections 768;\n    # multi_accept on;\n}\n\nhttp {\n\n    ##\n    # Basic Settings\n    ##\n\n    sendfile on;\n    tcp_nopush on;\n    types_hash_max_size 2048;\n    # server_tokens off;\n\n    # server_names_hash_bucket_size 64;\n    # server_name_in_redirect off;\n\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    ##\n    # SSL Settings\n    ##\n\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE\n    ssl_prefer_server_ciphers on;\n\n    ##\n    # Logging Settings\n    ##\n\n    access_log /var/log/nginx/access.log;\n    error_log /var/log/nginx/error.log;\n\n    ##\n    # Gzip Settings\n    ##\n\n    gzip on;\n\n    # gzip_vary on;\n    # gzip_proxied any;\n    # gzip_comp_level 6;\n    # gzip_buffers 16 8k;\n    # gzip_http_version 1.1;\n    # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;\n\n    ##\n    # Virtual Host Configs\n    ##\n\n    include /etc/nginx/conf.d/*.conf;\n    #include /etc/nginx/sites-enabled/*;\n\n      server { # simple reverse-proxy\n      root /var/www/html;\n    listen       80;\n\n    # pass requests for dynamic content to rails/turbogears/zope, et al\n    location /test1/ {\n      proxy_pass      http://dumy/test1/;\n    }\n\n    location /test2/ {\n      proxy_pass      http://dumy/test2/;\n    }\n  }\n}\n`\n```\nDockerfile:\n```\n`FROM node:alpine AS builder\nWORKDIR '/app'\nCOPY package.json .\nRUN npm install\nCOPY . .\nRUN npm run prod\n\nFROM nginx:alpine\nCOPY --from=builder /app/dist /usr/share/nginx/html\nCOPY nginx.conf /etc/nginx/\nCOPY default.conf /etc/nginx/conf.d/\n\nRUN chgrp -R root /var/cache/nginx /var/run /var/log/nginx && \\\n    chmod -R 770 /var/cache/nginx /var/run /var/log/nginx\nEXPOSE 8080\nCMD [\"nginx\",\"-g\", \"daemon off;\"]\n`\n```\nPlease keep in mind that in both default.conf and nginx.conf files the root inside the server object should be changed to match the path of your static files html files. in my case the path inside the docker was :  /usr/share/nginx/html so the entire root variable should be :\n```\n`  root /usr/share/nginx/html;\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-06-03T17:08:46",
      "url": "https://stackoverflow.com/questions/67824017/nginx-refuses-to-read-custom-nginx-config-when-dockerized"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 67527599,
      "title": "nginx with sub-request redirection removes query params",
      "problem": "I have a test application which I am authorizing by having an internal `/auth` sub-request to flask back-end.\nAuthorization happens by google sign in and once authorized it comes back to redirect to the actual application client has asked for.\nAlthough, I am facing an issue here. If the client has passed multiple query-parameters in the original URL, that is being stripped off afterwards.\nFor example:\n```\n`127.0.0.1/test/?query1=val1&query2=val2&query3=val3\n`\n```\nbecomes\n```\n`127.0.0.1/test/?query1=val1\n`\n```\nBasically `$request_uri` does not hold all the query-parameters passed initially. URL Encoding is the culprit here?\nBelow is my Nginx configuration file.\n```\n`worker_processes 1;\ndaemon off;\nerror_log stderr debug;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\nserver {\n    listen 80;\n    server_name  _;\n\n    proxy_set_header Host $host:80;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n\n    location ^~ / {\n        proxy_pass http://127.0.0.1:8010/;\n    }\n\n    # Internal auth check endpoint.\n    location = /auth {\n        internal;\n        proxy_pass http://127.0.0.1:8010/auth;\n        proxy_pass_request_body off;\n        proxy_set_header Content-Length \"\";\n        proxy_set_header X-Original-URI $request_uri;\n    }\n\n    location ^~ /test/ {\n        # Internal sub-request auth check before serving the endpoint.\n        auth_request /auth;\n        proxy_pass http://127.0.0.1:8011/;\n\n        # Redirect to @login if 401 from /auth.\n        error_page 401 @login;\n    }\n\n    # Catch if 401/unauthorized and redirect for login\n    location @login {\n        return 302 /authorize?next=$request_uri;\n    }\n}\n}\n`\n```\nPlease help.",
      "solution": "Finally A solution of my own after 2 days of research into nginx. :D\nAs I was passing every incoming request to `/auth`, I encoded the url in the auth backend (Flask application in my case).\nSending back the encoded url to nginx by updating the headers like this.\n```\n`@app.route('/auth')\ndef auth():\n    if not has_valid_cookies():\n        resp = flask.Response(\"\", status=401)\n        resp.headers['X-Original-URI'] = url_parse.quote(\n            flask.request.headers.get('X-Original-URI', '/')\n        )\n        return resp\n    else:\n        return flask.jsonify(success=True)\n`\n```\nThe nginx conf becomes like below where I am sending `X-Original-URI` with original request_uri value back to backend, encode it there and hold the encoded value like this:\n`auth_request_set $next_uri $upstream_http_X_Original_URI;`\n`$next_uri` holds the encoded original request url.\n```\n`    location = /auth {\n        internal;\n        proxy_pass http://127.0.0.1:8010/auth;\n        proxy_pass_request_body off;\n        proxy_set_header Content-Length \"\";\n        proxy_set_header X-Original-URI $request_uri;\n    }\n\n    location ^~ /test/ {\n        # Internal sub-request auth check before serving the endpoint.\n        auth_request /auth;\n        auth_request_set $next_uri $upstream_http_X_Original_URI;\n        proxy_pass http://127.0.0.1:8011/;\n\n        # Redirect to @login if 401 from /auth.\n        error_page 401 @login;\n    }\n\n    # Catch if 401/unauthorized and redirect for login\n    location @login {\n        return 302 /authorize?next=$next_uri;\n    }\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-05-14T02:07:16",
      "url": "https://stackoverflow.com/questions/67527599/nginx-with-sub-request-redirection-removes-query-params"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 67509648,
      "title": "Can&#39;t forward images to webp with Nginx using Laravel",
      "problem": "I'm trying to forward all jpeg and png images to webp. It's a Laravel project. Most of images in /storage folder as a symlink in public folder. I followed guides and I know a bit regex but I couldn't find any clue what's wrong.\nI have webp images in every folder.\n```\n`path/to/image.jpg\npath/to/image.jpg.webp\n`\n```\nngnix.conf file:\n```\n`sendfile on;\ntcp_nopush on;\ntcp_nodelay on;\n\nkeepalive_timeout  65;\n\nmap $http_accept $webp_suffix {\n    default \"\";\n    \"~*webp\" \".webp\";\n}\n`\n```\nServer config:\n```\n`server{\n    root /var/www/site/public;\n    server_name example.com www.example.org;\n\n    add_header X-Frame-Options \"SAMEORIGIN\";\n    add_header X-Content-Type-Options \"nosniff\";\n\n    index index.php;\n\n    charset utf-8;\n\n    location / {\n        try_files $uri $uri/ /index.php?$query_string;\n    }\n\n    location = /favicon.ico { access_log off; log_not_found off; }\n    location = /robots.txt  { access_log off; log_not_found off; }\n\n    location ~*  \\.(jpg|jpeg|png|webp|gif|ico|css|js)$ {\n        expires 365d;\n    }\n\n    location ~* ^.+\\.(png|jpe?g)$ {\n        add_header Vary Accept;\n        try_files $uri$webp_suffix $uri =404;\n    }\n\n    error_page 404 /index.php;\n\n    if ($host = example.org) {\n        return 301 https://www.example.org$request_uri;\n    } # managed by Certbot \n\n    location ~ \\.php$ {\n        include snippets/fastcgi-php.conf;\n    }\n\n    location ~ /\\.ht {\n        deny all;\n    }\n\n    location ~ /\\.(?!well-known).* {\n        deny all;\n    }\n\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n   \n    ssl_certificate /etc/letsencrypt/live/example.org/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/example.org/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n}\nserver{\n    if ($host = www.example.org) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n    if ($host = example.org) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n    listen 80;\n    server_name example.org www.example.org;\n    return 404; # managed by Certbot\n\n}\n`\n```\nI don't know what I am doing wrong. Any help will be appreciated thanks.",
      "solution": "Regular expression `location` blocks are evaluated in order until a match is found. See this document for details.\nYou have two `location` expressions which match `.png`, `.jpg` and `.jpeg`. You need to remove these from the first expression for the second expression to succeed.\nFor example:\n```\n`location ~* \\.(gif|ico|css|js)$ {\n    expires 365d;\n}\n\nlocation ~* \\.(png|jpe?g)$ {\n    expires 365d;\n    add_header Vary Accept;\n    try_files $uri$webp_suffix $uri =404;\n}\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-05-12T21:07:04",
      "url": "https://stackoverflow.com/questions/67509648/cant-forward-images-to-webp-with-nginx-using-laravel"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 70111124,
      "title": "Nginx Php-fpm 7.3 Can&#39;t read PHP files from a particular folder",
      "problem": "We have a Magento 2 website. For some reason our Nginx/PHP-FPM is unable to read files from `MAGEROOT/pub/` folder other than `index.php`.\nWe are getting the following error in Nginx Log `\"Unable to open primary script: /home/goodprice/public_html/releases/current/pub/get.php (No such file or directory)\"` and the browser shows No input file specified.\nHere is the partial Nginx config file.\n```\n`# Run Magento (behind Varnish)\nserver {\n    listen 8088;\n\n    server_name {{website name}}.com.au www.{{website name}}.com.au m2.{{website name}}.com.au;\n\n    set $MAGE_ROOT /home/goodprice/public_html/releases/current;\n\n    index index.php;\n    root $MAGE_ROOT/pub;\n    set $code default;\n\n    location /sitemap.xml {\n        root $MAGE_ROOT/pub/media;\n        autoindex off;\n    }\n\n    # Rewrites for edm\n    include /etc/nginx/global/rewrites.conf;\n\n    location / {\n        try_files $uri $uri/ /index.php?$args;\n    }\n\n    # Serve media under /pub/media/\n    location /pub/ {\n        location ~ ^/pub/media/(downloadable|customer|import|theme_customization/.*\\.xml) {\n            deny all;\n        }\n        alias $MAGE_ROOT/pub/;\n        add_header X-Frame-Options \"SAMEORIGIN\";\n    }\n\n    # Rewrite signed static files\n    rewrite ^/static/(version\\d*/)?(.*)$ /static/$2 last;\n\n    # Static assets\n    location ~ ^/static/(version\\d*/)?(.*)$ {\n        tcp_nodelay on;\n\n        # Images, CSS, JS\n        location ~* \\.(jpg|jpeg|png|gif|svg|js|css|ico|txt)$ {\n                expires max;\n                log_not_found off;\n                access_log off;\n                add_header ETag \"\";\n                add_header Access-Control-Allow-Origin \"*\";\n                add_header Cache-Control \"public\";\n                try_files $uri $uri/ @static;\n        }\n\n        # Fonts\n        location ~* \\.(swf|eot|ttf|otf|woff|woff2)$ {\n                expires max;\n                log_not_found off;\n                access_log off;\n                add_header ETag \"\";\n                add_header Access-Control-Allow-Origin \"*\";\n                add_header Cache-Control \"public\";\n                try_files $uri $uri/ @static;\n        }\n\n        # Catch all\n        try_files $uri $uri/ @static;\n    }\n\n    # Media assets\n    location /media/ {\n        tcp_nodelay on;\n        autoindex off;\n\n        # Images, CSS, JS\n        location ~* \\.(jpg|jpeg|png|gif|svg|js|css|ico|txt)$ {\n                expires max;\n                log_not_found off;\n                access_log off;\n                add_header ETag \"\";\n                add_header Access-Control-Allow-Origin \"*\";\n                add_header Cache-Control \"public\";\n                try_files $uri $uri/ @media;\n        }\n\n        # Fonts\n        location ~* \\.(swf|eot|ttf|otf|woff|woff2)$ {\n                expires max;\n                log_not_found off;\n                access_log off;\n                add_header ETag \"\";\n                add_header Access-Control-Allow-Origin \"*\";\n                add_header Cache-Control \"public\";\n                try_files $uri $uri/ @media;\n        }\n\n        # Catch all\n        try_files $uri $uri/ @media;\n    }\n\n    # Password paths\n    location /media/order_attachments {\n        auth_basic \"Restricted\";\n        auth_basic_user_file /etc/nginx/htpasswd;\n    }\n    location /media/convert {\n        auth_basic \"Restricted\";\n        auth_basic_user_file /etc/nginx/htpasswd;\n    }\n    # Below prescriptions dir does not contain actual prescriptions\n    #location /media/prescriptions {\n    #    auth_basic \"Restricted\";\n    #    auth_basic_user_file /etc/nginx/htpasswd;\n    #}\n    location /media/webforms {\n        auth_basic \"Restricted\";\n        auth_basic_user_file /etc/nginx/htpasswd;\n    }\n    location /media/raveinfosys/exporter {\n        auth_basic \"Restricted\";\n        auth_basic_user_file /etc/nginx/htpasswd;\n    }\n\n    location @static { rewrite /static/(version\\d*/)?(.*)$ /static.php?resource=$2 last; }\n    location @media { try_files $uri $uri/ /get.php$is_args$args; }\n\n    # PHP entry point for setup application\n    location ~* ^/setup($|/) {\n        root $MAGE_ROOT;\n        location ~ ^/setup/index.php {\n            fastcgi_pass fastcgi_backend;\n\n            fastcgi_param  PHP_FLAG  \"session.auto_start=off \\n suhosin.session.cryptua=off\";\n            fastcgi_param  PHP_VALUE \"memory_limit=756M \\n max_execution_time=600\";\n            fastcgi_read_timeout 300s;\n            fastcgi_connect_timeout 300s;\n\n            fastcgi_index  index.php;\n            fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;\n            include        fastcgi_params;\n        }\n\n        location ~ ^/setup/(?!pub/). {\n            deny all;\n        }\n\n        location ~ ^/setup/pub/ {\n            add_header X-Frame-Options \"SAMEORIGIN\";\n        }\n    }\n\n    # PHP entry point for update application\n    location ~* ^/update($|/) {\n        root $MAGE_ROOT;\n\n        location ~ ^/update/index.php {\n            fastcgi_split_path_info ^(/update/index.php)(/.+)$;\n            fastcgi_pass fastcgi_backend;\n            fastcgi_index  index.php;\n            fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;\n            fastcgi_param  PATH_INFO        $fastcgi_path_info;\n            include        fastcgi_params;\n        }\n\n        # Deny everything but index.php\n        location ~ ^/update/(?!pub/). {\n            deny all;\n        }\n\n        location ~ ^/update/pub/ {\n            add_header X-Frame-Options \"SAMEORIGIN\";\n        }\n    }\n\n    # Main PHP\n    location ~ (index|get|static|report|404|503|health_check|deploy_clear_opcache)\\.php$ {\n        try_files $uri =404;\n\n        fastcgi_pass fastcgi_backend;\n\n        fastcgi_param  PHP_FLAG      \"session.auto_start=off \\n suhosin.session.cryptua=off\";\n        fastcgi_read_timeout         300s;\n        fastcgi_connect_timeout      300s;\n\n        # fastcgi_param  MAGE_MODE     $MAGE_MODE;\n        fastcgi_param  MAGE_RUN_CODE $code;\n        fastcgi_param  MAGE_RUN_TYPE store;\n\n        # Increase fastcgi buffer size to stop nginx errors on large posts\n        fastcgi_buffers 32 256k;\n        fastcgi_buffer_size 512k;\n\n        fastcgi_index  index.php;\n        fastcgi_param  SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        include        fastcgi_params;\n\n        fastcgi_hide_header  'X-Powered-By';\n    }\n\n    # Return 503 if the maintenance flag is found\n#    if (-f $MAGE_ROOT/var/.maintenance.flag) {\n#        return 503;\n#    }\n#\n#    # Custom 503 error page\n#    error_page 503 @maintenance;\n#\n#    location @maintenance {\n#        root /home/goodprice/public_html/maintenance;\n#        rewrite ^(.*)$ /503.html break;\n#    }\n\n    # Use Magento 403 404 page\n    error_page 403 404 /errors/404.php;\n\n   # Banned locations (only reached if the earlier PHP entry point regexes don't match)\n    location ~* (\\.php$|\\.htaccess$|\\.git) {\n    deny all;\n    }\n}\n`\n```\nThis causes a few problems. One is Magento 2 can't serve the place holder image as it need to execute get.php. It's not a permission issue as index.php is being executed. Can anybody help fix the problem in the above mentioned Nginx config? Any help will much appreciated.\nls -la from pub dir following\n```\n`drwxr-xr-x  6 goodprice goodprice 4096 Nov 24 16:16 .\ndrwxr-xr-x 16 goodprice goodprice 4096 Nov 30 12:11 ..\n-rw-rw-r--  1 goodprice goodprice 1038 Nov 11 01:12 cron.php\n-rwxrwxr-x  1 goodprice goodprice  102 Nov 10 23:04 deploy_clear_opcache.php\ndrwxrwxr-x  3 goodprice goodprice 4096 Nov 11 01:12 errors\n-rw-rw-r--  1 goodprice goodprice 2775 Nov 24 16:16 get.php\n-rw-rw-r--  1 goodprice goodprice 3329 Nov 11 01:12 health_check.php\n-rw-rw-r--  1 goodprice goodprice 6206 Nov 11 01:12 .htaccess\n-rw-r--r--  1 goodprice goodprice 1360 Nov 12 11:49 index.php\n-rw-rw-r--  1 goodprice goodprice  169 Jan 10  2021 info.php\ndrwxrwxr-x 67 goodprice goodprice 4096 Nov 29 00:01 media\ndrwxrwxr-x  3 goodprice goodprice 4096 Nov 11 01:12 opt\ndrwxr-xr-x  4 goodprice goodprice 4096 Nov 30 13:12 static\n-rw-rw-r--  1 goodprice goodprice  445 Nov 11 01:12 static.php\n-rw-rw-r--  1 goodprice goodprice  101 Nov 11 01:12 .user.ini\n`\n```\nPhp Fpm conf.d file extract users and groups.\n```\n`group = \"goodprice\"\nlisten.group = \"nobody\"\nlisten.mode = 0660\nlisten.owner = \"goodprice\"\nuser = \"goodprice\"\n`\n```\nnginx.conf as following\n```\n`include /etc/nginx/conf.d/modules/*.conf;\n\nuser nobody;\n\nworker_processes  1;\nworker_rlimit_nofile 16384;\n\nerror_log  /var/log/nginx/error.log warn;\npid        /var/run/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log  /var/log/nginx/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/conf.d-custom/*.conf;\n}\n`\n```",
      "solution": "The issue here was php-fpm config. My mistake in asking the question was that I should have posted the whole php-fpm config with nginx config.\nOn our server the php-fpm settings are controlled from cpanel for each site. The problem was that php-fpm had `php_value[doc_root]` set to a folder above the pub folder. That was due to the fact the server and cpanel is configured to have code in `/home/goodprice/public_html/`. Which I modified to `php_value[doc_root] = \"/home/goodprice/public_html/releases/current/\"` thinking that's Magento root so php should be reading there. But actually it should have been `php_value[doc_root] = \"/home/goodprice/public_html/releases/current/pub/\"`. So on run time php is looking for a file, but the root (folder) is wrong where it's looking at. This problem was confusing because php was erroring out with the path of the file but not where it was actually trying to locate the file. I Can't explain why it would give out a correct path then look for just the file in it's root folder.\nSo to summarise, if there is `try_files` in nginx config make sure that the nginx root, or the final path is same as folder `php_value[doc_root]` in php-fpm conf. Or better don't have `php_value[doc_root]` in your php-fpm at all.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-11-25T13:26:58",
      "url": "https://stackoverflow.com/questions/70111124/nginx-php-fpm-7-3-cant-read-php-files-from-a-particular-folder"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 77343994,
      "title": "MongoDB live server at http://127.0.0.1:27017/ says &quot;It looks like you are trying to access MongoDB over HTTP on the native driver port.&quot;",
      "problem": "I have taken project from GitHub for my college project and I have no idea about this technology. The project is on creating online education platform. There where few errors like not having `.env` file in project to connect to server. I already fixed that. I downloaded MongoDB from official website and I started server on `127.0.0.1:27017` created new database named `virtual_class` and also created all the collection inside it (from his YouTube video | Link: https://www.youtube.com/watch?v=9P7LzhL5i3w | GitHub link: https://github.com/MahbubulHasanSakib/virtual_classroom_deploy). I configured my `.env` file as `MONGOURI = mongodb://127.0.0.1:27017/virtual_class`. Now when I run the program  database is connected successfully but when I open the URL in browser `i.e., 127.0.0.1:27017` it says `It looks like you are trying to access MongoDB over HTTP on the native driver port.` I have searched many threads but all they provide is the solution for only Linux platform and not for Windows.\nI tried to connect this project with nginx by configuring `nginx.conf` file as mentioned in How to setup MongoDB behind Nginx Reverse Proxy Here is how I configured\n```\n`\nevents{\n       ...\n}\nstream {\n    server {\n        listen  27017;\n        proxy_connect_timeout 1s;\n        proxy_timeout 3s;\n        proxy_pass    stream_mongo_backend;\n    }\n\n    upstream stream_mongo_backend {\n      server 127.0.0.1:27017;\n  }\n}\n\nhttp{\n     ...\n`\n```\nwhen i run localhost on port 80  it says\n```\n`Welcome to nginx!\n\nIf you see this page, the nginx web server is successfully installed and working. Further configuration is required.\n\nFor online documentation and support please refer to nginx.org.\nCommercial support is available at nginx.com.\n\nThank you for using nginx.\n`\n```\nI have also tried Cannot access mongodb through browser - It looks like you are trying to access MongoDB over HTTP on the native driver port but it seems to be the solution for Linux platform\nHope my question is understood and sorry for bad English :)",
      "solution": "You cannot connect to mongodb via HTTP. That means you cannot browse to it in your browser. The HTTP Interface and REST API was removed in version 3.6.\nIf you want to connect to your database you can use the Node native driver or use the mongosh shell.\nThere are a number of other Node packages that will allow you to connect such as mongoose but that should be enough to get you started.\nEdit:\nI just checked the repo you are using and that app is listening on `process.env.PORT` so if you have already created your `.env` file and you have a `PORT` constant defined, for example, `PORT=3000`, then you can browse to your app on `http://localhost:3000/`. That repo is already using mongoose too so the app will be able to connect.",
      "question_score": 1,
      "answer_score": 5,
      "created_at": "2023-10-23T11:14:33",
      "url": "https://stackoverflow.com/questions/77343994/mongodb-live-server-at-http-127-0-0-127017-says-it-looks-like-you-are-tryin"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 66887092,
      "title": "docker nginx not loading css styles",
      "problem": "When uploading static files to my server using Nginx as the web server my css, javascript, and google fonts are not working as they do when testing the site on localhost.\nI'm running Nginx in a docker container using the base image.\nDockerfile\n```\n`FROM nginx\nCOPY example.com.conf /etc/nginx/nginx.conf\nCOPY build /etc/nginx/html/\n`\n```\nnginx.conf\n```\n`user nginx;\n\nevents {\n  worker_connections  4096;  ## Default: 1024\n}\n\nhttp {\n  server {\n    listen 80;\n    listen [::]:80;\n\n    server_name example.com;\n\n    include /etc/nginx/mime.types;\n    root /etc/nginx/html;\n    index index.html;\n\n    location ~ \\.css {\n      add_header  Content-Type    text/css;\n    }\n    location ~ \\.js {\n      add_header  Content-Type    application/x-javascript;\n    }\n\n    location / {\n      try_files $uri /index.html =404;\n    }\n  }\n}\n`\n```\nCan someone tell me whats wrong with my conf?\nAlso when viewed on Chrome the console logs this `Resource interpreted as Stylesheet but transferred with MIME type text/plain`\nSome other SO post I looked at:\nSO post\nSO post",
      "solution": "With the help of this SO answer and the comments I was able to get it working. If my answer doesn't help you I suggest you look at that one when running Nginx in a docker container.\nFor me it was moving the `include /etc/nginx/mime.types;` and adding `sendfile on;`\noutside my `server` block and in the `http` block\nMy example.com.conf now looks like this:\n```\n`user nginx;\n\nevents {\n  worker_connections  4096;  ## Default: 1024\n}\n\nhttp {\n\n  include /etc/nginx/mime.types;\n  sendfile on;\n\n  server {\n    listen 80;\n    listen [::]:80;\n\n    server_name example.com;\n\n    root /etc/nginx/html;\n    index index.html;\n\n    location ~ \\.css {\n      add_header  Content-Type    text/css;\n    }\n    location ~ \\.js {\n      add_header  Content-Type    application/x-javascript;\n    }\n\n    location / {\n      try_files $uri /index.html =404;\n    }\n  }\n}\n`\n```",
      "question_score": 1,
      "answer_score": 4,
      "created_at": "2021-03-31T13:36:21",
      "url": "https://stackoverflow.com/questions/66887092/docker-nginx-not-loading-css-styles"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 76448346,
      "title": "NGINX Configuration showing &quot;Welcome to nginx!&quot;",
      "problem": "I am trying to install a new Nginx reverse proxy for a NodeJS application.\nI've done it several times in the past and after hours of comparing the different configurations everything seems the same on both, but one works and the other one shows me the page:\n\nWelcome to nginx!\nIf you see this page, the nginx web server is successfully installed and working. Further configuration is required.\"\n\nI am using an EC2 instance, I installed nginx with the following command:\n```\n`sudo yum update -y\nsudo yum install nginx\n`\n```\nThere are NO sites-available nor sites-enabled directories by default.\nI configured the other server directly within conf.d (for testing purposes).\n`sudo vim /etc/nginx/conf.d/testing.api.example.com`\nI wrote the following configuration:\n```\n`server {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n        server_name testing.api.example.com;\n\n        location / {\n                    proxy_pass http://127.0.0.1:8082;\n                    proxy_set_header Host $host;\n                    proxy_set_header X-Real-IP $remote_addr;\n                    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n                    proxy_set_header X-Forwarded-Proto $scheme;\n\n            }\n}\n`\n```\nI started nginx:\n```\n`sudo nginx -t\nsudo systemctl restart nginx\n`\n```\nFrom the server I run a test to see if the server is running:\n```\n`$ curl 127.0.0.1:8082\nHello Node!\n`\n```\nThe NodeJS server is running OK.\nBut when calling the port 80 for the reverse proxy, I've got the default \"Welcome to nginx!\" page.\nIt seems the nginx.conf file includes the conf.d folder:\n```\n`# For more information on configuration, see:\n#   * Official English Documentation: http://nginx.org/en/docs/\n#   * Official Russian Documentation: http://nginx.org/ru/docs/\n\nuser nginx;\nworker_processes auto;\nerror_log /var/log/nginx/error.log notice;\npid /run/nginx.pid;\n\n# Load dynamic modules. See /usr/share/doc/nginx/README.dynamic.\ninclude /usr/share/nginx/modules/*.conf;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log  /var/log/nginx/access.log  main;\n\n    sendfile            on;\n    tcp_nopush          on;\n    keepalive_timeout   65;\n    types_hash_max_size 4096;\n\n    include             /etc/nginx/mime.types;\n    default_type        application/octet-stream;\n\n    # Load modular configuration files from the /etc/nginx/conf.d directory.\n    # See http://nginx.org/en/docs/ngx_core_module.html#include\n    # for more information.\n    include /etc/nginx/conf.d/*.conf;\n\n    server {\n        listen       80;\n        listen       [::]:80;\n        server_name  _;\n        root         /usr/share/nginx/html;\n\n        # Load configuration files for the default server block.\n        include /etc/nginx/default.d/*.conf;\n\n        error_page 404 /404.html;\n        location = /404.html {\n        }\n\n        error_page 500 502 503 504 /50x.html;\n        location = /50x.html {\n        }\n    }\n\n# Settings for a TLS enabled server.\n#\n#    server {\n#        listen       443 ssl http2;\n#        listen       [::]:443 ssl http2;\n#        server_name  _;\n#        root         /usr/share/nginx/html;\n#\n#        ssl_certificate \"/etc/pki/nginx/server.crt\";\n#        ssl_certificate_key \"/etc/pki/nginx/private/server.key\";\n#        ssl_session_cache shared:SSL:1m;\n#        ssl_session_timeout  10m;\n#        ssl_ciphers PROFILE=SYSTEM;\n#        ssl_prefer_server_ciphers on;\n#\n#        # Load configuration files for the default server block.\n#        include /etc/nginx/default.d/*.conf;\n#\n#        error_page 404 /404.html;\n#        location = /404.html {\n#        }\n#\n#        error_page 500 502 503 504 /50x.html;\n#        location = /50x.html {\n#        }\n#    }\n\n}\n`\n```\nI've tried several changes, but none are working...\nIs there any other configuration missing?\nMaybe the name_server is not correct?\nI've tried:\n```\n`server_name testing.api.example.com;\nserver_name 3.89.65.77;\n#server_name 3.89.65.77; (commented)\nserver_name wach.quest;\n`\n```",
      "solution": "It seems the nginx.conf file includes the conf.d folder:\n\nIf you look at the actual line in `nginx.conf` that includes the `conf.d` folder, you will see it only includes files in that folder that end in the `.conf` extension:\n```\n`include /etc/nginx/conf.d/*.conf;\n`\n```\nYour config file `/etc/nginx/conf.d/testing.api.example.com` does not have a `.conf` extension. You whould rename it to something like `/etc/nginx/conf.d/testing.api.example.com.conf`",
      "question_score": 1,
      "answer_score": 4,
      "created_at": "2023-06-11T00:14:19",
      "url": "https://stackoverflow.com/questions/76448346/nginx-configuration-showing-welcome-to-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 66943907,
      "title": "How to deploy backend and frontend on the same server but different path with Nginx",
      "problem": "I need to deploy the frontend in https://service.domain.it and the backend in https://service.domain.it/api.\nI've done a deploy configuration but I'm having troube with spring security + JWT Authentication. This is the configure method of WebSecurityConfigurerAdapter\n```\n`@Override\npublic void configure(HttpSecurity http) throws Exception {\n    http.csrf().disable()\n            .authorizeRequests()\n            .antMatchers(\"/public/**\").permitAll() //login/logout/recoverypassw\n            .antMatchers(\"/user/**\").hasAnyRole(\"USER\",\"ADMIN\")\n            .antMatchers(\"/admin/**\").hasRole(\"ADMIN\")\n            .anyRequest().authenticated()\n            .and().exceptionHandling().authenticationEntryPoint(jwtAuthenticationEntryPoint).\n            and().sessionManagement().sessionCreationPolicy(SessionCreationPolicy.STATELESS).\n            and().addFilterBefore(jwtAuthenticationFilter, UsernamePasswordAuthenticationFilter.class);\n}\n`\n```\nAnd this is the nginx configuration\n```\n`#service.domain.it\nserver{\n        listen 443 ssl;\n        server_name service.domain.it;\n        ssl_certificate /etc/letsencrypt/live/service.domain.it/fullchain.pem;\n        ssl_certificate_key /etc/letsencrypt/live/service.domain.it/privkey.pem;\n        location /api/ {\n                #backend\n                proxy_pass http://localhost:8085;\n        }\n\n       location / {\n               #frontend\n               index index.html;\n                alias /var/www/html/Service/;\n       }\n}\nserver{\n        listen 80;\n        server_name service.domain.it;\n        return 301 https://service.domain.it$request_uri;\n}\n`\n```\nWhat should I do?",
      "solution": "Your backend service does not understand the `/api` used in your proxy_configuration. You must rewrite the URI before sending it to the backend.\n```\n`location /api {\n\n   rewrite ^/api/(.*) /$1 break;\n   proxy_pass http://backend/;\n\n}\n`\n```\nThis will remove the `/api` from the URI before sending it to the backend.",
      "question_score": 1,
      "answer_score": 3,
      "created_at": "2021-04-04T19:17:38",
      "url": "https://stackoverflow.com/questions/66943907/how-to-deploy-backend-and-frontend-on-the-same-server-but-different-path-with-ng"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 66264713,
      "title": "How to install nginx without the modules in RedHat",
      "problem": "I install nginx using Yum following these steps:\n\n`yum install epel-release`\n`yum install nginx`\n\nThe following is the output of `nginx -V`:\n```\n`built by gcc 4.8.5 20150623 (Red Hat 4.8.5-44) (GCC)\nbuilt with OpenSSL 1.1.1c FIPS  28 May 2019 (running with OpenSSL 1.1.1g FIPS  21 Apr 2020)\nTLS SNI support enabled\nconfigure arguments: --prefix=/usr/share/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --http-client-body-temp-path=/var/lib/nginx/tmp/client_body --http-proxy-temp-path=/var/lib/nginx/tmp/proxy --http-fastcgi-temp-path=/var/lib/nginx/tmp/fastcgi --http-uwsgi-temp-path=/var/lib/nginx/tmp/uwsgi --http-scgi-temp-path=/var/lib/nginx/tmp/scgi --pid-path=/run/nginx.pid --lock-path=/run/lock/subsys/nginx --user=nginx --group=nginx --with-file-aio --with-ipv6 --with-http_ssl_module --with-http_v2_module --with-http_realip_module --with-stream_ssl_preread_module --with-http_addition_module --with-http_xslt_module=dynamic --with-http_image_filter_module=dynamic --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_degradation_module --with-http_slice_module --with-http_stub_status_module --with-http_perl_module=dynamic --with-http_auth_request_module --with-mail=dynamic --with-mail_ssl_module --with-pcre --with-pcre-jit --with-stream=dynamic --with-stream_ssl_module --with-google_perftools_module --with-debug --with-cc-opt='-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic' --with-ld-opt='-Wl,-z,relro -specs=/usr/lib/rpm/redhat/redhat-hardened-ld -Wl,-E'\n`\n```\nHow can I install nginx without the `--with*`",
      "solution": "In order to do that you must install nginx from source.\nFirst download the tar.gz file from http://nginx.org/en/download.html then run the following command for compiling and installing:\n\n`./configure --prefix=/etc/nginx  --sbin-path=/usr/sbin/nginx  --modules-path=/usr/lib64/nginx/modules --conf-path=/etc/nginx/nginx.conf  --error-log-path=/var/log/nginx/error.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --user=nginx --group=nginx --build=CentOS --builddir=nginx-1.18.0 --with-http_gunzip_module --with-http_gzip_static_module`\nmake sure to edit the version in builddir as your current version\nrun for compiling: `make`\nfor installing run `make install`",
      "question_score": 1,
      "answer_score": 3,
      "created_at": "2021-02-18T18:07:25",
      "url": "https://stackoverflow.com/questions/66264713/how-to-install-nginx-without-the-modules-in-redhat"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 74521117,
      "title": "NGINX proxy_pass to defined upstream instead of https url directly",
      "problem": "I have an nginx config that looks similar to this (simplified):\n```\n`http {\n    server {\n        listen 80 default_server;\n\n        location /api {\n            proxy_pass https://my-bff.azurewebsites.net;\n            proxy_ssl_server_name on;\n        }\n    }\n}\n\n`\n```\nEssentially, I have a reverse proxy to an API endpoint that uses https.\nNow, I would like to convert this to an upstream group to gain access to keepalive and other features. So I tried this:\n```\n`http {\n    upstream bff-app {\n        server my-bff.azurewebsites.net:443;\n    }\n\n    server {\n        listen 80 default_server;\n\n        location /api {\n            proxy_pass https:/bff-app;\n            proxy_ssl_server_name on;\n        }\n    }\n}\n\n`\n```\nYet it doesn't work. Clearly I'm missing something.\nIn summary, how do I correctly do this \"conversion\" i.e. from url to defined upstream?\nI have tried switching between http instead of https in the proxy_pass directive, but that didn't work either.\nI was honestly expecting this to be a simple replacement. One upstream for another, but I'm doing something wrong it seems.",
      "solution": "Richard Smith pointed me in the right direction.\nEssentially, the issue was that the host header was being set to \"bff-app\" instead of \"my-bff.azurewebsites.net\" and this caused the remote server to close the connection.\nFixed by specifying header manually like below:\n```\n`http {\n    upstream bff-app {\n        server my-bff.azurewebsites.net:443;\n    }\n\n    server {\n        listen 80 default_server;\n\n        location /api {\n            proxy_pass https:/bff-app;\n            proxy_ssl_server_name on;\n            # Manually set Host header to \"my-bff.azurewebsites.net\",\n            # otherwise it will default to \"bff-app\".\n            proxy_set_header Host my-bff.azurewebsites.net; \n        }\n    }\n}\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-11-21T16:18:31",
      "url": "https://stackoverflow.com/questions/74521117/nginx-proxy-pass-to-defined-upstream-instead-of-https-url-directly"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 74183222,
      "title": "Godaddy SSL Certificates Install in NGINX Server | Failing",
      "problem": "I have requested SSL Certificate from `GoDaddy`, I got `Private Key` & `CSR` file, which downloaded as `TEXT` format.\n\nI have modified file extensions as follows\n```\n`**Original File Names**\nfirstcsrfile.txt\nfirstprivatekey.txt\n\n**After Renaming File Names**\nfirstcsrfile.csr\nfirstprivatekey.key\n`\n```\ndomain.com.chained with below files downloaded from `GoDaddy` by selecting `other` option\n\nFrom above files\n\n1fbfa674f5fe68aa.crt to domain.com.crt\ngd_bundle-g2-g1.crt to intermediate.crt\n\n```\n`cat domain.com.crt intermediate.crt > domain.com.chained.crt\n`\n```\nMy nginx.conf file\n```\n`worker_processes 4;\n\nevents { worker_connections 1024; }\n\nhttp {\n    server {\n        listen 443 ssl;\n        server_name _;\n\n        ssl_certificate     /etc/nginx/ssl/domain.com.chained.crt;\n        ssl_certificate_key /etc/nginx/ssl/firstprivatekey.key;\n\n        ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n        add_header Strict-Transport-Security max-age=15768000;\n\n        include /etc/nginx/mime.types;\n\n        location / {\n            root  /usr/share/nginx/html;\n        }\n    }\n}\n`\n```\nI have tried multiple times with various approaches but always same error\n```\n`2022/10/24 13:51:20 [emerg] 1#1: SSL_CTX_use_PrivateKey(\"/etc/nginx/ssl/firstprivatekey.key\") failed (SSL: error:0B080074:x509 certificate routines:X509_check_private_key:key values mismatch)\nnginx: [emerg] SSL_CTX_use_PrivateKey(\"/etc/nginx/ssl/firstprivatekey.key\") failed (SSL: error:0B080074:x509 certificate routines:X509_check_private_key:key values mismatch)\n\n`\n```\nI have followed few blogs from Godaddy and some random blogs\nhttps://blog.yudiz.com/install-ssl-certificate-with-nginx/\nSince last 6-7 days struggled a lot, and where I am doing mistakes not sure !!.",
      "solution": "First You should chose other and download,\nafter that In the downloaded file you will combine the .crt and bundle.crt file.\nYou will save it as a .pem in the /etc/nginx/ssl file path. I tried to do that as well.",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-10-24T17:08:28",
      "url": "https://stackoverflow.com/questions/74183222/godaddy-ssl-certificates-install-in-nginx-server-failing"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 72297978,
      "title": "How can I conditionally display an error page in nginx?",
      "problem": "How can I configure nginx to return an error_page if the URI does not contain `ajax` but if it does contain `ajax` don't send an error page and just return the response? Something like the following but I can't figure out how to access $status. I want to do this for all statuses that are 4xx or 5xx\nEssentially, I want to be able to receive a JSON response when there is an AJAX request error and an error page when the request failed to render HTML\n```\n`# If the location contains ajax\nlocation ~ ajax {\n    # Return the error status code\n    return $status;\n}\n# Location did not contain ajax so send an error page\nerror_page $status error.html;\n`\n```\nThank you!",
      "solution": "It turns out I was thinking about nginx directives wrong. I was thinking about it like a programming language as if the error_page for the non-ajax responses would be evaluated before the URIs containing ajax. Instead, the error_page directive defined in the location block for URIs that match the regex is what will be used. This ended up working perfect.\n```\n`# All pages error page\nerror_page 404 400 401 402 403 405 406 407 408 409 410 411 412 413 414 415 416 417 500 501 502 503 504 505 error.html;\n\nlocation ~ ajax {\n    # Error page for URI containing ajax\n    error_page 500 501 502 503 504 505 error.html;\n}\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-05-19T04:27:51",
      "url": "https://stackoverflow.com/questions/72297978/how-can-i-conditionally-display-an-error-page-in-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 71486612,
      "title": "How can i set automaticly registered services on nginx config using consul template",
      "problem": "I'm using consul, consul-template and nginx on docker. When adding each new service, i have to change consul-template source file again.\nBy the way all we're using soap services and proxy. All of them have service uri.\nHow can i write nginx.ctmpl ?\nexample web service end point :\n```\n` 1.1.1.1:123/Service1.asmx\n`\n```\nin consul-config, added like this:\n```\n`\"services\": [\n  {\n    \"id\": \"Svc0\",\n    \"name\": \"Service\",\n    \"port\": 3307,\n    \"address\": \"1.1.1.1\",\n    \"checks\": [\n      {\n      \"http\": \"http://1.1.1.1:123/service1.asmx\",\n      \"method\": \"GET\",\n      \"interval\": \"10s\",\n      \"timeout\": \"1s\"\n      }]\n  }\n  ]\n`\n```\nIn nginx.ctmpl. I want to change this part for dynamic but i could'nt find any solution because of server part.\n```\n`upstream backend {\n\n{{ range service \"Service\" }}\n  server {{ .Address }}:{{ .Port }};{{ end }}\n}\nserver {\n        listen                443 ssl;\n        server_name           domainname.com.tr;\n        proxy_set_header      X-Forwarded-Port 443;\n        ssl_certificate       /etc/nginx/tls/..crt;\n        ssl_certificate_key   /etc/nginx/tls/..key;\n        \n   location / {\n            proxy_set_header X-Forwarded-Host $host;\n            proxy_set_header X-Forwarded-Server $host;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header Host $http_host;\n            proxy_pass https://domainanother;\n        }\n        \n   location  ^~ /Service1.asmx {\n \n            proxy_pass http://backend;\n            proxy_redirect off;\n        }\n        access_log /etc/nginx/log/gw/https/access.log;\n        error_log /etc/nginx/log/gw/https/error.log;\n}\n`\n```",
      "solution": "This should do what you want.\nGiven the following service config:\n```\n`# services.hcl\nservices {\n  id = \"svc1\"\n  name = \"service1\"\n  address = \"1.1.1.1\"\n  port = 8080\n}\n\nservices {\n  id = \"svc2\"\n  name = \"service2\"\n  address = \"1.1.1.1\"\n  port = 8081\n  check = {\n    http = \"http://1.1.1.1/Service1.asmx\"\n    method = \"GET\"\n    interval = \"10s\"\n    timeout = \"1s\"\n  }\n}\n`\n```\nand the following template:\n`{{- /*\n\n  Upstream template\n\n  This template is used to the upstream configuration for the service.\n  It takes an array of service health objects as input and returns the template\n  as a string.\n\n*/ -}}\n{{- define \"upstream-template\" -}}\n### Upstream configuration for {{ . }}\nupstream {{ . }} {\n  zone upstream_{{ . }} 128k;\n  {{ range service . \"any\" }}\n  # Instance: {{ printf \"%s-%s\" .ID .Name }}\n\n  {{- /* Mark the backend as down if the health status is critical */ -}}\n  {{- $is_down := sprig_ternary \" down\" \"\" (eq .Status \"critical\") }}\n  server {{ printf \"%s:%d%s\" .Address .Port $is_down -}};\n  {{ end }}\n}\n{{ end -}}\n\n{{- /* Obtain list of services from the catalog */ -}}\n{{- $servicesList := services -}}\n\n{{- /* Generate upstream configurations for each logical service */ -}}\n{{- range $servicesList -}}\n  {{- if and (ne .Name \"consul\") (.Name | contains \"sidecar\" | not) -}}\n    {{- executeTemplate \"upstream-template\" .Name -}}\n  {{- end -}}\n{{- end -}}\n\nserver {\n  listen                443 ssl;\n  server_name           domainname.com.tr;\n  proxy_set_header      X-Forwarded-Port 443;\n  ssl_certificate       /etc/nginx/tls/..crt;\n  ssl_certificate_key   /etc/nginx/tls/..key;\n\n  access_log /etc/nginx/log/gw/https/access.log;\n  error_log /etc/nginx/log/gw/https/error.log;\n\n  location / {\n    proxy_set_header X-Forwarded-Host $host;\n    proxy_set_header X-Forwarded-Server $host;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header Host $http_host;\n    proxy_pass https://domainanother;\n  }\n\n  {{- /*\n    Generate the location blocks for each logical service.\n    Ignore the 'consul' service itself, and any sidecar services.\n  */ -}}\n  {{ range $servicesList -}}\n  {{- if and (ne .Name \"consul\") (.Name | contains \"sidecar\" | not) }}\n  location ^~ /{{ .Name | sprig_title }}.asmx {\n    proxy_pass http://{{ .Name }};\n    proxy_redirect off;\n  }\n  {{ end -}}\n  {{- end }}\n}\n`\nConsul template will produce the following nginx configuration.\n```\n`### Upstream configuration for service1\nupstream service1 {\n  zone upstream_service1 128k;\n  \n  # Instance: svc1-service1\n  server 1.1.1.1:8080;\n  \n}\n### Upstream configuration for service2\nupstream service2 {\n  zone upstream_service2 128k;\n  \n  # Instance: svc2-service2\n  server 1.1.1.1:8081;\n  \n}\nserver {\n  listen                443 ssl;\n  server_name           domainname.com.tr;\n  proxy_set_header      X-Forwarded-Port 443;\n  ssl_certificate       /etc/nginx/tls/..crt;\n  ssl_certificate_key   /etc/nginx/tls/..key;\n\n  access_log /etc/nginx/log/gw/https/access.log;\n  error_log /etc/nginx/log/gw/https/error.log;\n\n  location / {\n    proxy_set_header X-Forwarded-Host $host;\n    proxy_set_header X-Forwarded-Server $host;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header Host $http_host;\n    proxy_pass https://domainanother;\n  }\n  location ^~ /Service1.asmx {\n    proxy_pass http://service1;\n    proxy_redirect off;\n  }\n  \n  location ^~ /Service2.asmx {\n    proxy_pass http://service2;\n    proxy_redirect off;\n  }\n  \n}\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-03-15T18:34:51",
      "url": "https://stackoverflow.com/questions/71486612/how-can-i-set-automaticly-registered-services-on-nginx-config-using-consul-templ"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 70618582,
      "title": "unable to edit nginx.conf file from K8 cluster",
      "problem": "I want to edit my `Nginx.conf` file present inside Nginx controller pod in AKS, but the edit command is not working using the exec command, is there any way else I could edit my `nginx.conf`.\nthe command which I tried:\n```\n`kubectl exec -it nginx-nginx-ingress-controller -n nginx --  cat /etc/nginx/nginx.conf\n`\n```",
      "solution": "As mentioned by CrowDev, it's not good practice to update the config of Nginx controller like that.\nNginx controller is the backend of the ingress you can use the config map to update the configuration of the Nginx controller and redeploy the pod of the controller.\nSome of the Nginx controller config could be also overwritten using the ingress config and annotation inside it.\nYou can read more about annotation here : https://docs.nginx.com/nginx-ingress-controller/configuration/ingress-resources/advanced-configuration-with-annotations/\nUpdate :\nYou can separate out different ingress by their name. if you want to manage different configs or headers you need to separate out ingress for managing different configs.\nExample :\ningress : 1\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-one\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"3600\"\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /one\n        pathType: Prefix\n        backend:\n          service:\n            name: one\n            port:\n              number: 80\n`\n```\ningress : 2\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-two\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /two\n        pathType: Prefix\n        backend:\n          service:\n            name: two\n            port:\n              number: 80\n`\n```\nnow `nginx.ingress.kubernetes.io/proxy-read-timeout: \"3600\"` will get apply to only one ingress or service.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2022-01-07T09:37:17",
      "url": "https://stackoverflow.com/questions/70618582/unable-to-edit-nginx-conf-file-from-k8-cluster"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 69836892,
      "title": "Nginx block all traffic with specific custom header except to some urls",
      "problem": "I have a service that is hosted in an internal network that is receiving traffic in port 443 (via https) behind a custom loadbalancer both from the internet but also from the internal network.\nInternal network requests are coming with an extra custom header, let's call it `X-my-lb-header`.\nI want to block all external incoming traffic to all uris (return an http response code), except to some specific ones.\nEg, let's say that i want to allow traffic that is coming to two endpoints `/endpoind1/` (prefix match) and `/endpoint2` actual match.\nWhat is the best way to achieve a behaviour like this?\nIf my understanding is correct I need something like (not correct syntax bellow)\n```\n`   location = /endpoind2 {\n        if ($http_x_my_lb_header not exists) {\n            pass\n        } else {\n            return 404\n        }\n        ... the rest of the directives\n    }\n\n   location ~ / {\n        if ($http_x_my_lb_header) {\n            return 404;\n        }\n        ... the rest of the directives\n    }\n`\n```\nBut since else is not supported in nginx, i cannot figure out to do it.\nAny ideas?",
      "solution": "So you need some logic like\n`if (header exists) {\n    if (request URI isn't whitelisted) {\n        block the request\n    }\n}\n`\nor in another words\n`if ((header exists) AND (request URI isn't whitelisted)) {\n    block the request\n}\n`\nWell, nginx don't allow nested `if` blocks (nor logical conditions). While some people inventing a really weird but creative solutions like this one (emulating AND) or even this one (emulating OR), a huge part of such a problems can be solved using `map` blocks (an extremely powerfull nginx feature).\nHere is an example:\n`# get the $block variable using 'X-my-lb-header' value\nmap $http_x_my_lb_header $block {\n    # if 'X-my-lb-header doesn't exists, get the value from another map block\n    ''    $endpoint;\n    # default value (if the 'X-my-lb-header' exists) will be an empty string\n    # (unless not explicitly defined using 'default' keyword)\n}\n\n# get the $endpoint variable using request URI\nmap $uri $endpoint {\n    # endpoint1 prefix matching (using regex)\n    ~^/endpoint1    ''; don't block\n    # endpoint2 exact matching\n    /endpoint2      ''; don't block\n    default         1; # block everything other\n}\n`\nNow you can use this check in your server block (don't put it to some location, use at the `server` context):\n```\n`if ($block) { return 404; }\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2021-11-04T10:20:21",
      "url": "https://stackoverflow.com/questions/69836892/nginx-block-all-traffic-with-specific-custom-header-except-to-some-urls"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 69171002,
      "title": "Nginx serving angular static files",
      "problem": "I am configuring to change the deployment of the angular project deployed in nginx. The default files are hosting at /usr/share/nginx/html which works when i access from localhost. However, i will like to define the /dev or /prod at the URL which will looks like: localhost/dev or localhost/prod but when i change the nginx configuration it does not work cause it keep looks for file at /usr/share/nginx/html/dev\nHow could i rewrite the URL to point to /usr/share/nginx/html where the static files are located?\ncurrent nginx location config:\n```\n`server {\n    listen       80;\n    listen  [::]:80;\n    server_name  localhost;\n\n    #charset koi8-r;\n    #access_log  /var/log/nginx/host.access.log  main;\n\n    location /dev/ {\n        root   /usr/share/nginx/html;\n        #index  index.html index.htm;\n    }\n}\n`\n```\nerror:\n```\n`2021/09/14 01:43:34 [error] 75#75: *7 \"/usr/share/nginx/html/dev/index.html\" is not found (2: No such file or directory), client: 172.18.0.1, server: localhost, request: \"GET /dev/ HTTP/1.1\", host: \"localhost:4201\"\n`\n```\ni have tried changing the config but I face a forbidden issue\nconfig:\n```\n`    location /dev/ {\n        #root   /usr/share/nginx/html;\n        #index  index.html index.htm;\n        alias /usr/share/nginx/html;\n        try_files $uri $uri/ /index.html;\n    }\n`\n```\nerror:\n```\n` 2021/09/14 02:11:45 [error] 92#92: *10 directory index of \"/usr/share/nginx/html\" is forbidden, client: 172.18.0.1, server: localhost, request: \"GET /dev/ HTTP/1.1\", host: \"localhost:4201\"\n`\n```",
      "solution": "I found some resources online that have helped me to troubleshoot and manage to get it up.\n\nif you are facing nginx HTML is forbidden --> https://programmer.group/directory-index-of-usr-share-nginx-html-is-forbidden.html\n\nfor alias we need to add the / at the back\n\n```\n`location /prod/ {\n    alias  /usr/share/nginx/html/dev/;\n    try_files $uri $uri/ /index.html;\n}\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2021-09-14T04:09:40",
      "url": "https://stackoverflow.com/questions/69171002/nginx-serving-angular-static-files"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 68000175,
      "title": "Nginx - Custom configuration files location",
      "problem": "I use Nginx with many domains. Some of these domains have custom configurations. I'm including these files inside the server blocks in the Nginx configurations.\nFor example:\n```\n`server {\n    ... some configurations things here...\n    include /var/somewhere/custom.conf;\n    etc.. etc.. \n}\n`\n```\nThe configuration files of Nginx are inside: /etc/nginx\nTo try and keep everything in one place and not have my custom configuration files all over the place I would like to place my custom configuration files inside /etc/nginx/some_directory\nCan I create a sub directory inside /etc/nginx without it causing any issues with Nginx itself? I want to create /etc/nginx/some_directory/ and place my many custom configuration files inside it and include them.\nI'm specifically asking this question because I don't want to break something on my production server.",
      "solution": "If nginx doesn't know about a directory, it'll not touch it. You can verify that by `grep`ing against such pattern in nginx's codebase.\nHowever, messing with a foreign folder structure might cause problems with permissions and ownership of the files, therefore either just use a pre-defined folders nginx prepared for you (`/etc/nginx/sites-enabled` and `/etc/nginx/sites-available`) which you can use with symlinks such as nginx itself does\n```\n`# ls /etc/nginx/sites-enabled\ndefault -> /etc/nginx/sites-available/default\n\n# ls /etc/nginx/sites-available\ndefault\n`\n```\notherwise you're getting into a situation what C/C++ programmers call an undefined behavior and there's no guarantee that what works now will work in the future / nginx doesn't change as well as the distro maintainers might mess with the folder structure and permissions for the packages in distro package manager.\nExample:\nNginx might verify the full `/etc/nginx` tree's permissions and owners - if your folders/files don't match it might cause a warning or crash even. If it's installed by a package manager, it might cause issues when removing the package itself e.g. if the package manager attempts to remove only a known list of folders + afterwards the parent i.e. `/etc/nginx` by `rmdir` or similar. Situations you don't really want to get into and debug when you can use allowed folders or symlinks or your own folders that are not bound to an application or behavior except the one you define.",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2021-06-16T11:42:39",
      "url": "https://stackoverflow.com/questions/68000175/nginx-custom-configuration-files-location"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 67438025,
      "title": "nginx two different error_pages for same error code",
      "problem": "I want to configure a maintenance page for Nginx.\nI wanted to differentiate the 503 maintenance page with other 503 pages.\n```\n`server {\n    ...\n    location / {\n        if (-f /www/maintenance_on.html) {\n            return 503;\n        }\n        ...\n    }\n\n    # Error pages.\n    error_page 503 /maintenance_on.html;\n    location = /maintenance_on.html {\n        root /www/;\n    }\n\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n        root   html;\n    }\n    ...\n}\n`\n```\nI want to serve maintenance_on.html only when it is present. For all the 503s where maintenance_on.html is not there, I want to serve 50x.html.",
      "solution": "Use a separate `error_page` directive for handling 503. You can point it at a named `location` block with a `try_files` directive.\nFor example:\n```\n`error_page 503 @error503;\nerror_page 500 502 504 /50x.html;\nlocation = /50x.html {\n    root   html;\n}\nlocation @error503 {\n    root   html;\n    try_files /maintenance_on.html /50x.html =404;\n}\n`\n```\nThe `@error503` block will first check for the existence of the file `maintenance_on.html` and if it does not exist, the file `50x.html` instead. The `=404` term is not reached.",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2021-05-07T17:46:31",
      "url": "https://stackoverflow.com/questions/67438025/nginx-two-different-error-pages-for-same-error-code"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 67148337,
      "title": "case sensitive/in-sensitive match not working in nginx",
      "problem": "in my `server` directive, the location configuration are as below\n```\n`    location ~ \\.(html)$ {\n        expires max;\n        return 200 \"case sensitive match\";\n    }\n\n    location ~* \\.(html)$ {\n            expires 10d;\n            return 200 \"case insensitive match\";\n    }\n`\n```\nMy expectation is that when I load `localhost/somthing.html` it should print `case sensitive match` and when I load `localhost/something.hTML` it should print `case insensitive match`\nHowever, in both the cases, `case sensitive match` gets printed\nThe request log in `access.log` is\n```\n`127.0.0.1 - - [18/Apr/2021:17:56:15 +0530] \"GET /something.hTML HTTP/1.1\" 200 20 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15\"\n`\n```\nAttached picture, see the statement printed and also the `expires` which is set to `MAX` proving that `case sensitive match` worked. What could be going wrong here?",
      "solution": "`location ~` matches are still case-insensitive under operating systems with case-insensitive filesystems (such as Mac OS & Windows).\nTo force a case-insensitive pattern you need to include it in the regex itself with `(?-i)` e.g.\n```\n`location ~ \"(?-i)\\.(html)$\" {\n    ...\n}\n`\n```\nSee this (very old) issue.",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2021-04-18T14:08:00",
      "url": "https://stackoverflow.com/questions/67148337/case-sensitive-in-sensitive-match-not-working-in-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 78870768,
      "title": "Nginx location specific timeout",
      "problem": "I am trying to rewrite `proxy_read_timeout` for a specific route that sends requests to Replicate that has longer response times.\nIf the AI model is cold, it takes more than 1 minute to respond and Nginx throws `504 timeout error`.\nBelow is my current nginx config. It throws `Cannot POST /` error for all requests to `/api/ai/`. All requests to `/api/` are working fine.\nWhat am I doing wrong?\n```\n`        location /api/ {\n            proxy_pass http://localhost:3000/;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_redirect /api/ /;\n\n        }\n          # Replicate\n        location /api/ai {\n            proxy_pass http://localhost:3000/;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n            proxy_connect_timeout 120s;\n            proxy_read_timeout 120s;\n            proxy_send_timeout 120s;\n        }\n`\n```",
      "solution": "In the first location block, requests to a URL like `/api/foo/` are sent upstream to `http://localhost:3000/foo/` effectively removing the `/api` prefix.\nAssuming that you wish the same transformation in the second location block, you need to make similar changes to both the `location` and `proxy_pass` statements.\nFor example:\n```\n`location /api/ai {\n    proxy_pass http://localhost:3000/ai;\n    ...\n}\n`\n```\nSo requests to the URL `/api/ai/` are sent upstream to `http://localhost:3000/ai/`",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2024-08-14T13:55:08",
      "url": "https://stackoverflow.com/questions/78870768/nginx-location-specific-timeout"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 78446184,
      "title": "respond with a custom file from query string or default if file doesn&#39;t exist",
      "problem": "I have an nginx server running a react single page application, simple stuff:\n```\n`server{\n    server_name testing001.example.com;\n\n    location / {\n      root /var/www/testing001;\n      try_files $uri /index.html;\n    }\n}\n`\n```\nInside my `/var/www/testing001` directory, besides of the app files, i have a directory:\n```\n`\\runtimes\n\\runtimes\\1.js\n\\runtimes\\2.js\n\\runtimes\\3.js\n...\n\\runtimes\\default.js\n`\n```\nI want all the requests to `https://testing.example.com/theRuntime.js?id={1,2,3,4}` to:\n\nserve me the respective file, depending on the id query string\n\nthis is working fine, using:\n\n```\n`location ~* ^/theRuntime\\.js {\n        if ($arg_id != \"\") {\n            set $id $arg_id;\n            rewrite ^ /runtimes/$id.js last;\n        }\n    }\n`\n```\n\nif the /runtimes/$id.js file doesn't exist, i want to serve /runtimes/default.js, or even just a common string directly from nginx i don't care\n\nThis is the part i can't figure out, i tried many combinations and it either stops serving me any file (404) or, in some cases, it defaults to the root `index.html`",
      "solution": "```\n`server{\n    server_name testing001.example.com;\n    root /var/www/testing001;\n\n    location / {\n        try_files $uri /index.html;\n    }\n    location = /theRuntime.js {\n        try_files /runtimes/$arg_id.js /runtimes/default.js =404;\n    }\n}\n`\n```\nMove the `root` into the `server` block so that it serves both `location` blocks.\nYou need to match a single URL, so the \"exact match\" `location` syntax is used.\nThe `id` argument is available as `$arg_id`.\n`try_files` will test for the existence of multiple pathnames under `/var/www/testing001` in order.\nThe final `=404` is never reached. See `try_files`",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2024-05-08T07:02:31",
      "url": "https://stackoverflow.com/questions/78446184/respond-with-a-custom-file-from-query-string-or-default-if-file-doesnt-exist"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 77717858,
      "title": "How to host 2 nodejs servers running on different ports(3000 and 5000) using nginx in one virtual machine(azure)",
      "problem": "Is it possible to access the 2 nodejs servers like, `public_ip:3000` and `public_ip:5000`?\nI have an `index.js` and `app.js` file in `/var/www/html` folder. `index.js` runs on port `3000` and `app.js` runs on port `5000`. I am able to access only the server running on port 3000. If I try to access the other server by `public_ip:5000` I am getting a 502 Error.\nThis is `/etc/nginx/site-available/default` file config.\n```\n`server {\n\n    listen 80 default_server;\n    listen [::]:80 default_server;\n    \n    root /var/www/html;\n\n    index index.html index.htm index.nginx-debian.html;\n\n    server_name _;\n\n    location / {\n         proxy_pass http://localhost:3000;\n         proxy_set_header Host $host;\n         proxy_set_header X-Real-IP $remote_addr;\n         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n         proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n\nserver {\n\n    listen 80;\n    listen [::]:80;\n    \n    root /var/www/html;\n\n    index index.html index.htm index.nginx-debian.html;\n\n    server_name _;\n\n    location / {\n         proxy_pass http://localhost:5000;\n         proxy_set_header Host $host;\n         proxy_set_header X-Real-IP $remote_addr;\n         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n         proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n`\n```",
      "solution": "There might be a mistake wait let me correct and put the updated code try it once and let me know.\n\r\n\r\n`server {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n\n    root /var/www/html;\n    index index.html index.htm index.nginx-debian.html;\n\n    server_name _;\n\n    location /app1/ {\n        proxy_pass http://localhost:3000/;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    location /app2/ {\n        proxy_pass http://localhost:5000/;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}`\r\n\r\n\r\n\nI added path prefixes (/app1/ and /app2/) to the location blocks. http://public_ip/app1/ for the Node.js server running on port 3000 and http://public_ip/app2/ for the one on port 5000.\nAlso added a trailing slash to the proxy_pass URLs.\n\r\n\r\n`sudo service nginx restart`\r\n\r\n\r\n\ndon't forget to restart NGINX for the changes to take effect.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-12-26T16:03:30",
      "url": "https://stackoverflow.com/questions/77717858/how-to-host-2-nodejs-servers-running-on-different-ports3000-and-5000-using-ngi"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 76448293,
      "title": "react-router-dom &amp; nginx -&gt; path /equipe/:id return index.html",
      "problem": "I use `react-router-dom` in my react application like this:\n```\n`import {BrowserRouter, Route, Routes} from \"react-router-dom\";\n// other code...\nReactDOM.createRoot(document.getElementById(\"root\") as HTMLElement).render(\n    \n        \n            }/>\n            }/>\n            {/*other route...*/}\n        \n    \n);\n`\n```\nI specify that by launching my application in development mode with `react-scripts start` I have no worries.\nI build my project by running `react-scripts build`, which works.\nI'm using the following `nginx` configuration:\n```\n`server {\n   server_name server_name_url;\n   location / {\n            root /path/to/folder/build;\n            try_files $uri $uri/ /index.html;\n   }\n   listen 443 ssl; # managed by Certbot\n   # other elements managed by Certbot\n}\n`\n```\nWhen I access `server_name_url/equipe` it works fine.\nWhen I access `server_name_url/equipe/:id` (server_name_url/equipe/12345 for example) it returns me the index.html file instead of the `main.396fb688.js` file.\nI understand why (related to try_files which can't find $uri and $uri/).\n\nHow can I modify the nginx configuration in order to access my `/equipe/:id` route please ?",
      "solution": "I might have found a solution for your issue here. I had the same problem, it was because the environment variable `PUBLIC_URL` was not defined to `/`.\nSo I had to add to my .env file:\n```\n`PUBLIC_URL=/\n`\n```\nTry that one",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-06-10T23:52:30",
      "url": "https://stackoverflow.com/questions/76448293/react-router-dom-nginx-path-equipe-id-return-index-html"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 76325234,
      "title": "Why aren&#39;t my sub pages loading when they are in location blocks in the nginx configuration?",
      "problem": "I have a certain subdomain: /var/www/test.domain.com. Now I would like to have multiple pages, so an /about page and a /contact page for example. The homepage works just fine. For some reason I cannot get these subpages to load.\nCurrently I have 3 files in my /var/www/test.domain.com folder\n\nindex.html\nabout.html\ncontact.html\n\nI was under the impression that I did not have to create different location blocks for all my subpages, but I am not sure about this. My 'default' location block looked like this:\n```\n`  location / {\n    try_files $uri $uri/ =404;\n  }\n`\n```\nHowever, since that did not work, I also tried this:\n```\n`server {\n  root /var/www/test.domain.com;\n\n  server_name test.domain.com;\n\n  listen 443 ssl;\n\n  ssl_certificate /etc/letsencrypt/live/domain.com/fullchain.pem;\n  ssl_certificate_key /etc/letsencrypt/live/domain.com/privkey.pem;\n\n  if ($scheme != \"https\") {\n    return 301 https://$host$request_uri;\n  } # managed by Certbot\n\n  location / {\n    try_files $uri $uri/ =404;\n  }\n\n  location /about {\n    root /var/www/test.domain.com;\n    index about.html;\n  }\n\n  location /contact {\n    root /var/www/test.domain.com;\n    index contact.html;\n  }\n}\n`\n```\nI restart nginx but the /about page and /contact page returns a 404. What seems to be the problem?",
      "solution": "To return the `about.html` file with the URL `/about` - you could use a `$uri.html` term in the `try_files` statement.\nFor example:\n```\n`location / {\n    try_files $uri $uri.html $uri/ =404;\n}\n`\n```",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-05-24T17:36:30",
      "url": "https://stackoverflow.com/questions/76325234/why-arent-my-sub-pages-loading-when-they-are-in-location-blocks-in-the-nginx-co"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 76057031,
      "title": "Cannot Configure (Error While) Django setting in nginx",
      "problem": "My server cannot find the files, it says no files found . I have following configuration\n```\n`user www-data;\nworker_processes auto;\npid /run/nginx.pid;\ninclude /etc/nginx/modules-enabled/*.conf;\n\nevents {\n        worker_connections 768;\n       \n}\n\nhttp {\n\n       \n\n        sendfile on;\n        tcp_nopush off;\n        tcp_nodelay off;\n        keepalive_timeout 265;\n        types_hash_max_size 2000;\n\n`\n```\nand Server is\n```\n`server {\n    listen 8000;\n    server_name joshna.co www.joshna.co joshna.net www.joshna.net;\n\n    location = /favicon.ico { access_log off; log_not_found off; }\n    location /static/{\n    autoindex on;\n    alias /home/bsyal/mysite/mypro/static;\n}\n    location /media/{\n    autoindex on;\n    alias /home/bsyal/mysite/mypro-project/static;\n}\n    location / {\n        include proxy_params;\n        proxy_pass http://unix:/run/gunicorn.sock;\n    }\n}\n`\n```\nServer cannot find file, I have gone thhrough others solution but could not figured out",
      "solution": "Instead of Nginx, it is because of your Django static configuration. You need , static and media files to be served from different directories.\nCreate two directories (the directories \"/home/egor/mysite/mypro-project/static\" and \"/home/egor/mysite/mypro-project/media\" exist ) if not there already and update your Nginx configuration as follows:\n```\n`server {\nlisten 80;\nserver_name joshna.co www.joshna.co joshna.net www.joshna.net;\n\nlocation = /favicon.ico { access_log off; log_not_found off; }\nlocation /static/ {\n    alias /home/bsyal/mysite/mypro-project/static/;\n}\nlocation /media/ {\n    alias /home/bsyal/mysite/mypro-project/media/;\n}\nlocation / {\n    include proxy_params;\n    proxy_pass http://unix:/run/gunicorn.sock;\n}\n}\n`\n```",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-04-19T18:51:06",
      "url": "https://stackoverflow.com/questions/76057031/cannot-configure-error-while-django-setting-in-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 76040359,
      "title": "While refreshing the page in browser getting 404 in nginx",
      "problem": "Deployed my react app in Vultr and below is my `nginx` configuration. navigating to a page and while refreshing the browser throws 404 error. I have added `try_files $uri /index.html;` under location and did restarted the nginx by running below command. Could someone please advise to fix the issue !\n```\n`$ sudo systemctl restart nginx\n`\n```\nBut while adding `try_files $uri /index.html; ` I am getting error System error: net::ERR_BLOCKED_BY_CLIENT\ngroupByTags.js:38 TypeError: Cannot read properties of undefined (reading '0')\nat groupByTags.js:35:39\nat c (regeneratorRuntime.js:44:17)\n// nginx configuration\n```\n`server {\n        \n                listen 80;\n                server_name example.com www.example.com;\n                root /var/www/example.com/build;\n                index index.html;\n        \n            location /service {\n               proxy_pass http://localhost:8000;\n               proxy_http_version 1.1;\n               proxy_set_header Upgrade $http_upgrade;\n               proxy_set_header Connection 'upgrade';\n               proxy_set_header Host $host;\n               proxy_cache_bypass $http_upgrade;\n               try_files $uri /index.html;    ## try_files $uri $uri/ /index.html; ## tried this one\n            }\n    \n    }\n`\n```",
      "solution": "I was able to figure out this. I have added another block of `location / { try_files $uri /index.html; }` in nginx conf file solved the page refresh issue. Second block of `location /service {...` is used for reaching the existing api services.\nIn my case, my api service end point looks as follows , example: `service/listOfBlogs`. So if your api endpoind starts with `api/some_end_point`, then location block should be written as `location /api {...`\nFull nginx conf listed below:\n```\n`server {\n        \n            listen 80;\n            server_name example.com www.example.com;\n            root /var/www/example.com/build;\n            index index.html;\n            \n            location / {\n                try_files $uri /index.html;\n            }\n\n        \n            location /service {\n               proxy_pass http://localhost:8000;\n               proxy_http_version 1.1;\n               proxy_set_header Upgrade $http_upgrade;\n               proxy_set_header Connection 'upgrade';\n               proxy_set_header Host $host;\n               proxy_cache_bypass $http_upgrade;\n            }\n        \n    }\n`\n```",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-04-18T03:11:25",
      "url": "https://stackoverflow.com/questions/76040359/while-refreshing-the-page-in-browser-getting-404-in-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 76031110,
      "title": "How can I point the react api service point to hit my domain rather than localhost:8000",
      "problem": "I have deployed my react app in `Vultr` server and installed `nginx` in server and configured the  below settings by running below command.\n```\n`$ sudo nano /etc/nginx/sites-available/default\n\nserver {\n\n    listen 80;\n    server_name somedomain-test.com www.somedomain-test.com;\n    root /var/www/somedomain-test.com/build;\n    index index.html;\n}\n`\n```\nI did ran `npm run build` and copied the build folder into the following destination folder `/var/www/automateandmore.com/build`\nThen ran below commands:\n```\n`$ sudo nginx -t\n$ sudo systemctl restart nginx\n`\n```\nI able to see the front end. Now I have started the `server.js` from the folder location `src/` but still I can see it is calling `localhost:8000/service/listofblogs: `\nHow do i fix the issue, could someone please advise ?\nThis is my package.json settings\n```\n`{\n  \"name\": \"myblogs\",\n  \"version\": \"0.1.0\",\n  \"private\": true,\n  \"dependencies\": {\n    .....\n     \n  },\n  \"proxy\": \"http://localhost:8000\",\n  \"scripts\": {\n    \"start\": \"react-scripts start\",\n    \"build\": \"react-scripts build\",\n    \"test\": \"react-scripts test\",\n    \"eject\": \"react-scripts eject\"\n  },\n    ....\n  }\n}\n`\n```\n.env file\n```\n`DANGEROUSLY_DISABLE_HOST_CHECK=true\nREACT_APP_URL=http://somedomain-test.com\n`\n```",
      "solution": "If I read the docs correctly, you have it backwards. See Proxying API Requests in Development\n\nTo tell the development server to proxy any unknown requests to your API server in development, add a proxy field to your package.json, for example:\n`\"proxy\": \"http://localhost:4000\",\n`\n\nBut you say \"rather than localhost:8000\", but that is the url your proxy is giving the app.\nChange it to the url you want to hit.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-04-17T03:14:18",
      "url": "https://stackoverflow.com/questions/76031110/how-can-i-point-the-react-api-service-point-to-hit-my-domain-rather-than-localho"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 75192293,
      "title": "Permission denied /media files Django Nginx setup",
      "problem": "I followed this tutorial:\nhttps://www.digitalocean.com/community/tutorials/how-to-set-up-django-with-postgres-nginx-and-gunicorn-on-ubuntu-22-04\nEverything is working (static files are served etc) but by user uploaded media files show a \u2018permission denied\u2019 when trying to access the image:\n```\n`2023/01/21 09:50:01 [error] 12912#12912: *266 open() \"/home/hvn/intranet/intranet/media/images/werkstujk_1_Far44Li.2e16d0ba.fill-322x247-c100.jpg\" failed (13: Permission denied), client: xxx.xxx.xxx.xxx, server: xxxxx.net, request: \"GET /media/images/werkstujk_1_Far44Li.2e16d0ba.fill-322x247-c100.jpg HTTP/1.1\", host: \"www.xxxxxx.net\", referrer: \"https://www.xxxxx.net/blogs/\"\n`\n```\nI\u2019m using wagtail as cms system.\nThe Gunicorn socket is running under user \u2018hvn\u2019 and group \u2018www-data\u2019.\nThe directory and filepermissions are like:\n750 for dirs and 644 for files:\n```\n`ll | grep media\ndrwxr-xr-x  5 hvn www-data 4096 Jan 17 22:36 media/\n\n-rw-r--r-- 1 hvn www-data  33857 Jan 21 00:24 werkstujk_1_Far44Li.2e16d0ba.fill-322x247-c100.jpg\n`\n```\nMy nginx config file is serving the media folder:\n```\n`location /media/ {\n        root /home/hvn/intranet/intranet;\n    }\n`\n```\n```\n`/etc/nginx/sites-enabled/xxx.xx                                               \nserver {\n    server_name xxx.xx *.xxx.xx;\n\nlocation = /favicon.ico { access_log off; log_not_found off; }\n    location /collectstatic/ {\n        root /home/hvn/intranet/intranet;\n    }\n\nlocation /media/ {\n        root /home/hvn/intranet/intranet;\n    }\n\nlocation / {\n        include proxy_params;\n        proxy_pass http://unix:/run/gunicorn.sock;\n    }\n\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/xxx.xx/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/xxx.xx/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n}\nserver {\n    if ($host = www.xxxx.xx) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n    if ($host = xxx.xx) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n    listen 80;\n    server_name xxx.net *.xxx.xx;\n    return 404; # managed by Certbot\n`\n```\nWhat am I doing wrong?\nPlease help me. Thnx in advanced.",
      "solution": "Solved it:\nHad to set in the nginx.conf that nginx runs on the same user that is serving the website:\nCheck the user in /etc/nginx/nginx.conf\nChange ownership to user.\nsudo chown -R nginx:nginx /var/lib/nginx",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-01-21T10:22:20",
      "url": "https://stackoverflow.com/questions/75192293/permission-denied-media-files-django-nginx-setup"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 74883074,
      "title": "How can I deny a request with a specific url encoded character?",
      "problem": "I'm having problems with a site being exploited, and I have tried many ways to solve this, but I'm missing some skills to get it done.\nThe issue is I need to deny POST requests to \"/%21/Form/create\" while accepting POST requests to \"/!/Form/create\".\nI have tried:\n```\n`location = /%21/Form/create {\ndeny all;\n}\n`\n```\n```\n`location ~ ^/%21.*/ {\ndeny all;\n}\n`\n```\nwithout any luck. I would really appreciate some help solving this.",
      "solution": "They are the same URL - but if your server is receiving both forms of request - and you need to differentiate between them - you can use `$request_uri` to view the request as it was originally received.\nThe variable can be tested using an `if` block.\n```\n`if ($request_uri = /%21/Form/create) { return 403; }\n`\n```",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2022-12-22T01:28:10",
      "url": "https://stackoverflow.com/questions/74883074/how-can-i-deny-a-request-with-a-specific-url-encoded-character"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 74768073,
      "title": "&quot;ERR_TOO_MANY_REDIRECTS&quot; nginx-ingress controller does not overwrite X-Forwarded-Proto: http, X-Forwarded-Scheme: http",
      "problem": "We are using an IAP, GCP L7 Loadbalancer with nginx-ingress controller (version 0.49.3). We deployed self-hosted GitLab and we are getting \"ERR_TOO_MANY_REDIRECTS\".\nAfter some intense days of trouble shooting we noticed that\n```\n`POST /api/v4/jobs/request HTTP/1.1\nHost: gitlab.ci.g.nakhoda.ai\nX-Request-ID: dfa874d97ed06e0e7a7cf17c0a4ae2c0\nX-Real-IP: 35.191.12.183\nX-Forwarded-For: 35.191.12.183\nX-Forwarded-Host: gitlab.ci.g.nakhoda.ai\nX-Forwarded-Port: 80\nX-Forwarded-Proto: http\nX-Forwarded-Scheme: http\nX-Scheme: http\nX-Original-Forwarded-For: 62.189.73.245, 35.186.225.221\nContent-Length: 714\nUser-Agent: gitlab-runner 15.6.1 (15-6-stable; go1.18.8; linux/amd64)\nAccept: application/json\nContent-Type: application/json\nAccept-Encoding: gzip\nX-Cloud-Trace-Context: 4efdd65224a5882999fd0fb26a888bfd/2273898499790060164\nVia: 1.1 google\n`\n```\nX-Forwarded-Proto: http and X-Forwarded-Scheme: http it is set to `http` in our initial redirects. After fiddling with it a bit we executed in the container of the nginx-ingress-controller and edited the `nginx.conf` to have https for both of them and also added annotation `ssl-redirect: false`.\nAfterwards the request looks like this:\n```\n`POST /api/v4/jobs/request HTTP/1.1\nHost: gitlab.ci.g.nakhoda.ai\nX-Request-ID: f103bba96d47527dae15087d1dd1d476\nX-Real-IP: 35.191.12.180\nX-Forwarded-For: 35.191.12.180\nX-Forwarded-Host: gitlab.ci.g.nakhoda.ai\nX-Forwarded-Port: 80\nX-Forwarded-Proto: https\nX-Forwarded-Scheme: https\nX-Scheme: http\nX-Original-Forwarded-For: 194.203.216.4, 35.186.225.221\nContent-Length: 714\nUser-Agent: gitlab-runner 15.6.1 (15-6-stable; go1.18.8; linux/amd64)\nAccept: application/json\nContent-Type: application/json\nAccept-Encoding: gzip\nX-Cloud-Trace-Context: 3ceb1d9d95fa28be4da929dea1f3ac95/3016269448751760533\nVia: 1.1 google\n`\n```\nBy manually editing now we can access GitLab without any issues but the problem is that this is a manual fix we added so every time a pipeline will do a deployment this will be reset in place.\nThe issue is that we looked for adding custom headers to overwrite the [nginx.conf](https://kubernetes.github.io/ingress-nginx/examples/customization/custom-headers/ is not overwriting the normal nginx.conf configuration) but after adding a ConfigMap with the specific things or just adding similar annotations like this to the Ingress of the nginx-ingress controller or to the ConfigMap:\nGitlab Ingress\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: gitlab-chart-webservice-default\n  namespace: gitlab\n  labels:\n    app: webservice\n    app.kubernetes.io/managed-by: Helm\n    chart: webservice-6.6.2\n    gitlab.com/webservice-name: default\n    heritage: Helm\n    release: gitlab-chart\n  annotations:\n    kubernetes.io/ingress.provider: nginx\n    meta.helm.sh/release-name: gitlab-chart\n    meta.helm.sh/release-namespace: gitlab\n    nginx.ingress.kubernetes.io/proxy-body-size: 512m\n    nginx.ingress.kubernetes.io/proxy-connect-timeout: '15'\n    nginx.ingress.kubernetes.io/proxy-read-timeout: '600'\n    nginx.ingress.kubernetes.io/service-upstream: 'true'\n    nginx.ingress.kubernetes.io/ssl-redirect: 'false'\nstatus:\n  loadBalancer:\n    ingress:\n      - ip: 1.1.1.1\n      - ip: 1.1.1.1\nspec:\n  ingressClassName: stable-protected\n  tls:\n    - hosts:\n        - gitlab.ci.example.com\n      secretName: gitlab-cert\n  rules:\n    - host: gitlab.ci.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: gitlab-chart-webservice-default\n                port:\n                  number: 8181\n`\n```\nConfigMap for nginx controller\n```\n`apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: nginx\n  namespace: ingress-stable-protected\n  annotations:\n    refresh-me: |\n      This 'refresh-me' annotation is purely used as a placeholder so we can\n      modify its value in order to manually force the nginx ingress-controller\n      to reload its configuration.\n      Reload.\ndata:\n  enable-vts-status: 'true'\n  hide-headers: Strict-Transport-Security\n  hsts: 'true'\n  hsts-include-subdomains: 'false'\n  hsts-preload: 'false'\n  proxy-body-size: 2048m\n  proxy-buffer-size: 16k\n  proxy-connect-timeout: '5'\n  proxy-next-upstream: 'off'\n  proxy-read-timeout: '600'\n  proxy-send-timeout: '600'\n  server-name-hash-bucket-size: '256'\n  server-tokens: 'false'\n`\n```\n```\n`nginx.ingress.kubernetes.io/x-forwarded-proto=https\nnginx.ingress.kubernetes.io/x-forwarded-scheme=https\n`\n```\nIt still takes the nginx.conf `http` so we are kind of stuck with this temporary fix.\nTried to add a bunch of custom headers and x-forwarded-headers as well but to no avail.",
      "solution": "The issue was after version 0.24.0 of nginx-ingress there was a change for an annotation so by adding the following to the nginx configmap there is no more error.\nA more deep description can be found in this ticket\n`use-forwarded-headers: \"true\"\nuse-proxy-protcol: \"false\"\n`\nFull example:\n`apiVersion: v1\ndata:\n  enable-vts-status: \"true\"\n  hide-headers: Strict-Transport-Security\n  hsts-preload: \"false\"\n  proxy-body-size: 2048m\n  proxy-buffer-size: 16k\n  proxy-connect-timeout: \"5\"\n  proxy-next-upstream: \"off\"\n  proxy-read-timeout: \"600\"\n  proxy-send-timeout: \"600\"\n  server-name-hash-bucket-size: \"256\"\n  server-tokens: \"false\"\n  use-forwarded-headers: \"true\"\n  use-proxy-protcol: \"false\"\nkind: ConfigMap\nmetadata:\n  annotations:\n    refresh-me: |\n      This 'refresh-me' annotation is purely used as a placeholder so we can\n      modify its value in order to manually force the nginx ingress-controller\n      to reload its configuration.\n  labels:\n    app.kubernetes.io/managed-by: pulumi\n  name: nginx\n  namespace: namespace\n`",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2022-12-12T08:52:17",
      "url": "https://stackoverflow.com/questions/74768073/err-too-many-redirects-nginx-ingress-controller-does-not-overwrite-x-forwarded"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 73926261,
      "title": "nginx location block not returning static content",
      "problem": "I am attempting to work on a personal project that is using nginx as a reverse proxy, the basic premise of the project is that any static content should always be served up to the user, and any api requests must be authenticated. Any that fail authentication will immediately force the page to redirect to a /login page.\nI have sucessfully implemented the bulk of the project: auth_request is enabled and working, the content is served up and works fine.\nMy problem is that I can't seem to be able to handle serving up content from the /login location on a failed api request; I have reduced the problem down to some repeatable code below:\n```\n`server {\n    listen 81;\n\n    location /login {\n        root /etc/nginx/websites/login;\n        index index.html;\n    }\n}\n`\n```\nSome notes about my configuration:\n\nI am running a windows machine and using linux docker containers\nThe port 81 above is mapped to port 80 on my local machine - I'd rather not change this.\nThe path /etc/nginx/websites/login; maps to a folder on my local machine which contains a built Vue3 projects distribution folder. It contains an index.html file, along with other js/ and css/ distributables.\n\nI have verified this by browsing to the same location within the container and making sure at least the same files exist.\n\nIt probably goes without saying, but I'll say it anyway: between each configuration file change, I am running nginx -s reload and in every case below there have been no errors returned.\n\nI would expect that when I browse to localhost/login, the request would be mapped through the location block and load the /login/index.html page. With the code above, on chrome, I get 404 not found.\nI have also tried:\n```\n`server {\n    listen 81;\n\n    location /login/ {\n        root /etc/nginx/websites/login;\n        index index.html;\n    }\n}\n`\n```\nand get the same error.\nIf I modify the root to:\n```\n`root /etc/nginx/websites/login/;\n`\n```\nThe problem persists.\nIf I try:\n```\n`server {\n    listen 81;\n\n    location /login {\n        return 200 'It's heeeere';\n    }\n}\n`\n```\nThen chrome downloads a file containing the above text.\nIf I try alias, then the entire request is redirected to localhost:81/login and completely falls over - as one would expect.\nI can't help but feel I'm missing something entirely obvious, but after 15 hours straight even if the answer jumped out of the page and slapped me in the face I'd probably be oblivious to it!\nConfiguration blindness aside, and to avoid any \"RTFM\" responses, I have been through this page in the docs: https://docs.nginx.com/nginx/admin-guide/web-server/serving-static-content/, as I understand them at least one of the configurations I have posted above should work.\nI appreciate any help that you can give in helping me out of this pit of configuration hell.\nMany thanks,\nSteve\nEDIT\nSince the original post, I have checkout out the logs from docker (I also have logs written from nginx and would expect them to be similar, but in this case clearly aren't), and when accessing the endpoint it reports: open() \"/etc/nginx/websites/login/login\" failed (2: No such file or directory).\nThis confuses me, I would expect the index.html page would be the default index page, and my explicit declaration should ensure that it is.\nAnother Edit\nIt seems I was being more of a fool than I anticipated, I took another look at the configuration and realised that the second /login wasn't a file, but a folder. So changed the root directive to:\n```\n`root /etc/nginx/websites/;\n`\n```\nAnd whilst it no longer throws a 404, it does not return a 301 to localhost:81/login, which - as I stated before - is not a valid endpoint on my local machine.",
      "solution": "So the URI `/login` should return `/login/index.html`?\nThe `index` directive only works with URIs that end with `/`, which is why you get a redirection to `localhost:81`.\nHow do you want to fix this?\nIf you change your original URI to `/login/` the problem goes away.\nOtherwise use `try_files $uri /login/index.html =404;` to force Nginx to return the index file without a redirection.\nOther considerations: use `port_in_redirect off;` and/or `server_name_in_redirect off;` to achieve a redirection that works for your implementation.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2022-10-02T15:37:35",
      "url": "https://stackoverflow.com/questions/73926261/nginx-location-block-not-returning-static-content"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 72269852,
      "title": ".NET Core WebAPI - AWS ElasticBeanstalk Nginx Configuration",
      "problem": "I've moved my .NET Core WebAPI to an AWS EB Instance. This works fine, however my file upload has now broken due to the Nginx 'client_max_body_size' configuration.\nI've looked up how to override this, however I cannot get this to work. Here is my current set-up:\n\nWithin this file I have added:\n```\n`client_max_body_size 0;\n`\n```\nThis file has no hidden characters (Notepad++ with show all chars on):\n\nWhen my EB environment is updated I get the following eb-engine log:\n```\n`2022/05/17 07:15:57.025994 [ERROR] An error occurred during execution of command [app-deploy] - [FlipProxyForDotNetCore]. Stop running the command. Error: copy proxy conf from staging failed with error validate nginx configuration failed with error Command /bin/sh -c /usr/sbin/nginx -t -c /var/proxy/staging/nginx/nginx.conf failed with error exit status 1. Stderr:nginx: [emerg] unknown directive \"\u00ef\u00bb\u00bfclient_max_body_size\" in /var/proxy/staging/nginx/conf.d/myConf.conf:1\nnginx: configuration file /var/proxy/staging/nginx/nginx.conf test failed\n`\n```\nMy EB instance is running Amazon Linux 2/2.3.1.\nWhat am I doing wrong?",
      "solution": "The error msg\n```\n`\"\u00ef\u00bb\u00bfclient_max_body_size\"\n`\n```\nindicates that you have some non-ASCII characters (`\u00ef\u00bb\u00bf`) in your `myConf.conf`. Please open the file in a regular text editor and verify that it has only ASCII characters.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2022-05-17T09:32:07",
      "url": "https://stackoverflow.com/questions/72269852/net-core-webapi-aws-elasticbeanstalk-nginx-configuration"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 70536824,
      "title": "Why is this NGINX config file invalid?",
      "problem": "So I have this NGINX config file:\n```\n`events { }\nhttp {\n    server {\n        listen 443 ssl;\n        ssl_certificate /home/dietpi/certs/cert.pem;\n        ssl_certificate_key /home/dietpi/certs/privkey.pem.key;\n        location / {\n            proxy_set_header   X-Real-IP $remote_addr;\n            proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_pass         http://localhost:3001/;\n            proxy_http_version 1.1;\n            proxy_set_header   Upgrade $http_upgrade;\n            proxy_set_header   Connection \"upgrade\";\n        }\n    }\n}\n`\n```\nIt is a reverse-proxy for a Docker container. It does SSL for me. I wanted to redirect HTTP to HTTPS, so I tried adding this:\n```\n`events { }\nhttp {\n    server {\n        listen 80 default_server;\n        server _;\n        return 301 https://$host$request_uri;\n    }\n    server {\n        listen 443 ssl;\n        ssl_certificate /home/dietpi/certs/cert.pem;\n        ssl_certificate_key /home/dietpi/certs/privkey.pem.key;\n        location / {\n            proxy_set_header   X-Real-IP $remote_addr;\n            proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_pass         http://localhost:3001/;\n            proxy_http_version 1.1;\n            proxy_set_header   Upgrade $http_upgrade;\n            proxy_set_header   Connection \"upgrade\";\n        }\n    }\n}\n`\n```\nBut now it doesn't work (`sudo nginx -t` fails).\nIt says this:\n```\n`nginx: [emerg] \"server\" directive is not allowed here in /etc/nginx/nginx.conf:5\nnginx: configuration file /etc/nginx/nginx.conf test failed\n`\n```\nMost people that have this error tend to have the server block not in an `http` block, and putting it in one fixes it. But... my `server` block is already in an `http` block. So how do I fix it?",
      "solution": "Typo is `server` instead of `server_name` within the `server {}` block\n```\n`server {\n  listen 80 default_server;\n  server_name _;   # \u2705 corrected\n}\n`\n```",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-12-30T22:20:42",
      "url": "https://stackoverflow.com/questions/70536824/why-is-this-nginx-config-file-invalid"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 70220088,
      "title": "Nginx does not compress web pages",
      "problem": "My Nginx website config with `gzip on`:\n```\n`server {\n    listen 443 ssl;\n    listen [::]:443 ssl;\n\n    ssl_certificate /etc/letsencrypt/live/...\n    ssl_certificate_key /etc/letsencrypt/live/...\n\n    gzip on;\n    gzip_types text/plain application/xml text/css text/js text/xml application/javascript text/javascript application/json application/xml+rss;\n\n    root /home/devnote/www;\n\n    index index.php index.html;\n\n    access_log /var/log/nginx/devnote-ssl.access.log;\n    error_log /var/log/nginx/devnote-ssl.error.log info;\n\n    server_name ...\n\n    # Deny all attempts to access hidden files such as .htaccess, .htpasswd, .DS_Store (Mac).\n    location ~ /\\. {\n             deny all;\n             access_log off;\n             log_not_found off;\n    }\n\n    location / {\n             try_files $uri $uri/ /index.php?$args;\n    }\n\n    # Add trailing slash to */wp-admin requests.\n    rewrite /wp-admin$ $scheme://$host$uri/ permanent;\n\n    # Rewrite for multi site files\n    rewrite /files/(.+)$ /wp-includes/ms-files.php?file=$1 last;\n\n    location ~*  \\.(jpg|jpeg|png|gif|css|js|ico)$ {\n             expires max;\n    }\n\n    location ~ \\.php$ {\n            fastcgi_connect_timeout 60;\n            fastcgi_send_timeout 300;\n            fastcgi_read_timeout 300;\n            fastcgi_buffer_size 128k;\n            fastcgi_buffers 4 256k;\n            fastcgi_busy_buffers_size 256k;\n            fastcgi_temp_file_write_size 256k;\n            fastcgi_intercept_errors on;\n            try_files $uri =404;\n            fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n            fastcgi_pass unix:/run/php/www-devnote.sock;\n            fastcgi_index index.php;\n            include fastcgi.conf;\n    }\n}\n`\n```\nOS: Ubuntu 16.04, Nginx version:\n```\n`nginx -V\nbuilt with OpenSSL 1.0.2g  1 Mar 2016\nTLS SNI support enabled\nconfigure arguments: --with-cc-opt='-g -O2 -fPIE -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2' --with-ld-opt='-Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now' --prefix=/usr/share/nginx --conf-path=/etc/nginx/nginx.conf --http-log-path=/var/log/nginx/access.log --error-log-path=/var/log/nginx/error.log --lock-path=/var/lock/nginx.lock --pid-path=/run/nginx.pid --http-client-body-temp-path=/var/lib/nginx/body --http-fastcgi-temp-path=/var/lib/nginx/fastcgi --http-proxy-temp-path=/var/lib/nginx/proxy --http-scgi-temp-path=/var/lib/nginx/scgi --http-uwsgi-temp-path=/var/lib/nginx/uwsgi --with-debug --with-pcre-jit --with-ipv6 --with-http_ssl_module --with-http_stub_status_module --with-http_realip_module --with-http_auth_request_module --with-http_addition_module --with-http_dav_module --with-http_geoip_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_image_filter_module --with-http_v2_module --with-http_sub_module --with-http_xslt_module --with-stream --with-stream_ssl_module --with-mail --with-mail_ssl_module --with-threads \n`\n```\nBut I do not see `Content-Encoding: gzip` if I open a webpage with Developer Tools:\n\nEDIT1\nIt does not compress `application/javascript`, but comresses `text/html` whille `text/html` is not listed in `gzip_types`:\n\nactually adding/remoing `gzip on;` directive to the config does not have an effect.\nChanging to this does not help:\n```\n`gzip_types    text/plain application/javascript application/x-javascript text/javascript text/xml text/css;\n`\n```\nEDIT2\n`gzip_static on;` from here does not help.\nNothing helps, it refuses to work, this does not help:\n```\n`# output compression saves bandwidth\ngzip  on;\ngzip_http_version 1.1;\ngzip_vary on;\ngzip_comp_level 6;\ngzip_proxied any;\ngzip_types text/plain text/html text/css application/json application/javascript application/x-javascript text/javascript text/xml application/xml application/rss+xml application/atom+xml application/rdf+x$\n\n# make sure gzip does not lose large gzipped js or css files\n# see http://blog.leetsoft.com/2007/07/25/nginx-gzip-ssl.html\ngzip_buffers 16 8k;\n\n# Disable gzip for certain browsers.\ngzip_disable \u201cMSIE [1-6].(?!.*SV1)\u201d;\n`\n```\nIn my `/etc/nginx/nginx.conf` I have this:\n```\n`    gzip on;\n    gzip_disable \"msie6\";\n\n    # gzip_vary on;\n    # gzip_proxied any;\n    # gzip_comp_level 6;\n    # gzip_buffers 16 8k;\n    # gzip_http_version 1.1;\n    # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;\n`\n```",
      "solution": "In Chrome Dev Tools, ensure that \"Disable cache\" is checked when refreshing and testing.\n\nYou can also try testing on static URLs, and Nginx will return `Content-Encoding: gzip` when configured properly:\n```\n`location ~ ^/test.js$ {\n  gzip_types application/javascript;\n  gzip on;\n\n  default_type application/javascript;\n  return 200 \"/*****  hello  *****/\";\n}\n`\n```\n```\n`$ curl --compressed -kIX GET https://example.com/test.js\n\nHTTP/1.1 200 OK\nServer: nginx\nDate: Fri, 01 Dec 2021 00:00:00 GMT\nContent-Type: application/javascript; charset=utf-8\nTransfer-Encoding: chunked\nConnection: keep-alive\nContent-Encoding: gzip\n`\n```",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-12-03T21:04:48",
      "url": "https://stackoverflow.com/questions/70220088/nginx-does-not-compress-web-pages"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 69799687,
      "title": "nginix on windowse don&#39;t redirect?",
      "problem": "I'm working on Kubernetes deployment services using minikube locally on my windows 10 machine, so when I expose my service which is an expressjs API I can reach it via: `localhost:3000`\n\nI want to expose that service on the network so I can test the API from another device (My mobile phone) to do that I installed Nginx to set a reverse proxy to forward all incoming requests on port 80 to `localhost:3000/api`  but when I hit localhost it shows the default page of Nginx ?\n\nthis is my nginx.conf\n```\n`#user  nobody;\nworker_processes  1;\n\n#error_log  logs/error.log;\n#error_log  logs/error.log  notice;\n#error_log  logs/error.log  info;\n\n#pid        logs/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    #log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n    #                  '$status $body_bytes_sent \"$http_referer\" '\n    #                  '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    #access_log  logs/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    #keepalive_timeout  0;\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    server {\n        listen       80;\n        server_name  localhost;\n        location / {\n                proxy_pass http://localhost:3000/api/;\n                }\n\n        \n        #\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n\n        # proxy the PHP scripts to Apache listening on 127.0.0.1:80\n        #\n        #location ~ \\.php$ {\n        #    proxy_pass   http://127.0.0.1;\n        #}\n\n        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000\n        #\n        #location ~ \\.php$ {\n        #    root           html;\n        #    fastcgi_pass   127.0.0.1:9000;\n        #    fastcgi_index  index.php;\n        #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;\n        #    include        fastcgi_params;\n        #}\n\n        # deny access to .htaccess files, if Apache's document root\n        # concurs with nginx's one\n        #\n        #location ~ /\\.ht {\n        #    deny  all;\n        #}\n    }\n\n    # another virtual host using mix of IP-, name-, and port-based configuration\n    #\n    #server {\n    #    listen       8000;\n    #    listen       somename:8080;\n    #    server_name  somename  alias  another.alias;\n\n    #    location / {\n    #        root   html;\n    #        index  index.html index.htm;\n    #    }\n    #}\n\n    # HTTPS server\n    #\n    #server {\n    #    listen       443 ssl;\n    #    server_name  localhost;\n\n    #    ssl_certificate      cert.pem;\n    #    ssl_certificate_key  cert.key;\n\n    #    ssl_session_cache    shared:SSL:1m;\n    #    ssl_session_timeout  5m;\n\n    #    ssl_ciphers  HIGH:!aNULL:!MD5;\n    #    ssl_prefer_server_ciphers  on;\n\n    #    location / {\n    #        root   html;\n    #        index  index.html index.htm;\n    #    }\n    #}\n\n}\n`\n`\n```",
      "solution": "A few things could be happening here:\n\nAfter the Nginx configuration changed, the stop and reload of the application was not performed; this is necessary to load the new configuration and is performed with the commands `nginx -s stop`, and then `nginx -s reload`.\n\nAccidentally running multiple instances: if for any reason the command `start nginx` was run more than once, you will have a process running for each time and cannot kill them with the `nginx -s stop` command; in this case, you will need to kill the processes on the Task Manager or restart the Windows system.\n\nBe aware that Nginx for Windows is considered a beta version and it has some performance and operability issues, as stated in the following documentation [1].\n\nI recommend switching to a Linux system which fully supports Minikube and Nginx. Your scenario has been replicated on an Ubuntu VM and is working as expected.\n[1] http://nginx.org/en/docs/windows.html",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-11-01T17:14:14",
      "url": "https://stackoverflow.com/questions/69799687/nginix-on-windowse-dont-redirect"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 69750893,
      "title": "Nginx configuration to only forward request to php laravel server for files with prefix",
      "problem": "I have a kubernetes deployment of a laravel app with two containers:\n\nNGINX container that receives requests and either immediately returns the static files on the container (images, javascript, css..) or, if the requested file does not exist, proxy the request to the PHP container\n\nPHP container running laravel\n\nIt works perfectly with the following nginx configuration:\n```\n`server {\n        listen 80;\n        root /var/www/public;\n\n        index index.html index.htm index.php;\n        charset utf-8;\n\n        location / {\n            try_files $uri $uri/ /index.php?$query_string;\n        }\n\n        error_page 404 /index.php;\n\n        location ~ \\.php$ {\n            fastcgi_pass 127.0.0.1:9000;\n            fastcgi_index index.php;\n            fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;\n            include fastcgi_params;\n        }\n\n        location ~* \\.(js|css|png|jpg|jpeg|gif|ico|svg|eot|ttf|woff|woff2)$ {\n            expires 2d;\n            add_header Cache-Control \"public, no-transform\";\n        }\n    }\n`\n```\nHere comes the problem: I need to return some encrypted files that should be handled by laravel (to handle authorization, autentication and decryption). Those files are requested using the following endpoint:\n`example.com/files/decrypt/path/to/file.jpg?token=tokentovalidaterequest`\nSuch a request generates a nginx error and 404 response (from the nginx logs, I replaced the requested path with $path):\n```\n`2021/10/28 08:29:22 [error] 24#24: *1 open() \"/var/www/public/files/decrypt/$path\" failed (2: No such file or directory), client: 10.244.0.97, server: , request: \"GET /files/decrypt/files/decrypt/$path?hash=$hash HTTP/1.1\", host: \"example.com\"\n10.244.0.97 - - [28/Oct/2021:08:29:22 +0000] \"GET /files/decrypt/$path?hash=$hash HTTP/1.1\" 404 6622 \"https://example.com\" \"user-agent\" \"ip\"\n`\n```\nThe request is actually handled by php due to:\n`error_page 404 /index.php;`\nBut it loses the querystring parameter and I don't want my nginx logs to be full of fake errors.\nIs there a way to tell nginx \"if the location starts with `/files`, send the request directly to php without checking if the file exists on the filesystem\"?\nI tried adding:\n```\n`location /files {\n    try_files /index.php?$query_string;\n}\n`\n```\nbefore the `location /` block, but I obtained a nginx configuration error\nWhat is the proper way to achieve this?",
      "solution": "The `try_files` statement requires at least two parameters, see this document. You can add a fake filename as the first parameter.\nFor example:\n```\n`try_files nonexistent /index.php?$query_string;\n`\n```\nAlternatively, a `rewrite` statement would work too, and note that `rewrite` will automatically append the query string, see this document.\nFor example:\n```\n`rewrite ^ /index.php last;\n`\n```",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-10-28T10:43:53",
      "url": "https://stackoverflow.com/questions/69750893/nginx-configuration-to-only-forward-request-to-php-laravel-server-for-files-with"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 68584688,
      "title": "What is the relationship of server&#39;s setting in both nginx.conf and proxy.conf?",
      "problem": "I am very newbie on NGINX.\nIn my project, the `server` is defined in both `etc/nginx/nginx.conf` and `etc/nginx/conf.d/proxy.conf`. And `etc/nginx/conf.d/proxy.conf` is included in `nginx.conf`\nI am not understand the relationship the server's setting in these two files. ex. In `nginx.conf`, server's setting is  `listen 80 ; listen [::]:80 ;` and in proxy.conf, server's setting is `listen 80 proxy_protocol`.\n\nIn above example, which setting will be used in real communication?\nDoes the server's setting of proxy.conf overwrite the server's setting of nginx.conf?\nor the server's setting of proxy.conf will be merged into server's setting of nginx.conf?\n\nPlease find the full conf files as below:\netc/nginx/conf.d/proxy.conf\n```\n`content: |\n  client_max_body_size 500M;\n  server_names_hash_bucket_size 128;\n\n  upstream backend {\n    server unix:///var/run/puma/my_app.sock;\n  }\n\n  server {\n     listen 80 proxy_protocol;\n\n     access_log /var/log/nginx/access.log;\n     error_log /var/log/nginx/error.log;\n  \n     large_client_header_buffers 8 32k;\n\n     set_real_ip_from 10.0.0.0/8;\n     real_ip_header proxy_protocol;\n\n    location / {\n       proxy_http_version 1.1;\n       proxy_set_header X-Real-IP $proxy_protocol_addr;\n       proxy_set_header X-Forwarded-For $proxy_protocol_addr;\n       proxy_set_header Host $http_host;\n       proxy_set_header X-NginX-Proxy true;\n       proxy_buffers 8 32k;\n       proxy_buffer_size 64k;\n       proxy_pass http://backend;\n       proxy_redirect off;\n\n       Enables WebSocket support\n     location /v1/cable {\n         proxy_pass http://backend;\n         proxy_http_version 1.1;\n         proxy_set_header Upgrade \"websocket\";\n         proxy_set_header Connection \"Upgrade\";\n         proxy_set_header X-Real-IP $proxy_protocol_addr;\n         proxy_set_header X-Forwarded-For $proxy_protocol_addr;\n      }\n    }\n  }\n`\n```\netc/nginx/nginx.conf\n```\n`user nginx;\nworker_processes auto;\nerror_log /var/log/nginx/error.log;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log  /var/log/nginx/access.log  main;\n\n    sendfile            on;\n    tcp_nopush          on;\n    tcp_nodelay         on;\n    keepalive_timeout   65;\n    types_hash_max_size 2048;\n\n    include             /etc/nginx/mime.types;\n    default_type        application/octet-stream;\n\n    include /etc/nginx/conf.d/*.conf;\n\n    server {\n        listen       80 ;\n        listen       [::]:80 ;\n        server_name  localhost;\n        root         /usr/share/nginx/html;\n\n        location / {\n        }      \n    }   \n}\n`\n```",
      "solution": "Nginx selects a `server` block to process a request based on the values of the `listen` and `server_name` directives.\nIf a matching server name cannot be found, the default server for that port will be used.\nIn the configuration in your question, the `server` block in `proxy.conf` is encountered first, so it becomes the de-facto default server for port 80.\nThe `server` block in `nginx.conf` will only match requests which use the correct host name, i.e. `http://localhost`\nSee this document for details.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-07-30T04:16:48",
      "url": "https://stackoverflow.com/questions/68584688/what-is-the-relationship-of-servers-setting-in-both-nginx-conf-and-proxy-conf"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 68238328,
      "title": "NGINX redirect https to https + /location getting loop redirect",
      "problem": "I am trying to deploy my angular app with a nginx server. The problem that i have is when i access to the website i need to be redirected to a specific location, in this case i need to be redirected to mydomain.com/shop, when i enter to this site it gets in a loop and start to type mydomain.com//shop/shop/shop/shop/shop......\nHere is my code.\n```\n`  server {\n    listen 443 ssl;\n\n    ssl_certificate C:/nginx/ssl/cc.crt;\n    ssl_certificate_key C:/nginx/ssl/pkc.key;\n\n    server_name  mydomain.com www.mydomain.com;\n    return 301 https://$host$request_uri/shop;\n} \n\nserver {\n    listen       443 ssl;\n\n    client_max_body_size 200M;\n\n    ssl_certificate C:/nginx/ssl/cc.crt;\n    ssl_certificate_key C:/nginx/ssl/pkc.key;\n\n    server_name  mydomain.com www.mydomain.com;\n\n    location / {\n        root   html/myApp;       \n        try_files $uri $uri/ /index.html;\n    }\n\n    location /api/ {\n        client_max_body_size 200M;\n        \n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $http_host;\n        proxy_set_header X-NginX-Proxy true;\n\n        proxy_pass https://127.0.0.1:4000/;\n        proxy_redirect off;\n    }\n\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n        root   html;\n    }\n}\n`\n```\nhow can i fix it? Thanks in advance",
      "solution": "You have two `server` blocks with the same `listen` and `server_name`. The second block is being ignored as a duplicate.\nYou need to delete that first `server` block and place a redirection rule into the second block.\nFor example:\n```\n`location = / { \n    return 301 /shop; \n}\n`\n```",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-07-03T19:00:42",
      "url": "https://stackoverflow.com/questions/68238328/nginx-redirect-https-to-https-location-getting-loop-redirect"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 68033236,
      "title": "Cannot remove .html from url",
      "problem": "I have a static site and I'm trying to remove the `.html` from the url, so when I visit the site `www.example.com/home.html` I should get: `www.example.com/home`.\nThis is my project structure:\n```\n`project\n    docker\n       nginx\n           conf.d\n               default.conf\n    www\n        index.html\n        home.html\n        services.html\ndocker-compose.yml\n`\n```\nThis is the `docker-compose.yml` file:\n```\n`version: '3.6'\n\nservices:\n  my-app:\n    container_name: trasauto_nginx\n    image: nginx:stable-alpine\n    restart: always\n    volumes:\n      - \"./www/:/usr/share/nginx/html\"\n      - ./docker/nginx/conf.d/:/etc/nginx/conf.d\n    expose:\n      - 80\n\nnetworks:\n  default:\n    external:\n      name: proxy\n`\n```\nand this is the `default.conf`:\n```\n`server {\n    try_files $uri.html $uri $uri/ =404;\n}\n`\n```\nI tried to remove the `.html` part from the url, but for some reason I get:\n\n404 not found\n\nwhat I did wrong?",
      "solution": "You need to add some more lines to your Nginx configuration in order to have what you want. I think this question has already been answered in detail here.\nEdited.\nHere's an example Nginx configuration that should work\n```\n`server {\n    listen 80;    \n    index index.html;\n\n    root /usr/share/nginx/html;\n\n    location / {\n        if ($request_uri ~ ^/(.*)\\.html) {\n            return 302 /$1;\n        }\n        try_files $uri $uri.html $uri/ =404;\n    }\n}\n`\n```\nYou need to specify the root directory from which you're serving your static files.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-06-18T12:06:12",
      "url": "https://stackoverflow.com/questions/68033236/cannot-remove-html-from-url"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 67871989,
      "title": "Prevent nginx from adding extra slashes",
      "problem": "I wanted my nginx configuration to redirect all incomings requests from\n`myServer.com/myApplication/doSomething` -> `myServer.com:7080/doSomething`\n`myServer.com/myApplication/doSomethingElse` -> `myServer.com:7080/doSomethingElse`\nI came up with the following solution after reading this post:\n```\n`location /myApplication{\n  proxy_pass http://127.0.0.1:7080/;\n}\n`\n```\nNo I encounter this weird behavior, that when I test everything locally on the server it seems to work fine, but when I call it from another machine nginx seems to add an extra slash to the path. The curl request I use is this one:\n```\n`curl --location --request POST 'myServer.com/myApplication/doSomething'\n`\n```\nThe error I get from my application has the follwing error message:\n```\n`{\n    \"timestamp\": \"2021-06-07T12:33:41.666+0000\",\n    \"status\": 500,\n    \"error\": \"Internal Server Error\",\n    \"message\": \"The request was rejected because the URL contained a potentially malicious String \\\"//\\\"\",\n    \"path\": \"//doSomething\"\n}\n`\n```\nThe error message says, that there is a problem with the extra slashes, but the curl request does not contain double slashes. When testing it locally, where everything works, I use the following request:\n```\n`curl -X POST localhost:7080/doSomething\n`\n```\nThanks in advance.",
      "solution": "It looks like I just needed to add a `/` to the end of the location so it would be properly substituted away.\n```\n`location /myApplication/{\n  proxy_pass http://127.0.0.1:7080/;\n}\n`\n```",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-06-07T14:53:17",
      "url": "https://stackoverflow.com/questions/67871989/prevent-nginx-from-adding-extra-slashes"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 66810902,
      "title": "Nginx config for ip alow denny starts downloading files and 403 on folder access",
      "problem": "I simply want to allow my static ip & ipv6 to have access to folder and its content and deny to all\nhere is the config I have.\n```\n`location ~ /(wp-admin\\/|wp-login\\.php) {\n    allow 72.1.1.1;\n    allow 2400:abcd:1234:1234:1234:1234:1234:ba4b;\n\n    deny all;\n}\n`\n```\nIf I remove the ipv6 line its works fine and return 403 forbidden on folder and files.\nBut with ipv6 it starts downloading every url I hit valid or not.\nError: You have choose to open - application/octet-stream (7.0 KB)\nWhat am I missing, please guide.\nEdit: server block\n```\n`server {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name www.mysite.com;\n    server_tokens off;\n    root /home/wwwadt/www.mysite.com/public;\n\n    # FORGE SSL (DO NOT REMOVE!)\n    ssl_certificate /etc/nginx/ssl/www.mysite.com/1048699/server.crt;\n    ssl_certificate_key /etc/nginx/ssl/www.mysite.com/1048699/server.key;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers TLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:TLS_AES_256_GCM_SHA384:TLS-AES-256-GCM-SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS-CHACHA20-POLY1305-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-CHACHA20-POLY1305:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA:ECDHE-RSA-AES256-SHA;\n    ssl_prefer_server_ciphers on;\n    ssl_dhparam /etc/nginx/dhparams.pem;\n\n    add_header X-Frame-Options \"SAMEORIGIN\";\n    add_header X-XSS-Protection \"1; mode=block\";\n    add_header X-Content-Type-Options \"nosniff\";\n\n    index index.html index.htm index.php;\n\n    charset utf-8;\n\n    location / {\n        try_files $uri $uri/ /index.php?$query_string;\n    }\n\n    location = /favicon.ico { access_log off; log_not_found off; }\n    location = /robots.txt  { access_log off; log_not_found off; }\n\n    access_log  /var/log/nginx/www.mysite.com-access.log;\n    error_log  /var/log/nginx/www.mysite.com-error.log error;\n\n    error_page 404 /index.php;\n\n    # New changes as per Richard's instructions\n    location ~ ^/(wp-admin|wp-login\\.php) {\n        allow 72.1.1.1;\n        allow 2400:abcd:1234:1234:1234:1234:1234:1234;\n        deny all;\n\n        # also tried this to serve but no luck\n        try_files $uri $uri/ /index.php?$query_string;\n\n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n        fastcgi_pass unix:/var/run/php/php7.4-fpm-wwwadt.sock;\n        fastcgi_index index.php;\n        include fastcgi_params;\n    }\n\n    location ~ \\.php$ {\n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n        fastcgi_pass unix:/var/run/php/php7.4-fpm-wwwadt.sock;\n        fastcgi_index index.php;\n        include fastcgi_params;\n    }\n\n    location ~ /\\.(?!well-known).* {\n        deny all;\n    }\n}\n`\n```",
      "solution": "The protected `location` block needs to include the necessary statements to execute PHP scripts.\nFor example:\n```\n`location / {\n    try_files $uri $uri/ /index.php?$query_string;\n}\n\nlocation ~ ^/(wp-admin|wp-login\\.php) {\n    allow 72.1.1.1;\n    allow 2400:abcd:1234:1234:1234:1234:1234:1234;\n    deny all;\n\n    location ~ \\.php$ {\n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n        fastcgi_pass unix:/var/run/php/php7.4-fpm-wwwadt.sock;\n        fastcgi_index index.php;\n        include fastcgi_params;\n    }\n}\n\nlocation ~ \\.php$ {\n    fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n    fastcgi_pass unix:/var/run/php/php7.4-fpm-wwwadt.sock;\n    fastcgi_index index.php;\n    include fastcgi_params;\n}\n`\n```\nPHP only expects to see URIs which end with `.php`, so the `location ~ \\.php$` block is included as a nested location.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-03-26T05:03:48",
      "url": "https://stackoverflow.com/questions/66810902/nginx-config-for-ip-alow-denny-starts-downloading-files-and-403-on-folder-access"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 66184795,
      "title": "multiple location in nginx is not working - error 404",
      "problem": "I am trying to run two nodejs app one on default path (/) and another on /api , I have tried multiple ways but multiple locations are not working with nginx , only root domain (/) works fine,  it doesn't matter which app I do assign (2nd or first). and if I try to visit (/api) it return 404 not found and (/) path is working fine.\nHere is my default nginx file\n```\n`server {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n\n    root /var/www/html;\n\n    # Add index.php to the list if you are using PHP\n    index index.html index.htm index.nginx-debian.html;\n\n    server_name example.com;\n\n    location /api {\n            proxy_pass http://localhost:3000;\n            proxy_http_version 1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection 'upgrade';\n            proxy_set_header Host $host;\n            proxy_cache_bypass $http_upgrade;\n            try_files $uri $uri/ =404;\n        }\n\n    location / {\n        proxy_pass http://localhost:8081;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n        try_files $uri $uri/ =404;\n    }\n}\n`\n```\nWhat I am doing wrong. Any help will be apricated. thanks",
      "solution": "After Doing a lot of googling and tried many ways I have found the solution and instead of using react app as dynamic loading i generated a build of react and stored that build on a particular location and served these build files on main location with nginx.\n```\n`location / {\n            root /home/user/gui/build;\n            try_files $uri /index.html;\n        }\n   \nlocation /api/ {\n        proxy_pass http://localhost:3002/;\n        proxy_redirect off;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n\nlocation /static/ {\n        root  /home/user/gui;\n        try_files\n            /gui/build$uri\n            =404;\n    }\n`\n```\nSo here (/) will try files in the root folder which is here (/home/user/gui/build) and we have index.html which is generated by react build this index.html will be served. Now the next problem was to serve react generated static files so i have created a separate location (/static/) with the same logic of / path.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-02-13T12:51:59",
      "url": "https://stackoverflow.com/questions/66184795/multiple-location-in-nginx-is-not-working-error-404"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 66028707,
      "title": "unknown directive &quot;location /&quot; (inside server block)",
      "problem": "I'm getting the following error from a seemingly valid nginx configuration:\n`nginx: [emerg] unknown directive \"location\u00a0/\" in /etc/nginx/conf.d/default.conf:49`\nHere's the relevant part of my `default.conf`:\n```\n`upstream channels-backend {\n    server api:5000;\n}\n\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name _;\n    server_tokens off;\n\n    location = /.well-known/acme-challenge/ {\n        root /var/www/certbot;\n    }\n\n    location / {\n        return 301 https://$host$request_uri;\n    }\n}\n\nserver {\n    listen 443 ssl default_server;\n    server_name _;\n    server_tokens off;\n\n    ssl_certificate /etc/letsencrypt/live/mydomain.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/mydomain.com/privkey.pem;\n    # include /etc/letsencrypt/options-ssl-nginx.conf;\n    # ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n    # ssl_password_file /etc/letsencrypt/live/mydomain.com/global.pass;\n    ssl_session_cache shared:SSL:10m;\n    ssl_session_timeout 10m;\n    ssl_protocols TLSv1.2 TLSv1.1;\n\n    access_log /var/log/nginx/access.log;\n    underscores_in_headers on;\n\n    location = /favicon.ico {\n        access_log off;\n        log_not_found off;\n    }\n\n    location /static {\n        alias /home/docker/code/static;\n    }\n\n    location\u00a0/ {  # this is line 49\n        try_files $uri @proxy_to_app;\n    }\n\n    location @proxy_to_app {\n        proxy_read_timeout 30;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $http_x_forwarded_proto;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-Host $server_name;\n        proxy_redirect off;\n        proxy_pass http://channels-backend;\n    }\n}\n`\n```\nMy problem is different from nginx : unknown directive \"location\" because the directive is located inside a `server` block.\nNote that \"mydomain.com\" has been replaced with my actual domain, and that almost identical configurations have worked many times before. The main differences between this configuration and previous configurations are that the `ssl_certificate*` settings point to a different location, and there's no `/.well-known/acme-challenge/` because I haven't used certbot/let's encrypt in nginx/docker before.\nAny ideas?",
      "solution": "In the error message:\n\nnginx: [emerg] unknown directive \"location /\" in /etc/nginx/conf.d/default.conf:49\n\nNginx is reading the quoted text as a single directive, so it has not recognise the gap between the `location` and `/` parts.\nThe gap should be a white-space character (e.g. ASCII space 20h). It's very probably that you are missing a space separator or your editor has inserted an invisible formatting character that is not a normal ASCII space.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-02-03T14:38:45",
      "url": "https://stackoverflow.com/questions/66028707/unknown-directive-location-inside-server-block"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 65922227,
      "title": "Nifi on docker behind nginx processor configure not opening",
      "problem": "Followed guide ( https://michalklempa.com/2019/04/nifi-registry-nginx-proxy-tls-basic-auth/ ) to set up nginx basic auth, however instead of proxy for nifi-registry I set it up for nifi. Auth is working and page is accessible but somehow processor configure window not opening. The issue is due to nginx since direct access to nifi through HTTP exposed ports works ,just not behind nginx proxy.\nbelow is the config I am using:\n```\n`server {\n  listen 9988 ssl;\n\n  root /usr/share/nginx/html;\n\n  index index.html;\n\n  server_name _;\n\n  ssl_certificate /etc/nginx/server_cert.pem;\n  ssl_certificate_key /etc/nginx/server_key.pem;\n\n  ssl_client_certificate /etc/nginx/client_cert.pem;\n  ssl_verify_client optional;\n\n  ssl_protocols TLSv1 TLSv1.1 TLSv1.2;\n  # enables server-side protection from BEAST attacks\n  ssl_prefer_server_ciphers on;\n\n  # Disabled insecure ciphers suite. For example, MD5, DES, RC4, PSK\n  ssl_ciphers \"ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA:DHE-RSA-AES128-SHA:ECDHE-RSA-DES-CBC3-SHA:EDH-RSA-DES-CBC3-SHA:AES256-GCM-SHA384:AES128-GCM-SHA256:AES256-SHA256:AES128-SHA256:AES256-SHA:AES128-SHA:DES-CBC3-SHA:HIGH:!aNULL:!eNULL:!EXPORT:!DES:!MD5:!PSK:!RC4:@STRENGTH\";\n\n  # -!MEDIUM\uff1aexclude encryption cipher suites using 128 bit encryption.\n  # -!LOW\uff1a   exclude encryption cipher suites using 64 or 56 bit encryption algorithms\n  # -!EXPORT\uff1a exclude export encryption algorithms including 40 and 56 bits algorithms.\n  # -!aNULL\uff1a  exclude the cipher suites offering no authentication. This is currently the anonymous DH algorithms and anonymous ECDH algorithms.\n  # These cipher suites are vulnerable to a \"man in the middle\" attack and so their use is normally discouraged.\n  # -!eNULL\uff1aexclude the \"NULL\" ciphers that is those offering no encryption.\n  # Because these offer no encryption at all and are a security risk they are disabled unless explicitly included.\n  # @STRENGTH\uff1asort the current cipher list in order of encryption algorithm key length.\n\n  location / {\n    if ($ssl_client_verify = SUCCESS) {\n      set $auth_basic off;\n    }\n    if ($ssl_client_verify != SUCCESS) {\n      set $auth_basic \"Restricted Content. Please provide Nifi Authentication:\";\n    }\n\n    auth_basic $auth_basic;\n    auth_basic_user_file /etc/nginx/nginx.htpasswd;\n\n    proxy_pass    http://172.18.0.77:8181/; # actual container ip/port of nifi\n    proxy_set_header   Host                 $host;\n    proxy_set_header   X-Real-IP            $remote_addr;\n    proxy_set_header   X-Forwarded-For      $proxy_add_x_forwarded_for;\n    proxy_set_header   X-Forwarded-Proto    $scheme;\n    proxy_set_header   X-Forwarded-User     $remote_user;\n    proxy_set_header   Authorization        \"\";\n    proxy_set_header   X-ProxyScheme        $scheme;\n    proxy_set_header   X-ProxyHost          $hostname;\n    proxy_set_header   X-ProxyPort          $server_port;\n    proxy_set_header   X-ProxyContextPath   \"/\";\n  }\n}\n`\n```\nI tried passing container ip of nifi/host/nginx for X-ProxyHost but instead of giving \"Unable to communicate to nifi\" immediately it spins for a while and eventually gives the same error. What needs to be modified here? Any help would be appreciated.",
      "solution": "nginx noob here!\nAfter much fiddling with multiple ip/hostname combinations I was able to fix it with below config changes.\nHad to add nifi env properties to the docker-compose:\n```\n`environment:\n  - NIFI_REMOTE_INPUT_HOST=\n  - NIFI_WEB_PROXY_CONTEXT_PATH=/\n  - NIFI_WEB_HTTP_HOST=\n  - NIFI_WEB_HTTP_PORT=8181\n`\n```\nAnd for nginx config: modified proxy_set_header to \"localhost\" (since nginx server needed proxyHost defined as loopback server):\n```\n`proxy_set_header X-ProxyHost localhost;\n`\n```\nHope this helps someone scratching their head who are in the same boat :)",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-01-27T16:26:42",
      "url": "https://stackoverflow.com/questions/65922227/nifi-on-docker-behind-nginx-processor-configure-not-opening"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 65708913,
      "title": "Do I need to create my own nginx.conf file to run this docker-composer.yml file succesfully?",
      "problem": "I am trying to get a nextcloud + mariadb + nginx docker-compose up and running locally, but I am stuck when it comes to the nginx.conf file. I am following this guide at the base-fpm section. Here is the docker-compose.yml file, what I ran in my CLI and the error i got:\n`version: '2'\nvolumes:\n  nextcloud:\n  db:\nservices:\n  db:\n    image: mariadb\n    restart: always\n    command: --transaction-isolation=READ-COMMITTED --binlog-format=ROW\n    volumes:\n      - db:/var/lib/mysql\n    environment:\n      - MYSQL_ROOT_PASSWORD=mypw\n      - MYSQL_PASSWORD=mypw\n      - MYSQL_DATABASE=nextcloud\n      - MYSQL_USER=nextcloud\n  app:\n    image: nextcloud:fpm\n    restart: always\n    links:\n      - db\n    volumes:\n      - nextcloud:/var/www/html\n    environment:\n      - MYSQL_PASSWORD=mypw\n      - MYSQL_DATABASE=nextcloud\n      - MYSQL_USER=nextcloud\n      - MYSQL_HOST=db\n  web:\n    image: nginx\n    restart: always\n    ports:\n      - 8080:80\n    links:\n      - app\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n    volumes_from:\n      - app\n`\n```\n`$ docker-compose up\nCreating network \"nextcloud_default\" with the default driver\nCreating volume \"nextcloud_nextcloud\" with default driver\nCreating volume \"nextcloud_db\" with default driver\nCreating nextcloud_db_1 ... done\nCreating nextcloud_app_1 ... done\nCreating nextcloud_web_1 ... error\n\nERROR: for nextcloud_web_1  Cannot start service web: OCI runtime create failed: \ncontainer_linux.go:370: starting container process caused: process_linux.go:459: container init \ncaused: rootfs_linux.go:59: mounting \"/home/nowak/docker/nextcloud/nginx.conf\" to rootfs at \n\"/var/lib/docker/overlay2/4869db7f0302ec8b7e5f4328b861e64627daa78728d443913052cecd1cd095a9/merge\nd/etc/nginx/nginx.conf\" caused: not a directory: unknown: Are you trying to mount a directory \nonto a file (or vice-versa)? Check if the specified host path exists and is the expected type\n\nERROR: for web  Cannot start service web: OCI runtime create failed: container_linux.go:370: \nstarting container process caused: process_linux.go:459: container init caused: \nrootfs_linux.go:59: mounting \"/home/nowak/docker/nextcloud/nginx.conf\" to rootfs at \n\"/var/lib/docker/overlay2/4869db7f0302ec8b7e5f4328b861e64627daa78728d443913052cecd1cd095a9/merge\nd/etc/nginx/nginx.conf\" caused: not a directory: unknown: Are you trying to mount a directory \nonto a file (or vice-versa)? Check if the specified host path exists and is the expected type\nERROR: Encountered errors while bringing up the project.\n`\n```\nDo I need to create a nginx.conf file and place it in my work directory?\nThe guide does mention this:\n\nThe configuration for nginx is stored in the configuration file nginx.conf, that is mounted into the container. An example can be found in the examples section here.\n\nBut when I follow that link, I can't seem to find any example of nginx.conf files.",
      "solution": "Looks like other people are also searching for the file, so I'll add the link from my comment to the right file here:\nhttps://github.com/nextcloud/docker/blob/master/.examples/docker-compose/with-nginx-proxy/mariadb/fpm/web/nginx.conf",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-01-13T20:55:22",
      "url": "https://stackoverflow.com/questions/65708913/do-i-need-to-create-my-own-nginx-conf-file-to-run-this-docker-composer-yml-file"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 65656728,
      "title": "Will Nginx health check work when upstream servers are again being proxied?",
      "problem": "I have the following Nginx setup:\n```\n`\n# nginx load balancer\nupstream web_app {\n    server localhost:7021; # nginx1\n    server localhost:7031; # nginx2\n}\n\nserver {\n  listen 7777 ssl;\n  server_name localhost 0.0.0.0;;\n\n  client_max_body_size 25m;\n  gzip on;\n  gzip_vary on;\n  gzip_min_length 10240;\n  gzip_proxied expired no-cache no-store private auth;\n  gzip_types text/plain text/css text/xml text/javascript application/x-javascript application/javascript application/xml;\n  gzip_disable \"MSIE [1-6]\\.\";\n\n location / {\n    proxy_set_header   X-Real-IP        $remote_addr;\n    proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;\n    proxy_set_header   X-Forwarded-Proto $scheme;\n    proxy_set_header   Host             $http_host;\n\n    proxy_pass https://web_app;\n    proxy_read_timeout 600s;\n    proxy_send_timeout 600s;\n    proxy_connect_timeout 600s;\n    send_timeout 600s;\n  }\n\n}\n\n# nginx1\nserver {\n  listen 7021 ssl;\n  server_name localhost 0.0.0.0;\n\n  client_max_body_size 25m;\n  gzip on;\n  gzip_vary on;\n  gzip_min_length 10240;\n  gzip_proxied expired no-cache no-store private auth;\n  gzip_types text/plain text/css text/xml text/javascript application/x-javascript application/javascript application/xml;\n  gzip_disable \"MSIE [1-6]\\.\";\n\n  location / {\n    proxy_set_header   X-Real-IP        $remote_addr;\n    proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;\n    proxy_set_header   X-Forwarded-Proto $scheme;\n    proxy_set_header   Host             $host;\n\n    proxy_pass http://localhost:7001; # process1\n    proxy_read_timeout 600s;\n    proxy_send_timeout 600s;\n    proxy_connect_timeout 600s;\n    send_timeout 600s;\n  }\n}\n\n# nginx2\nserver {\n  listen 7031 ssl;\n  server_name localhost 0.0.0.0;\n\n  client_max_body_size 25m;\n  gzip on;\n  gzip_vary on;\n  gzip_min_length 10240;\n  gzip_proxied expired no-cache no-store private auth;\n  gzip_types text/plain text/css text/xml text/javascript application/x-javascript application/javascript application/xml;\n  gzip_disable \"MSIE [1-6]\\.\";\n\n  location / {\n    proxy_set_header   X-Real-IP        $remote_addr;\n    proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;\n    proxy_set_header   X-Forwarded-Proto $scheme;\n    proxy_set_header   Host             $http_host;\n\n    proxy_pass http://localhost:7011; # process2\n    proxy_read_timeout 600s;\n    proxy_send_timeout 600s;\n    proxy_connect_timeout 600s;\n    send_timeout 600s;\n  }\n}\n`\n```\nThe load balancer has an upstream group which is again Nginx processes\nEach Nginx process proxies to an application process\n```\n`                   Nginx Load Balancer\n                           /     \\\n                          /       \\\n                       Nginx1   Nginx2\n                         |         |\n                       Process1   Process2\n\n`\n```\nThe problem here is that even when one of the processes is not running the load balancer sends requests to that upstream server causing issues.\nI assume this is happening as the Nginx health check only performs checks for the immediate upstream server and not any proxies.\ni.e.\nIf process2 is stopped the load balancer only checks the health of the Nginx process at localhost:7031 and not any proxies from localhost:7031\nI want health check to be done at the application process level ie @ localhost:7001 and localhost:7011",
      "solution": "Figured out the issue.\nThe health check were not happening as I expected as the app process was returning 502 in my case.\nI had to set `proxy_next_upstream error timeout http_502`\nto handle 502\nhttps://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_next_upstream\nFinal Nginx LB conf\n```\n`# nginx load balancer\nupstream web_app {\n    server localhost:7021; # nginx1\n    server localhost:7031; # nginx2\n}\n\nserver {\n  listen 7777 ssl;\n  server_name localhost 0.0.0.0;;\n\n  client_max_body_size 25m;\n  gzip on;\n  gzip_vary on;\n  gzip_min_length 10240;\n  gzip_proxied expired no-cache no-store private auth;\n  gzip_types text/plain text/css text/xml text/javascript application/x-javascript application/javascript application/xml;\n  gzip_disable \"MSIE [1-6]\\.\";\n\n location / {\n    proxy_set_header   X-Real-IP        $remote_addr;\n    proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;\n    proxy_set_header   X-Forwarded-Proto $scheme;\n    proxy_set_header   Host             $http_host;\n\n    proxy_pass https://web_app;\n    proxy_next_upstream error timeout http_502;\n    proxy_read_timeout 600s;\n    proxy_send_timeout 600s;\n    proxy_connect_timeout 600s;\n    send_timeout 600s;\n  }\n\n}\n`\n```",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-01-10T19:11:06",
      "url": "https://stackoverflow.com/questions/65656728/will-nginx-health-check-work-when-upstream-servers-are-again-being-proxied"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-config",
      "question_id": 65608619,
      "title": "Nginx - Reverse proxy all requests starting with a keyword",
      "problem": "I want to redirect all requests starting with \"mydomain/_dash\" to \"mydomain:8050/_dash\" so that \"mydomain/_dash-component-suites/\" redirects to \"mydomain:8050/_dash-component-suites/\". I have added the following directive but it doesn't work. Plus, I also want to maintain the headers of each request.\n```\n`location /_dash(.*)$ {\n    proxy_set_header Host $http_host;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Scheme $scheme;\n\n    client_max_body_size 0;\n    \n    proxy_pass http://analytics:8050/_dash(*);\n  }\n`\n```",
      "solution": "You need to use regular expressions:\n```\n`location ~ /_dash(.*)$ {\n    proxy_set_header Host $http_host;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Scheme $scheme;\n\n    client_max_body_size 0;\n    \n    proxy_pass http://analytics:8050/_dash$1;\n  }\n`\n```",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-01-07T09:02:59",
      "url": "https://stackoverflow.com/questions/65608619/nginx-reverse-proxy-all-requests-starting-with-a-keyword"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 68714556,
      "title": "Nginx proxy manager is not being able to serve the page from another docker container",
      "problem": "I am trying for nginx proxy manager (running in a docker container) to connect to another docker container that has port 8080 open on it. When I setup the proxy to connect to `192.168.0.29:8080` the ip address of the host, but it doesn't work, the browser just says that the site didn't send any data.\nI tried setting up the reverse proxy with other services (that weren't running inside a docker container), and they worked flawlessly. So, I've concluded, the problem is something with the docker containers.\nFirst, I tried replacing the ip address with the address of the container (shown in portainer) which showed to be `172.17.0.2`. But, that didn't work. I can confirm that both containers are in the same network, `bridge`.\nI could not find any solutions for this problem either here, at Stack Overflow, or anywhere else. Hope there's enough data to solve this problem. Thanks ahead of time!\nEdit:\nrunning `arp -na` from within the container gives this output:\n`[root@docker-00244f7ab2cc:/app]# arp -na\n? (172.17.0.1) at 02:42:d1:fc:fc:6b [ether] on eth0\n`",
      "solution": "You simply need to set both NGINXPM and your containers on the same non-default bridge network (Default bridge cant resolve hostnames which are easier to work with). Setting your containers on the host networks is not recommended since they are no longer isolated from the rest of your network.",
      "question_score": 5,
      "answer_score": 3,
      "created_at": "2021-08-09T17:19:08",
      "url": "https://stackoverflow.com/questions/68714556/nginx-proxy-manager-is-not-being-able-to-serve-the-page-from-another-docker-cont"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 66286042,
      "title": "Nginx reverse proxy for Angular apps",
      "problem": "I have created a reverse proxy using Nginx which redirects in various applications (ASP.NET API's and Angular app's).\nReverse proxy nginx.conf (the most important settings):\n```\n`...\nserver {\n    listen 80;\n    server_name localhost 127.0.0.1;\n\n    location /projects/sample-app1/api {\n        proxy_pass http://sample-app1-api:80;\n    }\n\n    location /projects/sample-app1 {\n        # Angular app\n        proxy_pass http://sample-app1:80;\n    }\n\n    location /projects/sample-app2 {\n        # Angular app \n        proxy_pass http://sample-app2:80;\n    }\n\n    location /api {\n        proxy_pass http://random-api:80;\n    }\n\n    location / {\n        proxy_pass http://personal-app:80;\n    }\n}\n`\n```\nAll API's are available and work properly because their path indicated by the location parameter is the same as in the controllers. An Angular application that runs on the url \"/\" also works, but the problem is with \"sample-app1\" and \"sample-app2\". When I type the url to go to these applications, I get an error similar to:\n```\n`Uncaught SyntaxError: Unexpected token My suspicion is that the URL leading to the application contains additional elements (/projects/sample-app1) and its default index path is simply \"/\". So I would have to rewrite to remove the redundant part of the URL, but how to do it? My attempts so far have not been successful and I have tried different ways from other threads on StackOverflow and Github.\nAngular App nginx.conf:\n```\n`events{}\nhttp {\n   include /etc/nginx/mime.types;\n\n   server {\n       listen 80;\n       server_name localhost;\n       root /usr/share/nginx/html;\n       index index.html;\n\n       location / {\n           try_files $uri $uri/ /index.html;\n       }\n   }\n`\n```\n}",
      "solution": "Part of the solution is the response of the user: Esmaeil Mazahery, but a few more steps must be taken.\nFirst, I changed the Angular application Dockerfile (passed additional build parameters like: base-href and deploy-url)\n```\n`RUN npm run ng build -- --prod --base-href /projects/sample-app1/ --deploy-url /projects/sample-app1/\n`\n```\nThen, I changed the reverse proxy nginx.conf configuration from\n```\n`location /projects/sample-app1 {\n    # Angular app\n    proxy_pass http://sample-app1:80;\n}\n`\n```\nto:\n```\n`location /projects/sample-app1 {\n    # Angular app\n    proxy_pass http://sample-app1:80/;\n}\n`\n```\nRedirection did not work properly without a slash at the end.\nThe order in which nginx redirects are matched is also important. Therefore, before the addresses: `/projects/sample-app1` and `/projects/sample-app2` I put the symbol `^~`, which causes the given locations to be taken first. This nginx localization simulation tool also proved very useful: Nginx location match tester",
      "question_score": 4,
      "answer_score": 3,
      "created_at": "2021-02-19T23:51:17",
      "url": "https://stackoverflow.com/questions/66286042/nginx-reverse-proxy-for-angular-apps"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 67570998,
      "title": "Why is X-Forwarded-Proto always set to HTTP on Elastic Beanstalk?",
      "problem": "Setup\nHi. I'm deploying an ASP.Net Core application to AWS Elastic Beanstalk. The platform I'm running on is 64bit Amazon Linux 2/2.1.5 using Nginx as the proxy server software. I've got a pair of listeners for my load balancer set up in the environment configuration. They are set up as follows:\n\n`Port=443 Protocol=HTTPS SSL=certificate Process=default`\n`Port=80 Protocal=HTTP Process=default`\n\nAnd I've got a single process:\n`Name=default Port=80 Protocol=HTTPS`\nProblem\nOn my ASP.Net Core server, I'm trying to check if the original client to the server is communicating over HTTPS or HTTP. As I understand, the `X-Forwarded-Proto` header for requests should carry this information. However, the value of `X-Forwarded-Proto` is always `http` regardless of how a client connects to the server. Why is the `X-Forwarded-Proto` not ever set to `https` even when connected as so from my web browser?\nThanks in advance for any help!",
      "solution": "The problem was in the Nginx configuration as pointed out by @MarkB. AWS Elastic Beanstalk has a default configuration file `00_application.conf` in `/etc/nginx/conf.d/elasticbeanstalk` that is the culprit. It has a declaration:\n```\n`proxy_set_header    X-Forwarded-Proto     $scheme;\n`\n```\nthat needed to be changed to:\n```\n`proxy_set_header    X-Forwarded-Proto     $http_x_forwarded_proto;\n`\n```\n\nTo overwrite this file, I used the method detailed here: https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/platforms-linux-extend.html.\nI added a file `.platform/nginx/conf.d/elasticbeanstalk` to the root of my deployed project. It contains:\n```\n`location / {\n    proxy_pass          http://127.0.0.1:5000;\n    proxy_http_version  1.1;\n    proxy_cache_bypass  $http_upgrade;\n    proxy_set_header    Upgrade               $http_upgrade;\n    proxy_set_header    Connection            $http_connection;\n    proxy_set_header    Host                  $host;\n    proxy_set_header    X-Forwarded-For       $proxy_add_x_forwarded_for;\n    proxy_set_header    X-Forwarded-Proto     $http_x_forwarded_proto;\n}\n`\n```\n\nI also had to add a middleware to my ASP.Net Core application to use the forwarded headers as noted in this answer: Redirect URI sent as HTTP and not HTTPS in app running HTTPS.\nI added the following to my `Startup.cs`:\n`public void ConfigureServices(IServiceCollection services)\n{\n    //...\n    services.Configure(options =>\n    {\n        options.ForwardedHeaders =\n            ForwardedHeaders.XForwardedFor |\n            ForwardedHeaders.XForwardedProto;\n        options.KnownNetworks.Clear();\n        options.KnownProxies.Clear();\n    });\n    //...\n}\npublic void Configure(IApplicationBuilder app, IWebHostEnvironment env)\n{\n    //...\n    app.UseForwardedHeaders();\n    //...\n}\n`\nI hope this helps others!",
      "question_score": 3,
      "answer_score": 12,
      "created_at": "2021-05-17T15:48:33",
      "url": "https://stackoverflow.com/questions/67570998/why-is-x-forwarded-proto-always-set-to-http-on-elastic-beanstalk"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 65837046,
      "title": "How to get nginx to do a redirect to url-encoded query parameter",
      "problem": "I have a requirement to do a proxy call to url delivered via a query parameter as per example:\nMy nginx proxy is deployed at: `https://myproxy.net`\nif the redirect parameter is not url encoded I can do the call with this block:\n```\n`  location /basepath {\n        if ( $arg_redirect = '') { \n          return 400 \"Missing redirect directive in request\"; \n        }\n        proxy_pass $arg_redirect;\n        proxy_intercept_errors on;\n        error_page 301 302 307 = @handle_redirects;\n    }\n\n`\n```\nthe error intercepts and @handle_redirects then take care of othe 30X codes that might pop up at new destination.\nThis works for a request:\n`GET`: `https://myproxy.net/basepath?redirect=https://destination.com/somepath/uuid`\nWhat do I need to do to make it work for:\n`GET`: `https://myproxy.net/basepath?redirect=https%3A%2F%2Fdestination.com%2Fsomepath%2Fuuid`\nAdditionally as part of spec it has to be pure nginx, not additional modules, lua etc.\nThanks!",
      "solution": "Actually, `proxy_pass` does normalisation by default, but it only affects `$uri` part. Thus you only need to decode the beginning of the passed string to get it working:\n```\n`  location / {\n    if ( $arg_redirect = '') {\n      return 400 \"Missing redirect directive in request\";\n    }\n    if ( $arg_redirect ~ (.+)%3A%2F%2F(.+) ){ # fix :// between scheme and destination\n      set $arg_redirect $1://$2;\n    }\n    if ( $arg_redirect ~ (.+?)%3A(.*) ){ # fix : between destination and port\n      set $arg_redirect $1:$2;\n    }\n    if ( $arg_redirect ~ (.+?)%2F(.*) ){ # fix / after port, the rest will be decoded by proxy_pass\n      set $arg_redirect $1/$2;\n    }\n    proxy_pass $arg_redirect;\n  }\n`\n```\nWith the above I managed to access `http://localhost/?redirect=http%3A%2F%2F127.0.0.1%3A81%2Fsfoo%20something%2Fs`\nThe solution seems dirty and the only alternative using default modules is `map` (even less cleaner in my opinion). I'd rather split `redirect` argument into pieces: scheme (http or https), destination, port, and uri. With that you would be able to construct full address without rewriting:\n```\n`proxy_pass $arg_scheme://$arg_dest:$arg_port/$arg_uri\n`\n```",
      "question_score": 3,
      "answer_score": 5,
      "created_at": "2021-01-22T00:04:42",
      "url": "https://stackoverflow.com/questions/65837046/how-to-get-nginx-to-do-a-redirect-to-url-encoded-query-parameter"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 72707854,
      "title": "google analytics 4 reverse proxy with nginx",
      "problem": "I have a mostly working nginx reverse proxy to handle interfacing with ga4.\nThe problem I have, is that the geolocation data of visitors to my site all comes from ashburn virginia (where my alb lives).\nHere is my nginx config with site-specific data edited:\n```\n`events {\n    worker_connections 4096;\n}\n\nhttp {\n    set_real_ip_from 10.1.20.0/24;\n    set_real_ip_from 10.1.30.0/24;\n    real_ip_header X-Forwarded-For;\n\n    log_format main '$remote_addr - $remote_user [$time_local] \"$request\" '\n                    '$status $body_bytes_sent \"$http_referrer\" '\n                    '\"$http_user_agent\" \"$http_x_forwarded_for\" ';\n\n    access_log /var/log/nginx/access.log main;\n    error_log /var/log/nginx/error.log notice;\n    rewrite_log on;\n\n    server {\n        listen 80;\n        server_name _;\n        client_max_body_size 500M;\n        location / {\n            include uwsgi_params;\n            uwsgi_pass 0.0.0.0:8000;\n        }\n\n        location /workaround-ga4/ {\n            resolver 8.8.8.8;\n            proxy_set_header X-real-ip $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            rewrite /workaround-ga4/([^/]+) /g/collect?$args&uip=$remote_addr break;\n            proxy_pass https://www.google-analytics.com;\n        }\n    }\n}\n`\n```\nI can see in my error_log which catches and debugs the nginx rewrites, the following two entries:\n```\n`2022/06/21 22:03:36 [notice] 528#528: *1165 \"/workaround-ga4/([^/]+)\" matches \"/workaround-ga4/g/collect\", client: 555.555.555.555, server: _, request: \"POST /workaround-ga4/g/collect?v=2&tid=G-MYGOOGLEANALYTICSCODE&gtm=555555&_p=555555555&_z=55555&cid=555555555.5555555555&ul=en-us&sr=5555x555&sid=5555555555&sct=55&seg=5&dl=https%3A%2F%2Fmy.site.com%2F&dt=my%20site%20which%20%7C%20is%20having%20trouble%20with%20googleanalytics&_s=1 HTTP/1.1\", host: \"my-site.com\", referrer: \"https://my-site.com/\"\n`\n```\nand\n```\n`2022/06/21 22:03:36 [notice] 528#528: *1165 rewritten data: \"/g/collect\", args: \"v=2&tid=G-MYGOOGLEANALYTICSCODE&gtm=555555&_p=555555555&_z=5555555&cid=555555555.5555555555&ul=en-us&sr=5555x555&sid=5555555555&sct=55&seg=5&dl=https%3A%2F%2Fmy-site.com%2F&dt=my%20site%20is%20%7C%20having%20problems%20with%20google%20analytics&_s=1&uip=my.real.ip/&v=2&tid=G-MYGOOGLEANALYTICSCODE&gtm=555555&_p=5555555555&_z=555555&cid=5555555555.5555555555&ul=en-us&sr=5555x555&sid=5555555555&sct=55&seg=5&dl=https%3A%2F%2Fmy-site.com%2F&dt=my%20site%20is%20%7C%20having%20trouble%20with%20google%20analytics&_s=1\", client: my.actual.ip, server: _, request: \"POST /workaround-ga4/g/collect?v=2&tid=G-MYGOOGLECODE&gtm=555555&_p=5555555555&_z=555555&cid=5555555555.5555555555&ul=en-us&sr=5555x555&sid=5555555555&sct=55&seg=5&dl=https%3A%2F%2Fmy-site.com%2F&dt=my%20site%20is%20%7C%20having%20trouble%20with%20google%20analytics&_s=1 HTTP/1.1\", host: \"my-site.com\", referrer: \"https://my-site.com/\"\n`\n```\nWhich to me suggests that the rewrite is working as intended - the `uip` parameter is being set to the real ip address of the visitor, and not the 10.1.x ip of my albs.\nmy ga4 events and page views are firing as expected - but geolocation shows everyone as coming from ashburn.\nwhat am I missing/not understanding?\nI should note that for performances' sake my google analytics js library is loaded locally with my webapp, and not included in this proxy business (though has been edited to point all google analytics api calls to mydomain.com/workaround-ga4/).\nAny help is greatly appreciated :)",
      "solution": "OK. Turns out GA4 does not yet officially support the `uip` parameter in the URL.\nHowever, Google prefixes alpha/beta URL parameters with `_`. Changing `&uip=$remote_addr` in my `proxy_pass` to `&_uip=$remote_addr` did the trick.\n**Note this is a temporary solution, and will break if/once Google decides to officially support the `uip` parameter, or otherwise decides to change the API.",
      "question_score": 3,
      "answer_score": 6,
      "created_at": "2022-06-22T00:43:48",
      "url": "https://stackoverflow.com/questions/72707854/google-analytics-4-reverse-proxy-with-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 69218786,
      "title": "ERROR: cannot start nginx as networking would not start on alpine docker image",
      "problem": "We are trying to install and run nginx on java based alpine image (`anapsix/alpine-java:7_jdk`) but we are facing below error when we start it\n```\n`rc-service nginx start\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/blkio/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/cpu/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/cpu,cpuacct/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/cpuacct/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/cpuset/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/devices/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/freezer/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/hugetlb/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/memory/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/net_cls/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/net_cls,net_prio/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/net_prio/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/perf_event/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/pids/tasks: Read-only file system\n/lib/rc/sh/openrc-run.sh: line 250: can't create /sys/fs/cgroup/systemd/tasks: Read-only file system\n * Starting networking ...\nawk: /etc/network/interfaces: No such file or directory\n * ERROR: networking failed to start\n * ERROR: cannot start nginx as networking would not start\n`\n```\nWe have tried many articles but nowhere it is mentioned that how to fix networking issue with the nginx on this alpine based image. Even if we create `/etc/network/interfaces` file, we don't know what should be the correct values inside it. Below is what we are running Dockerfile\n```\n`# Add Nginx\nRUN apk --update add nginx openrc\nRUN mkdir -p /run/nginx\nRUN touch /run/nginx/nginx.pid\n# RUN adduser -D -g 'nginx' nginx\n# RUN mkdir /home/nginx\nRUN chown -R nginx:nginx /var/lib/nginx\n# RUN chown -R nginx:nginx /home/nginx\nCOPY birt.conf /etc/nginx/conf.d/birt.conf\n# COPY index.html /nginx\nRUN openrc\nRUN touch /run/openrc/softlevel\nRUN rc-update add nginx default\n`\n```\nPlease help us to achieve this.",
      "solution": "I managed to get Nginx to work within `anapsix/alpine-java:7_jdk` image after seeing this amazing answer.\nHere is a working Dockerfile :\n```\n`FROM anapsix/alpine-java:7_jdk\n\nCOPY script.bash .\n\nRUN apk --update add nginx openrc\nRUN openrc\nRUN touch /run/openrc/softlevel\n\nCMD bash ./script.bash\n`\n```\nand here is the `script.bash` used in `CMD` :\n```\n`#!/bin/bash\n\n# Tell openrc loopback and net are already there, since docker handles the networking\necho 'rc_provide=\"loopback net\"' >> /etc/rc.conf\n\n# get inside the container bash\nbash\n`\n```\nafter building the image using `docker build . -t nginx_alpine_java` run the following commands :\n`docker run -it -p 80:80 nginx_alpine_java`\nnow we are inside our container bash\n```\n`bash-4.3# rc-service nginx status\n * status: stopped\n\nbash-4.3# rc-service nginx start\n * /run/nginx: creating directory\n * /run/nginx: correcting owner                                [ ok ]\n * Starting nginx ...                                          [ ok ]\n`\n```\nI hope that it will work with you.",
      "question_score": 3,
      "answer_score": 6,
      "created_at": "2021-09-17T08:36:30",
      "url": "https://stackoverflow.com/questions/69218786/error-cannot-start-nginx-as-networking-would-not-start-on-alpine-docker-image"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 78095252,
      "title": "getting 502 Bad Gateway from nginx when using nginx as reverse proxy while calling an API",
      "problem": "I have been trying to use nginx as a reverse proxy to one of my external REST GET API to debug latency issue b/w my golang service and the external service.\nI can easily call that public URL via golang's net/http library and get successful response, but when i use nginx as reverse proxy, nginx gives 502 Bad Gateway. In nginx-error.log file i get errors regarding SSL like below, but wonder how i dont get error while calling that API via golang net/http client.\nP.S: I have cross checked that nginx was running by creating a simple /ping-nginx API which just returns 200 statusCode and pong-nginx as response.\nping.go\n```\n`package main\n\nimport (\n    \"fmt\"\n    \"log\"\n    \"net/http\"\n    \"strconv\"\n)\n\nfunc main() {\n    http.HandleFunc(\"/ping-via-go-client\", func(w http.ResponseWriter, r *http.Request) {\n        url := \"https://flights-explorer.makemytrip.com/ping\"\n        resp, err := http.Get(url)\n        var statusCode string\n        if err == nil {\n            statusCode = strconv.Itoa(resp.StatusCode)\n        }\n        fmt.Fprintf(w, \"pong-via-go-client with statusCode:\"+statusCode)\n    })\n\n    http.HandleFunc(\"/ping-via-nginx\", func(w http.ResponseWriter, r *http.Request) {\n        url := \"http://localhost/ping\"\n        resp, err := http.Get(url)\n        var statusCode string\n        if err == nil {\n            statusCode = strconv.Itoa(resp.StatusCode)\n        }\n        fmt.Fprintf(w, \"pong-via-nginx with statusCode:\"+statusCode)\n    })\n\n    log.Fatal(http.ListenAndServe(\":3003\", nil))\n}\n`\n```\nresponse of curls:\n```\n`\u279c  ~ curl http://localhost:3003/ping-via-go-client\npong-via-go-client with statusCode:200%\n\u279c  ~ curl http://localhost:3003/ping-via-nginx\npong-via-nginx with statusCode:502%\n`\n```\nnginx.conf\n```\n`#user  nginx;\ndaemon off;\n\nworker_processes  auto;\n\nerror_log  /opt/logs/nginx-error.log warn;\npid        /var/run/nginx.pid;\nevents {\n    worker_connections  250;\n}\nhttp {\nlog_format upstream_time '$time_local $status $remote_addr to:- $upstream_addr $request '\n    'uct:$upstream_connect_time uht:$upstream_header_time urt:$upstream_response_time '\n    'request_time:$request_time tid_header:$http_tid status:$upstream_cache_status '\n    'slot:$http_slot slot_time:$http_slotstarttime ttl_req:$http_ttl ttl_resp:$upstream_http_x_accel_expires '\n    'job_flag:$http_jobflag cookies:\"$http_cookie\" bytes_sent:$bytes_sent gzip_ratio:$gzip_ratio '\n    '\"$http_referer\" \"$http_user_agent\" $http_x_forwarded_for cur_time:$msec';\n        keepalive_timeout 85;\n        upstream flights-explorer.makemytrip.com {\n              server flights-explorer.makemytrip.com:443;\n              keepalive 30;\n        }\n    server {\n        listen 80;\n        access_log /opt/logs/nginx-access.log upstream_time;\n                  location = /basic_status {\n                            stub_status;\n                  }\n\n        location /ping-nginx {\n            return 200 'pong-nginx\\n';\n            add_header Content-Type text/plain;\n        }\n\n        location /ping {\n               # proxy_buffering off;\n             proxy_pass https://flights-explorer.makemytrip.com$request_uri;\n             proxy_http_version 1.1;\n             proxy_set_header Connection \"\";\n             proxy_ssl_verify off;  # Disable SSL certificate verification\n             proxy_ssl_verify_depth 0;\n             #proxy_ssl_session_reuse on;\n             #proxy_socket_keepalive on;\n             proxy_connect_timeout 10s;\n             proxy_read_timeout 10s;\n        }\n\n    }\n}\n`\n```\nerrors in nginx-error.log\n```\n`2024/03/03 11:07:55 [error] 20078#0: *6 SSL_do_handshake() failed (SSL: error:0A000438:SSL routines::tlsv1 alert internal error:SSL alert number 80) while SSL handshaking to upstream, client: 127.0.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"https://23.63.110.25:443/ping\", host: \"localhost\"\n2024/03/03 11:07:55 [warn] 20078#0: *6 upstream server temporarily disabled while SSL handshaking to upstream, client: 127.0.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"https://23.63.110.25:443/ping\", host: \"localhost\"\n2024/03/03 11:07:55 [error] 20078#0: *6 SSL_do_handshake() failed (SSL: error:0A000438:SSL routines::tlsv1 alert internal error:SSL alert number 80) while SSL handshaking to upstream, client: 127.0.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"https://23.63.110.67:443/ping\", host: \"localhost\"\n2024/03/03 11:07:55 [warn] 20078#0: *6 upstream server temporarily disabled while SSL handshaking to upstream, client: 127.0.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"https://23.63.110.67:443/ping\", host: \"localhost\"\n2024/03/03 11:07:56 [error] 20078#0: *6 SSL_do_handshake() failed (SSL: error:0A000438:SSL routines::tlsv1 alert internal error:SSL alert number 80) while SSL handshaking to upstream, client: 127.0.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"https://23.63.110.74:443/ping\", host: \"localhost\"\n2024/03/03 11:07:56 [warn] 20078#0: *6 upstream server temporarily disabled while SSL handshaking to upstream, client: 127.0.0.1, server: , request: \"GET /ping HTTP/1.1\", upstream: \"https://23.63.110.74:443/ping\", host: \"localhost\"\n`\n```\nlogs at nginx-access.log\n```\n`03/Mar/2024:11:07:56 +0530 502 127.0.0.1 to:- 23.63.110.25:443, 23.63.110.67:443, 23.63.110.74:443 GET /ping HTTP/1.1 uct:-, -, - uht:-, -, - urt:0.131, 0.116, 0.107 request_time:0.354 tid_header:- status:- slot:- slot_time:- ttl_req:- ttl_resp:- job_flag:- cookies:\"-\" bytes_sent:314 gzip_ratio:- \"-\" \"Go-http-client/1.1\" - cur_time:1709444276.083\n`\n```",
      "solution": "Finally found a solution.\nThis blog clearly explains the need of Servername (SNI) demanded by the upstream (it can be validated using openssl command) and after making changes like it recommended, it's working for me without any issue.\nhttps://www.infiniroot.com/blog/1120/nginx-reverse-proxy-ssl-alert-number-40-while-ssl-handshaking-upstream\nP.S: i am posting the link directly instead of explaining bcz the author has explained everything in details and worth the read.\n@Steffen Ullrich had suggested this earlier but with the other two confs didn't let it work.",
      "question_score": 3,
      "answer_score": 4,
      "created_at": "2024-03-03T06:47:26",
      "url": "https://stackoverflow.com/questions/78095252/getting-502-bad-gateway-from-nginx-when-using-nginx-as-reverse-proxy-while-calli"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 74858837,
      "title": "invalid host in upstream NginX when used path in upstream",
      "problem": "```\n`upstream backend {\n  server domain1.com/path1;\n  server domain2.com/path/path2;\n  server domain3.com/pah3;\n}\nlocation @ {\n  proxy_pass https://backend;\n  proxy_ssl_trusted_certificate /etc/nginx/sslcerts/backend.server.pem;\n  proxy_ssl_verify              off;\n}\n`\n```\nwas trying to load balance traffic to all servers in backend, getting error as `invalid host in upstream ` is there any other way to configure nginX to meet this requirement.",
      "solution": "Upstream does not take paths.\nDon't know why you're using a named location here (@)?!\n```\n`upstream backend {\n  server domain1.com;\n  server domain2.com;\n  server domain3.com;\n}\nlocation / {\n  proxy_pass https://backend/path1;\n  proxy_ssl_trusted_certificate /etc/nginx/sslcerts/backend.server.pem;\n  proxy_ssl_verify              off;\n}\n`\n```\nYou have to use the same path on the backends or at least forward from this path to the right one..\nIf you rely on different paths and you can't touch the backend servers try this (hacky) work-around:\n```\n`\nupsteam virtualloadbalancer {\n    server 127.0.1.1;\n    server 127.0.1.2;\n    server 127.0.1.3;\n}\n\nserver {\n    listen 127.0.1.1;\n    location / {\n        proxy_pass http://domain1.com/path1;\n    }\n}\n\nserver {\n    listen 127.0.1.2;\n    location / {\n        proxy_pass http://domain2.com/path2/path;\n    }\n}\nserver {\n    listen 127.0.1.3;\n    location / {\n        proxy_pass http://domain3.com/path3;\n    }\n}\n\nserver {\n    listen 80;\n    location / {\n        proxy_pass http://virtualloadbalancer;\n        proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | http_429\n    }\n}\n\n`\n```",
      "question_score": 3,
      "answer_score": 4,
      "created_at": "2022-12-20T06:29:44",
      "url": "https://stackoverflow.com/questions/74858837/invalid-host-in-upstream-nginx-when-used-path-in-upstream"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 72784914,
      "title": "Nginx docker-compose forward traffic to my backend services",
      "problem": "I have services running in docker-compose and i want to reverse proxy to them using nginx\nHow do I reach my backend service through the proxy, at the moment Nginx not passing my request on to backend. I also want to strip out the `/api/search` before the request reaches the backend service (meilisearch)\n```\n`meilisearch    | [2022-07-11T14:00:02Z INFO  actix_server::server] Actix runtime found; starting in Actix runtime\nnginx          | 172.25.0.1 - - [11/Jul/2022:14:00:09 +0000] \"GET /api/search HTTP/1.1\" 301 169 \"-\" \"insomnia/2022.4.2\" \"-\"\nnginx          | 2022/07/11 14:00:09 [error] 31#31: *1 \"/etc/nginx/html/index.html\" is not found (2: No such file or directory), client: 172.25.0.1, server: _, request: \"GET /api/search/ HTTP/1.1\", host: \"127.0.0.1\"\nnginx          | 172.25.0.1 - - [11/Jul/2022:14:00:09 +0000] \"GET /api/search/ HTTP/1.1\" 404 153 \"-\" \"insomnia/2022.4.2\" \"-\"\n`\n```\nThis is the `reverse_proxy.conf` file\n```\n`server{\n    listen 80;\n    server_name _;\n    location /api/ {\n        location /api/search/ {            \n            proxy_pass http://meilisearch:7700; \n            rewrite ^/api/search(/.*) $1 last;           \n        } \n    }       \n}\n`\n```\nThis is the `docker-compose.yml` file\n```\n`version: '3'\nservices:\n  nginx:\n    image: nginx:1.23.0-alpine\n    hostname: nginx\n    container_name: nginx\n    networks:\n      - safedawanetwork \n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./reverse_proxy.conf:/etc/nginx/conf.d/default.conf\n  meilisearch:\n    image: getmeili/meilisearch:v0.28.0rc4\n    hostname: meilisearch\n    container_name: meilisearch\n    networks:\n      - safedawanetwork       \nnetworks:\n    safedawanetwork:\n        driver: bridge\n`\n```\nWhen I start the services with `sudo docker-compose up` and `curl localhost/api/search` I expect to see the meilisearch response but I don't. Whats going on",
      "solution": "This should be doable just using a proxy pass that ends with a slash (/).\nThis works since nginx omits the matching part of the location block:\n```\n`server{\n    listen 80;\n    server_name _;\n    location /api/ {\n        location /api/search/ {     \n            proxy_set_header   X-Real-IP $remote_addr;\n            proxy_set_header   Host      $http_host;\n            proxy_pass http://meilisearch:7700/;          \n        } \n    }       \n}\n`\n```\nA request looking like: `curl localhost/api/search/test123`\nwill result in a request within your search service that ends up looking like this:\n```\n`GET /test123 HTTP/1.0\n`\n```",
      "question_score": 3,
      "answer_score": 2,
      "created_at": "2022-06-28T12:36:10",
      "url": "https://stackoverflow.com/questions/72784914/nginx-docker-compose-forward-traffic-to-my-backend-services"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 77250028,
      "title": "Problem with loading jpg images in NextJS with NGINX over HTTPS",
      "problem": "For some reason when working through Nginx, jpg images are not loading. Although svg images work fine. Everything works via HTTP (127.0.0.1:3000), so the problem is in NGINX. I have no idea how to fix that. Im using Node v20, npm, nginx, nextjs v13.5.4\nNginx configuration:\n```\n`server {\n    server_name ylous.keenetic.link www.ylous.keenetic.link;\n\n    server_tokens off;\n\n    gzip on;\n    gzip_proxied any;\n    gzip_comp_level 4;\n    gzip_types text/css application/javascript image/svg+xml;\n\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection 'upgrade';\n    proxy_set_header Host $host;\n    proxy_cache_bypass $http_upgrade;\n\n    location / {\n        proxy_pass http://127.0.0.1:3000;\n    }\n\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/ylous.keenetic.link/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/ylous.keenetic.link/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n}\n\nserver {\n    if ($host = www.ylous.keenetic.link) {\n        return 301 https://$host$request_uri;\n        } # managed by Certbot\n\n        if ($host = ylous.keenetic.link) {\n            return 301 https://$host$request_uri;\n            } # managed by Certbot\n\n            listen 80;\n\n            server_name ylous.keenetic.link www.ylous.keenetic.link;\n            return 404; # managed by Certbot\n\n        }\n`\n```\nNext Image usage:\n```\n`\n`\n```\nExample request: https://ylous.keenetic.link/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsnicker.2ee2553c.jpg&w=640&q=75\nCode: 500\nResponse:  \"url\" parameter is valid but upstream response is invalid\nAll images are expected to load normally. Found someone on DigitalOcean with the same problem, he solved it but didn't provide the solution itself LOL",
      "solution": "```\n`proxy_http_version 1.1;\nproxy_set_header Upgrade $http_upgrade;\nproxy_set_header Connection 'upgrade';\nproxy_set_header Host $host;\nproxy_cache_bypass $http_upgrade;\n\nlocation / {\n    proxy_pass http://127.0.0.1:3000;\n    proxy_set_header X-Forwarded-Proto https;\n    proxy_set_header X-Url-Scheme $scheme;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header Host $http_host;        \n    proxy_redirect off;\n}\n`\n```\nEverything works. I will leave the question so that other people who encounter this problem can find a solution",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2023-10-07T15:44:57",
      "url": "https://stackoverflow.com/questions/77250028/problem-with-loading-jpg-images-in-nextjs-with-nginx-over-https"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 66375236,
      "title": "Getting a user&#39;s IP address in Laravel through Docker containers and Nginx webserver",
      "problem": "Good day,\nMy problem is that I am ONLY getting my Docker network IP address when using Laravel's `$request->ip()` or `$request->getClientIp ()` or `$request->server->get('REMOTE_ADDR')` or `$_SERVER['REMOTE_ADDR']` which essentially all do the same I assume.\nSo far the problem occurs on my local test pc (without Nginx Reverse Proxy) as well as on my live servers\nI hope I've supplied enough relevant info below, if not please let me know :) Thanks in advance!\nSo my setup is the following (simplified), both Nginx configs are pasted below as well:\n```\n`Server -> Nginx Reverse Proxy -> Docker Containers & Network (db, php, nginx, redis) -> Nginx Webserver  PHP-FPM\n`\n```\nSome results related to _SERVER:\n```\n`[SERVER_ADDR] => 172.20.0.3 (nginx webserver)\n[REMOTE_PORT] => 55378\n[REMOTE_ADDR] => 172.20.0.1 (docker network / gateway)\n[SERVER_SOFTWARE] => nginx/1.19.6\n`\n```\nI have read multiple forums and solutions for hours and hours while trying and changing configs etc. but none of it seems to be working.\nWhat I have tried:\n\nGet User IP address in laravel with similar method to HTTP_X_FORWARDED_FOR\nhttps://serverfault.com/questions/618456/getting-the-client-ip-when-passing-through-a-reverse-proxy\n\nSo I have also tried to set my \"Trusted Proxy\" in Laravel's `/Http/Middleware/TrustProxies.php` by allowing all: `protected $proxies = '*';`\nI also don't need these additional Laravel packages as of >5.5 I believe this is a built in feature of Laravel (TrustProxies).\nPlease find below my Nginx webserver config:\n```\n`server {\n    listen 80;\n    server_name domain.com;\n    return 301 https://www.example.com;\n}\n\nserver {\n    listen 80 default_server;\n\n    index index.html index.htm index.php;\n\n    server_name www.example.com;\n\n    root /var/www/public;\n\n    location ~ \\.php$ {\n        try_files $uri =404;\n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n        fastcgi_pass php-fpm:9013;\n        fastcgi_index index.php;\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME /var/www/example.com/public/$fastcgi_script_name;\n        fastcgi_param PATH_INFO $fastcgi_path_info;\n    }\n    \n   # Support Clean (aka Search Engine Friendly) URLs & enable Gzip compression:\n    location / {\n        proxy_set_header    X-Real-IP            $remote_addr;\n        proxy_set_header    X-Forwarded-For      $proxy_add_x_forwarded_for;\n        try_files $uri $uri/ /index.php?$query_string;\n        gzip_static on;\n    }\n   # Override the load balancer IP with real IP.\n    fastcgi_param REMOTE_ADDR $http_x_real_ip;\n\n    error_log  /var/log/nginx/error.log;\n    access_log /var/log/nginx/access.log;\n}\n`\n```\nAnd my server's Nginx Reverse Proxy config (IF relevant):\n```\n`server {\n    listen 80;\n    listen [::]:80;\n\n    server_name     example.com.au www.example.com.au;\n\n    location / {\n        proxy_pass      http://localhost:8013;\n        proxy_set_header   Host $host;\n        proxy_set_header   X-Real-IP $remote_addr;\n        proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header   X-Forwarded-Host $server_name;\n    }\n}\n`\n```",
      "solution": "Ok figured it out! :D\n\nI was using Cloudflare as a proxy, my DNS is with CloudFlare and I have enabled the \"Proxy through CloudFlare\" option due to speed / caching improvements.\nThis resulted in CloudFlare \"injecting\" a `HTTP_CF_CONNECTING_IP` into my header.\nTo retrieve this header value I have used `$_SERVER['HTTP_CF_CONNECTING_IP']` in my code.\n\nAnother solution was to use the `HTTP_X_FORWARDED_FOR` value from the header by using `_SERVER['HTTP_X_FORWARDED_FOR']`, this I believe would, in my situation only work after doing the following (posted in my question):\n\nTrustProxies.php\nproxy_set_header    X-Real-IP            $remote_addr;\nproxy_set_header    X-Forwarded-For      $proxy_add_x_forwarded_for;\n\nI hope this helps others as well :D",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2021-02-25T20:30:15",
      "url": "https://stackoverflow.com/questions/66375236/getting-a-users-ip-address-in-laravel-through-docker-containers-and-nginx-webse"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 74553987,
      "title": "Can&#39;t connect from outside to Postgres running on AWS EC2 instance",
      "problem": "I have installed Postgres 10 on my EC2 ubuntu(18). But I can't access it from my Local Mac. Get this error.\n\nMy SETUP is:\nI updated Postgres configs:\n\nto /etc/postgresql/10/main/pg_hba.conf added these lines:\n\n```\n`    host    all             all             0.0.0.0/0               md5\n    host    all             all             ::/0                    md5\n`\n```\n\nin /etc/postgresql/10/main/postgresql.conf changed this line:\n\n```\n`    listen_addresses = '*'                  # what IP address(es) to listen on;\n`\n```\n\nI did set password to default 'postgres' user, which I am using to connect to DB from outside;\n\nOn EC2 instance I changed:\n\nadded \"Inbound rule\" for port 5432 from any IPv4:\n\nOn EC2 instance this command returns that port is exposed:\n```\n`ubuntu@ip-XXXXXXXXXX:~$ netstat -nat |grep :5432\ntcp        0      0 0.0.0.0:5432            0.0.0.0:*               LISTEN     \ntcp6       0      0 :::5432                 :::*                    LISTEN   \n`\n```\nLooks like EC2 instance did not expose this port in fact. Other ports like :80 or :22 are accessible fine, but port :5432 returns error:\n```\n`\u279c  ~ nc -zv XX.XXX.XXX.XXX 80  \nConnection to XX.XXX.XXX.XXX port 80 [tcp/http] succeeded!\n\n\u279c  ~ nc -zv XX.XXX.XXX.XXX 5432\nnc: connectx to XX.XXX.XXX.XXX port 5432 (tcp) failed: Operation timed out\n`\n```\nI also have Nginx installed on my EC2 instance, its config is:\n```\n`server {\n  charset utf-8;\n  listen 80;\n  server_name XXXXXXXXXXXXXXX.ca; # PostgreSQL service is running:\n```\n`ubuntu@ip-XXXXXXXXXX:~$ service postgresql status\n\u25cf postgresql.service - PostgreSQL RDBMS\n   Loaded: loaded (/lib/systemd/system/postgresql.service; enabled; vendor preset: enabled)\n   Active: active (exited) since Wed 2022-11-23 22:41:33 UTC; 1h 6min ago\n  Process: 6283 ExecStart=/bin/true (code=exited, status=0/SUCCESS)\n Main PID: 6283 (code=exited, status=0/SUCCESS)\n\nNov 23 22:41:33 ip-XXXXXXXXXX systemd[1]: Starting PostgreSQL RDBMS...\nNov 23 22:41:33 ip-XXXXXXXXXX systemd[1]: Started PostgreSQL RDBMS.\n`\n```\nWhat is wrong in my setup? I tried many different posts in this forum and on Internet, nothing helps. ((\nDo I have to also configure Nginx with Postgres routing?",
      "solution": "You followed the correct steps. The issue is that the firewall is blocking the port of Postgres, 5432, so need to add it to the firewall allowed list.\n```\n`sudo ufw allow 5432/tcp\n`\n```\nWhen you run `$ sudo ufw status`, you'll see:\n```\n`Status: active\n\nTo Action From\n-- ------ ----\nOpenSSH ALLOW Anywhere\nNginx Full ALLOW Anywhere\n5432/tcp ALLOW Anywhere\nOpenSSH (v6) ALLOW Anywhere (v6)\nNginx Full (v6) ALLOW Anywhere (v6)\n5432/tcp (v6) ALLOW Anywhere (v6)\n`\n```\nAnd then run `sudo firewall-cmd --reload`, when you see `success`, you're done!\nYou will be able to connect from outside of the instance",
      "question_score": 3,
      "answer_score": 2,
      "created_at": "2022-11-24T00:23:36",
      "url": "https://stackoverflow.com/questions/74553987/cant-connect-from-outside-to-postgres-running-on-aws-ec2-instance"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 74246794,
      "title": "Where did the socket for GitLab-workhorse go?",
      "problem": "The /var/opt/gitlab/gitlab-workhorse/ folder is missing a socket and is generally almost empty.\nI'm trying to set up GitLab + nginx proxy. When I try to load the page, I get a 502 error.\nHaving figured out what exactly does not work for me, I realized (gitlab-ctl status):\n`down: gitlab-workhorse: 0s, normally up, want up; run: log: (pid 3756258) 12450s`\nThen I decided to look at my workhorse socket and this is what I saw in the /var/opt/gitlab/gitlab-workhorse folder (ls -ap /var/opt/gitlab/gitlab-workhorse/):\n`./  ../  config.toml  VERSION`\nMy gitlab settings:\n```\n`nginx['enable'] = false\nweb_server['external_users'] = ['www-data']\ngitlab_rails['trusted_proxies'] = ['127.0.0.1', ]\ngitlab_workhorse['listen_network'] = \"unix\"\ngitlab_workhorse['listen_addr'] = \"/var/opt/gitlab/gitlab-workhorse/sockets/socket\"\n`\n```\nnginx log:\n`connect() to unix:/var/opt/gitlab/gitlab-workhorse/sockets/socket failed (13: Permission denied) while connecting to upstream`\nAs I understand it, I am missing the required software or some files. Where can I get them if that's the problem. If not, why might my workhorse not work?\np.s. sorry for google translate :)\nupd. (/var/log/gitlab/gitlab-workhorse/current):\n```\n`{\"build_time\":\"20221024.191252\",\"level\":\"info\",\"msg\":\"Starting\",\"time\":\"2022-10-30T20:05:21+03:00\",\"version\":\"v15.5.1\"}\n{\"address\":\"localhost:9229\",\"level\":\"info\",\"msg\":\"Running metrics server\",\"network\":\"tcp\",\"time\":\"2022-10-30T20:05:21+03:00\"}\n{\"level\":\"info\",\"msg\":\"keywatcher: starting process loop\",\"time\":\"2022-10-30T20:05:21+03:00\"}\n{\"address\":\"/var/opt/gitlab/redis/redis.socket\",\"level\":\"info\",\"msg\":\"redis: dialing\",\"network\":\"unix\",\"time\":\"2022-10-30T20:05:21+03:00\"}\n{\"address\":\"/var/opt/gitlab/gitlab-workhorse/sockets/socket\",\"level\":\"info\",\"msg\":\"Running upstream server\",\"network\":\"unix\",\"time\":\"2022-10-30T20:05:21+03:00\"}\n{\"error\":\"listen unix /var/opt/gitlab/gitlab-workhorse/sockets/socket: bind: no such file or directory\",\"level\":\"fatal\",\"msg\":\"shutting down\",\"time\":\"2022-10-30T20:05:21+03:00\"\n`\n```",
      "solution": "Change path to socket in `listen_addr` setting to existing directory.\nFor example `gitlab_workhorse['listen_addr'] = \"/var/opt/gitlab/gitlab-workhorse/socket\"` or `gitlab_workhorse['listen_addr'] = \"/tmp/gitlab-workhorse-socket\"`",
      "question_score": 3,
      "answer_score": 1,
      "created_at": "2022-10-29T18:06:30",
      "url": "https://stackoverflow.com/questions/74246794/where-did-the-socket-for-gitlab-workhorse-go"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 72676267,
      "title": "CSRF session token missing in a nginx + gunicorn + flask architecture",
      "problem": "my website developed in flask works fine on gunicorn, it is using flask_wtf for setting up CSRF. Login and other html pages are using CSRF.\nAs i run it behind nginx reverse proxy i got a \"The CSRF session token is missing.\" error.\nAs everything works fine on gunicorn i suppose problem is in my current nginx configuration.\nfollows the nginx.conf I m using:\n```\n`'''\n\nuser ec2-user;\nworker_processes auto;\nerror_log /var/log/nginx/error.log debug;\npid /run/nginx.pid;\n\n# Load dynamic modules. See /usr/share/nginx/README.dynamic.\ninclude /usr/share/nginx/modules/*.conf;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log  /var/log/nginx/access.log  main;\n    error_log /var/log/nginx/error.log;\n    \n\n    sendfile            on;\n    tcp_nopush          on;\n    tcp_nodelay         on;\n    keepalive_timeout   120;\n    types_hash_max_size 2048;\n\n    include             /etc/nginx/mime.types;\n    default_type        application/octet-stream;\n\n    include /etc/nginx/conf.d/*.conf;\n\n    ##\n    # SSL Settings\n    ##\n    \n    ssl_session_timeout 10m;\n    ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE\n    ssl_prefer_server_ciphers on;\n\n##\n    # Gzip Settings\n    ##\n\n    gzip on;\n\n    gzip_proxied any;\n    gzip_min_length 500;\n    gzip_disable \"MSIE [1-6]\\.\"\n    gzip_http_version 1.1;\n    gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;\n\n    ##\n    # Virtual Host Configs\n    ##\n    \n    upstream app_servers {\n        server  127.0.0.1:8000;\n    }   \n\n    server {\n        listen 80;\n        return 301 https://$host$request_uri;   \n    \n    }\n\n    server {\n        listen 443 ssl;\n        \n        ssl_certificate /home/cert/cert.pem;\n        ssl_certificate_key /home/cert/privkey.pem;\n        keepalive_timeout 120;\n        \n        location / {\n            proxy_set_header Host $http_host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n            proxy_connect_timeout   3;\n            proxy_send_timeout      3;\n            proxy_read_timeout      3;\n            proxy_ignore_headers Set-Cookie;\n            proxy_hide_header    Set-Cookie;\n            proxy_cache                     off;\n            proxy_pass http://app_servers;\n            # Headers for client browser NOCACHE + CORS origin filter \n            proxy_cache                     off;\n            proxy_pass http://app_servers;\n            # set all cookies to secure, httponly and samesite by modifying \"path\"\n                proxy_cookie_path / \"/; secure; HttpOnly; SameSite=lax\";\n            expires -1;\n            \n        }\n        \n        location ^~ /static/ {\n            root /home/ec2-user/blabla/application/;\n        }\n\n    }\n'''\n`\n```\nany help, hint, suggestion how to investigate further the problem, how to trace the request will be more than welcome.",
      "solution": "adding\nproxy_set_header Cookie $http_cookie;\nas per below\n'''\n```\n`location / {\n            proxy_set_header Host $http_host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n            proxy_set_header Cookie $http_cookie;\n`\n```\n'''\nfixed all.",
      "question_score": 3,
      "answer_score": 2,
      "created_at": "2022-06-19T12:57:41",
      "url": "https://stackoverflow.com/questions/72676267/csrf-session-token-missing-in-a-nginx-gunicorn-flask-architecture"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 76546274,
      "title": "nginx error: bind() to 0.0.0.0:80 failed (98: Unknown error); conflicting server name &quot;&quot; on 0.0.0.0:80, ignored",
      "problem": "I host an nginx web Server with an configured reverse proxy. I needed to renew some certificates. I had faulty configs in some configs of some domains. After fixing them nginx cant start anymore and I cant get anything of the error. I googled so much, nothing runs on port 80 except nginx. And I don't understand the empty server name. Which server name?\nedit:\nit seems I fixed the server_name \"\" warning. But that's sadly not the solution to the problem.\nSystemctl status:\n```\n`nginx: [emerg] bind() to 0.0.0.0:80 failed (98: Unknown error)\n`\n```\nsudo grep -r server_name /etc/nginx* output:\n```\n`/etc/nginx/sites-enabled/pitlivesforever.conf:   server_name pitlivesforever.de;\n\n/etc/nginx/sites-enabled/pitlivesforever.conf:   server_name pitlivesforever.de;\n/etc/nginx/sites-enabled/calmingsurround.conf:   server_name calmingsurround.de;\n\n/etc/nginx/sites-enabled/calmingsurround.conf:   server_name calmingsurround.de;\n/etc/nginx/sites-enabled/walrussi.conf:   server_name walrussi.com;\n/etc/nginx/sites-enabled/walrussi.conf:   server_name walrussi.com;\n/etc/nginx/sites-enabled/onlyoffice.walrussi.conf:    server_name onlyoffice.walrussi.com;\n/etc/nginx/sites-enabled/onlyoffice.walrussi.conf:    return 301 https://$server_name$request_uri;\n/etc/nginx/sites-enabled/onlyoffice.walrussi.conf:    server_name onlyoffice.walrussi.com;\n/etc/nginx/sites-enabled/bitwarden.walrussi.com:    server_name bitwarden.walrussi.com; #Change this to your domain name\n/etc/nginx/sites-enabled/bitwarden.walrussi.com:  server_name bitwarden.walrussi.com; #Change this to your domain name\n/etc/nginx/sites-enabled/wiki.walrussi.com.conf:    server_name wiki.walrussi.com;\n/etc/nginx/sites-enabled/wiki.walrussi.com.conf:    return 301 https://$server_name$request_uri;\n/etc/nginx/sites-enabled/wiki.walrussi.com.conf:    server_name wiki.walrussi.com;\n/etc/nginx/sites-enabled/nextcloud.conf:   server_name nextcloud.walrussi.com;          \n/etc/nginx/sites-enabled/nextcloud.conf:  return 301 https://$server_name$request_uri;\n/etc/nginx/sites-enabled/nextcloud.conf:    server_name nextcloud.walrussi.com;\n/etc/nginx/sites-enabled/dyndns.conf:    server_name libellulanas.lohse.de;\n/etc/nginx/sites-enabled/dyndns.conf:    return 301 https://$server_name$request_uri;\n/etc/nginx/sites-enabled/dyndns.conf:    server_name libellulanas.lohse.de;\n/etc/nginx/scgi_params:scgi_param  SERVER_NAME        $server_name;\n/etc/nginx/nginx.conf.old:  # server_names_hash_bucket_size 64;\n/etc/nginx/nginx.conf.old:  # server_name_in_redirect off;\n/etc/nginx/nginx.conf:  # server_names_hash_bucket_size 64;\n/etc/nginx/nginx.conf:  # server_name_in_redirect off;\n/etc/nginx/sites-available/default:        server_name _;\n/etc/nginx/sites-available/default:#       server_name example.com;\n/etc/nginx/uwsgi_params:uwsgi_param  SERVER_NAME        $server_name;\n/etc/nginx/fastcgi.conf:fastcgi_param  SERVER_NAME        $server_name;\n/etc/nginx/fastcgi_params:fastcgi_param  SERVER_NAME        $server_name;\n`\n```\n\nHere the error:\n```\n`2023/06/24 13:09:12 [warn] 4027610#4027610: conflicting server name \"\" on 0.0.0.0:80, ignored\n2023/06/24 13:09:12 [warn] 4027610#4027610: conflicting server name \"\" on 0.0.0.0:80, ignored\n2023/06/24 13:09:12 [warn] 4027611#4027611: conflicting server name \"\" on 0.0.0.0:80, ignored\n2023/06/24 13:09:12 [warn] 4027611#4027611: conflicting server name \"\" on 0.0.0.0:80, ignored\n2023/06/24 13:09:12 [emerg] 4027611#4027611: bind() to 0.0.0.0:80 failed (98: Unknown error)\n2023/06/24 13:09:12 [emerg] 4027611#4027611: bind() to 0.0.0.0:80 failed (98: Unknown error)\n2023/06/24 13:09:12 [emerg] 4027611#4027611: bind() to 0.0.0.0:80 failed (98: Unknown error)\n2023/06/24 13:09:12 [emerg] 4027611#4027611: bind() to 0.0.0.0:80 failed (98: Unknown error)\n2023/06/24 13:09:12 [emerg] 4027611#4027611: bind() to 0.0.0.0:80 failed (98: Unknown error)\n2023/06/24 13:09:12 [emerg] 4027611#4027611: still could not bind()\n\n`\n```\nsudo nginx -t:\n```\n`nginx: [warn] conflicting server name \"\" on 0.0.0.0:80, ignored\nnginx: [warn] conflicting server name \"\" on 0.0.0.0:80, ignored\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nnginx: configuration file /etc/nginx/nginx.conf test is successful\n\n`\n```\nsystemctl status ngingx.service:\n```\n`\u00d7 nginx.service - A high performance web server and a reverse proxy server\n     Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled)\n     Active: failed (Result: exit-code) since Sat 2023-06-24 13:09:15 UTC; 9min ago\n       Docs: man:nginx(8)\n    Process: 4027610 ExecStartPre=/usr/sbin/nginx -t -q -g daemon on; master_process on; (code=exited, status=0/SUCCESS)\n    Process: 4027611 ExecStart=/usr/sbin/nginx -g daemon on; master_process on; (code=exited, status=1/FAILURE)\n        CPU: 82ms\n\n`\n```\nnetstat -tulpn | grep --color :80:\n```\n`tcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      3366/nginx: master  \ntcp        0      0 127.0.0.1:8080          0.0.0.0:*               LISTEN      1916/docker-proxy   \n`\n```\nI hope I just oversee some empty (?!) config but I can't find it.\nThanks for your help!\nI tried to create \"default\" domain config if maybe nginx is missing a default?\nUpgraded the System.\nKilled all nginx processes and tried to start it again.",
      "solution": "@sleepyhead\n\nI'd rebuild the configs one domain at a time until you hit problems,\nyou can use reload to add configs while the other sites remain up.\nFrom the above I can't spot a fault\n\nThat worked. Haha. I was the fault.",
      "question_score": 3,
      "answer_score": 1,
      "created_at": "2023-06-24T15:25:52",
      "url": "https://stackoverflow.com/questions/76546274/nginx-error-bind-to-0-0-0-080-failed-98-unknown-error-conflicting-server"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 68139826,
      "title": "Nginx Proxy Pass Nodejs to React Application",
      "problem": "I have a front end of react and backend of node, for some reason it wont make the right request to the backend.\nThe error log given by nginx\n```\n`111: Connection refused) while connecting to upstream, server: _, request: \"GET /api/info HTTP/1.1\", upstream: \"http://127.0.0.1:5000/info\"\n`\n```\nI noticed that it makes the wrong request because the `http://127.0.0.1:5000/info` should be `http://127.0.0.1:5000/api/info`\nMy default config\n```\n`server {\n        listen 80 default_server;\n        listen [::]:80 default_server;\n\n        root /var/www/{{AppName}}/frontend/build;\n\n        server_name {{myDomainName}};\n\n        location / {\n                try_files $uri $uri/ =404;\n        }\n\n        location /api/ {\n                proxy_pass http://localhost:5000/;\n        }\n`\n```\nWhen I visit my website it just errors me out with Error 404",
      "solution": "I noticed that it makes the wrong request because the\nhttp://127.0.0.1:5000/info should be http://127.0.0.1:5000/api/info\n\nAction\nRemove the '/' at the end of the proxy address\n```\n`location /api/ {\n    proxy_pass http://localhost:5000; # remove the '/' at the end\n}\n`\n```\nExplain\nFrom nginx documentation\n\nTo pass a request to an HTTP proxied server, the proxy_pass directive\nis specified inside a location. For example:\n```\n`location /some/path/ {\n    proxy_pass http://www.example.com/link/; \n}\n`\n```\nNote that in the first example above, the address of the proxied server is followed by a URI, /link/.\nIf the URI is specified along with the address, it replaces the part\nof the request URI that matches the location parameter. For example,\nhere the request with the /some/path/page.html URI will be proxied to\nhttp://www.example.com/link/page.html\n\nIn your case, the URI is `/`, it replaces `/api/` in the request URI. So:\n`http://yourserver/api/info` will be proxied to `http://127.0.0.1:5000/info`",
      "question_score": 2,
      "answer_score": 6,
      "created_at": "2021-06-26T08:27:22",
      "url": "https://stackoverflow.com/questions/68139826/nginx-proxy-pass-nodejs-to-react-application"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 69556600,
      "title": "Adding Headers to NGINX Ingress using ConfigMap not working",
      "problem": "I'm trying to pass my client IP address through my NGINX Ingress using Kubernetes on Azure\nI've created this configmap for the NGINX config to add the headers:\n```\n`apiVersion: v1\ndata:\n  X-Real-IP: $remote_addr;\n  X-Forwarded-For: $proxy_add_x_forwarded_for;\n  X-Forwarded-Proto: $proxy_x_forwarded_proto;\n  use-forwarded-headers: \"true\"\n  use-proxy-protocol: \"true\"\n  real-ip-header: \"proxy_protocol\"\nkind: ConfigMap\nmetadata:\n  name: custom-headers\n  namespace: default\n`\n```\nThen added this config to reference the previous file:\n```\n`apiVersion: v1\ndata:\n  proxy-set-headers: \"custom-headers\"\n  externalTrafficPolicy: Local\nkind: ConfigMap\nmetadata:\n  name: ingress-nginx-controller\n  namespace: default\n  labels:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/part-of: ingress-nginx\n`\n```\nIf I describe my nginx controller:\n```\n`kubectl describe deploy ingress-nginx-controller\n`\n```\nI can see the line:\n```\n`--configmap=$(POD_NAMESPACE)/ingress-nginx-controller\n`\n```\nIf I describe the ingress-nginx-controller configmap\n```\n`kubectl describe configmap ingress-nginx-controller\n`\n```\nI can see the following in the data section:\n```\n`proxy-set-headers:\n----\ncustom-headers\n`\n```\nIf I log out the nginx.conf file in my controller though, I can't see the changed values. For example this is still the default:\n```\n`proxy_set_header X-Forwarded-For        $remote_addr;\n`\n```",
      "solution": "You are missing the namespace prefix for proxy-set-headers value. Because you have deployed `custom-headers` configmap to the default namespace, it should be\n```\n`data:\n  proxy-set-headers: default/custom-headers\n`\n```",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2021-10-13T15:37:39",
      "url": "https://stackoverflow.com/questions/69556600/adding-headers-to-nginx-ingress-using-configmap-not-working"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 73324767,
      "title": "IdentityServer 4 : connect/authorize/callback address not found behind Nginx reverse proxy",
      "problem": "hi i am new in identityserver 4 and trying to deploy my test project on the server.\ni have client ids and api project which are dockerized. after playing around with identity server 4 and nginx reverse proxy configuration finally every thing work properly except the redirect callback after login.\nSTORY : \nin my reverse proxy i have 3 upstreams as follow : \n\nClient APP which is accessible by url https ://xxx.com/ itself. and it is configured as\n\n```\n`   location / {\n                    proxy_pass http ://Client;\n                    proxy_buffering off;\n                    proxy_set_header X-Real-IP $remote_addr;\n                    proxy_set_header X-Forwarded-Host $host;\n                    proxy_set_header X-Forwarded-Port $server_port;\n    \n                    fastcgi_buffers 16 16k;\n                    fastcgi_buffer_size 32k;\n    \n            }\n`\n```\n\ni added the below code to pipe line to set the original url. without this i got invalid redirect uri (in configuration setup i set it with proper address but in error it shows it trying to redirect to https ://Client/signin-iodc)\n```\n`app.Use(async (ctx, next) =>\n{\n    ctx.Request.Scheme = \"https\";\n    ctx.Request.Host = new HostString(\"xxx.com\");\n    \n    await next();\n});\n`\n```\n\nIdentity Server 4 that is accessible by base URL https ://xxx.com/identity and also i can get the configuration properly with proper addresses. it is configured as\n\n```\n`location /identity/ {\n                proxy_pass http ://Identity/;\n\n                proxy_buffering off;\n                proxy_set_header X-Real-IP $remote_addr;\n                proxy_set_header X-Forwarded-Host $host;\n                proxy_set_header X-Forwarded-Port $server_port;\n\n                fastcgi_buffers 16 16k;\n                fastcgi_buffer_size 32k;\n\n        }\n`\n```\n\nsame here added the below code to pipe line to set the original url for Identity server\n```\n`app.Use(async (ctx, next) =>\n{\n    ctx.Request.Scheme = \"https\";\n    ctx.Request.Host = new HostString(\"xxx.com/identity/\");\n    \n    await next();\n});\n`\n```\nwithout this in openid-configuration i had the wrong addresses like https ://identity/connect....\n\nApi resource which is not the problem here and it accessible on url https ://xxx.com/api/....\n\nUPSTREAMS:\n```\n`upstream Client{\n        zone Client 64k;\n        server localhost:5001;\n}\n\nupstream Identity{\n\n        zone Identity 64k;\n        server localhost:9001;\n}\n`\n```\n\nProblem:\nnow with this config everything works. i redirect to login page with proper url \n\nhttps ://xxx.com/identity/Account/Login?ReturnUrl=%......\n\nbut after login it should go for\n\nhttps ://xxx.com/identity/connect/authorize/callback?client_id=\n\nbut it redirects to\n\nhttps ://xxx.com/connect/authorize/callback?client_id=\n\nwhich not valid and obviously i get page can\u2019t be found.\nif i add identity to the same url it works properly and go to the home page of client since i have cookies and authorized.\ni dont know if i messed up something here by adding the middle-ware for origin url or i missed some configuration in nginx.",
      "solution": "the problem was in my middleware pipeline. before i had defined the base url for my identity server as\n```\n`app.Use(async (ctx, next) => \n{ \n    ctx.Request.Scheme = \"https\"; \n    ctx.Request.Host = new HostString(\"xxx.com/identity/\");\n    \n    await next(); \n});\n`\n```\nwhich was ok. i got the correct discovery configuration with correct urls and also redirect to correct url for login and span around identityserver without problem except the connect/authorize on redirect after login as i explained in the question.\ni changed it as follow:\n```\n`app.Use(async (ctx, next) => \n{ \n    ctx.Request.Scheme = \"https\"; \n    ctx.Request.Host = new HostString(\"xxx.com\");\n    ctx.Request.PathBase = new PathString(\"/identity\");\n    await next(); \n});\n`\n```\nand for now my problem solved. i wont mark this solution as answer since i dont have any idea if this is the standard solution and best practice.",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2022-08-11T19:32:16",
      "url": "https://stackoverflow.com/questions/73324767/identityserver-4-connect-authorize-callback-address-not-found-behind-nginx-rev"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 72260921,
      "title": "Redirecting captured regex group using nginx",
      "problem": "With the following nginx location directive\n```\n`  location ~* (.*)(\\/graphql)$ {\n    proxy_pass http://my-backend:80/$2;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n    proxy_set_header Host $host;\n  }\n`\n```\nI expect that URLs like `https://example.com/anything/graphql` is redirected to `http://my-backend:80/$2` but that's not the case as nginx is giving me a 404 error whenever I try to visit an URL ending with `/graphql`. The error will be\n```\n`[error] 31#31: *1 no resolver defined to resolve my-backend, client: 172.18.0.1, server: localhost, request: \"GET /anything/graphql HTTP/2.0\", host: \"localhost\"\n`\n```",
      "solution": "It is a known nginx limitation that you can't specify an URI for `proxy_pass` inside the regex location. If you'd try to do something like\n```\n`proxy_pass http://my-backend/graphql;\n`\n```\nyou've got the following nginx error:\n\nnginx: [emerg] \"proxy_pass\" cannot have URI part in location given by regular expression, or inside named location, or inside \"if\" statement, or inside \"limit_except\" block in ...\n\nYou have two options instead. The first one is to use variables to pass whatever you want to your upstream as an URI, either the way you have chosen or, if it is a constant string, specifying your endpoint explicitly like\n```\n`set $endpoint graphql;\nproxy_pass http://my_backend/$endpoint;\n`\n```\nHowever this approach have a drawback you already faced - it is requires a `resolver` being defined if your upstream is specified via the hostname rather than IP address. That is, the\n```\n`proxy_pass http://localhost/$endpoint;\n`\n```\nconfiguration line would require a resolver while\n```\n`proxy_pass http://127.0.0.1/$endpoint;\n`\n```\nwon't require it. It doesn't matter the `$endpoint` variable is used only for the URI part. If you wonder what is the need of that `resolver`, let me quote the most relevant part from the blog post already mentioned:\n\nLinux, POSIX and the like offer only one way to get an IP from a name: `gethostbyname`. If you take time to read the man page (always a safe thing to do... ;)) you'll realise there is a lot to do to resolve a name: open files, ask NIS or YP what they think about it, ask a DNS server (may be in a few different ways). And all this is synchronous. Now that you are used to the nginx way, you know how bad this is and you don't want to go down the ugly synchronous way. So Igor, faithful to himself, reimplemented a DNS lookup (with an in-memory cache, mind you) just to avoid calling this ugly blocking `gethostbyname`... And that's why we have this extra `resolver` directive. Yes, coding the fastest web server comes at a price...\n\nWhen there are no other way but to use variables with the `proxy_pass`, using the public DNS like `8.8.8.8` is an option, however setting up your own local one should be much more performant (or you'll have continuous traffic exchange with that `8.8.8.8` host). However there is another option. You can rewrite an URI inside your location block to required one and use the `proxy_pass` without any additional variables:\n`location ~ /graphql$ {\n    rewrite ^ /graphql break;\n    proxy_pass http://my-backend;\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n    proxy_set_header Host $host;\n}\n`\nFor the most of cases this is a more convenient way since using such a configuration you won't need any specified `resolver` at all.\nAs you can see, I don't use any capture groups here since there are no any real sense to use them solving your particular case. The given regex does exactly the same as yours (while being slightly more performant). However there are cases when you really need to use them, and if someone who really need to use a capture group(s) will read this, he must be warned that the straight way of doing something like\n`location ~ (/graphql)$ {\n    rewrite ^ $1 break;\n   ...\n`\nwon't work. The reason is that numbered captures are being reevaluated whenever regex pattern matching operation takes its place, and the `rewrite` directive is exactly one of those that did such an operation (making `$1` to be an empty string). The solution would be to use named capture groups instead:\n`location ~ (?/graphql)$ {\n    rewrite ^ $url break;\n   ...\n`\nor one can reuse regex pattern (which I think will be somewhat less performant):\n`location ~ /graphql$ {\n    rewrite (/graphql)$ $1 break;\n    ...\n`",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2022-05-16T16:34:05",
      "url": "https://stackoverflow.com/questions/72260921/redirecting-captured-regex-group-using-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 70277034,
      "title": "How to set reverse proxy using jwilder/nginx-proxy?",
      "problem": "I'm trying to set a reverse proxy using jwilder/nginx-proxy container.\nI have a small Express app:\n`var express = require(\"express\");\nvar app = express();\n\napp.get(\"/api\", (req, res, next) => {\n  res.json({ hello: \"world\" });\n});\n\napp.listen(3000, () => {\n  console.log(\"Server running on port 3000\");\n});\n`\nand a `docker-compose.yml`:\n`version: \"3.4\"\nservices:\n  reverse-proxy:\n    image: jwilder/nginx-proxy\n    ports:\n      - 80:80\n    volumes:\n      - /var/run/docker.sock:/tmp/docker.sock:ro\n    networks:\n      - testt\n\n  testt:\n    container_name: testt\n    image: node:lts\n    working_dir: /var/www/html/app/\n    entrypoint: /bin/bash\n    environment:\n      - HOST=0.0.0.0\n      - VIRTUAL_HOST=testt.dev # for reverse proxy\n      - VIRTUAL_PORT=3000 # for reverse proxy\n    ports:\n      - 3000:3000\n    volumes:\n      - ./testt/:/var/www/html/app\n    tty: true\n    networks:\n      - testt\n\nnetworks:\n  testt:\n    external: true\n\n`\nThat is all I have set. Nothing else.\nWhen I run `localhost:3000/api` I get the expected result `{\"hello\":\"world\"}`. The same I'd expect to get when I run `http://testt.dev/api` in the browser, but it is not working (DNS_PROBE_FINISHED_NXDOMAIN).\nWhat else do I have to set and where?\nDo I have to set something to HOSTS file?\nThank you\nEDIT:\nDocker log:\n```\n`Setting up DH Parameters..\n\nforego      | starting dockergen.1 on port 5000\n\nforego      | starting nginx.1 on port 5100\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: using the \"epoll\" event method\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: nginx/1.21.3\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: built by gcc 8.3.0 (Debian 8.3.0-6) \n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: OS: Linux 5.10.47-linuxkit\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: getrlimit(RLIMIT_NOFILE): 1048576:1048576\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: start worker processes\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: start worker process 27\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: start worker process 28\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: start worker process 29\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: start worker process 30\n\ndockergen.1 | 2021/12/09 09:39:36 Template error: open /etc/nginx/certs: no such file or directory\n\ndockergen.1 | 2021/12/09 09:39:36 Generated '/etc/nginx/conf.d/default.conf' from 2 containers\n\ndockergen.1 | 2021/12/09 09:39:36 Running 'nginx -s reload'\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: signal 1 (SIGHUP) received from 32, reconfiguring\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: reconfiguring\n\ndockergen.1 | 2021/12/09 09:39:36 Watching docker events\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: using the \"epoll\" event method\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: start worker processes\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: start worker process 37\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: start worker process 38\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: start worker process 39\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: start worker process 40\n\ndockergen.1 | 2021/12/09 09:39:36 Template error: open /etc/nginx/certs: no such file or directory\n\ndockergen.1 | 2021/12/09 09:39:36 Contents of /etc/nginx/conf.d/default.conf did not change. Skipping notification 'nginx -s reload'\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 27#27: gracefully shutting down\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 28#28: gracefully shutting down\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 30#30: gracefully shutting down\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 29#29: gracefully shutting down\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 27#27: exiting\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 30#30: exiting\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 29#29: exiting\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 28#28: exiting\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 27#27: exit\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 29#29: exit\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 30#30: exit\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 28#28: exit\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: signal 17 (SIGCHLD) received from 28\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: worker process 27 exited with code 0\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: worker process 28 exited with code 0\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: signal 29 (SIGIO) received\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: signal 17 (SIGCHLD) received from 27\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: worker process 30 exited with code 0\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: signal 29 (SIGIO) received\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: signal 17 (SIGCHLD) received from 29\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: worker process 29 exited with code 0\n\nnginx.1     | 2021/12/09 09:39:36 [notice] 22#22: signal 29 (SIGIO) received\n`\n```",
      "solution": "I think you need `url` and then `letesencrypt_host` and `letsencrypt_email` if you wants certs. Try:\n```\n`version: '3.7'\nservices:\n\n    ghost01:\n        image: \"ghost\"\n        user: \"1000\"\n        environment:\n            - url=https://test01.zathras.io\n            - VIRTUAL_HOST=test01.zathras.io\n            - VIRTUAL_HOST_ALIAS=test01.zathras.io\n            - LETSENCRYPT_HOST=test01.zathras.io\n            - LETSENCRYPT_EMAIL=qdzlug@gmail.com\n        networks:\n            - webproxy\nnetworks:\n    webproxy:\n        external: true\n`\n```",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2021-12-08T15:54:40",
      "url": "https://stackoverflow.com/questions/70277034/how-to-set-reverse-proxy-using-jwilder-nginx-proxy"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 68710670,
      "title": "Nginx reverse proxy stalls on large files",
      "problem": "My setup:\nNginx reverse proxy which proxy's traffic from my domain to a Synology NAS\n`https://photo.domain.com => Synology Photos (local IP)`\nBut, when trying to upload large files (=videos), the upload fails.\nConnecting directly to the local IP works just fine - so: Somehow the proxy fails.\nIn /etc/nginx/nginx.conf i have specified:\n```\n`client_max_body_size 0;\nsendfile on;\ntcp_nopush on;\ntcp_nodelay on;\n`\n```\nAlso tested with\n```\n`client_header_timeout 300s;\nclient_body_timeout 300s;\nkeepalive_timeout 300s;\nsend_timeout 300s;\n`\n```\nUpload still fails. Advice or hints are much appreciated! :-)",
      "solution": "Solved this with:\n```\n`client_max_body_size 0;\nproxy_read_timeout 1800;\nproxy_connect_timeout 1800;\nproxy_send_timeout 1800;\nproxy_request_buffering off;\n`\n```\nThink it was the last line that did the job :)",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2021-08-09T12:38:47",
      "url": "https://stackoverflow.com/questions/68710670/nginx-reverse-proxy-stalls-on-large-files"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 66436980,
      "title": "nginx proxypass TCP 389",
      "problem": "We have one \"OpenLDAP\" server with port 389 currently active,using nginx we want to proxypass this TCP port 389 to TCP based ingress. can any one please share the nginx.conf detail for this.\nSo far, left with incomplete as per below,\n```\n`upstream rtmp_servers {\nserver  acme.example.com:389;\n   }\n\nserver {\nlisten     389;\nserver_name localhost:389;\nproxy_pass rtmp_servers;\nproxy_protocol on;\n}\n`\n```\nGetting an error, any recommendation is appreciated\n\n2021/03/02 09:45:39 [emerg] 1#1: \"proxy_pass\" directive is not allowed\nhere in /etc/nginx/conf.d/nginx-auth-tunnel.conf:9 nginx: [emerg]\n\"proxy_pass\" directive is not allowed here in\n/etc/nginx/conf.d/nginx-auth-tunnel.conf:9",
      "solution": "Your configuration should be in a `stream` block\nYou don't need `server_name localhost:389;`\nYou are including the configuration from `/etc/nginx/conf.d` folder which is included inside http block in main nginx.conf file. The stream block should be at the same level as http block. Check the `/etc/nginx/nginx.conf` for the `include` and maybe you have to add one for the stream section\n\nThis is a sample nginx.conf,\n```\n`user  nginx;\nworker_processes  1;\n\nerror_log  /var/log/nginx/error.log warn;\npid        /var/run/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log  /var/log/nginx/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf; #This include is your problem\n}\n\nstream {\n    upstream rtmp_servers {\n       server  acme.example.com:389;\n    }\n\n   server {\n      listen     389;\n      proxy_pass rtmp_servers;\n      proxy_protocol on;\n   }\n}\n`\n```",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2021-03-02T10:49:04",
      "url": "https://stackoverflow.com/questions/66436980/nginx-proxypass-tcp-389"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 76169722,
      "title": "How to connect to a secure WebSocket SurrealDB instance over HTTPS via nginx?",
      "problem": "I'm trying to solve this problem I've been experiencing wherein I've been unable to connect to my SurrealDB backend over HTTPS/WSS. When attempting to connect via HTTP or WS, things work just fine, but adding any sort of SSL seems to break everything. My current stack looks like this:\n\nnginx - For serving my web content and providing a reverse proxy to the SurrealDB instance on its default port (:8000).\nSurrealDB - The database solution I am using for my site (perhaps one of my favorite db solutions of all time... when it works \ud83d\ude0b)\nReact with Next.js - The mostly front-end solution for my website.\nCloudflare - For DNS routing and proxying.\n\nMy nginx configuration looks like this:\n```\n`worker_processes 1;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    include mime.types;\n    default_type application/octet-stream;\n\n    map $http_upgrade $connection_upgrade {\n        default upgrade;\n        '' close;\n    }\n\n    upstream websocket {\n        server 127.0.0.1:4321;\n    }\n\n    sendfile on;\n\n    keepalive_timeout 65;\n\n    # HTTP server\n    server {\n        listen 443 ssl;\n        server_name [...].com;\n\n        ssl_certificate C:\\Certbot\\live\\[...].com\\fullchain.pem;\n        ssl_certificate_key C:\\Certbot\\live\\[...].com\\privkey.pem;\n\n        location / {\n            proxy_pass http://127.0.0.1:3000;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n\n        error_page 500 502 503 504 /50x.html;\n        location = /50x.html {\n            root html;\n        }\n    }\n\n    # Secure WebWocket (WSS) server\n    server {\n        listen 443;\n        server_name dev.db.[...].com;\n\n        ssl_certificate C:\\Certbot\\live\\[...].com\\fullchain.pem;\n        ssl_certificate_key C:\\Certbot\\live\\[...].com\\privkey.pem;\n\n        location / {\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection $connection_upgrade;\n\n            proxy_http_version 1.1;\n            proxy_pass http://websocket;\n            proxy_redirect off;\n            proxy_pass_request_headers on;\n        }\n    }\n}\n`\n```\nCloudflare is setup to forward traffic to the main domain and all subdomains to the same server (everything is currently hosted from the same machine.) Both configuration options (A records) are set to the same IP address and are proxied.\nThe proxy to port 3000 works and the Next.js instance is accessible via HTTPS, so I don't imagine that nginx itself is messed up, but I might be wrong.\nI have tried various solutions to this problem, including the following:\n\nIssuing separate SSL certificates for the subdomain and the primary domain (using certbot),\n\nSharing the same SSL certificate for both domains (using certbot),\n\nPointing `proxy-pass` to an `upstream` as well as a direct `127.0.0.1:8000` approach,\n\nEnsuring the following:\n\n`proxy_http_version` is set to `1.1`.\n`proxy_set_header Upgrade` is set to `$http_upgrade` or `upgrade`.\n\nListening on both 443 and 80, including and excluding the `ssl` suffix on the `listen` directive.\n\nChanging the `server_name` from `dev.db.[...].com` to various other options, with no success,\n\nPort-forwarding port 8000, 443, 80, and 8080.\n\nAdding firewall rules (TCP/UDP + incoming/outgoing) for the aforementioned ports, as well as port 3000 (for the Next.js instance).\n\nChanging SurrealDB's address and port binding (`--bind`) to something else. Note that the `--addr` flag available when starting SurrealDB is something I have not yet tried as I cannot quite seem to figure out the proper way to manipulate it. Could this be the issue?\n\nAttempted connection via local network and external WSS port testing tool, both failures,\n\nReordered nginx configuration to use a `location /ws` instead of a `server` directive just to see if that might work (unfortunately it did not).\n\nThis is the error I get every single time I attempt to connect from any medium:\nConsole log error \"WebSocket connection to wss://dev.db.censored.com/' failed\nAre there any suggestions? Am I perhaps missing something, or maybe I did this incorrectly?\n(Note that the [...] in the examples provided is the censored domain name, not literal characters.)",
      "solution": "I solved my own problem! The issue was that I was not proxying the `/rpc` endpoint properly in my `nginx.conf`. The fix was to add this to my default server entry in the configuration:\n```\n`location /rpc {\n    proxy_pass http://127.0.0.1:8000;\n\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header Host $host;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n    # WebSocket support\n    proxy_http_version 1.1;\n    proxy_set_header Upgrade $http_upgrade;\n    proxy_set_header Connection \"upgrade\";\n}\n`\n```\nThis allows the JavaScript library to access the correct SurrealDB endpoint and fixed my problem right away. In hindsight, I feel like it should have been obvious, but oh  well! If anyone else has a similar problem getting SurrealDB to work with your nginx configuration, I hope this helps!",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2023-05-04T07:02:46",
      "url": "https://stackoverflow.com/questions/76169722/how-to-connect-to-a-secure-websocket-surrealdb-instance-over-https-via-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 73552138,
      "title": "Nginx responds 404 not found on Django media URL in preprod, dev ok",
      "problem": "I have a quite standard Django application with a Vuejs frontend.\nI have different environments (`preprod`/`dev`) in which I have file upload/download features.\nFor files, everything works fine because they are returned through standard API views in attachment (`Content-Disposition: attachment`). When it comes to images though, like profile pictures, there is a problem.\nIn development (`DEBUG=True`), I have this :\n`from django.conf import settings\nfrom django.conf.urls.static import static\nfrom django.urls import include, path\n\nfrom backend.applications.base.views.authentication_views import LoginAPIView, LogoutAPIView\n\nurlpatterns = [\n    path(\"api/login\", LoginAPIView.as_view()),\n    path(\"api/logout\", LogoutAPIView.as_view()),\n    path(\"api/base/\", include(\"backend.applications.base.urls\")),\n    path(\"api/contact/\", include(\"backend.applications.contact.urls\")),\n    path(\"api/helpdesk/\", include(\"backend.applications.helpdesk.urls\")),\n    path(\"api/inventory/\", include(\"backend.applications.inventory.urls\")),\n] + static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)  # For serving media files when DEBUG=True\n`\nand images are correctly served (no nginx in dev mode, just frontend and backend dev servers `django's runserver`).\nMy preprod however, is made of a nginx container which serves my built vuejs frontend, and a backend container which contains my Django (`DEBUG=False`) application (which runs with `gunicorn` this time, like this : `gunicorn backend.wsgi:application --bind 0.0.0.0:8000 --access-logfile=\"-\"`).\nBefore trying to serve images, I had this nginx configuration :\n```\n`http {\n    client_max_body_size 5M;\n\n    upstream backend_api {\n        server backend:8000;\n        # 'backend' is the name of the backend service in my docker-compose config\n    }\n\n    server {\n        listen 80;\n\n        include /etc/nginx/mime.types;\n\n        root /usr/share/nginx/html;\n        index index.html;\n\n        location = /favicon.ico {\n            access_log off;\n            log_not_found off;\n        }\n\n        location /api {\n            proxy_pass http://backend_api;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-Proto $http_x_forwarded_proto;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_redirect off;\n        }\n\n        location / {\n            try_files $uri $uri/ /index.html;\n        }\n    }\n}\n`\n```\nThen I thought that `/media` requests should also be passed to the backend and I changed\n```\n`location /api\n`\n```\ninto\n```\n`location ~ ^/(api|media)/ {\n`\n```\nMy `/api` URLs are still handled correctly but `/media` URLs are answered by a 404 :\n\n(trying to load profile pictures of my user(s) in a kanban view).\nAlso trying directly `http://localhost/media/base/users/8/picture.jpg` directly in my browser doesn't work :\n\nFrom here I don't know what to do to solve the issue. If something is missing, mention it and I'll update the post.",
      "solution": "Django does not serve static- and media files with runserver, you will need WhiteNoise for that. See http://whitenoise.evans.io/en/stable/\nWhitenoise however is not suitable for serving user-uploaded media files. See http://whitenoise.evans.io/en/stable/django.html#serving-media-files\n(Optionally, skip whitenoise, and host static/media files through NGINX.)\nYou really shouldn't be hosting your server with `py manage.py runserver`. This is not secure. See Why not use \"runserver\" for production at Django? and https://docs.djangoproject.com/en/dev/ref/django-admin/#runserver\nUse something like Gunicorn instead.\nSee https://docs.djangoproject.com/en/4.1/howto/deployment/wsgi/gunicorn/\n(Or waitress, the windows alternative)\nhttps://pypi.org/project/django-waitress/\nTo host static/media files with nginx, paste this into your nginx conf:\n```\n`    location /media  {\n        alias /PATH/TO/DIRECTORY; #Absolute path.\n    }\n`\n```\nAnd in your settings.py, set the media root to that same directory.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2022-08-31T09:13:33",
      "url": "https://stackoverflow.com/questions/73552138/nginx-responds-404-not-found-on-django-media-url-in-preprod-dev-ok"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 69390660,
      "title": "nginx: [emerg] host not found in upstream &quot;udagram-users:8080&quot; in /etc/nginx/nginx.conf:11",
      "problem": "After deploying to `AWS EKS` I get this error \nGtihub repo: https://github.com/oussamabouchikhi/udagram-microservices\nSteps to reproduce\n\nCreate `AWS EKS` cluster and node groups\nConfigure `EKS` cluster with `kubectl`\nDeploy to `EKS` cluster (secrets first, then other services, then reverserproxy)\n. `kubectl apply -f env-secret.yaml`\n. `kubectl apply -f aws-secret.yaml`\n. `kubectl apply -f env-configmap.yaml`\n. ...\n. `kubectl apply -f reverseproxy-deployment.yaml`\n. `kubectl apply -f reverseproxy-service.yaml`\n\nnginx-config\n```\n`worker_processes 1;\n  \nevents { worker_connections 1024; }\nerror_log /dev/stdout debug;\n\nhttp {\n\n    sendfile on;\n\n    upstream users {\n        server udagram-users:8080;\n    }\n\n    upstream feed {\n        server udagram-feed:8080;\n    }\n    \n    proxy_set_header   Host $host;\n    proxy_set_header   X-Real-IP $remote_addr;\n    proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header   X-Forwarded-Host $server_name;\n    \n    server {\n        listen 8080;\n        location /api/v0/feed {\n            resolver           8.8.8.8;\n            proxy_pass         http://feed;\n        }\n        location /api/v0/users {\n            resolver           8.8.8.8;\n            proxy_pass         http://users;\n        }            \n    }\n\n}\n`\n```\ndocker-compose\n```\n`version: '3'\nservices:\n  reverseproxy:\n    image: oussamabouchikhi/reverseproxy\n    ports:\n      - 8080:8080\n    restart: always\n    depends_on:\n      - udagram-users\n      - udagram-feed\n    networks:\n      - example-net\n  udagram-users:\n    image: oussamabouchikhi/udagram-api-users\n    volumes:\n      - $HOME/.aws:/root/.aws\n    environment:\n      POSTGRES_USERNAME: $POSTGRES_USERNAME\n      POSTGRES_PASSWORD: $POSTGRES_PASSWORD\n      POSTGRES_DB: $POSTGRES_DB\n      POSTGRES_HOST: $POSTGRES_HOST\n      AWS_REGION: $AWS_REGION\n      AWS_PROFILE: $AWS_PROFILE\n      AWS_MEDIA_BUCKET: $AWS_BUCKET\n      JWT_SECRET: $JWT_SECRET\n      URL: $URL\n      networks:\n        - example-net\n  udagram-feed:\n    image: oussamabouchikhi/udagram-api-feed\n    volumes:\n      - $HOME/.aws:/root/.aws\n    environment:\n      POSTGRES_USERNAME: $POSTGRES_USERNAME\n      POSTGRES_PASSWORD: $POSTGRES_PASSWORD\n      POSTGRES_DB: $POSTGRES_DB\n      POSTGRES_HOST: $POSTGRES_HOST\n      AWS_REGION: $AWS_REGION\n      AWS_PROFILE: $AWS_PROFILE\n      AWS_MEDIA_BUCKET: $AWS_BUCKET\n      JWT_SECRET: $JWT_SECRET\n      URL: $URL\n    networks:\n      - example-net\n  udagram-frontend:\n    image: oussamabouchikhi/udagram-frontend\n    ports:\n      - '8100:80'\n    networks:\n      - example-net\nnetworks:\n  example-net:\n    external: true\n`\n```\nreverseproxy-deployment\n```\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    service: reverseproxy\n  name: reverseproxy\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      service: reverseproxy\n  template:\n    metadata:\n      labels:\n        service: reverseproxy\n    spec:\n      containers:\n        - image: oussamabouchikhi/reverseproxy:latest\n          name: reverseproxy\n          imagePullPolicy: Always\n          resources:\n            requests:\n              memory: '64Mi'\n              cpu: '250m'\n            limits:\n              memory: '1024Mi'\n              cpu: '500m'\n          ports:\n            - containerPort: 8080\n      restartPolicy: Always\n\n`\n```\nreverseproxy-service\n```\n`apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    service: reverseproxy\n  name: reverseproxy\nspec:\n  ports:\n  - name: \"8080\"\n    port: 8080\n    targetPort: 8080\n  selector:\n    service: reverseproxy\n  type: LoadBalancer\n`\n```",
      "solution": "Use `resolver` in `nginx` config\nThe `nginx` `resolver` directive is required.\nNginx is a multiplexing server (many connections in one OS process), so each call of system resolver will stop processing all connections till the resolver answer is received. That's why Nginx implemented its own internal non-blocking resolver.\nIf your config file has static `DNS` names (not generated), and you do not care about track IP changes without `nginx reload`, you don't need `nginx`'s resolver. In this case all `DNS` names will be resolved on startup.\n`Nginx`'s resolver\n`Nginx` `resolver` directive should be used, if you want to resolve domain name in runtime without `nginx` reload.\nE.g.:\n```\n`location /my_uri {\n  resolver kube-dns.kube-system valid=10s;\n  ...\n}\n`\n```\n```\n`location /my_uri {\n  resolver 127.0.0.1:53 ipv6=off valid=10s;\n  ...\n}\n`\n```\nUse the same network (not your case, but still worth noting)\nContainers you are trying to link may not be on the same network.\nYou may want to put them all on the same network.\nIn your case subnets are the same, it's ok:\n`docker-compose`\n```\n`version: '3'\nservices:\n  reverseproxy:\n    ...\n    networks:\n      - example-net\n  udagram-users:\n    ...\n      networks:\n        - example-net\n  udagram-feed:\n    ...\n    networks:\n      - example-net\n  udagram-frontend:\n    ...\n    networks:\n      - example-net\nnetworks:\n  example-net:\n    external: true\n`\n```",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-09-30T12:32:53",
      "url": "https://stackoverflow.com/questions/69390660/nginx-emerg-host-not-found-in-upstream-udagram-users8080-in-etc-nginx-ngi"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 69304930,
      "title": "Configure Nginx with Vue.js, Django Rest Framework as backend and /api/ on same server?",
      "problem": "I am in a process of deploying my newly developed e-commerce to a Ubuntu server that I have. I have already set up Nginx for Frontend and for Backend. The whole application is working fine. The only problem is DRF API that doesn't get anything from the backend (it doesn't send emails, users can't register). All of that gets error 500. It seems to me that I still need to add /api/ to my Nginx configuration, but when I do that the whole app goes down. Could someone explain the best way to set this up in \"sites-available\"? Thank you!\nHere is my Sites-Available for Backend:\n\r\n\r\n`upstream perulab_app_server {\n    server unix:/webapps/perulab/venv/run/gunicorn.sock fail_timeout=0;\n}\n\nserver {\n    listen 8000;\n    server_name 172.16.7.52;\n\n    client_max_body_size 4G;\n\n    location /static/ {\n        root /webapps/perulab/web-backend;\n    }\n\n    location /media/ {\n        root /webapps/perulab/web-backend;\n    }\n\n    location / {\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $http_host;\n        proxy_redirect off;\n        if (!-f $request_filename) {\n            proxy_pass http://perulab_app_server;\n        }\n    }\n}`\r\n\r\n\r\n\nAnd this is my Sites-Available for Backend:\n\r\n\r\n`server {\n    listen 8010;\n    listen [::]:8010;\n    server_name _;\n    charset utf-8;\n    root /webapps/perulab/web-frontend/dist;\n    index index.html index.htm;\n\n    location / {\n        try_files $uri /index.html;\n    }\n}`\r\n\r\n\r\n\nWhen I use it the way it is right now, console prints this error:\n\r\n\r\n`GET http://172.16.7.52:8000/api/v1/get-user-details/ 500 (Internal Server Error)\n\nNameError at /api/v1/get-user-details/\n\nname 'token' is not defined`\r\n\r\n\r\n\nIt says here for example on login that token is not defined when on local machine everything is working fine. Also, Token has nothing to do with Send User Details, it doesn't even have anything related to that in a model.",
      "solution": "I was able to find the solution. Basically, I had to add location configuration to my Backend \"Sites-Available\" file:\n\r\n\r\n`upstream perulab_app_server {\n    server unix:/webapps/perulab/venv/run/gunicorn.sock fail_timeout=0;\n}\n\nserver {\n    listen 8000;\n    server_name 172.16.7.52;\n\n    client_max_body_size 4G;\n\n    location /static/ {\n        root /webapps/perulab/web-backend;\n    }\n\n    location /media/ {\n        root /webapps/perulab/web-backend;\n    }\n\n    location / {\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header Host $http_host;\n        proxy_redirect off;\n        if (!-f $request_filename) {\n            proxy_pass http://perulab_app_server;\n        }\n    }\n\n/ THIS IS THE SOLUTION:\n    location /api/ {\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-NginX-Proxy true;\n        proxy_pass http://perulab_app_server/api/;\n        proxy_ssl_session_reuse off;\n        proxy_set_header Host $http_host;\n        proxy_redirect off;\n    }\n\n    \n    \n}`",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-09-23T20:03:55",
      "url": "https://stackoverflow.com/questions/69304930/configure-nginx-with-vue-js-django-rest-framework-as-backend-and-api-on-same"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 67635073,
      "title": "http only cookie not working on express js with reverse proxy",
      "problem": "Good day people i have a node js appplication which i use nginx as reverse proxy.\nwhenever i set cookie it works but the httpOnly and secure flag is not ticked,\nplease i need solution this is an image of the problemthe cookie when set on browser\nmy nginx configuration\n```\n`app.set(\"trust proxy\", 1);\napp.use(helmet());\napp.use(\n  cors({\n    credentials: true,\n    origin: [\n      \"http://localhost:8080\",\n      \"http://thegainer.xyz\",\n      \"https://thegainer.xyz\"\n    ],\n    exposedHeaders: [\"set-cookie\"]\n  })\n); \n\n  res.cookie(\"token\", JSON.stringify(accessToken), {\nsecure: true,\nhttpOnly: true,\nmaxAge: 2592000000\n`\n```\n});",
      "solution": "oh sorry i got my answer.\nforgot to add `app.set(\"trust proxy\",1)` on my frontend code this happened because I was not using nginx for static files but another nodejs server",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-05-21T12:25:28",
      "url": "https://stackoverflow.com/questions/67635073/http-only-cookie-not-working-on-express-js-with-reverse-proxy"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 67037770,
      "title": "Hosted server returning localhost/web instead",
      "problem": "I have a website host on a server in Digital Ocean that is behaving weirdly.\nThe website is written in Flask which is deployed in Docker and using reverse proxy with a combination of Let's Encrypt to host on the web.\nThe website's domain is mes.th3pl4gu3.com.\nIf I go on `mes.th3pl4gu3.com/web/` the website appears and works normal.\nIf I go on `mes.th3pl4gu3.com/web` it gives me `http://localhost/web/` in the URl instead and conenction fails.\nHowever, when I run it locally, it works fine.\nI've checked my nginx logs, when i browse `mes.th3pl4gu3.com/web/` the access_logs returns success but when i use `mes.th3pl4gu3.com/web` nothing comes to the log.\nDoes anyone have any idea what might be causing this ?\nBelow are some codes that might help in troubleshooting.\n```\n`server {\n\nserver_name   mes.th3pl4gu3.com;\n\n  location / {\n    access_log  /var/log/nginx/mes/access_mes.log;\n    error_log  /var/log/nginx/mes/error_mes.log;\n    proxy_pass  http://localhost:9003; # The mes_pool nginx vip\n  }\n\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/..........\n    ssl_certificate_key /etc/letsencrypt/........\n    include /etc/letsencrypt/.........\n    ssl_dhparam /etc/letsencrypt/......\n\n}\n\nserver {\n    if ($host = mes.th3pl4gu3.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n  listen        80;\n  server_name   mes.th3pl4gu3.com;\n    return 404; # managed by Certbot\n\n}\n`\n```\nDocker Instances:\n```\n`7121492ad994   docker.pkg.github.com/mervin16/mauritius-emergency-services-api/mes:1.2.5     \"uwsgi \napp.ini\"          4 weeks ago    Up 4 weeks   0.0.0.0:9002->5000/tcp   mes-instace-2\nf4dc063e33b8   docker.pkg.github.com/mervin16/mauritius-emergency-services-api/mes:1.2.5     \"uwsgi app.ini\"          4 weeks ago    Up 4 weeks   0.0.0.0:9001->5000/tcp   mes-instace-1\nfb269ed2229a   nginx                                                                         \"/docker-entrypoint.\u2026\"   4 weeks ago    Up 4 weeks   0.0.0.0:9003->80/tcp     nginx_mes\n2ad5afe0afd1   docker.pkg.github.com/mervin16/mauritius-emergency-services-api/mes:1.2.5     \"uwsgi app.ini\"          4 weeks ago    Up 4 weeks   0.0.0.0:9000->5000/tcp   mes-backup\n`\n```\ndocker-compose-instance.yml\n```\n`version: \"3.8\"\n\n# Contains all Production instances\n# Should always stay up\n# In case both instances fails, backup instance will takeover\nservices:\n  mes-instace-1:\n    container_name: mes-instace-1\n    image: \"docker.pkg.github.com/mervin16/mauritius-emergency-services-api/mes:${MES_VERSION}\"\n    networks:\n      - mes_net\n    volumes:\n      - ./data:/app/data\n    env_file:\n      - secret.env\n    ports:\n      - \"9001:5000\"\n    restart: always\n    environment:\n      - MES_VERSION=${MES_VERSION}\n\n  mes-instace-2:\n    container_name: mes-instace-2\n    image: \"docker.pkg.github.com/mervin16/mauritius-emergency-services-api/mes:${MES_VERSION}\"\n    networks:\n      - mes_net\n    volumes:\n      - ./data:/app/data\n    env_file:\n      - secret.env\n    ports:\n      - \"9002:5000\"\n    restart: always\n    environment:\n      - MES_VERSION=${MES_VERSION}\n\nnetworks:\n  mes_net:\n    name: mes_network\n    driver: bridge\n`\n```\ndocker-compose.yml\n```\n`version: \"3.8\"\n\n# Contains the backup instance and the nginx server\n# This should ALWAYS stay up\n\nservices:\n  mes-backup:\n    container_name: mes-backup\n    image: \"docker.pkg.github.com/mervin16/mauritius-emergency-services-api/mes:${MES_VERSION}\"\n    networks:\n      - mes_net\n    volumes:\n      - ./data:/app/data\n    env_file:\n      - secret.env\n    ports:\n      - \"9000:5000\"\n    restart: always\n    environment:\n      - MES_VERSION=${MES_VERSION}\n\n  nginx_mes:\n    image: nginx\n    container_name: nginx_mes\n    ports:\n      - \"9003:80\"\n    networks:\n      - mes_net\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/conf.d/default.conf\n      - ./log/nginx:/var/log/nginx\n    depends_on:\n      - mes-backup\n    restart: always\n\nnetworks:\n  mes_net:\n    name: mes_network\n    driver: bridge\n`\n```\nI have multiple instances for load balancing across apps.\nCan someone please help or if anyone has any clue why this might be happening ?",
      "solution": "As long as I tested the page https://mes.th3pl4gu3.com/web with or without `/` trailing at the end it worked fine.  (Firefox version 87 on Ubuntu)\nMaybe there is a bug / problem with your web browser or any kind of VPN / Proxy you are running. Make sure all of them are off.\nPlus on Nginx you can get rid of trailing `/` using `rewrite` rule\ne.g.\n```\n`location = /stream {\n    rewrite ^/stream /stream/;\n}\n`\n```\nwhich tells Nginx parse `stream` as it is `stream/`\nand for making sure you are not facing any issue because of cached data, disable and clear all the cache. On your web browser hit `F12` -> go to console tab , hit `F1` and there disable cache. On Nginx set \"no cache\" for header, e.g.\n```\n`add_header Last-Modified $date_gmt;\nadd_header Cache-Control 'no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0';\nif_modified_since off;\nexpires off;\netag off;\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-04-10T20:15:35",
      "url": "https://stackoverflow.com/questions/67037770/hosted-server-returning-localhost-web-instead"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 78136016,
      "title": "ASP NET Core service with Nginx Reverse Proxy",
      "problem": "I'm trying to setup some of my ASP NET Core services with a Nginx Reverse Proxy but I've been stuck with the same problem for some time now: Getting my service to use the original path for redirects.\nI have a service called ConfigCloud, that should be accessed via site.net/api/configcloud. Accessing the service works fine but whenever my service performs a redirect or sends a Url to another service, it never includes the /api/configcloud prefix and this prevents the service from being usable.\nThis has been quite a headache when it comes to authentication and authorisation as those processes involve redirects and call-backs. For example, site.net/api/configcloud/account/profile will redirect the user to site.net/account/login, which is not desirable. Also, when my Auth provider (Auth0) wants to send a callback, it will send back site.net/callback instead of site.net/api/configcloud/callback.\nI have attempted many different Kestrel and Nginx configurations to get this working, including those suggested by Microsoft (Link 1, Link 2).\nIt's difficult for me to determine whether the problem lies with my Kestrel config or Nginx config.\nInitially, I would have thought would have been the answer to this problem but that doesn't seem have any effect.\nEnvironment:\n\nASP NET Core 7\nNginx latest\nDocker Compose via WSL 2\n\nCurrent Nginx config:\n```\n`server {\n    listen 443 ssl;\n    listen [::]:443 ssl;\n    \n    server_name localhost site.net;\n    \n    ssl_certificate         /etc/letsencrypt/live/site.net/fullchain.pem;\n    ssl_certificate_key     /etc/letsencrypt/live/site.net/privkey.pem;\n        \n    # Increase client upload size.\n    client_max_body_size 10M;\n    \n    # Reuse ssl sessions, avoids unnecessary handshakes.\n    ssl_session_tickets on;\n\n    location /api/configcloud/ {\n        proxy_pass          https://aurora-configcloud/;\n        proxy_set_header    Host $host;\n        proxy_set_header    Upgrade $http_upgrade;\n        proxy_set_header    Connection $http_connection;\n        proxy_set_header    Referer $http_referer;\n\n        # I'm sure some of these are unnecessary but I've just been trying everything.\n        proxy_set_header    X-Real-IP $remote_addr;\n        proxy_set_header    X-Real-Port $remote_port;\n        proxy_set_header    X-Forwarded-Server $host;\n        proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header    X-Forwarded-Proto $scheme;\n        proxy_set_header    X-Forwarded-Host $host:$remote_port;\n    }\n\n    # Other services\n`\n```\nI would appreciate any assistance on this matter as it has become quite a blocker in trying to learn backend web dev. Thank you.\nEdit:\nI have found a working solution. The following code had to be added to my ASP.NET Core program.\n`  app.Use((httpContext, next) =>\n  {\n      httpContext.Request.PathBase = pathBase;\n      return next();\n  });\n`\nThe above code works as you expect a Base URL to work in other environments, unlike ASP NET Core's UsePathBase.",
      "solution": "I have found a working solution. The following code had to be added to the ASP.NET Core program.\n`  app.Use((httpContext, next) =>\n  {\n      httpContext.Request.PathBase = pathBase;\n      return next();\n  });\n`",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2024-03-10T14:23:58",
      "url": "https://stackoverflow.com/questions/78136016/asp-net-core-service-with-nginx-reverse-proxy"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 77026878,
      "title": "nginx-proxy path based routing gives 404 error for application assets",
      "problem": "I'm attempting to use the path based routing feature of `nginx-proxy/nginx-proxy` to host dozzle at http://media.local/dozzle/.\n```\n`version: \"3\"\n\nservices:\n  nginx-proxy:\n    image: nginxproxy/nginx-proxy\n    ports:\n      - \"80:80\"\n    volumes:\n      - \"/var/run/docker.sock:/tmp/docker.sock:ro\"\n      - \"./nginx/vhost.d:/etc/nginx/vhost.d\"\n\n  dozzle:\n    container_name: dozzle\n    image: amir20/dozzle:latest\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n    environment:\n      - VIRTUAL_HOST=media.local\n      - VIRTUAL_PATH=/dozzle/\n      - VIRTUAL_PORT=8080\n`\n```\nWhen I load http://media.local/dozzle/ in chrome, I get a blank page with the dozzle favicon. The chrome dev tools report\n```\n`/dozzle/:15     GET http://media.local/assets/main-aeb02c57.css net::ERR_ABORTED 404 (Not Found)\n/dozzle/:16     GET http://media.local/assets/main-299e3767.js net::ERR_ABORTED 404 (Not Found)\n`\n```\nI've tried this with services other than dozzle and the result is the same, so I do not think this is a dozzle-specific issue. How can I get the path based routing to include all of the application assets?",
      "solution": "Dozzle creator here. You haven't configured Dozzle correctly. If you want to route all your traffic to a different base, ie. `/dozzle/` then you need to provide `DOZZLE_BASE` env variable. Example here.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2023-09-02T05:37:43",
      "url": "https://stackoverflow.com/questions/77026878/nginx-proxy-path-based-routing-gives-404-error-for-application-assets"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 74360557,
      "title": "No &#39;Access-Control-Allow-Origin&#39; header error, but it&#39;s available",
      "problem": "I have created a proxy server using nginx. I installed SSL certificate using Certbot. After installing SSL, I get `No 'Access-Control-Allow-Origin' header` error on the frontend.  I added the `add_header 'Access-Control-Allow-Origin' '*'` command  to .conf file. But I keep getting the same error.\nError: `Access to fetch at 'https://api.mywebsite.com/api/users' from origin 'https://panel.mywebsite.com' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource. If an opaque response serves your needs, set the request's mode to 'no-cors' to fetch the resource with CORS disabled.`\nmy frontend website: https://panel.mywebsite.com\nmy backend website: https://api.mywebsite.com\n#/etc/nginx/sites-enabled/api.mywebsite.com\n`server {\n\n    server_name api.mywebsite.com;\n    add_header Access-Control-Allow-Origin https://panel.mywebsite.com;\n\n    location / {\n            proxy_pass http://localhost:1337;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_redirect off;\n     }\n\n    listen [::]:443 ssl; # managed by Certbot\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/api.mywebsite.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/api.mywebsite.com/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n}\nserver {\n    if ($host = api.mywebsite.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n    listen 80;\n    listen [::]:80;\n\n    server_name api.mywebsite.com;\n    return 404; # managed by Certbot\n\n}\n`\n#/etc/nginx/sites-enabled/panel.mywebsite.com\n`server {\n\n    server_name panel.mywebsite.com;\n\n    location / {\n            proxy_pass http://127.0.0.1:3000;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_redirect off;\n     }\n\n    listen [::]:443 ssl; # managed by Certbot\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/panel.mywebsite.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/panel.mywebsite.com/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n}\nserver {\n    if ($host = panel.mywebsite.com) {\n        return 301 https://$host$request_uri;\n    } # managed by Certbot\n\n    listen 80;\n    listen [::]:80;\n\n    server_name panel.mywebsite.com;\n    return 404; # managed by Certbot\n\n}\n`",
      "solution": "i fixed problem. Although the CORS error occurred, when I examined the error in detail, I realized that the problem was not caused by CORS, but due to the insufficient max body size value.After increasing the `client_max_body_size` the problem was solved.\n413 Request Entity Too Large - File Upload Issue",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2022-11-08T13:13:14",
      "url": "https://stackoverflow.com/questions/74360557/no-access-control-allow-origin-header-error-but-its-available"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 70172632,
      "title": "Nginx reverse proxy with docker-compose doesn&#39;t forward requests",
      "problem": "I've been creating a micro-frontend project and the glue (nginx) isn't working as expected.\nMy projects are structured as such:\n```\n`/app1\n  Dockerfile\n/app2\n  Dockerfile\n/nginx\n  Dockerfile\n  nginx.conf\n/shell\n  Dockerfile\ndocker-compose.local.yaml\n`\n```\nThe project Dockerfiles look like the following:\n```\n`# ...\n\nFROM nginx:alpine\n\n# Remove default nginx website\nRUN rm -rf /usr/share/nginx/html/*\n\nCOPY --from=builder /app/dist/shell /usr/share/nginx/html\n\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n`\n```\nThe nginx Dockerfile:\n```\n`FROM nginx:alpine\n\nCOPY ./nginx.conf /etc/nginx/conf.d/nginx.conf\n`\n```\nThe `nginx.conf` file:\n```\n`upstream shell {\n  server localhost:3001;\n}\n\nupstream app1 {\n  server localhost:3002;\n}\n\nupstream app2 {\n  server localhost:3003;\n}\n\nlog_format compact '$request $status - $bytes_sent';\naccess_log off;\n\nserver {\n  listen 80;\n  listen [::]:80;\n\n  access_log /var/log/nginx/access.log compact;\n  ssi on;\n\n  location = / {\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_pass  http://shell;\n  }\n\n  location /app1/ {\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_pass  http://app1/;\n  }\n\n  location /app2/ {\n    proxy_set_header Host $host;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_pass  http://app2/;\n  }\n}\n`\n```\nFinally the `docker-compose.local.yaml` file:\n```\n`version: '3.8'\n\nservices:\n  nginx:\n    image: localhost:5000/nginx:alpine\n    build: ./nginx\n    ports:\n      - \"3000:80\"\n    depends_on:\n      - shell\n      - app1\n      - app2\n\n  shell:\n    image: localhost:5000/mf-angular-shell\n    build: ./shell\n    ports:\n      - \"3001:80\"\n\n  app1:\n    image: localhost:5000/mf-angular-app1\n    build: ./app1\n    ports:\n      - \"3002:80\"\n\n  app2:\n    image: localhost:5000/mf-angular-app2\n    build: ./app2\n    ports:\n      - \"3003:80\"\n`\n```\nThe application is then launched via:\n```\n`docker-compose -f docker-compose.local.yaml up -d\n`\n```\nAfter launching I can navigate to the individual apps without issue:\nshell http://localhost:3001/\napp1 http://localhost:3002/\napp2 http://localhost:3003/\nBut when I navigate to the root http://localhost:3000/ I just see the \"Welcome to nginx!\" message.\nWhen navigating to the individual paths such as http://localhost:3000/app1/ I see the following error in the terminal from the proxy:\n`\"/usr/share/nginx/html/app1\" failed (2: No such file or directory)`\nAnd a 404 error in the browser.\nIs the problem due to my overwriting the wrong file? `/etc/nginx/conf.d/nginx.conf` or is it a problem with the configuration itself? Something else entirely?",
      "solution": "The primary issue is that `localhost:` is not accessible between containers. The containers should reference the service names defined in docker-compose.\n`nginx.conf` becomes:\n```\n`upstream shell {\n  server shell:3001;\n}\n\nupstream app1 {\n  server app1:3002;\n}\n\nupstream app2 {\n  server app2:3003;\n}\n...\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-11-30T17:21:15",
      "url": "https://stackoverflow.com/questions/70172632/nginx-reverse-proxy-with-docker-compose-doesnt-forward-requests"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 66756896,
      "title": "How to forward API Response with the same HTTP Status Code and Body through Nginx reverse proxy to the Client",
      "problem": "I am currently dockerizing an API developped in Laravel and I am using Nginx as a reverse_proxy,\nhere is the conf.d file\n```\n`server {\nlisten 80;\nindex index.php index.html;\nroot /var/www/public;\nclient_max_body_size 32M;\n\nfastcgi_intercept_errors on;\nproxy_intercept_errors on;\n\nlocation / {\n    try_files $uri /index.php$is_args$args;\n}\n\nlocation ~ \\.php$ {\n\n    add_header Access-Control-Allow-Origin http://foo.bar;\n    add_header Access-Control-Max-Age 3600;\n    add_header Access-Control-Expose-Headers Content-Length;\n    add_header Access-Control-Allow-Headers Range;\n\n    fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n    fastcgi_pass laravel:9000;\n    fastcgi_index index.php;\n    include fastcgi_params;\n    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n    fastcgi_param PATH_INFO $fastcgi_path_info;\n\n    internal;\n}\n`\n```\nI am getting the Internal server response bodies and 404 Not Found responses but the problem is that the HTTP Status Code is always 200.\nI need the HTTP Status Code to be sent as it is to the client making the request because I am using 401, 403 and others for the web app client application, like this\n```\n`if ($isAuthenticated) {\n   return $token\n} else { \n   return response()->json(['error'='Unauthorized','attempts'=$number ],401);\n}\n`\n```\nThen the 401 Error is catched by Ajax to show a specific alert to the user. And Nginx is getting in the way of doing that with sending back always 200. I tried setting fastcgi_intercept_errors and proxy_intercept_errors on, but it still does not work. The image i am using is nginx:1.19.8-perl and I tried the nginx:1.17-alpine one. Is there any way I can do this ? Or probably I am using Nginx for the wrong purpose and there is a better reverse proxy for APIs ?",
      "solution": "I figured it out. The problem was not with nginx but with the PHP-FPM container, i missed to command the container to use the php.ini-production file as the php.ini configuration file. Adding this command in the Dockerfile fixed the issue and HTTP Errors are being sent back through the nginx reverse proxy the way I want it.\n```\n`RUN mv \"$PHP_INI_DIR/php.ini-production\" \"$PHP_INI_DIR/php.ini\"\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-03-23T04:30:03",
      "url": "https://stackoverflow.com/questions/66756896/how-to-forward-api-response-with-the-same-http-status-code-and-body-through-ngin"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 65535286,
      "title": "EC2 Ubuntu NGINX config HTTPS Redirect giving me error: ERR_TOO_MANY_REDIRECTS",
      "problem": "Background\nI've got an Ubuntu machine running on an AWS EC2 instance (Node/Express app), with its SSL certs setup using Certificate Manager and a Load Balancer. This worked fine for going to my site directly using https, e.g, `https://example.com`. However, using `http`, resulted in an insecure connection.\nChecking on whynopadlock.com, I'm told my web server is not forcing HTTPS. My web server is setup using NGINX as a reverse proxy to my private IP of my EC2 instance. I've hunted around and can't quite seem to find a proper example like mine, although I've tried to piece together what I was able to find.\nWhen I attempt to setup a force HTTPS redirect, I get `ERR_TOO_MANY_REDIRECTS`.\nBefore: Original Nginx Config\n```\n`server {\n    listen 80;\n    location / {\n        proxy_pass http://{{MASKED_EC2_INSTANCE_PRIVATE_IP_FOR_POST}}:8000;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n}\n`\n```\n\nNotes: This config allowed https://example.com to load fine, however there was no redirect if navigating to the site using http://example.com and resulted an insecure connection.\n\nAfter: NGINX Config after adding HTTPS Redirect\n```\n`# HTTP\nserver {\n    listen       80 default_server;\n    listen       [::]:80 default_server;\n    server_name  localhost;\n    return 301   https://$host$request_uri;\n}\n\n# HTTPS\nserver {\n    listen       443 default_server;\n    listen       [::]:443 default_server;\n    server_name  localhost;\n\n    location / {\n        proxy_set_header X-Real-IP  $remote_addr;\n        proxy_set_header X-Forwarded-For $remote_addr;\n        proxy_set_header Host $host;\n        proxy_pass https://{{MASKED_EC2_INSTANCE_PRIVATE_IP_FOR_POST}}:8000;\n        proxy_set_header X-Forwarded-Proto https;\n    }\n}\n`\n```\nIssue\nI see now that when I load the domain with http, I am redirected successfully to https, however I am receiving the error `ERR_TOO_MANY_REDIRECTS`.\nCan anyone help me understand what I'm missing or may be doing wrong in my config?",
      "solution": "Since you are using ALB, you can redirect http to https on the ALB itself. AWS provides a guide how to set it up:\n\nHow can I redirect HTTP requests to HTTPS using an Application Load Balancer?\n\nThe process involves creating http listener and adding redirection action  to it instead of regular forward rule. This way you don't have to perform any changes to your instances, as all is taken care of by the ALB.\nAlso since you are using AWS Certificate Manager you have to use ALB as ACM SSL cert can't be used on instance. The ACM can only be used on a load balancer (ALB, CLB or NLB), CloudFront distro or API Gateway.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-01-02T02:32:01",
      "url": "https://stackoverflow.com/questions/65535286/ec2-ubuntu-nginx-config-https-redirect-giving-me-error-err-too-many-redirects"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 66023562,
      "title": "502 Bad Gateway when using reverse proxy with Docker and Nginx",
      "problem": "I have searched StackOverflow for my problem but I always seem to be hitting the `502 Bad Gateway` with my Nginx Docker configuration. I am trying to access `pgadmin4` using my domain `mydomain.com/pgadmin` instead of `mydomain.com:8060` where `8060` is the port exposed by it's docker container. My `docker-compose.yml` file looks like this:\n```\n`version: '3.5'\n\nservices:\n  reverse-proxy:\n    image: nginx:1.19.6\n    restart: always\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n        \n  postgres:\n    image: postgres:12\n    ports:\n      - \"5432:5432\"\n        \n  pgadmin:\n    image: dpage/pgadmin4\n    depends_on:\n      - postgres\n    ports:\n      - \"8060:80\"\n      \nnetworks:\n  default:\n    external:\n      name: defaultnetwork\n`\n```\nThe `default.conf` file of my nginx container looks like this:\n```\n`upstream pgadmin {\n    server 127.0.0.1:8060;\n}\n\nserver {\n    listen       80;\n    listen  [::]:80;\n    server_name  mydomain.com;\n    \n    root   /usr/share/nginx/html;\n    index  index.html index.htm;\n    \n    location /pgadmin {\n        proxy_pass http://pgadmin;\n    } \n}\n`\n```\nWith this configuration, I keep getting the `502 Bad Gateway` error. Could someone kindly point to me where I am going wrong. I would really appreciate it.\nThanks.\n[EDIT]\nThis is from the docker logs:\n```\n`2021/02/03 08:07:42 [error] 23#23: *2 connect() failed (111: Connection refused) while connecting to upstream, client: ***.***.***.***, server: mydomain.com, request: \"GET /pgadmin HTTP/1.1\", upstream: \"http://127.0.0.1:8082/pgadmin\", host: \"mydomain.com\"\n`\n```",
      "solution": "The 502 problem comes from the loopback IP here:\n\nupstream pgadmin {\nserver 127.0.0.1:8060;\n}\n\n`127.0.0.1` or `localhost` for the NGINX container is the NGINX container itself. You should use the name of the service instead:\n```\n`upstream pgadmin {\n    server pgadmin:8060;\n}\n`\n```\nName of the service comes from the `docker-compose.yml`:\n`services:\n  pgadmin: # \nIf you hit 404 after these changes, this is because you have to change base path of the application. Try using this config:\n```\n`    location /pgadmin/ {\n        proxy_set_header X-Script-Name /pgadmin;\n        proxy_set_header Host $host;\n        proxy_pass http://pgadmin;\n        proxy_redirect off;\n    }\n`\n```",
      "question_score": 1,
      "answer_score": 6,
      "created_at": "2021-02-03T09:14:59",
      "url": "https://stackoverflow.com/questions/66023562/502-bad-gateway-when-using-reverse-proxy-with-docker-and-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 78998304,
      "title": "NGINX reverse proxy returns HTTP 400 with a invalid header line for my flutter app.Works fine in Postman",
      "problem": "I've setup Nginx with reverse proxy to my django backend api. The requests from Postman work perfectly fine but on Flutter I get a HTTP 400 157 from the nginx server while performing a GET request.\nUpon inspecting the log , I see the following :\n```\n`client sent invalid header line: \"\\x3a...\" while reading client request headers\n`\n```\nHere is my nginx.conf.\n```\n`worker_processes auto;\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n\n    log_format custom '$remote_addr - $remote_user [$time_local] \"$request\" '\n    '$status $body_bytes_sent \"$http_referer\" '\n    '\"$http_user_agent\" \"$http_x_forwarded_for\" $request_time';\n\n    #Note that these are defined outside of the server block altho they don't necessarily need to be\n    proxy_cache_path /tmp/nginx levels=1:2 keys_zone=my_zone:10m inactive=60m;\n    proxy_cache_key \"$scheme$request_method$host$request_uri\";\n\n    default_type application/octet-stream;\n\n    include /etc/nginx/mime.types;\n\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 65;\n    types_hash_max_size 4096;\n    \n    \n    upstream my-django-rest-api {\n\n        server 172.16.16.1:8080; # The internal Django API service\n    }\n\n    server {\n        listen 1652;\n\n        # Access & Error Logs\n        access_log /var/log/nginx/access.log custom;\n        error_log /var/log/nginx/error.log;\n\n        location / {\n            proxy_pass http://my-django-rest-api;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n            \n            proxy_cache my_zone;\n            add_header X-Proxy-Cache $upstream_cache_status;\n            proxy_buffering on;\n            proxy_cache_valid 200 302 60m;\n            proxy_cache_valid 404 1m;\n\n            # WebSocket support (nginx 1.4)\n            proxy_http_version 1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection \"upgrade\";\n        }\n    }\n}\n`\n```\n\nWhat Do I need to do on the Nginx end before I start troubleshooting\nit from the Frontend ?\nWhat exactly is \"\\x3a...\" which is termed as Invalid in header line?\n\nFurther to the above, I'm adding the headers that are sent for each Postman and flutter for the same GET request:\nPostman Headers for a GET request\n```\n`Key                      Value\nHost                     \n\nUser-Agent               PostmanRuntime/7.42\n\nAccept                   */*\n\nAccept Encoding          gzip,deflate,br\n\nConnection               keep-alive\n\nAuthorization            Token f384996c63b4****************\n`\n```\nFlutter side functions while request is sent\n```\n` Future get(url,\n      {Map? headers,\n      Map? queryParameters,\n      bool? appendLanguageHeader,\n      bool? appendAuthorizationToken}) async {\n    var finalHeaders = _getHeadersWithConfig(\n        headers: headers,\n        appendLanguageHeader: appendLanguageHeader,\n        appendAuthorizationToken: appendAuthorizationToken);\n\n    if (queryParameters != null && queryParameters.keys.isNotEmpty) {\n      url = url + _makeQueryString(queryParameters);\n    }\n\n    Response? response;\n\n    try {\n      response = await client.get(Uri.parse(url), headers: finalHeaders);\n    } catch (error) {\n      _handleRequestError(error);\n    }\n\n    if (response != null) {\n      return HttpieResponse(response);\n    }\n    throw ();\n  }\n      \n  Map _getHeadersWithConfig(\n      {Map? headers = const {},\n      bool? appendLanguageHeader,\n      bool? appendAuthorizationToken}) {\n    headers = headers ?? {};\n\n    Map finalHeaders = Map.from(headers);\n\n    appendLanguageHeader = appendLanguageHeader ?? true;\n    appendAuthorizationToken = appendAuthorizationToken ?? false;\n\n    if (appendLanguageHeader) finalHeaders['Accept-Language'] = _getLanguage();\n\n    if (appendAuthorizationToken && authorizationToken != null) {\n      finalHeaders['Authorization'] = 'Token $authorizationToken';\n    }\n\n    if (magicHeaderName != null && magicHeaderValue != null) {\n      finalHeaders[magicHeaderName!] = magicHeaderValue!;\n    }\n\n    return finalHeaders;\n  }\n\n  String _getLanguage() {\n    return _localizationService.getLocale().languageCode.toLowerCase();\n  }\n`\n```\n.env.json\n```\n`  {\n  \"API_URL\": \"http://24.XX.XX.XX:70/\",\n  \"MAGIC_HEADER_NAME\": \"\",\n  \"MAGIC_HEADER_VALUE\": \"\",\n  }\n`\n```",
      "solution": "Presumably the empty `magicHeaderName` and `magicHeaderValue` result in the following line being added to the request headers:\n```\n`:\n`\n```\nWhich is not allowed, specifically RFC 9110 defines that the HTTP header name must be non-empty:\n```\n`field-name = token\ntoken = 1*tchar\n`\n```\nThe `1*` means \"at least one\", so an empty name is not allowed.",
      "question_score": 1,
      "answer_score": 4,
      "created_at": "2024-09-18T14:49:45",
      "url": "https://stackoverflow.com/questions/78998304/nginx-reverse-proxy-returns-http-400-with-a-invalid-header-line-for-my-flutter-a"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 70507200,
      "title": "HTTP nginx to HTTPS proxy_pass returns 504 BAD Gateway",
      "problem": "I'm trying to creating a proxy_pass to a https address (my nginx is running under 80 using plain HTTP protocol).\nThis is my declaration in conf file:\n```\n`   location /viacep/ {\n                  proxy_pass https://viacep.com.br/;\n                  proxy_set_header X-Real-IP $remote_addr;\n                  proxy_set_header Host $host;\n                  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n       }\n`\n```\nWell, the idea is when I enter in `localhost/viacep/ws/09340400/json` I got the following address resolution under the hood: https://viacep.com.br/ws/09340400/json. But I got the following error in error.log file:\n```\n`2021/12/28 09:32:59 [error] 34664#0: *1 upstream prematurely closed connection while reading response header from upstream, client: 127.0.0.1, server: , request: \"GET /viacep/ws/09540400/json HTTP/1.1\", upstream: \"https://165.227.126.241:443/ws/09540400/json\", host: \"localhost\"\n`\n```\nI imagine this error occurs because of the address resolved (https://165.227.126.241:443/ws/09540400/json), look it using IP instead of DNS.\nEdit 1\nI tried add `proxy_ssl_server_name on;` but same error.",
      "solution": "NGINX will allways resolve the DNS Name to an IP address.\nThe problem could be with the backend-servers SNI. Given there are multiple sites hosted on this server and the server supports SNI you should send the `server name` by using `proxy_ssl_server_name on;` in your NGINX configuration.\nI have just configured that on my NGINX Version `1.20`\n`server {\n  listen 80;\n\n  location / {\n    proxy_pass https://viacep.com.br/;\n    proxy_set_header Host viacep.com.br;\n    proxy_set_header X-Forwarded-Proto https;\n    proxy_ssl_server_name on;\n\n  }\n}\n\n`\nMake sure you are sending the right `Host` header. In your configuration you are sending `localhost` as `Host` to the upstream server. This will not work as you have noticed correctly.",
      "question_score": 1,
      "answer_score": 6,
      "created_at": "2021-12-28T13:37:49",
      "url": "https://stackoverflow.com/questions/70507200/http-nginx-to-https-proxy-pass-returns-504-bad-gateway"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 68070959,
      "title": "Why doesn&#39;t my Nginx configuration cache the response?",
      "problem": "I have the following Nginx configuration, which we can see from the output of `nginx -T` is syntactically correct. I bolded some relevant parts of the output below:\n```\n\n$ sudo nginx -T\nnginx: the configuration file /etc/nginx/nginx.conf syntax is ok\nnginx: configuration file /etc/nginx/nginx.conf test is successful\n# configuration file /etc/nginx/nginx.conf:\nevents {}\n\nhttp {\n    proxy_cache_path /tmp/cache keys_zone=one:10m levels=1:2 inactive=2M max_size=100g;\n\n    access_log /var/log/nginx/access.log;\n    error_log /var/log/nginx/error.log;\n\n    # Static file server\n    server {\n        listen 127.0.0.1:8080;\n\n        root /opt/nginx-test-data;\n\n        location / {\n        }\n    }\n\n    # Reverse proxy that talks to server defined above\n    server {\n        listen 127.0.0.1:8081;\n        proxy_cache_min_uses 1;\n\n        location / {\n            proxy_pass http://127.0.0.1:8080;\n            proxy_cache one;\n        }\n    }\n}\n\n```\nI know in normal practice that the server and proxy server are on different hosts. At the moment I am just trying to learn how to configure an Nginx proxy server with content caching, since Nginx is new to me.\nI have the following 2MB file of random bytes:\n```\n`$ ls -lh /opt/nginx-test-data/random.bin \n-rw-rw-r-- 1 shane shane 2.0M Jun 21 11:39 /opt/nginx-test-data/random.bin\n`\n```\nWhen I curl the reverse proxy server, I get a 200 response:\n```\n\n$ curl --no-progress-meter -D - http://localhost:8081/random.bin --output local-random.bin\nHTTP/1.1 200 OK\nServer: nginx/1.18.0 (Ubuntu)\nDate: Mon, 21 Jun 2021 15:50:07 GMT\nContent-Type: text/plain\nContent-Length: 2000000\nConnection: keep-alive\nLast-Modified: Mon, 21 Jun 2021 15:39:54 GMT\nETag: \"60d0b2ca-1e8480\"\nAccept-Ranges: bytes\n\n```\nHowever, my cache directory is empty:\n```\n`$ sudo ls -a /tmp/cache/\n.  ..\n`\n```\nI checked both `/var/log/nginx/access.log` and `/var/log/nginx/error.log`, and there were no errors logged.\nWhat have I done wrong so that there are no entries in my cache directory after making a request to the reverse proxy server?",
      "solution": "It turns out that I needed to add a `proxy_cache_valid` directive (though it is not clear to me why this is necessary - I assumed simply using `proxy_cache` in a `location` would turn on caching on its own).\nMy `nginx.conf` that worked (note the new line in bold):\n```\n\nevents {}\n\nhttp {\n    proxy_cache_path /tmp/cache keys_zone=one:10m levels=1:2 inactive=2M max_size=100g;\n\n    access_log /var/log/nginx/access.log;\n    error_log /var/log/nginx/error.log;\n\n    # Static file server\n    server {\n        listen 127.0.0.1:8080;\n\n        root /opt/nginx-test-data;\n\n        location / {\n        }\n    }\n\n    # Reverse proxy that talks to server defined above\n    server {\n        listen 127.0.0.1:8081;\n        proxy_cache_min_uses 1;\n\n        location / {\n            proxy_pass http://127.0.0.1:8080;\n            proxy_cache one;\n            proxy_cache_valid 200 10m;\n        }\n    }\n}\n\n```",
      "question_score": 1,
      "answer_score": 6,
      "created_at": "2021-06-21T17:47:55",
      "url": "https://stackoverflow.com/questions/68070959/why-doesnt-my-nginx-configuration-cache-the-response"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 66176321,
      "title": "Keycloak behind reverse proxy mixes internal and external addresses",
      "problem": "I'm trying to setup a keycloak instance behind a reverse proxy with nginx and I almost did it.\nMy (partial) docker-compose:\n```\n`version: '3.4'                                                                          \n                                                                                    \nservices:  \n  [...]\n                                                                                                                                                                                                                                                 \n  keycloak:                                                                             \n    image: jboss/keycloak                                                                                                                                     \n    environment:                                                                        \n      - DB_VENDOR=[vendor]\n      - DB_USER=[user]                                                                      \n      - DB_PASSWORD=[password]\n      - DB_ADDR=[dbaddr]\n      - DB_DATABASE=[dbname]\n      - KEYCLOAK_USER=[adminuser]                                                         \n      - KEYCLOAK_PASSWORD=[adminpassword]                                                       \n      - KEYCLOAK_IMPORT=/tmp/my-realm.json                                           \n      - KEYCLOAK_FRONTEND_URL=https://auth.mydomain.blah/auth                          \n      - PROXY_ADDRESS_FORWARDING=true                                                   \n      - REDIRECT_SOCKET=proxy-https\n                                                 \n  [...]\n`\n```\nmy nginx conf is just\n```\n`server {\n    listen       443 ssl;\n    server_name  auth.mydomain.blah;\n  \n    ssl_certificate /etc/letsencrypt/live/auth.mydomain.blah/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/auth.mydomain.blah/privkey.pem;\n\n    location / {\n        proxy_pass http://keycloak:8080;\n    }\n}\n`\n```\nand it works, I can access keycloak from `https://auth.mydomain.blah/auth` BUT when I look at `https://auth.mydomain.blah/auth/realms/campi/.well-known/openid-configuration` I get this:\n```\n`{\n  \"issuer\": \"https://auth.mydomain.blah/auth/realms/campi\",\n  \"authorization_endpoint\": \"https://auth.mydomain.blah/auth/realms/campi/protocol/openid-connect/auth\",\n  \"token_endpoint\": \"http://keycloak:8080/auth/realms/campi/protocol/openid-connect/token\",\n  \"introspection_endpoint\": \"http://keycloak:8080/auth/realms/campi/protocol/openid-connect/token/introspect\",\n  \"userinfo_endpoint\": \"http://keycloak:8080/auth/realms/campi/protocol/openid-connect/userinfo\",\n  \"end_session_endpoint\": \"https://auth.mydomain.blah/auth/realms/campi/protocol/openid-connect/logout\",\n  \"jwks_uri\": \"http://keycloak:8080/auth/realms/campi/protocol/openid-connect/certs\",\n  \"check_session_iframe\": \"https://auth.mydomain.blah/auth/realms/campi/protocol/openid-connect/login-status-iframe.html\",\n  [...]\n`\n```\nwhy does keycloak mix internal and external uris? what am I missing?",
      "solution": "https://www.keycloak.org/docs/latest/server_installation/index.html#_setting-up-a-load-balancer-or-proxy\nYour reverse proxy/nginx is not forwarding host headers properly, so Keycloak has no idea which host/protocol has been used for the request and it using backend/internal host name. You need to set a few `proxy_set_header` lines:\n```\n`server {\n    listen       443 ssl;\n    server_name  auth.mydomain.blah;\n  \n    ssl_certificate /etc/letsencrypt/live/auth.mydomain.blah/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/auth.mydomain.blah/privkey.pem;\n\n    location / {\n            proxy_pass          http://keycloak:8080;\n            proxy_set_header    Host               $host;\n            proxy_set_header    X-Real-IP          $remote_addr;\n            proxy_set_header    X-Forwarded-For    $proxy_add_x_forwarded_for;\n            proxy_set_header    X-Forwarded-Host   $host;\n            proxy_set_header    X-Forwarded-Server $host;\n            proxy_set_header    X-Forwarded-Port   $server_port;\n            proxy_set_header    X-Forwarded-Proto  $scheme;\n    }\n}\n`\n```",
      "question_score": 1,
      "answer_score": 7,
      "created_at": "2021-02-12T18:23:02",
      "url": "https://stackoverflow.com/questions/66176321/keycloak-behind-reverse-proxy-mixes-internal-and-external-addresses"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 72917269,
      "title": "FastAPI, nginx, Docker Explicitly Add Each Endpoint",
      "problem": "I have a simple `FastAPI` that returns a string based on a query parameter at the endpoint `/day`. Trying to deploy using `Docker` and `nginx` as a reverse proxy. In order to get `http://localhost:3000/api/day?day_num=5` to work, I needed to explicitly add `location /api/day` to my `nginx-setup.conf`. I would receive an error if I only had `location /api/` and tried to visit `http:localhost:3000/api/day`.\nHow can I avoid having to explicitly add each endpoint? Is there a way to make `/api/day`, `/api/docs` and any other valid endpoints for `localhost:8000` (port Docker exposes for the backend service) work when I visit `http:localhost:3000/api/{valid endpoints}`?\n`main.py`\n```\n`from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/day\", tags=[\"Dates\"])\nasync def get_day_of_week(day_num: int = 0):\n    \"\"\"\n    Get the current day of week\n    \"\"\"\n    days = ['Sun', 'M', 'T', 'W', 'Th', 'F', 'S']\n    return days[day_num]\n`\n```\nI am trying to use `nginx` as a reverse proxy.\n`nginx-setup.conf`\n```\n`upstream api {\n    server backend:8000;\n}\n\nserver {\n    listen 8080;\n\n    location /api/ {\n        proxy_pass http://api;\n        proxy_set_header Host $http_host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n\n    location /api/day {\n        proxy_pass http://api/day;\n        proxy_set_header Host $http_host;\n        proxy_set_header X-Real-IP $remote_addr;\n    }\n}\n`\n```\n`docker-compose.yml`\n```\n`version: '3'\n\nservices:\n  backend:\n    build:\n      context: ./backend\n    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --root-path /api\n    ports:\n      - \"8000:8000\"\n\n  nginx:\n    image: nginx:latest\n    ports:\n     - 3000:8080\n    volumes:\n      - ./nginx/nginx-setup.conf:/etc/nginx/conf.d/default.conf:ro\n    depends_on:\n      - backend\n`\n```",
      "solution": "If you don't have a trailing slash in the `proxy_pass` entry, the path will be included verbatim. So:\n```\n`location /api/ {\n    proxy_pass http://api;\n    proxy_set_header Host $http_host;\n    proxy_set_header X-Real-IP $remote_addr;\n}\n`\n```\nWill result in the backend seeing `/api/day` as the request path. Since your application only expects `/day`, you have to modify your `proxy_pass` directive to include a trailing slash - this tells nginx to strip the matching part from the `location /api/` entry (and you should have a trailing slash here as well).\n```\n`location /api/ {\n    proxy_pass http://api/;  # <- trailing slash\n    proxy_set_header Host $http_host;\n    proxy_set_header X-Real-IP $remote_addr;\n}\n`\n```",
      "question_score": 1,
      "answer_score": 5,
      "created_at": "2022-07-08T23:42:31",
      "url": "https://stackoverflow.com/questions/72917269/fastapi-nginx-docker-explicitly-add-each-endpoint"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 71489926,
      "title": "Jenkins server --httpListenAddress=127.0.0.1 not working",
      "problem": "recently I installed Jenkins server, and wanted to hide it behind Nginx proxy.\nMy Nginx proxy works fine and I read to restrict Jenkins to `127.0.0.1:8080` therefore, I edited the config file `/etc/default/jenkins` and put below line of code:\n```\n`JENKINS_ARGS=\"--webroot=/var/cache/$NAME/war --httpPort=8080 --httpListenAddress=127.0.0.1\"\n`\n```\nAfter restarting jenkins, I still have access to Jenkins on port `8080`\nEnvironment:\nUbuntu 20.04\nOpenJDK 11\nJenkins 2.332.1\nNetstat output:\n```\n`    sudo netstat -plnt\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name\ntcp        0      0 0.0.0.0:8080            0.0.0.0:*               LISTEN      2313/java\n\ntcp        0      0 0.0.0.0:80              0.0.0.0:*               LISTEN      970/nginx: master p\ntcp        0      0 127.0.0.53:53           0.0.0.0:*               LISTEN      708/systemd-resolve\ntcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      946/sshd: /usr/sbin\ntcp        0      0 127.0.0.1:631           0.0.0.0:*               LISTEN      757/cupsd\n\ntcp6       0      0 :::80                   :::*                    LISTEN      970/nginx: master p\ntcp6       0      0 :::22                   :::*                    LISTEN      946/sshd: /usr/sbin\ntcp6       0      0 ::1:631                 :::*                    LISTEN      757/cupsd\n`\n```\nP.S. I tried on EC2/Amazom linux 2, same issue",
      "solution": "As of Jenkins version 2.332.1, which you indicated you are running, Jenkins made the switch from running as a service using classic SysV init scripts over to fully integrating with systemd on Linux distributions that support it, which includes Ubuntu 20.04.  I don't see any signs that the systemd unit file for Jenkins ever parses `/etc/default/jenkins`, meaning those settings are only parsed by the SysV init script, which would explain why your configuration had no effect there.\nAs you found, setting the environment variable in `/lib/systemd/system/jenkins.service` indeed works, but your instinct is absolutely correct that it is not best practice to directly edit the unit file managed by the packaging system.  As with most things in Linux, the `/etc` directory is where administrators are meant to put their configuration files, and `/lib` and `/usr/lib` are reserved for the package manager, so luckily systemd is no exception to this and provides a mechanism for such changes.\nSystemd has the concept of \"drop-in\" directories where you can place \".conf\" files with partial systemd unit configurations whose directives will override those in the main unit file.  From the systemd.unit man page:\n\nAlong with a unit file `foo.service`, a \"drop-in\" directory `foo.service.d/` may exist. All files with the suffix \".conf\" from this directory will be merged in the alphanumeric order and parsed after the main unit file itself has been parsed. This is useful to alter or add configuration settings for a unit, without having to modify unit files. Each drop-in file must contain appropriate section headers.\n\nHere's how I set up Jenkins 2.332.1 on Ubuntu 20.04 using a systemd drop-in override to bind the listener to 127.0.0.1:\nVerify Jenkins is running and listening on all addresses/interfaces:\n```\n`$ sudo ss -tlnp | grep 8080\nLISTEN    0         50               *:8080               *:*        users:((\"java\",pid=2688,fd=116))       \n`\n```\nCreate a systemd drop-in directory for Jenkins:\n```\n`$ sudo mkdir /etc/systemd/system/jenkins.service.d\n`\n```\nCreate an override file using your favorite editor.  You can name it whatever you want as long as it has a `.conf` extension.  Personally, I prefer something descriptive and to begin with a number so that I can control the lexicographic order in which the files are parsed, should I ever end up with multiple override files.  Given that, I created a file `/etc/systemd/system/jenkins.service.d/50-listen-address-override.conf` with the following content:\n```\n`[Service]\nEnvironment=\"JENKINS_LISTEN_ADDRESS=127.0.0.1\"\n`\n```\nNow, all we have to do is tell systemd that we made some changes we want it to reparse:\n```\n`$ sudo systemctl daemon-reload\n`\n```\nAnd we can restart Jenkins to give it its new config:\n```\n`$ sudo systemctl restart jenkins\n`\n```\nIf we verify our work, we can now see that Jenkins is only bound to 127.0.0.1:\n```\n`$ sudo ss -tlnp | grep 8080\nLISTEN   0        50          [::ffff:127.0.0.1]:8080          *:*       users:((\"java\",pid=31636,fd=116))\n`\n```\nFor what it's worth, you can also use the command `systemctl edit jenkins` to create the override, and systemd will create the drop-in directory and override file automatically for you and drop you into your default editor to write the file contents, however it does not give you the freedom to choose your own name for the override file, giving it instead a generic name of `override.conf`.",
      "question_score": 1,
      "answer_score": 5,
      "created_at": "2022-03-15T23:55:13",
      "url": "https://stackoverflow.com/questions/71489926/jenkins-server-httplistenaddress-127-0-0-1-not-working"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 77646139,
      "title": "Nginx reverse proxy for minio presigned url throwing SignatureDoesNotMatch error",
      "problem": "minio is running on url: abc.example.com:9000\nFor application we have xyz.example.com,\nI want to reverse proxy the minio presigned URL with application url (xyzminio.example.com/presigned_url).\n```\n`server {\n  listen 80;\n  server_name xyzminio.example.com;\n\n  location / {\n    proxy_pass https://abc.example.com:9000;\n    #proxy_pass_request_headers off;        \n    proxy_set_header Host $http_host;        \n    #proxy_set_header Host $host;\n    proxy_buffering off;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $remote_addr;        \n    #proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n  }\n}\n`\n```\nBut I'm getting below exception with 403 error code\n\n```\n`SignatureDoesNotMatchThe request signature we calculated does not match the signature you provided. Check your key and signing method.\n`\n```",
      "solution": "After few trial and error below configuration worked:\n```\n`server {\n  listen 80;\n  server_name xyzminio.example.com;\n\n  location / {\n    proxy_pass https://abc.example.com:9000;\n    proxy_pass_request_headers off;\n   }\n  }\n`\n```",
      "question_score": 1,
      "answer_score": 4,
      "created_at": "2023-12-12T13:32:58",
      "url": "https://stackoverflow.com/questions/77646139/nginx-reverse-proxy-for-minio-presigned-url-throwing-signaturedoesnotmatch-error"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 75820301,
      "title": "How to configure Nginx reverse proxy to NodeJS app",
      "problem": "I am new to nginx and I am following tutorials to set up nodejs app with nginx reverse proxy but nothing seems to be working. I have a very simple configuration and I\u2019m not sure what the problem is can anybody let me know? I am just trying to get the standard welcome to nginx page to be served at my_domain/ and then proxy to my node app at my_domain/api but the node app doesn\u2019t seem to be working. When I navigate to my_domain/ I get the standard welcome to nginx page, but when I go to my_domain/api I get \"cannot GET /api\"\nThe default config file for nginx\n```\n`server {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n\n    \n\n    root /var/www/html;\n\n    index index.html index.htm index.nginx-debian.html;\n\n    server_name my_domain;\n\n    location / {\n        # First attempt to serve request as file, then\n        # as directory, then fall back to displaying a 404.\n        try_files $uri $uri/ =404;\n    }\n\n    location /api {\n        proxy_pass http://localhost:3000;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n\n    \n}\n`\n```\nThe nodejs app\n```\n`const app = express()\n\napp.use(express.json())\n\napp.get('/', (req, res) => {\n    res.send('Hello world')\n})\n\napp.get('/products', (req, res) => {\n    res.send('All Products')\n})\n\napp.get('/products/:id', (req, res) => {\n    const id = req.params.id\n    res.send(`Product: ${id}`)\n})\n\nconst PORT = 3000\n\napp.listen(PORT, () => {\n    console.log(`App listening on port ${PORT}`)\n})\n`\n```",
      "solution": "you need to use proxi_pass on your case.\nfor nginx what you can do is to rewrite the requests for the relevant port, in your case to 3000.\nthis is how i handle it.\n```\n`    location /node/ {\n    rewrite /node/(.*)  /$1 break;\n    proxy_pass http://localhost:3000;\n}\n`\n```",
      "question_score": 1,
      "answer_score": 4,
      "created_at": "2023-03-23T08:42:02",
      "url": "https://stackoverflow.com/questions/75820301/how-to-configure-nginx-reverse-proxy-to-nodejs-app"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 73813770,
      "title": "Modify nginx config file in Elasticbeanstalk to increase body size .platform / .ebextension folders not taking effect",
      "problem": "I need to upload large files to the server (some of them reach 1GB) and I get this error:\n```\n`\n\n    413 Request Entity Too Large\n\n    \n        413 Request Entity Too Large\n    \n    \n    nginx/1.20.0\n\n`\n```\nI know this error comes from ningx, and I need to increaste\n\nclient_max_body_size\n\nI created a .ebextensions folder with this structure:\n\n.ebextensions/nginx/conf.d/proxy.conf\n\nAlso I created a .platform folder with the same structure\n\n.platform/nginx/conf.d/proxy.conf\n\nproxy.conf contains:\n\nclient_max_body_size        999M;\n\nAfter doing that and deploying it keeps throwing the same error.\nThe platform (created by elastic beanstalk) is\n\nLinux/UNIX\n\nI can see in the logs (eb-engine.log) this, but Im not sure if it is because of what I did:\n\n2022/09/22 11:00:35.780593 [INFO] Executing instruction: start proxy\nwith new configuration 2022/09/22 11:00:35.780613 [INFO] Running\ncommand /bin/sh -c /usr/sbin/nginx -t -c\n/var/proxy/staging/nginx/nginx.conf 2022/09/22 11:00:35.803451 [INFO]\nnginx: the configuration file /var/proxy/staging/nginx/nginx.conf\nsyntax is ok nginx: configuration file\n/var/proxy/staging/nginx/nginx.conf test is successful\n\nThanks!",
      "solution": "For anyone facing the same issue. I was actually doing it okey, but I missed moving the .platform folder to the dist/ folder in the build step.\nSo I just did:\n```\n`- cp -R .platform/ dist/.platform\n`\n```\nin the postbuild step.",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-09-22T13:25:43",
      "url": "https://stackoverflow.com/questions/73813770/modify-nginx-config-file-in-elasticbeanstalk-to-increase-body-size-platform"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 72534833,
      "title": "Docker - Nginx proxy_pass &quot;502 bad gateway&quot; only with client routes?",
      "problem": "I have the following docker compose:\n`version: '3.1'\n\nservices:\n\n  backend:\n    container_name: backend\n    image: backendnode\n    restart: always\n    ports:\n      - 3000:3000\n\n  frontend:\n    container_name: frontend\n    image: frontnginx\n    restart: always\n    ports:\n      - 4200:80\n\n  apigw:\n    image: reverseproxy\n    restart: always\n    ports:\n      - 80:80\n    depends_on: \n      - frontend\n      - backend\n`\nThis is the `reverseproxy` image nginx.conf:\n```\n`worker_processes auto;\n  \nevents { worker_connections 1024; }\n\nhttp {\n\n    server {\n        listen 80;\n        server_name localhost 127.0.0.1;\n \n        location / {\n            proxy_pass         http://frontend:4200;\n            proxy_set_header   X-Forwarded-For $remote_addr;\n        }\n        location /api {\n            proxy_pass         http://backend:3000;\n            proxy_set_header   X-Forwarded-For $remote_addr;\n        }\n    }\n \n}\n`\n```\nWhen running `docker-compose run`, I get the following results:\n\nlocalhost:80/api/users: works great, nginx redirects to backend properly.\nlocalhost:80/index.html: not working, I get the following error:\n\nconnect() failed (111: Connection refused) while connecting to upstream, client: 172.20.0.1, server: localhost, request: \"GET /index.html HTTP/1.1\", upstream: \"http://172.20.0.5:4200/index.html\", host: \"localhost:80\"\n\n`Frontend` is a simple nginx web server, this is its nginx.conf:\n```\n`events{}\n\nhttp {\n\n    include /etc/nginx/mime.types;\n\n    server {\n        listen 80;\n        server_name localhost;\n        root /usr/share/nginx/html;\n        index index.html;\n\n        location / {\n            try_files $uri $uri/ /index.html;\n        }\n    }\n}\n`\n```\nAny idea why reverse proxy it's not working with frontend routes?",
      "solution": "Created answer from the comment thread:\nDocker networking works like this: if you use communication within docker's network, you need to refer to the internal ports. Since port mapping is used for the \"outside world\". So in your case, you would need to refer to \"frontend:80\" instead of 4200.",
      "question_score": 1,
      "answer_score": 3,
      "created_at": "2022-06-07T18:43:31",
      "url": "https://stackoverflow.com/questions/72534833/docker-nginx-proxy-pass-502-bad-gateway-only-with-client-routes"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 70563622,
      "title": "Pod with ClusterIP had a different IP than static IP of ingress",
      "problem": "I'm managing a small Kubernetes cluster on Azure with Postgres. This cluster is accessible through an Nginx controller with a static IP.\nThe ingress routes to a ClusterIP to a pod which uses a Postgres instance. This Postgres instance has all IPs blocked, with a few exceptions for my own IP and the static IP of the ingress.\nThis worked well until I pushed an update this morning, where to my amazement I see in the logs an error that the pods IP address differs from the static ingress IP, and it has a permission error because of it.\nMy question: how is it possible that my pod, with ClusterIP, has a different outer IP address than the ingress static IP I assigned it?\nNote that the pod is easily reached, through the Ingress.",
      "solution": "`Ingresses` and `Services` handle only incoming pod traffic. Pod outgoing traffic IP depends on Kubernetes networking implementation you use. By default all outgoing connections from pods are source NAT-ed on node level which means pod will have an IP of node which it runs on. So you might want to allow worker node IP addresses in your Postgres.",
      "question_score": 1,
      "answer_score": 3,
      "created_at": "2022-01-03T10:14:52",
      "url": "https://stackoverflow.com/questions/70563622/pod-with-clusterip-had-a-different-ip-than-static-ip-of-ingress"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 66632271,
      "title": "Nginx reverse proxy for keycloak",
      "problem": "I've deployed a keycloak server at localhost:7070 (in Docker container, it run on 8080), now I want to setup a reverse proxy for it. Here is my conf:\n```\n`server {\n    listen       11080 ;\n\n    location /auth/ {\n        proxy_set_header Host $host;\n        proxy_set_header X-Forwarded-Server $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Host   $host;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        proxy_pass  http://localhost:7070/auth/;\n    }\n}\n`\n```\nwhen I access `http://my-ip:11080/auth`, I could see the welcome page. But when I tried to login following the link on the welcome page, then it show error and the url now is `http://my-ip:auth/admin/`, but I expect `http://my-ip:11080/auth/admin/` with the port 11080\nWhen I manually type `http://my-ip:11080/auth/admin` and press Enter, it redirect to `http://my-ip/auth/admin/master/console/`, but I expect `http://my-ip:11080/auth/admin/master/console/`  with the port 11080\nI also tried many solutions that I found but no luck for now. Could you guy tell me what is the problem here?\nUPDATE: docker-compose.yml\n```\n`version: \"3.7\"\nservices:\n  keycloak:\n    volumes:\n      - keycloak-pgdb:/var/lib/postgresql/data\n    build:\n      context: .\n      dockerfile: Dockerfile\n    ports:\n      - \"7070:8080\"\n    environment:\n      - KEYCLOAK_USER=admin\n      - KEYCLOAK_PASSWORD=password\n      - DB_VENDOR=postgres\n      - POSTGRES_PASSWORD=root\n      - POSTGRES_DB=keycloak\n      - DB_ADDR=localhost\n      - DB_USER=postgres\n      - DB_PASSWORD=root\n      - PROXY_ADDRESS_FORWARDING=true\nvolumes:\n  keycloak-pgdb:\n`\n```\nDocker ps:\n```\n`CONTAINER ID  IMAGE                   COMMAND           CREATED          STATUS          PORTS                               NAMES\n30ad65460a0c  pic-keycloak_keycloak   \"entrypoint.sh\"   38 minutes ago   Up 38 minutes   5432/tcp, 0.0.0.0:7070->8080/tcp    pic-keycloak_keycloak_1\n`\n```",
      "solution": "The application in the container is not aware that you are forwarding port `11080`, so when the application renders the response, if it's following the `X-Forwarded-xxxxx` headers, it will use the `X-Forwarded-Poroto` to determine where the redirection should be sent.\nDepending on your application, you have 2 options do deal with this cases:\n\nApplication that recognizes a `X-Forwarded-Port` header can be told to redirect to a specific port, like in this case:\n```\n`    proxy_set_header X-Forwarded-Port 11080\n`\n```\n\nLegacy application that do not obey the rules provided in the header can be handled by response rewrite pass. Here is example with sub_filter:\n```\n`sub_filter     'http:/my-ip/auth'    'http:/my-ip:11080/auth';\n`\n```\nFor sub_filter to work, the module should be installed and enabled `--with-http_sub_module `",
      "question_score": 1,
      "answer_score": 3,
      "created_at": "2021-03-15T05:12:29",
      "url": "https://stackoverflow.com/questions/66632271/nginx-reverse-proxy-for-keycloak"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 77974944,
      "title": "Django FileResponse crashes with large files",
      "problem": "...I have a Django application with a lot of data and a MariaDB database running on a Raspberry Pi (OS = Debian 12). The application uses Daphne as Webserver because there are also Django Channels components in there (Websocket). Now I want to implement a backup feature, that automatically dumps the database, zips together the dump with the other data files and has the browser automatically download the ZIP-file. So I made a view for the download:\n```\n`def downbackup(request): \n  if request.user.is_superuser:\n    filename = '../temp/backup/backup.zip'\n    sourcefile = open(filename, 'rb')\n    return FileResponse(sourcefile)\n  else:\n    return(HttpResponse('No Access.'))\n`\n```\nThat view is called from the relevant template via url and verything is fine. Until we meet large files in real live. In this case (filesize around 6 GB) Daphne immediatly stops operation, and the Raspi crashes so deep that I have to switch power on and of. Also, in Monitorix I see huge memory consumption spikes after these crashes. But there is no error message in the Daphne logs, in the Django logs (incl. debug-setting) nor in the journalctl. Nginx (the reverse proxy) reports an uplink timeout (504). I think I learned from the Django documentation the FileResponse buffers the file to avoid memory consumption, but something must be wrong here. Any ideas, recommendations?",
      "solution": "I would strongly advise not to use Django as a file server, it is not intended to use that way. Typically nginx is used for example with an `X-Accel-Redirect`\u00a0[nginx-doc] such that Django essentially says where the file is, and nginx, can then return the file in a manner that only nginx provides the file when an `X-Accel-Redirect` is present.\nSo essentially you work with:\n```\n`def downbackup(request):\n    if request.user.is_superuser:\n        response = HttpResponse()\n        response['Content-Disposition'] = 'attachment; filename=backup.zip'\n        response['X-Accel-Redirect'] = '/protected/temp/backup/backup.zip'\n        return response\n    else:\n        return HttpResponse('No Access.')`\n```\nand then the nginx server thus serves a protected path with:\n```\n`location /protected/ {\n  internal;\n  alias   /path/one/above/tmp/;\n}`\n```\nthis will not only make sure there are no problems with nginx buffering and steaming, but can also result in the nginx caching certain files and thus boosting efficiency of the webserver.\nThe `internal` keyword in the `/protected/` config means that you can not make requests from outside to this path. So a person can not visit `/protected/temp/backup/backup.zip`, it can only be used for internal communication in nginx with the \"sub-servers\".",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2024-02-10T23:25:03",
      "url": "https://stackoverflow.com/questions/77974944/django-fileresponse-crashes-with-large-files"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 76929695,
      "title": "Running Keycloak container behing Nginx Reverse proxy with Docker swarm",
      "problem": "I want to run the Keycloak container in a non-root path ( /auth ) behind a nginx reverse proxy in docker swarm mode.\nThis is my Dockerfile:\n```\n`FROM quay.io/keycloak/keycloak:latest as builder\n\n# Enable health and metrics support\nENV KC_HEALTH_ENABLED=true\nENV KC_METRICS_ENABLED=true\n\n# Configure a database vendor\nENV KC_DB=mysql\n\nWORKDIR /opt/keycloak\n\n#Generating a Self-Signed Certificate\nRUN keytool -genkeypair -storepass password -storetype PKCS12 -keyalg RSA -keysize 2048 -dname \"CN=server\" -alias server -ext \"SAN:c=DNS:app.example.com\" -keystore conf/server.keystore\nRUN /opt/keycloak/bin/kc.sh build\n\nFROM quay.io/keycloak/keycloak:latest\nCOPY --from=builder /opt/keycloak/ /opt/keycloak/\n\n#change these values to point to a running Mysql instance\nENV KC_DB=mysql\nENV KC_DB_URL=jdbc:mysql://keycloak_database:3306/keycloak\nENV KC_DB_USERNAME=keycloak\nENV KC_DB_PASSWORD=keycloak\nENV KC_HOSTNAME_URL=https://app.example.com/auth/\nENV KC_HOSTNAME_ADMIN_URL=https://app.example.com/auth/\nENV KC_PROXY=edge\nENV KC_LOG_LEVEL=INFO\nENV KC_HOSTNAME_DEBUG=true\nENV KC_HOSTNAME_STRICT=false\n\nENTRYPOINT [\"/opt/keycloak/bin/kc.sh\"]\n`\n```\nUsing the above docker file I have used this command to run the keycloak service in which keycloakpro is the image name\n```\n`docker service create --name keycloak --network test_overlay --constraint node.labels.server==true --env KEYCLOAK_ADMIN=admin --env KEYCLOAK_ADMIN_PASSWORD=admin keycloakpro start --optimized\n`\n```\nThis is my nginx reverse proxy configuration,\n```\n`server {\n        listen 443 ssl;\n        \n        index index.html index.htm index.nginx-debian.html;\n\n        server_name app.example.com;\n        ssl_certificate /home/certificate.crt;\n        ssl_certificate_key /home/private.key;\n        \n        proxy_set_header Host $http_host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n        access_log /var/log/nginx/reverse-access.log;\n        error_log /var/log/nginx/reverse-error.log;\n\n     \n\n        location /backend {\n                    rewrite ^/backend(.*)$ $1 break;\n                    proxy_pass http://backend-server:9999/;\n                    proxy_redirect off;\n        }\n        \n        \n        location /auth {\n                    rewrite ^/auth(.*)$ $1 break;\n                    proxy_set_header Host $host;\n                    proxy_set_header X-Real-IP $remote_addr;\n                    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n                    proxy_set_header X-Forwarded-Proto https;\n                    proxy_set_header X-Forwarded-Host app.example.com;\n                    proxy_set_header X-Forwarded-Port 8443;\n                    proxy_pass https://keycloak:8443/;\n                    add_header Set-Cookie $http_cookie;\n       \n        }\n    \n        location / {\n                    rewrite ^/(.*)$ /$1 break;\n                    proxy_pass http://react-server/;\n                    proxy_http_version 1.1;\n                    proxy_set_header Upgrade $http_upgrade;\n                    proxy_set_header Connection \u2018upgrade\u2019;\n                    proxy_cache_bypass $http_upgrade;\n\n        }\n        \n    \n}\n\nserver {\n    listen 80;\n\n    server_name app.example.com;\n\n    return 301 https://$host$request_uri;\n}\n`\n```\nIn the above nginx configuration, I have a backend service running in the \"/backend\" location block and a react server served by nginx in the root path.\nWhen all the above configurations are used together, keycloak will be accessible through https://app.example.com/auth\nWhen I go to https://app.example.com/auth/, it redirects me to the Keycloak page. This URL takes me to the admin's page: https://app.example.com/auth/admin/.\nThis will initiate the OAuth2 flow login page: https://app.example.com/auth/realms/master/protocol/openid-connect/auth?client_id=security-admin-console ...\nOnce I reach this point, Keycloak will store a cookie in the browser, which is not happening in my case. If I access it using https://app.example.com:8443/, the cookie is set, and I am unable to log in. Only if the request goes throw proxy it won't set the cookie.\nI have checked various articles related to this but none of them are able to solve my issue.\nAny help is appreciated.",
      "solution": "It was my mistake actually, I was ignoring the cookie headers in the nginx.conf file of the reverse proxy due to which I got the above issue.\nTo be more specific it's because of these lines,\n```\n`proxy_ignore_headers Expires Cache-Control Set-Cookie;\nproxy_hide_header Set-Cookie;\n`\n```\nCommenting these two lines out did the trick.",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2023-08-18T15:14:55",
      "url": "https://stackoverflow.com/questions/76929695/running-keycloak-container-behing-nginx-reverse-proxy-with-docker-swarm"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 75918429,
      "title": "Error &quot;upstream timed out (110: Unknown error) while SSL handshaking to upstream&quot; when trying to reverse proxy",
      "problem": "I want to get info from a web socket api and this needs to send an api-key as query string, so I want to use nginx as a reverse proxy to get a request and then add the api-key . After that send this request to the destination url (I don't want my users to be able to inspect the browser and find that key!!!)\nBelow is the request that my Nuxtjs app is sending :\nhttp://my-site.com/ws/signalr/negotiate?clientProtocol=2.1\nand this is the nginx config in /etc/nginx/sites-available/my-site.com :\n```\n`server {\n    listen          80;             # the port nginx is listening on\n    server_name     my-site.com;    # setup your domain here\n\n    gzip            on;\n    gzip_types      text/plain application/xml text/css application/javascript;\n    gzip_min_length 1000;\n\n    charset utf-8;\n\n    root /var/www/mysite;\n\n    location ~* \\.(?:ico|gif|jpe?g|png|woff2?|eot|otf|ttf|svg|js|css)$ {\n        expires $expires;\n        add_header Pragma public;\n        add_header Cache-Control \"public\";\n\n        try_files $uri $uri/ @proxy;\n    }\n\n    location / {\n        expires $expires;\n        #add_header Content-Security-Policy \"default-src 'self' 'unsafe-inline' https: data:; base-uri 'self';\";\n        add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains; preload\" always;\n        add_header X-Frame-Options \"SAMEORIGIN\";\n\n        try_files $uri $uri/index.html @proxy; # for generate.subFolders: true\n        # try_files $uri $uri.html @proxy; # for generate.subFolders: false\n    }\n\n    location /ws/ {\n        proxy_pass https://external-api.net:7890/;\n        set $args $args&apiKey=MYAPIKEY;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"Upgrade\";\n        proxy_set_header Host external-api.net;\n    }\n}\n\n`\n```\nBut this gives me an error in error.log :\nupstream timed out (110: Unknown error) while SSL handshaking to upstream, client: x.x.x.x, server: my-site.com, request: \"GET /ws/signalr/negotiate?clientProtocol=2.1 HTTP/1.1\", upstream: \"https://y.y.y.y:7890/signalr/negotiate?clientProtocol=2.1&apiKey=MYAPIKEY\", host: \"my-site.com\"\nHow can I make this work ?\nFYI : I don't use Docker ,Containers or load balancer. So I didn't put upstream in my nginx config.\nAdding `proxy_read_timeout 3600;` to my location block didn't work.",
      "solution": "I've found the solution. In my case, the problem was with the SSL. I've added the below lines to my NGINX location block configuration which I explained earlier in the main question :\n```\n`proxy_ssl_name $host;\nproxy_ssl_server_name on;\nproxy_ssl_session_reuse off;\n`\n```\nand then reload NGINX :\n```\n`systemctl reload nginx\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2023-04-03T12:23:55",
      "url": "https://stackoverflow.com/questions/75918429/error-upstream-timed-out-110-unknown-error-while-ssl-handshaking-to-upstream"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 75034728,
      "title": "WSO2 + NGINX - Problem to access created APIs",
      "problem": "Situation:\nEnviroment:\n1 Server:  Oracle Linux\nMicro-integrator 4.1.0 running\nApi-Manager 4.1.0 running\nAdmin,Publisher, DevPortal sites can be accessed within the server and the LAN\nAn API I've created with oauth2 (authorization+token) can be accessed within the LAN (via Postman)\nNOW...I want to expose that API to internet.  My IT Team addedfollowing to the DMZ server (NGINX) conf file, where oauth2 is to invoke the auth services  and dsFenicio is the API .\n```\n`    location /oauth2 {\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n            proxy_pass https://192.168.135.64:9443;\n            proxy_read_timeout  300;\n            proxy_ssl_server_name on;\n            proxy_ssl_session_reuse off;\n            proxy_ssl_verify off;\n    }\n\n    location /dsFenicio {\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n            proxy_pass https://192.168.135.64:8243;\n            proxy_read_timeout  300;\n            proxy_ssl_server_name on;\n            proxy_ssl_session_reuse off;\n            proxy_ssl_verify off;\n    }\n`\n```\nThe Problem:\nWhen I sent the oauth2 autorization code request (from postman), I received a msg in the browser stating: \"Suspicious authentication attempts found\nSuspicious login attempts found during the authentication process. Please try signing in again\"\n\nand this is in the Logs (wso2carbon.log):\nERROR {org.wso2.carbon.identity.application.authentication.framework.handler.request.impl.DefaultRequestCoordinator} - Exception in Authentication Framework org.ws$wso2.carbon.identity.application.authentication.framework.exception.FrameworkException: Session nonce cookie value is not matching for session with sessionDataKey: bf74d0ec-05ef-4682- ...",
      "solution": "This is due to a feature called Session Nonce Cookie Validation which is enabled by default.\nI was able to reproduce this scenario and was able to solve this situation while keeping the session nonce cookie validation enabled. The following steps were followed.\n\nExposed the `/commonauth`, `/authenticationendpoint`, `/logincontext` endpoints through nginx in addition to the `/oauth2` endpoint.\nAdded the following to the `deployment.toml`\n\n```\n`[authentication.endpoints]\nlogin_url=\"https:///authenticationendpoint/login.do\"\nretry_url=\"https:///authenticationendpoint/retry.do\"\n`\n```\nWithout the above steps, you can disable this feature also for your scenario to work. This feature can be disabled by adding the following to the `deployment.toml` file.\n```\n`[session.nonce.cookie]\nenabled=\"false\"\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2023-01-06T19:19:08",
      "url": "https://stackoverflow.com/questions/75034728/wso2-nginx-problem-to-access-created-apis"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 74677904,
      "title": "Upstream timed out error when deploying Docker Nginx FastAPI application on Google Cloud",
      "problem": "I'm trying to deploy simple FastAPI app with Docker and Nginx proxy on Google Cloud using simple ssh-terminal window.\nMy nginx.conf:\n```\n`access_log                  /var/log/nginx/app.log;\nerror_log                   /var/log/nginx/app.log;\n\nproxy_headers_hash_max_size 512;\nproxy_headers_hash_bucket_size 128;\n\nproxy_set_header Host $http_host;\nproxy_set_header Upgrade $http_upgrade;\nproxy_set_header Connection $proxy_connection;\nproxy_set_header X-Real-IP $remote_addr;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_set_header X-Forwarded-Proto $proxy_x_forwarded_proto;\nproxy_set_header X-Forwarded-Ssl $proxy_x_forwarded_ssl;\nproxy_set_header X-Forwarded-Port $proxy_x_forwarded_port;\nproxy_set_header X-Original-URI $request_uri;\nproxy_set_header Proxy \"\";\n\nupstream app_server {\n  server example.com:8000;\n}\n\nserver {\n  server_name               example.com;\n  listen                    80;\n  return 301 https://$host$request_uri;\n}\n\nserver {\n  listen                  443 ssl;\n  server_name             example.com;\n  ssl_certificate         /root/ssl/cert.pem;\n  ssl_certificate_key     /root/ssl/key.pem;\n  location / {\n    proxy_pass \"http://app_server\";\n  }\n}\n`\n```\nMy docker-compose.yml:\n```\n`version: '3.8'\n\nservices:\n  reverse-proxy:\n    image: jwilder/nginx-proxy\n    container_name: reverse-proxy\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - /var/run/docker.sock:/tmp/docker.sock:ro\n      - ./nginx:/etc/nginx/conf.d\n      - ./ssl/cert1.pem:/root/ssl/cert.pem\n      - ./ssl/privkey1.pem:/root/ssl/key.pem\n      - ./ssl/dhparam.pem:/etc/nginx/dhparam/dhparam.pem\n    networks:\n      - reverse-proxy\n\n  web:\n    environment: [.env]\n    build: ./project\n    ports:\n      - 8000:8000\n    command: gunicorn main:app -k uvicorn.workers.UvicornWorker -w 2 -b 0.0.0.0:8000\n    volumes:\n      - ./project:/usr/src/app\n    networks:\n      - reverse-proxy\n      - back\n\nnetworks:\n  reverse-proxy:\n    external:\n      name: reverse-proxy\n  back:\n      driver: bridge\n`\n```\nAfter run `docker-compose up` command and going to example.com address, I get error:\n\n*3 upstream timed out (110: Connection timed out) while connecting to upstream...\n\nAlso, I have opened ports with Google Cloud Firewall service (checked with netstat command) and configured my VM's instance with network parameters from this article.\nI don't understand why I receive 504 Gateway Time-out cause my service work with the similar configuration on a simple VPS hosting, and also it works from the inside Google Cloud VM's ssh-terminal when using curl and check localhost instead example.com domain. I want to know how to run my service on Google Cloud VM using only docker-compose util for this purpose?",
      "solution": "In Nginx config file, try to mention the web container name:\n```\n`upstream app_server {\n  server web:8000;\n}\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-12-04T16:11:51",
      "url": "https://stackoverflow.com/questions/74677904/upstream-timed-out-error-when-deploying-docker-nginx-fastapi-application-on-goog"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 73994600,
      "title": "Logging Middleware Microservice",
      "problem": "I am required to save logs into a MySQL database of each request and response made to the backend. The issue is that we are migrating to microservices architecture. The backend was made with NodeJS and Express, and it has a middleware that does this task. Currently, it has this middleware attached to each microservice.\n\nI would like to isolate this middleware as its own microservice. The issue is that I don't know how to redirect the traffic this way. This is how I would like to manage it:\n\nI would like to do it this way, because we can make changes or add features to the middleware without having to implement it in each microservice. This is the middleware's code:\n```\n`const connection = require(\"../database/db\");\n\nconst viewLog = (req, res, next) => {\n  const oldWrite = res.write,\n    oldEnd = res.end,\n    chunks = [],\n    now = new Date();\n\n  res.write = function (chunk) {\n    chunks.push(chunk);\n    oldWrite.apply(res, arguments);\n  };\n\n  res.end = function (chunk, error) {\n    if (chunk) chunks.push(chunk);\n\n    const bodyRes = Buffer.concat(chunks).toString(\"utf8\");\n\n    connection.query(\"CALL HospitalGatifu.insertLog(?,?,?,?,?)\", [\n      `[${req.method}] - ${req.url}`,\n      `${JSON.stringify(req.body) || \"{}\"}`,\n      bodyRes,\n      res.statusCode === 400 ? 1 : 0,\n      now,\n    ]);\n\n    oldEnd.apply(res, arguments);\n  };\n\n  next();\n};\n\nmodule.exports = viewLog;\n`\n```\nI think there might be a way to manage this with Nginx which is the reverse proxy that we are using. I would like to get an approach of how to change the logs middleware.",
      "solution": "Perhaps you might want to take a look at the sidecar pattern which is used in microservice architectures for common tasks (like logging).\nIn short, a sidecar runs in a container besides your microservice container. One task of the sidecar could be intercepting network traffic and logging requests and responses (and a lot of other possible tasks). The major advantage of this pattern is that you don't need to change any code in your microservices and you don't have to manage traffic redirection yourself. The latter will be handled by the sidecar itself.\nThe disadvantage is that you are required to run your microservices containerized and use some kind of container orchestration solution. I assume this being the case since you are moving towards a microservices based application.\nOne question about the log service in between of the webapp and the NGNIX server. What if the logging services goes down for some reason, is it acceptable for the entire application to go down?",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2022-10-08T07:23:03",
      "url": "https://stackoverflow.com/questions/73994600/logging-middleware-microservice"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 73838887,
      "title": "Setting up react and nodejs servers on same machine",
      "problem": "I am setting up a reactjs application on port 3000 as well as a nodejs API server on port 3500 on the same box on the internet. Assume the box has a domain name example.com, and I am using nginx in reverse proxy to receive the end users over https, and internally direct it to the port 3000 of the reactjs server.\nOn the react code, while calling axios API for a get command, which of the following should I be using:\n\nlocalhost:3500\nhttp://localhost:3500\nhttps://localhost:3500\nexample.com:3500\nhttp://example.com:3500\nhttps://example.com:3500\n\nFew tests I did:\n\nAccess from my browser the reactjs application successfully as example.com (nginx does the mapping to port 3000)\nUsing https://reqbin.com/ I was able to access the nodejs server API and get the correct result using: http://example.com:3500/users\nUsing https instead of http causes an error: SSL connection error Error code: 10035",
      "solution": "If end user is supposed to connect over https to the react server, then the react server as well as the nodejs server should be running in https mode, or the browser will block the request and it will never reach the server.\nHere is how to:\n\nRun the react server in https mode:\n\nChange nginx reverse proxy configuration to be:\n\n```\n`\n         proxy_pass https://localhost:3000;\n\n`\n```\n\nChanged the URL for the nodejs server that axios is calling from `http://localhost:3500` to `https://example.com:3500`\n\nAfter npm run build, and upload the build directory to the server, run the following commands:\n\n```\n`su\nserve -s build --listen 3000 --ssl-cert \"/etc/letsencrypt/live/example.com/fullchain.pem\" --ssl-key \"/etc/letsencrypt/live/example.com/privkey.pem\"\n`\n```\n\nRun the nodejs server in https mode:\n\nChange the code of server.js with the following:\n\n```\n`    const https = require('https');\n    const fs = require('fs');\n    \n    const options = {\n      key: fs.readFileSync('/etc/letsencrypt/live/example.com/privkey.pem'),\n      cert: fs.readFileSync('/etc/letsencrypt/live/example.com/fullchain.pem')\n    };\n    \n    https.createServer(options, app).listen(PORT, ()=>{\n       console.log(`Server running https on port ${PORT}`)\n      });\n\n`\n```\n\nRun the following commands:\n\n```\n`\n    su\n    node server\n\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-09-24T18:32:19",
      "url": "https://stackoverflow.com/questions/73838887/setting-up-react-and-nodejs-servers-on-same-machine"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 73110585,
      "title": "Unable to setup Mercure with docker and Nginx (502 Bad Gateway)",
      "problem": "I'm currently trying to set up a project with Mercure. My initial project has been setup by someone else, so I have very few knowledge of either Nginx or Docker.\nWe've tried some solutions found when looking through it but it's too different from our config to be able to apply any of them... And we don't want to break anything of course.\nThat said here is the issue :\nWe have integrated Mercure to our Symfony project and it's working fine in a local environment. However, we can't make it work in a production environment (meaning HTTPS in enabled). At first, we had issues with cors_policy, but now we just run through a 502 error.\nHere is our configuration :\ndocker-compose.yml (mercure part) :\n`  dj_mercure:\n    image: dunglas/mercure\n    container_name: dj_mercure\n    restart: unless-stopped\n    ports:\n      - \"3000:3000\"\n    networks:\n      - core\n    environment:\n      SERVER_NAME: ':3000'\n      MERCURE_PUBLISHER_JWT_KEY: '${MERCURE_SECRET}'\n      MERCURE_SUBSCRIBER_JWT_KEY: '${MERCURE_SECRET}'\n      # Set the URL of your Symfony project (without trailing slash!) as value of the cors_origins directive\n      MERCURE_EXTRA_DIRECTIVES: |\n        cors_origins https://${HOST}\n        use_forwarded_headers \"1\"\n    # Comment the following line to disable the development mode\n    #command: /usr/bin/caddy run -config /etc/caddy/Caddyfile.dev\n    volumes:\n      - caddy_data:/data\n      - caddy_config:/config\n\nnetworks:\n  core:\n    driver: bridge\n\nvolumes:\n  caddy_data:\n  caddy_config:\n`\nI'd like to point that our env variable HOST contains `dev.mysite.fr`\nAnd here is the default.conf file of Nginx :\n```\n`server {\n    listen 80 default_server;\n\n    server_name localhost;\n    root /var/www/html/public;\n    index index.php index.html index.htm;\n\n    location /.well-known/mercure {\n        proxy_pass http://127.0.0.1:3000;\n        proxy_read_timeout 24h;\n        proxy_http_version 1.1;\n        proxy_set_header Connection \"\";\n\n        ## Be sure to set USE_FORWARDED_HEADERS=1 to allow the hub to use those headers ##\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Host $host;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    location / {\n        # try to serve file directly, fallback to index.php\n        try_files $uri /index.php$is_args$args;\n    }\n\n    # Dev\n    location ~ ^/(index_dev|config)\\.php(/|$) {\n        fastcgi_pass dj_php:9000;\n        fastcgi_split_path_info ^(.+\\.php)(/.*)$;\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;\n        fastcgi_param DOCUMENT_ROOT $realpath_root;\n    }\n\n    # Prod\n    location ~ ^/index\\.php(/|$) {\n        fastcgi_pass dj_php:9000;\n        fastcgi_split_path_info ^(.+\\.php)(/.*)$;\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;\n        fastcgi_param DOCUMENT_ROOT $realpath_root;\n        internal;\n    }\n\n    # return 404 for all other php files not matching the front controller\n    # this prevents access to other php files you don't want to be accessible.\n    location ~ \\.php$ {\n        return 404;\n    }\n\n   # return 404 for all other php files not matching the front controller\n   # this prevents access to other php files you don't want to be accessible.\n   location ~ \\.php$ {\n     return 404;\n   }\n\n}\n`\n```\nI only added the `location /.well-known/mercure` part to the file. Everything else was already set up, so I' not sure if I should modify it or not.\nFinally, we have this code in our Javascript :\n`const url = new URL('https://dev.mysite.fr/.well-known/mercure');\nurl.searchParams.append('topic', \"http://somesite.local/xyz\");\neventSource = new EventSource(url);\neventSource.onmessage = event => { // ...\n}\n`\nBut I keep getting a 502 Bad Gateway error basically saying :\n```\n`2022/07/25 13:46:59 [error] 44#44: *24 connect() failed (111: Connection refused) while connecting to upstream, client: 172.18.0.5, server: localhost, request: \"GET /.well-known/mercure?topic=http%3A%2F%2Fsomesite.local%2Fxyz HTTP/1.1\", upstream: \"http://127.0.0.1:3000/.well-known/mercure?topic=http%3A%2F%2Fsomesite.local%2Fxyz\", host: \"dev.mysite.fr\", referrer: \"https://dev.mysite.fr/fr/admin/dashboard\"\n`\n```\nWe feel like we're really close to the answer, but our lack of knowledge is getting in the way. We have not a complete idea of that we're doing, so is there anyone here who could help us understand and fix this ?\nThanks!",
      "solution": "Well, it turns out the answer was given on the Docker forums, so I'll share the solution just in case someone is interested :\nAs stated by meyay, we changed this line\n```\n`- proxy_pass http://127.0.0.1:3000;\n+ proxy_pass http://dj_mercure:3000;\n`\n```\nAnd now the request is properly redirected to the Mercure Hub. We still have an issue to fix, but at least this is working correctly for now!",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-07-25T16:04:07",
      "url": "https://stackoverflow.com/questions/73110585/unable-to-setup-mercure-with-docker-and-nginx-502-bad-gateway"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 72710633,
      "title": "Fixing nginx sub_filter?",
      "problem": "I'm trying to fix a misbehaving app behind my reverse proxy - basically, it drops absolute URLs into pages.\nMy conf looks like\n```\n`...\n\nlocation /openproject/ {\n    proxy_set_header Host ;\n    proxy_set_header X-Real-IP $remote_addr;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_pass http:///openproject/;\n\n    sub_filter 'http:' 'https:';\n    sub_filter_once on;\n    sub_filter_last_modified on;\n}\n...\n`\n```\nthings in <> are replaced to protect my hosts.. and yes the misbehaving app is OpenProject\nIt doesn't seem to be working and debug doesn't say anything about substitutions happening..\nIs there anything that I've done wrong?\nnginx -V is\n\nnginx version: nginx/1.18.0 built with OpenSSL 1.1.1k  25 Mar 2021\n(running with OpenSSL 1.1.1o  3 May 2022) TLS SNI support enabled\nconfigure arguments: --with-cc-opt='-g -O2\n-ffile-prefix-map=/build/nginx-q9LD4J/nginx-1.18.0=. -fstack-protector-strong -Wformat -Werror=format-security -fPIC -Wdate-time -D_FORTIFY_SOURCE=2' --with-ld-opt='-Wl,-z,relro -Wl,-z,now -fPIC' --prefix=/usr/share/nginx --conf-path=/etc/nginx/nginx.conf --http-log-path=/var/log/nginx/access.log --error-log-path=/var/log/nginx/error.log --lock-path=/var/lock/nginx.lock --pid-path=/run/nginx.pid --modules-path=/usr/lib/nginx/modules --http-client-body-temp-path=/var/lib/nginx/body --http-fastcgi-temp-path=/var/lib/nginx/fastcgi --http-proxy-temp-path=/var/lib/nginx/proxy --http-scgi-temp-path=/var/lib/nginx/scgi --http-uwsgi-temp-path=/var/lib/nginx/uwsgi --with-compat --with-debug --with-pcre-jit --with-http_ssl_module --with-http_stub_status_module --with-http_realip_module --with-http_auth_request_module --with-http_v2_module --with-http_dav_module --with-http_slice_module --with-threads --with-http_addition_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_sub_module",
      "solution": "Found this https://marsbard.github.io/2016-07-30-replace-urls-behind-nginx-reverse-proxy/\nseems I needed the config to be:\n```\n`location /openproject/ {\n\n        proxy_set_header Accept-Encoding \"\"; # no compression allowed or next won't work\n\n        sub_filter \"http:///\" \"https:///\";\n        sub_filter_once off;\n\n        proxy_set_header Host ;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Host $host:$server_port;\n\n        proxy_pass http:///openproject/;\n\n}\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-06-22T08:28:35",
      "url": "https://stackoverflow.com/questions/72710633/fixing-nginx-sub-filter"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 72341779,
      "title": "Pass param to @proxy location?",
      "problem": "I'd like to set up nuxt with NGINX as load balancer. Additionally, I'd like to add some caching to the images.\nNow I get 404 for my images using this:\n```\n`    location ~ ^/img.+\\.(?:ico|gif|jpe?g|webp|png|woff2?|eot|otf|ttf|svg|js|css)$ {\n        expires 365d;\n        add_header Pragma public;\n        add_header Cache-Control \"public\";\n\n        try_files $uri $uri/ @proxy;\n    }\n    \n    location @proxy {\n        expires 365d;\n        add_header Content-Security-Policy \"default-src 'self' 'unsafe-inline';\";\n        add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains; preload\" always;\n        add_header X-Frame-Options \"SAMEORIGIN\";\n        add_header X-Cache-Status $upstream_cache_status;\n\n        proxy_redirect                      off;\n        proxy_set_header Host               $host;\n        proxy_set_header X-Real-IP          $remote_addr;\n        proxy_set_header X-Forwarded-For    $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto  $scheme;\n        proxy_ignore_headers        Cache-Control;\n        proxy_http_version          1.1;\n        proxy_read_timeout          1m;\n        proxy_connect_timeout       1m;\n        proxy_pass http://1649681_app/$request_uri;\n        #proxy_cache                 nuxt-cache;\n        #proxy_cache_bypass          $arg_nocache; # probably better to change this\n        #proxy_cache_valid           200 302  60m; # set this to your needs\n        #proxy_cache_valid           404      1m;  # set this to your needs\n        #proxy_cache_lock            on;\n        #proxy_cache_use_stale error timeout http_500 http_502 http_503 http_504;\n        #proxy_cache_key             $uri$is_args$args;\n    } \n`\n```\nIt seems like `$request_uri` is wrong in the line `proxy_pass http://1649681_app/$request_uri` - but how can I pass the requested path to the `@proxy`-location?",
      "solution": "No, it isn't completely wrong to specify an URI using variables for the `proxy_pass` directive inside the named (as well as the regex) locations. However such a thing will have a drawback - if you can't specify your upstream address using IP rather than hostname, you'll need either a `resolver` defined in your configuration (worse) or an additional `upstream` block to define your `1649681_app` backend (better). More details can be found here (exactly the same is applicable to named locations too).\nBeing that said, how do you think, what a request URI will be passed to the upstream specified in the `proxy_pass` directive if you won't specify any explicitly? It will be exactly the URI being processed (and if for some reason you'd need to pass a modified URI instead, you'd need to to modify it via the `rewrite` rules).\nFor the given configuration, assuming you don't need to modify the request URI or query arguments, you should simply use the\n`proxy_pass http://1649681_app;\n`\nAnd, do you understand what the `$uri/` parameter does exactly mean? It makes the `try_files` directive to check if the given URI is a directory to search an index file inside it. I really doubt you need it using that kind of regex pattern. Remove it, it is only an extra (some kind of expensive) system kernel `stat` call. Use\n`try_files $uri @proxy;\n`\ninstead.",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-05-23T00:43:48",
      "url": "https://stackoverflow.com/questions/72341779/pass-param-to-proxy-location"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 71393797,
      "title": "Putting NGINX in front of kafka",
      "problem": "I have elasticsearch, filebeat and kibana behind NGINX server and all three of them uses ssl and basic authentication of Nginx reverse proxy. I want to place kafka behind NGINX as well. Kafka is communicating with filebeat. Is there any possible way that filebeat (with ssl) and kafka (without ssl) can communicate?\nI mean is there any exception kind of thing that we can add in NGINX configuration?",
      "solution": "There's not much benefit to using Nginx with Kafka beyond the initial client connection. In other words, yes, you can use `stream` directive, in theory, for `tcp` reverse proxy, and point `bootstrap.servers` at it, but Kafka will return its `advertised.listeners` after that, and clients then bypass Nginx to communicate directly with individual brokers (including authentication)\nRelated\n\nAllow access to kafka via nginx",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2022-03-08T11:52:15",
      "url": "https://stackoverflow.com/questions/71393797/putting-nginx-in-front-of-kafka"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 70012004,
      "title": "pass or write the username from Nginx into an app",
      "problem": "Hi I am an absolute beginer in `Nginx`! I use Nginx as a reverse proxy in front of a shiny server and recognised that Nginx writes two files `html` and `log`. In `access.log` I can see the usernames. The important part of my Nginx config file contains this part\n```\n`http {\n    server_tokens off;\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log  logs/nginx_shiny_access.log;\n\n    sendfile    on;\n    keepalive_timeout 65;\n    auth_ldap_cache_enabled on;\n    auth_ldap_cache_expiration_time 10000;\n    auth_ldap_cache_size 1000;\n \n`\n```\nI can see the user names in `logs/nginx_shiny_access.log` because of `$remote_user`.\nHow can I get the user names in `html` file and just  temporary because I need the user names in the application and I do not know how can I get them?\nThank you in advance.",
      "solution": "In the case of reverse proxy,  `nginx.conf` has generally the following structure:\n```\n`http{ ...\n...\n   ldap_server MY_WEBSITE {\n       url ...\n        binddn ...;\n        binddn_passwd ...;\n        group_attribute member;\n        group_attribute_is_dn on;\n                           }\n    server {\n        listen 443 ssl http2;\n        server_name  localhost *.example.com;\n        ssl_certificate     /apps/my.cer;\n        ssl_certificate_key /apps/my.key;\n        proxy_max_temp_file_size 0;\n        add_header xv-nginx-remote_user $remote_user;\n           }\n}\n`\n```\nNew is  `add_header xv-nginx-remote_user $remote_user;`\nThen, one can define a java script function in `ui.R`:\n```\n`library(shinyjs)\nlibrary(shiny)\n    \n    shinyUI(fluidPage(\n      \n    useShinyjs(),  # Set up \n    tags$script('\n        shinyjs.init = function() {\n        var client = new XMLHttpRequest();\n        client.open(\"GET\", \"\" , true);\n        client.send();\n        return client.onreadystatechange = function() {\n        var remote_user = client.getResponseHeader(\"xv-nginx-remote_user\");\n        Shiny.onInputChange(\"USERNAME\", remote_user);}\n        };\n      '),\n      \n      verbatimTextOutput(\"USERNAME\")\n      \n))\n`\n```\nand one has to ask for members in LDAP-group in `server.R`\n```\n`     if(Sys.info()[\"sysname\"] == \"Linux\") {\n        ldap.members <- paste(\"ldapsearch -LLL -x -h dcwi.org.com -b \\\"dc=org,dc=com\\\" -D \\\n\"CN=\",Sys.getenv(\"ldaptu\"),\",OU=...,DC=org,DC=com\\\" -w \",Sys.getenv(\"ldappwd\"),\"\\\"CN=....\\\" member\")\n        ....\n      } \n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2021-11-17T22:49:12",
      "url": "https://stackoverflow.com/questions/70012004/pass-or-write-the-username-from-nginx-into-an-app"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 69163969,
      "title": "openResty fails to write log header",
      "problem": "I have the following configuration to write logs to access.log\nSTART Header logging with LUA with Masking\n```\n`    set $resp_header \"\";\n    header_filter_by_lua_block {\n        local rh = ngx.resp.get_headers()\n        for k, v in pairs(rh) do\n            ngx.var.resp_header = ngx.var.resp_header .. k..\"=\"..v..\" \"\n        end}\n`\n```\nEND Header logging with LUA with Masking\nThis works fine for most of my upstream responses. but for the one that sends duplicate header of the same name \"Set-Cookie\" and both are pretty lengthy in number of characters. nginx error log says .\n[error] 3142684#3142684: 790582 failed to run header_filter_by_lua: header_filter_by_lua:11: attempt to concatenate local 'v' (a table value)\nI am looking into all possible LUA documentation. Any help will be appreciated.\nAs a workaround I have set the header \"Set-Cookie\" forcefully in nginx.\n#---\nfor k, v in pairs(rh) do\nif k:lower() == (\"set-cookie\") then\nv=\"REDACTED\"\nend\n#---\nThanks.",
      "solution": "Some of the headers are allowed to repeat (`Set-Cookie` is one of them) and will be returned as a table by `get_headers()` function, which your code doesn't take into account (hence the error you're getting).\nReplace `ngx.var.resp_header .. k..\"=\"..v..\" \"` with something like `ngx.var.resp_header .. k..\"=\"..(type(v) == \"table\" and table.concat(v, \";\") or v)..\" \"`",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2021-09-13T15:58:30",
      "url": "https://stackoverflow.com/questions/69163969/openresty-fails-to-write-log-header"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 67431335,
      "title": "reverse proxy doesn&#39;t work with .svc url?",
      "problem": "here's my attempt to do a reverse proxy using url rewrite in `IIS` from `mysubdomaintarget.mytargetdomain.com` to `mysubdomainreal.myrealdomain.com`\n```\n`\n    \n        \n            \n                \n                    \n                        \n                        \n                    \n                    \n                \n            \n        \n        \n            \n                \n                    \n                    \n                    \n                        \n                        \n                    \n                \n            \n            \n                \n                    \n                    \n                \n                \n                    \n                    \n                \n                \n                    \n                        \n                    \n                    \n                        \n                    \n                \n            \n        \n    \n\n`\n```\nIf I call website using `mysubdomaintarget.mytargetdomain.com/myApp` it works (render the page/etc). But if I call `mysubdomaintarget.mytargetdomain.com/myApp.svc` I got an 404.\nWhy? Where am I wrong on this configuration?\nEDIT\nHere's the failedRequest tag's attribute:\n```\n`\n`\n```\nEDIT2\nHere's the last event I got from failed request tracking:\n```\n`\n \n  \n  0\n  1\n  0\n  2\n  0x0\n  \n  \n  \n  MyPC\n \n \n  {80000549-1000-FB00-B63F-84710C7967BB}\n  2180\n  993\n  404\n  0\n \n \n  GENERAL_REQUEST_END\n \n \n  {D42CF7EF-DE92-473E-8B6C-621EA663113A}\n \n\n`\n```\nits not \"talking\" at all. Where do I see any error from this last Event?\nEDIT3\nxml opened by browser:",
      "solution": "In order to allow WCF to use multiple domain you should set `multipleSiteBindingsEnabled` to `true`.\nThe following configuration should fix your issue.\n`\n    \n\n`\n`multipleSiteBindingsEnabled`\n\nA Boolean value that specifies whether multiple IIS bindings per site is enabled. \nIIS consists of web sites, which are containers for virtual applications containing virtual directories. The application in a site can be accessed through one or more IIS binding. An IIS binding provides two pieces of information: a binding protocol and binding information. Binding protocol defines the scheme over which communication occurs, and binding information is the information used to access the site. An example of a binding protocol can be HTTP, whereas binding information can contain an IP address, Port, host header, etc.\nIIS supports specifying multiple IIS bindings per site, which results in multiple base addresses per scheme. However, a Windows Communication Foundation (WCF) service hosted under a site allows binding to only one baseAddress per scheme.\nTo enable multiple IIS bindings per site for a Windows Communication Foundation (WCF) service, set this attribute to true. Notice that multiple site binding is supported only for the HTTP protocol. The address of endpoints in the configuration file needs to be a complete URI.",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2021-05-07T10:18:15",
      "url": "https://stackoverflow.com/questions/67431335/reverse-proxy-doesnt-work-with-svc-url"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 67305405,
      "title": "Spring boot with keycloak using nginx proxy only works if redirect_uri localhost",
      "problem": "I have been banging my head over this one.\nI have a basic web application using Spring Boot running on localhost:8082, a dockerized keycloak server running on localhost:8081 and a dockerized nginx server running on port 80.\nWhen I was using keycloak without spring security integration, a user accessing a secured resource would be redirected to the keycloak login page at http://{keycloak-server}/auth/realms/{myrealm}/protocol/openid-connect/auth/... and everything worked great.\nWhen I added spring security into the mix, as per this tutorial and several others, suddenly my application attempts to redirect to http://{myapp}/sso/login where there is no /sso/login endpoint so I get a 404.\nI was only able to get the application routing to the correct login end-point by accessing it directly at http://localhost:8082 and setting the redirect_uri in keycloak for the client to http://localhost:8082/*.\nI suspect it may have something to do with nginx config, but again, it was working before I added spring security into the mix, so I am scratching my head. Here is my nginx.conf\n```\n`worker_processes 2;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n\n    proxy_set_header    Host               $host;\n    proxy_set_header    X-Real-IP          $remote_addr;\n    proxy_set_header    X-Forwarded-For    $proxy_add_x_forwarded_for;\n    proxy_set_header    X-Forwarded-Host   $host;\n    proxy_set_header    X-Forwarded-Server $host;\n    proxy_set_header    X-Forwarded-Port   $server_port;\n    proxy_set_header    X-Forwarded-Proto  $scheme;\n\n    # auth local (keycloak)\n    server {\n        listen  80;\n        server_name auth.local;\n\n            location / {\n                # keycloak\n                proxy_pass http://host.docker.internal:8081/;\n            }\n\n        }\n\n        server {\n            listen  80;\n            server_name guardian.local;\n\n                location / {\n                    # send to portal\n                    rewrite ^/(.*)$ http://guardian.local/portal/$1 permanent;\n                }\n\n                location /portal {\n                    # guardian web-portal\n                    proxy_pass http://host.docker.internal:8082;\n                }\n            }\n\n}\n`\n```\nMy security config class:\n```\n`@Configuration\n@EnableWebSecurity\n@ComponentScan(basePackageClasses = KeycloakSecurityComponents.class)\npublic class SecurityConfig extends KeycloakWebSecurityConfigurerAdapter {\n\n    // Submits the KeycloakAuthenticationProvider to the AuthenticationManager\n    @Autowired\n    public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception {\n        KeycloakAuthenticationProvider keycloakAuthenticationProvider = keycloakAuthenticationProvider();\n        keycloakAuthenticationProvider.setGrantedAuthoritiesMapper(new SimpleAuthorityMapper());\n        auth.authenticationProvider(keycloakAuthenticationProvider);\n    }\n\n    /**\n     * Used by Spring Security to add Keycloak config from spring config resource (like application.properties).\n     * @return\n     */\n    @Bean\n    public KeycloakSpringBootConfigResolver KeycloakConfigResolver() {\n        return new KeycloakSpringBootConfigResolver();\n    }\n\n    // Specifies the session authentication strategy\n    @Bean\n    @Override\n    protected SessionAuthenticationStrategy sessionAuthenticationStrategy() {\n        return new RegisterSessionAuthenticationStrategy(new SessionRegistryImpl());\n    }\n\n    @Override\n    protected void configure(HttpSecurity http) throws Exception {\n        super.configure(http);\n        http.authorizeRequests()\n                .antMatchers(\"/portal/client*\")\n                .hasRole(\"user\")\n                .anyRequest()\n                .permitAll();\n    }\n}\n`\n```\nAnd my application.properties\n```\n`server.port = 8082\n\nkeycloak.auth-server-url = http://auth.local/auth\nkeycloak.realm = myRealm\nkeycloak.resource = guardian-web-portal\nkeycloak.public-client = true\nkeycloak.use-resource-role-mappings = true\nkeycloak.principal-attribute = preferred_username\n`\n```\nAny help on this would be greatly appreciated. I am using keycloak-spring-boot-starter 12.0.4 and spring-boot-starter-security 2.4.5.",
      "solution": "Try to add the below and change the permitAll() to authenticated()\n```\n`.antMatchers(\"/login*\", \"/error*\", \"/sso*\" ).permitAll()\n`\n```\non your\n```\n`@Override\nprotected void configure(HttpSecurity http) throws Exception {\n    super.configure(http);\n    http.authorizeRequests()\n            .antMatchers(\"/portal/client*\")\n            .hasRole(\"user\")\n            .anyRequest()\n            .permitAll();\n}\n`\n```\nso in the end you will have:\n```\n`@Override\nprotected void configure(HttpSecurity http) throws Exception {\n    super.configure(http);\n    http.authorizeRequests()\n            .antMatchers(\"/login*\", \"/error*\", \"/sso*\" ).permitAll()\n            .antMatchers(\"/portal/client*\")\n            .hasRole(\"user\")\n            .anyRequest()\n            .authenticated();\n}\n`\n```",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2021-04-28T19:48:52",
      "url": "https://stackoverflow.com/questions/67305405/spring-boot-with-keycloak-using-nginx-proxy-only-works-if-redirect-uri-localhost"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 67300292,
      "title": "Two layers of NGINX reverse proxies with ssl_client_verify on the second",
      "problem": "The project I'm working on is an application that is deployed onto a Kubernetes cluster and uses a smartcard PKI scheme for authentication. This cluster is shared between several applications and not all of these applications need (or even should have) the client cert verification for PKI. So we are using the ingress-nginx helm chart to handle ingress into the cluster, then directing to a second reverse proxy that proxies to the application services (web app, api server, etc.). Both proxies have SSL certificates.\nInitially, we were using Ingress annotations and mounting the CA certificates into the ingress-nginx deployment in order to handle the client certificate verification, but now we are trying to handle all of the certificate verification on the second proxy so that we have more control over it. Ingress-nginx is a great tool, but it abstracts away a lot of the server config.\nCurrently, the problem I'm seeing is that the first proxy (ingress-nginx) is receiving the requests and correctly proxying them on to the second proxy. However, because ingress-nginx doesn't have the `ssl_client_verify` directive, it doesn't request the client's certificate. When the request reaches the second proxy (which does have `ssl_client_verify`), this proxy simply returns a 400 and says that the client never sent a certificate (which it didn't).\nHow can I tell the second proxy to request the certificate from the first in such a way that the first then requests the certificate from the user? Or if there is a simpler solution, I'm open to that as well.\nOur ingress object for the ingress-nginx controller looks like this: (the hostname is populated with kustomize)\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: proxy\n  namespace: web\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/issuer: cert-issuer\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\nspec:\n  tls:\n  - hosts:\n    - placeholder.com\n    secretName: web-cert\n  rules:\n  - host: placeholder.com\n    http:\n      paths:\n      - backend:\n          serviceName: proxy\n          servicePort: 443\n        path: /\n\n`\nand the server configuration I'm using for the second proxy looks like this: (environment variables are substituted on container start for the proxy image)\n```\n`# nginx.conf\nuser nginx;\nworker_processes auto;\n\nerror_log /var/log/nginx/error.log warn;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    log_format main '$remote_addr - $remote_user [$time_local] \"$request\" '\n        '$status $body_bytes_sent \"$http_referer\" '\n        '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log /var/log/nginx/access.log main;\n\n    sendfile on;\n\n    keepalive_timeout 65;\n\n    include /etc/nginx/conf.d/default.conf;\n\n    client_max_body_size 0;\n}\n`\n```\n```\n`# default.conf\nserver {\n    listen 443 ssl http2 default_server;\n    listen [::]:443 ssl http2 default_server;\n    server_name ${PROXY_DOMAIN} www.${PROXY_DOMAIN};\n\n    ssl_certificate /etc/nginx/certs/certificate.pem;\n    ssl_certificate_key /etc/nginx/certs/key.pem;\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers HIGH:!aNULL:!MD5;\n    ssl_prefer_server_ciphers on;\n\n    ssl_verify_client on;\n    ssl_verify_depth 4;\n    ssl_client_certificate /etc/nginx/certs/DoDRoots.crt;\n\n    # Inform the proxyed app which user had connected to this TLS endpoint\n    add_header X-Client-Verified $ssl_client_verify;\n    add_header X-CLient-Certificate $ssl_client_escaped_cert;\n\n    include /etc/nginx/conf.d/shared_locations.conf;\n}\n\nserver {\n    listen 80;\n    server_name ${PROXY_DOMAIN} www.${PROXY_DOMAIN};\n    return 301 https://$server_name$request_uri;\n}\n`\n```\n```\n`# shared_locations.conf\nlocation / {\n    proxy_pass http://${DOMAIN_FRONT}:${PORT_FRONT}/;\n    proxy_set_header Host $host;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n}\n\nlocation /api/ {\n    proxy_pass http://${DOMAIN_BACK}:${PORT_BACK}/api/;\n    proxy_set_header Host $host;\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n}\n`\n```",
      "solution": "How can I tell the second proxy to request the certificate from the first in such a way that the first then requests the certificate from the user?\n\nThis is not possible. There is no way to terminate the TLS connection at the first proxy while at the same time passing through the client certificate at the TLS level. Apart from that the TLS handshake on the first proxy is finished before the TLS handshake with the second proxy is even started, e.g. there is no way to let the second proxy signal the requirement of a client certificate.",
      "question_score": 1,
      "answer_score": 2,
      "created_at": "2021-04-28T14:30:11",
      "url": "https://stackoverflow.com/questions/67300292/two-layers-of-nginx-reverse-proxies-with-ssl-client-verify-on-the-second"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 76813115,
      "title": "Facing a CORS policy issue when requesting from my deployed IP address site at EC2 instance",
      "problem": "I have deployed a Full Stack React/Node app on AWS EC2 instance using nginx and facing the CORS policy issue which I have already resolved in my code\n\nIndex.js\n```\n`const express = require('express');\nconst cors = require('cors');\nrequire('dotenv').config();\n\nconst app = express()\nconst port = process.env.PORT || 5000;\n\n// midleware to use API Endpoints\nconst corsOptions = {\n  origin: 'http://13.200.107.25'\n}\napp.use(express.json());\napp.use(cors(corsOptions));\n\n// Serving client react app build \nconst path = require('path');\nconst _dirname = path.dirname(\"\");\nconst buildPath = path.join(_dirname , \"../client/build\");\n\napp.use(express.static(buildPath));\n\napp.get('/*', (req, res) => {\n  res.sendFile(\n    path.join(__dirname, \"../client/build/index.html\"),\n    (err) => {\n      if(err)\n      {\n        res.status(500).send(err);\n      }\n    }\n  )\n})\n\n//Available Routes\napp.use('/api/auth', require('./Routes/authRoute'));\n// app.use('/api/notes', require('./Routes/notes'))\n\napp.listen(port, () => {\n  console.log(`iNotebook listening at http://localhost:${port}`)\n})\n`\n```\nI used pm2 to start backend server which is also serving the ../client/build of my react app\n\nI have changed /etc/nginx/sites-available/default file for configurations\n```\n`server {\n   listen 80 default_server;\n   listen [::]:80 default_server;\n    \n   server_name _;\n   \n   location / {\n        proxy_pass http://localhost:5000;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection upgrade;\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n} \n`\n```\nI have restarted pm2 and nginx and test nginx syntax configurations using `sudo nginx -t` which is successfull\nI have given corsOptions as a paramater in my index.js\n```\n`// midleware to use API Endpoints\nconst corsOptions = {\n  origin: 'http://13.200.107.25'\n}\napp.use(express.json());\napp.use(cors(corsOptions));\n`\n```",
      "solution": "I think your cors configurations are ok.\nA good way to realize if your Headers are ok is using curl in a bash terminal.\n`curl http://13.200.107.25 -I\n`\nThis command shows you the headers of your website:\n```\n`HTTP/1.1 200 OK\nServer: nginx/1.18.0 (Ubuntu)\nDate: Tue, 01 Aug 2023 15:56:25 GMT\nContent-Type: text/html; charset=UTF-8\nContent-Length: 1457\nConnection: keep-alive\nX-Powered-By: Express\nAccess-Control-Allow-Origin: http://13.200.107.25 #As you can see the cors header is ok.\nThe problem is that your front is attempting to connect to http://localhost:5000 and this is confusing because you said that your backend (node) is in the same EC2 (not in localhost).\nIf your backend is running in the same EC2 instance the solution is changing every http://localhost:5000 request in your react project for http://13.200.107.25. In this case, the CORS header is not necessary because the requests are from the same origin.\nIf actually, your backend is running on your personal computer (localhost)  you must configure cors(in your backend)  with http://localhost... and depending on your browser configure it to allow make this request like in this question CORS error on request to localhost dev server from remote site . Because fetching localhost from websites already hosted on the internet is not secure.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-08-01T17:23:33",
      "url": "https://stackoverflow.com/questions/76813115/facing-a-cors-policy-issue-when-requesting-from-my-deployed-ip-address-site-at-e"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 76444622,
      "title": "How can I stop Fail2ban from banning my external IP when attempting to access my Plex server?",
      "problem": "I have a fairly simple setup using fail2ban with NGINX Proxy Manager. In this setup, I have Plex exposed to the outside and routed internally using my reverse proxy, and that works fine without fail2ban. The problem is when I try to use fail2ban, my external IP immediately gets banned when attempting to access my Plex server. If I check my proxy host access logs, I'm getting successive 401 errors that seem to match the regex filter in fail2ban's filter.d directory. Here is my regex filter:\n```\n`[INCLUDES]\n\n[Definition]\n\nfailregex = ^.* (405|404|403|401|\\-) (405|404|403|401) - .* \\[Client \\] \\[Length .*\\] .* \\[Sent-to .*\\] \".*\" .*$\nignoreregex = ^.* (404|\\-) (404) - .*\".*(\\.png|\\.txt|\\.jpg|\\.ico|\\.js|\\.css)(/)*?\" \\[Client \\] \\[Length .*\\] \".*\" .*$\n`\n```\nIn my jail.d config, I have 'maxretry' set to 4, and the 'logpath' specifically includes all the nginx proxy manager's proxy host access and error logs. Here is that config:\n```\n`[npm-docker]\nenabled = true\nignoreip = 127.0.0.1/8 10.10.10.0/24 10.10.0.0/24\naction = cloudflare-apiv4\n         %(action_mwl)s\nchain = INPUT\nlogpath = /log/npm/default-host_access.log\n          /log/npm/proxy-host-*_access.log\n          /log/npm/proxy-host-*_error.log\nmaxretry = 4\nbantime  = -1\nfindtime = 86400\ndestemail = \nsender = fail2ban@notification\nsendername = fail2ban\n`\n```\nAnd as referenced in the first paragraph, If I look at the the plex proxy host access log, I can find four 401 errors when I attempted to access my plex server at the time it was banned from a mobile client with an outside IP:\n```\n`[09/Jun/2023:19:24:58 -0700] - 200 200 - GET https  \"/?X-Plex-Language=en-US&X-Plex-Device-Name=iPhone\" [Client ] [Length 4266] [Gzip -] [Sent-to 10.10.10.4] \"PlexMobile/8.20 (iPhone; iOS 16.5; Scale/3.00)\" \"-\"\n[09/Jun/2023:19:24:58 -0700] - 401 401 - GET https  \"/media/subscriptions/scheduled?X-Plex-Language=en-US&X-Plex-Device-Name=iPhone\" [Client ] [Length 82] [Gzip -] [Sent-to 10.10.10.4] \"PlexMobile/8.20 (iPhone; iOS 16.5; Scale/3.00)\" \"-\"\n[09/Jun/2023:19:24:58 -0700] - 200 200 - GET https  \"/media/providers\" [Client ] [Length 4849] [Gzip -] [Sent-to 10.10.10.4] \"PlexMediaServer/1.29.0.6244-819d3678c\" \"-\"\n[09/Jun/2023:19:24:58 -0700] - 200 200 - GET https  \"/media/providers?includePreferences=1&X-Plex-Language=en-US&X-Plex-Device-Name=iPhone\" [Client ] [Length 8849] [Gzip -] [Sent-to 10.10.10.4] \"PlexMobile/8.20 (iPhone; iOS 16.5; Scale/3.00)\" \"-\"\n[09/Jun/2023:19:24:58 -0700] - 401 401 - GET https  \"/activities?X-Plex-Language=en-US&X-Plex-Device-Name=iPhone\" [Client ] [Length 82] [Gzip -] [Sent-to 10.10.10.4] \"PlexMobile/8.20 (iPhone; iOS 16.5; Scale/3.00)\" \"-\"\n[09/Jun/2023:19:24:58 -0700] - 401 401 - GET https  \"/media/subscriptions?includeGrabs=1&X-Plex-Language=en-US&X-Plex-Device-Name=iPhone\" [Client ] [Length 82] [Gzip -] [Sent-to 10.10.10.4] \"PlexMobile/8.20 (iPhone; iOS 16.5; Scale/3.00)\" \"-\"\n[09/Jun/2023:19:24:58 -0700] - 200 200 - GET https  \"/clients?X-Plex-Language=en-US&X-Plex-Device-Name=iPhone\" [Client ] [Length 90] [Gzip -] [Sent-to 10.10.10.4] \"PlexMobile/8.20 (iPhone; iOS 16.5; Scale/3.00)\" \"-\"\n[09/Jun/2023:19:24:58 -0700] - 401 401 - GET https  \"/activities?X-Plex-Language=en-US&X-Plex-Device-Name=iPhone\" [Client ] [Length 82] [Gzip -] [Sent-to 10.10.10.4] \"PlexMobile/8.20 (iPhone; iOS 16.5; Scale/3.00)\" \"-\"\n[09/Jun/2023:19:24:58 -0700] - 200 200 - GET https  \"/media/providers?includePreferences=1&X-Plex-Language=en-US&X-Plex-Device-Name=iPhone\" [Client ] [Length 8849] [Gzip -] [Sent-to 10.10.10.4] \"PlexMobile/8.20 (iPhone; iOS 16.5; Scale/3.00)\" \"-\"\n`\n```\nI've only modified the above log to remove the public IP and URL. My question is, since the 401's here aren't really affecting my access as I'm still being authenticated, is there a way to change my regex filter to get Fail2ban to ignore these particular entries (I admit that I don't know much about regex), or is it better to change some specific part of my configuration in the NGINX proxy manager, and if so, what would that be?",
      "solution": "Looking into the same problem - same setup - fail2ban, nginx proxy manager and cloudflare dns (not tunnels). #1 - you should add your public IP to the ignoreip section of your jail file. As for the filter, this is not the most elegant solution as I'm not a regex ninja, but this is what I landed on.\n```\n` failregex = ^.+\" (4\\d\\d|3\\d\\d) (\\d\\d\\d|\\d) .+$\n        \n             ^.+ 4\\d\\d \\d\\d\\d - .+ \\[Client \\] \\[Length .+\\] \".+\" .+$\n\n ignoreregex = ^\\s*(?:\\[\\]\\s+)?- 4\\d\\d \\d+ - [A-Z]+ \\w+ \\S+ \"\\/video\\/:\\/transcode\\/.+?(?=\")\" \\[Client ]\n          \n               ^\\s*(?:\\[\\]\\s+)?- 4\\d\\d \\d+ - [A-Z]+ \\w+ \\S+ \"\\/photo\\/:\\/transcode\\/.+?(?=\")\" \\[Client ]\n`\n```\nThe ignoreregex looks for a new log line with a 400 error, specifically then the /video:/transcode and /photo:/transcode callouts, and then finally the Client IP Address. I was getting random 400 errors when movie posters or actor photos were missing causing bans. I'm still unclear what the /media/subscriptions and /media/providers errors are referring to. Honestly I see them fail from IPs I don't recognize and get banned so I'm not sure yet if I want to ignore them. If you have any detail there I'd appreciate it.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-06-10T05:44:30",
      "url": "https://stackoverflow.com/questions/76444622/how-can-i-stop-fail2ban-from-banning-my-external-ip-when-attempting-to-access-my"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 75415423,
      "title": "Prevent NGINX from serving local index.html instead of passing to proxied server",
      "problem": "Found other similar questions, but none seem to work in my circumstance.\nI am attempting to proxy from NGINX to an IIS server which is hosting an archived website in its entirety.  The site is coded with some hard index.html links and I don't want to go in and modify the site at all.\nAny time the site is called with the /index.html in the URL directly it appears that NGINX is not proxying the location, but instead serving out a local index.html page.\nAdditionally, I am trying to default instead of to the index.html page when no page is entered (i.e. domain only) instead to pass to a default.htm page (set as default in IIS) which provides a disclaimer page that will require reading before continuing on to the original index.html of the website.\nThis is my nginx configuration file for the site.  I do not want to change my overall structure around because it is what multiple sites use.  I need a solution that I can add in.\n```\n`upstream my_backend {\n        server 10.10.10.102:1011;\n        include snippets/shared_upstream_settings.conf;\n}\n\nserver {\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        server_name server.mydomain.com;\n\n        include snippets/shared_server_proxy_settings.conf;\n\n        location @proxy {\n                proxy_pass http://my_backend;\n        }\n\n        location / {\n                satisfy any;\n                allow 10.16.0.0/24;\n                deny all;\n                auth_basic \"Authorized Users Only\";\n                auth_basic_user_file secure/.htpasswd;\n                auth_request /auth-1;\n                try_files $uri @proxy;\n        }\n`\n```\n(I don't believe any of the includes should matter for this particular issue)\nThis configuration works for about 15 other sites I have, but none of them apparently have a hardcoded index.html.  Until today I never realized that NGINX will not proxy a direct link to index.html.  So I need to either disable or work around that \"feature\" as well as direct no indicated pages to the disclaimer page.\nthanks",
      "solution": "The `$uri` argument in your `try_files` statement instructs Nginx to test for the existence of a file before branching to the `@proxy` block. There exists a local `index.html` file that satisfies that test.\nYou have two options:\n\nReplace the `try_files $uri @proxy;` line with `proxy_pass http://my_backend;` as there is no need for a separate `location @proxy` block.\n\nOr:\nIf you want to keep the second location block, change the `try_files` statement to:\n```\n`try_files __nonexistent__ @proxy;\n`\n```\n`try_files` requires a minimum of two arguments. All arguments before the final argument are filenames to be tested. `__nonexistent__` is just one such name that probably does not exist on your file system (and also helps to document the author's intent).",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-02-10T20:35:58",
      "url": "https://stackoverflow.com/questions/75415423/prevent-nginx-from-serving-local-index-html-instead-of-passing-to-proxied-server"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 75321302,
      "title": "Why doesn&#39;t Nginx reverse proxy on WSL2 see Rails app in Docker Container using hostname?",
      "problem": "I've got several Rails websites running in Docker dev containers. Docker is running in WSL (Ubuntu 20.04) on Windows 11. Nginx is running in Ubuntu as a reverse proxy, IIS is turned off in Windows. The Ubuntu /etc/hosts file is automatically populated from the hosts file in Windows. It is set up like this because others on the team are running Linux on Macs but I switch between Rails and .Net development.\nAn example website is mysite1.localhost which is exposed on port 8081 on Docker and there is an entry of '127.0.0.1   mysite1.localhost' in both hosts files.\nThe problem I have is browsing (Chrome on Windows) localhost:8081 returns 200 from the website, great, but using the hostname mysite1.localhost returns 502 Bad Gateway.\nI am assuming Nginx doesn't know about Docker or something like that?\nHere is the mysite1.conf for Nginx:\n```\n` server {\n     listen 80;\n     listen [::]:80;\n     server_name mysite1.localhost;\n     \n     resolver 127.0.0.1;\n     \n     location ~* \"^/shared-nav\" {\n         proxy_set_header Accept-Encoding \"\";\n         proxy_pass http://localhost:3000/stuff$is_args$args;\n       }\n     \n     location / {\n         ssi on;\n         \n         ssi_silent_errors off;\n         log_subrequest on;\n     \n         proxy_set_header X-Forwarded-Proto $scheme;\n         proxy_set_header Host $host;\n         proxy_set_header X-Real-IP $remote_addr;\n         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n         proxy_pass http://127.0.0.1:8081;\n         add_header Cache-Control \"no-cache\";\n     \n         if ($request_filename ~* ^.*?/([^/]*?)$) {\n           set $filename $1;\n         }\n         if ($filename ~* ^.*?\\.(eot)|(ttf)|(woff)|(woff2)$) {\n           add_header Access-Control-Allow-Origin *;\n         }\n       }\n }\n`\n```\nI can see two problems in nginx/error.log:\n2023/02/02 08:50:10 [warn] 2841#2841: conflicting server name \"mysite1.localhost\" on 0.0.0.0:80, ignored\n2023/02/02 08:50:12 [error] 2845#2845: *52 connect() failed (111: Connection refused) while connecting to upstream, client: ::1, server: mysite1.localhost, request: \"GET / HTTP/1.1\", upstream: \"http://127.0.0.1:8081/\", host: \"mysite1.localhost\"\nIt doesn't seem to matter whether or not docker is running.\nFor the conflicting server name waring, I've tried looking for temporary files that need deleting but cannot find anything.\nMost of the other questions I've looked at involve solving problems with containerized Nginx where as this is sitting in WSL.\nPlease let me know if I can better explain the problem, thanks for any help.",
      "solution": "One thing I didn't take into consideration was using VS Code to dev in the containers means that the ports were forwarded to Windows - although the containers are running in WSL, VS Code is running in Windows.\nSo, I could either turn IIS back on and use it as a reverse proxy or try Nginx for Windows. I've opted for the latter as it means I can share the same config files as the Linux guys and will see how it works out, for now I can browse the websites by hostname.\nIf anyone else needs to work with this set up, I'm happy to pass on my experiences.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-02-02T10:50:10",
      "url": "https://stackoverflow.com/questions/75321302/why-doesnt-nginx-reverse-proxy-on-wsl2-see-rails-app-in-docker-container-using"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 75178937,
      "title": "How to set nginx proxy path to use static contents of a specific s3 bucket folder?",
      "problem": "I'm working on an nginx reverse proxy container image to proxy frontend files from s3, and Im trying to access these files from a specific folder location, instead of just the base path of the s3 bucket. As of yet I can only serve up the index.html which I'm using a rewrite for, but I'm getting a 403 on the js and css files.\nI've tried including mime.types\n```\n`include       mime.types;\n`\n```\nI've tried adding an s3 folder bucket param\n```\n`proxy_pass http://YOURBUCKET.s3-website.eu-central-1.amazonaws.com/$1;\n`\n```\nAnd then various regex options\nHere is my nginx conf file\n```\n`server {\n    listen 80;\n    listen  443 ssl;\n    ssl_certificate     /etc/ssl/nginx-server.crt;\n    ssl_certificate_key   /etc/ssl/nginx-server.key;\n\n    server_name timemachine.com;\n    sendfile on;\n    default_type application/octet-stream;\n    resolver        8.8.8.8;\n    server_tokens   off;\n\n    location ~ ^/app1/(.*) {\n        set $s3_bucket_endpoint  \"timemachineapp.s3-us-east-1.amazonaws.com\";\n        proxy_http_version     1.1;\n        proxy_buffering        off;\n        proxy_ignore_headers   \"Set-Cookie\";\n        proxy_hide_header      x-amz-id-2;\n        proxy_hide_header      x-amz-request-id;\n        proxy_hide_header      x-amz-meta-s3cmd-attrs;\n        proxy_hide_header      Set-Cookie;\n        proxy_set_header       Authorization \"\";\n        proxy_intercept_errors on;\n        rewrite ^/app1/?$ /dev/app1/index.html;    As you can see, I'm trying to make this so that the user goes to https://timemachine/app1 that this will go to the homepage and load all the css and js files. Again, what im getting is a 403 and sometimes a 404. Insight appreciated.",
      "solution": "From the question it looks like\n\nThere's a constant request-url prefix `/app1/`\nThere's a constant proxied-url prefix `/dev/app1/`\n\nOn that basis...\nFirst, enable the debug log\nThere will already be an `error_log` directive in the nginx config, locate it and temporarily change to debug:\n```\n`error_log  /dev/stderr debug;\n`\n```\nThis will allow you to see how these requests are being processed.\nTry naive-simple first\nLet's use this config (other header directives omitted for brevity):\n```\n`location = /app1 { # redirect for consistency\n    return 301 /app1/;\n}\n\nlocation = /app1/ { # explicitly handle the 'index' request\n    proxy_pass https://example.com/dev/app1/index.html;\n}\n\nlocation /app1/ {\n    proxy_pass https://example.com/dev/;\n}\n`\n```\nAnd emit a request to it:\n```\n`$ ~ curl -I http://test-nginx/app1/some/path/some-file.txt\nHTTP/1.1 403 Forbidden\n...\n`\n```\nNote that S3 returns a 403 for requests that don't exist, nginx is just proxying that response here.\nLet's look in the logs to see what happened:\n```\n`2023/01/28 14:46:10 [debug] 15#0: *1 test location: \"/\"\n2023/01/28 14:46:10 [debug] 15#0: *1 test location: \"app1/\"\n2023/01/28 14:46:10 [debug] 15#0: *1 using configuration \"/app1/\"\n...\n\"HEAD /dev/some/path/some-file.txt HTTP/1.0\nHost: example.com\nConnection: close\nUser-Agent: curl/7.79.1\nAccept: */*\n\"\n`\n```\nSo our request became `https://example.com/dev/some/path/some-file.txt`\nThat's because the way proxy_pass works is:\n\nIf the proxy_pass directive is specified with a URI, then when a request is passed to the server, the part of a normalized request URI matching the location is replaced by a URI specified in the directive\n\nMeaning:\n```\n`Nginx receives:\n/app1/some/path/some-file.txt\n      ^ the normalized path starts here\n\nProxied-upstream receives:\n/dev/some/path/some-file.txt\n     ^ and was appended to proxy-pass URI\n`\n```\nI point this out as renaming/moving things on s3 may lead to a simpler nginx setup.\nRewrite all paths, not specific requests\nModifying the config above like so:\n```\n`location = /app1 { # redirect for consistency\n    return 301 /app1/;\n}\n\nlocation = /app1/ { # explicitly handle the 'index' request\n    proxy_pass https://example.com/dev/app1/index.html;\n}\n\nlocation /app1/ {\n    rewrite ^/(.*) /dev/$1 break;             # prepend with /dev/\n    # rewrite ^/app1/(.*) /dev/app1/$1 break; # OR this\n    proxy_pass https://example.com/;          # no path here\n}\n`\n```\nAnd trying that test-request again yields the following logs:\n```\n`\"HEAD /dev/app1/some/path/some-file.txt HTTP/1.0\nHost: example.com\nConnection: close\nUser-Agent: curl/7.79.1\nAccept: */*\n\n\"\n`\n```\nIn this way the index request works, but also arbitrary paths - and there's no need to modify this config to handle each individual url requested.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-01-19T23:27:57",
      "url": "https://stackoverflow.com/questions/75178937/how-to-set-nginx-proxy-path-to-use-static-contents-of-a-specific-s3-bucket-folde"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 75120754,
      "title": "How to connect to Docker service UI via LAN on local network",
      "problem": "I am new to Docker and am trying to get Nginx Proxy Manager up and running.\nSo far, I have a docker-compose.yml that looks like (based on a tutorial I'm following):\n`version: \"3.9\"\n\nnetworks:\n  default:\n    driver: bridge\n  npm_proxy:\n    name: npm_proxy\n    driver: bridge\n    ipam:\n      config:\n        - subnet: 192.168.89.0/24\n  \nx-common-keys-core: &common-keys-core\n  networks:\n    - npm_proxy\n  security_opt:\n    - no-new-privileges:true\n  restart: always\n\nservices:\n  npm:\n    \nThis is works so far, and I can access the Nginx Proxy Manager on the host machine (NUC running Ubuntu connected via LAN to my router).\nHowever, I thought that it'd be simple to access this same UI on another machine on my local network (Windows PC connected to same router via LAN).\nFor the life of me, I can't seem to pull up the UI on the other computer. I just get a timeout error in my browser.\nI have tried:\n\nAccessing 192.168.89.254:81, which works fine on the host\nAdding --net=host flag\nSwitching ports/IPs in YAML\nRemoving custom network/bridge and just do default (i.e. localhost:81)\n\nDoes anyone know how to access the UI of a Docker service on another local PC on the same network. I don't need port-forwarding for this because it's local right?",
      "solution": "Seems all I had to do was expose the port in my UFW via `ufw allow 81`. Once exposed I can access the UI from any device in my local network.\nAs pointed out by @DavidMaze, it doesn't seem very useful to specify static IPs for Docker containers. It seems best practice would be to use default Docker networking, specify different ports for different containers, and just make sure these ports are accessible via UFW. Since I'm not port forwarding on my router they should only be accessible from my local network.\nI'm still a little curious though as to when a bridge would be useful. It seems even with a bridge Docker connects the bridge network to the host network. So I wonder what the point is... I'll be sure read up on some documentation.\nHere is my updated YAML:\n`version: \"3.9\"\n  \nx-common-keys-core: &common-keys-core\n  security_opt:\n    - no-new-privileges:true\n  restart: always\n\nservices:\n  npm:",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2023-01-14T20:41:35",
      "url": "https://stackoverflow.com/questions/75120754/how-to-connect-to-docker-service-ui-via-lan-on-local-network"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 73594429,
      "title": "How do I configure nginx.conf proxy to work with S3 and AWS ALB",
      "problem": "I have a number of UIs (Angular) that are currently deployed on ECS Fargate. These apps are built using a base nginx image, and further configurations are set in the nginx.conf file, etc. All of these apps also filter through an AWS ALB and have route paths set for them. Currently, each of these apps are using separate nginx containers and they are working fine.\nHowever, I am wanting to serve these up using one nginx container as a proxy that pulls the UI files from S3, but still uses the ALB to route the requests.\nAt this point, I have just been trying to get one sample Angular app working. I've build the dist file using ng build and loaded the artifacts in s3. After updating the nginx configurations, I am able to load the index.html in the browser, but for the css and js files its either not finding the files or not loading them for some reason (see png below). I have a default route set on the ALB that returns a text message when no artifacts are found on the path so that looks like what is being returned.\n\nI've tried various things to get this to work and have not found a solution. The following are the basic setup files im using for this. I'm needing insight from someone who knows nginx better than me to get a path forward.\nDockerfile\n```\n`FROM nginx:1.16.1-alpine\n\nCOPY nginx.conf /etc/nginx/\nCOPY entrypoint.sh /usr/local/bin/entrypoint.sh\nRUN cp -r /usr/share/nginx/html /etc/nginx/html\nRUN chown nginx:nginx /usr/local/bin/entrypoint.sh\nRUN chmod +x /usr/local/bin/entrypoint.sh\n\nEXPOSE 80\n\nENTRYPOINT [\"/usr/local/bin/entrypoint.sh\"]\nCMD [\"nginx\"]\n`\n```\nentrypoint.sh\n```\n`#!/bin/sh\n\nsed -i -e 's//${S3BUCKET}/;' \\\n    -i -e 's//${HOSTNAME}/;' \\\n    -i -e 's/8.8.8.8/{DNS}/;' \\\n\nchown nginx:nginx /etc/nginx/nginx.conf \\\n/etc/nginx/nginx.conf\n\nexec \"$@\" \n`\n```\nnginx.conf\n```\n`daemon off;\nuser nginx;\n\nworker_processes 4;\n\nevents { \n    worker_connections 1024; \n}\n\nhttp {\n        log_format logstash_json escape=json '{'\n        '\"agent\": \"$http_user_agent\", '\n        '\"body_bytes_sent\": \"$body_bytes_sent\", '\n        '\"bytes_sent\": \"$bytes_sent\", '\n        '\"clientip\": \"$remote_addr\", '\n        '\"http_host\": \"$http_host\", '\n        '\"log_timestamp\": \"$time_local\", '\n        '\"proxy_host\": \"$proxy_host\", '\n        '\"referrer\": \"$http_referer\", '\n        '\"request\": \"$request\", '\n        '\"request_time\": $request_time, '\n        '\"request_length\": $request_length, '\n        '\"status\": $status, '\n        '\"upstream_addr\": \"$upstream_addr\", '\n        '\"upstream_response_time\": \"$upstream_response_time\", '\n        '\"upstream_status\": \"$upstream_status\", '\n        '\"x_forwarded_for\": \"$http_x_forwarded_for\", '\n        '\"x_forwarded_port\": \"$http_x_forwarded_port\", '\n        '\"x_forwarded_proto\": \"$http_x_forwarded_proto\"'\n        '}';\n\n        access_log /var/log/nginx/access.log logstash_json;\n\n        gzip on;\n        gzip_proxied any;\n        gzip_vary on;\n        gzip_types application/json application/x-tar;\n        gzip_min_length 1000;\n\n        variables_hash_max_size 1024;\n        variables_hash_bucket_size 64;\n        server_names_hash_bucket_size 64;\n        types_hash_max_size 2048;\n        types_hash_bucket_size 64;\n        client_max_body_size 100m;\n\n        proxy_read_timeout 60;\n        proxy_buffers 256 32k;\n        proxy_busy_buffers_size 64k;\n\n        sendfile            on;\n        tcp_nopush          on;\n        tcp_nodelay         on;\n\n        keepalive_timeout  65;\n        include /etc/nginx/conf.d/*.conf;\n        # default_type application/octet-stream;\n        include mime.types;\n        include /etc/nginx/mime.types;\n\n    server {\n        listen 80;\n        server_name .com;\n        resolver 8.8.8.8 valid=30s;\n        index index.html;\n        gzip_types text/plain application/xml application/x-javascript text/css application/json text/javascript;\n\n        location = /app/ {\n            set $S3BUCKET \".s3.amazonaws.com\";\n            include /etc/nginx/mime.types;\n            proxy_buffering        off;\n            proxy_ignore_headers   \"Set-Cookie\";\n            proxy_hide_header      x-amz-id-2;\n            proxy_hide_header      x-amz-request-id;\n            proxy_hide_header      x-amz-meta-s3cmd-attrs;\n            proxy_hide_header      Set-Cookie;\n            proxy_set_header       Host $S3BUCKET;\n            proxy_set_header       Connection \"\";\n            proxy_intercept_errors on;\n            proxy_pass https://$S3BUCKET/index.html;\n            break;\n        }\n    }\n}\n`\n```\nNOTE: If I use just `location /app` instead of `location = /app` the the health checks fails and after some testing this appears to be because of the route path set in the ALB. Im finding they need to to be identical on each, but I could be wrong.\nAgain Im able to reach the index.html, just not load the css and js for some reason. All of the dist files in the bucket are in the same location (i.e., there are no separate folders). Any insight as to what Im missing?",
      "solution": "I just submitted this PR, I'm hoping it might help with your issue.\nhttps://github.com/nginxinc/nginx-s3-gateway/pull/158\nIt allows you to specify a portion of the path the request to be removed.  For example, let's say you have an ALB rule that sends traffic from www.mysite.com/mybucket to the S3 gateway, which is connected to the bucket s3://mybucket.  If you request www.mysite.com/mybucket/myfile.txt, the request would normally fail as it would try to pull the file from s3://mybucket/mybucket/myfile.txt.\nWith this change, setting the new env var to\n```\n`STRIP_LEADING_DIRECTORY_PATH=/mybucket\n`\n```\nwill instead try to pull the file from s3://mybucket/myfile.txt.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2022-09-03T20:05:53",
      "url": "https://stackoverflow.com/questions/73594429/how-do-i-configure-nginx-conf-proxy-to-work-with-s3-and-aws-alb"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 72705823,
      "title": "Nginx upstream server works with IP address but not with DNS",
      "problem": "Sorry for mistakes. I am new with Nginx.\nI have my application deployed on docker engine.\nSo I have basically 5 docker images but here 2 are most important:\n\n1st backend.   (Django DRF application using gunicorn)\n2nd frontend.  (React App on Nginx)\n\nI am upstreaming backend on Nginx so in Nginx.conf file I have 2 locations defined:\n\n\"/\" for frontend\n\"/api\" for backend (upstream backend to be able to use it).\n\nI am able to start my containers and they \"talk\" to each other if I am using IP address in my browser. So backend get requests and give responses.\nNow I bought dns and added ssl certificates (LetsEncrypt, but still i have to add exception , but that is a separate question). If I reach my site using DNS frontend works, but backend does not work.\nHere is unsuccessful with using DNS.\n\nand successful request using IP address.\n\nHere is my nginx.conf\n```\n`user  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log  /var/log/nginx/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    # include /etc/nginx/conf.d/*.conf;\n\n    upstream backend {\n       server api:8000;\n    }\n\n    server {\n        listen 443 ssl http2;\n        listen [::]:443 ssl http2;\n\n        ssl_certificate /etc/nginx/ssl/live/site.org/fullchain.pem;\n        ssl_certificate_key /etc/nginx/ssl/live/site.org/privkey.pem;\n\n        location /api {\n\n        if ($request_method = 'OPTIONS') {\n                add_header 'Access-Control-Allow-Origin' '*';\n                #\n                # Om nom nom cookies\n                #\n                add_header 'Access-Control-Allow-Credentials' 'true';\n                add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, OPTIONS';\n                #\n                # Custom headers and headers various browsers *should* be OK with but aren't\n                #\n                add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type';\n                #\n                # Tell client that this pre-flight info is valid for 20 days\n                #\n                add_header 'Access-Control-Max-Age' 1728000;\n                add_header 'Content-Type' 'text/plain charset=UTF-8';\n                add_header 'Content-Length' 0;\n                return 204;\n            }\n            # Tried this ipv6=off    \n            resolver 1.1.1.1 ipv6=off valid=30s;\n            set $empty \"\";\n            proxy_pass http://backend$empty;\n\n            # proxy_pass http://backend;\n\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header Host $host;\n            proxy_redirect off;\n\n            proxy_http_version  1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection 'upgrade';\n            proxy_cache_bypass $http_upgrade;\n            proxy_set_header   X-Real-IP         $remote_addr;\n            proxy_read_timeout 3600;\n            proxy_headers_hash_max_size 512;\n            proxy_headers_hash_bucket_size 128;\n            proxy_set_header Content-Security-Policy upgrade-insecure-requests;\n\n        }\n\n        location / {\n            root   /usr/share/nginx/html;\n            index  index.html index.htm;\n            try_files $uri $uri/ /index.html;\n        }\n\n        # location /static/ {\n        #     alias /home/app/web/staticfiles/;\n        # }\n        \n    }\n\n    server {\n        listen 80;\n        listen [::]:80;\n\n        location / {\n            return 301 https://$host$request_uri;\n        }\n        \n        location ~ /.well-known/acme-challenge/ {\n           root /var/www/certbot;\n        }\n\n    }\n}\n`\n```",
      "solution": "This HTTP `400 Bad Request` error looks like the one coming from the Django request validation, since your requests differs only by the `Host` HTTP request header value. You should include every used domain name to the `ALLOWED_HOSTS` list in the `settings.py` Django file. Domain names should be specified as they would appear in the `Host` header (excluding the possible port number); a wildcard-like entry like `.example.com` is allowed, assuming the `example.com` domain and every subdomain. Special value `*` can be used to skip `Host` header validation (not recommended unless you do this validation at some other request processing level).",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2022-06-21T20:52:12",
      "url": "https://stackoverflow.com/questions/72705823/nginx-upstream-server-works-with-ip-address-but-not-with-dns"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 72477655,
      "title": "Ngninx location returning 404 with",
      "problem": "I'm trying to understand how nginx works. I managed to use it with a simple sample app, and to make it work for my.domain.com. Now I'd like to do the same for my.domain.com/api, but I keep having 404 error. Here is my code\n```\n`server {\n  server_name my.domain.com;\n\n  listen 443 ssl;\n\n  ssl_certificate /etc/letsencrypt/live/ec2.tyremotion.fr/fullchain.pem;\n  ssl_certificate_key /etc/letsencrypt/live/ec2.tyremotion.fr/privkey.pem;\n\n  location /api {\n    proxy_pass http://webdemo:80;\n  }\n}\n`\n```\nWhen I connect with my browser to either my.domain.com or my.domain.com/api I'm greeted with an error 404. When i change `location /api` to `location /` it works when I connect to my.domain.com.\nWhat am I doing wrong here ?\nEdit : here is my full nginx config :\n```\n`nginx: the configuration file /etc/nginx/nginx.conf syntax is \nok\nnginx: configuration file /etc/nginx/nginx.conf test is successful\n# configuration file /etc/nginx/nginx.conf:\n\nuser  nginx;\nworker_processes  auto;\n\nerror_log  /var/log/nginx/error.log notice;\npid        /var/run/nginx.pid;\n\nevents {\n    worker_connections  1024;\n}\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log  /var/log/nginx/access.log  main;\n\n    sendfile        on;\n    #tcp_nopush     on;\n\n    keepalive_timeout  65;\n\n    #gzip  on;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n\n# configuration file /etc/nginx/mime.types:\n\ntypes {\n    text/html                                        html htm shtml;\n    text/css                                         css;\n    text/xml                                         xml;\n    image/gif                                        gif;\n    image/jpeg                                       jpeg jpg;\n    application/javascript                           js;\n    application/atom+xml                             atom;\n    application/rss+xml                              rss;\n\n    text/mathml                                      mml;\n    text/plain                                       txt;\n    text/vnd.sun.j2me.app-descriptor                 jad;\n    text/vnd.wap.wml                                 wml;\n    text/x-component                                 htc;\n\n    image/avif                                       avif;\n    image/png                                        png;\n    image/svg+xml                                    svg svgz;\n    image/tiff                                       tif tiff;\n    image/vnd.wap.wbmp                               wbmp;\n    image/webp                                       webp;\n    image/x-icon                                     ico;\n    image/x-jng                                      jng;\n    image/x-ms-bmp                                   bmp;\n\n    font/woff                                        woff;\n    font/woff2                                       woff2;\n\n    application/java-archive                         jar war ear;\n    application/json                                 json;\n    application/mac-binhex40                         hqx;\n    application/msword                               doc;\n    application/pdf                                  pdf;\n    application/postscript                           ps eps ai;\n    application/rtf                                  rtf;\n    application/vnd.apple.mpegurl                    m3u8;\n    application/vnd.google-earth.kml+xml             kml;\n    application/vnd.google-earth.kmz                 kmz;\n    application/vnd.ms-excel                         xls;\n    application/vnd.ms-fontobject                    eot;\n    application/vnd.ms-powerpoint                    ppt;\n    application/vnd.oasis.opendocument.graphics      odg;\n    application/vnd.oasis.opendocument.presentation  odp;\n    application/vnd.oasis.opendocument.spreadsheet   ods;\n    application/vnd.oasis.opendocument.text          odt;\n    application/vnd.openxmlformats-officedocument.presentationml.presentation\n                                                     pptx;\n    application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\n                                                     xlsx;\n    application/vnd.openxmlformats-officedocument.wordprocessingml.document\n                                                     docx;\n    application/vnd.wap.wmlc                         wmlc;\n    application/wasm                                 wasm;\n    application/x-7z-compressed                      7z;\n    application/x-cocoa                              cco;\n    application/x-java-archive-diff                  jardiff;\n    application/x-java-jnlp-file                     jnlp;\n    application/x-makeself                           run;\n    application/x-perl                               pl pm;\n    application/x-pilot                              prc pdb;\n    application/x-rar-compressed                     rar;\n    application/x-redhat-package-manager             rpm;\n    application/x-sea                                sea;\n    application/x-shockwave-flash                    swf;\n    application/x-stuffit                            sit;\n    application/x-tcl                                tcl tk;\n    application/x-x509-ca-cert                       der pem crt;\n    application/x-xpinstall                          xpi;\n    application/xhtml+xml                            xhtml;\n    application/xspf+xml                             xspf;\n    application/zip                                  zip;\n\n    application/octet-stream                         bin exe dll;\n    application/octet-stream                         deb;\n    application/octet-stream                         dmg;\n    application/octet-stream                         iso img;\n    application/octet-stream                         msi msp msm;\n\n    audio/midi                                       mid midi kar;\n    audio/mpeg                                       mp3;\n    audio/ogg                                        ogg;\n    audio/x-m4a                                      m4a;\n    audio/x-realaudio                                ra;\n\n    video/3gpp                                       3gpp 3gp;\n    video/mp2t                                       ts;\n    video/mp4                                        mp4;\n    video/mpeg                                       mpeg mpg;\n    video/quicktime                                  mov;\n    video/webm                                       webm;\n    video/x-flv                                      flv;\n    video/x-m4v                                      m4v;\n    video/x-mng                                      mng;\n    video/x-ms-asf                                   asx asf;\n    video/x-ms-wmv                                   wmv;\n    video/x-msvideo                                  avi;\n}\n\n# configuration file /etc/nginx/conf.d/default.conf:\nserver {\n    listen 80;\n    server_name my.domain.com;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n  server_name my.domain.com;\n\n  listen 443 ssl;\n\n  ssl_certificate /etc/letsencrypt/live/my.domain.com/fullchain.pem;\n  ssl_certificate_key /etc/letsencrypt/live/my.domain.com/privkey.pem;\n\n  location /api {\n    proxy_pass http://webdemo:80;\n  }\n}\n`\n```",
      "solution": "There might be other issues, but this one is probably not what you want :\nThis config means \"when you call to `my.domain.com/api`, use the backend URL `http://webdemo:80`\", and that is all :\n```\n`  location /api {\n    proxy_pass http://webdemo:80;\n  }\n`\n```\nYou might want this instead :\n```\n`  location /api/ {\n    proxy_pass http://webdemo:80/;\n  }\n`\n```\nWhich means : \"when you call to `my.domain.com/api/`, use the backend URL `http://webdemo:80/`, when you call to `my.domain.com/api/anything/else`, use the backend URL `http://webdemo:80/anything/else`, etc\".\nIn other words : locations ending with `/` are considered as roots for multiple locations. Other locations are considered as exact locations.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2022-06-02T16:10:43",
      "url": "https://stackoverflow.com/questions/72477655/ngninx-location-returning-404-with"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 72341371,
      "title": "Nginx locations, try_files and headers issue",
      "problem": "So I've replaced Passenger with Puma for a Rails app, and i just noticed that i now have issues with the cdn assets, they now give CORS errors.\nBack when i was using Passenger i had the following configs for Nginx:\n```\n`server {\n\n  server_name mysite.com;\n  root /var/www/mysite.com/public;\n\n  client_max_body_size 4000M;\n  passenger_enabled on;\n  rails_env production;\n\n  location ~* ^/cdn/ {\n    add_header Access-Control-Allow-Origin *;\n    expires 364d;\n    add_header Pragma public;\n    add_header Cache-Control \"public\";\n    break;\n  }\n\n  location ~* ^/assets/ {\n    # Per RFC2616 - 1 year maximum expiry\n    # http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html\n    expires 1y;\n    add_header Cache-Control public;\n\n    # Some browsers still send conditional-GET requests if there's a\n    # Last-Modified header or an ETag header even if they haven't\n    # reached the expiry date sent in the Expires header.\n    add_header Last-Modified \"\";\n    add_header ETag \"\";\n    break;\n  }\n\n  listen 443 ssl; # managed by Certbot\n  #the rest of the certbot ssl stuff\n\n}\n`\n```\nI then changed the configs to this to make it work with Puma and unix sockets:\n```\n`upstream puma {\n  server unix:///var/www/mysite.com/shared/sockets/puma.sock;\n}\nserver {\n\n  server_name mysite.com;\n  root /var/www/mysite.com/public;\n\n  client_max_body_size 4000M;\n\n  location / {\n    try_files $uri @app;\n  }\n\n  location ~* ^/cdn/ {\n    add_header Access-Control-Allow-Origin *;\n    expires 364d;\n    add_header Pragma public;\n    add_header Cache-Control \"public\";\n    break;\n  }\n\n  location ~* ^/assets/ {\n    # Per RFC2616 - 1 year maximum expiry\n    # http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html\n    expires 1y;\n    add_header Cache-Control public;\n\n    # Some browsers still send conditional-GET requests if there's a\n    # Last-Modified header or an ETag header even if they haven't\n    # reached the expiry date sent in the Expires header.\n    add_header Last-Modified \"\";\n    add_header ETag \"\";\n    break;\n  }\n\n  listen 443 ssl; # managed by Certbot\n  #ssl stuff\n\n  location @app {\n    proxy_pass http://puma;\n\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n    proxy_set_header X-Forwarded-Proto https;\n    proxy_set_header Host $http_host;\n\n    proxy_headers_hash_max_size 512;\n    proxy_headers_hash_bucket_size 128;\n\n    proxy_redirect off;\n  }\n\n}\n`\n```\nThis works fine but then i noticed that the cdn urls were giving 404, so i updated the cdn location to this (i added `try_files $uri @app;`):\n```\n`  location ~* ^/cdn/ {\n    add_header Access-Control-Allow-Origin *;\n    expires 364d;\n    add_header Pragma public;\n    add_header Cache-Control \"public\";\n    try_files $uri @app;\n    break;\n  }\n`\n```\nThis now works but i get CORS errors so it seems the headers are not getting set.\nMy guess is the `try_files` ignores what was set before it is called, so i tried setting the proxy header for access control inside the `location @app` (by adding `proxy_set_header Access-Control-Allow-Origin *;`) but i still get the errors.\nWhat's the correct way to go about this?",
      "solution": "There is no sense in trying to add the response headers with the `proxy_set_header` directive - it is designed for adding/changing headers for the request that will be sent to the upstream. To add the response headers, no matter is it a static or a proxied location, use the `add_header` one. To add headers conditionally, lets say depending on a request URI, you can use the `map` block(s):\n`map $uri $expires {\n    ~^/cdn/  1y;\n    default  off;\n}\nmap $uri $cache_control {\n    ~^/cdn/  public;\n    # default will be an empty value\n}\nmap $uri $allow_origin {\n    ~^/cdn/  *;\n    # default will be an empty value\n}\n`\nHowever in terms of performance, since all the `map`-derived variables are evaluated only once per request, matching regex pattern only once can be slightly more performant:\n```\n`map $cache $expires {\n    1        1y;\n    default  off;\n}\nmap $cache $cache_control {\n    1        public;\n}\nmap $cache $allow_origin {\n    1        *;\n}\nmap $uri $cache {\n    ~^/cdn/  1;\n}\n`\n```\nNext, in your `@app` location you can use the following:\n`location @app {\n    proxy_pass http://puma;\n\n    expires $expires;\n    add_header Cache-Control $cache_control;\n    add_header Access-Control-Allow-Origin $allow_origin;\n\n    # ... proxy_set_... and other upstream setup here\n}\n`\nIf evaluated variable used in an `add_header` directive will be empty, nginx won't add a header with an empty value - instead it won't add such a header at all.\n\nA few notes about your current config:\n\nUsing those kind of regex locations like `location ~ ^/cdn/ { ... }` or `location ~ ^/assets/ { ... }` in favor of prefix locations `location /cdn/ { ... }` or `location /assets/ { ... }` makes no sense and only a performance impact (due to the PCRE library is involved when it isn't nessesary).\n\nThat `break` directive at the end of static locations does nothing since there are no any directives from the rewrite module there which execution should be stopped.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2022-05-22T23:21:46",
      "url": "https://stackoverflow.com/questions/72341371/nginx-locations-try-files-and-headers-issue"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 71268876,
      "title": "Nginx Reverse proxy to Sonarqube not working. Getting 500 error",
      "problem": "Using docker-compose file spinned up 3 docker containers i.e nginx,sonarqube & postgres\ndocker-compose file below :\nversion: \"3.3\"\nservices:\n```\n`sonarqube:\ncontainer_name: sonarqube_9\n image: sonarqube:9-community\n restart: always\n ports: \n    - \"9000\" \n \n networks:\n   - sonarnet\n depends_on:\n    - db\n environment:\n     SONAR_JDBC_URL: jdbc:postgresql://db:5432/sonar\n     SONAR_JDBC_USERNAME: sonar\n     SONAR_JDBC_PASSWORD: sonar\n volumes:\n   - /data/docker-volumes/sonarqube/conf:/opt/sonarqube/conf\n   - /data/docker-volumes/sonarqube/data:/opt/sonarqube/data\n   - /data/docker-volumes/sonarqube/extensions:/opt/sonarqube/extensions\n   - /data/docker-volumes/sonarqube/bundled-plugins:/opt/sonarqube/lib/bundled-plugins\n\ndb:\n  image: postgres:14\n  restart: always\n  ports:\n    - 5432:5432\n  networks:\n    - sonarnet\n  environment:\n    POSTGRES_USER: sonar\n    POSTGRES_PASSWORD: sonar\n  volumes:\n    - /data/docker-volumes/postgresql:/var/lib/postgresql\n    - /data/docker-volumes/postgresql/data:/var/lib/postgresql/data\n\nreverse_proxy:\n  container_name: reverse_proxy\ndepends_on:\n  - sonarqube\nimage: nginx:latest\nnetworks:\n  - sonarnet\nports:\n  - 80:80\n  - 443:443\nrestart: always\nvolumes:\n    - /data/docker-volumes/nginx/conf:/etc/nginx/conf.d/\n    \nnetworks:\n\n sonarnet:\n   name: sonarnet\n  driver: bridge\n`\n```\n.......................................\nInside nginx container inside default.config file for reverse proxy\nserver\n{\n```\n`listen       80;\nserver_name  localhost:9000;\n\nlocation / {\n\n  proxy_pass http://127.0.0.1:9000;\n\n}\n`\n```\n}\nWhen on browser trying to access http://localhost:80\nwe are getting error 500 on screen\nin logs we are getting\nUser_Client: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36\"\n\"Request: GET / HTTP/1.1\nStatus: 502\nRequest_URI: /\nHost: localhost",
      "solution": "`localhost` within nginx container refers to nginx itself. You need to use container name as proxy_pass, e.g. `proxy_pass http://sonarqube_9:9000;`.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2022-02-25T17:31:09",
      "url": "https://stackoverflow.com/questions/71268876/nginx-reverse-proxy-to-sonarqube-not-working-getting-500-error"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 70656102,
      "title": "NGINX and nodejs upstream connection timed out while connecting to upstream but request will get responded after exactly 60s",
      "problem": "Subsequent HTTP requests GET and POST will sometimes take exactly 60s to get a response and other times requests get a response under 100 ms. How should I try to fix this?  I think it has something to do with my nodejs backend and mysql connection and not necessarily nginx reverse proxy and docker containers that these both live in.\nThis is the nginx error that I am getting fairly frequently:\n```\n`2022/01/10 16:43:15 [error] 33#33: *985 upstream timed out (110: Connection timed out) while connecting to upstream, client: xxx.xxx.xxx.xxx, server: sub.domain.tld, request: \"GET /getTemp?api_key=xxxxxxx HTTP/1.1\", upstream: \"http://127.0.0.1:8080/getTemp?api_key=xxxxxxx\", host: \"sub.domain.tld\"\n`\n```\nI have tried to increase nginx `proxy_read_timeout` to 120s as suggested on other posts but that isn't the fix here. I have also switched from `mysql.createConnection()` to `mysql.createPool()` but that didn't fix it.\nHere is my nodejs connection to mysql database:\n```\n`let pool = mysql.createPool({\n    connectionLimit: 10,\n    host: process.env.DB_HOST,\n    user: process.env.DB_USERNAME,\n    password: process.env.DB_PASSWORD,\n    database: process.env.DB_DATABASE,\n    timezone: 'Europe/Helsinki'\n});\n`\n```\nHere is snippet of getTemp endpoint:\n```\n`app.get('/getTemp', (req, res) =>{\n    console.log(req.path);\n    let ip = req.header('x-forwarded-for') || req.socket.remoteAddress;\n\n    let ua = req.get('user-agent');\n    console.log(ua);\n\n    let {api_key} = req.query;\n    console.log(req.query);\n\n    if(api_key == process.env.API_KEY){\n        console.log(`Authorized access from IP: '${ip}'`);\n        // if one of the variables are undefined then send 400 status code to the client\n        if(api_key == undefined){\n            return res.sendStatus(400).send({message:\"One or more variables are undefined\"});\n        }\n        \n        sql_query = \"SELECT * FROM tempData ORDER BY id DESC\";\n\n        sql_query = mysql.format(sql_query);\n        \n        // attempt to query mysql server with the sql_query \n        pool.query(sql_query, (error, result) =>{\n            if (error){\n                // on error log the error to console and send 500 status code to client\n                console.log(error);\n                return res.sendStatus(500);\n            };\n            \n            // if temp is found we send 200 status code to client\n        \n            if(result.length > 0){\n                let currentTemp = result[0].currentTemp;\n                console.log(`Temp: ${currentTemp}`);\n                return res.status(200).send({temperature:currentTemp});\n            }else{\n                // incase temp is not found then we send 500 status code to client\n                console.log('Temperature not found');\n                return res.status(500).send({error:\"Temperature not found\"});\n            }\n        });\n\n    }else{\n      // if client sends invalid api key then send 403 status code to the client\n  \n      console.log(`Unauthorized access using API key '${api_key}' from IP: '${ip}'`);\n      return res.sendStatus(403);\n    }\n})\n`\n```\nAnd here is my nginx config:\n```\n`user www-data;\nworker_processes auto;\npid /run/nginx.pid;\ninclude /etc/nginx/modules-enabled/*.conf;\n\nevents {\n        worker_connections 4096;\n}\n\nhttp {\n         server {\n            listen 80;\n            listen [::]:80;\n\n            listen 443 default_server ssl;\n            listen [::]:443 ssl;\n\n            ssl_certificate /cert.pem;\n            ssl_certificate_key /cert.key;\n\n            server_name sub.domain.tld;\n\n            location / {\n                proxy_read_timeout 120;\n\n                proxy_pass http://localhost:8080;\n                proxy_set_header X-Real-IP $http_cf_connecting_ip;\n                proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n                proxy_set_header Host $http_host;\n                proxy_set_header X-NginX-Proxy true;\n            }\n\n        }\n}\n`\n```",
      "solution": "I assigned static value to the endpoint so it wont query anything from the database and it also would take a minute to respond so it wasn't the database connection or the endpoint that was causing issues. I disabled rate limiting in the app and I didn't timeout anymore. So the reason for my timeouts was a misconfigured rate limit.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2022-01-10T17:56:33",
      "url": "https://stackoverflow.com/questions/70656102/nginx-and-nodejs-upstream-connection-timed-out-while-connecting-to-upstream-but"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 68001334,
      "title": "nginx redirection not working inside location directive",
      "problem": "I have two location directives both containing conditional redirects.\n```\n`server {\n        listen 443 ssl;\n        ssl_certificate /etc/ssl/cert.pem;\n        ssl_certificate_key /etc/ssl/cert.key;\n        server_name services.gixxx.de;\n        \n        location / {\n            if (-f $document_root/maintenance.on) {\n                return 503;\n            }\n            root /usr/share/nginx/html;\n            index index.html index.htm;\n            try_files $uri $uri/ /index.html =404;\n            proxy_set_header Host $host;\n            proxy_http_version 1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection 'upgrade';\n            add_header Cache-Control 'no-cache, must-revalidate, proxy-revalidate, max-age=0';\n        }\n\n        location /api {\n            if (-f $document_root/maintenance.on) {\n                return 503;\n            }\n            proxy_read_timeout 120;\n            proxy_connect_timeout 120;\n            proxy_send_timeout 120;\n            proxy_pass http://serviceapp;\n        }\n        upstream serviceapp {\n            server serviceapp:3000;\n        }\n`\n```\nWhen I create a document name `maintenance.on` on the route folder it works for the first `location / {` directive but not for `location /api {` part.\nWhat is going wrong here.",
      "solution": "You have no `root` defined for the second block. You should move the `root` statement into the outer block and allow it to be inherited by both `location` blocks.",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-06-16T12:56:40",
      "url": "https://stackoverflow.com/questions/68001334/nginx-redirection-not-working-inside-location-directive"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 67412096,
      "title": "How to solve 413 &quot;413 Request Entity Too Large&quot; on elasticbeanstalk Django project",
      "problem": "I am getting this error while uploading file of size larzer then 1MB and i am not able to configure nginx for Django project(Python) how to default file uploading size.",
      "solution": "Increase the value of `client_max_body_size`\nhave a look to this site\nhttps://techies-world.com/nginx-error-413-request-entity-too-large/",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-05-06T07:01:38",
      "url": "https://stackoverflow.com/questions/67412096/how-to-solve-413-413-request-entity-too-large-on-elasticbeanstalk-django-proje"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 67098447,
      "title": "Nginx websocket proxy for Node.js",
      "problem": "I am trying to use Node.js to read phoenix channels using npm package phoenix-channels. Phoenix channels are multiplexed on top of websockets. I'm using an NGINX proxy in front of my phoenix webserver, so for NGINX, it's just a websocket.\nPhoenix channels work fine going to a web page, as you can see here (you'll see data coming through in the web page).\nIt also works fine from nodejs on my internal network:\n\ntest_chan.js (with explicit IP and port):\n```\n`const { Socket } = require('phoenix-channels')\n\nlet socket = new Socket(\"https://192.168.1.113:4445/socket\")\n\nsocket.connect()\n\n// Now that you are connected, you can join channels with a topic:\nlet channel = socket.channel(\"room:lobby\", {})\n\nchannel.on(\"new_msg\", payload => {\n  console.log(`${payload.body}`);\n});\n\nchannel.join()\n  .receive(\"ok\", resp => { console.log(\"Joined successfully\", resp) })\n  .receive(\"error\", resp => { console.log(\"Unable to join\", resp) })\n`\n```\nHowever if I replace the explicity IP:PORT address with the domain name, and run it from externally, it doesn't work (the only difference here from the script above is the URL):\ntest_chan.js (through domain name, and via my NGINX proxy):\n```\n`const { Socket } = require('phoenix-channels')\n\nlet socket = new Socket(\"https://suprabonds.com/socket\")\n\nsocket.connect()\n\n// Now that you are connected, you can join channels with a topic:\nlet channel = socket.channel(\"room:lobby\", {})\n\nchannel.on(\"new_msg\", payload => {\n  console.log(`${payload.body}`);\n});\n\nchannel.join()\n  .receive(\"ok\", resp => { console.log(\"Joined successfully\", resp) })\n  .receive(\"error\", resp => { console.log(\"Unable to join\", resp) })\n`\n```\nSo the suprabonds.com websockets works fine in a browser through the proxy, but doesn't work as a nodejs script.\nHere is my nginx conf for suprabonds.com:\nsites-enabled relevant server section:\n```\n`server {\n    server_name suprabonds.com www.suprabonds.com;\n    \n    location / {\n        proxy_pass  http://localhost:4445;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n    }\n\n    listen 443 ssl; # managed by Certbot\n    ssl_certificate /etc/letsencrypt/live/suprabonds.com/fullchain.pem; # managed by Certbot\n    ssl_certificate_key /etc/letsencrypt/live/suprabonds.com/privkey.pem; # managed by Certbot\n    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot\n\n}\n`\n```\nAny idea as to what I'm doing wrong?\nEDIT\nHere are the /var/log/nginx/access.log latest entries:\n```\n`86.143.74.170 - - [22/Apr/2021:15:52:56 +0000] \"GET /socket/websocket?vsn=1.0.0 HTTP/1.1\" 301 178 \"-\" \"-\"\n86.143.74.170 - - [22/Apr/2021:15:52:58 +0000] \"GET /socket/websocket?vsn=1.0.0 HTTP/1.1\" 301 178 \"-\" \"-\"\n86.143.74.170 - - [22/Apr/2021:15:53:03 +0000] \"GET /socket/websocket?vsn=1.0.0 HTTP/1.1\" 301 178 \"-\" \"-\"\n86.143.74.170 - - [22/Apr/2021:15:53:08 +0000] \"GET /phoenix/live_reload/socket/websocket?vsn=2.0.0 HTTP/1.1\" 101 143 \"-\" \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:87.0) Gecko/20100101 Firefox/87.0\"\n86.143.74.170 - - [22/Apr/2021:15:53:08 +0000] \"GET /socket/websocket?token=undefined&vsn=2.0.0 HTTP/1.1\" 101 113098 \"-\" \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:87.0) Gecko/20100101 Firefox/87.0\"\n86.143.74.170 - - [22/Apr/2021:15:53:19 +0000] \"GET /phoenix/live_reload/socket/websocket?vsn=2.0.0 HTTP/1.1\" 101 79 \"-\" \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:87.0) Gecko/20100101 Firefox/87.0\"\n86.143.74.170 - - [22/Apr/2021:15:53:19 +0000] \"GET /socket/websocket?token=undefined&vsn=2.0.0 HTTP/1.1\" 101 27025 \"-\" \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:87.0) Gecko/20100101 Firefox/87.0\"\n86.143.74.170 - - [22/Apr/2021:15:53:20 +0000] \"GET /socket/websocket?token=undefined&vsn=2.0.0 HTTP/1.1\" 101 479 \"-\" \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:87.0) Gecko/20100101 Firefox/87.0\"\n86.143.74.170 - - [22/Apr/2021:15:53:20 +0000] \"GET /phoenix/live_reload/socket/websocket?vsn=2.0.0 HTTP/1.1\" 101 79 \"-\" \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:87.0) Gecko/20100101 Firefox/87.0\"\n86.143.74.170 - - [22/Apr/2021:15:53:23 +0000] \"GET /socket/websocket?vsn=1.0.0 HTTP/1.1\" 301 178 \"-\" \"-\"\n86.143.74.170 - - [22/Apr/2021:15:53:24 +0000] \"GET /socket/websocket?vsn=1.0.0 HTTP/1.1\" 301 178 \"-\" \"-\"\n86.143.74.170 - - [22/Apr/2021:15:53:26 +0000] \"GET /socket/websocket?vsn=1.0.0 HTTP/1.1\" 301 178 \"-\" \"-\"\n86.143.74.170 - - [22/Apr/2021:15:53:31 +0000] \"GET /socket/websocket?vsn=1.0.0 HTTP/1.1\" 301 178 \"-\" \"-\"\n86.143.74.170 - - [22/Apr/2021:15:53:41 +0000] \"GET /socket/websocket?vsn=1.0.0 HTTP/1.1\" 301 178 \"-\" \"-\"\n`\n```\nThe firefox ones are the ones that work fine. The others (with 301 178 in them) are the ones from the non-working Node.js script (that is, the one using the domain name). The error.log file in the same location is empty.\nPlease note that I'm also using noip dynamic dns.",
      "solution": "If you change your URL to:\n```\n`let socket = new Socket(\"wss://suprabonds.com/socket/websocket?token=undefined\")\n`\n```\nor\n```\n`let socket = new Socket(\"wss://suprabonds.com/socket/websocket?vsn=1.0.0\")\n`\n```\nIt will connect",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-04-14T22:09:18",
      "url": "https://stackoverflow.com/questions/67098447/nginx-websocket-proxy-for-node-js"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-reverse-proxy",
      "question_id": 66599780,
      "title": "Base URL is non-www which results in routes non-www",
      "problem": "I have a Laravel 8 project running on an Nginx Webserver in a Docker container through an Nginx Reverse Proxy.\nSo DNS -> Reverse Proxy -> Docker Webserver container -> PHP-FPM container\nThe problem is that when I use Laravel's `route()` it is missing the www resulting in login not working (as well as assets etc).\nBecause I AM on the www domain (because of Nginx redirect) but the route endpoint is non-www (so a different site, token issue I believe).\nIn my .env I have APP_URL set which I believe is only for CLI commands and additionally I have ASSET_URL set, which works for the `asset()` functions. I should not have to use ASSET_URL if the source of the problem, my setup, is correct (which it clearly is not).\nI CAN bypass the problem by using `URL::forceRootUrl(config('app.url'));` in my router, that forces the APP_URL set in my .env to be used in the `RouteUrlGenerator` (I believe)\nOutput of `\\URL::to('/')` is https://example.com, so NON-WWW (obv. WITHOUT using `URL::forceRootUrl(config('app.url'));`)\nEven though my browser's URL is including www, so https://www.example.com/blabla.\nI would say something is wrong in my setup, either my DNS, Nginx Reverse Proxy, or Nginx Webserver configs but I can't figure out what it is...\nI hope it is just a simple redirect fix somehow.\nI have also already restarted my servers etc and done a `php artisan optimize:clear` and also `config:cache` and `config:clear` to be sure.\nPlease find below my configs:\nDNS via CloudFlare (proxied):\n```\n`A      example.com  123.123.123.123  Proxied\nA      www          123.123.123.123  Proxied\nCNAME  *            example.com      DNS Only\n`\n```\nMy Nginx Reverse Proxy config:\n```\n`server {\n        listen 80;\n        listen [::]:80;\n\n        server_name     example.com www.example.com;\n\n        location / {\n                proxy_pass      http://localhost:8012;\n                proxy_set_header   Host $host;\n                proxy_set_header   X-Real-IP $remote_addr;\n                proxy_set_header   X-Forwarded-For $proxy_add_x_forwarded_for;\n                proxy_set_header   X-Forwarded-Host $server_name;\n        }\n}\n`\n```\nMy Nginx webserver config:\n```\n`server {\n#    listen 80;\n    server_name example.com;\n    return 301 https://www.example.com$request_uri;\n}\n\nserver {\n#    listen 80 default_server;\n    index index.html index.htm index.php;\n    server_name www.example.com;\n    root /var/www/public;\n\n    location ~ \\.php$ {\n        try_files $uri =404;\n        fastcgi_split_path_info ^(.+\\.php)(/.+)$;\n        fastcgi_pass php-fpm:9012;\n        fastcgi_index index.php;\n        include fastcgi_params;\n        # fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        fastcgi_param SCRIPT_FILENAME /var/www/example.com/public/$fastcgi_script_name;\n        # fastcgi_param SCRIPT_FILENAME $document_root/example.com.au/$fastcgi_script_name;\n        fastcgi_param PATH_INFO $fastcgi_path_info;\n    }\n    \n   # Support Clean (aka Search Engine Friendly) URLs & enable Gzip compression:\n    location / {\n        try_files $uri $uri/ /index.php?$query_string;\n        gzip_static on;\n    }\n\n    error_log  /var/log/nginx/error.log;\n    access_log /var/log/nginx/access.log;\n}\n`\n```\nMy \"default\" Laravel 8 .htaccess:\n```\n`\n    \n        Options -MultiViews -Indexes\n    \n\n    RewriteEngine On\n\n    # Handle Authorization Header\n    RewriteCond %{HTTP:Authorization} .\n    RewriteRule .* - [E=HTTP_AUTHORIZATION:%{HTTP:Authorization}]\n\n    # Redirect Trailing Slashes If Not A Folder...\n    RewriteCond %{REQUEST_FILENAME} !-d\n    RewriteCond %{REQUEST_URI} (.+)/$\n    RewriteRule ^ %1 [L,R=301]\n\n    # Send Requests To Front Controller...\n    RewriteCond %{REQUEST_FILENAME} !-d\n    RewriteCond %{REQUEST_FILENAME} !-f\n    RewriteRule ^ index.php [L]\n\n`\n```\nMy .env:\n```\n`APP_NAME=SomeSite.com\nAPP_ENV=production\nAPP_KEY=base64:sdljkldasjkasjasdjklaslkasd\nAPP_DEBUG=true\nAPP_URL=https://www.example.com#Used for CLI function such as artisan...\n#ASSET_URL=https://asseturl.test#Only used in asset()\nTRUSTPROXIES=*\n...\n`\n```",
      "solution": "Solution is moving the 301 redirect from Nginx Webserver to Nginx Reverse Proxy (superior level).\nThis is the following part of the configuration file:\n```\n`server {\n    listen 80;\n    server_name example.com;\n    return 301 https://www.example.com$request_uri;\n}\n`\n```\nEdit: I suspect it's related to the part:\n```\n`proxy_set_header   Host $host;\n`\n```",
      "question_score": 1,
      "answer_score": 1,
      "created_at": "2021-03-12T13:17:14",
      "url": "https://stackoverflow.com/questions/66599780/base-url-is-non-www-which-results-in-routes-non-www"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69517855,
      "title": "Microk8s dashboard using nginx-ingress via http not working (Error: `no matches for kind &quot;Ingress&quot; in version &quot;extensions/v1beta1&quot;`)",
      "problem": "I have microk8s v1.22.2 running on Ubuntu 20.04.3 LTS.\nOutput from `/etc/hosts`:\n```\n`127.0.0.1 localhost\n127.0.1.1 main\n`\n```\nExcerpt from `microk8s status`:\n```\n`addons:\n  enabled:\n    dashboard            # The Kubernetes dashboard\n    ha-cluster           # Configure high availability on the current node\n    ingress              # Ingress controller for external access\n    metrics-server       # K8s Metrics Server for API access to service metrics\n`\n```\nI checked for the running dashboard (`kubectl get all --all-namespaces`):\n```\n`NAMESPACE     NAME                                             READY   STATUS    RESTARTS   AGE\nkube-system   pod/calico-node-2jltr                            1/1     Running   0          23m\nkube-system   pod/calico-kube-controllers-f744bf684-d77hv      1/1     Running   0          23m\nkube-system   pod/metrics-server-85df567dd8-jd6gj              1/1     Running   0          22m\nkube-system   pod/kubernetes-dashboard-59699458b-pb5jb         1/1     Running   0          21m\nkube-system   pod/dashboard-metrics-scraper-58d4977855-94nsp   1/1     Running   0          21m\ningress       pod/nginx-ingress-microk8s-controller-qf5pm      1/1     Running   0          21m\n\nNAMESPACE     NAME                                TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE\ndefault       service/kubernetes                  ClusterIP   10.152.183.1             443/TCP    23m\nkube-system   service/metrics-server              ClusterIP   10.152.183.81            443/TCP    22m\nkube-system   service/kubernetes-dashboard        ClusterIP   10.152.183.103           443/TCP    22m\nkube-system   service/dashboard-metrics-scraper   ClusterIP   10.152.183.197           8000/TCP   22m\n\nNAMESPACE     NAME                                               DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\nkube-system   daemonset.apps/calico-node                         1         1         1       1            1           kubernetes.io/os=linux   23m\ningress       daemonset.apps/nginx-ingress-microk8s-controller   1         1         1       1            1                              22m\n\nNAMESPACE     NAME                                        READY   UP-TO-DATE   AVAILABLE   AGE\nkube-system   deployment.apps/calico-kube-controllers     1/1     1            1           23m\nkube-system   deployment.apps/metrics-server              1/1     1            1           22m\nkube-system   deployment.apps/kubernetes-dashboard        1/1     1            1           22m\nkube-system   deployment.apps/dashboard-metrics-scraper   1/1     1            1           22m\n\nNAMESPACE     NAME                                                   DESIRED   CURRENT   READY   AGE\nkube-system   replicaset.apps/calico-kube-controllers-69d7f794d9     0         0         0       23m\nkube-system   replicaset.apps/calico-kube-controllers-f744bf684      1         1         1       23m\nkube-system   replicaset.apps/metrics-server-85df567dd8              1         1         1       22m\nkube-system   replicaset.apps/kubernetes-dashboard-59699458b         1         1         1       21m\nkube-system   replicaset.apps/dashboard-metrics-scraper-58d4977855   1         1         1       21m\n`\n```\nI want to expose the microk8s dashboard within my local network to access it through `http://main/dashboard/`\nTo do so, I did the following `nano ingress.yaml`:\n```\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: public\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\n  name: dashboard\n  namespace: kube-system\nspec:\n  rules:\n  - host: main\n    http:\n      paths:\n      - backend:\n          serviceName: kubernetes-dashboard\n          servicePort: 443\n        path: /\n`\n```\nEnabling the ingress-config through `kubectl apply -f ingress.yaml` gave the following error:\n```\n`error: unable to recognize \"ingress.yaml\": no matches for kind \"Ingress\" in version \"extensions/v1beta1\"\n`\n```\nHelp would be much appreciated, thanks!\nUpdate:\n@harsh-manvar pointed out a mismatch in the config version. I have rewritten ingress.yaml to a very stripped down version:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: dashboard\n  namespace: kube-system\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /dashboard\n        pathType: Prefix\n        backend:\n          service:\n            name: kubernetes-dashboard\n            port:\n              number: 443\n`\n```\nApplying this works. Also, the ingress rule gets created.\n```\n`NAMESPACE     NAME        CLASS    HOSTS   ADDRESS     PORTS   AGE\nkube-system   dashboard   public   *       127.0.0.1   80      11m\n`\n```\nHowever, when I access the dashboard through `http:///dashboard`, I get a `400` error.\nLog from the ingress controller:\n```\n`192.168.0.123 - - [10/Oct/2021:21:38:47 +0000] \"GET /dashboard HTTP/1.1\" 400 54 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.71 Safari/537.36\" 466 0.002 [kube-system-kubernetes-dashboard-443] [] 10.1.76.3:8443 48 0.000 400 ca0946230759edfbaaf9d94f3d5c959a\n`\n```\nDoes the dashboard also need to be exposed using the `microk8s proxy`? I thought the ingress controller would take care of this, or did I misunderstand this?",
      "solution": "To fix the error `error: unable to recognize \"ingress.yaml\": no matches for kind \"Ingress\" in version \"extensions/v1beta1` you need to set `apiVersion` to the ` networking.k8s.io/v1`. From the Kubernetes v1.16 article about deprecated APIs:\n\nNetworkPolicy in the  extensions/v1beta1  API version is no longer served\n-   Migrate to use the  networking.k8s.io/v1  API version, available since v1.8. Existing persisted data can be retrieved/updated via the new version.\n\nNow moving to the second issue. You need to add a few annotations and make few changes in your Ingress definition to make dashboard properly exposed on the microk8s cluster:\n\nadd `nginx.ingress.kubernetes.io/rewrite-target: /$2` annotation\nadd `nginx.ingress.kubernetes.io/configuration-snippet: | rewrite ^(/dashboard)$ $1/ redirect;` annotation\nchange `path: /dashboard` to `path: /dashboard(/|$)(.*)`\n\nWe need them to properly forward the request to the backend pods - good explanation in this article:\n\nNote: The \"nginx.ingress.kubernetes.io/rewrite-target\" annotation rewrites the URL before forwarding the request to the backend pods. In /dashboard(/|$)(.*) for path, (.*) stores the dynamic URL that's generated while accessing the Kubernetes Dashboard. The \"nginx.ingress.kubernetes.io/rewrite-target\" annotation replaces the captured data in the URL before forwarding the request to the kubernetes-dashboard service. The \"nginx.ingress.kubernetes.io/configuration-snippet\" annotation rewrites the URL to add a trailing slash (\"/\") only if ALB-URL/dashboard is accessed.\n\nAlso we need another two changes:\n\nadd `nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"` annotation to tell NGINX Ingress to communicate with Dashboard service using HTTPs\nadd `kubernetes.io/ingress.class: public` annotation to use NGINX Ingress created by microk8s `ingress` plugin\n\nAfter implementing everything above, the final YAML file looks like this:\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      rewrite ^(/dashboard)$ $1/ redirect;\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\n    kubernetes.io/ingress.class: public\n  name: dashboard\n  namespace: kube-system\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /dashboard(/|$)(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: kubernetes-dashboard\n            port:\n              number: 443\n`\nIt should work fine. No need to run `microk8s proxy` command.",
      "question_score": 38,
      "answer_score": 42,
      "created_at": "2021-10-10T20:23:07",
      "url": "https://stackoverflow.com/questions/69517855/microk8s-dashboard-using-nginx-ingress-via-http-not-working-error-no-matches"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66568194,
      "title": "Kustomize how to replace only the host in Ingress configuration",
      "problem": "I've got this ingress.yaml base configuration:\n```\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  labels:\n    sia: aza\n    app: asap-ingress-internal\n  name: asap-ingress-internal\n  annotations:\n    kubernetes.io/ingress.class: \"nginx-external\"\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\nspec:\n  rules:\n    - host: the-host-value\n      http:\n        paths:\n          - path: /asap-srv-template/(.*)\n            backend:\n              serviceName: asap-srv-template\n              servicePort: 8080\n`\n```\nAnd want to replace the spec.rules.host value only (and keep all http.paths as is.\nSo I create a env-var.yaml like this :\n```\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: asap-ingress-internal\nspec:\n  rules:\n    - host: the.real.hostname\n`\n```\nBut the result is the following:\n```\n`$ kustomize build\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx-external\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n  labels:\n    app: asap-ingress-internal\n    env: dev\n    sia: aza\n  name: asap-ingress-internal\n  namespace: aza-72461-dev\nspec:\n  rules:\n  - host: the.real.hostname\n`\n```\nI have lost all http.paths configuration and I can't find out how to do.\nI tried with patches: or patchesStrategicMerge in kustomization.yaml but the result is always the same.\nAny help would be greatly appreciated",
      "solution": "You can use a json patch for this, below is an example.\nHere is an example `kustomization.yaml`. It will call out a patch in the `patches` section:\n```\n`apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\n\nresources:\n- ../../base/app1\n\npatches:\n- target:\n    kind: Ingress\n    name: my-ingress\n  path: ingress-patch.json  \n`\n```\nHere would be an example `ingress-patch.json`:\n```\n`[\n    { \n        \"op\": \"replace\", \n        \"path\": \"/spec/rules/0/host\", \n        \"value\": \"the.real.hostname\"\n    }\n]\n`\n```",
      "question_score": 25,
      "answer_score": 28,
      "created_at": "2021-03-10T16:46:49",
      "url": "https://stackoverflow.com/questions/66568194/kustomize-how-to-replace-only-the-host-in-ingress-configuration"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66450970,
      "title": "Kubernetes ingress nginx redirect to https",
      "problem": "To redirect any HTTP traffic to HTTPS on tls enabled hosts, I have added the below annotation to my ingress resources\n```\n`nignx.ingress.kubernetes.io/force-ssl-redirect: true\n`\n```\nWith this when I curl the host in question, I get redirected as expected\n\nBut when I use a browser, the request to HTTP times out.\nNow, I am not sure if it's something I am doing wrong at Nginx ingress conf as curl works?\nAny pointers please? Thanks!\ncomplete annotaiotns:\n```\n`   annotations:\n    kubernetes.io/ingress.class: nginx-ingress\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/proxy-body-size: 100m\n    nginx.ingress.kubernetes.io/proxy-connect-timeout: \"300\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"300\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"300\"\n    nginx.ingress.kubernetes.io/ssl-passthrough: \"false\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"false\"\n`\n```\nrules\n```\n` rules:\n  - host: hostX\n    http:\n      paths:\n      - backend:\n          serviceName: svcX\n          servicePort: 8080\n        path: /\n  - host: hostY\n    http:\n      paths:\n      - backend:\n          serviceName: svcX\n          servicePort: 8080\n        path: /\n  tls:\n  - hosts:\n    - hostX\n  - hosts:\n    - hostY\n    secretName: hostY-secret-tls\n`\n```\nNote:\n\nThe curl mentioned is to hostY in the rule above.\nHTTPS to hostY via browser works and so cert is valid one.",
      "solution": "As @mdaniel have mentioned your snippet shows `nignx.ingress.kubernetes.io/force-ssl-redirect: true` but annotations should be strings. Notice that in your \"complete\" config, you have both `force-ssl-redirect: \"true\"`  (now correctly a string) and `ssl-redirect: \"false\"` .\nSimply remove annotation  `nginx.ingress.kubernetes.io/ssl-redirect: \"false\"` and leave just `nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"`\nAlso enable `--enable-ssl-passthrough`. This is required to enable passthrough backends in Ingress objects.\nYour annotation should look like:\n```\n`kubernetes.io/ingress.class: nginx-ingress\nnginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\nnginx.ingress.kubernetes.io/ssl-passthrough: \"true\"\nnginx.ingress.kubernetes.io/proxy-body-size: 100m\nnginx.ingress.kubernetes.io/proxy-connect-timeout: \"300\"\nnginx.ingress.kubernetes.io/proxy-read-timeout: \"300\"\nnginx.ingress.kubernetes.io/proxy-send-timeout: \"300\"\n`\n```\nIf you defined hosts under TLS section they are going to be accessible only using https. HTTP requests are being redirected to use HTTPS. That is why you cannot access host via HTTP. Also you have to specify secret for host `hostX`, otherwise the default certificate will be used for ingress. Or if you don't want to connect to host `hostX` via HTTPS simply create different ingress without TLS section for it.\nTake a look: .",
      "question_score": 18,
      "answer_score": 14,
      "created_at": "2021-03-03T05:49:04",
      "url": "https://stackoverflow.com/questions/66450970/kubernetes-ingress-nginx-redirect-to-https"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 71170639,
      "title": "Error converting YAML to JSON: yaml: line 15: did not find expected alphabetic or numeric character",
      "problem": "I want to set wildcard subdomain for my project, using k8s, nginx ingress controller, helm chart:\nIn `ingress.yaml` file:\n```\n`...\nrules:\n  - host: {{ .Values.ingress.host }}\n...\n`\n```\nIn `values.yaml` file, I change host `example.local` to `*.example.local`:\n```\n`...\ningress:\n  enabled: true\n  host: \"*.example.local\"\n...\n`\n```\nThen, when I install chart using helm chart:\n```\n`Error: YAML parse error on example/templates/ingress.yaml: error converting YAML to JSON: yaml: line 15: did not find expected alphabetic or numeric character\n`\n```\nHow can I fix it?\nThank for your support.",
      "solution": "YAML treats strings starting with asterisk in a special way - that's why the hostname with wildcards like `*.example.local`  breaks the ingress on `helm install`.\nIn order to be recognized as strings, the values in `ingress.yaml` file should be quoted with  `\" \"` characters:\n`...\nrules:\n  - host: \"{{ .Values.ingress.host }}\"\n...\n`\nOne more option here - adding `| quote` :\n`...\nrules:\n  - host: {{ .Values.ingress.host | quote }}\n...\n`\nI've reproduced your issue, both these options worked correctly. More information on quoting special characters for YAML is here.",
      "question_score": 14,
      "answer_score": 28,
      "created_at": "2022-02-18T09:47:06",
      "url": "https://stackoverflow.com/questions/71170639/error-converting-yaml-to-json-yaml-line-15-did-not-find-expected-alphabetic-o"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70327524,
      "title": "How to reload nginx ingress controller",
      "problem": "I have a Kubernetes cluster (v. 1.22) and inside it I have Nginx ingress controller deployed. I have found I could reload my ingress in several situations:\nThe next list describes the scenarios when a reload is required:\n\nNew Ingress Resource Created.\nTLS section is added to existing Ingress.\nChange in Ingress annotations that impacts more than just upstream configuration. For instance load-balance annotation does not require a reload.\nA path is added/removed from an Ingress.\nAn Ingress, Service, Secret is removed.\nSome missing referenced object from the Ingress is available, like a Service or Secret.\nA Secret is updated.\n\nMy ingress now using only HTTP traffic and I want to add TLS section to existing Ingress.\nSo, my question is: What should I exactly do to reload my ingress?\nI cannot find any information in docs or other places. Any suggestion is appreciated!",
      "solution": "What should I exactly do to reload my ingress?\n\nYou just need to update the ingress, in your case you just need to add the TLS section is to existing Ingress.\nThen (automatically) the ingress controller should find the differences (as anemyte says in its answer) and update the ingress. From now on, you will be able to use TLS.\nIn general, this should all happen automatically. In theory, this could also be done manually, although it is not recommended. It is described in this topic.\n\nEDIT:\nI have reproduced this situation.\nFirst I have created simple ingress with following `ingress.yaml`:\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ing-1\nspec:\n  ingressClassName: nginx\n  rules:\n    - host: www.example.com\n      http:\n        paths:\n          - backend:\n              service:\n                name: app-1\n                port:\n                  number: 80\n            path: /\n            pathType: Prefix\n`\nThen I have run `kubectl get ingress` and here is the output:\n```\n`NAME    CLASS   HOSTS             ADDRESS        PORTS     AGE\ning-1   nginx   www.example.com   35.X.X.X       80        3m\n`\n```\nIn this step I had working ingress without TLS (only working port 80). Then I have created  `tls.yaml` for TLS (I have used self signed certs, you need to use your certs and domain):\n`apiVersion: v1\nkind: Secret\nmetadata:\n  name: tls\ndata:\n  tls.crt: |\n    \n  tls.key: |\n    \ntype: kubernetes.io/tls\n`\nI have run in by `kubectl apply -f tls.yaml` and then I had changed `ingress.yaml` as below:\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ing-1\nspec:\n  ingressClassName: nginx\n  rules:\n    - host: www.example.com\n      http:\n        paths:\n          - backend:\n              service:\n                name: app-1\n                port:\n                  number: 80\n            path: /\n            pathType: Prefix\n    # This section is only required if TLS is to be enabled for the Ingress\n  tls:\n   - hosts:\n     - www.example.com\n     secretName: tls\n`\nI have added the TLS section. Then I have run `kubectl apply -f ingress.yaml` and after few second I could see this output when running `kubectl get ingress`:\n```\n`NAME    CLASS   HOSTS             ADDRESS        PORTS     AGE\ning-1   nginx   www.example.com   35.239.7.126   80, 443   18m\n`\n```\nTLS is working. In the logs I can see this message:\n```\n`Event(v1.ObjectReference{Kind:\"Ingress\", Namespace:\"default\", Name:\"ing-1\", UID:\"84966fae-e135-47bb-8110-bf372de912c8\", APIVersion:\"networking.k8s.io/v1\", ResourceVersion:\"11306\", FieldPath:\"\"}): type: 'Normal' reason: 'Sync' Scheduled for sync\n`\n```\nIngress reloaded automatically :)",
      "question_score": 13,
      "answer_score": 9,
      "created_at": "2021-12-12T21:40:40",
      "url": "https://stackoverflow.com/questions/70327524/how-to-reload-nginx-ingress-controller"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66280437,
      "title": "How to properly configure ingress cache to get it working?",
      "problem": "I'm trying to configure cache for a specific host, but getting 404. Also It seems my config was not included into final nginx.conf. This file doesn't contain it\nMy ingress.yaml:\n```\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: images-ingress\n  labels:\n    last_updated: \"14940999355\"\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    nginx.ingress.kubernetes.io/proxy-body-size: 8m\n    nginx.ingress.kubernetes.io/proxy-buffering: \"on\"\n    nginx.ingress.kubernetes.io/server-snippet: |\n      proxy_cache static-cache;\n      proxy_cache_valid 404 10m;\n      proxy_cache_use_stale error timeout updating http_404 http_500 http_502 http_503 http_504;\n      proxy_cache_bypass $http_x_purge;\n      add_header X-Cache-Status $upstream_cache_status;\nspec:\n  tls:\n  - hosts:\n    - static.qwstrs.com\n    secretName: letsencrypt-prod\n  rules:\n  - host: static.qwstrs.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: imaginary\n          servicePort: 9000\n`\n```\nIf I remove this sample\n```\n`  nginx.ingress.kubernetes.io/server-snippet: |\n      proxy_cache static-cache;\n      proxy_cache_valid 404 10m;\n      proxy_cache_use_stale error timeout updating http_404 http_500 http_502 http_503 http_504;\n      proxy_cache_bypass $http_x_purge;\n      add_header X-Cache-Status $upstream_cache_status;\n`\n```\neverything works but without cache\neven if I have one line from snippet above It produces 404 error and doesn't work\n```\n`  nginx.ingress.kubernetes.io/server-snippet: |\n      proxy_cache static-cache;\n`\n```",
      "solution": "To enable caching, you need to configure the proxy_cache_path for the `nginx-ingress-controller`.\nYou can do it by modifying the `ConfigMap` for `nginx-ingress-controller`.\n\nI've created an example to illustrate you how it works (I assume you have kubernetes/ingress-nginx).\nFirst, create a `ConfigMap` named `ingress-nginx-controller` as described in the documentation custom_configuration:\nNote: You may need to modify the `proxy_cache_path` settings, but shared memory zone (keys_zone=static-cache) should be the same as in your `proxy_cache` directive.\n```\n`$ cat configmap.yml\n# configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: ingress-nginx-controller\n  namespace: default\ndata:\n  http-snippet: \"proxy_cache_path /tmp/nginx_cache levels=1:2 keys_zone=static-cache:10m max_size=10g  inactive=60m use_temp_path=off;\"\n  \n$ kubectl apply -f configmap.yml \nconfigmap/ingress-nginx-controller configured\n`\n```\nAnd then create the `Ingress` resource ( I've modified your ingress resource a bit to demonstrate how `X-Cache-Status` header works):\n```\n`$ cat ingress.yml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: images-ingress\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    nginx.ingress.kubernetes.io/proxy-body-size: 8m\n    nginx.ingress.kubernetes.io/proxy-buffering: \"on\"\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      proxy_cache static-cache;\n      proxy_cache_valid any 60m;\n      add_header X-Cache-Status $upstream_cache_status;\nspec:\n  tls:\n  - hosts:\n    - static.qwstrs.com\n    secretName: letsencrypt-prod\n  rules:\n  - host: static.qwstrs.com\n    http:\n      paths:\n      - path: /\n        backend:\n          serviceName: imaginary\n          servicePort: 9000\n          \n$ kubectl apply -f ingress.yml\ningress.extensions/images-ingress configured\n`\n```\nFinally we can check:\n```\n`$ curl -k -I https://static.qwstrs.com\nHTTP/2 200\n...\nx-cache-status: MISS\naccept-ranges: bytes\n\n$ curl -k -I https://static.qwstrs.com\nHTTP/2 200\n...\nx-cache-status: HIT\naccept-ranges: bytes\n`\n```\nMore information on `proxy_cache_path` and `proxy_cache` can be found here.",
      "question_score": 10,
      "answer_score": 12,
      "created_at": "2021-02-19T16:30:48",
      "url": "https://stackoverflow.com/questions/66280437/how-to-properly-configure-ingress-cache-to-get-it-working"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70531119,
      "title": "Why do I have to edit /etc/hosts just sometimes when using nginx-ingress controller and resources in my local k8s environment?",
      "problem": "Not sure if this is OS specific, but on my M1 Mac, I'm installing the Nginx controller and resource example located in the official Quick Start guide for the controller. for Docker Desktop for Mac. The instructions are as follows:\n```\n`// Create the Ingress\nhelm upgrade --install ingress-nginx ingress-nginx \\\n  --repo https://kubernetes.github.io/ingress-nginx \\\n  --namespace ingress-nginx --create-namespace\n\n// Pre-flight checks\nkubectl get pods --namespace=ingress-nginx\n\nkubectl wait --namespace ingress-nginx \\\n  --for=condition=ready pod \\\n  --selector=app.kubernetes.io/component=controller \\\n  --timeout=120s\n\n// and finally, deploy and test the resource.\nkubectl create deployment demo --image=httpd --port=80\nkubectl expose deployment demo\n\nkubectl create ingress demo-localhost --class=nginx \\\n  --rule=demo.localdev.me/*=demo:80\n\nkubectl port-forward --namespace=ingress-nginx service/ingress-nginx-controller 8080:80\n`\n```\nI noticed that the instructions did not mention having to edit the `/etc/hosts` file, which I found strange. And, when I tested it by putting `demo.localdev.me:8080` into the browser, it did work as expected!\nBut why? What happened that an application inside of a docker container was able to influence behavior on my host machine and intercept its web traffic without me having to edit the `/etc/hosts` file?\nFor my next test, I re-executed everything above with the only change being that I switched `demo` to `demo2`. That did not work. I did have to go into `/etc/hosts` and add `demo2.localdev.me 127.0.0.1` as an entry. After that both demo and demo2 work as expected.\nWhy is this happening? Not having to edit the /etc/hosts file is appealing. Is there a way to configure it so that they all work? How would I turn it \"off\" from happening automatically if I needed to route traffic back out to the internet rather than my local machine?",
      "solution": "I replicated your issue and got a similar behaviour on the Ubuntu 20.04.3 OS.\nThe problem is that NGINX Ingress controller Local testing guide did not mention that `demo.localdev.me` address points to `127.0.0.1` - that's why it works without editing `/etc/hosts` or `/etc/resolve.conf` file. Probably it's something like `*.localtest.me` addresses:\n\nHere\u2019s how it works. The entire domain name localtest.me\u2014and all wildcard entries\u2014point to 127.0.0.1. So without any changes to your host file you can immediate start testing with a local URL.\n\nAlso good and detailed explanation in this topic.\nSo Docker Desktop / Kubernetes change nothing on your host.\nThe address `demo2.localdev.me` also points to `127.0.0.1`, so it should work as well for you - and as I tested in my environment the behaviour was exactly the same as for the `demo.localdev.me`.\nYou may run `nslookup` command and check which IP address is pointed to the specific domain name, for example:\n```\n`user@shell:~$ nslookup demo2.localdev.me\nServer:         127.0.0.53\nAddress:        127.0.0.53#53\n\nNon-authoritative answer:\nName:   demo2.localdev.me\nAddress: 127.0.0.1\n`\n```\nYou may try to do some tests with other hosts name, like some existing ones or no-existing then of course it won't work because the address won't be resolved to the `127.0.0.1` thus it won't be forwarded to the Ingress NGINX controller. In these cases, you can edit `/etc/hosts` (as you did) or use `curl` flag `-H`, for example:\nI created the ingress using following command:\n```\n`kubectl create ingress demo-localhost --class=nginx --rule=facebook.com/*=demo:80\n`\n```\nThen I started port-forwarding and I run:\n```\n`user@shell:~$ curl -H \"Host: facebook.com\" localhost:8080\nIt works!\n`\n```\nYou wrote:\n\nFor my next test, I re-executed everything above with the only change being that I switched `demo` to `demo2`. That did not work. I did have to go into `/etc/hosts` and add `demo2.localdev.me 127.0.0.1` as an entry. After that both demo and demo2 work as expected.\n\nWell, that sounds strange, could you run `nslookup demo2.localdev.me` without adding an entry in the `/etc/hosts` and then check? Are you sure you performed the correct query before, did you not change something on the Kubernetes configuration side? As I tested (and presented above), it should work exactly the same as for `demo.localdev.me`.",
      "question_score": 9,
      "answer_score": 9,
      "created_at": "2021-12-30T12:39:33",
      "url": "https://stackoverflow.com/questions/70531119/why-do-i-have-to-edit-etc-hosts-just-sometimes-when-using-nginx-ingress-control"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69471950,
      "title": "Problem creating another ingress-nginx/ingress-nginx via helm &quot;Error: rendered manifests contain a resource that already exists&quot;",
      "problem": "I keep getting this error or variations when I try to do as it asks:\n```\n`Error: rendered manifests contain a resource that already exists. Unable to continue with install: IngressClass \"nginx\" in namespace \"\" exists and cannot be imported into the current release: invalid ownership metadata; annotation validation error: key \"meta.helm.sh/release-name\" must equal \"new-ingress-nginx\": current value is \"old-ingress-nginx\"\n`\n```\nI'm using helm to install:\n```\n`helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\nhelm repo update\n\nhelm install new-ingress-nginx ingress-nginx/ingress-nginx --set-string controller.podAnnotations.\"app\\.kubernetes\\.io/instance\"=\"new\"\n`\n```\nI've tried with and without the podAnnotations as I found a post mentioning to try that.\nI'm using google kubernetes engine and what I have done is merged all my api's under one load balancer/ingress-nginx but I would like to figure out the issue.",
      "solution": "I was able to solve my problem after reading through this on github\nSome changes were made and `--set controller.ingressClassResource.name=` is now used and the yaml file no longer looks like:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: some-ingress\n  namespace: somenamespace\n  annotations:\n    kubernetes.io/ingress.class: \n    ...\nspec:\n  tls:\n  ...\n`\n```\nit looks like:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: some-ingress\n  namespace: somenamespace\n  annotations:\n    ...\nspec:\n  ingressClassName: \n  tls:\n  ...\n`\n```",
      "question_score": 7,
      "answer_score": 10,
      "created_at": "2021-10-06T21:53:26",
      "url": "https://stackoverflow.com/questions/69471950/problem-creating-another-ingress-nginx-ingress-nginx-via-helm-error-rendered-m"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 65598713,
      "title": "K8S Ingress: How to limit requests in flight per pod",
      "problem": "I am porting an application to run within k8s.  I have run into an issue with ingress.  I am trying to find a way to limit the number of REST API requests in flight at any given time to each backend pod managed by a deployment.\nSee the image below the shows the architecture.\nIngress is being managed by nginx-ingress.  For a given set of URL paths, the ingress forwards the request to a service that targets a deployment of REST API backend processes.  The deployment is also managed by an HPA based upon CPU load.\nWhat I want to do is find a way to queue up ingress requests such that there are never more than X requests in flight to any pod running our API backend process.  (ex. only allow 50 requests in flight at once per pod)\nDoes anyone know how to put a request limit in place like this?\nAs a bonus question, the next thing I would need to do is have the HPA monitor the request queuing and automatically scale up/down the deployment to match the number of pods to the number of requests currently being processed / queued.  For example if each pod can handle 100 requests in flight at once and we currently have load levels of 1000 requests to handle, then autoscale to 10 pods.\nIf it is useful, I am also planning to have linkerd in place for this cluster.  Perhaps it has a capability that could help.",
      "solution": "Autoscaling in Network request requires the custom metrics. Given that you are using the NGINX ingress controller, you can first install prometheus and prometheus adaptor to export the metrics from NGINX ingress controller. By default, NGINX ingress controller has already exposed the prometheus endpoint.\nThe relation graph will be like this.\n```\n`NGINX ingress The arrow means the calling in API. So, in total, you will have three more extract components in your cluster.\nOnce you have set up the custom metric server, you can scale your app based on the metrics from NGINX ingress. The HPA will look like this.\n```\n`apiVersion: autoscaling/v2beta1\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: srv-deployment-custom-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: extensions/v1beta1\n    kind: Deployment\n    name: srv-deployment\n  minReplicas: 1\n  maxReplicas: 100\n  metrics:\n  - type: Pods\n    pods:\n      metricName: nginx_srv_server_requests_per_second\n      targetAverageValue: 100\n`\n```\nI won't go through the actual implementation here because it will include a lot of environment specific configuration.\nOnce you have set that up, you can see the HPA object will show up the metrics which is pulling from the adaptor.\nFor the rate limiting in the `Service` object level, you will need a powerful service mesh to do so. Linkerd2 is designed to be lightweight so it does not ship with the function in rate limiting. You can refer to this issue under linkerd2. The maintainer rejected to implement the rate limiting in the service level. They would suggest you to do this on `Ingress` level instead.\nAFAIK, Istio and some advanced serivce mesh provides the rate limiting function. In case you haven't deployed the linkerd as your service mesh option, you may try Istio instead.\nFor Istio, you can refer this document to see how to do the rate limiting. But I need to let you know that Istio with NGINX ingress may cause you a trouble. Istio is shipped with its own ingress controller. You will need to have extra work for making it work.\nTo conclude, if you can use the HPA with custom metrics in the number of requests, it will be the quick solution to resolve your issue in traffic control. Unless you still have a really hard time with the traffic control, you will then need to consider the `Service` level rate limiting.",
      "question_score": 7,
      "answer_score": 4,
      "created_at": "2021-01-06T16:36:30",
      "url": "https://stackoverflow.com/questions/65598713/k8s-ingress-how-to-limit-requests-in-flight-per-pod"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66223566,
      "title": "Adding Public IP to Nginx Ingress Controller with MetalLB",
      "problem": "I have three nodes in my cluster who are behind a firewall I do not control. This firewall has a public IP connected to it and can forward traffic to my kubernetes node. It has port 80 and 443 opened to my node.\nInitially, I used the public IP in the MetalLB config like this:\n```\n`apiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: default\n      protocol: layer2\n      addresses:\n      - 186.xx.xx.xx-186.xx.xx.xx\n\n`\n```\nBut after reading this answer of another question I'm guessing it is invalid since the IP used by MetalLB needs to be on the same subnet as the nodes? And they are all using private IPs.\nWhen I tested locally a HTTP server listening on port 80 and ran it on the actual node (not in the cluster) then I was able get a response on the public IP from outside the network.\nSo my question is:\nHow do I make MetalLB or Nginx ingress controller listen on port 80 and 443 for incoming request?\nWhen using `curl 186.xx.xx.xx:80` on of the nodes in the cluster then I'm receiving a response from the nginx ingress controller. But not when doing it outside of the node.",
      "solution": "Answering the question:\n\nHow can I create a setup with Kubernetes cluster and separate firewall to allow users to connect to my `Nginx Ingress` controller which is exposing my application.\n\nAssuming the setup is basing on Kubernetes cluster provisioned in the internal network and there is a firewall between the cluster and the \"Internet\", following points should be addressed (there could be some derivatives which I will address):\n\n`Metallb` provisioned on Kubernetes cluster (assuming it's a bare metal self-managed solution)\n`Nginx Ingress` controller with modified `Service`\n`Port-forwarding` set on the firewall\n\n`Service` of type `Loadbalancer` in the most part (there are some exclusions) is a resource that requires a cloud provider to assign an `External IP` address for your `Service`.\n\nA side note!\nMore reference can be found here:\n\nKubernetes.io: Docs: Tasks: Access application cluster: Create external load balancer\n\nFor solutions that are on premise based, there is a tool called `metallb`:\n\nKubernetes does not offer an implementation of network load-balancers (Services of type LoadBalancer) for bare metal clusters. The implementations of Network LB that Kubernetes does ship with are all glue code that calls out to various IaaS platforms (GCP, AWS, Azure\u2026). If you\u2019re not running on a supported IaaS platform (GCP, AWS, Azure\u2026), LoadBalancers will remain in the \u201cpending\u201d state indefinitely when created.\nBare metal cluster operators are left with two lesser tools to bring user traffic into their clusters, \u201cNodePort\u201d and \u201cexternalIPs\u201d services. Both of these options have significant downsides for production use, which makes bare metal clusters second class citizens in the Kubernetes ecosystem.\nMetalLB aims to redress this imbalance by offering a Network LB implementation that integrates with standard network equipment, so that external services on bare metal clusters also \u201cjust work\u201d as much as possible.\nMetallb.universe.tf\n\nFollowing the guide on the installation/configuration of metallb, there will be a configuration for a single internal IP address that the firewall will send the traffic to:\n`apiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: single-ip # \nThis IP address will be associated with the `Service` of type `LoadBalancer` of `Nginx Ingress` controller.\n\nThe changes required with the `Nginx Ingress` manifest (`Service` part):\n\nRaw.githubusercontent.com: Kubernetes: Ingress nginx: Controller: ... : deploy.yaml\n\n```\n`# Source: ingress-nginx/templates/controller-service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    metallb.universe.tf/address-pool: single-ip #  \n  name: ingress-nginx-controller\n  namespace: ingress-nginx\nspec:\n  type: LoadBalancer\n  externalTrafficPolicy: Local\n  ports:\n    - name: http\n      port: 80\n      protocol: TCP\n      targetPort: http\n    - name: https\n      port: 443\n      protocol: TCP\n      targetPort: https\n  selector:\n    #  \n`\n```\nAbove changes in the `YAML` manifest will ensure that the address that was configured in a `metallb` `ConfigMap` will be used with the `Service`.\n\nA side note!\nYou can omit the `metallb` and use the `Service` of type `Nodeport` but this carries some disadvantages.\n\nThe last part is to set the port-forwarding on the firewall. The rule should be following:\n\n`FIREWALL_IP:80` -> `SINGLE_IP:80`\n`FIREWALL_IP:443` -> `SINGLE_IP:443`\n\nAfter that you should be able to communicate with your `Nginx Ingress` controller by:\n\n`$ curl FIREWALL_IP:80`\n\nAdditional resources:\n\nKubernetes.io: Docs: Concepts: Services networking: Service",
      "question_score": 6,
      "answer_score": 15,
      "created_at": "2021-02-16T12:31:15",
      "url": "https://stackoverflow.com/questions/66223566/adding-public-ip-to-nginx-ingress-controller-with-metallb"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 67194692,
      "title": "Problem with minikube and nginx ingress when reinstalled minikube",
      "problem": "When I'm running following code:\n`minikube addons enable ingress\n`\nI'm getting following error:\n`\u25aa Using image k8s.gcr.io/ingress-nginx/controller:v0.44.0\n    \u25aa Using image docker.io/jettech/kube-webhook-certgen:v1.5.1\n    \u25aa Using image docker.io/jettech/kube-webhook-certgen:v1.5.1\n\ud83d\udd0e  Verifying ingress addon...\n\n\u274c  Exiting due to MK_ENABLE: run callbacks: running callbacks: [sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.20.2/kubectl apply -f /etc/kubernetes/addons/ingress-configmap.yaml -f /etc/kubernetes/addons/ingress-rbac.yaml -f /etc/kubernetes/addons/ingress-dp.yaml: Process exited with status 1\nstdout:\nnamespace/ingress-nginx unchanged\nconfigmap/ingress-nginx-controller unchanged\nconfigmap/tcp-services unchanged\nconfigmap/udp-services unchanged\nserviceaccount/ingress-nginx unchanged\nclusterrole.rbac.authorization.k8s.io/ingress-nginx unchanged\nclusterrolebinding.rbac.authorization.k8s.io/ingress-nginx unchanged\nrole.rbac.authorization.k8s.io/ingress-nginx unchanged\nrolebinding.rbac.authorization.k8s.io/ingress-nginx unchanged\nserviceaccount/ingress-nginx-admission unchanged\nclusterrole.rbac.authorization.k8s.io/ingress-nginx-admission unchanged\nclusterrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission unchanged\nrole.rbac.authorization.k8s.io/ingress-nginx-admission unchanged\nrolebinding.rbac.authorization.k8s.io/ingress-nginx-admission unchanged\nservice/ingress-nginx-controller-admission unchanged\nservice/ingress-nginx-controller unchanged\nvalidatingwebhookconfiguration.admissionregistration.k8s.io/ingress-nginx-admission configured\n\nstderr:\nError from server (Invalid): error when applying patch:\n{\"metadata\":{\"annotations\":{\"kubectl.kubernetes.io/last-applied-configuration\":\"{\\\"apiVersion\\\":\\\"apps/v1\\\",\\\"kind\\\":\\\"Deployment\\\",\\\"metadata\\\":{\\\"annotations\\\":{},\\\"labels\\\":{\\\"addonmanager.kubernetes.io/mode\\\":\\\"Reconcile\\\",\\\"app.kubernetes.io/component\\\":\\\"controller\\\",\\\"app.kubernetes.io/instance\\\":\\\"ingress-nginx\\\",\\\"app.kubernetes.io/name\\\":\\\"ingress-nginx\\\"},\\\"name\\\":\\\"ingress-nginx-controller\\\",\\\"namespace\\\":\\\"ingress-nginx\\\"},\\\"spec\\\":{\\\"minReadySeconds\\\":0,\\\"revisionHistoryLimit\\\":10,\\\"selector\\\":{\\\"matchLabels\\\":{\\\"addonmanager.kubernetes.io/mode\\\":\\\"Reconcile\\\",\\\"app.kubernetes.io/component\\\":\\\"controller\\\",\\\"app.kubernetes.io/instance\\\":\\\"ingress-nginx\\\",\\\"app.kubernetes.io/name\\\":\\\"ingress-nginx\\\"}},\\\"strategy\\\":{\\\"rollingUpdate\\\":{\\\"maxUnavailable\\\":1},\\\"type\\\":\\\"RollingUpdate\\\"},\\\"template\\\":{\\\"metadata\\\":{\\\"labels\\\":{\\\"addonmanager.kubernetes.io/mode\\\":\\\"Reconcile\\\",\\\"app.kubernetes.io/component\\\":\\\"controller\\\",\\\"app.kubernetes.io/instance\\\":\\\"ingress-nginx\\\",\\\"app.kubernetes.io/name\\\":\\\"ingress-nginx\\\",\\\"gcp-auth-skip-secret\\\":\\\"true\\\"}},\\\"spec\\\":{\\\"containers\\\":[{\\\"args\\\":[\\\"/nginx-ingress-controller\\\",\\\"--ingress-class=nginx\\\",\\\"--configmap=$(POD_NAMESPACE)/ingress-nginx-controller\\\",\\\"--report-node-internal-ip-address\\\",\\\"--tcp-services-configmap=$(POD_NAMESPACE)/tcp-services\\\",\\\"--udp-services-configmap=$(POD_NAMESPACE)/udp-services\\\",\\\"--validating-webhook=:8443\\\",\\\"--validating-webhook-certificate=/usr/local/certificates/cert\\\",\\\"--validating-webhook-key=/usr/local/certificates/key\\\"],\\\"env\\\":[{\\\"name\\\":\\\"POD_NAME\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.name\\\"}}},{\\\"name\\\":\\\"POD_NAMESPACE\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.namespace\\\"}}},{\\\"name\\\":\\\"LD_PRELOAD\\\",\\\"value\\\":\\\"/usr/local/lib/libmimalloc.so\\\"}],\\\"image\\\":\\\"k8s.gcr.io/ingress-nginx/controller:v0.44.0@sha256:3dd0fac48073beaca2d67a78c746c7593f9c575168a17139a9955a82c63c4b9a\\\",\\\"imagePullPolicy\\\":\\\"IfNotPresent\\\",\\\"lifecycle\\\":{\\\"preStop\\\":{\\\"exec\\\":{\\\"command\\\":[\\\"/wait-shutdown\\\"]}}},\\\"livenessProbe\\\":{\\\"failureThreshold\\\":5,\\\"httpGet\\\":{\\\"path\\\":\\\"/healthz\\\",\\\"port\\\":10254,\\\"scheme\\\":\\\"HTTP\\\"},\\\"initialDelaySeconds\\\":10,\\\"periodSeconds\\\":10,\\\"successThreshold\\\":1,\\\"timeoutSeconds\\\":1},\\\"name\\\":\\\"controller\\\",\\\"ports\\\":[{\\\"containerPort\\\":80,\\\"hostPort\\\":80,\\\"name\\\":\\\"http\\\",\\\"protocol\\\":\\\"TCP\\\"},{\\\"containerPort\\\":443,\\\"hostPort\\\":443,\\\"name\\\":\\\"https\\\",\\\"protocol\\\":\\\"TCP\\\"},{\\\"containerPort\\\":8443,\\\"name\\\":\\\"webhook\\\",\\\"protocol\\\":\\\"TCP\\\"}],\\\"readinessProbe\\\":{\\\"failureThreshold\\\":3,\\\"httpGet\\\":{\\\"path\\\":\\\"/healthz\\\",\\\"port\\\":10254,\\\"scheme\\\":\\\"HTTP\\\"},\\\"initialDelaySeconds\\\":10,\\\"periodSeconds\\\":10,\\\"successThreshold\\\":1,\\\"timeoutSeconds\\\":1},\\\"resources\\\":{\\\"requests\\\":{\\\"cpu\\\":\\\"100m\\\",\\\"memory\\\":\\\"90Mi\\\"}},\\\"securityContext\\\":{\\\"allowPrivilegeEscalation\\\":true,\\\"capabilities\\\":{\\\"add\\\":[\\\"NET_BIND_SERVICE\\\"],\\\"drop\\\":[\\\"ALL\\\"]},\\\"runAsUser\\\":101},\\\"volumeMounts\\\":[{\\\"mountPath\\\":\\\"/usr/local/certificates/\\\",\\\"name\\\":\\\"webhook-cert\\\",\\\"readOnly\\\":true}]}],\\\"dnsPolicy\\\":\\\"ClusterFirst\\\",\\\"serviceAccountName\\\":\\\"ingress-nginx\\\",\\\"volumes\\\":[{\\\"name\\\":\\\"webhook-cert\\\",\\\"secret\\\":{\\\"secretName\\\":\\\"ingress-nginx-admission\\\"}}]}}}}\\n\"},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"app.kubernetes.io/managed-by\":null,\"app.kubernetes.io/version\":null,\"helm.sh/chart\":null}},\"spec\":{\"minReadySeconds\":0,\"selector\":{\"matchLabels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\"}},\"strategy\":{\"$retainKeys\":[\"rollingUpdate\",\"type\"],\"rollingUpdate\":{\"maxUnavailable\":1}},\"template\":{\"metadata\":{\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"gcp-auth-skip-secret\":\"true\"}},\"spec\":{\"$setElementOrder/containers\":[{\"name\":\"controller\"}],\"containers\":[{\"$setElementOrder/ports\":[{\"containerPort\":80},{\"containerPort\":443},{\"containerPort\":8443}],\"args\":[\"/nginx-ingress-controller\",\"--ingress-class=nginx\",\"--configmap=$(POD_NAMESPACE)/ingress-nginx-controller\",\"--report-node-internal-ip-address\",\"--tcp-services-configmap=$(POD_NAMESPACE)/tcp-services\",\"--udp-services-configmap=$(POD_NAMESPACE)/udp-services\",\"--validating-webhook=:8443\",\"--validating-webhook-certificate=/usr/local/certificates/cert\",\"--validating-webhook-key=/usr/local/certificates/key\"],\"image\":\"k8s.gcr.io/ingress-nginx/controller:v0.44.0@sha256:3dd0fac48073beaca2d67a78c746c7593f9c575168a17139a9955a82c63c4b9a\",\"name\":\"controller\",\"ports\":[{\"containerPort\":80,\"hostPort\":80},{\"containerPort\":443,\"hostPort\":443}]}],\"nodeSelector\":null,\"terminationGracePeriodSeconds\":null}}}}\nto:\nResource: \"apps/v1, Resource=deployments\", GroupVersionKind: \"apps/v1, Kind=Deployment\"\nName: \"ingress-nginx-controller\", Namespace: \"ingress-nginx\"\nfor: \"/etc/kubernetes/addons/ingress-dp.yaml\": Deployment.apps \"ingress-nginx-controller\" is invalid: spec.selector: Invalid value: v1.LabelSelector{MatchLabels:map[string]string{\"addonmanager.kubernetes.io/mode\":\"Reconcile\", \"app.kubernetes.io/component\":\"controller\", \"app.kubernetes.io/instance\":\"ingress-nginx\", \"app.kubernetes.io/name\":\"ingress-nginx\"}, MatchExpressions:[]v1.LabelSelectorRequirement(nil)}: field is immutable\nError from server (Invalid): error when applying patch:\n{\"metadata\":{\"annotations\":{\"helm.sh/hook\":null,\"helm.sh/hook-delete-policy\":null,\"kubectl.kubernetes.io/last-applied-configuration\":\"{\\\"apiVersion\\\":\\\"batch/v1\\\",\\\"kind\\\":\\\"Job\\\",\\\"metadata\\\":{\\\"annotations\\\":{},\\\"labels\\\":{\\\"addonmanager.kubernetes.io/mode\\\":\\\"Reconcile\\\",\\\"app.kubernetes.io/component\\\":\\\"admission-webhook\\\",\\\"app.kubernetes.io/instance\\\":\\\"ingress-nginx\\\",\\\"app.kubernetes.io/name\\\":\\\"ingress-nginx\\\"},\\\"name\\\":\\\"ingress-nginx-admission-create\\\",\\\"namespace\\\":\\\"ingress-nginx\\\"},\\\"spec\\\":{\\\"template\\\":{\\\"metadata\\\":{\\\"labels\\\":{\\\"addonmanager.kubernetes.io/mode\\\":\\\"Reconcile\\\",\\\"app.kubernetes.io/component\\\":\\\"admission-webhook\\\",\\\"app.kubernetes.io/instance\\\":\\\"ingress-nginx\\\",\\\"app.kubernetes.io/name\\\":\\\"ingress-nginx\\\"},\\\"name\\\":\\\"ingress-nginx-admission-create\\\"},\\\"spec\\\":{\\\"containers\\\":[{\\\"args\\\":[\\\"create\\\",\\\"--host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc\\\",\\\"--namespace=$(POD_NAMESPACE)\\\",\\\"--secret-name=ingress-nginx-admission\\\"],\\\"env\\\":[{\\\"name\\\":\\\"POD_NAMESPACE\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.namespace\\\"}}}],\\\"image\\\":\\\"docker.io/jettech/kube-webhook-certgen:v1.5.1@sha256:950833e19ade18cd389d647efb88992a7cc077abedef343fa59e012d376d79b7\\\",\\\"imagePullPolicy\\\":\\\"IfNotPresent\\\",\\\"name\\\":\\\"create\\\"}],\\\"restartPolicy\\\":\\\"OnFailure\\\",\\\"securityContext\\\":{\\\"runAsNonRoot\\\":true,\\\"runAsUser\\\":2000},\\\"serviceAccountName\\\":\\\"ingress-nginx-admission\\\"}}}}\\n\"},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"app.kubernetes.io/managed-by\":null,\"app.kubernetes.io/version\":null,\"helm.sh/chart\":null}},\"spec\":{\"template\":{\"metadata\":{\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"app.kubernetes.io/managed-by\":null,\"app.kubernetes.io/version\":null,\"helm.sh/chart\":null}},\"spec\":{\"$setElementOrder/containers\":[{\"name\":\"create\"}],\"containers\":[{\"image\":\"docker.io/jettech/kube-webhook-certgen:v1.5.1@sha256:950833e19ade18cd389d647efb88992a7cc077abedef343fa59e012d376d79b7\",\"name\":\"create\"}]}}}}\nto:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"ingress-nginx-admission-create\", Namespace: \"ingress-nginx\"\nfor: \"/etc/kubernetes/addons/ingress-dp.yaml\": Job.batch \"ingress-nginx-admission-create\" is invalid: spec.template: Invalid value: core.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:\"ingress-nginx-admission-create\", GenerateName:\"\", Namespace:\"\", SelfLink:\"\", UID:\"\", ResourceVersion:\"\", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{\"addonmanager.kubernetes.io/mode\":\"Reconcile\", \"app.kubernetes.io/component\":\"admission-webhook\", \"app.kubernetes.io/instance\":\"ingress-nginx\", \"app.kubernetes.io/name\":\"ingress-nginx\", \"controller-uid\":\"d33a74a3-101c-4e82-a2b7-45b46068f189\", \"job-name\":\"ingress-nginx-admission-create\"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:\"\", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:core.PodSpec{Volumes:[]core.Volume(nil), InitContainers:[]core.Container(nil), Containers:[]core.Container{core.Container{Name:\"create\", Image:\"docker.io/jettech/kube-webhook-certgen:v1.5.1@sha256:950833e19ade18cd389d647efb88992a7cc077abedef343fa59e012d376d79b7\", Command:[]string(nil), Args:[]string{\"create\", \"--host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc\", \"--namespace=$(POD_NAMESPACE)\", \"--secret-name=ingress-nginx-admission\"}, WorkingDir:\"\", Ports:[]core.ContainerPort(nil), EnvFrom:[]core.EnvFromSource(nil), Env:[]core.EnvVar{core.EnvVar{Name:\"POD_NAMESPACE\", Value:\"\", ValueFrom:(*core.EnvVarSource)(0xc00a79dea0)}}, Resources:core.ResourceRequirements{Limits:core.ResourceList(nil), Requests:core.ResourceList(nil)}, VolumeMounts:[]core.VolumeMount(nil), VolumeDevices:[]core.VolumeDevice(nil), LivenessProbe:(*core.Probe)(nil), ReadinessProbe:(*core.Probe)(nil), StartupProbe:(*core.Probe)(nil), Lifecycle:(*core.Lifecycle)(nil), TerminationMessagePath:\"/dev/termination-log\", TerminationMessagePolicy:\"File\", ImagePullPolicy:\"IfNotPresent\", SecurityContext:(*core.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]core.EphemeralContainer(nil), RestartPolicy:\"OnFailure\", TerminationGracePeriodSeconds:(*int64)(0xc003184dc0), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:\"ClusterFirst\", NodeSelector:map[string]string(nil), ServiceAccountName:\"ingress-nginx-admission\", AutomountServiceAccountToken:(*bool)(nil), NodeName:\"\", SecurityContext:(*core.PodSecurityContext)(0xc010b3d980), ImagePullSecrets:[]core.LocalObjectReference(nil), Hostname:\"\", Subdomain:\"\", SetHostnameAsFQDN:(*bool)(nil), Affinity:(*core.Affinity)(nil), SchedulerName:\"default-scheduler\", Tolerations:[]core.Toleration(nil), HostAliases:[]core.HostAlias(nil), PriorityClassName:\"\", Priority:(*int32)(nil), PreemptionPolicy:(*core.PreemptionPolicy)(nil), DNSConfig:(*core.PodDNSConfig)(nil), ReadinessGates:[]core.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), Overhead:core.ResourceList(nil), EnableServiceLinks:(*bool)(nil), TopologySpreadConstraints:[]core.TopologySpreadConstraint(nil)}}: field is immutable\nError from server (Invalid): error when applying patch:\n{\"metadata\":{\"annotations\":{\"helm.sh/hook\":null,\"helm.sh/hook-delete-policy\":null,\"kubectl.kubernetes.io/last-applied-configuration\":\"{\\\"apiVersion\\\":\\\"batch/v1\\\",\\\"kind\\\":\\\"Job\\\",\\\"metadata\\\":{\\\"annotations\\\":{},\\\"labels\\\":{\\\"addonmanager.kubernetes.io/mode\\\":\\\"Reconcile\\\",\\\"app.kubernetes.io/component\\\":\\\"admission-webhook\\\",\\\"app.kubernetes.io/instance\\\":\\\"ingress-nginx\\\",\\\"app.kubernetes.io/name\\\":\\\"ingress-nginx\\\"},\\\"name\\\":\\\"ingress-nginx-admission-patch\\\",\\\"namespace\\\":\\\"ingress-nginx\\\"},\\\"spec\\\":{\\\"template\\\":{\\\"metadata\\\":{\\\"labels\\\":{\\\"addonmanager.kubernetes.io/mode\\\":\\\"Reconcile\\\",\\\"app.kubernetes.io/component\\\":\\\"admission-webhook\\\",\\\"app.kubernetes.io/instance\\\":\\\"ingress-nginx\\\",\\\"app.kubernetes.io/name\\\":\\\"ingress-nginx\\\"},\\\"name\\\":\\\"ingress-nginx-admission-patch\\\"},\\\"spec\\\":{\\\"containers\\\":[{\\\"args\\\":[\\\"patch\\\",\\\"--webhook-name=ingress-nginx-admission\\\",\\\"--namespace=$(POD_NAMESPACE)\\\",\\\"--patch-mutating=false\\\",\\\"--secret-name=ingress-nginx-admission\\\",\\\"--patch-failure-policy=Fail\\\"],\\\"env\\\":[{\\\"name\\\":\\\"POD_NAMESPACE\\\",\\\"valueFrom\\\":{\\\"fieldRef\\\":{\\\"fieldPath\\\":\\\"metadata.namespace\\\"}}}],\\\"image\\\":\\\"docker.io/jettech/kube-webhook-certgen:v1.5.1@sha256:950833e19ade18cd389d647efb88992a7cc077abedef343fa59e012d376d79b7\\\",\\\"imagePullPolicy\\\":\\\"IfNotPresent\\\",\\\"name\\\":\\\"patch\\\"}],\\\"restartPolicy\\\":\\\"OnFailure\\\",\\\"securityContext\\\":{\\\"runAsNonRoot\\\":true,\\\"runAsUser\\\":2000},\\\"serviceAccountName\\\":\\\"ingress-nginx-admission\\\"}}}}\\n\"},\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"app.kubernetes.io/managed-by\":null,\"app.kubernetes.io/version\":null,\"helm.sh/chart\":null}},\"spec\":{\"template\":{\"metadata\":{\"labels\":{\"addonmanager.kubernetes.io/mode\":\"Reconcile\",\"app.kubernetes.io/managed-by\":null,\"app.kubernetes.io/version\":null,\"helm.sh/chart\":null}},\"spec\":{\"$setElementOrder/containers\":[{\"name\":\"patch\"}],\"containers\":[{\"image\":\"docker.io/jettech/kube-webhook-certgen:v1.5.1@sha256:950833e19ade18cd389d647efb88992a7cc077abedef343fa59e012d376d79b7\",\"name\":\"patch\"}]}}}}\nto:\nResource: \"batch/v1, Resource=jobs\", GroupVersionKind: \"batch/v1, Kind=Job\"\nName: \"ingress-nginx-admission-patch\", Namespace: \"ingress-nginx\"\nfor: \"/etc/kubernetes/addons/ingress-dp.yaml\": Job.batch \"ingress-nginx-admission-patch\" is invalid: spec.template: Invalid value: core.PodTemplateSpec{ObjectMeta:v1.ObjectMeta{Name:\"ingress-nginx-admission-patch\", GenerateName:\"\", Namespace:\"\", SelfLink:\"\", UID:\"\", ResourceVersion:\"\", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{\"addonmanager.kubernetes.io/mode\":\"Reconcile\", \"app.kubernetes.io/component\":\"admission-webhook\", \"app.kubernetes.io/instance\":\"ingress-nginx\", \"app.kubernetes.io/name\":\"ingress-nginx\", \"controller-uid\":\"ef303f40-b52d-49c5-ab80-8330379fed36\", \"job-name\":\"ingress-nginx-admission-patch\"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:\"\", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:core.PodSpec{Volumes:[]core.Volume(nil), InitContainers:[]core.Container(nil), Containers:[]core.Container{core.Container{Name:\"patch\", Image:\"docker.io/jettech/kube-webhook-certgen:v1.5.1@sha256:950833e19ade18cd389d647efb88992a7cc077abedef343fa59e012d376d79b7\", Command:[]string(nil), Args:[]string{\"patch\", \"--webhook-name=ingress-nginx-admission\", \"--namespace=$(POD_NAMESPACE)\", \"--patch-mutating=false\", \"--secret-name=ingress-nginx-admission\", \"--patch-failure-policy=Fail\"}, WorkingDir:\"\", Ports:[]core.ContainerPort(nil), EnvFrom:[]core.EnvFromSource(nil), Env:[]core.EnvVar{core.EnvVar{Name:\"POD_NAMESPACE\", Value:\"\", ValueFrom:(*core.EnvVarSource)(0xc00fd798a0)}}, Resources:core.ResourceRequirements{Limits:core.ResourceList(nil), Requests:core.ResourceList(nil)}, VolumeMounts:[]core.VolumeMount(nil), VolumeDevices:[]core.VolumeDevice(nil), LivenessProbe:(*core.Probe)(nil), ReadinessProbe:(*core.Probe)(nil), StartupProbe:(*core.Probe)(nil), Lifecycle:(*core.Lifecycle)(nil), TerminationMessagePath:\"/dev/termination-log\", TerminationMessagePolicy:\"File\", ImagePullPolicy:\"IfNotPresent\", SecurityContext:(*core.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]core.EphemeralContainer(nil), RestartPolicy:\"OnFailure\", TerminationGracePeriodSeconds:(*int64)(0xc00573d190), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:\"ClusterFirst\", NodeSelector:map[string]string(nil), ServiceAccountName:\"ingress-nginx-admission\", AutomountServiceAccountToken:(*bool)(nil), NodeName:\"\", SecurityContext:(*core.PodSecurityContext)(0xc00d7d9100), ImagePullSecrets:[]core.LocalObjectReference(nil), Hostname:\"\", Subdomain:\"\", SetHostnameAsFQDN:(*bool)(nil), Affinity:(*core.Affinity)(nil), SchedulerName:\"default-scheduler\", Tolerations:[]core.Toleration(nil), HostAliases:[]core.HostAlias(nil), PriorityClassName:\"\", Priority:(*int32)(nil), PreemptionPolicy:(*core.PreemptionPolicy)(nil), DNSConfig:(*core.PodDNSConfig)(nil), ReadinessGates:[]core.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), Overhead:core.ResourceList(nil), EnableServiceLinks:(*bool)(nil), TopologySpreadConstraints:[]core.TopologySpreadConstraint(nil)}}: field is immutable\n]\n\n\ud83d\ude3f  If the above advice does not help, please let us know: \n\ud83d\udc49  https://github.com/kubernetes/minikube/issues/new/choose\n`\nSo I had some bug issue in my PC. So, i reinstall minikube. After this when I use `minikube start` and all want fine. But when i enable ingress then the above error was showing.\nAnd when i run `skaffold dev` the following error was showing:\n`Warning: extensions/v1beta1 Ingress is deprecated in v1.14+, unavailable in v1.22+; use networking.k8s.io/v1 Ingress\n - Error from server (InternalError): error when creating \"STDIN\": Internal error occurred: failed calling webhook \"validate.nginx.ingress.kubernetes.io\": an error on the server (\"\") has prevented the request from succeeding\nexiting dev mode because first deploy failed: kubectl apply: exit status 1\n\n`",
      "solution": "As @Brian de Alwis pointed out in the comments section, this PR #11189 should resolve the above issue.\nYou can try the v1.20.0-beta.0 release with this fix. Additionally, a stable v1.20.0 version is now available.",
      "question_score": 6,
      "answer_score": 2,
      "created_at": "2021-04-21T13:10:40",
      "url": "https://stackoverflow.com/questions/67194692/problem-with-minikube-and-nginx-ingress-when-reinstalled-minikube"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70899601,
      "title": "Helm3 template error calling include: template: no template &quot;microservice.labels&quot; associated with template &quot;gotpl&quot;",
      "problem": "I have helm 3 template created using `helm create microservice` command. it has below files.\n```\n`/Chart.yaml\n./values.yaml\n./.helmignore\n./templates/ingress.yaml\n./templates/deployment.yaml\n./templates/service.yaml\n./templates/serviceaccount.yaml\n./templates/hpa.yaml\n./templates/NOTES.txt\n./templates/_helpers.tpl\n./templates/tests/test-connection.yaml\n`\n```\nUpdated values file based on my application, when I try to install the helm chat its giving below error message.\n```\n`Error: UPGRADE FAILED: template: microservice/templates/ingress.yaml:20:8: executing \"microservice/templates/ingress.yaml\" at : error calling include: template: no template \"microservice.labels\" associated with template \"gotpl\"\nhelm.go:75: [debug] template: microservice/templates/ingress.yaml:20:8: executing \"microservice/templates/ingress.yaml\" at : error calling include: template: no template \"microservice.labels\" associated with template \"gotpl\"\n`\n```\nHere is the `ingress.yaml` file.\n```\n`{{- if .Values.ingress.enabled -}}\n{{- $fullName := include \"microservice.fullname\" . -}}\n{{- $svcPort := .Values.service.port -}}\n{{- if and .Values.ingress.className (not (semverCompare \">=1.18-0\" .Capabilities.KubeVersion.GitVersion)) }}\n  {{- if not (hasKey .Values.ingress.annotations \"kubernetes.io/ingress.class\") }}\n  {{- $_ := set .Values.ingress.annotations \"kubernetes.io/ingress.class\" .Values.ingress.className}}\n  {{- end }}\n{{- end }}\n{{- if semverCompare \">=1.19-0\" .Capabilities.KubeVersion.GitVersion -}}\napiVersion: networking.k8s.io/v1\n{{- else if semverCompare \">=1.14-0\" .Capabilities.KubeVersion.GitVersion -}}\napiVersion: networking.k8s.io/v1beta1\n{{- else -}}\napiVersion: extensions/v1beta1\n{{- end }}\nkind: Ingress\nmetadata:\n  name: {{ $fullName }}\n  labels:\n    {{- include \"microservice.labels\" . | nindent 4 }}\n  {{- with .Values.ingress.annotations }}\n  annotations:\n    {{- toYaml . | nindent 4 }}\n  {{- end }}\nspec:\n  {{- if and .Values.ingress.className (semverCompare \">=1.18-0\" .Capabilities.KubeVersion.GitVersion) }}\n  ingressClassName: {{ .Values.ingress.className }}\n  {{- end }}\n  {{- if .Values.ingress.tls }}\n  tls:\n    {{- range .Values.ingress.tls }}\n    - hosts:\n        {{- range .hosts }}\n        - {{ . | quote }}\n        {{- end }}\n      secretName: {{ .secretName }}\n    {{- end }}\n  {{- end }}\n  rules:\n    {{- range .Values.ingress.hosts }}\n    - host: {{ .host | quote }}\n      http:\n        paths:\n          {{- range .paths }}\n          - path: {{ .path }}\n            {{- if and .pathType (semverCompare \">=1.18-0\" $.Capabilities.KubeVersion.GitVersion) }}\n            pathType: {{ .pathType }}\n            {{- end }}\n            backend:\n              {{- if semverCompare \">=1.19-0\" $.Capabilities.KubeVersion.GitVersion }}\n              service:\n                name: {{ $fullName }}\n                port:\n                  number: {{ $svcPort }}\n              {{- else }}\n              serviceName: {{ $fullName }}\n              servicePort: {{ $svcPort }}\n              {{- end }}\n          {{- end }}\n    {{- end }}\n{{- end }}\n`\n```\nHow to I added `microservice.labels` template?. Do I need to create `microservice.labels.tlp` file?\nAny tips to fix this error.\nThanks\nSR",
      "solution": "I copied the `ingress.yaml` file to, chart created older version helm. this value was missing in `_helpers.tpl` file. Now I copied new version of hellpers.tpl file. deployment works now.",
      "question_score": 5,
      "answer_score": 12,
      "created_at": "2022-01-28T20:58:14",
      "url": "https://stackoverflow.com/questions/70899601/helm3-template-error-calling-include-template-no-template-microservice-labels"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66579259,
      "title": "Error: file &#39;home/user/values.yaml&#39; seems to be a YAML file, but expected a gzipped archive",
      "problem": "I am trying to install Kube Prometheus Stack using helm.\nI have already setup ingress, so it needs to be running behind a proxy.\nFor that I have updated values of the chart by using below command.\n```\n`helm show values prometheus-com/kube-prometheus-stack > values.yaml\n\n`\n```\nI followed this doc and changed configurations,\n```\n`[server]\ndomain = example.com\n`\n```\nNow I am trying to install using below command.\n```\n`helm install monitoring ./values.yaml  -n monitoring\n`\n```\nI have already created a namespace `monitoring`\nI get below error on running above command.\n```\n`Error: file '/home/user/values.yaml' seems to be a YAML file, but expected a gzipped archive\n`\n```",
      "solution": "Your helm command should be something like this:\n```\n`$ helm install  / --values ./values.yaml  -n monitoring\n\n`\n```",
      "question_score": 5,
      "answer_score": 4,
      "created_at": "2021-03-11T10:00:09",
      "url": "https://stackoverflow.com/questions/66579259/error-file-home-user-values-yaml-seems-to-be-a-yaml-file-but-expected-a-gzip"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69888157,
      "title": "How to expose a service to outside Kubernetes cluster via ingress?",
      "problem": "I'm struggling to expose a service in an AWS cluster to outside and access it via a browser. Since my previous question haven't drawn any answers, I decided to simplify the issue in several aspects.\nFirst, I've created a deployment which should work without any configuration. Based on this article, I did\n\n`kubectl create namespace tests`\n\ncreated file `probe-service.yaml` based on `paulbouwer/hello-kubernetes:1.8` and deployed it `kubectl create -f probe-service.yaml -n tests`:\n```\n`apiVersion: v1\nkind: Service\nmetadata:\n  name: hello-kubernetes-first\nspec:\n  type: ClusterIP\n  ports:\n  - port: 80\n    targetPort: 8080\n  selector:\n    app: hello-kubernetes-first\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-kubernetes-first\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: hello-kubernetes-first\n  template:\n    metadata:\n      labels:\n        app: hello-kubernetes-first\n    spec:\n      containers:\n      - name: hello-kubernetes\n        image: paulbouwer/hello-kubernetes:1.8\n        ports:\n        - containerPort: 8080\n        env:\n        - name: MESSAGE\n          value: Hello from the first deployment!\n`\n```\n\ncreated `ingress.yaml` and applied it (`kubectl apply -f .\\probes\\ingress.yaml -n tests`)\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: hello-kubernetes-ingress\nspec:\n  rules:\n  - host: test.projectname.org\n    http:\n      paths:\n      - pathType: Prefix\n        path: \"/test\"\n        backend:\n          service:\n            name: hello-kubernetes-first\n            port:\n              number: 80\n  - host: test2.projectname.org\n    http:\n      paths:\n      - pathType: Prefix\n        path: \"/test2\"\n        backend:\n          service:\n            name: hello-kubernetes-first\n            port:\n              number: 80\n  ingressClassName: nginx\n`\n```\n\nSecond, I can see that DNS actually point to the cluster and ingress rules are applied:\n\nif I open `http://test.projectname.org/test` or any irrelevant path (`http://test.projectname.org/test3`), I'm shown `NET::ERR_CERT_AUTHORITY_INVALID`, but\nif I use \"open anyway\" in browser, irrelevant paths give `ERR_TOO_MANY_REDIRECTS` while `http://test.projectname.org/test` gives `Cannot GET /test`\n\nNow, TLS issues aside (those deserve a separate question), why can I get `Cannot GET /test`? It looks like ingress controller (ingress-nginx) got the rules (otherwise it wouldn't descriminate paths; that's why I don't show DNS settings, although they are described in the previous question) but instead of showing the simple hello-kubernetes page at `/test` it returns this simple 404 message. Why is that? What could possibly go wrong? How to debug this?\nSome debug info:\n\n`kubectl version --short` tells Kubernetes Client Version is v1.21.5 and Server Version is v1.20.7-eks-d88609\n\n`kubectl get ingress -n tests` shows that `hello-kubernetes-ingress` exists indeed, with `nginx` class, 2 expected hosts, address equal to that shown for load balancer in AWS console\n\n`kubectl get all -n tests` shows\n```\n`NAME                                          READY   STATUS    RESTARTS   AGE\npod/hello-kubernetes-first-6f77d8ff99-gjw5d   1/1     Running   0          5h4m\npod/hello-kubernetes-first-6f77d8ff99-ptwsn   1/1     Running   0          5h4m\npod/hello-kubernetes-first-6f77d8ff99-x8w87   1/1     Running   0          5h4m\n\nNAME                             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE\nservice/hello-kubernetes-first   ClusterIP   10.100.18.189           80/TCP    5h4m\n\nNAME                                     READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/hello-kubernetes-first   3/3     3            3           5h4m\n\nNAME                                                DESIRED   CURRENT   READY   AGE\nreplicaset.apps/hello-kubernetes-first-6f77d8ff99   3         3         3       5h4m\n`\n```\n\n`ingress-nginx` was installed before me via the following chart:\n```\n`apiVersion: v2\nname: nginx\ndescription: A Helm chart for Kubernetes\ntype: application\nversion: 4.0.6\nappVersion: \"1.0.4\"\ndependencies:\n- name: ingress-nginx\n  version: 4.0.6\n  repository: https://kubernetes.github.io/ingress-nginx\n`\n```\nand the values overwrites applied with the chart differ from the original ones mostly (well, those got updated since the installation) in `extraArgs`: `default-ssl-certificate: \"nginx-ingress/dragon-family-com\"` is uncommneted\n\nPS To answer Andrew, I indeed tried to setup HTTPS but it seemingly didn't help, so I haven't included what I tried into the initial question. Yet, here's what I did:\n\ninstalled cert-manager, currently without a custom chart: `kubectl apply -f https://github.com/jetstack/cert-manager/releases/download/v1.5.4/cert-manager.yaml`\n\nbased on cert-manager's tutorial and SO question created a ClusterIssuer with the following config:\n```\n`apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-backoffice\n\nspec:\n  acme:\n    server: https://acme-staging-v02.api.letsencrypt.org/directory\n    # use https://acme-v02.api.letsencrypt.org/directory after everything is fixed and works\n    privateKeySecretRef: # this secret will be created in the namespace of cert-manager\n      name: letsencrypt-backoffice-private-key\n    # email: \n\n    solvers:\n    # TODO: add for each domain/second-level domain/*.projectname.org\n    - selector:\n        dnsZones:\n          - test.projectname.org\n          - test2.projectname.org\n      # haven't made it to work yet, so switched to the simpler to configure http01 challenge\n      # dns01:\n      #   route53:\n      #     region: ... # that of load balancer (but we also have ...)\n      #     accessKeyID: \n      #     secretAccessKeySecretRef: # created that\n      #       name: route53-credentials-secret\n      #       key: secret-access-key\n      #     role: arn:aws:iam::645730347045:role/cert-manager\n      http01:\n        ingress:\n          class: nginx\n`\n```\nand applied it via `kubectl apply -f issuer.yaml`\n\ncreated 2 certificates in the same file and applied it again:\n```\n`---\napiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: letsencrypt-certificate\nspec:\n  secretName: tls-secret\n  issuerRef:\n    kind: ClusterIssuer\n    name: letsencrypt-backoffice\n  commonName: test.projectname.org\n  dnsNames:\n  - test.projectname.org\n---\napiVersion: cert-manager.io/v1\nkind: Certificate\nmetadata:\n  name: letsencrypt-certificate-2\nspec:\n  secretName: tls-secret-2\n  issuerRef:\n    kind: ClusterIssuer\n    name: letsencrypt-backoffice\n  commonName: test2.projectname.org\n  dnsNames:\n  - test2.projectname.org\n`\n```\n\nmade sure that the certificates are issued correctly (skipping the pain part, the result is: `kubectl get certificates` shows that both certificates have `READY` = `true` and both tls secrets are created)\n\nfigured that my ingress is in another namespace and secrets for tls in ingress spec can only be referred in the same namespace (haven't tried the wildcard certificate and `--default-ssl-certificate` option yet), so for each one copied them to `tests` namespace:\n\nopened existing secret, like `kubectl edit secret tls-secret-2`, copied data and annotations\ncreated an empty (Opaque) secret in tests: `kubectl create secret generic tls-secret-2-copy -n tests`\nopened it (`kubectl edit secret tls-secret-2-copy -n tests`) and inserted data an annotations\n\nin ingress `spec`, added the tls bit:\n```\n`tls:\n- hosts:\n  - test.projectname.org\n  secretName: tls-secret-copy\n- hosts:\n  - test2.projectname.org\n  secretName: tls-secret-2-copy\n`\n```\n\nI hoped that this will help, but actually it made no difference (I get `ERR_TOO_MANY_REDIRECTS` for irrelevant paths, redirect from http to https, `NET::ERR_CERT_AUTHORITY_INVALID` at https and `Cannot GET /test` if I insist on getting to the page)",
      "solution": "Well, I haven't figured this out for ArgoCD yet (edit: figured, but the solution is ArgoCD-specific), but for this test service it seems that path resolving is the source of the issue. It may be not the only source (to be retested on test2 subdomain), but when I created a new subdomain in the hosted zone (test3, not used anywhere before) and pointed it via `A` entry to the load balancer (as \"alias\" in AWS console), and then added to the ingress a new rule with `/` path, like this:\n```\n`  - host: test3.projectname.org\n    http:\n      paths:\n      - pathType: Prefix\n        path: \"/\"\n        backend:\n          service:\n            name: hello-kubernetes-first\n            port:\n              number: 80\n`\n```\nI've finally got the hello kubernetes thing on `http://test3.projectname.org`. I have succeeded with TLS after a number of attempts/research and some help in a separate question.\nBut I haven't succeeded with actual debugging: looking at `kubectl logs -n nginx ` doesn't really help understanding what path was passed to the service and is rather difficult to understand (can't even find where those IPs come from: they are not mine, LB's, cluster IP of the service; neither I understand what `tests-hello-kubernetes-first-80` stands for \u2013 it's just a concatenation of namespace, service name and port, no object has such name, including ingress):\n```\n`192.168.14.57 - - [14/Nov/2021:12:02:58 +0000] \"GET /test2 HTTP/2.0\" 404 144\n \"-\" \"\" 448 0.002\n [tests-hello-kubernetes-first-80] [] 192.168.49.95:8080 144 0.000 404 \n`\n```\nAny more pointers on debugging will be helpful; also suggestions regarding correct path ~rewriting for nginx-ingress are welcome.",
      "question_score": 5,
      "answer_score": 2,
      "created_at": "2021-11-08T19:18:55",
      "url": "https://stackoverflow.com/questions/69888157/how-to-expose-a-service-to-outside-kubernetes-cluster-via-ingress"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 68360097,
      "title": "How to change fronend URL in Keycloak behind NGINX ingress?",
      "problem": "There are many questions like this I can find in the internet but none of the solutions provided worked.\nI am using `jboss/keycloak:14.0.0` docker image. The following properties are set in my `ConfigMap`:\n```\n`KEYCLOAK_FRONTEND_URL: /mycontext/access-management\nPROXY_ADDRESS_FORWARDING: \"true\"\n\n`\n```\nPlease note that, change the `KEYCLOAK_FRONTEND_URL` to an absolute URL like this `https://mycompany.com/mycontext/access-managemen` makes no difference.\nNow the ingress has been defined as below:\n```\n`Path: /mycontext/access-management(/|$)(.*)\nRewrite To: /$2\nAnnotations:\n    ingress.kubernetes.io/ssl-redirect: \"False\"\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      proxy_set_header X-Request-ID $request_id;\n      proxy_set_header X-Trace-ID $request_id;\n      gzip off;\n    nginx.ingress.kubernetes.io/proxy-connect-timeout: \"180\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"180\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"180\"\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\n    nginx.ingress.kubernetes.io/server-snippet: |\n      add_header X-Request-ID $request_id;\n      add_header X-Trace-ID $request_id;\n    nginx.org/redirect-to-https: \"True\"\n\n`\n```\nWhat happens is very strange. See below it shows you where it takes me when I hit a URL:\n```\n`Go to [server]/mycontext/access-management =takes you to=> [server]/auth\nGo to [server]/mycontext/access-management/auth =takes you to=> [server]/mycontext/access-management/auth (works fine)\n\n`\n```\nAs you can see the second link works fine and you can see the Keycloak Welcome page with a number of links in it. One of the links is `Administration Console` that is broken. If you hover your mouse the link is `[server]/mycontext/access-management/admin` instead of `[server]/mycontext/access-management/auth/admin` (comparing it with my local Keycloak server). Now if we ignore the link and put the right path in the address bar as `[server]/mycontext/access-management/auth/admin` another strange thing happens and that changes the URL to `[server]/auth/mycontext/access-management/admin/master/console/`.\nI really don't understand what is happening here. Setting `KEYCLOAK_FRONTEND_URL` on my local also breaks the links.\nI have tried to change the `rewrite` annotation of the ingress to `/mycontext/access-management/$2` but this configuration doesn't work at all.\nIn the Keycloak documentation here it talks about a property named `adminUrl`, however, setting `-DadminUrl` or `-Dkeycloak.adminUrl` seems to be ignored completely by the docker image when using `JAVA_OPTS_APPEND` according to JBoss documentation page.\nWhat have I missed here? Is there anything that I have missed in my configuration?\nPlease note that, we have no choice other than exposing it under a context-path followed by the name (i.e. `/mycontext/access-management`). This is because of both our client requirements as well as the fact that we have many micro-services deployed under `/mycontext` each of which has its own ingress configuration.\nAny help is appreciated.",
      "solution": "Okay I managed to get this working by gathering all the solutions that are mentioned out there.\nSo basically, `web-context` needs to be set and that's something that is not mentioned anywhere in any documentation except word of mouth.\nTo set that, you can write a `cli` script:\n```\n`set CONTEXT=${env.KEYCLOAK_WEB_CONTEXT}\necho $CONTEXT\nembed-server --server-config=standalone-ha.xml --std-out=echo\n/subsystem=keycloak-server/:write-attribute(name=web-context,value=$CONTEXT)\nstop-embedded-server\n\nembed-server --server-config=standalone.xml --std-out=echo\n/subsystem=keycloak-server/:write-attribute(name=web-context,value=$CONTEXT)\nstop-embedded-server\n`\n```\nThis is mentioned here but the important things are 1. you need to start embed server otherwise there is no server to connect to and second you should change both `standalone.xml` and `standalone-ha.xml` unless you know which one exactly you are running.\nSee this answer here on how to copy custom scripts to your docker image.\nHowever, there is one important point here! Although Keycloak documentation says that you can change the front-end URL to whatever you want, you actually HAVE TO add `/auth` at the end of your new URL. It seems many pages in Keycloak are hardcoded to that path\nNow you need to set these two properties in your ConfigMap:\n```\n`#ConfigMap\n# Has to end with /auth and has to be absolute URL\nKEYCLOAK_FRONTEND_URL: https://your.website.address/mycontext/access-management/auth\nPROXY_ADDRESS_FORWARDING: \"true\"\n# The following is our own env var that will be used by the above cli\n# Note that it SHOULD NOT start with / and it must END with /auth\nKEYCLOAK_WEB_CONTEXT: mycontext/access-management/auth\n\n`\n```\nThis is a bit annoying because `KEYCLOAK_FRONTEND_URL` cannot be relative path and has to be full absolute URL. The issue is you constructing that makes things not nice and elegant. Luckily we have a `host` property in `global` and is shared across the Helm's subcharts, so I could use it but really this makes the design a bit nasty.\nBut that's not just this, because of all these crap settings, now you have to change your `liveness` and `readiness` probes to `GET /mycontext/access-management`\nAnd even worst, if you have micro-services, which is nearly 20 for us, you'll need to change all the auth server URLs that was previously as simple as `http://access-management:8080/auth` to `http://access-management:8080/mycontext/access-management/auth`.\nNow make sure your ingress also includes this new path plus another important property `proxy-buffer-size`. If you don't have a large buffer size Keycloak requests may not work and you will get `Bad Gateway` error:\n```\n`Path: /mycontext/access-management(/|$)(.*)\nRewrite To: /mycontext/access-management/$2\nnginx.ingress.kubernetes.io/proxy-buffer-size: 8k \n`\n```\nI really wished we could manage this with ingress without having to touch all these things but it seems not possible. I hope `Keycloak.X` will solve all these bad coding.",
      "question_score": 5,
      "answer_score": 5,
      "created_at": "2021-07-13T11:47:03",
      "url": "https://stackoverflow.com/questions/68360097/how-to-change-fronend-url-in-keycloak-behind-nginx-ingress"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70327305,
      "title": "nginx ingress controller type nlb with static ip giving error &quot;AllocationIdNotFound&quot;",
      "problem": "I am creating nginx ingress controller of type nlb with static ips, but for static ips I am getting this error `AllocationIdNotFound`. Although this allocation id is valid and eip with this id is present in the same region.\nHere are the annotations that I am using with nginx ingress controller service\n```\n`annotations:\n      service.beta.kubernetes.io/aws-load-balancer-backend-protocol: tcp\n      service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: 'true'\n      service.beta.kubernetes.io/aws-load-balancer-type: nlb\n      service.beta.kubernetes.io/aws-load-balancer-subnets: \"subnet-xxxxxxxxxx, subnet-xxxxxxxxxx\"\n      service.beta.kubernetes.io/aws-load-balancer-eip-allocations: \"eipalloc-xxxxxxxxxx, eipalloc-xxxxxxxxxx\"\n`\n```\nIf I comment `service.beta.kubernetes.io/aws-load-balancer-eip-allocations` annotation, load balancer gets created successfully but without eips.\nWhat am I doing wrong here ?",
      "solution": "You're not doing anything wrong, I have just encountered the same issue.\nThere seems to be a bug in the way the service interprets the `service.beta.kubernetes.io/aws-load-balancer-eip-allocations` annotation. If you remove the space after the comma it should work.\nTry this:\n`annotations:\n      service.beta.kubernetes.io/aws-load-balancer-backend-protocol: tcp\n      service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: 'true'\n      service.beta.kubernetes.io/aws-load-balancer-type: nlb\n      service.beta.kubernetes.io/aws-load-balancer-subnets: \"subnet-xxxxxxxxxx, subnet-xxxxxxxxxx\"\n      service.beta.kubernetes.io/aws-load-balancer-eip-allocations: \"eipalloc-xxxxxxxxxx,eipalloc-xxxxxxxxxx\"\n`",
      "question_score": 5,
      "answer_score": 5,
      "created_at": "2021-12-12T21:10:55",
      "url": "https://stackoverflow.com/questions/70327305/nginx-ingress-controller-type-nlb-with-static-ip-giving-error-allocationidnotfo"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 73204128,
      "title": "Issues migrating from v1beta to v1 for kubernetes ingress",
      "problem": "In my firm our Kubernetes Cluster was recently updated to 1.22+ and we are using AKS. So I had to change the manifest of our ingress yaml file which was using : networking.k8s.io/v1beta1, to be compliant to the new apiVersion : networking.k8s.io/v1\nThis is the earlier manifest for the ingress file :\n```\n`{{- if .Values.ingress.enabled -}}\n{{- $fullName := include \"amroingress.fullname\" . -}}\n{{- $svcPort := .Values.service.port -}}\n{{- if semverCompare \">=1.14-0\" .Capabilities.KubeVersion.GitVersion -}}\napiVersion: networking.k8s.io/v1beta1\n{{- else -}}\napiVersion: extensions/v1beta1\n{{- end }}\nkind: Ingress\nmetadata:\n  name: {{ $fullName }}\n  labels:\n    {{- include \"amroingress.labels\" . | nindent 4 }}\n  {{- with .Values.ingress.annotations }}\n  annotations:\n    {{- toYaml . | nindent 4 }}\n  {{- end }}\nspec:\n  {{- if .Values.ingress.tls }}\n  tls:\n    {{- range .Values.ingress.tls }}\n    - hosts:\n        {{- range .hosts }}\n        - {{ . | quote }}\n        {{- end }}\n      secretName: {{ .secretName }}\n    {{- end }}\n  {{- end }}\n  rules:\n    {{- range .Values.ingress.hosts }}\n    - host: {{ .host | quote }}\n      http:\n        paths:\n          #{{- range .paths }}\n          #- path: {{ . }}\n          #  backend:\n          #    serviceName: {{ $fullName }}\n          #    servicePort: {{ $svcPort }}\n          #{{- end }}\n          - path: /callista/?(.*)\n            backend:\n              serviceName: amro-amroingress\n              servicePort: 8080\n    {{- end }}\n  {{- end }}\n`\n```\nand after my changes it looks like this:\n```\n`{{- if .Values.ingress.enabled -}}\n{{- $fullName := include \"amroingress.fullname\" . -}}\n{{- $svcPort := .Values.service.port -}}\napiVersion: networking.k8s.io/v1\n{{- end }}\nkind: Ingress\nmetadata:\n  name: {{ include \"amroingress.fullname\" . }}\n  labels:\n    {{- include \"amroingress.labels\" . | nindent 4 }}\n  {{- with .Values.ingress.annotations }}\n  annotations:\n    {{- toYaml . | nindent 4 }}\n  {{- end }}\nspec:\n  {{- if .Values.ingress.tls }}\n  tls:\n    {{- range .Values.ingress.tls }}\n    - hosts:\n        {{- range .hosts }}\n        - {{ . | quote }}\n        {{- end }}\n      secretName: {{ .secretName }}\n    {{- end }}\n  {{- end }}\n  rules:\n    {{- range .Values.ingress.hosts }}\n    - host: {{ .host | quote }}\n      http:\n        paths:\n          {{- range .paths }}\n          - path: /callista/?(.*)\n            pathType: Prefix\n            backend:\n              service:\n                name: amro-amroingres\n                port: \n                  number: 8080\n    {{- end }}\n  {{- end }}\n\n`\n```\nBut, after I made the changes and tried to deploy using helm, I receive this error:\n`Error: UPGRADE FAILED: current release manifest contains removed kubernetes api(s) for this kubernetes version and it is therefore unable to build the kubernetes objects for performing the diff. error from kubernetes: unable to recognize \"\": no matches for kind \"Ingress\" in version \"networking.k8s.io/v1beta1\"`\nI am not sure why this error occurs even though the ingress manifest has changed and I have been stuck at this for a few days now. I am new to kubernetes and ingress in general, any help will be massively appreciated.",
      "solution": "After trying out a lot more stuff I just decided to finally use helm unistall to remove the deployments and the charts currently in the cluster.\nI then simply tried to install with the new ingress manifest which I have mentioned in the question and that worked out and was finally able to deploy. So, the manifest itself which I had modified did not have any issues it seems.",
      "question_score": 4,
      "answer_score": 2,
      "created_at": "2022-08-02T10:17:26",
      "url": "https://stackoverflow.com/questions/73204128/issues-migrating-from-v1beta-to-v1-for-kubernetes-ingress"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70434928,
      "title": "Nginx Controller Returns 404 Not Found On Path and Default Backend",
      "problem": "I have created a kubernetes cluster using Vagrant. I created a Nginx pod and a Cluster IP service for it. I can curl both the pod and the service getting a successful result. I have now installed an Nginx Ingress Controller from: https://kubernetes.github.io/ingress-nginx/deploy/#bare-metal-clusters and ran the following command:\n`kubectl create ingress nginxingress --rule=\"/nginx=nginx-service:80\" --annotation nginx.ingress.kubernetes.io/rewrite-target=/ --default-backend=nginx-service:80` and they both have been setup correctly as far as I see as there are no errors. But whenever I try to curl the path then it fails, the controller keeps throwing a 404 Not found.\nSome more information that might help:\nservices:\n\ningresses:\n\nany help will be greatly appreciated",
      "solution": "Try adding the ingress class annotation to the ingress configuration. `kubernetes.io/ingress.class: \"nginx\"`\nuse below YAML as reference and try to update the configuration.\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-myserviceb\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"\nspec:\n  rules:\n  - host: myserviceb.foo.org\n    http:\n      paths:\n      - path: /nginx\n        pathType: Prefix\n        backend:\n          service:\n            name: nginx-service\n            port:\n              number: 80\n`\n```",
      "question_score": 4,
      "answer_score": 12,
      "created_at": "2021-12-21T12:46:08",
      "url": "https://stackoverflow.com/questions/70434928/nginx-controller-returns-404-not-found-on-path-and-default-backend"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 65540117,
      "title": "Getting All hosts are taken by other resources with Nginx Ingress Controller",
      "problem": "I have setup Nginx Controller as mentioned in the docs https://docs.nginx.com/nginx-ingress-controller/installation/installation-with-manifests/. I have setup the Ingress with the below configuration\nIngressClass\n```\n`apiVersion: networking.k8s.io/v1beta1\nkind: IngressClass\nmetadata:\n  name: nginx\n  # annotations:\n  #   ingressclass.kubernetes.io/is-default-class: \"true\"\nspec:\n  controller: nginx.org/ingress-controller\n`\n```\nIngress\n```\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: hn-service-ingress\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: hostnameservice.classpath.com\n    http:\n      paths:\n      - path: /test\n        backend:\n          serviceName: hostname-service\n          servicePort: 80\n`\n```\nBelow is the error when running the `describe` command. I am getting `All hosts are taken by other resources`\n```\n`kubectl describe ingress hn-service-ingress\nName:             hn-service-ingress\nNamespace:        pradeep\nAddress:\nDefault backend:  default-http-backend:80 ()\nRules:\n  Host                           Path  Backends\n  ----                           ----  --------\n  hostnameservice.classpath.com\n                                 /test    hostname-service:80 (100.96.1.12:8111,100.96.1.13:8111,100.96.2.13:8111)\nAnnotations:                     \nEvents:\n  Type     Reason    Age   From                      Message\n  ----     ------    ----  ----                      -------\n  Warning  Rejected  5s    nginx-ingress-controller  All hosts are taken by other resources\n`\n```\nWhen I used to check with the `cafe` example, it is working fine. Where am I going wrong?\nNote: I have configured the AWS load balancer and set the `/etc/hosts` to point to the `ELB` from AWS using the dnslookup.",
      "solution": "I realize this is a bit old so hopefully OP was able to find a solution! I'm posting this answer as I believe one of the most common ways to end up in this situation is when you're using cert-manager. I'm sure many people have encountered this error, where you can create a non-SSL ingress resource just fine, but as soon as you create a TLS-based ingress resource with the cert-manager ingress shim, you encounter this error!\nThis is because cert-manager will create an additional ingress resource for you when attempting an HTTP challenge. It does this because the certificate authority has to have a way to access the file created by cert-manager to verify you own the domain, but SSL is not yet working, so it creates an ingress on your default port.\nHere's an example of when I ran into this exact same thing:\n```\n`NAME                        CLASS   HOSTS            ADDRESS   PORTS     AGE\ncm-acme-http-solver-6m9qm   nginx   isaacgentz.com             80        2s\nisaac-site-ssl              nginx   isaacgentz.com             80, 443   4s\n`\n```\nYou can see that the hosts are the same, which is what nginx-ingress is complaining about.\nWhat's the solution\nMake sure you have the following annotation on your ingress resource:\n```\n`acme.cert-manager.io/http01-edit-in-place: \"true\"\n`\n```\nThis will prevent cert-manager from creating a second ingress resource that conflicts!",
      "question_score": 4,
      "answer_score": 4,
      "created_at": "2021-01-02T15:21:25",
      "url": "https://stackoverflow.com/questions/65540117/getting-all-hosts-are-taken-by-other-resources-with-nginx-ingress-controller"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 72220278,
      "title": "Waiting for HTTP-01 challenge propagation: failed to perform self check GET request",
      "problem": "I'm trying to secure my nginx-ingress connection with let's encrypt, following this tutorial (https://github.com/digitalocean/Kubernetes-Starter-Kit-Developers/blob/main/03-setup-ingress-controller/nginx.md).\nI installed cert-manager (v1.8.0) using helm.\nApplied my ClusterIssuer `kubectl apply -f issuer.yaml`\n```\n`apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-nginx\nspec:\n  # ACME issuer configuration\n  # `email` - the email address to be associated with the ACME account (make sure it's a valid one)\n  # `server` - the URL used to access the ACME server\u2019s directory endpoint\n  # `privateKeySecretRef` - Kubernetes Secret to store the automatically generated ACME account private key\n  acme:\n    email: 'myemail'\n    server: https://acme-staging-v02.api.letsencrypt.org/directory\n    privateKeySecretRef:\n      name: letsencrypt-nginx-private-key\n    solvers:\n      # Use the HTTP-01 challenge provider\n      - http01:\n          ingress:\n            class: nginx\n`\n```\nThen applied my ingress `kubectl apply -f ingress.yaml`\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-echo\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-nginx\nspec:\n  tls:\n  - hosts:\n    - www.exmple.com\n    secretName: letsencrypt-nginx-echo\n  rules:\n    - host: www.example.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: backend\n                port:\n                  number: 80\n  ingressClassName: nginx\n`\n```\nFor debugging I ran\n```\n`$ kubectl get certificate\nNAME                     READY   SECRET                   AGE\nletsencrypt-nginx-echo   False   letsencrypt-nginx-echo   39s\n\n$ kubectl describe certificate\n[...]\nStatus:\n  Conditions:\n    Last Transition Time:        2022-05-12T17:24:32Z\n    Message:                     Issuing certificate as Secret does not exist\n    Observed Generation:         1\n    Reason:                      DoesNotExist\n    Status:                      True\n    Type:                        Issuing\n    Last Transition Time:        2022-05-12T17:24:32Z\n    Message:                     Issuing certificate as Secret does not exist\n    Observed Generation:         1\n    Reason:                      DoesNotExist\n    Status:                      False\n    Type:                        Ready\n  Next Private Key Secret Name:  letsencrypt-nginx-echo-nxzw6\nEvents:\n  Type    Reason     Age    From                                       Message\n  ----    ------     ----   ----                                       -------\n  Normal  Issuing    3m23s  cert-manager-certificates-trigger          Issuing certificate as Secret does not exist\n  Normal  Generated  3m23s  cert-manager-certificates-key-manager      Stored new private key in temporary Secret resource \"letsencrypt-nginx-echo-nxzw6\"\n  Normal  Requested  3m23s  cert-manager-certificates-request-manager  Created new CertificateRequest resource \"letsencrypt-nginx-echo-x2flf\"\n\n$ kubectl describe certificaterequest\nStatus:\n  Conditions:\n    Last Transition Time:  2022-05-12T17:24:32Z\n    Message:               Certificate request has been approved by cert-manager.io\n    Reason:                cert-manager.io\n    Status:                True\n    Type:                  Approved\n    Last Transition Time:  2022-05-12T17:24:33Z\n    Message:               Waiting on certificate issuance from order default/letsencrypt-nginx-echo-x2flf-1264636722: \"pending\"\n    Reason:                Pending\n    Status:                False\n    Type:                  Ready\nEvents:\n  Type    Reason           Age   From                                          Message\n  ----    ------           ----  ----                                          -------\n  Normal  cert-manager.io  5m2s  cert-manager-certificaterequests-approver     Certificate request has been approved by cert-manager.io\n  Normal  OrderCreated     5m1s  cert-manager-certificaterequests-issuer-acme  Created Order resource default/letsencrypt-nginx-echo-x2flf-1264636722\n\n$ kubectl describe order\nStatus:\n  Authorizations:\n    Challenges:\n      Token:        bArXItH3_w1FLvjPfFprj2ksjFHPwZ0K6Vb25MlybRU\n      Type:         http-01\n      URL:          https://acme-v02.api.letsencrypt.org/acme/chall-v3/107853386656/VmvKxA\n      Token:        bArXItH3_w1FLvjPfFprj2ksjFHPwZ0K6Vb25MlybRU\n      Type:         dns-01\n      URL:          https://acme-v02.api.letsencrypt.org/acme/chall-v3/107853386656/LgcZ5Q\n      Token:        bArXItH3_w1FLvjPfFprj2ksjFHPwZ0K6Vb25MlybRU\n      Type:         tls-alpn-01\n      URL:          https://acme-v02.api.letsencrypt.org/acme/chall-v3/107853386656/Ut9rIQ\n    Identifier:     www.example.com\n    Initial State:  pending\n    URL:            https://acme-v02.api.letsencrypt.org/acme/authz-v3/107853386656\n    Wildcard:       false\n  Finalize URL:     https://acme-v02.api.letsencrypt.org/acme/finalize/540497076/88058915876\n  State:            pending\n  URL:              https://acme-v02.api.letsencrypt.org/acme/order/540497076/88058915876\nEvents:\n  Type    Reason   Age    From                 Message\n  ----    ------   ----   ----                 -------\n  Normal  Created  6m16s  cert-manager-orders  Created Challenge resource \"letsencrypt-nginx-echo-x2flf-1264636722-1300283520\" for domain \"www.example.com\"\n\n$ kubectl describe challenge\nSpec:\n  Authorization URL:  https://acme-v02.api.letsencrypt.org/acme/authz-v3/107853386656\n  Dns Name:           www.example.com\n  Issuer Ref:\n    Group:  cert-manager.io\n    Kind:   ClusterIssuer\n    Name:   letsencrypt-nginx\n  Key:      bArXItH3_w1FLvjPfFprj2ksjFHPwZ0K6Vb25MlybRU.NSQqkslrJ8YD-aL7n_dLekPhCAy4DkdFIOF0DCAHGzo\n  Solver:\n    http01:\n      Ingress:\n        Class:  nginx\n  Token:        bArXItH3_w1FLvjPfFprj2ksjFHPwZ0K6Vb25MlybRU\n  Type:         HTTP-01\n  URL:          https://acme-v02.api.letsencrypt.org/acme/chall-v3/107853386656/VmvKxA\n  Wildcard:     false\nStatus:\n  Presented:   true\n  Processing:  true\n  Reason:      Waiting for HTTP-01 challenge propagation: failed to perform self check GET request 'http://www.example.com/.well-known/acme-challenge/bArXItH3_w1FLvjPfFprj2ksjFHPwZ0K6Vb25MlybRU': Get \"https://www.example.com:443/.well-known/acme-challenge/bArXItH3_w1FLvjPfFprj2ksjFHPwZ0K6Vb25MlybRU\": remote error: tls: unrecognized name\n  State:       pending\nEvents:\n  Type    Reason     Age    From                     Message\n  ----    ------     ----   ----                     -------\n  Normal  Started    8m45s  cert-manager-challenges  Challenge scheduled for processing\n  Normal  Presented  8m45s  cert-manager-challenges  Presented challenge using HTTP-01 challenge mechanism\n`\n```\nIf I describe the ingress I get\n```\n`TLS:\n  letsencrypt-nginx-echo terminates www.example.com\nRules:\n  Host               Path  Backends\n  ----               ----  --------\n  www.example.com\n                     /   backend:80 ('//myip')\nAnnotations:         cert-manager.io/cluster-issuer: letsencrypt-nginx\nEvents:\n  Type     Reason                     Age   From                       Message\n  ----     ------                     ----  ----                       -------\n  Warning  AddedOrUpdatedWithWarning  12m   nginx-ingress-controller   Configuration for default/ingress-echo was added or updated ; with warning(s): TLS secret letsencrypt-nginx-echo is invalid: secret doesn't exist or of an unsupported type\n  Normal   CreateCertificate          12m   cert-manager-ingress-shim  Successfully created Certificate \"letsencrypt-nginx-echo\"\n`\n```",
      "solution": "I finally managed to fix the problem. Cert manager was creating an ingresss `acme-http-solver` which pointed to no address. After adding     `acme.cert-manager.io/http01-edit-in-place: \"true\"` to my ingress file, everything seems to work.\nIt may not be sufficient to just update the resource, but actually do delete and re-create it. See Issue 6065",
      "question_score": 4,
      "answer_score": 10,
      "created_at": "2022-05-12T20:06:10",
      "url": "https://stackoverflow.com/questions/72220278/waiting-for-http-01-challenge-propagation-failed-to-perform-self-check-get-requ"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 75034450,
      "title": "How to rewrite target for two paths in an ingress yaml",
      "problem": "I have an `ingress.yaml` with two paths; each to one of my microfrontends. However I'm really struggling to get the rewrite-target to work. mf1 loads correctly, but mf2 doesn't. I've done some research and know I need to use Captured Groups, but can't seem to properly implement this. How do I do that?\nThis is what my ingress looks like:\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: http-ingress\n  annotations:\n    kubernetes.io/ingress.class: public\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n    - http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: mf1\n                port:\n                  number: 80\n          - path: /mf2\n            pathType: Prefix\n            backend:\n              service:\n                name: mf2\n                port:\n                  number: 80\n`",
      "solution": "You need to use a regular expression capture group in your `path` expression, and then reference the capture group in your `.../rewrite-target` annotation.\nThat might look like this:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: http-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: \"/$2\"\nspec:\n  rules:\n    - http:\n        paths:\n          - path: /()(.*)\n            pathType: Prefix\n            backend:\n              service:\n                name: backend1\n                port:\n                  name: http\n          - path: /mf2(/|$)(.*)\n            pathType: Prefix\n            backend:\n              service:\n                name: backend2\n                port:\n                  name: http\n`\n```\nWe need to ensure that for both rules, capture group `$2` contains the desired path. For the first rule (`path: /`), we have an empty group `$1` (because it's not necessary here), with the entire path captured in `$2`.\nFor the second rule, we match either `/mf2` followed by either a `/path...` or as the end of the url (this ensures we don't erroneously match `/mf2something`). Group `$1` will contain the `/` (or nothing), and the path goes into `$2`.\nIn both cases, the rewritten path (`/$2`) will have what we want.",
      "question_score": 4,
      "answer_score": 8,
      "created_at": "2023-01-06T18:53:38",
      "url": "https://stackoverflow.com/questions/75034450/how-to-rewrite-target-for-two-paths-in-an-ingress-yaml"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 67164032,
      "title": "k8s ExternalName endpoint not found - but working",
      "problem": "I deployed a simple test `ingress` and an `externalName` `service` using `kustomize`.\nThe deployment works and I get the expected results, but when `describing` the `test-ingress` it shows the error: ``.\nIt seems like a k8s bug. It shows this error, but everything is working fine.\nHere is my deployment:\n`kustomization.yaml`:\n`apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nnamespace: platform\nresources:\n  - test-ingress.yaml\n  - test-service.yaml\ngeneratorOptions:\n  disableNameSuffixHash: true\n`\n`test-service.yaml`:\n`apiVersion: v1\nkind: Service\nmetadata:\n  name: test-external-service\n  namespace: platform\nspec:\n  type: ExternalName\n  externalName: \"some-working-external-elasticsearch-service\"\n`\n`test-ingress.yaml`:\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: test-ingress\n  annotations:\n    kubernetes.io/ingress.class: nginx-external\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      proxy_cache_bypass $http_upgrade;\nspec:\n  rules:\n    - host: testapi.mydomain.com\n      http:\n        paths:\n          - path: /\n            backend:\n              serviceName: test-external-service\n              servicePort: 9200\n`\nHere, I connected the external service to a working `elasticsearch` server. When browsing to `testapi.mydomain.com` (\"mydomain\" was replaced with our real domain of course), I'm getting the well known expected `elasticsearch` results:\n`{\n  \"name\" : \"73b40a031651\",\n  \"cluster_name\" : \"docker-cluster\",\n  \"cluster_uuid\" : \"Xck-u_EFQ0uDHJ1MAho4mQ\",\n  \"version\" : {\n    \"number\" : \"7.10.1\",\n    \"build_flavor\" : \"oss\",\n    \"build_type\" : \"docker\",\n    \"build_hash\" : \"1c34507e66d7db1211f66f3513706fdf548736aa\",\n    \"build_date\" : \"2020-12-05T01:00:33.671820Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.7.0\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n`\nSo everything is working. But when describing the `test-ingress`, there is the following error:\n`test-external-service:9200 ()`\nWhat is this error? Why am I getting it even though everything is working properly? What am I missing here?",
      "solution": "This is how the `kubectl describe ingress` command works.\nThe `kubectl describe ingress` command calls the describeIngressV1beta1 function, which calls the describeBackendV1beta1 function to describe the backend.\nAs can be found in the source code, the describeBackendV1beta1 function looks up the endpoints associated with the backend services, if it doesn't find appropriate endpoints, it generate an error message (as in your example):\n```\n`func (i *IngressDescriber) describeBackendV1beta1(ns string, backend *networkingv1beta1.IngressBackend) string {\n    endpoints, err := i.client.CoreV1().Endpoints(ns).Get(context.TODO(), backend.ServiceName, metav1.GetOptions{})\n    if err != nil {\n        return fmt.Sprintf(\"\", err)\n    }\n...\n`\n```\nIn the Integrating External Services documentation, you can find that `ExternalName` services do not have any defined endpoints:\n\nExternalName services do not have selectors, or any defined ports or endpoints, therefore, you can use an ExternalName service to direct traffic to an external service.",
      "question_score": 4,
      "answer_score": 8,
      "created_at": "2021-04-19T16:35:44",
      "url": "https://stackoverflow.com/questions/67164032/k8s-externalname-endpoint-not-found-but-working"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66901072,
      "title": "Could not access Minikube(v1.18.1) Ingress on Docker-Driver Windows 10",
      "problem": "My issue is exactly the same as this. But replication the question again for your reference::\nI am facing the problem which is that I could not access the Minikube Ingress on the Browser using it's IP. I have installed Minikube on Windows 10 Home, and starting the minikube with docker driver(`minikube start --driver=docker`).\n\nSystem info:\nWindows 10 Home\nMinikube(v1.18.1)\nDocker(driver for minikube) - Docker\nengine version 20.10.5\n\nI am following this official document - https://kubernetes.io/docs/tasks/access-application-cluster/ingress-minikube/\nFirst I created the deployment by running this below command on Minikube.\n`kubectl create deployment web --image=gcr.io/google-samples/hello-app:1.0`\nThe deployment get created which can be seen on the below image: enter image description here\n\nNext, I exposed the deployment that I created above. For this I ran the below command.\n`kubectl expose deployment web --type=NodePort --port=8080`\nThis created a service which can be seen by running the below command:\n`kubectl get service web`\nThe screenshot of the service is shown below:\n\nI can now able to visit the service on the browser by running the below command:\n\n`minikube service web`\nIn the below screenshot you can see I am able to view it on the browser.\n\nNext, I created an Ingress by running the below command:\n\n`kubectl apply -f https://k8s.io/examples/service/networking/example-ingress.yaml`\nThe ingress gets created and I can verify it by running the below command:\n`kubectl get ingress`\nThe screenshot for this is given below:\n\nThe ingress ip is listed as 192.168.49.2. So that means if I should open it in the browser then it should open, but unfortunately not. It is showing site can't be reached. See the below screenshot.\n\nWhat is the problem. Please provide me a solution for it?\nI also added the mappings on etc\\hosts file.\n`192.168.49.2 hello-world.info`\nThen I also tried opening hello-world.info on the browser but no luck.\nIn the below picture I have done ping to hello-world.info which is going to IP address 192.168.49.2. This shows etc\\hosts mapping is correct:\n\nI also did curl to minikube ip and to hello-world.info and both get timeout. See below image:\n\nThe `kubectl describe services web` provides the following details:\n```\n`Name:                     web\nNamespace:                default\nLabels:                   app=web\nAnnotations:              \nSelector:                 app=web\nType:                     NodePort\nIP:                       10.100.184.92\nPort:                       8080/TCP\nTargetPort:               8080/TCP\nNodePort:                   31880/TCP\nEndpoints:                172.17.0.4:8080\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   \n`\n```\nThe `kubectl describe ingress example-ingress` gives the following output:\n```\n`Name:             example-ingress\nNamespace:        default\nAddress:          192.168.49.2\nDefault backend:  default-http-backend:80 ()\nRules:\n  Host              Path  Backends\n  ----              ----  --------\n  hello-world.info\n                    /   web:8080   172.17.0.4:8080)\nAnnotations:        nginx.ingress.kubernetes.io/rewrite-target: /$1\nEvents:             \n`\n```\nThe issue seems to have been resolved there, by following the below instructions(as posted in the comments):\n\nOnce you setup the ingress with necessary change, i guess you are in\nthe powershell of windows with minikube running right? Make sure you\n\u2018enable addons ingress\u2019 and have a separate console running \u2018minikube\ntunnel\u2019 as well. Also, add the hostname and ip address to windows\u2019\nhost table. Then type \u2018minikue ssh\u2019 in powershell, it gives you\ncommand line. Then you can \u2018curl myapp.com\u2019 then you should get\nresponse as expected.\n\nNevertheless, in my case, the minikube tunnel is not responding upon giving the `minikube tunnel` command. :\n\nI am not able to `curl hello-world.info` even through `minikube ssh`. Kindly help!",
      "solution": "On Windows\nAfter some decent amount of time, I came to the conclusion that ingress has some conflicts to work with Docker on Windows10-Home. Things are working fine if we want to expose a service of NodePort type but Ingress is troublesome.\nFurther, I tried to set up WSL 2 with Ubuntu in Windows 10 but no luck.\nFinally, the following worked for Ingress of Minikube on Windows10 Home:\n\nInstall VirtualBox\nUncheck the Virtual Machine Platform and Windows Hypervisor Platform options from `Control Panel -> Programs -> Turn Windows Features on and off (under Programs and Features)` and then click ok. Restart your computer if prompted to.\nNow, execute the following commands in a new cmd\n\n```\n`minikube delete\nminikube start --driver=virtualbox\n`\n```\nif `minikube start --driver=virtualbox` doesn't work, then use `minikube start --driver=virtualbox --no-vtx-check`.\nThis process solved my problem and ingress is working fine on my Windows 10 Home Minikube.\nOn Ubuntu\nFinally, Docker on Ubuntu is inherently supporting Minikube Ingress seamlessly without any glitch.",
      "question_score": 4,
      "answer_score": 8,
      "created_at": "2021-04-01T10:33:25",
      "url": "https://stackoverflow.com/questions/66901072/could-not-access-minikubev1-18-1-ingress-on-docker-driver-windows-10"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69878685,
      "title": "ingress-nginx not working when using ingressClassName instead of kubernetes.io/ingress.class in annotations",
      "problem": "I have a baremetal cluster deployed using Kubespray with kubernetes 1.22.2, MetalLB, and ingress-nginx enabled. I am getting `404 Not found` when trying to access any service deployed via helm when setting `ingressClassName: nginx`. However, everything works fine if I don't use `ingressClassName: nginx` but `kubernetes.io/ingress.class: nginx` instead in the helm chart values.yaml. How can I get it to work using `ingressClassName`?\nThese are my kubespray settings for `inventory/mycluster/group_vars/k8s_cluster/addons.yml`\n```\n`# Nginx ingress controller deployment\ningress_nginx_enabled: true\ningress_nginx_host_network: false\ningress_publish_status_address: \"\"\ningress_nginx_nodeselector:\n  kubernetes.io/os: \"linux\"\ningress_nginx_tolerations:\n  - key: \"node-role.kubernetes.io/master\"\n    operator: \"Equal\"\n    value: \"\"\n    effect: \"NoSchedule\"\n  - key: \"node-role.kubernetes.io/control-plane\"\n    operator: \"Equal\"\n    value: \"\"\n    effect: \"NoSchedule\"\ningress_nginx_namespace: \"ingress-nginx\"\ningress_nginx_insecure_port: 80\ningress_nginx_secure_port: 443\ningress_nginx_configmap:\n  map-hash-bucket-size: \"128\"\n  ssl-protocols: \"TLSv1.2 TLSv1.3\"\ningress_nginx_configmap_tcp_services:\n  9000: \"default/example-go:8080\"\ningress_nginx_configmap_udp_services:\n  53: \"kube-system/coredns:53\"\ningress_nginx_extra_args:\n  - --default-ssl-certificate=default/mywildcard-tls\ningress_nginx_class: \"nginx\"\n`\n```\ngrafana helm values.yaml\n```\n`ingress:\n  enabled: true\n  # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName\n  # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress\n  ingressClassName: nginx\n  # Values can be templated\n  annotations:\n  #  kubernetes.io/ingress.class: nginx\n  #  kubernetes.io/tls-acme: \"true\"\n  labels: {}\n  path: /\n\n  # pathType is only for k8s >= 1.1=\n  pathType: Prefix\n\n  hosts:\n    - grafana.mycluster.org\n  tls:\n   - secretName: mywildcard-tls\n     hosts:\n       - grafana.mycluster.org\n`\n```\n`kubectl describe pod grafana-679bbfd94-p2dd7`\n```\n`...\nEvents:\n  Type     Reason     Age                From               Message\n  ----     ------     ----               ----               -------\n  Normal   Scheduled  25m                default-scheduler  Successfully assigned default/grafana-679bbfd94-p2dd7 to node1\n  Normal   Pulled     25m                kubelet            Container image \"grafana/grafana:8.2.2\" already present on machine\n  Normal   Created    25m                kubelet            Created container grafana\n  Normal   Started    25m                kubelet            Started container grafana\n  Warning  Unhealthy  24m (x3 over 25m)  kubelet            Readiness probe failed: Get \"http://10.233.90.33:3000/api/health\": dial tcp 10.233.90.33:3000: connect: connection refused\n`\n```\n`kubectl get svc`\n```\n`NAME         TYPE           CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE\ngrafana      LoadBalancer   10.233.14.90   10.10.30.52   80:30285/TCP   55m\nkubernetes   ClusterIP      10.233.0.1             443/TCP        9d\n`\n```\n`kubectl get ing` (no node address assigned)\n```\n`NAME      CLASS   HOSTS                    ADDRESS   PORTS     AGE\ngrafana   nginx   grafana.mycluster.org             80, 443   25m\n`\n```\n`kubectl describe ing grafana` (no node address assigned)\n```\n`Name:             grafana\nNamespace:        default\nAddress:\nDefault backend:  default-http-backend:80 ()\nTLS:\n  mywildcard-tls terminates grafana.mycluster.org\nRules:\n  Host                    Path  Backends\n  ----                    ----  --------\n  grafana.mycluster.org\n                          /   grafana:80 (10.233.90.33:3000)\nAnnotations:              meta.helm.sh/release-name: grafana\n                          meta.helm.sh/release-namespace: default\nEvents:                   \n`\n```\n`kubectl get all --all-namespaces`\n```\n`NAMESPACE        NAME                                                              READY   STATUS    RESTARTS   AGE\ndefault          pod/grafana-b988b9b6-pxccw                                        1/1     Running   0          2m53s\ndefault          pod/nfs-client-nfs-subdir-external-provisioner-68f44cd9f4-wjlpv   1/1     Running   0          17h\ningress-nginx    pod/ingress-nginx-controller-6m2vt                                1/1     Running   0          17h\ningress-nginx    pod/ingress-nginx-controller-xkgxl                                1/1     Running   0          17h\nkube-system      pod/calico-kube-controllers-684bcfdc59-kmsst                      1/1     Running   0          17h\nkube-system      pod/calico-node-dhlnt                                             1/1     Running   0          17h\nkube-system      pod/calico-node-r8ktz                                             1/1     Running   0          17h\nkube-system      pod/coredns-8474476ff8-9sbwh                                      1/1     Running   0          17h\nkube-system      pod/coredns-8474476ff8-fdgcb                                      1/1     Running   0          17h\nkube-system      pod/dns-autoscaler-5ffdc7f89d-vskvq                               1/1     Running   0          17h\nkube-system      pod/kube-apiserver-node1                                          1/1     Running   0          17h\nkube-system      pod/kube-controller-manager-node1                                 1/1     Running   1          17h\nkube-system      pod/kube-proxy-hbjz6                                              1/1     Running   0          16h\nkube-system      pod/kube-proxy-lfqzt                                              1/1     Running   0          16h\nkube-system      pod/kube-scheduler-node1                                          1/1     Running   1          17h\nkube-system      pod/kubernetes-dashboard-548847967d-qqngw                         1/1     Running   0          17h\nkube-system      pod/kubernetes-metrics-scraper-6d49f96c97-2h7hc                   1/1     Running   0          17h\nkube-system      pod/nginx-proxy-node2                                             1/1     Running   0          17h\nkube-system      pod/nodelocaldns-64cqs                                            1/1     Running   0          17h\nkube-system      pod/nodelocaldns-t5vv6                                            1/1     Running   0          17h\nkube-system      pod/registry-proxy-kljvw                                          1/1     Running   0          17h\nkube-system      pod/registry-proxy-nz4qk                                          1/1     Running   0          17h\nkube-system      pod/registry-xzh9d                                                1/1     Running   0          17h\nmetallb-system   pod/controller-77c44876d-c92lb                                    1/1     Running   0          17h\nmetallb-system   pod/speaker-fkjqp                                                 1/1     Running   0          17h\nmetallb-system   pod/speaker-pqjgt                                                 1/1     Running   0          17h\n\nNAMESPACE     NAME                                TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE\ndefault       service/grafana                     LoadBalancer   10.233.1.104    10.10.30.52   80:31116/TCP             2m53s\ndefault       service/kubernetes                  ClusterIP      10.233.0.1              443/TCP                  17h\nkube-system   service/coredns                     ClusterIP      10.233.0.3              53/UDP,53/TCP,9153/TCP   17h\nkube-system   service/dashboard-metrics-scraper   ClusterIP      10.233.35.124           8000/TCP                 17h\nkube-system   service/kubernetes-dashboard        ClusterIP      10.233.32.133           443/TCP                  17h\nkube-system   service/registry                    ClusterIP      10.233.30.221           5000/TCP                 17h\n\nNAMESPACE        NAME                                      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE\ningress-nginx    daemonset.apps/ingress-nginx-controller   2         2         2       2            2           kubernetes.io/os=linux   17h\nkube-system      daemonset.apps/calico-node                2         2         2       2            2           kubernetes.io/os=linux   17h\nkube-system      daemonset.apps/kube-proxy                 2         2         2       2            2           kubernetes.io/os=linux   17h\nkube-system      daemonset.apps/nodelocaldns               2         2         2       2            2           kubernetes.io/os=linux   17h\nkube-system      daemonset.apps/registry-proxy             2         2         2       2            2                              17h\nmetallb-system   daemonset.apps/speaker                    2         2         2       2            2           kubernetes.io/os=linux   17h\n\nNAMESPACE        NAME                                                         READY   UP-TO-DATE   AVAILABLE   AGE\ndefault          deployment.apps/grafana                                      1/1     1            1           2m53s\ndefault          deployment.apps/nfs-client-nfs-subdir-external-provisioner   1/1     1            1           17h\nkube-system      deployment.apps/calico-kube-controllers                      1/1     1            1           17h\nkube-system      deployment.apps/coredns                                      2/2     2            2           17h\nkube-system      deployment.apps/dns-autoscaler                               1/1     1            1           17h\nkube-system      deployment.apps/kubernetes-dashboard                         1/1     1            1           17h\nkube-system      deployment.apps/kubernetes-metrics-scraper                   1/1     1            1           17h\nmetallb-system   deployment.apps/controller                                   1/1     1            1           17h\n\nNAMESPACE        NAME                                                                    DESIRED   CURRENT   READY   AGE\ndefault          replicaset.apps/grafana-b988b9b6                                        1         1         1       2m53s\ndefault          replicaset.apps/nfs-client-nfs-subdir-external-provisioner-68f44cd9f4   1         1         1       17h\nkube-system      replicaset.apps/calico-kube-controllers-684bcfdc59                      1         1         1       17h\nkube-system      replicaset.apps/coredns-8474476ff8                                      2         2         2       17h\nkube-system      replicaset.apps/dns-autoscaler-5ffdc7f89d                               1         1         1       17h\nkube-system      replicaset.apps/kubernetes-dashboard-548847967d                         1         1         1       17h\nkube-system      replicaset.apps/kubernetes-metrics-scraper-6d49f96c97                   1         1         1       17h\nkube-system      replicaset.apps/registry                                                1         1         1       17h\nmetallb-system   replicaset.apps/controller-77c44876d                                    1         1         1       17h\n`\n```\n`kubectl get ing grafana -o yaml`\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/tls-acme: \"true\"\n    meta.helm.sh/release-name: grafana\n    meta.helm.sh/release-namespace: default\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n  creationTimestamp: \"2021-11-11T07:16:12Z\"\n  generation: 1\n  labels:\n    app.kubernetes.io/instance: grafana\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: grafana\n    app.kubernetes.io/version: 8.2.2\n    helm.sh/chart: grafana-6.17.5\n  name: grafana\n  namespace: default\n  resourceVersion: \"3137\"\n  uid: 6c34d3bd-9ab6-42fe-ac1b-7620a9566f62\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: grafana.mycluster.org\n    http:\n      paths:\n      - backend:\n          service:\n            name: ssl-redirect\n            port:\n              name: use-annotation\n        path: /*\n        pathType: Prefix\n      - backend:\n          service:\n            name: grafana\n            port:\n              number: 80\n        path: /\n        pathType: Prefix\nstatus:\n  loadBalancer: {}\n`\n```",
      "solution": "Running `kubectl get ingressclass` returned 'No resources found'.\n\nThat's the main reason of your issue.\nWhy?\nWhen you are specifying `ingressClassName: nginx` in your Grafana `values.yaml` file you are setting your Ingress resource to use `nginx` Ingress class which does not exist.\nI replicated your issue using minikube, MetalLB and NGINX Ingress installed via modified deploy.yaml file with commented `IngressClass` resource + set NGINX Ingress controller name to `nginx` as in your example. The result was exactly the same - `ingressClassName: nginx` didn't work (no address), but annotation `kubernetes.io/ingress.class: nginx` worked.\n\n(For the below solution I'm using controller pod name `ingress-nginx-controller-86c865f5c4-qwl2b`, but in your case it will be different - check it using `kubectl get pods -n ingress-nginx` command. Also keep in mind it's kind of a workaround - usually `ingressClass` resource should be installed automatically with a whole installation of NGINX Ingress. I'm presenting this solution to understand why it's not worked for you before, and why it works with NGINX Ingress installed using helm)\nIn the logs of the Ingress NGINX controller I found (`kubectl logs ingress-nginx-controller-86c865f5c4-qwl2b -n ingress-nginx`):\n```\n`\"Ignoring ingress because of error while validating ingress class\" ingress=\"default/minimal-ingress\" error=\"no object matching key \\\"nginx\\\" in local store\"\n`\n```\nSo it's clearly shown that there is no matching key to `nginx` controller class - because there is no `ingressClass` resource which is the \"link\" between the NGINX Ingress controller and running Ingress resource.\nYou can verify which name of controller class is bidden to controller by running `kubectl get pod ingress-nginx-controller-86c865f5c4-qwl2b -n ingress-nginx -o yaml`:\n`...\nspec:\n  containers:\n  - args:\n    - /nginx-ingress-controller\n    - --publish-service=$(POD_NAMESPACE)/ingress-nginx-controller\n    - --election-id=ingress-controller-leader\n    - --controller-class=k8s.io/nginx\n...\n`\nNow I will create and apply following Ingress class resource:\n`apiVersion: networking.k8s.io/v1\nkind: IngressClass\nmetadata:\n  name: nginx\nspec:\n  controller: k8s.io/nginx\n`\nNow in the logs I can see that it's properly configured:\n```\n`I1115 12:13:42.410384       7 main.go:101] \"successfully validated configuration, accepting\" ingress=\"minimal-ingress/default\"\nI1115 12:13:42.420408       7 store.go:371] \"Found valid IngressClass\" ingress=\"default/minimal-ingress\" ingressclass=\"nginx\"\nI1115 12:13:42.421487       7 event.go:282] Event(v1.ObjectReference{Kind:\"Ingress\", Namespace:\"default\", Name:\"minimal-ingress\", UID:\"c708a672-a8dd-45d3-a2ec-f2e2881623ea\", APIVersion:\"networking.k8s.io/v1\", ResourceVersion:\"454362\", FieldPath:\"\"}): type: 'Normal' reason: 'Sync' Scheduled for sync\n`\n```\nI re-applied the ingress resource definition, I get IP address for Ingress resource.\n\nAs I said before, instead of using this workaround, I'd suggest installing the NGINX Ingress resource using a solution that automatically installs `IngressClass` as well. As you have chosen helm chart, it has Ingress Class resource so the problem is gone. Other possible ways to install are here.",
      "question_score": 4,
      "answer_score": 7,
      "created_at": "2021-11-08T05:32:21",
      "url": "https://stackoverflow.com/questions/69878685/ingress-nginx-not-working-when-using-ingressclassname-instead-of-kubernetes-io-i"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 72950423,
      "title": "GCP external HTTP Cloud Load Balancer with nginx-ingress on GKE",
      "problem": "my goal is to have EXTERNAL HTTP CLOUD LOAD BALANCER with NGINX INGRESS in our GCP GKE.\nIm trying solution as Rami H proposed and Google developer Garry Singh confirmed here:\nGlobal load balancer (HTTPS Loadbalancer) in front of GKE Nginx Ingress Controller\n\nYou can create the Nginx as a service of type LoadBalancer and give it a NEG annotation as per this google documentation. https://cloud.google.com/kubernetes-engine/docs/how-to/container-native-load-balancing Then you can use this NEG as a backend service (target) for HTTP(S) load balancing You can use the gcloud commands from this article https://hodo.dev/posts/post-27-gcp-using-neg/\n\nI have followed mentioned hodo.dev tutorial and successfully deployed HTTP LB with NEGs as backend service.\nThen I found this script to attach NGINX-INGRESS to NEGs but its probably obsolete and fails while deploying. https://gist.github.com/halvards/dc854f16d76bcc86ec59d846aa2011a0\nPlease can somebody help me to to adapt hodo.dev config to deploy there nginx-ingress?\nHere is repo with my config script https://github.com/robinpecha/hododev_gke-negs-httplb\n```\n`#First lets define some variables:\nPROJECT_ID=$(gcloud config list project --format='value(core.project)') ; echo $PROJECT_ID\nZONE=europe-west2-b ; echo $ZONE\nCLUSTER_NAME=negs-lb ; echo $CLUSTER_NAME\n\n# and we need a cluster\ngcloud container clusters create $CLUSTER_NAME --zone $ZONE --machine-type \"e2-medium\" --enable-ip-alias --num-nodes=2\n\n# the --enable-ip-alias enables the VPC-native traffic routing option for your cluster. This option creates and attaches additional subnets to VPC, the pods will have IP address allocated from the VPC subnets, and in this way the pods can be addressed directly by the load balancer aka container-native load balancing.\n\n# Next we need a simple deployment, we will use nginx\ncat  app-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: nginx:latest\n        ports:\n        - containerPort: 80\nEOF\nkubectl apply -f app-deployment.yaml\n\n# and the service\ncat  app-service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: app-service\n  annotations:\n    cloud.google.com/neg: '{\"exposed_ports\": {\"80\":{\"name\": \"app-service-80-neg\"}}}'\nspec:\n  type: ClusterIP\n  ports:\n  - port: 80\n    targetPort: 80\n  selector:\n    app: nginx\nEOF\nkubectl apply -f app-service.yaml\n\n# this annotation cloud.google.com/neg tells the GKE to create a NEG for this service and to add and remove endpoints (pods) to this group.\n# Notice here that the type is ClusterIP. Yes it is possible to expose the service to the internet even if the type is ClusterIP. This one of the magic of NEGs.\n# You can check if the NEG was created by using next command\ngcloud compute network-endpoint-groups list\n\n# Next let\u2019s create the load balancer and all the required components.\n# We need a firewall rule that will allow the traffic from the load balancer\n\n# find the network tags used by our cluster\nNETWORK_TAGS=$(gcloud compute instances describe \\\n    $(kubectl get nodes -o jsonpath='{.items[0].metadata.name}') \\\n    --zone=$ZONE --format=\"value(tags.items[0])\")\necho $NETWORK_TAGS\n\n# create the firewall rule\ngcloud compute firewall-rules create $CLUSTER_NAME-lb-fw \\\n    --allow tcp:80 \\\n    --source-ranges 130.211.0.0/22,35.191.0.0/16 \\\n    --target-tags $NETWORK_TAGS\n\n# and a health check configuration\ngcloud compute health-checks create http app-service-80-health-check \\\n  --request-path / \\\n  --port 80 \\\n  --check-interval 60 \\\n  --unhealthy-threshold 3 \\\n  --healthy-threshold 1 \\\n  --timeout 5\n\n# and a backend service\ngcloud compute backend-services create $CLUSTER_NAME-lb-backend \\\n  --health-checks app-service-80-health-check \\\n  --port-name http \\\n  --global \\\n  --enable-cdn \\\n  --connection-draining-timeout 300\n\n# next we need to add our NEG to the backend service\ngcloud compute backend-services add-backend $CLUSTER_NAME-lb-backend \\\n  --network-endpoint-group=app-service-80-neg \\\n  --network-endpoint-group-zone=$ZONE \\\n  --balancing-mode=RATE \\\n  --capacity-scaler=1.0 \\\n  --max-rate-per-endpoint=1.0 \\\n  --global\n\n# This was the backend configuration, let\u2019s setup also the fronted.\n# First the url map\ngcloud compute url-maps create $CLUSTER_NAME-url-map --default-service $CLUSTER_NAME-lb-backend\n\n# and then the http proxy\ngcloud compute target-http-proxies create $CLUSTER_NAME-http-proxy --url-map $CLUSTER_NAME-url-map\n\n# and finally the global forwarding rule\n\ngcloud compute forwarding-rules create $CLUSTER_NAME-forwarding-rule \\\n  --global \\\n  --ports 80 \\\n  --target-http-proxy $CLUSTER_NAME-http-proxy\n\n# Done! Give some time for the load balancer to setup all the components and then you can test if your setup works as expected.\n\n# get the public ip address\nIP_ADDRESS=$(gcloud compute forwarding-rules describe $CLUSTER_NAME-forwarding-rule --global --format=\"value(IPAddress)\")\n# print the public ip address\necho $IP_ADDRESS\n# make a request to the service\ncurl -s -I http://$IP_ADDRESS/\n\n`\n```",
      "solution": "The trick is to deploy the `ingress-nginx` service as `ClusterIP` and not as `LoadBalancer` and then expose the `ingresss-nginx-controller` service using NEG and GCP External Load Balancer feature.\nFirst you need to update the helm repo\n`helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\nhelm repo update\n`\nThe default installation of this ingress-nginx is configured to use the LoadBalancer option, this will\nautomatically create a load balancer for you, but in this case is not the expected behavior.\nIf I understood correctly, you want to create/configure\nyour own GCP Load Balancer, outside GKE and to manually configure it, and to route traffic to your custom ingress-nginx.\nFor this you need to change the service type to be \"ClusterIP\" and to add the NEG annotation.\nCreate a file values.yaml\n`cat  values.yaml\ncontroller:\n  service:\n    type: ClusterIP\n    annotations:\n      cloud.google.com/neg: '{\"exposed_ports\": {\"80\":{\"name\": \"ingress-nginx-80-neg\"}}}'\nEOF\n`\nAnd install the ingress-nginx\n`helm install -f values.yaml ingress-nginx ingress-nginx/ingress-nginx\n`\nAfter that you need to configure the load balancer to point to your ingress-nginx controller using NEG.\nI added the complete steps to follow in this gist https://gist.github.com/gabihodoroaga/1289122db3c5d4b6c59a43b8fd659496",
      "question_score": 4,
      "answer_score": 6,
      "created_at": "2022-07-12T11:57:18",
      "url": "https://stackoverflow.com/questions/72950423/gcp-external-http-cloud-load-balancer-with-nginx-ingress-on-gke"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 71709856,
      "title": "Unable to self sign certificate nginx ingress k3s",
      "problem": "I'm new to K3s, and have struggle with this step for a few days.\nEnvironment: Ubuntu 20.04 | K3s installation without Traefik.\nK3s installation script:\n```\n`curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC=\"server --no-deploy=traefik\" sh -s -\n`\n```\nNginx ingress installation script\n```\n`helm repo add nginx-stable https://helm.nginx.com/stable\nhelm repo update\nhelm install my-release nginx-stable/nginx-ingress\n`\n```\nCert-manager installation script\n```\n`helm repo add jetstack https://charts.jetstack.io\nhelm repo update\nhelm install \\\n  cert-manager jetstack/cert-manager \\\n  --namespace cert-manager \\\n  --create-namespace \\\n  --version v1.3.1 \\\n  --set installCRDs=true\n`\n```\nVerified with Cert-manager verifier\nCreate a testing namespace to play with `kubectl create ns practice-cls`\nTest service deployment\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kuard\n  namespace: practice-cls\nspec:\n  selector:\n    matchLabels:\n      app: kuard\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: kuard\n    spec:\n      containers:\n        - image: gcr.io/kuar-demo/kuard-amd64:1\n          imagePullPolicy: Always\n          name: kuard\n          ports:\n            - containerPort: 8080\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: kuard\n  namespace: practice-cls\nspec:\n  ports:\n  - port: 80\n    targetPort: 8080\n    protocol: TCP\n  selector:\n    app: kuard\n`\nIssuer\n`apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: selfsigned-cluster-issuer\n  namespace: cert-manager\nspec:\n  selfSigned: {}\n`\nservice ingress\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: kuard\n  namespace: practice-cls\n  annotations:\n    cert-manager.io/cluster-issuer: \"selfsigned-cluster-issuer\"\nspec:\n  tls:\n  - hosts:\n    - example.example.com\n    secretName: quickstart-example-tls\n  rules:\n  - host: example.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: kuard\n            port:\n              number: 80\n  ingressClassName: nginx\n`\n```\n`# kubectl describe ing kuard -n practice-cls\n\nName:             kuard\nLabels:           \nNamespace:        practice-cls\nAddress:          10.227.224.141\nDefault backend:  default-http-backend:80 ()\nTLS:\n  quickstart-example-tls terminates example.example.com\nRules:\n  Host                 Path  Backends\n  ----                 ----  --------\n  example.example.com  \n                       /   kuard:80 (10.42.0.76:8080)\nAnnotations:           cert-manager.io/cluster-issuer: selfsigned-cluster-issuer\nEvents:\n  Type     Reason                     Age   From                      Message\n  ----     ------                     ----  ----                      -------\n  Warning  AddedOrUpdatedWithWarning  6m9s  nginx-ingress-controller  Configuration for practice-cls/kuard was added or updated ; with warning(s): TLS secret quickstart-example-tls is invalid: secret doesn't exist or of an unsupported type\n`\n```\nI don't know if there was anything wrong with this, the kuard image was just a tutorial service from `cert-manager`. And I got `ERR_SSL_UNRECOGNIZED_NAME_ALERT` from the manifests above.\nLet me know if there's some more information to troubleshoot this.\nThank you guys",
      "solution": "After a while searching and experiment, I manage to handle this by:\nUsing K8s nginx ingress instead of the official one provide by nginx themself\nEnable SSL passthrough either by editing the deployment of nginx controller or enable that right when installing",
      "question_score": 4,
      "answer_score": 5,
      "created_at": "2022-04-01T18:05:40",
      "url": "https://stackoverflow.com/questions/71709856/unable-to-self-sign-certificate-nginx-ingress-k3s"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66173551,
      "title": "Configure TCP Port on Nginx Ingress on Azure Kubernetes Cluster (AKS)",
      "problem": "I need to configure a TCP port on my AKS Cluster to allow RabbitMQ to work\nI have installed nginx-ingress with helm as follows:\n```\n`kubectl create namespace ingress-basic\n\nhelm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\n\nhelm install nginx-ingress ingress-nginx/ingress-nginx \\\n    --namespace ingress-basic \\\n    --set controller.replicaCount=2 \\\n    --set controller.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n    --set defaultBackend.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n    --set controller.admissionWebhooks.patch.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux\n`\n```\nI have setup an A record with our DNS provider to point to the public IP of the ingress controller.\nI have created a TLS secret (to enable https)\nI have created an ingress route with:\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: rabbit-ingress\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\nspec:\n  tls:\n  - hosts:\n    - my.domain.com\n    secretName: tls-secret\n  rules:\n    - http:\n        paths:\n          - backend:\n              serviceName: rabbitmq-cluster\n              servicePort: 15672\n            path: /(.*)\n`\nI can navigate to my cluster via the domain name from outside and see the control panel (internally on 15672)  with valid https. So the ingress is up and running, and I can create queues etc... so rabbitmq is working correctly.\nHowever, I can't get the TCP part to work to post to the queues from outside the cluster.\nI have edited the yaml of the what I believe is the configmap (azure - cluster - configuration - nginx-ingress-ingress-nginx-controller) for the controller (nginx-ingress-ingress-nginx-controller) via the azure portal interface and added this to the end\n`data:\n  '5672': 'default/rabbitmq-cluster:5672'\n`\nI have then edited they yaml for the service itself via the azure portal and added this to the end\n`  - name: amqp\n      protocol: TCP\n      port: 5672\n`\nHowever, when I try to hit my domain using a test client the request just times out. (The client worked when I used a LoadBalancer and just hit the external IP of the cluster, so I know the client code should work)\nIs there another step that I should be doing?",
      "solution": "I believe the issue here was that helm was configuring so much of my own stuff that I wasn't able to customise too much.\nI uninstalled the ingress with helm and changed the ingress creation script to this:\n`helm install nginx-ingress ingress-nginx/ingress-nginx \\\n    --namespace ingress-basic \\\n    --set controller.replicaCount=2 \\\n    --set controller.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n    --set defaultBackend.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n    --set controller.admissionWebhooks.patch.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n    --set tcp.5672=\"default/rabbitmq-cluster:5672\"\n`\nWhich pre-configures the TCP port forwarding and I don't have to do anything else. I don't know if it effected it, but this seemed to 'break' my SSL implementation, so I upgraded the ingress route creation script from v1beta to v1 and https was working again perfectly.\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: rabbit-ingress\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\nspec:\n  tls:\n  - hosts:\n      - my.domain.com\n    secretName: tls-secret\n  rules:\n  - host: my.domain.com\n    http:\n      paths:\n      - path: /(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: rabbitmq-cluster\n            port:\n              number: 15672\n`",
      "question_score": 4,
      "answer_score": 4,
      "created_at": "2021-02-12T15:24:00",
      "url": "https://stackoverflow.com/questions/66173551/configure-tcp-port-on-nginx-ingress-on-azure-kubernetes-cluster-aks"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 71257667,
      "title": "GKE Ingress with Multiple Backend Services returns 404",
      "problem": "I'm trying to create a GKE Ingress that points to two different backend services based on path. I've seen a few posts explaining this is only possible with an nginx Ingress because gke ingress doesn't support rewrite-target. However, this Google documentation, GKE Ingresss - Multiple backend services, seems to imply otherwise. I've followed the steps in the docs but haven't had any success. Only the service that is available on the path prefix of `/` is returned. Any other path prefix, like `/v2`, returns a 404 Not found.\nDetails of my setup are below. Is there an obvious error here -- is the Google documentation incorrect and this is only possible using nginx ingress?\n```\n`-- Ingress\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app-ingress\n  annotations:\n    kubernetes.io/ingress.global-static-ip-name: app-static-ip\n    networking.gke.io/managed-certificates: app-managed-cert\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: api-service\n            port:\n              number: 80\n      - path: /v2\n        pathType: Prefix\n        backend:\n          service:\n            name: api-2-service\n            port:\n              number: 8080\n\n-- Service 1\napiVersion: v1\nkind: Service\nmetadata:\n  name: api-service\n  labels:\n    app: api\nspec:\n  type: NodePort\n  selector:\n    app: api\n  ports:\n  - port: 80\n    targetPort: 5000\n\n-- Service 2\napiVersion: v1\nkind: Service\nmetadata:\n  name: api-2-service\n  labels:\n    app: api-2\nspec:\n  type: NodePort\n  selector:\n    app: api-2\n  ports:\n  - port: 8080\n    targetPort: 5000\n`\n```",
      "solution": "GCP Ingress supports multiple paths. This is also well described in Setting up HTTP(S) Load Balancing with Ingress. For my test I've used both Hello-world v1 and v2.\nThere are 3 possible issues.\n\nIssue is with container ports opened. You can check it using netstat:\n\n```\n`$ kk exec -ti first-55bb869fb8-76nvq -c container -- bin/sh\n/ # netstat -plnt\nActive Internet connections (only servers)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name\ntcp        0      0 :::8080                 :::*                    LISTEN      1/hello-app\n`\n```\n\nIssue might be also caused by the `Firewall` configuration. Make sure you have proper settings. (In general, in the new cluster I didn't need to add anything but if you have more stuff and have specific Firewall configurations it might block).\n\nMisconfiguration between `port`, `containerPort` and `targetPort`.\n\nBelow my example:\n1st deployment with\n```\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: first\n  labels:\n    app: api\nspec:\n  selector:\n    matchLabels:\n      app: api\n  template:\n    metadata:\n      labels:\n        app: api\n    spec:\n      containers:\n        - name: container\n          image: gcr.io/google-samples/hello-app:1.0\n          ports:\n          - containerPort: 8080\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: api-service\n  labels:\n    app: api\nspec:\n  type: NodePort\n  selector:\n    app: api\n  ports:\n  - port: 5000\n    targetPort: 8080\n`\n```\n2nd deployment\n```\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: second\n  labels:\n    app: api-2\nspec:\n  selector:\n    matchLabels:\n      app: api-2\n  template:\n    metadata:\n      labels:\n        app: api-2\n    spec:\n      containers:\n        - name: container\n          image: gcr.io/google-samples/hello-app:2.0\n          ports:\n          - containerPort: 8080\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: api-2-service\n  labels:\n    app: api-2\nspec:\n  type: NodePort\n  selector:\n    app: api-2\n  ports:\n  - port: 6000\n    targetPort: 8080\n`\n```\nIngress\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app-ingress\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: api-service\n            port:\n              number: 5000\n      - path: /v2\n        pathType: Prefix\n        backend:\n          service:\n            name: api-2-service\n            port:\n              number: 6000\n`\n```\nOutputs:\n```\n`$ curl 35.190.XX.249\nHello, world!\nVersion: 1.0.0\nHostname: first-55bb869fb8-76nvq\n$ curl 35.190.XX.249/v2\nHello, world!\nVersion: 2.0.0\nHostname: second-d7d87c6d8-zv9jr\n`\n```\nPlease keep in mind that you can also use `Nginx Ingress` on GKE by adding specific annotation.\n```\n`kubernetes.io/ingress.class: \"nginx\" \n`\n```\nMain reason why people use `nginx ingress` on `GKE` is using `rewrite` annotation and possibility to use `ClusterIP` or `NodePort` as serviceType, where `GCP ingress` allows only `NodePort` serviceType.\nAdditional information you can find in GKE Ingress for HTTP(S) Load Balancing",
      "question_score": 4,
      "answer_score": 2,
      "created_at": "2022-02-24T21:07:14",
      "url": "https://stackoverflow.com/questions/71257667/gke-ingress-with-multiple-backend-services-returns-404"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 68609694,
      "title": "How to implement Fail2Ban inside a Docker container running Nginx",
      "problem": "I am trying to implement fail2ban inside my docker environment that uses my Nginx logs. \n```\n`version: '3'\nservices:\n  fail2ban:\n    image: 'crazymax/fail2ban:latest'\n    restart: 'always'\n    network_mode: 'host'\n    cap_add:\n      - 'NET_ADMIN'\n      - 'NET_RAW'\n    volumes:\n      - 'nginx-log:/var/log:ro'\n      - 'fail2ban-data:/data'\n    env_file:\n      - './fail2ban.env'\n  laravel-mysql:\n    [SNIP]\n  laravel-php:\n    [SNIP]\n  laravel-nginx:\n    image: 'nginx:alpine'\n    restart: 'always'\n    depends_on:\n      - 'laravel-php'\n    expose:\n      - '80'\n    volumes:\n      - 'laravel-src:/var/www/html'\n      - './nginx.conf:/etc/nginx/conf.d/default.conf'\n      - 'nginx-log:/var/log/nginx'\n    networks:\n      - 'traefik'\n      - 'laravel'\n    labels:\n      - 'traefik.enable=true'\n      - 'traefik.docker.network=traefik'\n      - 'traefik.http.routers.nginx.entrypoints=http'\n      - 'traefik.http.routers.nginx.rule=Host(`${DOMAIN}`) || Host(`www.${DOMAIN}`)'\n      - 'traefik.http.routers.nginx.middlewares=redirect@file'\n      - 'traefik.http.routers.nginx-https.rule=Host(`${DOMAIN}`) || Host(`www.${DOMAIN}`)'\n      - 'traefik.http.routers.nginx-https.tls=true'\n      - 'traefik.http.routers.nginx-https.tls.certresolver=${DNS_PROVIDER}'\n      - 'traefik.http.routers.nginx-https.tls.domains[0].main=${DOMAIN}'\n      - 'traefik.http.routers.nginx-https.tls.domains[1].main=www.${DOMAIN}'\n      - 'traefik.http.routers.nginx.service=nginx'\n      - 'traefik.http.services.nginx.loadbalancer.server.port=80'\n      - 'traefik.http.services.nginx.loadBalancer.passHostHeader=true'\n      - 'traefik.http.middlewares.https_redirect.redirectscheme.scheme=https'\n      - 'traefik.http.middlewares.https-redirect.redirectscheme.scheme=https'\n      - 'traefik.http.middlewares.https-redirect.headers.customrequestheaders.X-Forwarded-Proto=https'\n      - 'traefik.http.routers.nginx.middlewares=https-redirect'\n      - 'traefik.http.middlewares.https_redirect.redirectscheme.permanent=true'\n      - 'traefik.http.routers.http_catchall.rule=HostRegexp(`{any:.+}`)'\n      - 'traefik.http.routers.http_catchall.entrypoints=http'\n      - 'traefik.http.routers.http_catchall.middlewares=https_redirect'\nnetworks:\n  laravel:\n    driver: 'bridge'\n  traefik:\n    name: '${TRAEFIK_NETWORK}'\n    external: 'true'\nvolumes:\n  laravel-database:\n    driver: 'local'\n  laravel-src:\n    driver: 'local'\n  nginx-log:\n    driver: 'local'\n  fail2ban-data:\n    driver: 'local'\n`\n```\nRunning `docker logs laravel_fail2ban_1 --tail 100` after `docker-compose up -d` shows me:\n```\n`Setting timezone to Europe/London...\nSetting SSMTP configuration...\nWARNING: SSMTP_HOST must be defined if you want fail2ban to send emails\nInitializing files and folders...\nSetting Fail2ban configuration...\nChecking for custom actions in /data/action.d...\nChecking for custom filters in /data/filter.d...\n2021-08-01 11:40:13,199 fail2ban.configreader   [1]: INFO    Loading configs for fail2ban under /etc/fail2ban\n2021-08-01 11:40:13,202 fail2ban.configparserinc[1]: INFO      Loading files: ['/etc/fail2ban/fail2ban.conf']\n2021-08-01 11:40:13,203 fail2ban.configparserinc[1]: INFO      Loading files: ['/etc/fail2ban/fail2ban.conf']\n2021-08-01 11:40:13,204 fail2ban                [1]: INFO    Using socket file /var/run/fail2ban/fail2ban.sock\n2021-08-01 11:40:13,204 fail2ban                [1]: INFO    Using pid file /var/run/fail2ban/fail2ban.pid, [INFO] logging to STDOUT\n2021-08-01 11:40:13,218 fail2ban.configreader   [1]: INFO    Loading configs for jail under /etc/fail2ban\n2021-08-01 11:40:13,219 fail2ban.configparserinc[1]: INFO      Loading files: ['/etc/fail2ban/jail.conf']\n2021-08-01 11:40:13,255 fail2ban.configparserinc[1]: INFO      Loading files: ['/etc/fail2ban/paths-debian.conf']\n2021-08-01 11:40:13,257 fail2ban.configparserinc[1]: INFO      Loading files: ['/etc/fail2ban/paths-common.conf']\n2021-08-01 11:40:13,260 fail2ban.configparserinc[1]: INFO      Loading files: ['/etc/fail2ban/paths-overrides.local']\n2021-08-01 11:40:13,263 fail2ban.configparserinc[1]: INFO      Loading files: ['/etc/fail2ban/paths-common.conf', '/etc/fail2ban/paths-debian.conf', '/etc/fail2ban/jail.conf']\n2021-08-01 11:40:13,369 fail2ban.server         [1]: INFO    --------------------------------------------------\n2021-08-01 11:40:13,372 fail2ban.server         [1]: INFO    Starting Fail2ban v0.11.2\n2021-08-01 11:40:13,373 fail2ban.observer       [1]: INFO    Observer start...\n2021-08-01 11:40:13,382 fail2ban.database       [1]: INFO    Connected to fail2ban persistent database '/data/db/fail2ban.sqlite3'\n2021-08-01 11:40:13,385 fail2ban.database       [1]: WARNING New database created. Version '4'\nServer ready\n`\n```\nIf I now attempt to stress my application, no logs are populated in fail2ban but if I `--follow` my nginx container logs, I see the requests firing away.\nIf I `docker exec -it -u root laravel_fail2ban_1 /bin/bash -c 'ls -la /var/log'` I can see my logs in the correct location:\n```\n`total 8\ndrwxr-xr-x    2 root     root          4096 Aug  1 11:35 .\ndrwxr-xr-x    1 root     root          4096 Dec 16  2020 ..\nlrwxrwxrwx    1 root     root            11 Jul  6 20:40 access.log -> /dev/stdout\nlrwxrwxrwx    1 root     root            11 Jul  6 20:40 error.log -> /dev/stderr\n`\n```\nI see the issue may be when I try `cat /var/log/access.log`. It is symlinked to the `/dev/stdout` which means the terminal tries attaching to it. I cannot unlink it whilst running:\n```\n`docker exec -it -u root laravel_fail2ban_1 /bin/bash -c 'unlink /var/log/access.log'\nunlink: can't remove file '/var/log/access.log': Read-only file system\n`\n```\nAny help appreciated to get this working. I need to keep the symlink on the volume so I can use docker logs on my nginx container.",
      "solution": "If `/var/log/access.log` is a symlink to stdout, it's not going to be available in the other container: `/dev/stdout` points to the stdout of the current process, so when `fail2ban` attempts to read from it, it gets its own stdout, rather than the stdout of the nginx process.\nIf you want `fail2ban` to be able to read the logs from nginx, you will need to write them to an actual file. If you also want them showing up on the container stdout, you can run something like a `tail -f` in the background of the nginx container.",
      "question_score": 4,
      "answer_score": 2,
      "created_at": "2021-08-01T12:54:42",
      "url": "https://stackoverflow.com/questions/68609694/how-to-implement-fail2ban-inside-a-docker-container-running-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 67099282,
      "title": "nginx-ingress on GKE fails to route to path for configured service",
      "problem": "I am trying to configure an nginx ingress for a GKE cluster and define a path on a configured subdomain. It seems that even if I am able to successfully ping the host, and the domain binding is done correctly, I keep getting a 404 back whenever I try to access the configured path.\nMy goal is to be able to have a single static IP configured for my ingress controller and expose multiple services on different paths.\nBelow you can find my deployment files - one more thing that I would add is that I am using Terraform to automate the configuration and deployment of GCP and Kubernetes resources.\nAfter the GKE cluster is successfully provisioned, I first deploy the official nginx-ingress controller from here - below my Terraform script that configures and deploys the controller with a custom static IP that I provisioned on GCP.\n```\n`resource \"helm_release\" \"nginx\" {\n  name  = \"nginx\"\n  chart = \"nginx-stable/nginx-ingress\"\n  timeout = 900\n\n  set {\n    name = \"controller.stats.enabled\"\n    value = true\n  }\n\n  set {\n    name  = \"controller.service.type\"\n    value = \"LoadBalancer\"\n  }\n\n  set {\n    name  = \"controller.service.loadBalancerIP\"\n    value = \"\"\n  }\n}\n`\n```\nBelow my ingress configuration that I also deploy via Terraform:\n```\n`resource \"kubernetes_ingress\" \"ingress\" {\n  wait_for_load_balancer = true\n\n  metadata {\n    name = \"app-ingress\"\n\n    annotations = {\n        \"kubernetes.io/ingress.class\": \"nginx\"\n        \"nginx.ingress.kubernetes.io/rewrite-target\": \"/\"\n        \"kubernetes.io/ingress.global-static-ip-name\": \n    }\n  }\n\n  spec {\n    rule {\n      host = custom.my_domain.com\n      http {\n        path {\n          backend {\n            service_name = \"app-service\"\n            service_port = 5000\n          }\n\n          path = \"/app\"\n        }\n      }\n    }\n  }\n}\n`\n```\nAnd the resulting ingress configuration as taken from GCP:\n```\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    kubernetes.io/ingress.global-static-ip-name: static-ip-name\n    nginx.ingress.kubernetes.io/rewrite-target: /\n  creationTimestamp: \"2021-04-14T20:28:41Z\"\n  generation: 7\n  name: app-ingress\n  namespace: default\n  resourceVersion: HIDDEN\n  selfLink: /apis/extensions/v1beta1/namespaces/default/ingresses/app-ingress\n  uid: HIDDEN\nspec:\n  rules:\n  - host: custom.my_domain.com\n    http:\n      paths:\n      - backend:\n          serviceName: app-service\n          servicePort: 5000\n        path: /app\nstatus:\n  loadBalancer:\n    ingress:\n    - ip: \n`\n```\nAnd the output for the `kubectl describe ingress app-ingress` command:\n```\n`Name:             app-ingress\nNamespace:        default\nAddress:          \nDefault backend:  default-http-backend:80 (192.168.10.8:8080)\nRules:\n  Host                  Path  Backends\n  ----                  ----  --------\n  custom.my_domain.com\n                        /app   app-service:5000 (192.168.10.11:5000)\nAnnotations:            kubernetes.io/ingress.class: nginx\n                        kubernetes.io/ingress.global-static-ip-name: static-ip-name\n                        nginx.ingress.kubernetes.io/rewrite-target: /\nEvents:\n  Type    Reason          Age                From                      Message\n  ----    ------          ----               ----                      -------\n  Normal  AddedOrUpdated  16m (x6 over 32m)  nginx-ingress-controller  Configuration for default/app-ingress was added or updated\n`\n```\nI deployed the application that I am trying to expose by using the following configuration files:\npvc.yaml\n```\n`apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: app-pvc\nspec:\n  accessModes:\n  - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: default\n`\n```\nservice.yaml\n```\n`apiVersion: v1\nkind: Service\nmetadata:\n  name: app-service\nspec:\n  type: NodePort\n  ports:\n    - port: 5000\n      targetPort: 5000\n      protocol: TCP\n      name: http\n`\n```\ndeployment.yaml\n```\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: app-deployment\nspec:\n  replicas: 1\n  template:\n    spec:\n      restartPolicy: Always\n      volumes:\n        - name: app-pvc\n          persistentVolumeClaim:\n            claimName: app-pvc\n      containers:\n      - name: app-container\n        image: \"eu.gcr.io//:VERSION_TAG\"\n        imagePullPolicy: IfNotPresent\n        ports:\n          - containerPort: 5000\n        livenessProbe:\n          tcpSocket:\n            port: 5000\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        readinessProbe:\n          tcpSocket:\n            port: 5000\n          initialDelaySeconds: 15\n          periodSeconds: 20\n        volumeMounts:\n          - mountPath: \"/data\"\n            name: app-pvc\n`\n```\nEverything gets deployed successfully, as I am able to directly connect to the application locally via the configured service by running the following command:\n```\n`kubectl port-forward service/app-service 5000:5000\n`\n```\nThis allows me to access the application in my browser and everything works as intended.\nTo make sure that `` that I configured is properly bound to `custom.my_domain.com`, I tried to ping the host and I do get the right response back:\n```\n`ping custom.my_domain.com\n\nPinging custom.my_domain.com [] with 32 bytes of data:\nReply from : bytes=32 time=36ms TTL=113\nReply from : bytes=32 time=37ms TTL=113\nReply from : bytes=32 time=36ms TTL=113\nReply from : bytes=32 time=45ms TTL=113\n\nPing statistics for :\n    Packets: Sent = 4, Received = 4, Lost = 0 (0% loss),\nApproximate round trip times in milli-seconds:\n    Minimum = 36ms, Maximum = 45ms, Average = 38ms\n`\n```\nEven if everything appears to be working as intended, whenever I try to navigate to `custom.my_domain.com/app` in my browser, I keep getting the following response in my browser, even after waiting for more than 30m to make sure that the ingress configuration has been properly registered on GCP:\n\nAnd this is the entry that shows up in the logs of my nginx-controller pod:\n```\n` - - [14/Apr/2021:21:18:10 +0000] \"GET /app/ HTTP/1.1\" 404 232 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:88.0) Gecko/20100101 Firefox/88.0\" \"-\"\n`\n```\nUPDATE #1\nIt appears that if I update my ingress to directly expose the targeted service on the `/` path, it works as intended. Below the updated configuration. Still, it appears that if I try to set any other path, it does not work.\n```\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    kubernetes.io/ingress.global-static-ip-name: static-ip-name\n    nginx.ingress.kubernetes.io/rewrite-target: /\n  creationTimestamp: \"2021-04-14T20:28:41Z\"\n  generation: 7\n  name: app-ingress\n  namespace: default\n  resourceVersion: HIDDEN\n  selfLink: /apis/extensions/v1beta1/namespaces/default/ingresses/app-ingress\n  uid: HIDDEN\nspec:\n  rules:\n  - host: custom.my_domain.com\n    http:\n      paths:\n      - backend:\n          serviceName: app-service\n          servicePort: 5000\n        path: /\nstatus:\n  loadBalancer:\n    ingress:\n    - ip: \n\n`\n```\nUpdate #2\nAfter going through the materials shared by @jccampanero in the comments section, I was able to get a working configuration.\nInstead of using nginx-stable which is referenced on the official nginx website, I used the one here and updated my Terraform script accordingly to use this one with the exact same configuration I had.\nAfterwards, I had to update my ingress by following the documentation here - below the updated configuration:\n```\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    kubernetes.io/ingress.global-static-ip-name: static-ip-name\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\n  creationTimestamp: \"2021-04-14T20:28:41Z\"\n  generation: 7\n  name: app-ingress\n  namespace: default\n  resourceVersion: HIDDEN\n  selfLink: /apis/extensions/v1beta1/namespaces/default/ingresses/app-ingress\n  uid: HIDDEN\nspec:\n  rules:\n  - host: custom.my_domain.com\n    http:\n      paths:\n      - backend:\n          serviceName: app-service\n          servicePort: 5000\n        path: /app(/|$)(.*)\nstatus:\n  loadBalancer:\n    ingress:\n    - ip: \n\n`\n```",
      "solution": "As indicated in the question comments and in the question itself, very well documented by @vladzam, two are the reasons of the problem.\nOn one hand, the nginx ingress controller available through the Helm `stable` channel seems to be deprecated in favor of the new `ingress-nginx` controller - please, see the Github repo and the official documentation.\nOn the other, it seems to be a problem related to the definition of the `Rewrite target` annotation. According to the docs:\n\nStarting in Version 0.22.0, ingress definitions using the annotation `nginx.ingress.kubernetes.io/rewrite-target` are not backwards compatible with previous versions. In Version 0.22.0 and beyond, any substrings within the request URI that need to be passed to the rewritten path must explicitly be defined in a capture group.\n\nAs a consequence, it is necessary to modify the definition of the ingress resource to take into account this change. For instance:\n`$ echo '\napiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\n  name: rewrite\n  namespace: default\nspec:\n  rules:\n  - host: rewrite.bar.com\n    http:\n      paths:\n      - backend:\n          serviceName: http-svc\n          servicePort: 80\n        path: /something(/|$)(.*)\n' | kubectl create -f -\n`\nThe question itself provides the exact ingress resource definition.",
      "question_score": 4,
      "answer_score": 1,
      "created_at": "2021-04-14T23:23:10",
      "url": "https://stackoverflow.com/questions/67099282/nginx-ingress-on-gke-fails-to-route-to-path-for-configured-service"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 65979766,
      "title": "Ingress with Nginx Controller not working, Address missing",
      "problem": "I have a Kubernetes Cluster running on a 1 master, 2 worker setup ob linux servers. I have a HAProxy forwarding my requests to Nginx Controllers. My complete setup is behind a corporate proxy. The DNS entry is enabled in this corporate proxy.\nRequests will get to the nginx controller, but wont be forwarded to the service.\nI installed the ingress controller as descibed by many tutorials with the files in https://github.com/kubernetes/ingress-nginx .\nI'm new to stack overflow, so if i should give more specific information just let me know. I hope someone can help me with my issue, thank you in advance :D\nMy Ingress with missing Address:\n```\n`Name:             app-ingress\nNamespace:        default\nAddress:\nDefault backend:  default-http-backend:80 ()\nRules:\n  Host                       Path  Backends\n  ----                       ----  --------\n  test.kubetest.lff.bybn.de\n                             /abc   app-service:80 (10.244.2.4:3000)\nAnnotations:                 kubernetes.io/ingress.class: nginx\nEvents:                      \n`\n```\nYaml Files of Deployment, Service and Ingress, IngressClass, ConfigMap\n```\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    run: app\n  name: app-blue\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      run: app\n      version: 0.0.1\n  template:\n    metadata:\n      labels:\n        run: app\n        version: 0.0.1\n    spec:\n      containers:\n      - name: app\n        image: errm/versions:0.0.1\n        ports:\n        - containerPort: 3000\n----\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: app-service\nspec:\n  selector:\n    run: app\n    version: 0.0.1\n  ports:\n  - name: http\n    port: 80\n    protocol: TCP\n    targetPort: 3000\n---\napiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: app-ingress\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: nginx\nspec:\n  rules:\n  - host: test.kubetest.lff.bybn.de\n    http:\n      paths:\n      - path: /abc\n        backend:\n          serviceName: app-service\n          servicePort: 80\n---\n\napiVersion: networking.k8s.io/v1beta1\nkind: IngressClass\nmetadata:\n  name: nginx\n  # annotations:\n  #   ingressclass.kubernetes.io/is-default-class: \"true\"\nspec:\n  controller: nginx.org/ingress-controller\n---\n\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: nginx-config\n  namespace: nginx-ingress\ndata:\n`\n```\nCurl from outside of the Cluster and Logs from Controller Pod\n```\n`curl test.kubetest.lff.bybn.de/abc\n% Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100    93    0    93    0     0      1      0 --:--:--  0:00:50 --:--:--    26504 Gateway Time-out\nThe server didn't respond in time.\n\nE0131 19:44:11.949261       1 reflector.go:138] /home/runner/work/kubernetes-ingress/kubernetes-ingress/internal/k8s/controller.go:574: Failed to watch *v1.Policy: failed to list *v1.Policy: the server could not find the requested resource (get policies.k8s.nginx.org)\nE0131 19:45:06.894791       1 reflector.go:138] /home/runner/work/kubernetes-ingress/kubernetes-ingress/internal/k8s/controller.go:574: Failed to watch *v1.Policy: failed to list *v1.Policy: the server could not find the requested resource (get policies.k8s.nginx.org)\nE0131 19:45:48.532075       1 reflector.go:138] /home/runner/work/kubernetes-ingress/kubernetes-ingress/internal/k8s/controller.go:574: Failed to watch *v1.Policy: failed to list *v1.Policy: the server could not find the requested resource (get policies.k8s.nginx.org)\n10.48.25.57 - - [31/Jan/2021:19:46:35 +0000] \"GET /abc HTTP/1.1\" 499 0 \"-\" \"curl/7.73.0\" \"-\"\nE0131 19:46:37.902444       1 reflector.go:138] /home/runner/work/kubernetes-ingress/kubernetes-ingress/internal/k8s/controller.go:574: Failed to watch *v1.Policy: failed to list *v1.Policy: the server could not find the requested resource (get policies.k8s.nginx.org)\nE0131 19:47:15.346193       1 reflector.go:138] /home/runner/work/kubernetes-ingress/kubernetes-ingress/internal/k8s/controller.go:574: Failed to watch *v1.Policy: failed to list *v1.Policy: the server could not find the requested resource (get policies.k8s.nginx.org)\nE0131 19:47:48.536636       1 reflector.go:138] /home/runner/work/kubernetes-ingress/kubernetes-ingress/internal/k8s/controller.go:574: Failed to watch *v1.Policy: failed to list *v1.Policy: the server could not find the requested resource (get policies.k8s.nginx.org)\nE0131 19:48:21.890770       1 reflector.go:138] /home/runner/work/kubernetes-ingress/kubernetes-ingress/internal/k8s/controller.go:574: Failed to watch *v1.Policy: failed to list *v1.Policy: the server could not find the requested resource (get policies.k8s.nginx.org)\n`\n```",
      "solution": "Looking at the Ingress definition, I see that it misses the ingress class. Either you defined an IngressClass annotated as the default class to use, or that may be the reason your Ingress is not working, at the moment.\nAn Ingress Class is basically a category which specify who needs to serve and manage the Ingress, this is necessary since in a cluster you can have more than one Ingress controller, each one with its rules and configurations.\nDepending on the Kubernetes version, the ingress class can be defined with an annotation on the ingress (before v1.18) such as:\n```\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: example-ingress\n  annotations:\n    kubernetes.io/ingress.class: nginx\nspec:\n  ...\n`\n```\nOr with a whole resource and then referred into the Ingress as shown in the documentation (https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-class)\nEven in new versions of Kubernetes, the old annotation may still be supported, depends on the controller.\nIf you are unsure on what ingress class you should use, that should be defined by the controller, you probably decided one when you installed it or you used the default one (which most of the times is nginx)",
      "question_score": 3,
      "answer_score": 10,
      "created_at": "2021-01-31T14:41:06",
      "url": "https://stackoverflow.com/questions/65979766/ingress-with-nginx-controller-not-working-address-missing"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 73699940,
      "title": "Nginx-Ingress not picking up certificate from cert-manager",
      "problem": "I'm currently trying to setup an application in K8S behind an nginx-ingress. The Certs should be generated by cert-manager and Let's Encrypt (Staging for now).\nThe application is in namespace prod, nginx-ingress-controller in namespace nginx and cert-manager lives in cert-manager namespace.\nWe setup a ClusterIssuer for Let's Encrypt staging and successfully generated a certificate (we can see it in the secrets and certificate resource). However, nginx-ingress-controller is still answering with the Kubernetes Ingress Controller Fake Certificate.\nHere are some technical details:\nIngress\n```\n`\u276f kubectl describe ingress/forgerock\nName:             forgerock\nLabels:           \nNamespace:        prod\nAddress:          someaws-id.elb.eu-central-1.amazonaws.com\nIngress Class:    \nDefault backend:  \nTLS:\n  sslcertciam terminates ciam.test.fancycorp.com\nRules:\n  Host                Path  Backends\n  ----                ----  --------\n  ciam.test.fancycorp.com\n                      /am/json/authenticate                                             am:80 (10.0.2.210:8081)\n                      ...\n                      /am/extlogin                                                      am:80 (10.0.2.210:8081)\nAnnotations:          cert-manager.io/cluster-issuer: letsencrypt-stage\n                      haproxy.router.openshift.io/cookie_name: route\n                      kubernetes.io/ingress.class: nginx\n                      nginx.ingress.kubernetes.io/affinity: cookie\n                      nginx.ingress.kubernetes.io/body-size: 64m\n                      nginx.ingress.kubernetes.io/enable-cors: false\n                      nginx.ingress.kubernetes.io/proxy-body-size: 64m\n                      nginx.ingress.kubernetes.io/proxy-buffer-size: 16k\n                      nginx.ingress.kubernetes.io/proxy-read-timeout: 600\n                      nginx.ingress.kubernetes.io/proxy-send-timeout: 600\n                      nginx.ingress.kubernetes.io/send-timeout: 600\n                      nginx.ingress.kubernetes.io/session-cookie-hash: sha1\n                      nginx.ingress.kubernetes.io/session-cookie-name: route\n                      nginx.ingress.kubernetes.io/ssl-redirect: true\nEvents:               \n`\n```\nIssuer:\n```\n`\u276f kubectl describe clusterissuer/letsencrypt-stage\nName:         letsencrypt-stage\nNamespace:\nLabels:       \nAnnotations:  \nAPI Version:  cert-manager.io/v1\nKind:         ClusterIssuer\nMetadata:\n  Creation Timestamp:  2022-09-12T07:26:05Z\n  Generation:          1\n  Managed Fields:\n    API Version:  cert-manager.io/v1\n    Fields Type:  FieldsV1\n    fieldsV1:\n      f:metadata:\n        f:annotations:\n          .:\n          f:kubectl.kubernetes.io/last-applied-configuration:\n      f:spec:\n        .:\n        f:acme:\n          .:\n          f:email:\n          f:privateKeySecretRef:\n            .:\n            f:name:\n          f:server:\n          f:solvers:\n    Manager:      kubectl-client-side-apply\n    Operation:    Update\n    Time:         2022-09-12T07:26:05Z\n    API Version:  cert-manager.io/v1\n    Fields Type:  FieldsV1\n    fieldsV1:\n      f:status:\n        .:\n        f:acme:\n          .:\n          f:lastRegisteredEmail:\n          f:uri:\n        f:conditions:\n    Manager:         controller\n    Operation:       Update\n    Subresource:     status\n    Time:            2022-09-12T07:26:06Z\n  Resource Version:  17749318\n  UID:               fcbcbfff-b875-4ac4-805b-65ab0b4e1a93\nSpec:\n  Acme:\n    Email:            admin@fancycorp.com\n    Preferred Chain:\n    Private Key Secret Ref:\n      Name:  letsencrypt-stage\n    Server:  https://acme-staging-v02.api.letsencrypt.org/directory\n    Solvers:\n      http01:\n        Ingress:\n          Class:  nginx\nStatus:\n  Acme:\n    Last Registered Email:  admin@fancycorp.com\n    Uri:                    https://acme-staging-v02.api.letsencrypt.org/acme/acct/68184363\n  Conditions:\n    Last Transition Time:  2022-09-12T07:26:06Z\n    Message:               The ACME account was registered with the ACME server\n    Observed Generation:   1\n    Reason:                ACMEAccountRegistered\n    Status:                True\n    Type:                  Ready\nEvents:                    \n`\n```\nCertificate:\n```\n`\u276f kubectl describe cert/sslcertciam\nName:         sslcertciam\nNamespace:    prod\nLabels:       \nAnnotations:  \nAPI Version:  cert-manager.io/v1\nKind:         Certificate\nMetadata:\n  Creation Timestamp:  2022-09-12T07:40:04Z\n  Generation:          1\n  Managed Fields:\n    API Version:  cert-manager.io/v1\n    Fields Type:  FieldsV1\n    fieldsV1:\n      f:metadata:\n        f:ownerReferences:\n          .:\n          k:{\"uid\":\"2a0af8f2-8166-4a8e-bb50-fd0aa906f844\"}:\n      f:spec:\n        .:\n        f:dnsNames:\n        f:issuerRef:\n          .:\n          f:group:\n          f:kind:\n          f:name:\n        f:secretName:\n        f:usages:\n    Manager:      controller\n    Operation:    Update\n    Time:         2022-09-12T07:40:04Z\n    API Version:  cert-manager.io/v1\n    Fields Type:  FieldsV1\n    fieldsV1:\n      f:status:\n        .:\n        f:conditions:\n        f:notAfter:\n        f:notBefore:\n        f:renewalTime:\n        f:revision:\n    Manager:      controller\n    Operation:    Update\n    Subresource:  status\n    Time:         2022-09-12T07:40:07Z\n  Owner References:\n    API Version:           networking.k8s.io/v1\n    Block Owner Deletion:  true\n    Controller:            true\n    Kind:                  Ingress\n    Name:                  forgerock\n    UID:                   2a0af8f2-8166-4a8e-bb50-fd0aa906f844\n  Resource Version:        17753197\n  UID:                     2484d1fe-5b80-4cbc-b2f8-7f4276e15a37\nSpec:\n  Dns Names:\n    ciam.test.fancycorp.com\n  Issuer Ref:\n    Group:      cert-manager.io\n    Kind:       ClusterIssuer\n    Name:       letsencrypt-stage\n  Secret Name:  sslcertciam\n  Usages:\n    digital signature\n    key encipherment\nStatus:\n  Conditions:\n    Last Transition Time:  2022-09-12T07:40:07Z\n    Message:               Certificate is up to date and has not expired\n    Observed Generation:   1\n    Reason:                Ready\n    Status:                True\n    Type:                  Ready\n  Not After:               2022-12-11T06:40:05Z\n  Not Before:              2022-09-12T06:40:06Z\n  Renewal Time:            2022-11-11T06:40:05Z\n  Revision:                1\nEvents:                    \n`\n```\nSecret:\n```\n`\u276f kubectl describe secret/sslcertciam\nName:         sslcertciam\nNamespace:    prod\nLabels:       \nAnnotations:  cert-manager.io/alt-names: ciam.test.fancycorp.com\n              cert-manager.io/certificate-name: sslcertciam\n              cert-manager.io/common-name: ciam.test.fancycorp.com\n              cert-manager.io/ip-sans:\n              cert-manager.io/issuer-group: cert-manager.io\n              cert-manager.io/issuer-kind: ClusterIssuer\n              cert-manager.io/issuer-name: letsencrypt-stage\n              cert-manager.io/uri-sans:\n\nType:  kubernetes.io/tls\n\nData\n====\ntls.crt:  5741 bytes\ntls.key:  1675 bytes\n`\n```\nCertificate Request:\n```\n`\u276f kubectl describe certificaterequests/sslcertciam-p6qpg\nName:         sslcertciam-p6qpg\nNamespace:    prod\nLabels:       \nAnnotations:  cert-manager.io/certificate-name: sslcertciam\n              cert-manager.io/certificate-revision: 1\n              cert-manager.io/private-key-secret-name: sslcertciam-ztc8q\nAPI Version:  cert-manager.io/v1\nKind:         CertificateRequest\nMetadata:\n  Creation Timestamp:  2022-09-12T07:40:05Z\n  Generate Name:       sslcertciam-\n  Generation:          1\n  Managed Fields:\n    API Version:  cert-manager.io/v1\n    Fields Type:  FieldsV1\n    fieldsV1:\n      f:metadata:\n        f:annotations:\n          .:\n          f:cert-manager.io/certificate-name:\n          f:cert-manager.io/certificate-revision:\n          f:cert-manager.io/private-key-secret-name:\n        f:generateName:\n        f:ownerReferences:\n          .:\n          k:{\"uid\":\"2484d1fe-5b80-4cbc-b2f8-7f4276e15a37\"}:\n      f:spec:\n        .:\n        f:issuerRef:\n          .:\n          f:group:\n          f:kind:\n          f:name:\n        f:request:\n        f:usages:\n    Manager:      controller\n    Operation:    Update\n    Time:         2022-09-12T07:40:05Z\n    API Version:  cert-manager.io/v1\n    Fields Type:  FieldsV1\n    fieldsV1:\n      f:status:\n        .:\n        f:certificate:\n        f:conditions:\n    Manager:      controller\n    Operation:    Update\n    Subresource:  status\n    Time:         2022-09-12T07:40:06Z\n  Owner References:\n    API Version:           cert-manager.io/v1\n    Block Owner Deletion:  true\n    Controller:            true\n    Kind:                  Certificate\n    Name:                  sslcertciam\n    UID:                   2484d1fe-5b80-4cbc-b2f8-7f4276e15a37\n  Resource Version:        17753174\n  UID:                     2289de7b-f43f-4859-816b-b4a9794846ec\nSpec:\n  Extra:\n    authentication.kubernetes.io/pod-name:\n      cert-manager-75947cd847-7gndz\n    authentication.kubernetes.io/pod-uid:\n      91415540-9113-4456-86d2-a0e28478718a\n  Groups:\n    system:serviceaccounts\n    system:serviceaccounts:cert-manager\n    system:authenticated\n  Issuer Ref:\n    Group:  cert-manager.io\n    Kind:   ClusterIssuer\n    Name:   letsencrypt-stage\n  Request:  xxx\n  UID:      5be755b9-711c-49ac-a962-6b3a3f80d16e\n  Usages:\n    digital signature\n    key encipherment\n  Username:  system:serviceaccount:cert-manager:cert-manager\nStatus:\n  Certificate:  \n  Conditions:\n    Last Transition Time:  2022-09-12T07:40:05Z\n    Message:               Certificate request has been approved by cert-manager.io\n    Reason:                cert-manager.io\n    Status:                True\n    Type:                  Approved\n    Last Transition Time:  2022-09-12T07:40:06Z\n    Message:               Certificate fetched from issuer successfully\n    Reason:                Issued\n    Status:                True\n    Type:                  Ready\nEvents:                    \n`\n```\nCurl:\n```\n`\u276f curl -v https://ciam.test.fancycorp.com/am/extlogin/ -k\n*   Trying xxx.xxx.xxx.xxx:443...\n* Connected to ciam.test.fancycorp.com (xxx.xxx.xxx.xxx) port 443 (#0)\n* ALPN, offering h2\n* ALPN, offering http/1.1\n* successfully set certificate verify locations:\n*  CAfile: /etc/ssl/cert.pem\n*  CApath: none\n* (304) (OUT), TLS handshake, Client hello (1):\n* (304) (IN), TLS handshake, Server hello (2):\n* (304) (IN), TLS handshake, Unknown (8):\n* (304) (IN), TLS handshake, Certificate (11):\n* (304) (IN), TLS handshake, CERT verify (15):\n* (304) (IN), TLS handshake, Finished (20):\n* (304) (OUT), TLS handshake, Finished (20):\n* SSL connection using TLSv1.3 / AEAD-AES256-GCM-SHA384\n* ALPN, server accepted to use h2\n* Server certificate:\n*  subject: O=Acme Co; CN=Kubernetes Ingress Controller Fake Certificate\n*  start date: Sep 12 07:43:15 2022 GMT\n*  expire date: Sep 12 07:43:15 2023 GMT\n*  issuer: O=Acme Co; CN=Kubernetes Ingress Controller Fake Certificate\n*  SSL certificate verify result: unable to get local issuer certificate (20), continuing anyway.\n* Using HTTP2, server supports multiplexing\n* Connection state changed (HTTP/2 confirmed)\n* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0\n* Using Stream ID: 1 (easy handle 0x126811e00)\n> GET /am/extlogin/ HTTP/2\n> Host: ciam.test.fancycorp.com\n> user-agent: curl/7.79.1\n> accept: */*\n...\n`\n```\n\nUpdate 1:\nWhen running `kubectl ingress-nginx certs --host ciam.test.fancycorp.com`, I am also getting the Fake Certificate returned.",
      "solution": "Found the issue and solution...\nThere was another ingress defined in another namespace that did define the same hostname, but failed to link to a proper secret with the TLS cert. When I deleted that one, it immediately worked.\nLessons learned: Be aware of impacts from other namespaces!",
      "question_score": 3,
      "answer_score": 6,
      "created_at": "2022-09-13T10:38:50",
      "url": "https://stackoverflow.com/questions/73699940/nginx-ingress-not-picking-up-certificate-from-cert-manager"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 67800296,
      "title": "Kubernetes NGINX Ing\u0155ess controller TCP / MQTT config",
      "problem": "I have an Kubernetes Cluster with a working Ingress config for one REST API. Now I want to add a port forward to my mqtt adapter to this config, but I have problems finding a way to add an TCP rule to the config. The Kubernetes docs only show a HTTP example. https://kubernetes.io/docs/concepts/services-networking/ingress/\nI'm pretty new to Kubernetes and I have problems adapting other configs, because whatever I find looks totally different from that what I found in the Kubernetes Docs.\nI have used a regular nginx webserver with letsencrypt to secure TCP connections. I hope this works with the ingress controller, too.\nMy goal is to send messages via MQTT with TLS to my cluster.\nDoes someone have the right docs for this or knows how to add the config?\nMy config looks like this:\n```\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: ratings-web-ingress\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt\nspec:\n  tls:\n    - hosts: \n      - example.com\n      secretName: ratings-web-cert\n  \n  rules:\n  - host: example.com\n    http:\n      paths:\n      - backend:\n          serviceName: test-api\n          servicePort: 8080\n        path: /\n`\n```",
      "solution": "the Ingress system only handles HTTP traffic in general. A few Ingress Controllers support custom extensions for non-HTTP packet handling but it's different for each. https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/ shows how to do this specifically for ingress-nginx, as shown there you configure it entirely out of band via some ConfigMaps, not via the Ingress object(s).\nWhat you probably actually want is a LoadBalancer type Service object instead.",
      "question_score": 3,
      "answer_score": 6,
      "created_at": "2021-06-02T08:55:41",
      "url": "https://stackoverflow.com/questions/67800296/kubernetes-nginx-ing%c5%95ess-controller-tcp-mqtt-config"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70011639,
      "title": "Ingress not forwarding the requests - Docker desktop for Windows and kubernetes",
      "problem": "EDIT:\nI deleted minikube, enabled kubernetes in Docker desktop for Windows and installed `ingress-nginx` manually.\n```\n`$helm upgrade --install ingress-nginx ingress-nginx --repo https://kubernetes.github.io/ingress-nginx --namespace ingress-nginx --create-namespace\nRelease \"ingress-nginx\" does not exist. Installing it now.\nError: rendered manifests contain a resource that already exists. Unable to continue with install: ServiceAccount \"ingress-nginx\" in namespace \"ingress-nginx\" exists and cannot be imported into the current release: invalid ownership metadata; annotation validation error: missing key \"meta.helm.sh/release-name\": must be set to \"ingress-nginx\"; annotation validation error: missing key \"meta.helm.sh/release-namespace\": must be set to \"ingress-nginx\"\n`\n```\nIt gave me an error but I think it's because I did it already before because:\n```\n`$kubectl get svc -n ingress-nginx\nNAME                                 TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE\ningress-nginx-controller             LoadBalancer   10.106.222.233   localhost     80:30199/TCP,443:31093/TCP   11m\ningress-nginx-controller-admission   ClusterIP      10.106.52.106            443/TCP                      11m\n`\n```\nThen applied all my yaml files again but this time ingress is not getting any address:\n```\n`$kubectl get ing\nNAME                CLASS    HOSTS       ADDRESS   PORTS   AGE\nmyapp-ingress          myapp.com             80      10m\n`\n```\n\nI am using docker desktop (windows) and installed nginx-ingress controller via minikube addons enable command:\n```\n`$kubectl get pods -n ingress-nginx\nNAME                                        READY   STATUS      RESTARTS   AGE\ningress-nginx-admission-create--1-lp4md     0/1     Completed   0          67m\ningress-nginx-admission-patch--1-jdkn7      0/1     Completed   1          67m\ningress-nginx-controller-5f66978484-6mpfh   1/1     Running     0          67m\n`\n```\nAnd applied all my yaml files:\n```\n`$kubectl get svc --all-namespaces -o wide\nNAMESPACE       NAME                                 TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE   SELECTOR\ndefault         event-service-svc                    ClusterIP      10.108.251.79            80/TCP                       16m   app=event-service-app\ndefault         kubernetes                           ClusterIP      10.96.0.1                443/TCP                      16m   \ndefault         mssql-clusterip-srv                  ClusterIP      10.98.10.22              1433/TCP                     16m   app=mssql\ndefault         mssql-loadbalancer                   LoadBalancer   10.109.106.174        1433:31430/TCP               16m   app=mssql\ndefault         user-service-svc                     ClusterIP      10.111.128.73            80/TCP                       16m   app=user-service-app\ningress-nginx   ingress-nginx-controller             NodePort       10.101.112.245           80:31583/TCP,443:30735/TCP   68m   app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx\ningress-nginx   ingress-nginx-controller-admission   ClusterIP      10.105.169.167           443/TCP                      68m   app.kubernetes.io/component=controller,app.kubernetes.io/instance=ingress-nginx,app.kubernetes.io/name=ingress-nginx\nkube-system     kube-dns                             ClusterIP      10.96.0.10               53/UDP,53/TCP,9153/TCP       72m   k8s-app=kube-dns\n`\n```\nAll pods and services seems to be running properly. Checked the pod logs, all migrations etc. has worked and app is up and running. But when I try to send an HTTP request, I get a socket hang up error. I've checked all the logs for all pods, couldn't find anything useful.\n```\n`$kubectl get ingress\nNAME                CLASS   HOSTS           ADDRESS     PORTS   AGE\nmyapp-ingress   nginx   myapp.com       localhost   80      74s\n`\n```\nThis one is also a bit weird, I was expecting ADRESS to be set to an IP not to localhost. So adding 127.0.0.1 entry for myapp.com in /etc/hosts also didn't seem so right.\nMy question here is what I might be doing wrong? Or how can I even trace where are my requests are being forwarded to?\ningress-svc.yaml\n```\n`  apiVersion: networking.k8s.io/v1\n    kind: Ingress\n    metadata:\n      name: myapp-ingress\n    spec:\n      rules:\n      - host: myapp.com\n        http:\n          paths:\n          - path: /api/Users\n            pathType: Prefix\n            backend:\n              service:\n                name: user-service-svc\n                port:\n                  number: 80\n          - path: /api/Events\n            pathType: Prefix\n            backend:\n              service:\n                name: event-service-svc\n                port:\n                  number: 80\n`\n```\nevents-depl.yaml:\n```\n`  apiVersion: apps/v1\n    kind: Deployment\n    metadata:\n      name: event-service-app\n      labels:\n        app: event-service-app\n    spec:\n      replicas: 1\n      selector:\n        matchLabels:\n          app: event-service-app\n      template:\n        metadata:\n          labels:\n            app: event-service-app\n        spec:\n          containers:\n            - name: event-service-app\n              image: ghcr.io/myapp/event-service:master\n              imagePullPolicy: Always\n              ports:\n                - containerPort: 80\n          imagePullSecrets:\n            - name: myapp\n    ---\n    apiVersion: v1\n    kind: Service\n    metadata:\n      name: event-service-svc\n    spec:\n      selector:\n        app: event-service-app\n      ports:\n        - protocol: TCP\n          port: 80\n          targetPort: 80\n`\n```",
      "solution": "Reproduction\nI reproduced the case using minikube `v1.24.0`, Docker desktop `4.2.0`, engine `20.10.10`\nFirst, `localhost` in ingress appears due to logic, it doesn't really matter what IP address is behind the domain in `/etc/hosts`, I added a different one for testing and still it showed localhost. Only `metallb` will provide an IP address from set up network.\nWhat happens\nWhen minikube driver is `docker`, minikube creates a big container (VM) where kubernetes components are run. This can be checked by running `docker ps` command in host system:\n```\n`$ docker ps\n\nCONTAINER ID   IMAGE                                 COMMAND                  CREATED          STATUS          PORTS                                                                                                                                  NAMES\nf087dc669944   gcr.io/k8s-minikube/kicbase:v0.0.28   \"/usr/local/bin/entr\u2026\"   16 minutes ago   Up 16 minutes   127.0.0.1:59762->22/tcp, 127.0.0.1:59758->2376/tcp, 127.0.0.1:59760->5000/tcp, 127.0.0.1:59761->8443/tcp, 127.0.0.1:59759->32443/tcp   minikube\n`\n```\nAnd then `minikube ssh` to get inside this container and run `docker ps` to see all kubernetes containers.\nMoving forward. Before introducing `ingress`, it's already clear that even `NodePort` doesn't work as intended. Let's check it.\nThere are two ways to get `minikube VM IP`:\n\nrun `minikube IP`\n`kubectl get nodes -o wide` and find the node's IP\n\nWhat should happen next with `NodePort` is requests should go to `minikube_IP:Nodeport` while it doesn't work. It happens because docker containers inside the minikube VM are not exposed outside of the cluster which is another docker container.\nOn `minikube` to access services within cluster there is a special command - `minikube service %service_name%` which will create a direct tunnel to the service inside the `minikube VM` (you can see that it contains `service URL` with `NodePort` which is supposed to be working):\n```\n`$ minikube service echo\n\n|-----------|------|-------------|---------------------------|\n| NAMESPACE | NAME | TARGET PORT |            URL            |\n|-----------|------|-------------|---------------------------|\n| default   | echo |        8080 | http://192.168.49.2:32034 |\n|-----------|------|-------------|---------------------------|\n* Starting tunnel for service echo.\n|-----------|------|-------------|------------------------|\n| NAMESPACE | NAME | TARGET PORT |          URL           |\n|-----------|------|-------------|------------------------|\n| default   | echo |             | http://127.0.0.1:61991 |\n|-----------|------|-------------|------------------------|\n* Opening service default/echo in default browser...\n! Because you are using a Docker driver on windows, the terminal needs to be open to run it\n`\n```\nAnd now it's available on host machine:\n```\n`$ curl http://127.0.0.1:61991/\n\nStatusCode        : 200\nStatusDescription : OK\n`\n```\nAdding ingress\nMoving forward and adding ingress.\n```\n`$ minikube addons enable ingress\n$ kubectl get svc -A\n\nNAMESPACE       NAME                                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\ndefault         echo                                 NodePort    10.111.57.237           8080:32034/TCP               25m\ningress-nginx   ingress-nginx-controller             NodePort    10.104.52.175           80:31041/TCP,443:31275/TCP   2m12s\n`\n```\nTrying to get any response from `ingress` by hitting `minikube_IP:NodePort` with no luck:\n```\n`$ curl 192.168.49.2:31041\n\ncurl : Unable to connect to the remote server\nAt line:1 char:1\n+ curl 192.168.49.2:31041\n`\n```\nTrying to create a tunnel with `minikube service` command:\n```\n`$ minikube service ingress-nginx-controller -n ingress-nginx\n\n|---------------|--------------------------|-------------|---------------------------|\n|   NAMESPACE   |           NAME           | TARGET PORT |            URL            |\n|---------------|--------------------------|-------------|---------------------------|\n| ingress-nginx | ingress-nginx-controller | http/80     | http://192.168.49.2:31041 |\n|               |                          | https/443   | http://192.168.49.2:31275 |\n|---------------|--------------------------|-------------|---------------------------|\n* Starting tunnel for service ingress-nginx-controller.\n|---------------|--------------------------|-------------|------------------------|\n|   NAMESPACE   |           NAME           | TARGET PORT |          URL           |\n|---------------|--------------------------|-------------|------------------------|\n| ingress-nginx | ingress-nginx-controller |             | http://127.0.0.1:62234 |\n|               |                          |             | http://127.0.0.1:62235 |\n|---------------|--------------------------|-------------|------------------------|\n* Opening service ingress-nginx/ingress-nginx-controller in default browser...\n* Opening service ingress-nginx/ingress-nginx-controller in default browser...\n! Because you are using a Docker driver on windows, the terminal needs to be open to run it.\n`\n```\nAnd getting `404` from `ingress-nginx` which means we can send requests to ingress:\n```\n`$ curl http://127.0.0.1:62234\n\ncurl : 404 Not Found\nnginx\nAt line:1 char:1\n+ curl http://127.0.0.1:62234\n`\n```\nSolutions\nAbove I explained what happens. Here are three solutions how to get it work:\n\nUse another minikube driver (e.g. virtualbox. I used `hyperv` since my laptop has windows 10 pro)\n\n`minikube ip` will return \"normal\" IP address of virtual machine and all network functionality will work just fine. You will need to add this IP address into `/etc/hosts` for domain used in ingress rule\nNote! Even though `localhost` was shown in `kubectl get ing ingress` output in `ADDRESS`.\n\nUse built-in kubernetes feature in Docker desktop for Windows.\n\nYou will need to manually install `ingress-nginx` and change `ingress-nginx-controller` service type from `NodePort` to `LoadBalancer` so it will be available on `localhost` and will be working. Please find my another answer about Docker desktop for Windows\n\n(testing only) - use port-forward\n\nIt's almost exactly the same idea as `minikube service` command. But with more control. You will open a tunnel from host VM port `80` to `ingress-nginx-controller` service (eventually pod) on port `80` as well. `/etc/hosts` should contain `127.0.0.1 test.domain` entity.\n```\n`$ kubectl port-forward service/ingress-nginx-controller -n ingress-nginx 80:80\n\nForwarding from 127.0.0.1:80 -> 80\nForwarding from [::1]:80 -> 80\n`\n```\nAnd testing it works:\n```\n`$ curl test.domain\n\nStatusCode        : 200\nStatusDescription : OK\n`\n```\nUpdate for kubernetes in docker desktop on windows and ingress:\nOn modern `ingress-nginx` versions `.spec.ingressClassName` should be added to ingress rules. See last updates, so ingress rule should look like:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\n...\nspec:\n  ingressClassName: nginx # can be checked by kubectl get ingressclass\n  rules:\n  - host: myapp.com\n    http:\n      ...\n`\n```",
      "question_score": 3,
      "answer_score": 5,
      "created_at": "2021-11-17T22:15:10",
      "url": "https://stackoverflow.com/questions/70011639/ingress-not-forwarding-the-requests-docker-desktop-for-windows-and-kubernetes"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 79139090,
      "title": "Strip suffix from Host header in k8s nginx ingress?",
      "problem": "The short version:\nThis is something we do with HAProxy. What is the equivalent for nginx when used as an kubernetes ingress?\n```\n`       acl is_extra hdr_end(host) .extra\n       http-request replace-header Host (.*)\\.extra$ \\1 if is_extra\n`\n```\nThe long version:\nHow can we strip a suffix from the host header in our HTTP requests?\nIn an HTTP request, the Host header matches `*.example.com`.  For example:\n\n`foo.example.com`\n`bar.example.com`\n\nHowever we also need to be able to receive hostnames with a `.extra` suffix:\n\n`foo.example.com.extra`\n`bar.example.com.extra`\n\nThe legacy apps can't understand the `.extra` notation, so we need to rewrite the `Host` header and strip the `.extra` suffix.\nIf there were only 2 such hosts, we could simply make 2 rewrite rules, one for `foo` and one for `bar`.\nSomething like:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: foo-extra\n  annotations:\n    nginx.ingress.kubernetes.io/upstream-vhost: foo.example.com\nspec:\n  ingressClassName: nginx-internal\n  rules:\n  - host: \"foo.example.com.extra\"\n    http:\n      ...\n      ...\n---\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: bar-extra\n  annotations:\n    nginx.ingress.kubernetes.io/upstream-vhost: bar.example.com\nspec:\n  ingressClassName: nginx-internal\n  rules:\n  - host: \"bar.example.com.extra\"\n    http:\n      ...\n      ...\n`\n```\nHowever the list of hosts is very large and changes frequently. Therefore, we need something dynamic.\nFor example, something like (fictional)\n```\n`    - host: \"*.example.com.extra\"\n      fictional-rewrite-host-with-regex: \"$1.example.com\"\n`\n```\nOr even \"something that magically strips the last 6 chars:\n```\n`    - host: \"*.example.com.extra\"\n      fictional-strip-last-chars-from-header: \"6\"\n`\n```",
      "solution": "For a stand-alone instance of NGINX, the way you would do this is to create a `map` in the `http` section of the configuration, which will allow you to create new variables from existing values. To change the `host` header, you would use the `$http_host` variable. You can then use a regex to capture part of the existing `host` value and write it to a new variable.\n```\n`map $http_host $modified_host {\n    \"~^(.*)\\.extra$\" \"$1\";\n    default $http_host;\n}\n`\n```\nThen this new variable can be used in the `location` section of the configuration to overwrite the host header using the `proxy_set_header` directive.\n```\n`location / {\n    proxy_set_header Host $modified_host;\n}\n`\n```\nSo the full configuration could look something like this.\n```\n`...\n\nhttp {\n    ...\n\n    map $http_host $modified_host {\n        \"~^(.*)\\.extra$\" \"$1\";\n        default $http_host;\n    }\n    \n    server {\n        ...\n\n        location / {\n            proxy_set_header Host $modified_host;\n        }\n    }\n}\n`\n```\nFrom there we just need to look at how to transpose these configuration values into  `ingress-nginx` so the controller will build the configuration that we want.\nSince map/variables are global they will have to be pushed as configuration to the controller itself. This can be done as an `http-snippet` in the ConfigMap of the controller. Since I'm using Helm to configure the controller I can pass it in via a values file that looks like this.\n```\n`controller:\n  config:\n    http-snippet: |\n      map $http_host $modified_host {\n        \"~^(.*)\\.extra$\" \"$1\";\n        default $http_host;\n      }\n`\n```\nOnce this is deployed, the new variable can be consumed using an annotation on the ingress object. The `nginx.ingress.kubernetes.io/upstream-vhost` annotation corresponds to the `proxy_set_header` directive in the native NGINX config. So the ingress object would look something like this.\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: extra-example\n  annotations:\n    nginx.ingress.kubernetes.io/upstream-vhost: $modified_host\nspec:\n  ingressClassName: ingress-nginx\n  rules:\n  - host: \"bar.example.com.extra\"\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: extra-example\n            port:\n              number: 80\n\n`\n```\nA negative aspect to this approach is that you must update the controller as well as the ingress object. In some cases, this might need to be done by two different people or teams, depending on cluster permissions. One useful thing I found in testing, is that the validation webhook will reject the ingress object if it tries to use a variable that hasn't been deployed to the controller yet. So you can be confident, if the ingress deploys successfully, that the controller configuration has also been updated.",
      "question_score": 3,
      "answer_score": 4,
      "created_at": "2024-10-29T22:46:41",
      "url": "https://stackoverflow.com/questions/79139090/strip-suffix-from-host-header-in-k8s-nginx-ingress"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 75607980,
      "title": "Ingress with IP address instead of host",
      "problem": "I'm self-hosting a few applications on my NAS, like tt-rss. I normally run them with docker-compose. To access an app like this when I'm not on my local network, I point a port of my home router to the port of my NAS where the app is running, and then I can just access the app through `htpp://public_ip_router_here:port_number/tt-rss`.\nI decided to move these apps to a k8s cluster. For \"fun\", but also because I can setup my ingress controller to do the TLS termination, and I would unlock https for all my apps.\nThe cluster is running (provisioned with microk8s). TLS works too, with some conditions:\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: fanout-ingress\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: fancy_domain.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: api\n            port:\n              number: 8080\n        path: /\n        pathType: ImplementationSpecific\n  tls:\n  - hosts:\n    - fancy_domain.com\n    secretName: tls-secret\n`\nIf I modify my `/etc/hosts` file (I run Linux), and put this inside:\n```\n`192.168.0.203 fancy_domain.com\n`\n```\nI can access my service through `https://fancy_domain.com`. This works perfectly, but it's a bit annoying because it would force me to modify my `/etc/hosts` file on all the devices I use. Is there a way to use an IP address instead of hostname? Or any workaround really, as long as I can do the fanout and keep the TLS termination.\nI tried something like this but weirdly, I'm getting a 404 error then:\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: minimal-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx-example\n  rules:\n  - http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: api\n            port:\n              number: 8080\n  tls:\n  - hosts:\n    - 192.168.0.203\n    secretName: tls-secret\n`",
      "solution": "Well I can't use an IP in the ingress, but:\n\nI created a self-signed certificate for a random domain name\nI put the certificate into a secret\nI built my ingress using the random domain name\nI modified the `/etc/hosts` files of all the devices that had to access the domain name. On Android, \"Virtual Hosts\" works like a charm\n\nThis works perfectly for a test setup.",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2023-03-01T20:10:45",
      "url": "https://stackoverflow.com/questions/75607980/ingress-with-ip-address-instead-of-host"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70677589,
      "title": "How to use aws nlb with nginx ingress controller for ssl",
      "problem": "I have attached AWS ACM provided SSL certificate to NLB. NLB will forward request to nginx ingress. Nginx is giving me the following error. `The plain HTTP request was sent to HTTPS port`.\nI have set the following annotation in nginx ingress.\n\nnginx.ingress.kubernetes.io/force-ssl-redirect: false\nnginx.ingress.kubernetes.io/ssl-redirect: false\n\nI have set following annotation in nginx ingress service which is running behind NLB.\n\nservice.beta.kubernetes.io/aws-load-balancer-backend-protocol: http\nservice.beta.kubernetes.io/aws-load-balancer-ssl-cert: \"certificate arn\"\nservice.beta.kubernetes.io/aws-load-balancer-ssl-ports: https\nservice.beta.kubernetes.io/aws-load-balancer-type: nlb",
      "solution": "For this error :\n\nThe plain HTTP request was sent to HTTPS port\n\nChange your port configuration in Nginx service like, your target port in HTTPS section should be http instead of https\n```\n`ports:\n  - name: https\n    **targetPort: http**\n`\n```\nHere the annotation for reference\n```\n`service.beta.kubernetes.io/aws-load-balancer-backend-protocol: tcp\nservice.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: \"60\"\nservice.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: \"true\"\nservice.beta.kubernetes.io/aws-load-balancer-ssl-cert: arn:aws:acm:ap-southeast-1:xxxxxxx:certificate/8991ftt8-69e0-4e7d-1164-yy0aae19da90v\nservice.beta.kubernetes.io/aws-load-balancer-type: nlb\n`\n```",
      "question_score": 3,
      "answer_score": 5,
      "created_at": "2022-01-12T08:13:10",
      "url": "https://stackoverflow.com/questions/70677589/how-to-use-aws-nlb-with-nginx-ingress-controller-for-ssl"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70469602,
      "title": "nginx.ingress.kubernetes.io/server-snippet annotation contains invalid word location",
      "problem": "I am new to kubernetes and using AWS EKS cluster 1.21. I am trying to write the nginx ingress config for my k8s cluster and blocking some request using server-snippet. My ingress config is below\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: abc-ingress-external\n  namespace: backend\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    kubernetes.io/ingress.class: nginx-external\n    nginx.ingress.kubernetes.io/server-snippet: |\n       location = /ping {\n         deny all;\n         return 403;\n       }\nspec:\n  rules:\n  - host: dev-abc.example.com\n    http:\n      paths:\n      - backend:\n          service:\n              name: miller\n              port:\n                number: 80\n        path: /\n        pathType: Prefix\n`\n```\nWhen I apply this config, I get this error:\n```\n`for: \"ingress.yml\": admission webhook \"validate.nginx.ingress.kubernetes.io\" denied the request: nginx.ingress.kubernetes.io/server-snippet annotation contains invalid word location\n`\n```\nI looked into this and got this is something related to annotation-value-word-blocklist. However i don't know how to resolve this. Any help would be appreciated.",
      "solution": "Seems there's issue using `location` with some versions. The following was tested successfully on EKS cluster.\nInstall basic ingress-nginx on EKS:\n`kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.1.0/deploy/static/provider/aws/deploy.yaml`\nNote: If your cluster version is \nRun a http service:\n`kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/docs/examples/http-svc.yaml`\nCreate an ingress for the service:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: http-svc\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/server-snippet: |\n       location = /ping {\n         deny all;\n         return 403;\n       }\nspec:\n  rules:\n  - host: test.domain.com\n    http:\n      paths:\n      - path: /\n        pathType: ImplementationSpecific\n        backend:\n          service:\n            name: http-svc\n            port:\n              number: 8080\n`\n```\nReturn 200 as expected:\n`curl -H 'HOST: test.domain.com' http://`\nReturn 200 as expected:\n`curl -H 'HOST: test.domain.com' -k https://`\nReturn 403 as expected, the snippet is working:\n`curl -H 'HOST: test.domain.com' -k https:///ping`\n\nUse the latest release to avoid the \"annotation contains invalid word location\" issue.",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2021-12-24T05:37:03",
      "url": "https://stackoverflow.com/questions/70469602/nginx-ingress-kubernetes-io-server-snippet-annotation-contains-invalid-word-loca"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66669589,
      "title": "nginx ingress rewrite-target problem with redirection",
      "problem": "I have a Kibana dashboard that I currently access through the root of my host : `https://my.host.com/`. I want to change it so I can access it through the path `https://my.host.com/kibana/`. For this, I used the `rewrite-target` annotation as provided in the main documentation:\n```\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: kibana-ing\n  annotations:\n      nginx.ingress.kubernetes.io/rewrite-target: /$2\n      kubernetes.io/ingress.class: kibana-ingress-class\n      nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\nspec:\n  rules:\n    - host: my.host.com\n      http:\n        paths:\n          - path: /kibana(/|$)(.*)\n            backend:\n              serviceName: kibana-svc\n              servicePort: 5601\n`\n```\nI think this works to some extent because when hitting https://my.host.com/kibana/, I get redirected to the login page. But the login page is returned to my browser without the kibana prefix : `https://my.host.com/app/login` and I get a 404.\nHow can I fix this?\nEDIT:\nThis is currently what is happening when I hit `https://my.host.com/kibana/` :\n\nThis sends back a HTTP 302 with a redirection to `app/login` as you can see in the Location header. But when my browser asks back Nginx to fetch for this app/login, it rightfully gives a 404 since this path is unkown to it.\nIs there a way (through an Ingress annotation maybe) to append the '/kibana' prefix to all the Location headers that are being returned?\nEDIT2:\nI managed to append the `/kibana/` part in the Location header by adding these 2 annotations:\n```\n`nginx.ingress.kubernetes.io/proxy-redirect-from: \"/\"\nnginx.ingress.kubernetes.io/proxy-redirect-to: \"/kibana/\"\n`\n```\nThis makes the redirection point to `kibana/app/login`, resulting in a 200 status. However more objects are being loaded by the page like a bootsrap.js and their location are hardcoded within the html page being sent back like this:\n```\n`\n`\n```\nObviously this hits back with another 404 error on my browser end... I think I will have to deal with this on the application end instead.",
      "solution": "I managed to fix this at the application level. In my `kibana.yml` config file, I had to tell Kibana that it was running behind a reverse proxy. So I set `server.basePath: /kibana`.\nNote that the configuration I made above for the Ingress is still needed, as the application is still reacheable at the root of server but only the responses URLs will include the `/kibana/` prefix.",
      "question_score": 3,
      "answer_score": 4,
      "created_at": "2021-03-17T09:42:53",
      "url": "https://stackoverflow.com/questions/66669589/nginx-ingress-rewrite-target-problem-with-redirection"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 74803158,
      "title": "Rewrite target issue with nginx ingress kubernetes",
      "problem": "I am having issue to load a website from a docker nginx container in a AKS cluster. I've installed an nginx ingress controller, and deployed the following:\nDeployment + Service\n```\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: articles\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: articles\n  template:\n    metadata:\n      labels:\n        app: articles\n    spec:\n      containers:\n      - name: articles\n        image: myimage/personal:articles\n        imagePullPolicy: Always\n        ports:\n        - containerPort: 80\n        env:\n        - name: TITLE\n          value: \"Articles\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: articles\nspec:\n  type: ClusterIP\n  ports:\n  - port: 80\n  selector:\n    app: articles\n`\n```\nIngress\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: personal\n  annotations:\n    nginx.ingress.kubernetes.io/ssl-redirect: \"false\"\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\nspec:\n  ingressClassName: nginx\n  rules:\n  - http:\n      paths:\n      - path: /articles(/|$)(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: articles\n            port:\n              number: 80\n      - path: /(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: landing-page\n            port:\n              number: 80\n\n`\n```\nAnd here is a part of the content of the index.html file that makes the website; I intentionally hide the content of the body as the problem is only with the external files that need to be loaded (css and js files)\n```\n`\n\n    \n        Editorial by HTML5 UP\n        \n        \n        \n    \n    \n\n        \n            \n            \n            \n            \n            \n\n    \n\n`\n```\nFiles are located in the following folder:\n```\n`/usr/share/nginx/html/assets\n`\n```\nWith that, let's say the ingress address is 20.200.200.200, when I go to 20.200.200.200/articles/ , everything is working fine and the page is loading correctly, while when I go to the address 20.200.200.200/articles (note the trailing slash is missing there), the external files can't be loaded ... I have the following errors in the console:\n```\n`Uncaught SyntaxError: Unexpected token 'I understand that it might be a problem when rewriting the url however I can't figure out how to solve this ...\nTried various rewrite-target options, tried to modify the default.conf file of the nginx container without success",
      "solution": "Found out how to handle this thanks to this post ...\nThe following ingress configuration makes it work with/without trailing slash:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: articles\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\n    nginx.ingress.kubernetes.io/configuration-snippet: |\n      rewrite ^(/articles)$ $1/ redirect;\nspec:\n  ingressClassName: nginx\n  rules:\n  - http:\n      paths:\n      - path: /articles(/|$)(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: articles\n            port:\n              number: 80\n`\n```",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2022-12-14T20:08:18",
      "url": "https://stackoverflow.com/questions/74803158/rewrite-target-issue-with-nginx-ingress-kubernetes"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70183450,
      "title": "What&#39;s the difference between an External and an Internal ingress?",
      "problem": "In the context of Kubernetes and Nginx ingress-controller, I can't grasp the difference between an external ingress and an internal ingress.\n\nwhat an external ingress and an internal ingress differ in?\n\nwhen should they be used and what use cases do they serve?\n\nwhen should one use `ingressClassName: nginx-internal`, `ingressClassName: nginx`, `metadata.annotations: [ kubernetes.io/ingress.class: nginx-external ]` aut similis?\n\nI can't find much on the net, that discusses such difference or exemplifies how to use them. There's always some implicit knowledge assumed.",
      "solution": "Both types allow ingress into the service in the ingress definition, but the external ingress will expose it to the internet.  The internal does not, it's only on the local subnet outside the kubernetes bubble.  Internal is used in situations where you need to allow a connection from another workload cluster on the same network but don't want it exposed to the internet.",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2021-12-01T12:33:13",
      "url": "https://stackoverflow.com/questions/70183450/whats-the-difference-between-an-external-and-an-internal-ingress"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69927448,
      "title": "Ingress path redirection, helm chart",
      "problem": "I have a service which is running in kubernetes, and has a path prefix `/api`. Now I want to use Ingress to access it through the host address `example.com/service1/` because I have multiple services. But the problem is that ingress redirects all the requests from path `service1/` with that prefix `service1/`, but I want it to redirect from `example.com/service1/` to my service with just `/` (so if I request `example.com/service1/api` it will redirect to service with just `/api`). Can I achieve something like this? I'm writing Ingress configuration in the helm chart of the service.\nIngress configuration in service chart file `values.yaml` looks like this:\n```\n`...\ningress:\n  enabled: true\n  className: \"\"\n  annotations: {}\n  # kubernetes.io/ingress.class: nginx // this comment was created when generating helm chart\n  hosts:\n    - host: example.com\n      paths:\n        - path: /service1(/|$)(.*)\n          pathType: ImplementationSpecific\n          backend:\n            serviceName: $name\n            servicePort: http\n  tls: []\n  ...\n`\n```\nAnd `ingress.yaml` inside `templates/` folder is a default file that was generated by `helm` when I was creating a chart for the service. It just uses values from `values.yaml` to configure ingress. I didn't find anything, only this question which is basically saying that I need to add either prefix `service1/` to my service or just use `/api` in the Ingress configuration. But is there solution suitable for my needs?",
      "solution": "Based on the solution provided in the comments (method 1 example 2 in the Medium post ), a possible `values.yaml` file for Ingress might looks like below.\n```\n`...\ningress:\n  enabled: true\n  className: \"\"\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/rewrite-target: http://example.com/$2 \n  hosts:\n    - host: example.com\n      paths:\n        - path: /service1(/|$)(.*)\n          backend:\n            serviceName: $name\n            servicePort: http\n  tls: []\n  ...\n`\n```",
      "question_score": 3,
      "answer_score": 3,
      "created_at": "2021-11-11T12:22:46",
      "url": "https://stackoverflow.com/questions/69927448/ingress-path-redirection-helm-chart"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 74628719,
      "title": "How can i install deleted default api service in kubernetes?",
      "problem": "I am on Kubernetes v1.22.13. When i was trying to delete a namespace that's stuck in status `terminating`, i deleted api-service `v1.networking.k8s.io` by mistake with:\n```\n`kubectl delete apiservices.apiregistration.k8s.io v1.networking.k8s.io\n`\n```\nAnd now i don't have crds related to `v1.networking.k8s.io` such as `Ingress`.  When i try to install ingress-controller it gives the error:\n\nerror: resource mapping not found for name: \"nginx\" namespace: \"\" from \"https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.4.0/deploy/static/provider/cloud/deploy.yaml\": no matches for kind \"IngressClass\" in version \"networking.k8s.io/v1\"\n\nHow can i undo that operation? Or how can i bring back api-resource `v1.networking.k8s.io`?\nTried to find a way to undo it and install it manually but i couldn't find the manifest related to that.",
      "solution": "You can recreate it via the following:\n```\n`cat <<EOF | kubectl apply -f -\napiVersion: apiregistration.k8s.io/v1\nkind: APIService\nmetadata:\n  labels:\n    kube-aggregator.kubernetes.io/automanaged: onstart\n  name: v1.networking.k8s.io\nspec:\n  group: networking.k8s.io\n  groupPriorityMinimum: 17200\n  version: v1\n  versionPriority: 15\nEOF\n`\n```",
      "question_score": 3,
      "answer_score": 2,
      "created_at": "2022-11-30T14:40:00",
      "url": "https://stackoverflow.com/questions/74628719/how-can-i-install-deleted-default-api-service-in-kubernetes"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 73968863,
      "title": "Nginx ingress failed: HTTP probe failed with statuscode: 503",
      "problem": "I'm following this Link to install `nginx-ingress-controller` on my bare metal server `Kubernetes-v.1.19.16`\nThe below commands i have executed as part of installation.\n```\n`$ git clone https://github.com/nginxinc/kubernetes-ingress.git --branch v2.4.0\n$ cd kubernetes-ingress/deployments\n\n$ kubectl apply -f common/ns-and-sa.yaml\n$ kubectl apply -f rbac/rbac.yaml\n$ kubectl apply -f rbac/ap-rbac.yaml\n$ kubectl apply -f rbac/apdos-rbac.yaml\n\n$ kubectl apply -f common/default-server-secret.yaml\n$ kubectl apply -f common/nginx-config.yaml\n$ kubectl apply -f common/ingress-class.yaml\n\n$ kubectl apply -f daemon-set/nginx-ingress.yaml\n`\n```\nI have followed `DaemonSet` method.\n```\n`$ kubectl get all -n nginx-ingress\nNAME                      READY   STATUS    RESTARTS   AGE\npod/nginx-ingress-bcrk5   0/1     Running   0          19m\npod/nginx-ingress-ndpfz   0/1     Running   0          19m\npod/nginx-ingress-nvp98   0/1     Running   0          19m\n\nNAME                           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE\ndaemonset.apps/nginx-ingress   3         3         0       3            0                     19m\n`\n```\nFor all three `nginx-ingress` pods same error it shown.\n```\n`$ kubectl describe pods nginx-ingress-bcrk5 -n nginx-ingress\nEvents:\n  Type     Reason     Age                     From               Message\n  ----     ------     ----                    ----               -------\n  Normal   Scheduled  38m                     default-scheduler  Successfully assigned nginx-ingress/nginx-ingress-bcrk5 to node-4\n  Normal   Pulling    38m                     kubelet            Pulling image \"nginx/nginx-ingress:2.4.0\"\n  Normal   Pulled     37m                     kubelet            Successfully pulled image \"nginx/nginx-ingress:2.4.0\" in 19.603066401s\n  Normal   Created    37m                     kubelet            Created container nginx-ingress\n  Normal   Started    37m                     kubelet            Started container nginx-ingress\n  Warning  Unhealthy  3m13s (x2081 over 37m)  kubelet            Readiness probe failed: HTTP probe failed with statuscode: 503\n`\n```\n```\n`$ kubectl logs -l app=nginx-ingress -n nginx-ingress\n\nE1007 03:18:37.278678       1 reflector.go:140] pkg/mod/k8s.io/client-go@v0.25.2/tools/cache/reflector.go:169: Failed to watch *v1.VirtualServer: failed to list *v1.VirtualServer: the server could not find the requested resource (get virtualservers.k8s.nginx.org)\nW1007 03:18:55.714313       1 reflector.go:424] pkg/mod/k8s.io/client-go@v0.25.2/tools/cache/reflector.go:169: failed to list *v1.Policy: the server could not find the requested resource (get policies.k8s.nginx.org)\nE1007 03:18:55.714361       1 reflector.go:140] pkg/mod/k8s.io/client-go@v0.25.2/tools/cache/reflector.go:169: Failed to watch *v1.Policy: failed to list *v1.Policy: the server could not find the requested resource (get policies.k8s.nginx.org)\nW1007 03:19:00.542294       1 reflector.go:424] pkg/mod/k8s.io/client-go@v0.25.2/tools/cache/reflector.go:169: failed to list *v1alpha1.TransportServer: the server could not find the requested resource (get transportservers.k8s.nginx.org)\nE1007 03:19:00.542340       1 reflector.go:140] pkg/mod/k8s.io/client-go@v0.25.2/tools/cache/reflector.go:169: Failed to watch *v1alpha1.TransportServer: failed to list *v1alpha1.TransportServer: the server could not find the requested resource (get transportservers.k8s.nginx.org)\n`\n```\nStill `READY` and `UP-TO-DATE` state showing `0`, Ideally it show `3` in both the categories. Please let me know what i'm missing here as part of installation?\nAny help is appreciated.",
      "solution": "I'd recommend installing it using `helm`\nSee https://github.com/nginxinc/kubernetes-ingress/tree/main/deployments/helm-chart\n`helm repo add nginx-stable https://helm.nginx.com/stable\n\nhelm install nginx-ingress nginx-stable/nginx-ingress \\\n    --namespace $NAMESPACE \\\n    --version $VERSION\n`\nYou can look for versions compatibles with your Kubernetes cluster version using:\n`helm search repo nginx-stable/nginx-ingress --versions\n`\nWhen installation is well finished, you should see ingress-controller service that holds an `$EXTERNAL-IP`\n`NAME                                 TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)                                  AGE\n\ningress-nginx-controller             LoadBalancer   10.0.XXX.XXX   XX.XXX.XXX.XX   80:30578/TCP,443:31874/TCP               548d\n`",
      "question_score": 3,
      "answer_score": 1,
      "created_at": "2022-10-06T07:05:27",
      "url": "https://stackoverflow.com/questions/73968863/nginx-ingress-failed-http-probe-failed-with-statuscode-503"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69249151,
      "title": "Page is not loading a file fully and net::ERR_HTTP2_PROTOCOL_ERROR is shown",
      "problem": "We have the page which has some of the larger Javascript files. When we hit the page, all the small files get downloaded. However, one of the large files was not downloaded fully and failed with net::ERR_HTTP2_PROTOCOL_ERROR most of the time. We need to open the page using only a VPN connection as it does not open to all.\nJust to add, the Nginx ingress controller is used with the following settings for that ingress:\n```\n`    nginx.ingress.kubernetes.io/configuration-snippet: |\n      gzip on;\n      gzip_types text/plain text/css image/png application/javascript;\n      if ($request_uri ~* \\.(js|css|gif|jpeg|png)) {\n        expires 1M;\n        add_header Cache-Control \"public\";\n      }\n    nginx.ingress.kubernetes.io/http2-push-preload: \"false\"\n    nginx.ingress.kubernetes.io/proxy-body-size: 500M\n    nginx.ingress.kubernetes.io/proxy-bufferings: \"off\"\n    nginx.ingress.kubernetes.io/proxy-connect-timeout: \"36000\"\n    nginx.ingress.kubernetes.io/proxy-max-temp-file-size: \"0\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"36000\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"36000\"\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    nginx.ingress.kubernetes.io/secure-backends: \"true\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n`\n```\nCan we set another annotation in the Nginx ingress or this might be an issue from VPN? I wonder how can we resolve this issue.",
      "solution": "I solved this by changing the configuration for the Nginx Ingress as following:\n```\n`data:\n  client-max-body-size: 50M\n  keep-alive: \"3600\"\n  proxy-buffer-size: 500m\n  proxy-buffers-number: \"8\" \n`\n```\nGlad if this is time-saving for anyone.",
      "question_score": 3,
      "answer_score": 2,
      "created_at": "2021-09-20T06:37:23",
      "url": "https://stackoverflow.com/questions/69249151/page-is-not-loading-a-file-fully-and-neterr-http2-protocol-error-is-shown"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66636366,
      "title": "How to redirect correctly usign nginx-ingress in Kubernetes",
      "problem": "I'm new to kubernetes and nginx, and am having trouble understanding how to implement Ingress (nginx-ingress) for my particular use case.\nI want to expose the pgadmin PostgreSQL admin tool from my cluster.\nI have other applications exposed via nginx-ingress from my cluster and I like each to hang off its own subdirectory e.g.:\n\nmyserver.com/purchasing/index.html\nmyserver.com/sales/index.html\n\nI have a problem doing this with pgadmin (although the problem would no doubt apply equally to other apps that behave in the same way)\nI have set up an Ingress rule to capture and route accordingly:\n```\n`  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\n\n  rules:\n  - http:\n      paths:\n        - path: /pgadmin4(/|$)(.*)\n\n`\n```\nit does the routing and the backend is hit.\nHowever when pgadmin then does a redirect, I lose the pgadmin/ from the redirect URl i.e.\n\nI send a GET to myserver.com/pgadmin\nI receive a 302 redirect to myserver.com/login\n\nwhereas I want redirecting to:\n\nmyserver.com/pgadmin/login\n\nWhat pieces am I missing to achieve this - it feels like it should be simple?\nThanks",
      "solution": "It's worth mentioning that exposing many different services using the same domain name may not be the best idea in terms of security. Many web security mechanisms rely on the domain name to determine what's trusted and what isn't. So if one of your containers is breached, other services sharing the same domain name might be affected.\nAnyway, the problem is with pgadmin. It isn't aware that it's being served from `myserver.com/pgadmin/` (another reason why having multiple services use the same domain name isn't the best idea), so it sends the wrong redirects.\nLuckily, the pgadmin documentation offers a solution:\n\nIf you wish to host pgAdmin under a subdirectory rather than on the root of the server, you must specify the location and set the X-Script-Name header which tells the pgAdmin container how to rewrite paths:\n```\n`server {\n  listen 80;\n  server_name _;\n\n  location /pgadmin4/ {\n      proxy_set_header X-Script-Name /pgadmin4;\n      proxy_set_header Host $host;\n      proxy_pass http://localhost:5050/;\n      proxy_redirect off;\n  } \n}\n`\n```\n\nSo it looks like you just have to make sure that calls to pgadmin are sent with the `X-Script-Name /pgadmin4` header, which is something that the nginx ingress controller knows how to do.",
      "question_score": 3,
      "answer_score": 1,
      "created_at": "2021-03-15T11:37:56",
      "url": "https://stackoverflow.com/questions/66636366/how-to-redirect-correctly-usign-nginx-ingress-in-kubernetes"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 71295991,
      "title": "Nginx Ingress Error 413 Request Entity Too Large",
      "problem": "I use ingress-nginx with Helm Chart. I used to have the problem, that when I would upload a file (50MB) that I would get the error 413 Request Entity Too Large nginx.\nSo I changed the proxy-body-size value in my values.yaml file to 150m, so I should now be able to upload my file.\nBut now I get the error \"413 Request Entity Too Large openresty/1.13.6.2\".\nI checked the nginx.conf file on the ingress controller and the value for client_max_body_size is correctly set to 150m.\nAfter some research I found out that openresty is used by the lua module in nginx.\nDoes anybody know how I can set this setting too for openresty, or what parameter I am missing ?\nMy current config is the following:\nvalues.yml:\n`ingress-nginx:\n  defaultBackend:\n    nodeSelector:\n      beta.kubernetes.io/os: linux\n  controller:\n    replicaCount: 2\n    resources:\n      requests:\n        cpu: 1\n        memory: 4Gi\n      limits:\n        cpu: 2\n        memory: 7Gi\n    autoscaling:\n      enabled: true\n      minReplicas: 2\n      maxReplicas: 10\n      targetCPUUtilizationPercentage: 90\n      targetMemoryUtilizationPercentage: 90\n    ingressClassResource:\n      name: nginx\n      controllerValue: \"k8s.io/nginx\"\n    nodeSelector:\n      beta.kubernetes.io/os: linux\n    admissionWebhooks:\n      enabled: false\n      patch:\n        nodeSelector:\n          beta.kubernetes.io/os: linux\n    extraArgs:\n      ingress-class: \"nginx\"\n    config:\n      proxy-buffer-size: \"16k\"\n      proxy-body-size: \"150m\"\n      client-body-buffer-size: \"128k\"\n      large-client-header-buffers: \"4 32k\"\n      ssl-redirect: \"false\"\n      use-forwarded-headers: \"true\"\n      compute-full-forwarded-for: \"true\"\n      use-proxy-protocol: \"false\"\n`\ningress.yml:\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress\n  namespace: namespacename\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"\n    nginx.ingress.kubernetes.io/proxy-buffer-size: \"128k\"\n    nginx.ingress.kubernetes.io/proxy-buffers-number: \"8\"\n    nginx.ingress.kubernetes.io/client-body-buffer-size: \"128k\"\n    nginx.ingress.kubernetes.io/proxy-body-size: \"150m\"\nspec:\n  tls:\n    - hosts:\n        - hostname\n  rules:\n    - host: hostname\n      http:\n        paths:\n          - path: /assets/static/\n            pathType: ImplementationSpecific\n            backend:\n              service:\n                name: servicename\n                port:\n                  number: 8080\n`",
      "solution": "So it turns out the Application wich had the error, had another reverse Proxy infront of it (wich uses Lua and Openresty for oauth registration).\nThe Proxy-body-size attribute needed to be raised there to. After that the File upload worked",
      "question_score": 3,
      "answer_score": 1,
      "created_at": "2022-02-28T14:48:35",
      "url": "https://stackoverflow.com/questions/71295991/nginx-ingress-error-413-request-entity-too-large"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70917854,
      "title": "How to use Ingress Nginx Controller to route traffic to private pods Internally",
      "problem": "Problem: I am currently using ingress-nginx in my EKS cluster to route traffic to services that need public access.\nMy use case: I have services I want to deploy in the same cluster but don't want them to have public access. I only want the pods to communicate will all other services within the cluster. Those pods are meant to be private because they're backend services and only need pod-to-pod communication. How do I modify my ingress resource for this purpose?\nCluster Architecture: All services are in the private subnets of the cluster while the load-balancer is in the public subnets\nAdditional note: I am using `external-dns` to dynamically create the subdomains for the hosted zones. The hosted zone is public\nThanks\nBelow are my `service.yml` and `ingress.yml` for public services. I want to modify these files for private services\nservice.yml\n`apiVersion: v1\nkind: Service\nmetadata:\n  name: myapp\n  namespace: myapp \n  annotations:\n    external-dns.alpha.kubernetes.io/hostname: myapp.dev.com\nspec:\n  ports:\n    - port: 80\n      targetPort: 3000\n  selector:\n    app: myapp\n`\ningress.yml\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp\n  namespace: myapp \n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    kubernetes.io/ingress.class: \"nginx\"\n  labels:\n    app: myapp\nspec:\n  tls:\n  - hosts:\n  - myapp.dev.com\n  secretName: myapp-staging\n  rules:\n  - host: myapp.dev.com\n    http:\n      paths:\n        - path: /\n          pathType: Prefix\n          backend:\n            service:\n              name: 'myapp'\n              port:\n                number: 80\n`",
      "solution": "From this what you have the Ingress already should work and your services are meant to be private(if you set like this in your public cloud cluster), except the Ingress itself. You can update the ConfigMap to use the PROXY protocol so that you can pass proxy information to the Ingress Controller:\n```\n`kind: ConfigMap\napiVersion: v1\nmetadata:\n  name: nginx-config\n  namespace: nginx-ingress\ndata:\n  proxy-protocol: \"True\"\n  real-ip-header: \"proxy_protocol\"\n  set-real-ip-from: \"0.0.0.0/0\"\n`\n```\nAnd then: `kubectl apply -f common/nginx-config.yaml`\nNow you can deploy any app that you want to have private with the name specified (for example your `myapp` Service in your yaml file provided.\nIf you are a new to Kubernetes Networking, then this article would be useful for you or in official Kubernetes documentation\nHere you can find other ELB annotations that may be useful for you",
      "question_score": 3,
      "answer_score": 1,
      "created_at": "2022-01-30T19:50:35",
      "url": "https://stackoverflow.com/questions/70917854/how-to-use-ingress-nginx-controller-to-route-traffic-to-private-pods-internally"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70745932,
      "title": "Ingress Nginx throwing a client request body is buffered to a temporary file warning",
      "problem": "We have an ingress resource hostname say `xyz.int.com` setup on two k8s cluster A and B. The ingress controller used is nginx. On DNS we have setup `xyz.int.com` to point to the loadbalancer IPs in respective clusters.\nFor some strange reason, in one cluster I'm getting the below warning and not getting any status code for request if its a success or not:\n```\n`2022/01/17 17:58:00 [warn] 13239#13239: *94097411 a client request body is buffered to a temporary file /tmp/client-body/0001505726, client: 10.9.8.0, server: xyz.int.com, request: \"POST /api/vss0/an/log/83f740daa89b3d3638b37a6a06de49a59f1f5126129a9a6?clientTimeInMs=1642442284833&sdkV=811409&gpid=a15e3b7c2-e1366-4327d-83a93-f7619&devNet=WIFI&locale=en-IN&region=IN HTTP/1.1\", host: \"xyz.int.com\"\n`\n```\nWhereas the same endpoint in another cluster works fine, and there is no explicit difference in both the nginx controller or ingress resource.\nWhat can be the issue? Kindly assist.",
      "solution": "Summarizing the comments:\nThis warning message means that the size of the uploaded file was larger than the in-memory buffer reserved for uploads.\nPlease refer to this description explaining how `client_body_buffer_size` works:\n\nSets buffer size for reading client request body. In case the request body is larger than the buffer, the whole body or only its part is written to a temporary file. By default, buffer size is equal to two memory pages. This is 8K on x86, other 32-bit platforms, and x86-64. It is usually 16K on other 64-bit platforms.",
      "question_score": 3,
      "answer_score": 1,
      "created_at": "2022-01-17T19:26:46",
      "url": "https://stackoverflow.com/questions/70745932/ingress-nginx-throwing-a-client-request-body-is-buffered-to-a-temporary-file-war"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66767660,
      "title": "Do not terminate SSL at ingress level for Kubernetes",
      "problem": "I have a Java application running inside tomcat server (which is inside a pod), which is configured to work with https.\nI am using nginx ingress. The problem is, the nginx ingress is terminating the SSL and forwarding only plain http to the tomcat server (to the pod actually). Since the tomcat server is configured to work with only HTTPS, it is not accepting the traffic.\nFollowing doesn't work:\n```\n`nginx.ingress.kubernetes.io/ssl-passthrough: \"true\"\n`\n```",
      "solution": "Finally I have found the answer:\nI have to add the following 2 lines:\n```\n`nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\nnginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n`\n```\nSo the ingress is like this (I have also added some comment to describe and also to show which options I tried and didn't work, so that you don't waste your time):\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-resource-staging\n  namespace: staging-space\n  annotations:\n    kubernetes.io/ingress.class: nginx #You may deploy any number of ingress controllers within a cluster. When you create an ingress, you should annotate each ingress with the appropriate ingress.class to indicate which ingress controller should be used if more than one exists within your cluster.\n    #If you do not define a class, your cloud provider may use a default ingress controller.\n    #nginx.ingress.kubernetes.io/ssl-passthrough: \"true\"\n    ##Following 2 lines are important, otherwise the SSL is terminated at the ingress level and the\n    ## traffic sent to the service is plain http and then tomcat complains that the host and port combination\n    ## needs https connection (in the tomcat server we have enabled the HTTPS internally)\n    ## We want to forward the HTTPS traffic to the pods\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n\nspec:\n  #tls:\n  #  - hosts:\n  #      - yourhost.com\n  rules:\n    - host: yourhost.com\n      http:\n        paths:\n          - pathType: Prefix\n            path: /\n            backend:\n              service:\n                name: my-app-service\n                port:\n                  #number: 8080\n                  number: 8443\n`\n```",
      "question_score": 2,
      "answer_score": 9,
      "created_at": "2021-03-23T17:52:14",
      "url": "https://stackoverflow.com/questions/66767660/do-not-terminate-ssl-at-ingress-level-for-kubernetes"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69313812,
      "title": "Installing multiple nginx ingress controller instances in the same AKS cluster",
      "problem": "I have a brand new (so empty) AKS cluster. I want to install two instances of the nginx ingress controller, in different namespaces and with different ingress class, using helm.\nI start with the first:\n```\n`helm install ingress1 ingress-nginx/ingress-nginx --namespace namespace1 --set controller.ingressClass=class1\n\nNAME: ingress1\nLAST DEPLOYED: Fri Sep 24 20:46:28 2021\nNAMESPACE: namespace1\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nThe ingress-nginx controller has been installed.\nIt may take a few minutes for the LoadBalancer IP to be available.\n`\n```\nAll good\nNow I go with the second:\n```\n`helm install ingress2 ingress-nginx/ingress-nginx --namespace namespace2 --set controller.ingressClass=class2\n\nError: rendered manifests contain a resource that already exists. Unable to continue with install: IngressClass \"nginx\" in namespace \"\" exists and cannot be imported into the current release: invalid ownership metadata; annotation validation error: key \"meta.helm.sh/release-name\" must equal \"ingress2\": current value is \"ingress1\"; annotation validation error: key \"meta.helm.sh/release-namespace\" must equal \"namespace2\": current value is \"namespace1\"\n`\n```\nWhat is the correct way to install multiple nginx ingress controller instances in the same cluster?",
      "solution": "I think that you're setting the wrong values, thus the class name is `nginx` in both installs. Take a look at the template here: controller-ingressclass\nIf you're using the official ingress-nginx Helm repository: `https://kubernetes.github.io/ingress-nginx` then try setting this instead: `controller.ingressClassResource.name=class1|class2` instead:\n`helm install ingress1 ingress-nginx/ingress-nginx --namespace namespace1 --set controller.ingressClassResource.name=class1\n\nhelm install ingress2 ingress-nginx/ingress-nginx --namespace namespace2 --set controller.ingressClassResource.name=class2\n`\ndepending on your needs, you may also require to change the other values of the ingressClassResource",
      "question_score": 2,
      "answer_score": 11,
      "created_at": "2021-09-24T12:53:43",
      "url": "https://stackoverflow.com/questions/69313812/installing-multiple-nginx-ingress-controller-instances-in-the-same-aks-cluster"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 67471377,
      "title": "Using HTTP/2 with nginx Ingress on GKE",
      "problem": "We have configured a cluster on GKE and installed nginx-ingress. Using our ingress rule it works, but I can't make it work with HTTP/2. We set the data information on the ConfigMap but it will always fallback to http/1.1. This exact setup was running fine on DigitalOcean. Can anyone provide some guidance?\nThanks\nInstall Nginx-Ingress\n```\n`kubectl create ns ingress-nginx\nhelm repo add nginx-stable https://helm.nginx.com/stable\nhelm repo update\nhelm install nginx-ingress nginx-stable/nginx-ingress --namespace ingress-nginx\n`\n```\nMy Ingress file:\n```\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: my-ingress\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    kubernetes.io/ingress.global-static-ip-name: \"mylocalip\"\nspec:\n  rules:\n  - host: test.mydomain.com\n    http:\n      paths:\n      - path: /hello\n        backend:\n          serviceName: hello-server\n          servicePort: 80\n      - backend:\n          serviceName: default-server\n          servicePort: 80\n`\n```\nMy ConfigMap data applied to nginx-ingress-nginx-ingress configmap\n```\n`data:\n  use-http2: \"true\"\n`\n```\nEDIT (05/11/2021):\nWe changed the ingress to work with certificates, now we connect using HTTPS. But still, all connections are established using http/1.1\nHi, thanks for the reply. But I've changed my ingress to use cert-manager and LetEncrypt, below is the updated Ingress.\nINGRESS\n```\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: my-ingress\n  namespace: mynamespace\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    kubernetes.io/ingress.global-static-ip-name: \"myip\"\nspec:\n  tls:\n  - hosts:\n    - test.mydomain.com\n    secretName: my-cert\n  rules:\n  - host: test.mydomain.com\n    http:\n      paths:\n      - backend:\n          serviceName: myweb\n          servicePort: 80\n`\n```\nEDIT 2 (05/14/2021)\nCurrent version: 1.19.9-gke.1400\nTest using curl and https://http2.pro/ (both indicate it's not available)\nThis same setup works using k8s on DigitalOcean.\nHere are my install and config files:\nINSTALL INGRESS-NGINX\n```\n`kubectl create ns ingress-nginx\nhelm repo add nginx-stable https://helm.nginx.com/stable\nhelm repo update\nhelm install nginx-ingress nginx-stable/nginx-ingress --namespace ingress-nginx --set controller.service.loadBalancerIP=x.x.x.x\n`\n```\nINGRESS\n```\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: my-ingress\n  namespace: mynamespace\n  annotations:\n    kubernetes.io/ingress.class: nginx\nspec:\n  tls:\n  - hosts:\n    - test.mydomain.com\n    secretName: my-cert\n  rules:\n  - host: test.mydomain.com\n    http:\n      paths:\n      - backend:\n          serviceName: myweb\n          servicePort: 80\n`\n```\nCONFIGMAP\n```\n`apiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: ingress-nginx\n  name: nginx-ingress-nginx-ingress\ndata:\n  proxy-buffering: \"false\"\n  ssl-ciphers: EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA256:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EDH+aRSA+AESGCM:EDH+aRSA+SHA256:EDH+aRSA:EECDH:!aNULL:!eNULL:!MEDIUM:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS:!RC4:!SEED\n  ssl-protocols: TLSv1.2 TLSv1.3\n  ssl-redirect: \"true\"\n  use-forward-headers: \"true\"\n  use-http2: \"true\"\n  \n  \n`\n```",
      "solution": "EDIT\n\nAfter further reproduction I've noticed that in the question there is a miss-match between the `NGINX Ingress controllers`.\nThere are 2 similarly named `Ingress` controllers:\n\nGithub.com: NginxInc: Kubernetes Ingress - for this purpose let's name it: nginx-inc\nGithub.com: Kubernetes: Ingress Nginx - for this purpose let's name it: nginx\n\nThis are 2 separate products where the differences are explained here:\n\nGithub.com: NginxInc: Kubernetes Ingress: Docs: Nginx ingress controllers\n\nDue to this `Configmap` key:\n\n`use-http2: \"true\"`\n\nI've incorrectly assumed that we are talking about the nginx where in fact it was the nginx-inc (I've missed the link of `$ helm repo add`). This field is specific to the nginx and will not work with the nginx-inc.\nI've managed to find a way to enable the `HTTP/2` support with the nginx-inc. Change:\n\nfrom: `use-http2: \"true\"`\nto: `http2: \"true\"`\n\nMore explanation can be found here:\n\nDocs.nginx.com: Nginx Ingress Controller: Configuration: Global configuration: Configmap resource: Listeners\n\nBelow part is more of a general approach to the support of `HTTP/2` on `GKE` with `Ingress`.\n\nA side note!\nEven without the `tls` part in the `YAML` manifest it's possible to use `HTTPS` due to the `Fake Ingress Controller certificate`\n\nAs pointed in the following github issue:\n\naledbf commented on 28 Mar 2019\n\nNGINX does not support HTTP/1.x and HTTP/2 at the same time on a cleartext (non-TLS) port.\nThat's the reason why it works only when HTTPS is used.\n-- Github.com: Kubernetes: Ingress nginx: Issue: HTTP2 support\n\nAs stated to enable `HTTP/2` you will need to have the tls part (certificate) configured in your `Ingress` resource.\nHere you can find the documentation to help you with the process:\n\nKubernetes.github.io: Ingress nginx: Examples: TLS termination\n\nI've used your setup on the `GKE` version `1.20.5-gke.2000` (the `Helm` part) and here is what I found.\nQuerying the external IP of your `Ingress` controller with `HTTP` request will allow you to use `HTTP/1.1`.\nAfter I've configured the certificate to use with the `Ingress` resource (and domain name), I could get the response stating that I'm using `HTTP/2`:\nYou can check it with various measures like `cURL` or online `HTTP/2` test sites:\n\n`curl -v -k https://DOMAIN.NAME`\n\n`* Trying IP_ADRESS\n* TCP_NODELAY set\n* Connected to DOMAIN.NAME ( IP_ADRESS) port 443 (#0)\n* ALPN, offering h2\n* ALPN, offering http/1.1\n* successfully set certificate verify locations:\n*   CAfile: /etc/ssl/cert.pem\n \n* Using HTTP2, server supports multi-use\n* Connection state changed (HTTP/2 confirmed)\n* Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0\n* Using Stream ID: 1 (easy handle 0x7fa5b300e800)\n> GET / HTTP/2\n> Host: DOMAIN.NAME\n> User-Agent: curl/7.64.1\n> Accept: */*\n> \n* Connection state changed (MAX_CONCURRENT_STREAMS == 128)!\n \n \n* Connection #0 to host DOMAIN.NAME left intact\n* Closing connection 0\n`\nYou can also go for more of a one line solution:\n\n`curl -k -sI https://DOMAIN.NAME -o/dev/null -w '%{http_version}\\n'`\n\nwhere the output should be `2`. More reference:\n\nStackoverflow.com: Question: Curl: one-liner to test http/2 support\n\nAlso, adding to whole answer on the modified part of the `Configmap` of your `nginx-ingress`:\n```\n`data:\n  use-http2: \"true\"\n`\n```\n\nuse-http2\nEnables or disables HTTP/2 support in secure connections.\n-- Kubernetes.github.io: Ingress nginx: User guide: Nginx configuration: Configmap: Use HTTP/2\n\nI'm not also sure about the usage of this annotation:\n\n`kubernetes.io/ingress.global-static-ip-name: \"mylocalip\"`\n\nas it's valid only for the `Ingress` resource for GKE `Ingress` and not `ingress-nginx`.\n\nAdditional resources:\n\nCloud.google.com: Kubernetes Engine: Docs: Tutorials: Configuring domain name static IP\nKubernetes.github.io: Ingress nginx",
      "question_score": 2,
      "answer_score": 7,
      "created_at": "2021-05-10T15:30:09",
      "url": "https://stackoverflow.com/questions/67471377/using-http-2-with-nginx-ingress-on-gke"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70366074,
      "title": "Ingress not working from official kubernetes tutorial",
      "problem": "I am following this official k8 ingress tutorial. However I am not able to `curl` the minikube IP address and access the \"web\" application.\n```\n`minikube addons enable ingress\nkubectl create deployment web --image=gcr.io/google-samples/hello-app:1.0\nkubectl expose deployment web --type=NodePort --port=8080\nkubectl apply -f https://k8s.io/examples/service/networking/example-ingress.yaml\n`\n```\nI'm able to curl the result of `minikube service web --url`\n```\n`    curl http://127.0.0.1:64671 \n    Hello, world!\n    Version: 1.0.0\n    Hostname: web-79d88c97d6-8z8tc \n`\n```\nBut not though ingress, with `kubectl apply -f https://k8s.io/examples/service/networking/example-ingress.yaml`\n(I don't have an external IP - just \"localhost\". )\n```\n`NGG282 kubernetes-ingress % kubectl get ingress\nNAME              CLASS   HOSTS   ADDRESS     PORTS   AGE\nexample-ingress   nginx   *       localhost   80      66m\n`\n```\nThis seems to be normal with minikube. Trying to curl the minikube IP:\n```\n`curl $(minikube ip)\ncurl: (7) Failed to connect to 192.168.49.2 port 80: Operation timed out\n`\n```\nAny help?\n----------EDIT :\n```\n`kubectl get deploy -n ingress-nginx -o yaml\n\n          ports:\n          - containerPort: 80\n            hostPort: 80\n            name: http\n            protocol: TCP\n          - containerPort: 443\n            hostPort: 443\n            name: https\n            protocol: TCP\n          - containerPort: 8443\n            name: webhook\n            protocol: TCP\n\nkubectl get svc -n ingress-nginx -o yaml\napiVersion: v1\nitems:\n- apiVersion: v1\n  kind: Service\n  metadata:\n    annotations:\n      kubectl.kubernetes.io/last-applied-configuration: |\n        {\"apiVersion\":\"v1\",\"kind\":\"Service\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/component\":\"controller\",\"app.kubernetes.io/instance\":\"ingress-nginx\",\"app.kubernetes.io/name\":\"ingress-nginx\"},\"name\":\"ingress-nginx-controller\",\"namespace\":\"ingress-nginx\"},\"spec\":{\"ipFamilies\":[\"IPv4\"],\"ipFamilyPolicy\":\"SingleStack\",\"ports\":[{\"appProtocol\":\"http\",\"name\":\"http\",\"port\":80,\"protocol\":\"TCP\",\"targetPort\":\"http\"},{\"appProtocol\":\"https\",\"name\":\"https\",\"port\":443,\"protocol\":\"TCP\",\"targetPort\":\"https\"}],\"selector\":{\"app.kubernetes.io/component\":\"controller\",\"app.kubernetes.io/instance\":\"ingress-nginx\",\"app.kubernetes.io/name\":\"ingress-nginx\"},\"type\":\"NodePort\"}}\n    creationTimestamp: \"2021-12-16T11:41:35Z\"\n    labels:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/instance: ingress-nginx\n      app.kubernetes.io/name: ingress-nginx\n    name: ingress-nginx-controller\n    namespace: ingress-nginx\n    resourceVersion: \"489\"\n    uid: 63826bc2-5d90-42f1-861f-f7f082ccf0fb\n  spec:\n    clusterIP: 10.104.208.171\n    clusterIPs:\n    - 10.104.208.171\n    externalTrafficPolicy: Cluster\n    internalTrafficPolicy: Cluster\n    ipFamilies:\n    - IPv4\n    ipFamilyPolicy: SingleStack\n    ports:\n    - appProtocol: http\n      name: http\n      nodePort: 30783\n      port: 80\n      protocol: TCP\n      targetPort: http\n    - appProtocol: https\n      name: https\n      nodePort: 30860\n      port: 443\n      protocol: TCP\n      targetPort: https\n    selector:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/instance: ingress-nginx\n      app.kubernetes.io/name: ingress-nginx\n    sessionAffinity: None\n    type: NodePort\n  status:\n    loadBalancer: {}\n- apiVersion: v1\n  kind: Service\n  metadata:\n    annotations:\n      kubectl.kubernetes.io/last-applied-configuration: |\n        {\"apiVersion\":\"v1\",\"kind\":\"Service\",\"metadata\":{\"annotations\":{},\"labels\":{\"app.kubernetes.io/component\":\"controller\",\"app.kubernetes.io/instance\":\"ingress-nginx\",\"app.kubernetes.io/name\":\"ingress-nginx\"},\"name\":\"ingress-nginx-controller-admission\",\"namespace\":\"ingress-nginx\"},\"spec\":{\"ports\":[{\"appProtocol\":\"https\",\"name\":\"https-webhook\",\"port\":443,\"targetPort\":\"webhook\"}],\"selector\":{\"app.kubernetes.io/component\":\"controller\",\"app.kubernetes.io/instance\":\"ingress-nginx\",\"app.kubernetes.io/name\":\"ingress-nginx\"},\"type\":\"ClusterIP\"}}\n    creationTimestamp: \"2021-12-16T11:41:35Z\"\n    labels:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/instance: ingress-nginx\n      app.kubernetes.io/name: ingress-nginx\n    name: ingress-nginx-controller-admission\n    namespace: ingress-nginx\n    resourceVersion: \"483\"\n    uid: fe797532-27c9-4dd1-a1bc-0662a3d2a4da\n  spec:\n    clusterIP: 10.106.175.35\n    clusterIPs:\n    - 10.106.175.35\n    internalTrafficPolicy: Cluster\n    ipFamilies:\n    - IPv4\n    ipFamilyPolicy: SingleStack\n    ports:\n    - appProtocol: https\n      name: https-webhook\n      port: 443\n      protocol: TCP\n      targetPort: webhook\n    selector:\n      app.kubernetes.io/component: controller\n      app.kubernetes.io/instance: ingress-nginx\n      app.kubernetes.io/name: ingress-nginx\n    sessionAffinity: None\n    type: ClusterIP\n  status:\n    loadBalancer: {}\nkind: List\nmetadata:\n  resourceVersion: \"\"\n  selfLink: \"\"\n`\n```",
      "solution": "OK so apparently this is a known issue with minikube, Ingress works properly on linux only.\n\nThe ingress, and ingress-dns addons are currently only supported on\nLinux. See #7332\n\nyou need to `minikube tunnel` on windows/macOS before being able to `curl`, but still there are differences:\nOn Windows, both `127.0.0.1` and `localhost` redirect to the application.\nOn macOS, `127.0.0.1` and `localhost` show an \"nginX not found\" message, but `curl hello-world.info` works only after changing `etc/hosts`.",
      "question_score": 2,
      "answer_score": 4,
      "created_at": "2021-12-15T16:14:59",
      "url": "https://stackoverflow.com/questions/70366074/ingress-not-working-from-official-kubernetes-tutorial"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69174737,
      "title": "Installing nginx ingress in AKS cluster fails with SyncLoadBalancerFailed error",
      "problem": "I have an AKS cluster with a web application. I want to provision an nginx Ingress controller to expose the app to the internet and later enable TLS.\nI have been following the official documentation\nhttps://learn.microsoft.com/en-us/azure/aks/ingress-basic\nand\nhttps://learn.microsoft.com/en-us/azure/aks/ingress-static-ip\nBut I always end up with a pending nginx-ingress service with this error\n```\n`reason: SyncLoadBalancerFailed\nmessage: >-\n  Error syncing load balancer: failed to ensure load balancer: instance not\n  found\n`\n```\n\nI have seen\nHow to fix \"failed to ensure load balancer\" error for nginx ingress\nand googled the error but so far no luck\nDoes anyone know what could it be?\nOr, is there some working example I can start from?",
      "solution": "I believe you are using a static IP address with the NGINX Ingress controller service. This issue pops up if the cloud controller manager cannot find the static Azure Public Ip Address resource in the containing resource group mentioned in the NGINX Ingress Controller's service annotation (if no resource group is explicitly specified with a service annotation, it will look for the Azure Public IP Address resource in the AKS cluster's node resource group)\nIf you have created the static Azure Public IP Address resource in the node resource group then please ensure that the Azure Public IP address resource exists.\nIf you have created the static Azure Public IP Address resource in a different resource group, then:\n\nPlease ensure the cluster identity used by the AKS cluster has delegated permissions to the other resource group, such as Network Contributor.\n```\n`az role assignment create \\\n  --assignee  \\\n  --role \"Network Contributor\" \\\n  --scope /subscriptions//resourceGroups/\n`\n```\nNote: Your cluster identity can be a service principal or a managed identity.\n\nIn the `helm install` command to deploy an NGINX Ingress Controller, please add the following argument:\n`--set controller.service.annotations.\"service\\.beta\\.kubernetes\\.io/azure-load-balancer-resource-group\"=$PublicIpAddressResourceGroupName`\nThus, if you are following this document the helm install command should look something like:\n```\n`# Use Helm to deploy an NGINX ingress controller\nhelm install nginx-ingress ingress-nginx/ingress-nginx \\\n  --namespace ingress-basic \\\n  --set controller.replicaCount=2 \\\n  --set controller.nodeSelector.\"kubernetes\\.io/os\"=linux \\\n  --set controller.image.registry=$ACR_URL \\\n  --set controller.image.image=$CONTROLLER_IMAGE \\\n  --set controller.image.tag=$CONTROLLER_TAG \\\n  --set controller.image.digest=\"\" \\\n  --set controller.admissionWebhooks.patch.nodeSelector.\"kubernetes\\.io/os\"=linux \\\n  --set controller.admissionWebhooks.patch.image.registry=$ACR_URL \\\n  --set controller.admissionWebhooks.patch.image.image=$PATCH_IMAGE \\\n  --set controller.admissionWebhooks.patch.image.tag=$PATCH_TAG \\\n  --set defaultBackend.nodeSelector.\"kubernetes\\.io/os\"=linux \\\n  --set defaultBackend.image.registry=$ACR_URL \\\n  --set defaultBackend.image.image=$DEFAULTBACKEND_IMAGE \\\n  --set defaultBackend.image.tag=$DEFAULTBACKEND_TAG \\\n  --set controller.service.loadBalancerIP=$STATIC_IP \\\n  --set controller.service.annotations.\"service\\.beta\\.kubernetes\\.io/azure-dns-label-name\"=$DNS_LABEL\n  --set controller.service.annotations.\"service\\.beta\\.kubernetes\\.io/azure-load-balancer-resource-group\"=$PublicIpAddressResourceGroupName\n`\n```\n\nFor more information please check here.",
      "question_score": 2,
      "answer_score": 5,
      "created_at": "2021-09-14T10:50:41",
      "url": "https://stackoverflow.com/questions/69174737/installing-nginx-ingress-in-aks-cluster-fails-with-syncloadbalancerfailed-error"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 67603606,
      "title": "How to setup a domain in GKE ingress nginx",
      "problem": "I have a cluster in GKE and it is working, everything seems to be working. If I forward the ports I am able to see that the containers are working.\nI am not able to setup a domain I own from namecheap.\nThese are the steps I followed\n\nIn Namecheap I setup a custom dns for the domain\n\n```\n`ns-cloud-c1.googledomains.com.\nns-cloud-c2.googledomains.com.\nns-cloud-c3.googledomains.com.\nns-cloud-c3.googledomains.com.\n`\n```\nI used the letter `c` because the cluster is in a `c` zone (I am not sure if this is right)\n\nBecause I am trying to setup as secure website I installed nginx ingress controller\n\n```\n`kubectl create clusterrolebinding cluster-admin-binding \\\n  --clusterrole cluster-admin \\\n  --user $(gcloud config get-value account)\n`\n```\nand\n```\n`kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.46.0/deploy/static/provider/cloud/deploy.yaml\n`\n```\n\nI applied the `issuer.yml`\n\n```\n`apiVersion: cert-manager.io/v1alpha2\nkind: ClusterIssuer\nmetadata:\n name: letsencrypt-prod\n namespace: cert-manager\nspec:\n acme:\n   # The ACME server URL\n   server: https://acme-v02.api.letsencrypt.org/directory\n   # Email address used for ACME registration\n   email: example@email.com\n   # Name of a secret used to store the ACME account private key\n   privateKeySecretRef:\n     name: letsencrypt-prod\n   # Enable the HTTP-01 challenge provider\n   solvers:\n   - http01:\n       ingress:\n         class:  nginx\n`\n```\n\nI applied ingress\n\n```\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  namespace: staging\n  name: ingress\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt-prod\"\nspec:\n  tls:\n    - hosts:\n      - www.stagingmyappsrl.com\n      - api.stagingmyappsrl.com\n      secretName: stagingmyappsrl-tls\n  rules:\n  - host: wwwstaging.myappsrl.com\n    http:\n      paths:\n      - backend:\n          serviceName: myappcatalogo-svc\n          servicePort: 80\n\n  - host: apistaging.stagingmyappsrl.com\n    http:\n      paths:\n      - backend:\n          serviceName: myappnodeapi-svc\n          servicePort: 80\n`\n```\nIt seems that everything is created and working if I check in GKE website, but when I try to access I get `DNS_PROBE_FINISHED_NXDOMAIN`\nI am not sure if I am missing an step or if I am setting up something wrong",
      "solution": "GKE should have created a cloud load balancer for your ingress service. Depending on your config, the LB can be internal or external. You can get your LB information by looking at the services:\n```\n`kubectl get svc -n ingress-nginx\n`\n```\nCreate a CNAME record in your DNS (namecheap) with the LB address and that should do it. Alternatively, if you have an IP address of the LB, create an A record in your DNS.\nCert-manager will create an ingress resource to resolve `HTTPS01` challenges. Make sure your ingresses are reachable over the Internet for the `HTTPS01` challenges to work. Alternatively, you could explore other solvers.",
      "question_score": 2,
      "answer_score": 5,
      "created_at": "2021-05-19T14:48:47",
      "url": "https://stackoverflow.com/questions/67603606/how-to-setup-a-domain-in-gke-ingress-nginx"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 67351729,
      "title": "Ingress - simple fanout configuration not working",
      "problem": "I'm using Ubuntu 20.04.2 LTS. I installed microk8s 1.20.6 rev 2143 and experimenting with ingress. I must be missing something - but it doesn't work as I expect it to. I tracked the strange behavior down to the following configuration:\ningress.yaml:\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-ubuntu\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n  - host: my-ubuntu\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n      - path: /nginx\n        pathType: Prefix\n        backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n`\nnginx-service.yaml:\n`apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\nspec:\n  ports:\n    - port: 80\n      name: http\n    - port: 443\n      name: https\n  type: ClusterIP\n  selector:\n    app: nginx\n`\nNow,\n`curl my-ubuntu/                     # this returns Welcome page, as expected\ncurl my-ubuntu/nginx                # this returns Welcome page, as expected\ncurl my-ubuntu/bad-page.html        # this returns 404 Not Found, as expected\ncurl my-ubuntu/nginx/bad-page.html  # this returns Welcome page. WHY?\n`\nAny request under my-ubuntu/nginx/* returns Welcome page, even when the url is correct and should have returned different content. Did I configure something wrong?\nI was able to reproduce the same strange behavior using Docker for Windows + WSL2 + Ubuntu + ingress installed using:\n`kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v0.41.2/deploy/static/provider/cloud/deploy.yaml\n`\nEDIT\nnginx-deployment.yaml I used:\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  revisionHistoryLimit: 0\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx\n        imagePullPolicy: Always\n        name: nginx\n`\nWhen I try `/nginx/` instead of `/nginx` like @HarshManvar suggested, I get this behavior:\n`curl my-ubuntu/                     # this returns Welcome page, as expected\ncurl my-ubuntu/bad-page.html        # this returns 404 Not Found, as expected\ncurl my-ubuntu/nginx                # this returns 404 Not Found\ncurl my-ubuntu/nginx/               # this returns Welcome page\ncurl my-ubuntu/nginx/bad-page.html  # this returns Welcome page\n`\nKubernetes Ingress documentation about Simple fanout also does use `/nginx` pattern but not working as described above.",
      "solution": "https://kubernetes.github.io/ingress-nginx/examples/rewrite/ explains how to use `rewrite-target` annotation. I was able to make it work with the following ingress.yaml:\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: my-ubuntu\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\nspec:\n  rules:\n  - host: localhost\n    http:\n      paths:\n      - path: /(.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n      - path: /nginx($|/.*)\n        pathType: Prefix\n        backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n`\nEach `path` defines regular expression with `( )`, which yields `$1`, `$2`, etc., aka. regex capture group variables. Now you put `rewrite-target` using those variables, and that will be the actual URL that is passed to the service's container that handles the request.\nMaybe there is another way, but this is the only way I was able to make it work.",
      "question_score": 2,
      "answer_score": 5,
      "created_at": "2021-05-02T01:32:31",
      "url": "https://stackoverflow.com/questions/67351729/ingress-simple-fanout-configuration-not-working"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 71558824,
      "title": "Enable CORS Kubernetes ingress issues",
      "problem": "I have a `Laravel` backend API and an `Angular` frontend. I deploy them with `Kubernetes \u2388` on Minikube.\n```\n`NAME                                      READY   STATUS    RESTARTS      AGE\npod/backend-deployment-bd4f98697-c2scp    1/1     Running   1 (22m ago)   23m\npod/frontend-deployment-8bc989f89-cxj67   1/1     Running   0             23m\npod/mysql-0                               1/1     Running   0             23m\n\nNAME                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nservice/backend-service    NodePort    10.108.40.53            8000:30670/TCP   23m\nservice/frontend-service   NodePort    10.105.57.226           4200:32353/TCP   23m\nservice/kubernetes         ClusterIP   10.96.0.1               443/TCP          25m\nservice/mysql              ClusterIP   None                    3306/TCP         23m\n\nNAME                                  READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/backend-deployment    1/1     1            1           23m\ndeployment.apps/frontend-deployment   1/1     1            1           23m\n\nNAME                                            DESIRED   CURRENT   READY   AGE\nreplicaset.apps/backend-deployment-bd4f98697    1         1         1       23m\nreplicaset.apps/frontend-deployment-8bc989f89   1         1         1       23m\n\nNAME                     READY   AGE\nstatefulset.apps/mysql   1/1     23m\n`\n```\nI can access both the front service and the back service with `minikube service SERVICE-NAME`.\n\nThis work perfectly. \u2705\n\nI have also an `Ingress` for the frontend.\n```\n`NAME               CLASS    HOSTS                          ADDRESS     PORTS   AGE\nfrontend-ingress      kubiapp-frontend-group35.com   localhost   80      27m\n`\n```\nI can access the `Ingress` with a curl. `curl http://kubiapp-frontend-group35.com`. \u2705\nBut, when I check the URL on a browser, I get some CORS errors.\n\nThe Ingress works but I have CORS Error. \u274c\n\n`frontend-ingress`:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"\n    nginx.ingress.kubernetes.io/enable-cors: \"true\"\n    nginx.ingress.kubernetes.io/cors-allow-origin: \"*\"\n    nginx.ingress.kubernetes.io/cors-allow-methods: \"PUT, GET, POST, OPTIONS, DELETE\"\n    nginx.ingress.kubernetes.io/cors-allow-headers: \"DNT,X-CustomHeader,X-LANG,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,X-Api-Key,X-Device-Id,Access-Control-Allow-Origin\"\n  name: frontend-ingress\n  labels:\n    name: frontend-ingress\nspec:\n  rules:\n    - host: kubiapp-frontend-group35.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: frontend-service\n                port:\n                  number: 4200\n`\n```\nI don't understand the Ingress annotation well, does it enable CORS policy for the Frontend? Shouldn't I make it for the Backend? Do I have to create a Backend Ingress?\nEDIT:\nThe error message was:\n\nCross-Origin Request Blocked: The Same Origin Policy disallows reading the remote resource at http://backend-service:8000/api/health. (Reason: CORS request did not succeed). Status code: (null).\n\nTL;DR :\nI can access the Ingress URL, but I have CORS errors. How to solve it with `Kubernetes`",
      "solution": "The mistake I made was using the `Kubernetes` annotations for the Frontend Ingress.\nWhat I had to do was create a Backend Ingress as well, that used the annotations:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"\n    nginx.ingress.kubernetes.io/enable-cors: \"true\"\n    nginx.ingress.kubernetes.io/cors-allow-origin: \"*\"\n    nginx.ingress.kubernetes.io/cors-allow-methods: \"PUT, GET, POST, OPTIONS, DELETE\"\n    nginx.ingress.kubernetes.io/cors-allow-headers: \"DNT,X-CustomHeader,X-LANG,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,X-Api-Key,X-Device-Id,Access-Control-Allow-Origin\"\n  name: backend-ingress\n  labels:\n    name: backend-ingress\nspec:\n  rules:\n    - host: kubiapp-backend-group35.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: backend-service\n                port:\n                  number: 8000\n`\n```\nThe frontend app, will now communicate correctly with `http://kubiapp-backend-group35.com`.",
      "question_score": 2,
      "answer_score": 4,
      "created_at": "2022-03-21T14:56:23",
      "url": "https://stackoverflow.com/questions/71558824/enable-cors-kubernetes-ingress-issues"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 71349571,
      "title": "Unable to start nginx-ingress-controller Readiness and Liveness probes failed",
      "problem": "I have installed using instructions at this link for the Install NGINX using NodePort option.\nWhen I do `ks logs -f ingress-nginx-controller-7f48b8-s7pg4 -n ingress-nginx` I get :\n```\n`W0304 09:33:40.568799       8 client_config.go:614] Neither --kubeconfig nor --master was \nspecified.  Using the inClusterConfig.  This might not work.\nI0304 09:33:40.569097       8 main.go:241] \"Creating API client\" host=\"https://10.96.0.1:443\"\nI0304 09:33:40.584904       8 main.go:285] \"Running in Kubernetes cluster\" major=\"1\" minor=\"23\" git=\"v1.23.1+k0s\" state=\"clean\" commit=\"b230d3e4b9d6bf4b731d96116a6643786e16ac3f\" platform=\"linux/amd64\"\nI0304 09:33:40.911443       8 main.go:105] \"SSL fake certificate created\" file=\"/etc/ingress-controller/ssl/default-fake-certificate.pem\"\nI0304 09:33:40.916404       8 main.go:115] \"Enabling new Ingress features available since Kubernetes v1.18\"\nW0304 09:33:40.918137       8 main.go:127] No IngressClass resource with name nginx found. Only annotation will be used.\nI0304 09:33:40.942282       8 ssl.go:532] \"loading tls certificate\" path=\"/usr/local/certificates/cert\" key=\"/usr/local/certificates/key\"\nI0304 09:33:40.977766       8 nginx.go:254] \"Starting NGINX Ingress controller\"\nI0304 09:33:41.007616       8 event.go:282] Event(v1.ObjectReference{Kind:\"ConfigMap\", Namespace:\"ingress-nginx\", Name:\"ingress-nginx-controller\", UID:\"1a4482d2-86cb-44f3-8ebb-d6342561892f\", APIVersion:\"v1\", ResourceVersion:\"987560\", FieldPath:\"\"}): type: 'Normal' reason: 'CREATE' ConfigMap ingress-nginx/ingress-nginx-controller\nE0304 09:33:42.087113       8 reflector.go:138] k8s.io/client-go@v0.20.2/tools/cache/reflector.go:167: Failed to watch *v1beta1.Ingress: failed to list *v1beta1.Ingress: the server could not find the requested resource\nE0304 09:33:43.041954       8 reflector.go:138] k8s.io/client-go@v0.20.2/tools/cache/reflector.go:167: Failed to watch *v1beta1.Ingress: failed to list *v1beta1.Ingress: the server could not find the requested resource\nE0304 09:33:44.724681       8 reflector.go:138] k8s.io/client-go@v0.20.2/tools/cache/reflector.go:167: Failed to watch *v1beta1.Ingress: failed to list *v1beta1.Ingress: the server could not find the requested resource\nE0304 09:33:48.303789       8 reflector.go:138] k8s.io/client-go@v0.20.2/tools/cache/reflector.go:167: Failed to watch *v1beta1.Ingress: failed to list *v1beta1.Ingress: the server could not find the requested resource\nE0304 09:33:59.113203       8 reflector.go:138] k8s.io/client-go@v0.20.2/tools/cache/reflector.go:167: Failed to watch *v1beta1.Ingress: failed to list *v1beta1.Ingress: the server could not find the requested resource\nE0304 09:34:16.727052       8 reflector.go:138] k8s.io/client-go@v0.20.2/tools/cache/reflector.go:167: Failed to watch *v1beta1.Ingress: failed to list *v1beta1.Ingress: the server could not find the requested resource\nI0304 09:34:39.216165       8 main.go:187] \"Received SIGTERM, shutting down\"\nI0304 09:34:39.216773       8 nginx.go:372] \"Shutting down controller queues\"\nE0304 09:34:39.217779       8 store.go:178] timed out waiting for caches to sync\nI0304 09:34:39.217856       8 nginx.go:296] \"Starting NGINX process\"\nI0304 09:34:39.218007       8 leaderelection.go:243] attempting to acquire leader lease ingress-nginx/ingress-controller-leader-nginx...\nI0304 09:34:39.219741       8 queue.go:78] \"queue has been shutdown, failed to enqueue\" key=\"&ObjectMeta{Name:initial-sync,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:,DeletionGracePeriodSeconds:nil,Labels:map[string]string{},Annotations:map[string]string{},OwnerReferences:[]OwnerReference{},Finalizers:[],ClusterName:,ManagedFields:[]ManagedFieldsEntry{},}\"\nI0304 09:34:39.219787       8 nginx.go:316] \"Starting validation webhook\" address=\":8443\" certPath=\"/usr/local/certificates/cert\" keyPath=\"/usr/local/certificates/key\"\nI0304 09:34:39.242501       8 leaderelection.go:253] successfully acquired lease ingress-nginx/ingress-controller-leader-nginx\nI0304 09:34:39.242807       8 queue.go:78] \"queue has been shutdown, failed to enqueue\" key=\"&ObjectMeta{Name:sync status,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:,DeletionGracePeriodSeconds:nil,Labels:map[string]string{},Annotations:map[string]string{},OwnerReferences:[]OwnerReference{},Finalizers:[],ClusterName:,ManagedFields:[]ManagedFieldsEntry{},}\"\nI0304 09:34:39.242837       8 status.go:84] \"New leader elected\" identity=\"ingress-nginx-controller-7f48b8-s7pg4\"\nI0304 09:34:39.252025       8 status.go:204] \"POD is not ready\" pod=\"ingress-nginx/ingress-nginx-controller-7f48b8-s7pg4\" node=\"fbcdcesdn02\"\nI0304 09:34:39.255282       8 status.go:132] \"removing value from ingress status\" address=[]\nI0304 09:34:39.255328       8 nginx.go:380] \"Stopping admission controller\"\nI0304 09:34:39.255379       8 nginx.go:388] \"Stopping NGINX process\"\nE0304 09:34:39.255664       8 nginx.go:319] \"Error listening for TLS connections\" err=\"http: Server closed\"\n2022/03/04 09:34:39 [notice] 43#43: signal process started\nI0304 09:34:40.263361       8 nginx.go:401] \"NGINX process has stopped\"\nI0304 09:34:40.263396       8 main.go:195] \"Handled quit, awaiting Pod deletion\"\nI0304 09:34:50.263585       8 main.go:198] \"Exiting\" code=0\n`\n```\nWhen I do `ks describe pod ingress-nginx-controller-7f48b8-s7pg4 -n ingress-nginx` I get :\n```\n`Name:         ingress-nginx-controller-7f48b8-s7pg4\nNamespace:    ingress-nginx\nPriority:     0\nNode:         fxxxxxxxx/10.XXX.XXX.XXX\nStart Time:   Fri, 04 Mar 2022 08:12:57 +0200\nLabels:       app.kubernetes.io/component=controller\n              app.kubernetes.io/instance=ingress-nginx\n              app.kubernetes.io/name=ingress-nginx\n              pod-template-hash=7f48b8\nAnnotations:  kubernetes.io/psp: 00-k0s-privileged\nStatus:       Running\nIP:           10.244.0.119\nIPs:\n  IP:           10.244.0.119\nControlled By:  ReplicaSet/ingress-nginx-controller-7f48b8\nContainers:\n  controller:\n    Container ID:  containerd://638ff4d63b7ba566125bd6789d48db6e8149b06cbd9d887ecc57d08448ba1d7e\n    Image:         k8s.gcr.io/ingress-nginx/controller:v0.48.1@sha256:e9fb216ace49dfa4a5983b183067e97496e7a8b307d2093f4278cd550c303899\n    Image ID:      k8s.gcr.io/ingress-nginx/controller@sha256:e9fb216ace49dfa4a5983b183067e97496e7a8b307d2093f4278cd550c303899\n    Ports:         80/TCP, 443/TCP, 8443/TCP\n    Host Ports:    0/TCP, 0/TCP, 0/TCP\n    Args:\n      /nginx-ingress-controller\n      --election-id=ingress-controller-leader\n      --ingress-class=nginx\n      --configmap=$(POD_NAMESPACE)/ingress-nginx-controller\n      --validating-webhook=:8443\n      --validating-webhook-certificate=/usr/local/certificates/cert\n      --validating-webhook-key=/usr/local/certificates/key\n    State:          Waiting\n      Reason:       CrashLoopBackOff\n    Last State:     Terminated\n      Reason:       Completed\n      Exit Code:    0\n      Started:      Fri, 04 Mar 2022 11:33:40 +0200\n      Finished:     Fri, 04 Mar 2022 11:34:50 +0200\n    Ready:          False\n    Restart Count:  61\n    Requests:\n      cpu:      100m\n      memory:   90Mi\n    Liveness:   http-get http://:10254/healthz delay=10s timeout=1s period=10s #success=1 #failure=5\n    Readiness:  http-get http://:10254/healthz delay=10s timeout=1s period=10s #success=1 #failure=3\n    Environment:\n      POD_NAME:       ingress-nginx-controller-7f48b8-s7pg4 (v1:metadata.name)\n      POD_NAMESPACE:  ingress-nginx (v1:metadata.namespace)\n      LD_PRELOAD:     /usr/local/lib/libmimalloc.so\n    Mounts:\n      /usr/local/certificates/ from webhook-cert (ro)\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-zvcnr (ro)\nConditions:\n  Type              Status\n  Initialized       True\n  Ready             False\n  ContainersReady   False\n  PodScheduled      True\nVolumes:\n  webhook-cert:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  ingress-nginx-admission\n    Optional:    false\n  kube-api-access-zvcnr:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       \n    DownwardAPI:             true\nQoS Class:                   Burstable\nNode-Selectors:              kubernetes.io/os=linux\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type     Reason     Age                     From     Message\n  ----     ------     ----                    ----     -------\n  Warning  Unhealthy  23m (x316 over 178m)    kubelet  Readiness probe failed: HTTP probe failed with statuscode: 500\n  Warning  BackOff    8m52s (x555 over 174m)  kubelet  Back-off restarting failed container\n  Normal   Pulled     3m54s (x51 over 178m)   kubelet  Container image \"k8s.gcr.io/ingress-nginx/controller:v0.48.1@sha256:e9fb216ace49dfa4a5983b183067e97496e7a8b307d2093f4278cd550c303899\" already present on machine\n`\n```\nWhen I try to curl the health endpoints I get Connection refused :\n\nThe state of the pods shows that they are both not ready  :\n```\n`NAME                                    READY   STATUS             RESTARTS       AGE\ningress-nginx-admission-create-4hzzk    0/1     Completed          0              3h30m\ningress-nginx-controller-7f48b8-s7pg4   0/1     CrashLoopBackOff   63 (91s ago)   3h30m\n`\n```\nI have tried to increase the values for initialDelaySeconds in /etc/nginx/nginx.conf but when I attempt to exec into the container (ks exec  -it  -n ingress-nginx ingress-nginx-controller-7f48b8-s7pg4  -- bash) I also get an error error: unable to upgrade connection: container not found (\"controller\")\nI am not really sure where I should be looking in the overall setup.",
      "solution": "I have installed using instructions at this link for the Install NGINX using NodePort option.\n\nThe problem is that you are using outdated k0s documentation:\n`https://docs.k0sproject.io/v1.22.2+k0s.1/examples/nginx-ingress/`\nYou should use this link instead:\n`https://docs.k0sproject.io/main/examples/nginx-ingress/`\nYou will install the `controller-v1.0.0` version on your Kubernetes cluster by following the actual documentation link.\n```\n`$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.0.0/deploy/static/provider/baremetal/deploy.yaml\n`\n```\nThe result is:\n`$ sudo k0s kubectl get pods -n ingress-nginx\nNAME                                        READY   STATUS      RESTARTS   AGE\ningress-nginx-admission-create-dw2f4        0/1     Completed   0          11m\ningress-nginx-admission-patch-4dmpd         0/1     Completed   0          11m\ningress-nginx-controller-75f58fbf6b-xrfxr   1/1     Running     0          11m\n`",
      "question_score": 2,
      "answer_score": 4,
      "created_at": "2022-03-04T10:54:33",
      "url": "https://stackoverflow.com/questions/71349571/unable-to-start-nginx-ingress-controller-readiness-and-liveness-probes-failed"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69801758,
      "title": "Why these ingress rules don&#39;t expose a service to outside? (NET::ERR_CERT_AUTHORITY_INVALID/ERR_TOO_MANY_REDIRECTS)",
      "problem": "I'm trying to setup and expose a service (ArgoCD) to outside a cluster. Note: I'm fairly new to Kubernetes, so quite probably I have some misconceptions. If you can see one, please help me get rid of it. If more information is needed to diagnose what's happening, please let me know, I'll add it.\nI have nginx-ingress ingress controller installed in the cluster in the namespace `nginx`. I have installed ArgoCD via helm into `argocd` namespace*. `kubectl get service -n argocd` shows (omitting AGE column):\n```\n`NAME                                        TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)\nprojectname-argocd-application-controller   ClusterIP   10.100.249.133           8082/TCP\nprojectname-argocd-dex-server               ClusterIP   10.100.80.187            5556/TCP,5557/TCP\nprojectname-argocd-redis                    ClusterIP   10.100.230.170           6379/TCP\nprojectname-argocd-repo-server              ClusterIP   10.100.221.87            8081/TCP\nprojectname-argocd-server                   ClusterIP   10.100.22.26             80/TCP,443/TCP\n`\n```\nAs far as I understand, service `projectname-argocd-server` is the one I should expose to get ArgoCD WebUI. Trying to do so, I've created an ingress (based on docs):\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-routing\n\nspec:\n  rules:\n  - host: test2.projectname.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix # presumably may comment this out\n        backend:\n          service:\n            name: projectname-argocd-server\n            port:\n              number: 80\n  # this was added later while trying to figure the problem out\n  defaultBackend:\n    service:\n      name: projectname-argocd-server\n      port:\n        number: 80\n  ingressClassName: nginx\n`\n```\nand applied it via `kubectl apply -f routing.yaml -n argocd`. Now I can see the ingress is created along with the one created by deployment of ArgoCD, and the output of `kubectl get ing -A` is (omitting AGE, and PORTS that are 80; `` is url of LoadBalancer shown in AWS console):\n```\n`NAMESPACE   NAME                        CLASS    HOSTS                   ADDRESS\nargocd      projectname-argocd-server   nginx    test.projectname.org    \nargocd      ingress-routing             nginx    test2.projectname.org   \n`\n```\nBy the way, `kubectl get svc -n nginx` shows that `nginx-ingress-ingress-nginx-controller` is LoadBalancer with url `` (`80:30538/TCP`).\n`kubectl describe ingress -n argocd` shows that ingress `ingress-routing` is ok, with correct address, default backend and rules; for ingress `projectname-argocd-server` it shows ok address and rules (path `/`), although `Default backend` is shown as `default-http-backend:80 ()`.\nNow let me also show the DNS settings to complete the picture:\n\nI've created a hosted zone for projectname.org (in Route 53), put its DNS servers to NS-entries of domain register\nI've created a CNAME entry in the hosted zone, pointing `test.projectname.org` to ``\nI've created an A entry for `test2.projectname.org`, selected the load balancer from the list and so it points to `dualstack.`\n\nI expected to see ArgoCD interface at least at one of `http://test.projectname.org/` and `http://test2.projectname.org/`. What actually happens is:\n\nwhen I open `http://test.projectname.org/`, it redirects me to https url and shows `NET::ERR_CERT_AUTHORITY_INVALID`. If I insist on visiting, browser shows `ERR_TOO_MANY_REDIRECTS`.\n\nBefore I added ingress class and moved `ingress-routing` from `nginx` namespace to `argocd` namespace, `http://test2.projectname.org/` gave me 404; now it also redirects to https and then gives `ERR_TOO_MANY_REDIRECTS`\n\nI've also checked the `/healthz` addresses but they give the same result as the `/` ones. (in contrast, `http:///healthz` gives an empty page)\n\nMy question is: what else am I missing, why I don't get the UI?\nIs it impossible to expose a service before setting some SSL certificate? Can 2 ingresses conflict when trying to expose the same thing on different subdomains (test.projectname.org and test2.projectname.org)? Can I see at least one service (ArgoCD) without using projectname.org to check if it is configured and deployed properly? (to separate if it's an ingress/routing/dns issue or a configuration issue)\n(*) Here's the chart that I used to install ArgoCD:\n```\n`apiVersion: v2\nname: argo-cd\nappVersion: v2.1.5\ndescription: A declarative, GitOps continuous delivery tool for Kubernetes\nversion: 3.26.3\n\ndependencies:\n  - name: argo-cd\n    version: 3.26.3\n    repository: https://argoproj.github.io/argo-helm\n`\n```\nand values-overwrite.yaml that I've used is just default values wrapped into `argo-cd:` thing since these should be applied to the dependency. Notably, those have `enabled: false` in `ingress:`, so the fact that ingress `projectname-argocd-server` is created is somewhat unexpected.\nPS the `nginx` IngressClass was generated, not created manually, so it may be useful to see it as well (I've substituted ids and timestamps with \"...\"), as shown by `kubectl get IngressClass nginx -o yaml`:\n```\n`apiVersion: networking.k8s.io/v1\nkind: IngressClass\nmetadata:\n  annotations:\n    meta.helm.sh/release-name: nginx-ingress\n    meta.helm.sh/release-namespace: nginx\n  creationTimestamp: ...\n  generation: 1\n  labels:\n    app.kubernetes.io/component: controller\n    app.kubernetes.io/instance: nginx-ingress\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/version: 1.0.3\n    helm.sh/chart: ingress-nginx-4.0.5\n  name: nginx\n  resourceVersion: \"5750\"\n  uid: ...\nspec:\n  controller: k8s.io/ingress-nginx\n`\n```",
      "solution": "Right, the issue was somewhat complicated, but I've figured it out. Basically, it consists of 2 problems:\n\nhttps configuration and\ningress configuration\n\nThe main problem about https configuration was solved in a separate question and is reduced to switching ACME server from staging to production. I've provided more details it in my answer.\nNow, the ingress configuration is somewhat tricky since ArgoCD has some redirections, ~inner TLS requirements~, and also serves more than one protocol at :443. Fortunately, I've found this tutorial which shows ssl-passthrough settings, more ingress annotations, including `nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"` which fixes the `ERR_TOO_MANY_REDIRECTS` error. Here's my ingress config which works fine with https set up (note also changes in port and tls secret):\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-argocd-routing\n  namespace: argocd\n  annotations:\n    cert-manager.io/cluster-issuer: \n    kubernetes.io/tls-acme: \"true\"\n    nginx.ingress.kubernetes.io/ssl-passthrough: \"true\"\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\nspec:\n  ingressClassName: nginx\n  tls:\n    - hosts:\n      - test2.projectname.org # switched to argocd. later\n      secretName: argocd-secret # do not change, this is provided by Argo CD\n  rules:\n    - host: test2.projectname.org # switched to argocd. later\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: projectname-argocd-server\n                port:\n                  number: 443\n`\n```",
      "question_score": 2,
      "answer_score": 4,
      "created_at": "2021-11-01T20:18:12",
      "url": "https://stackoverflow.com/questions/69801758/why-these-ingress-rules-dont-expose-a-service-to-outside-neterr-cert-author"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 67991420,
      "title": "Why does attempting to connect to my ingress show connection refused?",
      "problem": "I'm running kubernetes 1-21-0 on Centos7. I've set up a keycloak service to test my ingress controller and am able to access the keycloak on the host url with the keycloak port like `myurl.com:30872`. These are my running services:\n```\n`NAMESPACE       NAME                                 TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\ndefault         keycloak                             NodePort    10.96.11.164            8080:30872/TCP               21h\ndefault         kubernetes                           ClusterIP   10.96.0.1               443/TCP                      11d\ningress-nginx   ingress-nginx-controller             NodePort    10.102.201.24           80:31110/TCP,443:30566/TCP   9m45s\ningress-nginx   ingress-nginx-controller-admission   ClusterIP   10.107.90.207           80/TCP,443/TCP               9m45s\nkube-system     kube-dns                             ClusterIP   10.96.0.10              53/UDP,53/TCP,9153/TCP       11d\n`\n```\nI've deployed the following nginx ingress controller.\nAnd added an HTTP webhook to the service:\n```\n`# Source: ingress-nginx/templates/controller-service-webhook.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    helm.sh/chart: ingress-nginx-3.23.0\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/version: 0.44.0\n    app.kubernetes.io/managed-by: Helm\n    app.kubernetes.io/component: controller\n  name: ingress-nginx-controller-admission\n  namespace: ingress-nginx\nspec:\n  type: ClusterIP\n  ports:\n    - name: http-webhook\n      port: 80\n      targetPort: webhook\n    - name: https-webhook\n      port: 443\n      targetPort: webhook\n  selector:\n    app.kubernetes.io/name: ingress-nginx\n    app.kubernetes.io/instance: ingress-nginx\n    app.kubernetes.io/component: controller\n`\n```\nWith this ingress:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: keycloak\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n    - http:\n        paths:\n        - path: /keycloak\n          pathType: Prefix\n          backend:\n            service:\n              name: keycloak\n              port: \n                number: 8080\n`\n```\nNow when I attempt to connect to the keycloak service through the ingress I go to `myurl.com/keycloak` but it's unable to connect and trying to curl it from within my control node shows connection refused:\n```\n`# curl -I http://127.0.0.1/keycloak\ncurl: (7) Failed connect to 127.0.0.1:80; Connection refused\n`\n```\nCan someone see what I'm missing?\nEdit:\nI realized the ingress controller actually works, but I need to specify its port also to reach it like this:\n```\n`curl -I http://127.0.0.1:31110/keycloak\n`\n```\nWhich I'd like to avoid.",
      "solution": "You have to specify `31110` port because your nginx ingress is set up with `NodePort` which means kubernetes listens to this port and all traffic that goes here is redirected to `nginx-ingress-controller` pod.\nDepending on your setup and goals, this can be achieved differently.\nOption 1 - for testing purposes only and without any changes in setup. Works only on a control plane where `nginx-ingress-controller` pod is running\nit's possible to forward traffic from outside port 80 to `nginx-ingress-controller` pod directly port 80. You can run this command (in background):\n```\n`sudo kubectl port-forward ingress-nginx-controller-xxxxxxxx-yyyyy 80:80 -n ingress-nginx &\n`\n```\nCurl test shows that it's working:\n```\n`curl -I localhost/keycloak\nHandling connection for 80\nHTTP/1.1 200 OK\nDate: Wed, 16 Jun 2021 13:19:23 GMT\n`\n```\nCurl can be run on different instance, in this case command will look this way without specifying any ports:\n```\n`curl -I public_ip/keycloak\n`\n```\nOption 2 - this one is a bit more difficult, however provides better results.\nIt's possible to expose pods outside of the cluster. Feature is called `hostPort` - it allows to expose a single container port on the host IP. To have this work on different worker nodes, `ingress-nginx-controller` should be deployed as `DaemonSet`.\nBelow parts in `values.yaml` for ingress-nginx helm chart that I corrected:\nhostPort -> enabled -> true\n```\n`  ## Use host ports 80 and 443\n  ## Disabled by default\n  ##\n  hostPort:\n    enabled: true\n    ports:\n      http: 80\n      https: 443\n`\n```\nkind -> DaemonSet\n```\n`  ## DaemonSet or Deployment\n  ##\n  kind: DaemonSet\n`\n```\nThen install ingress-nginx-controller from this chart.\nWhat it does is by default `ingress-nginx-controller` pods will listen to traffic on 80 and 443 port.\nWhich confirms with simple test:\n```\n`curl -I localhost/keycloak\nHTTP/1.1 200 OK\nDate: Wed, 16 Jun 2021 13:31:25 GMT\n`\n```\nOption 3 - may be considered as well if ingress-nginx is installed with LoadBalancer type.\nUse `metallb` - software loadbalancer specifically designed for bare metal clusters. How to install metallb and configure\nOnce it's done and ingress-nginx is deployed, ingress-nginx will get External-IP:\nkubectl get svc --all-namespaces\n```\n`NAMESPACE       NAME                                 TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)                      AGE\ningress-nginx   ingress-nginx-controller             LoadBalancer   10.102.135.146   192.168.1.240   80:32400/TCP,443:32206/TCP   43s\n`\n```\nTesting this again with `curl`:\n```\n`curl -I 192.168.1.240/keycloak\nHTTP/1.1 200 OK\nDate: Wed, 16 Jun 2021 13:55:34 GMT\n`\n```\nMore information about topics above:\n\nhostPorts and hostNetwork\nMetallb project",
      "question_score": 2,
      "answer_score": 4,
      "created_at": "2021-06-15T20:06:55",
      "url": "https://stackoverflow.com/questions/67991420/why-does-attempting-to-connect-to-my-ingress-show-connection-refused"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 75514228,
      "title": "Deployed Nginx Ingress Controller but service with type LoadBalancer has external IP pending",
      "problem": "I have a k3s (light weighted k8s) cluster running on my Raspberry PI. So, I am not using any cloud hosted cluster but a bear metal one on my Raspberry PI.\nI have deployed a application with this manifest:\n```\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-world\n  namespace: myapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: hello-world\n  template:\n    metadata:\n      labels:\n        app: hello-world\n    spec:\n      containers:\n        - name: hello-world\n          image: bashofmann/rancher-demo:1.0.0\n          imagePullPolicy: Always\n          resources:\n            requests:\n              cpu: 200m\n          ports:\n          - containerPort: 8080\n            name: web\n            protocol: TCP\n`\n```\nI also created a service to forward traffic to the application pod. Its manifest is:\n```\n`apiVersion: v1\nkind: Service\nmetadata:\n  name: demo-app-svc\n  namespace: myapp\nspec:\n  selector:\n    app: hello-world\n  ports:\n  - name: web\n    protocol: TCP\n    port: 31113\n    targetPort: 8080\n`\n```\nThen, I created a Ingress for the routing rules:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: myapp-ing\n  namespace: myapp\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx \n  rules:\n  - host: myapp.com\n    http:\n      paths:\n      - pathType: Prefix\n        path: /\n        backend:\n          service:\n            name: demo-app-svc \n            port:\n              number: 31113\n\n`\n```\nI successfully deployed above application pod, service & Ingress to my k3s cluster.  Like the manifests indicate, they are under namespace `myapp`.\nThe next thing I would like to do is to deploy the Kubernetes Nginx Ingress Controller in order to have the clients outside the cluster be able to access the deployed application.\nSo, I deployed it by :\n```\n`kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.1.2/deploy/static/provider/cloud/deploy.yaml\n`\n```\nThe above command successfully deployed Ingress Controller under namespace `ingress-nginx` along with other objects as shown below with command `k get all -n ingress-nginx`:\n\nAs you can see above, the `LoadBalancer` type `service` external IP is with value ``. So, client outside the cluster still can not access the application pod.\nWhy is that & what do I miss deploying the Nginx Ingress Controller on a bear metal machine? The goal is to have an external IP that can be used to access the application pod from outside cluster, how can I achieve that?\n===== Update =====\nBased on the answer below from @Dawid Kruk , I decided to use the k3s default Traefik Ingress Controller.\nSo, I deleted all the deployed Nginx Ingress Controller resources by `k delete all --all -n ingress-nginx` .\nThen, I checked the Traefik Ingress related `LoadBalancer` type service:\n\nThe `external IP` of that Traefik service is exactly my Raspberry PI's IP address!\nSo, added this IP to `/etc/hosts` to map it to the hostname defined in my Ingress object:\n```\n`192.168.10.203 myapp.com\n`\n```\nI opened browser & use address http://myapp.com, with the routing rules defined in my `Ingress` object (see the manifest for my ingress above), I hoped I could see my deployed web application now. But get `404 Page Not Found`.  What am I missing now to access my deployed application?\nAnother side question: I noticed when I check the deployed `Ingress` object, its IP address is empty, I wonder am I supposed to see an IP address for this object or not when the Traefik Ingress Controller takes effect?\n\nAnother issue: Now, when I re-deploy my ingress manifest by `k apply -f ingress.yaml`, I get error:\n```\n`Resource: \"networking.k8s.io/v1, Resource=ingresses\", GroupVersionKind: \"networking.k8s.io/v1, Kind=Ingress\"\n...\nfor: \"ingress.yaml\": error when patching \"ingress.yaml\": Internal error occurred: failed calling webhook \"validate.nginx.ingress.kubernetes.io\": failed to call webhook: Post \"https://ingress-nginx-controller-admission.ingress-nginx.svc:443/networking/v1/ingresses?timeout=10s\": service \"ingress-nginx-controller-admission\" not found\n`\n```\nIt looks like even I decided to use Traefik Ingress Controller, I still need to instal Nginx Ingress Controller. I get confused now, anyone can explain it?",
      "solution": "I'm not K3S expert but I think I found a piece of documentation that is addressing your issue.\nTake a look:\n\nService Load Balancer\nAny service load balancer (LB) can be used in your K3s cluster. By default, K3s provides a load balancer known as ServiceLB (formerly Klipper Load Balancer) that uses available host ports.\nUpstream Kubernetes allows Services of type LoadBalancer to be created, but doesn't include a default load balancer implementation, so these services will remain `pending` until one is installed. Many hosted services require a cloud provider such as Amazon EC2 or Microsoft Azure to offer an external load balancer implementation. By contrast, the K3s ServiceLB makes it possible to use LoadBalancer Services without a cloud provider or any additional configuration.\nHow the Service LB Works\nThe ServiceLB controller watches Kubernetes Services with the `spec.type` field set to `LoadBalancer`.\nFor each LoadBalancer Service, a DaemonSet is created in the `kube-system` namespace. This DaemonSet in turn creates Pods with a `svc-` prefix, on each node. These Pods use iptables to forward traffic from the Pod's NodePort, to the Service's ClusterIP address and port.\nIf the ServiceLB Pod runs on a node that has an external IP configured, the node's external IP is populated into the Service's `status.loadBalancer.ingress` address list. Otherwise, the node's internal IP is used.\nIf multiple LoadBalancer Services are created, a separate DaemonSet is created for each Service.\nIt is possible to expose multiple Services on the same node, as long as they use different ports.\nIf you try to create a LoadBalancer Service that listens on port 80, the ServiceLB will try to find a free host in the cluster for port 80. If no host with that port is available, the LB will remain Pending.\n-- Docs.k3s.io: Networking\n\nAs a possible solution, I'd recommend to use `Traefik` as it's a default `Ingress` controller within `K3S`.\nThe `Pending` status on your `LoadBalancer` is most likely caused by another service used on that port (`Traefik`).\nIf you wish to still use `NGINX`, the same documentation page explains how you can disable `Traefik`.\n\nUPDATE\nI'd be more careful to delete resources as you did. The following command:\n\n`k delete all --all -n ingress-nginx`\n\nWill not delete all of the resources created. The better way in my opinion would be to use the command that you've used to create and instead of:\n\n`kubectl create -f ...`\n\nUse:\n\n`kubectl delete -f ...`\n\nI assume that you did not modify your `Ingress` definition, hence you receive the error and the `kubectl get ingress` is showing incorrect results.\nWhat you will need to do:\n`spec:\n  ingressClassName: nginx # \nEither delete or change should work as `traefik` is set to be a default `IngressClass` for this setup.",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2023-02-20T22:17:45",
      "url": "https://stackoverflow.com/questions/75514228/deployed-nginx-ingress-controller-but-service-with-type-loadbalancer-has-externa"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 75490731,
      "title": "Warning: Rejected - All hosts are taken by other resources",
      "problem": "I'm trying to setup `Nginx-ingress controller` to manage two paths on the same `hostname` in bare metal based cluster.\nIn the app1 namespace i have below nginx resource:-\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app1-ingress\n  namespace: app1\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: web.example.com\n    http:\n      paths:\n      - path: /app1\n        pathType: Prefix\n        backend:\n          service:\n            name: app1-service\n            port:\n              number: 80\n`\n```\nAnd in the app2 namespace i have below nginx resource:-\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app2-ingress\n  namespace: app2\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: web.example.com\n    http:\n      paths:\n      - path: /app2\n        pathType: Prefix\n        backend:\n          service:\n            name: app2-service\n            port:\n              number: 80\n`\n```\nMy `app1-service` applied first and it is running fine, now when i applied the second `app2-service` it shows below warning and not able to access it on browser.\n```\n`Annotations:       \nEvents:\n  Type     Reason    Age   From                      Message\n  ----     ------    ----  ----                      -------\n  Warning  Rejected  54s   nginx-ingress-controller  All hosts are taken by other resources\n  Warning  Rejected  54s   nginx-ingress-controller  All hosts are taken by other resources\n  Warning  Rejected  54s   nginx-ingress-controller  All hosts are taken by other resources\n`\n```\nHow do i configure my nginx ingress resource to connect multiple service paths on the same hostname?",
      "solution": "Default Nginx Ingress controller doesn't support having different `Ingress` resources with the same hostname. You can have one `Ingress` resource that contains multiple paths, but in this case all apps should live in one namespace. Like this:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: app1-ingress\n  namespace: app1\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: web.example.com\n    http:\n      paths:\n      - path: /app1\n        pathType: Prefix\n        backend:\n          service:\n            name: app1-service\n            port:\n              number: 80\n      - path: /app2\n        pathType: Prefix\n        backend:\n          service:\n            name: app2-service\n            port:\n              number: 80\n`\n```\nSplitting ingresses between namespaces is currently not supported by standard Nginx Ingress controller.\nYou may however take a look at an alternative implementation of Nginx Ingress by Nginx Inc. They have support for Mergeable Ingresses.",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2023-02-18T03:02:59",
      "url": "https://stackoverflow.com/questions/75490731/warning-rejected-all-hosts-are-taken-by-other-resources"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 75451560,
      "title": "Cluster-issuer secret wont replicate with multiple ingress",
      "problem": "I was under the impression that the main point of cluster-issuer is that its namespaced and doesn't have to be recreated across different resources, in general there could be one main cluster-issuer that will manage all ingresses across the cluster.\nFrom what I am seeing the cluster-issuer can only create one secret and if its in use by one ingress the second wont wont be created properly cause its already taken.\nIs there anyway to create one cluster-issuer to manage all ingresses across the cluster?\nCode included below\nCluster-issuer.yaml\n```\n`apiVersion: cert-manager.io/v1\nkind: ClusterIssuer\nmetadata:\n  name: letsencrypt-grafana\n  namespace: cert-manager\nspec:\n  acme:\n    server: https://acme-v02.api.letsencrypt.org/directory\n    email: foo@gmail.com\n    privateKeySecretRef:\n      name: letsencrypt-grafana\n    solvers:\n    - selector:\n        dnsZones:\n          - \"foo.com\"\n      dns01:\n        route53:\n          region: eu-central-1\n          hostedZoneID: foo\n          accessKeyID: foo\n          secretAccessKeySecretRef:\n            name: aws-route53-creds\n            key: password.txt\n`\n```\nIngress.yaml\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: grafana-ingress\n  namespace: loki\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-grafana\n    kubernetes.io/tls-acme: \"true\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/proxy-body-size:  \"125m\"\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - grafana.foo.com\n    secretName: letsencrypt-grafana # < cert-manager will store the created certificate in this secret.\n  rules:\n  - host: grafana.foo.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: loki-grafana\n            port:\n              number: 80\n`\n```",
      "solution": "@Harsh Manvar while I do appreciate your anwser I found something that is a better suit for my needs.\nCert-manager documentation contains multiple options to sync secrets across namespaces\nThe one I chose was reflector. The steps to install are included in the documentation but just for the sake of service i'll post here aswell\nRequirements: Helm\nInstallation:\n```\n`helm repo add emberstack https://emberstack.github.io/helm-charts\nhelm repo update\nhelm upgrade --install reflector emberstack/reflector\n`\n```\nSetup:\nAdd the following annotation to your secret `reflector.v1.k8s.emberstack.com/reflection-allowed: \"true\"`, it should look like the following\n```\n`apiVersion: v1\nkind: Secret\nmetadata:\n name: source-secret\n annotations:\n   reflector.v1.k8s.emberstack.com/reflection-allowed: \"true\"\n`\n```\nDone! Your secret should be replicated within all namespaces. For multiple ingress configurations within the same namespace you could edit your ingress.yaml like this\nIngress.yaml\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: jenkins-ingress\n  namespace: jenkins\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-global\n    kubernetes.io/tls-acme: \"true\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/proxy-body-size:  \"125m\"\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - jenkins.foo.com\n    - nginx.foo.com\n    secretName: letsencrypt-global # < cert-manager will store the created certificate in this secret.\n  rules:\n  - host: jenkins.foo.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: jenkins\n            port:\n              number: 80\n  - host: nginx.foo.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n`\n```",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2023-02-14T18:57:36",
      "url": "https://stackoverflow.com/questions/75451560/cluster-issuer-secret-wont-replicate-with-multiple-ingress"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 71077745,
      "title": "Using ingress in multi namespace cluster AKS",
      "problem": "I have a cluster, I created namespaces for different teams. Then, I tried to apply an ingress to one namespace with this command `kubectl apply -f ing2_dev_plat.yaml -n namespace_name`.\nAfter, this error was thrown. How can I properly configure the work of ingress controller in several namespaces?\nNginx ingress contoller service is in default namespace.\n```\n`Error from server (BadRequest): error when creating \"ing2_dev_plat.yaml\": admission webhook \"validate.nginx.ingress.kubernetes.io\" denied the request:\n-------------------------------------------------------------------------------\nError: exit status 1\n2022/02/11 09:17:49 [warn] 3250#3250: the \"http2_max_field_size\" directive is obsolete, use the \"large_client_header_buffers\" directive instead in /tmp/nginx-cfg1414424955:143\nnginx: [warn] the \"http2_max_field_size\" directive is obsolete, use the \"large_client_header_buffers\" directive instead in /tmp/nginx-cfg1414424955:143\n2022/02/11 09:17:49 [warn] 3250#3250: the \"http2_max_header_size\" directive is obsolete, use the \"large_client_header_buffers\" directive instead in /tmp/nginx-cfg1414424955:144\nnginx: [warn] the \"http2_max_header_size\" directive is obsolete, use the \"large_client_header_buffers\" directive instead in /tmp/nginx-cfg1414424955:144\n2022/02/11 09:17:49 [warn] 3250#3250: the \"http2_max_requests\" directive is obsolete, use the \"keepalive_requests\" directive instead in /tmp/nginx-cfg1414424955:145\nnginx: [warn] the \"http2_max_requests\" directive is obsolete, use the \"keepalive_requests\" directive instead in /tmp/nginx-cfg1414424955:145\n2022/02/11 09:17:49 [emerg] 3250#3250: duplicate location \"/\" in /tmp/nginx-cfg1414424955:1045\nnginx: [emerg] duplicate location \"/\" in /tmp/nginx-cfg1414424955:1045\nnginx: configuration file /tmp/nginx-cfg1414424955 test failed\n`\n```",
      "solution": "As I said in my comment under the question:\n`nginx: [emerg] duplicate location \"/\" in /tmp/nginx-cfg1414424955:1045\n`\nmay indicate you have the same location defined twice.\nIf you have any other Ingress resources with `path: /`, you have to edit those accordingly.\nYou can get all Ingress resources with their paths with\n`kubectl get ingress -A -o=jsonpath='{range .items[*]}{.metadata.name}{\"\\t\"}{.spec.rules[*].http.paths[*].path}{\"\\n\"}{end}'\n`",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2022-02-11T10:25:40",
      "url": "https://stackoverflow.com/questions/71077745/using-ingress-in-multi-namespace-cluster-aks"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 68146279,
      "title": "Kubernetes Nginx ingress - failed to ensure load balancer: could not find any suitable subnets for creating the ELB",
      "problem": "I would like to deploy a minimal k8s cluster on AWS with Terraform and install a Nginx Ingress Controller with Helm.\nThe terraform code:\n```\n`provider \"aws\" {\n  region = \"us-east-1\"\n}\n\ndata \"aws_eks_cluster\" \"cluster\" {\n  name = module.eks.cluster_id\n}\n\ndata \"aws_eks_cluster_auth\" \"cluster\" {\n  name = module.eks.cluster_id\n}\n\nvariable \"cluster_name\" {\n  default = \"my-cluster\"\n}\n\nvariable \"instance_type\" {\n  default = \"t2.large\"\n}\n\nprovider \"kubernetes\" {\n  host                   = data.aws_eks_cluster.cluster.endpoint\n  cluster_ca_certificate = base64decode(data.aws_eks_cluster.cluster.certificate_authority.0.data)\n  token                  = data.aws_eks_cluster_auth.cluster.token\n  load_config_file       = false\n  version                = \"~> 1.11\"\n}\n\ndata \"aws_availability_zones\" \"available\" {\n}\n\nmodule \"vpc\" {\n  source  = \"terraform-aws-modules/vpc/aws\"\n  version = \"3.0.0\"\n\n  name                 = \"k8s-${var.cluster_name}-vpc\"\n  cidr                 = \"172.16.0.0/16\"\n  azs                  = data.aws_availability_zones.available.names\n  private_subnets      = [\"172.16.1.0/24\", \"172.16.2.0/24\", \"172.16.3.0/24\"]\n  public_subnets       = [\"172.16.4.0/24\", \"172.16.5.0/24\", \"172.16.6.0/24\"]\n  enable_nat_gateway   = true\n  single_nat_gateway   = true\n  enable_dns_hostnames = true\n\n  public_subnet_tags = {\n    \"kubernetes.io/cluster/${var.cluster_name}\" = \"shared\"\n    \"kubernetes.io/role/elb\"                    = \"1\"\n  }\n\n  private_subnet_tags = {\n    \"kubernetes.io/cluster/${var.cluster_name}\" = \"shared\"\n    \"kubernetes.io/role/internal-elb\"           = \"1\"\n  }\n}\n\nmodule \"eks\" {\n  source  = \"terraform-aws-modules/eks/aws\"\n  version = \"12.2.0\"\n\n  cluster_name    = \"eks-${var.cluster_name}\"\n  cluster_version = \"1.18\"\n  subnets         = module.vpc.private_subnets\n\n  vpc_id = module.vpc.vpc_id\n\n  worker_groups = [\n   {\n     name                          = \"worker-group-1\"\n     instance_type                 = \"t3.small\"\n     additional_userdata           = \"echo foo bar\"\n     asg_desired_capacity          = 2\n   },\n   {\n     name                          = \"worker-group-2\"\n     instance_type                 = \"t3.small\"\n     additional_userdata           = \"echo foo bar\"\n     asg_desired_capacity          = 1\n   },\n  ]\n  \n\n  write_kubeconfig   = true\n  config_output_path = \"./\"\n\n  workers_additional_policies = [aws_iam_policy.worker_policy.arn]\n}\n\nresource \"aws_iam_policy\" \"worker_policy\" {\n  name        = \"worker-policy-${var.cluster_name}\"\n  description = \"Worker policy for the ALB Ingress\"\n\n  policy = file(\"iam-policy.json\")\n}\n`\n```\nThe installation performs correctly:\n`helm install my-release nginx-stable/nginx-ingress`\n```\n`NAME: my-release\nLAST DEPLOYED: Sat Jun 26 22:17:28 2021\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nThe NGINX Ingress Controller has been installed.\n`\n```\nThe `kubectl describe service my-release-nginx-ingress` returns:\n```\n`Error syncing load balancer: failed to ensure load balancer: could not find any suitable subnets for creating the ELB\n`\n```\nThe VPC is created and the public subnet seems to be correctly tagged, what is lacking to make the Ingress aware of the public subnet ?",
      "solution": "In the `eks` modules you are prefixing the cluster name with `eks-`:\n```\n`cluster_name    = \"eks-${var.cluster_name}\"\n`\n```\nHowever you do not use the prefix in your subnet tags:\n```\n`\"kubernetes.io/cluster/${var.cluster_name}\" = \"shared\"\n`\n```\nDrop the prefix from `cluster_name` and add it to the cluster name variable (assuming you want the prefix at all). Alternatively, you could add the prefix to your tags to fix the issue, but that approach makes it easier to introduce inconsistencies.",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2021-06-26T23:13:25",
      "url": "https://stackoverflow.com/questions/68146279/kubernetes-nginx-ingress-failed-to-ensure-load-balancer-could-not-find-any-su"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 67216042,
      "title": "How to patch Kubernetes Daemonset",
      "problem": "I have an ongoing requirement to patch my nginx-ingress daemonset each time I wish to expose new TCP ports.  I have reviewed the documentation and I cannot understand the correct kubectl patch syntax to perform the patch.  An excerpt from the yaml follows:\n```\n`spec:\n    revisionHistoryLimit: 10\n    selector:\n      matchLabels:\n        name: nginx-ingress-microk8s\n    template:\n      metadata:\n        creationTimestamp: null\n        labels:\n          name: nginx-ingress-microk8s\n      spec:\n        containers:\n        - args:\n          - /nginx-ingress-controller\n          - --configmap=$(POD_NAMESPACE)/nginx-load-balancer-microk8s-conf\n          - --default-backend-service=ingress/custom-default-backend\n          - --tcp-services-configmap=$(POD_NAMESPACE)/nginx-ingress-tcp-microk8s-conf\n          - --udp-services-configmap=$(POD_NAMESPACE)/nginx-ingress-udp-microk8s-conf\n          - --ingress-class=public\n          - ' '\n          - --publish-status-address=127.0.0.1\n          env:\n          - name: POD_NAME\n            valueFrom:\n              fieldRef:\n                apiVersion: v1\n                fieldPath: metadata.name\n          - name: POD_NAMESPACE\n            valueFrom:\n              fieldRef:\n                apiVersion: v1\n                fieldPath: metadata.namespace\n          image: k8s.gcr.io/ingress-nginx/controller:v0.44.0\n          imagePullPolicy: IfNotPresent\n          lifecycle:\n            preStop:\n              exec:\n                command:\n                - /wait-shutdown\n          livenessProbe:\n            failureThreshold: 3\n            httpGet:\n              path: /healthz\n              port: 10254\n              scheme: HTTP\n            initialDelaySeconds: 10\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 5\n          name: nginx-ingress-microk8s\n          ports:\n          - containerPort: 80\n            hostPort: 80\n            name: http\n            protocol: TCP\n          - containerPort: 443\n            hostPort: 443\n            name: https\n            protocol: TCP\n          - containerPort: 10254\n            hostPort: 10254\n            name: health\n            protocol: TCP\n          readinessProbe:\n            failureThreshold: 3\n            httpGet:\n              path: /healthz\n              port: 10254\n              scheme: HTTP\n            periodSeconds: 10\n            successThreshold: 1\n            timeoutSeconds: 5\n          resources: {}\n`\n```\nI want to use kubectl patch to append another port definition under ports i.e.\n```\n`          - containerPort: 1234\n            hostPort: 1234\n            name: my-port-1234\n            protocol: TCP\n`\n```\nPatching a config map was simple using:\n```\n`kubectl patch configmap nginx-ingress-tcp-microk8s-conf -n ingress --type merge -p '{\"data\":{\"1234\":\"namespace1/api-connect:1234\"}}'\n`\n```\nbut I cannot understand how to amend the command to cope with the more complex update required for the Daemonset.\nAny assistance gratefully received. Thanks",
      "solution": "As already mentioned by David in the comment it is better to keep every change under version control.\nBut if you really need to do this, here is the command:\n```\n`kubectl patch ds -n ingress nginx-ingress-microk8s-controller --type='json' -p='[{\"op\": \"add\", \"path\": \"/spec/template/spec/containers/0/ports/-\", \"value\":{\"containerPort\":1234,\"name\":\"my-port-1234\",\"hostPort\":1234,\"protocol\":\"TCP\"}}]'\n`\n```\npatch command is explained in k8s docs: update-api-object-kubectl-patch,\nand the json type patch details are explained in rfc6902.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-04-22T17:12:28",
      "url": "https://stackoverflow.com/questions/67216042/how-to-patch-kubernetes-daemonset"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 67058841,
      "title": "Nginx returning incorrect content-type",
      "problem": "I have a Vue.js application, and my deployment setup is very standard,\n\nPod -> Service -> Ingress\n\nHere's the related code,\nDockerfile:\n```\n`FROM node:lts-alpine AS build\nWORKDIR /app\nCOPY . .\n\n# Default build mode\nARG MODE=production\n\n# Build the dist folder\nRUN npm ci\nRUN npm run build ${MODE}\n\n# Serve from nginx\nFROM nginx:alpine\nCOPY ./nginx.conf /etc/nginx/nginx.conf\nCOPY --from=build /app/dist /usr/share/nginx/html\n`\n```\nNginx.conf:\n```\n`user  nginx;\nworker_processes  1;\nerror_log  /var/log/nginx/error.log warn;\npid        /var/run/nginx.pid;\nevents {\n  worker_connections  1024;\n}\nhttp {\n  include       /etc/nginx/mime.types;\n  default_type  application/octet-stream;\n  log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                    '$status $body_bytes_sent \"$http_referer\" '\n                    '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n  access_log  /var/log/nginx/access.log  main;\n  sendfile        on;\n  keepalive_timeout  65;\n  server {\n    listen       8080;\n    location / {\n      root   /usr/share/nginx/html;\n      index  index.html;\n      try_files $uri $uri/ /index.html;\n    }\n  }\n}\n`\n```\nIngress Prod: (kept only the necessary bits for brevity sakes),\n```\n`apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n  labels:\n    app: \n    app.kubernetes.io/instance: \n  name: \n  namespace: \nspec:\n  rules:\n    - host: \n      http:\n        paths:\n          - backend:\n              serviceName: livspace-hub\n              servicePort: 80\n            path: /\n\n`\n```\nIngress local:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: \n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n  - host: \n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: hub-service\n            port:\n              number: 9090\n`\n```\nThe error I get is,\n\nUncaught SyntaxError: Unexpected token '\nUncaught SyntaxError: Unexpected token '\n\nAnd the content-type for both these resources in the network tab is `text/html`.\nEdit 1:\nThis is what my folder looks like after deployment,\n```\n`/usr/share/nginx/html # ls\n50x.html assets css  favicon.ico fonts index.html  js  styles\n`\n```\nThe path for my js file is,\n`https:///js/app.a68a0468.js`\nEdit 2:\nHere are the logs from my local vs deployed application.\nLocal:\n\n - - [12/Apr/2021:10:38:18 +0000] \"GET / HTTP/1.1\" 200 3213 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36 Edg/89.0.774.75\"\n - - [12/Apr/2021:10:38:18 +0000] \"GET /css/milestone.1c126aff.css HTTP/1.1\" 200 1139 \"http:///\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36 Edg/89.0.774.75\"\n - - [12/Apr/2021:10:38:18 +0000] \"GET /css/catalogue.5794c500.css HTTP/1.1\" 200 156 \"http:///\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36 Edg/89.0.774.75\"\n\nDeployed:\n\n - - [12/Apr/2021:12:46:28 +0000] \"GET / HTTP/1.1\" 200 3213 \"https:///\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36 Edg/89.0.774.54\"\n - - [12/Apr/2021:12:46:28 +0000] \"GET / HTTP/1.1\" 200 3213 \"https:///\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36 Edg/89.0.774.54\"\n - - [12/Apr/2021:12:46:28 +0000] \"GET / HTTP/1.1\" 200 3213 \"https:///\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36 Edg/89.0.774.54\"\n - - [12/Apr/2021:12:46:28 +0000] \"GET / HTTP/1.1\" 200 3213 \"https:///\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36 Edg/89.0.774.54\"\n\nMy local instance is also run via docker/docker-compose, so the setup is essentially the same.\nAs you can see, my local setup logs show requests for specific files - `GET /` - whereas the deployed instance shows only logs for `GET /`.",
      "solution": "TL;DR\nRemove/Modify the following annotation from `Ingress Prod`:\n\n`nginx.ingress.kubernetes.io/rewrite-target: /$2`\n\nExplanation:\nThe annotation that you are using (`rewrite-target: /$2`) is targeting a capture group that does not exist.\nEach request that is sent to your application through your `Ingress` resource is getting rewritten to `/`.\nTo fix that you can either:\n\nEntirely remove this annotation.\nModify the annotation that would support your rewrite, for example: `/`.\n\nYou can read more about rewrites, capture groups and how `nginx-ingress` handles them by following this documentation:\n\nKubernetes.github.io: Ingress nginx: Examples: Rewrite\n\nExample:\nI've used your exact `Ingress` manifest with slight tweaks and stumbled upon the same issue as you've described:\n\n`curl IP`\n`curl IP/hello.html`\n\nTo show the request that came to the `Pod` I've used `nginx` `Pod` as a backend:\n`/docker-entrypoint.sh: Configuration complete; ready for start up\n10.88.0.20 - - [13/Apr/2021:15:01:37 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"curl/7.64.1\" \"SOURCE_IP_OF_MINE\"\n10.88.0.20 - - [13/Apr/2021:15:01:40 +0000] \"GET / HTTP/1.1\" 200 612 \"-\" \"curl/7.64.1\" \"SOURCE_IP_OF_MINE\"\n`\n\nAdditional resources:\n\nKubernetes.io: Docs: Concepts: Services networking: Ingress",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2021-04-12T15:00:48",
      "url": "https://stackoverflow.com/questions/67058841/nginx-returning-incorrect-content-type"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 77869181,
      "title": "How to correctly deploy a Blazor Server app on Kubernetes",
      "problem": "I am trying to deploy a test Blazor server-side application in a local Kubernetes cluster. I have it configured such that I can access it via either the service or an nginx-ingress. However, both routes have their own problems that make the application not function properly once served.\nWhen served over the service, it looks like this. I believe this is how it is supposed to look. However, there are a bunch of errors that make it so that I can't intereact with the page at all.\nErrors:\n```\n`blazor.server.js:1 WebSocket connection to 'ws://172.25.217.142:30500/_blazor?id=1qrCqjxomf15Rd6QTY11rw' failed: \n(anonymous) @ blazor.server.js:1\nblazor.server.js:1 [2024-01-23T20:20:31.036Z] Information: (WebSockets transport) There was an error with the transport.\nblazor.server.js:1 [2024-01-23T20:20:31.036Z] Error: Failed to start the transport 'WebSockets': Error: WebSocket failed to connect. The connection could not be found on the server, either the endpoint may not be a SignalR endpoint, the connection ID is not present on the server, or there is a proxy blocking WebSockets. If you have multiple servers check that sticky sessions are enabled.\nlog @ blazor.server.js:1\nblazor.server.js:1 [2024-01-23T20:20:31.107Z] Warning: Failed to connect via WebSockets, using the Long Polling fallback transport. This may be due to a VPN or proxy blocking the connection. To troubleshoot this, visit https://aka.ms/blazor-server-using-fallback-long-polling.\nlog @ blazor.server.js:1\n:30500/_blazor?id=eC3fba0OdI6vu_KNZl9_Kg:1 \n        \n        \n       Failed to load resource: the server responded with a status of 404 (Not Found)\nblazor.server.js:1 Uncaught (in promise) Error: No Connection with that ID: Status code '404'\n    at ut.send (blazor.server.js:1:39443)\n    at async rt (blazor.server.js:1:36427)\n    at async _t._sendLoop (blazor.server.js:1:61855)\n:30500/_blazor?id=eC3fba0OdI6vu_KNZl9_Kg:1 \n        \n        \n       Failed to load resource: the server responded with a status of 404 (Not Found)\nblazor.server.js:1 Uncaught (in promise) Error: No Connection with that ID: Status code '404'\n    at ut.send (blazor.server.js:1:39443)\n    at async rt (blazor.server.js:1:36427)\n    at async _t._sendLoop (blazor.server.js:1:61855)\n:30500/_blazor?id=eC3fba0OdI6vu_KNZl9_Kg:1 \n        \n        \n       Failed to load resource: the server responded with a status of 404 (Not Found)\nblazor.server.js:1 Uncaught (in promise) Error: No Connection with that ID: Status code '404'\n    at ut.send (blazor.server.js:1:39443)\n    at async rt (blazor.server.js:1:36427)\n    at async _t._sendLoop (blazor.server.js:1:61855)\n:30500/_blazor?id=eC3fba0OdI6vu_KNZl9_Kg:1 \n        \n        \n       Failed to load resource: the server responded with a status of 404 (Not Found)\nblazor.server.js:1 Uncaught (in promise) Error: No Connection with that ID: Status code '404'\n    at ut.send (blazor.server.js:1:39443)\n    at async rt (blazor.server.js:1:36427)\n    at async _t._sendLoop (blazor.server.js:1:61855)\n`\n```\nIt appears that there is some problem with the WebSockets, but I don't know how to fix that.\nWhen served over the ingress, it looks like this. This is obviously not correct, but I'm only getting one error:\n```\n`blazor.server.js:2 Uncaught SyntaxError: Unexpected token 'I don't know what file that is because I can't open it from the DevTools Console and I am unable to locate it in the DevTools Source pane. It doesn't appear to be in the codebase for the application either.\nI am running Minikube on Windows Hyper-V. The application is the default server-side Blazor application from Visual Studio 2022. I made some alterations to the default Dockerfile though:\n```\n`#See https://aka.ms/customizecontainer to learn how to customize your debug container and how Visual Studio uses this Dockerfile to build your images for faster debugging.\n\nFROM mcr.microsoft.com/dotnet/aspnet:6.0 AS base\nWORKDIR /app\nEXPOSE 80\nEXPOSE 443\n\nFROM mcr.microsoft.com/dotnet/sdk:6.0 AS build\nARG BUILD_CONFIGURATION=Release\nWORKDIR /src\nCOPY [\"WebApp.csproj\", \"WebApp/\"]\nRUN dotnet restore \"./WebApp/./WebApp.csproj\"\nCOPY . .\nWORKDIR \"/src/WebApp\"\nRUN dotnet build \"./WebApp.csproj\" -c $BUILD_CONFIGURATION -o /app/build\n\nFROM build AS publish\nARG BUILD_CONFIGURATION=Release\nRUN dotnet publish \"./WebApp.csproj\" -c $BUILD_CONFIGURATION -o /app/publish /p:UseAppHost=false\n\nFROM base AS final\nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\"dotnet\", \"WebApp.dll\"]\n`\n```\nAny clues as to what could be causing these two issues?\nEdit: Here are my Kubernetes .yaml files:\n```\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: blazor\n  labels:\n    app: blazor\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: blazor\n  template:\n    metadata:\n      labels:\n        app: blazor\n    spec:\n      containers:\n      - name: blazor\n        image: registry/...\n        ports:\n        - containerPort: 80\n      imagePullSecrets:  \n      - name: test-webapp\n\n`\n```\n```\n`apiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: blazor\n  name: blazor\n  namespace: default\nspec:\n  ports:\n  - nodePort: 30500\n    port: 80\n    protocol: TCP\n    targetPort: 80\n  selector:\n    app: blazor\n  type: NodePort\n`\n```\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: blazor-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\n    nginx.ingress.kubernetes.io/affinity: \"cookie\"\n    nginx.ingress.kubernetes.io/session-cookie-name: \"affinity\"\n    nginx.ingress.kubernetes.io/session-cookie-expires: \"14400\"\n    nginx.ingress.kubernetes.io/session-cookie-max-age: \"14400\"\nspec:\n  rules:\n    - host: blazor.test\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: blazor\n                port:\n                  number: 80\n`\n```",
      "solution": "We have 2 issues here\n\nIngress route\nSignalR with LoadBalancer\n\nIngress route\n`nginx.ingress.kubernetes.io/rewrite-target: /$1\n`\nRewrite has `$1` it means to place first `capturing group`, but what is it? Well it's something that can be used only when `nginx.ingress.kubernetes.io/use-regex` is added, so it just doesn't make sens, when request is send to get for file like `/styles.css` it would end up with something like `/$1styles.css` in Blazor app or anything else but not valid from your app point of view.\nYou can have for example\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: blazor-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\n    nginx.ingress.kubernetes.io/affinity: \"cookie\"\n    nginx.ingress.kubernetes.io/session-cookie-name: \"affinity\"\n    nginx.ingress.kubernetes.io/session-cookie-expires: \"14400\"\n    nginx.ingress.kubernetes.io/session-cookie-max-age: \"14400\"\nspec:\n  rules:\n    - host: blazor.test\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: blazor\n                port:\n                  number: 80\n`\nAnd everything should work, but rewrite `/`(`path: /`) to `/`(`rewrite-target: /` end with what we had at beginning, so removing line with `rewrite-target` has exactly same effect.\nAnother example using regex\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: blazor-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\n    nginx.ingress.kubernetes.io/affinity: \"cookie\"\n    nginx.ingress.kubernetes.io/session-cookie-name: \"affinity\"\n    nginx.ingress.kubernetes.io/session-cookie-expires: \"14400\"\n    nginx.ingress.kubernetes.io/session-cookie-max-age: \"14400\"\nspec:\n  rules:\n    - host: blazor.test\n      http:\n        paths:\n          - path: /(.*)\n            pathType: Prefix\n            backend:\n              service:\n                name: blazor\n                port:\n                  number: 80\n`\nIn this case in `path` we have `/(.*)` and we have one `capturing group` what is `(.*)`(to make path `/` work correctly you must have `*` instead of `+`), then `rewrite` comes in and it says `/$1` as we have regex enabled in place of `$1` the value stored in first capturing group will be used here.\nSignalR with LoadBalancer\nSignalR to establish connection with with Blazor backend needs to send 2 request\n\nNegotiate\nConnect\n\nThe first one will send `connectionToken` in the response then this token will be used to connect, so if you have more then one replica there is a chance(with number of replica it's growing) that those two requests will end in two different one. To resolve it Microsoft suggest suggest using some additional annotations to force ingress(nginx) to use always the same replica based on cookie, so `Negotiate` and `Connect` will always hit the same replica and issue will not occur(also some GitHub issue about it.\nTo answer the question why it doesn't work with `NodePort` as we already got it sends two request they have to hit the same replica, but service `NodePort` doesn't have feature like `nginx.ingress.kubernetes.io/affinity` to force requests to the same replica all the time, and there is no solution for it expect using just one replica(or at least I don't know).",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2024-01-23T21:46:03",
      "url": "https://stackoverflow.com/questions/77869181/how-to-correctly-deploy-a-blazor-server-app-on-kubernetes"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 75588517,
      "title": "Can i route host directly to a path in the backend?",
      "problem": "I am using nginx-ingress.\nIs it possible to route host to a path of the backend?\nFor example,\nfoo.example.com/ -> my-service:80/myapp/gui/\nbar.example.com/ -> my-service:80/different/path/here\nI tried this\n```\n`spec:\n  rules:\n  - host: foo.example.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: my-service\n            port:\n              name: http\n            path: /myapp/gui/\n`\n```\nThought, it's throwing an error with unknown field.\n`$ k apply -f ingress.yaml  error: error validating \"ingress.yaml\": error validating data: ValidationError(Ingress.spec.rules[0].http.paths[0].backend.service): unknown field \"path\" in io.k8s.api.networking.v1.IngressServiceBackend; if you choose to ignore these errors, turn validation off with --validate=false`",
      "solution": "It's can be done with two ingress config class and use of`nginx.ingress.kubernetes.io/rewrite-target` annotation to route change the path :\n`    apiVersion: networking.k8s.io/v1\n    kind: Ingress\n    metadata:\n      annotations:\n        nginx.ingress.kubernetes.io/rewrite-target: /myapp/gui/$2\n    spec:\n      rules:\n      - host: foo.example.com\n        http:\n          paths:\n            - path: (/|$)(.*)\n              backend:\n                serviceName: my-service\n                servicePort: 80\n\n`\n`    apiVersion: networking.k8s.io/v1\n    kind: Ingress\n    metadata:\n      annotations:\n        nginx.ingress.kubernetes.io/rewrite-target: /different/path/here/$2\n    spec:\n      rules:\n      - host: bar.example.com\n        http:\n          paths:\n            - path: (/|$)(.*)\n              backend:\n                serviceName: my-service\n                servicePort: 80\n\n`\nThe path will be `\"/myapp/gui/$2\"` where `$2` will be replaced by your subpath.\n```\n`foo.example.com/ -> my-service:80/myapp/gui/ \nfoo.example.com/test -> my-service:80/myapp/gui/test\nbar.example.com/ -> my-service:80/different/path/here\nbar.example.com/test -> my-service:80/different/path/here/test\n`\n```",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2023-02-28T07:23:42",
      "url": "https://stackoverflow.com/questions/75588517/can-i-route-host-directly-to-a-path-in-the-backend"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 74770691,
      "title": "Kubernetes Ingress Exact not prioritized over Prefix",
      "problem": "In Kubernetes we need a new service to handle the root path, but but still a catch everything else on our current frontend.\nCurrent frontend Ingress\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: current-frontend\n  labels:\n    app: current-frontend\n    tier: frontend\n  annotations:\n    kubernetes.io/ingress.class: nginx\nspec:\n  tls:\n    - hosts:\n      - my.domain.com\n      secretName: tls-secret\n  rules:\n    - host: my.domain.com\n      http:\n        paths:\n          - backend:\n              service:\n                name: current-frontend\n                port:\n                  number: 80\n            path: /\n            pathType: Prefix\n`\n```\nNew service Ingress\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: new-service\n  labels:\n    app: new-service\n    tier: frontend\n  annotations:\n    kubernetes.io/ingress.class: nginx\nspec:\n  tls:\n  - hosts:\n    - my.domain.com\n    secretName: tls-secret\n  rules:\n  - host: my.domain.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: new-service\n            port:\n              number: 80\n        path: /someendpoint\n        pathType: ImplementationSpecific\n      - backend:\n          service:\n            name: new-service\n            port:\n              number: 80\n        path: /\n        pathType: Exact\n`\n```\nAccording to the documentation of Kuberntes Ingress, it should prioritize Exact over Prefix\n\nIf two paths are still equally matched, precedence will be given to paths with an exact path type over prefix path type.\n\nhttps://kubernetes.io/docs/concepts/services-networking/ingress/#multiple-matches\nThe problem is that everything else then my.domain.com/someendpoint goes to the current-frontend, while the expected would be that my.domain.com/ would go to new-service.\nHow do I achieving this?\n\nSolution\nI got it working, even If it doesn't seams to be the optimal solution (According to the Documentation)\nI Followed Hemanth Kumar's answer and changed the Current Frontend to use Regex, with (.+) instead of (.*) as I wanted at least one char after the slash for it to be hit.\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: current-frontend\n  labels:\n    app: current-frontend\n    tier: frontend\n  annotations:\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    kubernetes.io/ingress.class: nginx\nspec:\n  tls:\n    - hosts:\n      - my.domain.com\n      secretName: tls-secret\n  rules:\n    - host: my.domain.com\n      http:\n        paths:\n          - backend:\n              service:\n                name: current-frontend\n                port:\n                  number: 80\n            path: /(.+)\n            pathType: Prefix\n`\n```\nAt the same time I needed to change the New service to use Prefix instead of Exact as it does not work, event if there is no other services to hit.\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: new-service\n  labels:\n    app: new-service\n    tier: frontend\n  annotations:\n    kubernetes.io/ingress.class: nginx\nspec:\n  tls:\n  - hosts:\n    - my.domain.com\n    secretName: tls-secret\n  rules:\n  - host: my.domain.com\n    http:\n      paths:\n      - backend:\n          service:\n            name: new-service\n            port:\n              number: 80\n        path: /someendpoint\n        pathType: ImplementationSpecific\n      - backend:\n          service:\n            name: new-service\n            port:\n              number: 80\n        path: /\n        pathType: Prefix\n`\n```",
      "solution": "Ingress path matching can be enabled by setting the\n`nginx.ingress.kubernetes.io/use-regex annotation to true` .\nSee the description of the use-regex annotation :\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: test-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: test.com\n    http:\n      paths:\n      - path: /foo/.*\n        pathType: Prefix\n        backend:\n          service:\n            name: test\n            port:\n              number: 80\n`\n```\nRefer to this ingress path matching for more information on path priority",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2022-12-12T12:50:36",
      "url": "https://stackoverflow.com/questions/74770691/kubernetes-ingress-exact-not-prioritized-over-prefix"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70611407,
      "title": "Kubernetes Ingress TLS not being created with headless service",
      "problem": "What I'm trying to achieve\nI'm trying to deploy an elixir (phoenix) application in a microk8s cluster namespace with TLS using let's encrypt. The cluster is hosted on an AWS EC2 instance.\nThe problem I'm facing\n\nThe ingress is created in the namespace\ningress routes to the correct domain\nthe application is working and displayed on the given domain\n\nThe TLS secret is not being created in the namespace and a 'default' one is created\nThe secrets after deploying both phoenix app and httpbin app:\n`me@me:~/Documents/kubernetes-test$ kubectl get secret -n production\nNAME                           TYPE                                  DATA   AGE\ndefault-token-jmgrg            kubernetes.io/service-account-token   3      20m\nhttpbin-tls                    kubernetes.io/tls                     2      81s\n`\nThe domain is insecure, i.e the TLS is not working.\nLogs from the ingress controller after applying the yml files:\n```\n`W0106 17:26:36.967036       6 controller.go:1192] Error getting SSL certificate \"production/phoenix-app-tls\": local SSL certificate production/phoenix-app-tls was not found. Using default certificate\nW0106 17:26:46.445248       6 controller.go:1192] Error getting SSL certificate \"production/phoenix-app-tls\": local SSL certificate production/phoenix-app-tls was not found. Using default certificate\nW0106 17:26:49.779680       6 controller.go:1192] Error getting SSL certificate \"production/phoenix-app-tls\": local SSL certificate production/phoenix-app-tls was not found. Using default certificate\nI0106 17:26:56.431925       6 status.go:281] \"updating Ingress status\" namespace=\"production\" ingress=\"phoenix-app-ingress\" currentValue=[] newValue=[{IP:127.0.0.1 Hostname: Ports:[]}]\nI0106 17:26:56.443405       6 event.go:282] Event(v1.ObjectReference{Kind:\"Ingress\", Namespace:\"production\", Name:\"phoenix-app-ingress\", UID:\"REDACTED\", APIVersion:\"networking.k8s.io/v1beta1\", ResourceVersion:\"1145907\", FieldPath:\"\"}): type: 'Normal' reason: 'Sync' Scheduled for sync\nW0106 17:26:56.443655       6 backend_ssl.go:46] Error obtaining X.509 certificate: no object matching key \"production/phoenix-app-tls\" in local store\nW0106 17:26:56.443781       6 controller.go:1192] Error getting SSL certificate \"production/phoenix-app-tls\": local SSL certificate production/phoenix-app-tls was not found. Using default certificate\n`\n```\nThe description of the created ingress, note that here at the bottom it says `Successfully created Certificate \"phoenix-app-tls\" but the secret does not exist`:\n`me@me:~/Documents/kubernetes-test$ kubectl describe ing phoenix-app-ingress -n production\nName:             phoenix-app-ingress\nLabels:           app=phoenix-app\nNamespace:        production\nAddress:          127.0.0.1\nDefault backend:  default-http-backend:80 ()\nTLS:\n  phoenix-app-tls terminates phoenix.sub.mydomain.com\nRules:\n  Host                           Path  Backends\n  ----                           ----  --------\n  phoenix.sub.mydomain.com  \n                                 /   phoenix-app-service-headless:8000 (REDACTED_IP:4000,REDACTED_IP:4000)\nAnnotations:                     cert-manager.io/cluster-issuer: letsencrypt\n                                 nginx.ingress.kubernetes.io/cors-allow-credentials: true\n                                 nginx.ingress.kubernetes.io/cors-allow-methods: GET, POST, OPTIONS\n                                 nginx.ingress.kubernetes.io/cors-allow-origin: *\n                                 nginx.ingress.kubernetes.io/enable-cors: true\nEvents:\n  Type    Reason             Age                  From                      Message\n  ----    ------             ----                 ----                      -------\n  Normal  CreateCertificate  29m                  cert-manager              Successfully created Certificate \"phoenix-app-tls\"\n  Normal  Sync               8m43s (x3 over 29m)  nginx-ingress-controller  Scheduled for sync\n`\nResources\nThe deployment yml:\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: phoenix-app\n  labels:\n    app: phoenix-app\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: phoenix-app\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        app: phoenix-app\n    spec:\n      containers:\n      - name: phoenix-app\n        image: REDACTED\n        imagePullPolicy: Always\n        command: [\"./bin/hello\", \"start\"]\n        lifecycle:\n          preStop:\n            exec:\n              command: [\"./bin/hello\", \"stop\"]\n        ports:\n        - containerPort: 4000\n        env:\n        - name: POD_IP\n          valueFrom:\n            fieldRef:\n              fieldPath: status.podIP\n        envFrom:\n        - configMapRef:\n            name: phoenix-app-config\n        - secretRef:\n            name: phoenix-app-secrets\n      imagePullSecrets:\n      - name: gitlab-pull-secret\n`\nThe service yml:\n```\n`apiVersion: v1\nkind: Service\nmetadata:\n  name: phoenix-app-service-headless\n  labels:\n    app: phoenix-app\nspec:\n  clusterIP: None\n  selector:\n    app: phoenix-app\n  ports:\n  - name: http\n    port: 8000\n    targetPort: 4000 # The exposed port by the phoenix app\n`\n```\nNote: I removed my actual domain\nThe ingress yml:\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: phoenix-app-ingress\n  labels:\n    app: phoenix-app\n  annotations:\n    nginx.ingress.kubernetes.io/enable-cors: \"true\"\n    nginx.ingress.kubernetes.io/cors-allow-methods: \"GET, POST, OPTIONS\"\n    nginx.ingress.kubernetes.io/cors-allow-origin: \"*\"\n    nginx.ingress.kubernetes.io/cors-allow-credentials: \"true\"\n    cert-manager.io/cluster-issuer: \"letsencrypt\"\nspec:\n  tls:\n  - hosts:\n    - \"phoenix.sub.mydomain.com\"\n    secretName: phoenix-app-tls\n  rules:\n  - host: \"phoenix.sub.mydomain.com\"\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: phoenix-app-service-headless\n            port:\n              number: 8000 # Same port as in service.yml\n`\nTested with different service\nI deployed a sample service using httpbin (is not a headless service) and the TLS works fine in the same namespace. Here are the resources that I used to deploy it:\ndeplyoment.yml\n```\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: httpbin\n  labels:\n    app: httpbin\nspec:\n  replicas: 1\n  selector: \n    matchLabels:\n      app: httpbin\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: httpbin\n        version: v1\n    spec:\n      containers:\n      - image: docker.io/kennethreitz/httpbin\n        imagePullPolicy: Always\n        name: httpbin\n        ports:\n        - containerPort: 80\n`\n```\nThe service yml:\n`apiVersion: v1\nkind: Service\nmetadata:\n  name: httpbin\n  labels:\n    app: httpbin\nspec:\n  ports:\n  - name: http\n    port: 8000\n    targetPort: 80\n  selector:\n    app: httpbin\n`\nThe ingress yml:\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: httpbin\n  labels:\n    app: httpbin\n  annotations:\n    cert-manager.io/cluster-issuer: \"letsencrypt\"\nspec:\n  tls:\n  - hosts:\n    - \"httpbin.sub.mydomain.com\"\n    secretName: httpbin-tls\n  rules:\n  - host: \"httpbin.sub.mydomain.com\" # This is a subdomain we want to route these requests to\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: httpbin\n            port:\n              number: 8000\n`\nMy best guess is that it has something to do with the fact that the service is headless, but I have no clue as to how I can resolve the issue.",
      "solution": "I found out that you can actually check for certificates with kubectl:\n`kubectl get certificate -n production`\nThe status of this certificate was READY = FALSE.\nI checked the description:\n`kubectl describe certificate  -n production`\nAt the bottom it said:\nToo many certificates have been created in the last 164 hours for this exact domain.\nI just changed the domain and voila! It works.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2022-01-06T18:49:49",
      "url": "https://stackoverflow.com/questions/70611407/kubernetes-ingress-tls-not-being-created-with-headless-service"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70256408,
      "title": "Getting failed calling webhook &quot;validate.nginx.ingress.kubernetes.io&quot;: error when applying ingress resource/rules yaml file in NginxIngress Controller",
      "problem": "I'm getting below error whenever I'm trying to apply an ingress resource/rules yaml file:\nfailed calling webhook \"validate.nginx.ingress.kubernetes.io\": Post \"https://ingress-nginx-controller-admission.ingress-nginx.svc:443/networking/v1/ingresses?timeout=10s\": EOF\nIt seems there are multiple errors for \"failed calling webhook \"validate.nginx.ingress.kubernetes.io\": Post \"https://ingress-nginx-controller-admission.ingress-nginx.svc:443/networking/v1/ingresses?timeout=10s\": Error here\nLike below:\n\ncontext deadline exceeded\nx509: certificate signed by unknown authority\nTemporary Redirect\nEOF\nno endpoints available for service \"ingress-nginx-controller-admission\"\n\n...and many more.\nMy Observations:\nAs soon as the the ingress resource/rules yaml is applied, the above error is shown and the Ingress Controller gets restarted as shown below:\n```\n`NAME                                        READY   STATUS      RESTARTS          AGE\ningress-nginx-controller-5cf97b7d74-zvrr6   1/1     Running            6          30m\ningress-nginx-controller-5cf97b7d74-zvrr6   0/1     OOMKilled          6          30m\n\ningress-nginx-controller-5cf97b7d74-zvrr6   0/1     CrashLoopBackOff   6          30m\n\ningress-nginx-controller-5cf97b7d74-zvrr6   0/1     Running            7          31m\n\ningress-nginx-controller-5cf97b7d74-zvrr6   1/1     Running            7          32m\n`\n```\nOne possible solution could be (not sure though) mentioned here:\nhttps://stackoverflow.com/a/69289313/12241977\nBut not sure if it could possibly work in case of Managed Kubernetes services like AWS EKS as we don't have access to kube-api server.\nAlso the section \"kind: ValidatingWebhookConfiguration\" has below field from yaml:\n```\n`clientConfig:\n  service:\n    namespace: ingress-nginx\n    name: ingress-nginx-controller-admission\n    path: /networking/v1/ingresses\n`\n```\nSo what does the \"path: /networking/v1/ingresses\" do & where it resides or simply where we can find this path?\nI checked the validation webhook using below command but, not able to get where to find the above path\n```\n`kubectl describe validatingwebhookconfigurations ingress-nginx-admission\n`\n```\nSetup Details\nI installed using the Bare-metal method exposed with NodePort\nIngress Controller Version - v1.1.0\nKubernetes Cluster Version (AWS EKS): 1.21",
      "solution": "Ok, I got this working now:\nI was getting the status as \"OOMKilled\" (Out Of Memory). So what I did is I've added the \"limits:\" section under \"resources:\" section of Deployment yaml as below:\n```\n`      resources:\n        requests:\n          cpu: 100m\n          memory: 90Mi\n        limits:              \n          cpu: 200m\n          memory: 190Mi\n`\n```\nNow, it works fine for me.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-12-07T08:36:01",
      "url": "https://stackoverflow.com/questions/70256408/getting-failed-calling-webhook-validate-nginx-ingress-kubernetes-io-error-whe"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69951499,
      "title": "I want my EKS cluster to listen to https request",
      "problem": "I use Network load balancer which was provisioned using the yaml file I got here: https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.0.4/deploy/static/provider/aws/deploy-tls-termination.yaml\nI have also pointed my domain to the Network Load balancer created by ingress-nginx.\nBut whenever I try it to access the site, I get a 502 Bad Gateway error.\nBelow is a sample of my ingress-nginx resource:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-service\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    # for backend TLS\n    nginx.ingress.kubernetes.io/secure-backends: \"true\"\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\nspec:\n  rules:\n    - host: \"my.sub.domain.com\"\n      http:\n        paths:\n          - pathType: Prefix\n            path: /\n            backend:\n              service:\n                name: apigateway\n                port:\n                  number: 1234\n`\n```\nPlease what can I do to solve the issue? I have searched the internet for days now. Thank you.",
      "solution": "i would suggest try checking out the\nThe annotation `nginx.ingress.kubernetes.io/ssl-passthrough` instructs the controller to send TLS connections directly to the backend instead of letting NGINX decrypt the communication.\nYou should also check out the\n```\n`nginx.ingress.kubernetes.io/configuration-snippet: |\n      proxy_ssl_name \"svc-s.default.svc.cluster.local\";\n`\n```\nReference doc : https://github.com/kubernetes/ingress-nginx/issues/4928#issuecomment-574331462\nHope your service is running, as Nginx only throws the 502 when there is the issue of backend or upstream service not running.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-11-13T05:38:28",
      "url": "https://stackoverflow.com/questions/69951499/i-want-my-eks-cluster-to-listen-to-https-request"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69657338,
      "title": "Expose Elastic APM through Ingress Controller",
      "problem": "I have deployed elastic APM server into kubernetes and was trying to expose it through nginx ingress controller. Following is my configuration:\n```\n`---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: elastic\n  name: apm-server-config\n  labels:\n    k8s-app: apm-server\ndata:\n  apm-server.yml: |-\n    apm-server:\n      host: \"0.0.0.0:8200\"\n    setup.kibana:\n      enabled: \"true\"\n      host: \"kibana:5601\"\n    output.elasticsearch:\n      hosts: [\"elastic:9200\"]\n---\n#Deployment Configuration\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    name: apm-server\n    env: msprod\n    state: common\n  name: apm-server\n  namespace: elastic\nspec:\n  replicas: 1\n  minReadySeconds: 10\n  selector:\n    matchLabels:\n      app: apm-server\n  strategy:\n    rollingUpdate:\n      maxSurge: 25%\n      maxUnavailable: 25%\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        app: apm-server\n    spec:\n      containers:\n        - image: docker.elastic.co/apm/apm-server:7.12.1\n          imagePullPolicy: Always\n          env:\n            - name: output.elasticsearch.hosts\n              value: \"http://elastic:9200\"\n          name: apm-server              \n          ports:\n          - name: liveness-port\n            containerPort: 8200\n          volumeMounts:\n          - name: apm-server-config\n            mountPath: /usr/share/apm-server/apm-server.yml\n            readOnly: true\n            subPath: apm-server.yml\n          resources:\n            limits:\n              cpu: 250m\n              memory: 1024Mi\n            requests:\n              cpu: 100m\n              memory: 250Mi\n      volumes:\n      - name: apm-server-config\n        configMap:\n          name: apm-server-config\n      nodeSelector:\n        env: prod\n      restartPolicy: Always\n      terminationGracePeriodSeconds: 30\n---\n#Service Configuration\napiVersion: v1\nkind: Service\nmetadata:\n  labels:\n    app: apm-server\n  name: apm-server\n  namespace: elastic\nspec:\n  ports:\n  - port: 8200\n    targetPort: 8200\n    name: http\n    nodePort: 31000\n  selector:\n    app: apm-server\n  sessionAffinity: None\n  type: NodePort\n---\napiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  namespace: elastic\n  name: gateway-ingress-apm\n  annotations:\n    kubernetes.io/ingress.class: nginx\nspec:\n  rules:\n    - host: my.domain.com\n      http: \n        paths:\n          - path: /apm\n            backend:\n              serviceName: apm-server\n              servicePort: 8200\n`\n```\nThe pod is running and I am able to hit APM server using `kubectl port-forward`.\nBut when I am accessing the apm server with `https://my.domain.com/apm` then I am getting page not found error in browser and following error in APM pod:\n```\n`{\"log.level\":\"error\",\"@timestamp\":\"2021-10-21T06:22:00.198Z\",\"log.logger\":\"request\",\"log.origin\":{\"file.name\":\"middleware/log_middleware.go\",\"file.line\":60},\"message\":\"404 page not found\",\"url.original\":\"/apm\",\"http.request.method\":\"GET\",\"user_agent.original\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.61 Safari/537.36\",\"source.address\":\"10.148.7.7\",\"http.request.body.bytes\":0,\"http.request.id\":\"9294124a-5356-4b2c-ba8e-c0a589b23571\",\"event.duration\":110881,\"http.response.status_code\":404,\"error.message\":\"404 page not found\",\"ecs.version\":\"1.6.0\"}\n`\n```\nThe error is coming because there is no context path configured in APM. I have gone through the APM documentation and couldn't find a way to configure context path in the apm server. Please help.",
      "solution": "Posting this as answer out of comments.\n\nInitial ingress rule passes the same path `/apm` to the APM service, which is confirmed by error in APM pod's logs - `\"message\":\"404 page not found\",\"url.original\":\"/apm\"`\nTo fix it, nginx ingress has rewrite annotation. The way it works is described in the link with example.\nFinal `ingress.yaml` should look like:\n```\n`apiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  namespace: elastic\n  name: gateway-ingress-apm\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/rewrite-target: /$2 # adding captured group\nspec:\n  rules:\n    - host: my.domain.com\n      http: \n        paths:\n          - path: /apm(/|$)(.*) # to have captured group works correctly\n            backend:\n              serviceName: apm-server\n              servicePort: 8200\n`\n```\nWhat happens here is requests sent to `my.domain.com/apm` goes to the service on `/` path.\n`Captured group` allows to preserve correct paths, for instance if the request goes to `my.domain.com/apm/something`, ingress will translate it to `/something` which will be passed to the service.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-10-21T09:02:55",
      "url": "https://stackoverflow.com/questions/69657338/expose-elastic-apm-through-ingress-controller"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69343470,
      "title": "How to disable http access to service using Kubernetes Nginx ingress controller?",
      "problem": "I have a service providing an API that I want to only be accessible over `https`. I don't want `http` to redirect to `https` because that will expose credentials and the caller won't notice. Better to get an error response.\nHow to do I configure my ingress.yaml? Note that I want to maintain the default 308 redirect from `http` to `https` for other services in the same cluster.\nThanks.",
      "solution": "In the documentation: you can read the following sentence about HTTPS enforcement through redirect:\n\nBy default the controller redirects (308) to HTTPS if TLS is enabled for that ingress. If you want to disable this behavior globally, you can use  `ssl-redirect: \"false\"`  in the NGINX  ConfigMap.\n\nTo configure this feature for specific ingress resources, you can use the nginx.ingress.kubernetes.io/ssl-redirect: \"false\" annotation in the particular resource.\n\nYou can also create two separate configurations: one with http and https and the other one only for http.\nUsing `kubernetes.io/ingress.class` annotation you can choose the ingress controller to be used.\n\nThis mechanism also provides users the ability to run multiple NGINX ingress controllers (e.g. one which serves public traffic, one which serves \"internal\" traffic).\n\nSee also this and this similar questions.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-09-27T10:30:55",
      "url": "https://stackoverflow.com/questions/69343470/how-to-disable-http-access-to-service-using-kubernetes-nginx-ingress-controller"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 67246746,
      "title": "TLS nginx ingress in AWS EKS Cluster results in 404 Not Found",
      "problem": "I am trying to use Kubernetes Ingress Nginx Controller and running a simple nginx server in AWS EKS.\nBrowser (https) --> Route 53 (DNS) --> CLB --> nginx Ingress (Terminate TLS) --> Service --> POD\nBut I am receiving 404 error in browser (url used: https://example.com/my-nginx):\n```\n`\n404 Not Found\n\n404 Not Found\nnginx/1.19.10\n\n`\n```\nand in ingress logs (kubectl logs -n nginx-ingress nginx-ingress-nginx-controller-6db6f85bc4-mfpwx), I can see below:\n192.168.134.181 - - [24/Apr/2021:19:02:01 +0000] \"GET /my-nginx HTTP/2.0\" 404 154 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:88.0) Gecko/20100101 Firefox/88.0\" 219 0.002 [eshop-dev-my-nginx-9443] [] 192.168.168.105:80 154 0.000 404 42fbe692a032bb40bf193954526369cd\nHere is my deployment yaml:\n```\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\n  namespace: eshop-dev\nspec:\n  selector:\n    matchLabels:\n      run: my-nginx\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        run: my-nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx\n        ports:\n        - containerPort: 80\n`\n```\nService yaml:\n```\n`apiVersion: v1\nkind: Service\nmetadata:\n  namespace: eshop-dev\n  name: my-nginx\nspec:\n  selector:\n    run: my-nginx\n  ports:\n    - name: server\n      port: 9443\n      targetPort: 80\n      protocol: TCP\n`\n```\nand ingress yaml:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: test-ingress\n  namespace: eshop-dev\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"\nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - path: /my-nginx\n        pathType: ImplementationSpecific\n        backend:\n          service:\n            name: my-nginx\n            port:\n                number: 9443\n  tls:\n  - hosts:\n    - example.com\n    secretName: externaluicerts\n`\n```\nI have verified that service returns the desired output, when used with port forwarding:\n```\n`kubectl -n eshop-dev port-forward service/my-nginx 9443:9443\n`\n```\nI'm not sure if the ingress is incorrectly configured or if it is another problem.Thanks in advance for the help!\nnginx-port-forward\nHere is the output of kubectl get ingress -n eshop-dev test-ingress -o yaml\n```\n`kubectl get ingress -n eshop-dev test-ingress -o yaml\nWarning: extensions/v1beta1 Ingress is deprecated in v1.14+, unavailable in v1.22+; use networking.k8s.io/v1 Ingress\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    kubectl.kubernetes.io/last-applied-configuration: |\n      {\"apiVersion\":\"networking.k8s.io/v1\",\"kind\":\"Ingress\",\"metadata\":{\"annotations\":{\"kubernetes.io/ingress.class\":\"nginx\"},\"name\":\"test-ingress\",\"namespace\":\"eshop-dev\"},\"spec\":{\"rules\":[{\"host\":\"example.com\",\"http\":{\"paths\":[{\"backend\":{\"service\":{\"name\":\"my-nginx\",\"port\":{\"number\":9443}}},\"path\":\"/my-nginx\",\"pathType\":\"ImplementationSpecific\"}]}}],\"tls\":[{\"hosts\":[\"example.com\"],\"secretName\":\"externaluicerts\"}]}}\n    kubernetes.io/ingress.class: nginx\n  creationTimestamp: \"2021-04-24T13:16:21Z\"\n  generation: 13\n  managedFields:\n  - apiVersion: networking.k8s.io/v1beta1\n    fieldsType: FieldsV1\n    fieldsV1:\n      f:status:\n        f:loadBalancer:\n          f:ingress: {}\n    manager: nginx-ingress-controller\n    operation: Update\n    time: \"2021-04-24T13:16:40Z\"\n  - apiVersion: extensions/v1beta1\n    fieldsType: FieldsV1\n    fieldsV1:\n      f:metadata:\n        f:annotations: {}\n    manager: kubectl-client-side-apply\n    operation: Update\n    time: \"2021-04-24T13:18:36Z\"\n  - apiVersion: networking.k8s.io/v1\n    fieldsType: FieldsV1\n    fieldsV1:\n      f:metadata:\n        f:annotations:\n          f:kubectl.kubernetes.io/last-applied-configuration: {}\n          f:kubernetes.io/ingress.class: {}\n      f:spec:\n        f:rules: {}\n        f:tls: {}\n    manager: kubectl-client-side-apply\n    operation: Update\n    time: \"2021-04-24T16:33:47Z\"\n  name: test-ingress\n  namespace: eshop-dev\n  resourceVersion: \"7555944\"\n  selfLink: /apis/extensions/v1beta1/namespaces/eshop-dev/ingresses/test-ingress\n  uid: a7694655-20c6-48c7-8adc-cf3a53cf2ffe\nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - backend:\n          serviceName: my-nginx\n          servicePort: 9443\n        path: /my-nginx\n        pathType: ImplementationSpecific\n  tls:\n  - hosts:\n    - example.com\n    secretName: externaluicerts\nstatus:\n  loadBalancer:\n    ingress:\n    - hostname: xxxxxxxxxxxxxxxxdc75878b2-433872486.eu-west-1.elb.amazonaws.com\n`\n```",
      "solution": "From the image you posted of the nginx-port-forward, I see you went on `localhost:9443` directly, which means the Nginx server you are trying to access serve its content under `/`\nBut in the ingress definition, you define that the service will be served with `path: /my-nginx`. This could be the problem, as you are requesting `https://example.com/my-nginx` which will basically go to `my-nginx:9443/my-nginx` and, depending on the Pod behind this service, it could return a 404 if there's nothing at that path.\nTo test if the problem is what I specified above, you have a few options:\n\neasiest one, remove `path: /my-nginx` an, instead, go with `path: /`. You could also specify `pathType: Prefix` which means that everything matching the subPath specified will be served by the service.\nAdd a rewrite target, which is necessary if you want to serve a service at a different path from the one expected by the application.\n\nAdd an annotation similar to the following:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: test-ingress\n  namespace: eshop-dev\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"\n    # this will rewrite request under / + second capture group\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n        # this will serve all paths under /my-nginx and capture groups for regex annotations\n      - path: /my-nginx(/|$)(.*)\n        pathType: ImplementationSpecific\n        backend:\n          service:\n            name: my-nginx\n            port:\n              number: 9443\n  tls:\n  - hosts:\n    - example.com\n    secretName: externaluicerts\n`\n```\n\nConfigure your application to know that it will be served under the path you desire. This is often the better approach, as frontend applications should almost always be served under the path that they expect to be.\n\nFrom the info you posted, I think this is the problem an once fixed, your setup should work.\n\nIf you are curious about rewrite targets or how paths work in an Ingress, here is some documentation:\nRewrites ( https://kubernetes.github.io/ingress-nginx/examples/rewrite/#rewrite )\nPath types ( https://kubernetes.io/docs/concepts/services-networking/ingress/#path-types )\n\nUpdate\nAbout why configuring the application to directly serve its content at the path specified in the Ingress (basically to know at which path it will served) is the best solution:\nLet's say you serve a complex application in your Pod which will serve its content under /. The main page will try to load several other resources like css, js code and so on, everything from the root directory. Basically, if I open `/`, the app will load also:\n```\n`/example.js\n/my-beautiful.css\n`\n```\nNow, if I serve this app behind an ingress at another path, let's say under `/test/` with a rewrite target, the main page will work, because:\n```\n`/test/ --> /  # this is my rewrite rule\n`\n```\nbut then, the page will request `/example.js`, and the rewrite works in one direction only, so the browser will request a resource which will go in 404, because the request should have been `/test/example.js` (as that would rewrite to remove the /test part of the path)\nSo, with frontend applications, rewrite targets may not be enough, mostly if the applications request resources with absolute paths. With just REST API or single requests instead, rewrites usually works great.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-04-24T21:36:10",
      "url": "https://stackoverflow.com/questions/67246746/tls-nginx-ingress-in-aws-eks-cluster-results-in-404-not-found"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66707145,
      "title": "HELM admission is constantly creating Pod in status &quot;Container Creating&quot;",
      "problem": "I am using K8S version 19.\nI tried to install second nginx-ingress controller on my server (I have already one for Linux so I tried to install for Windows as well)\n```\n`helm install nginx-ingress-win ingress-nginx/ingress-nginx \n-f internal-ingress.yaml \n--set controller.nodeSelector.\"beta\\.kubernetes\\.io/os\"=windows \n--set defaultBackend.nodeSelector.\"beta\\.kubernetes\\.io/os\"=windows \n--set controller.admissionWebhooks.patch.nodeSelector.\"beta\\.kubernetes\\.io/os\"=windows \n--set tcp.9000=\"default/frontarena-ads-win-test:9000\"\n`\n```\nThis failed with \"Error: failed pre-install: timed out waiting for the condition\".\nSo I have run helm uninstall to remove that chart\n```\n`helm uninstall nginx-ingress-win\nrelease \"nginx-ingress-win\" uninstalled\n`\n```\nBut I am getting Validation Webhook Pod created constantly\n```\n`kubectl get pods\nNAME                                                      READY   STATUS              RESTARTS   AGE\n\nnginx-ingress-win-ingress-nginx-admission-create-f2qcx    0/1     ContainerCreating   0          41m\n`\n```\nI delete pod with `kubectl delete pod` but it get created again and again.\nI tried also\n`kubectl delete -A ValidatingWebhookConfiguration nginx-ingress-win-ingress-nginx-admission` but I am getting message `not found` for all combinations. How I can resolve this and how I can get rid off this?\nThank you!!!",
      "solution": "If this `Pod` is managed by a `Deployment`,`StatefulSet`,`DaemonSet` etc., it will be automatically recreated every time you delete it, so trying to remove a `Pod` in most situations makes not much sense.\nIf you want to check what controlls this `Pod`, run:\n```\n`kubectl describe pod nginx-ingress-win-ingress-nginx-admission-create-f2qcx | grep Controlled\n`\n```\nYou would probably see some `ReplicaSet`, which is also managed by a `Deployment` or another object. Suppose I want to check what I should delete to get rid of my `nginx-deployment-574b87c764-kjpf6` `Pod`. I can do this as follows:\n```\n`$ kubectl describe pod nginx-deployment-574b87c764-kjpf6 | grep -i controlled\nControlled By:  ReplicaSet/nginx-deployment-574b87c764\n`\n```\nthen I need to run again `kubectl describe` on the name of the `ReplicaSet` we found:\n```\n`$ kubectl describe rs nginx-deployment-574b87c764 | grep -i controlled\nControlled By:  Deployment/nginx-deployment\n`\n```\nFinally we can see that it is managed by a `Deployment` named `nginx-deployment` and this is the resource we need to delete to get rid of our `nginx-deployment-574b87c764-kjpf6` `Pod`.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-03-19T12:17:39",
      "url": "https://stackoverflow.com/questions/66707145/helm-admission-is-constantly-creating-pod-in-status-container-creating"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66546725,
      "title": "Enable rewrite for a particular host in ingress nginx configuration",
      "problem": "I have below ingress-nginx configuration file.\nIt rewrites request for `one.example.com`. I have added another domain, but I don't want rewrite to happen for other domain.\nI went through doc, but there is now rewrite example for multiple host setup.\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-service\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\n    certmanager.k8s.io/cluster-issuer: \"letsencrypt-example-prod\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  tls:\n    - hosts:\n        - one.example.com\n        - two.example.com\n      secretName: super-secret\n  rules:\n    - host: one.example.com\n      http:\n        paths:\n          - path: /customer/?(.*)\n            pathType: Prefix\n            backend:\n              service:\n                name: customer-srv\n                port:\n                  number: 3000\n      host: two.example.com\n      http:\n        paths:\n        - path: /\n          pathType: Prefix\n          backend:\n            service:\n              name: kube-prometheus-grafana\n              port:\n                number: 80\n`\n```\nI could create two separate ingress files for each host.\nWhat will happen in that case it will create two load balancers with different dns?\n(cluster is hosted on aws)",
      "solution": "You can create two separate ingress.\nIn that case, nothing will change your ingress controller IP would be same only for DNS.\n\nWhat will happen in that case it will create two load balancers with\ndifferent dns?\n\nNo, it won't create two load balancers.",
      "question_score": 2,
      "answer_score": 2,
      "created_at": "2021-03-09T13:18:08",
      "url": "https://stackoverflow.com/questions/66546725/enable-rewrite-for-a-particular-host-in-ingress-nginx-configuration"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 65689703,
      "title": "Exposing service from Kubernetes NGINX Ingress controller always return 502 Bad Gateway",
      "problem": "I am having issues with request to my NodeJS app running in my kubernetes cluster in digital ocean. Every request returns a `502 Bad Gateway Error`. I am not sure what I am missing.\nThis is what the service config looks like\n`apiVersion: v1\nkind: Service\nmetadata:\n  name:  service-api\n  namespace: default\n  labels:\n    app:  service-api\nspec:\n  type: ClusterIP\n  ports:\n    - name: http\n      protocol: TCP\n      port: 80\n      targetPort: 3000\n  selector:\n    app:  service-api\n\n`\nThe Ingress.yml looks like this\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: service-api-ingress\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n    nginx.ingress.kubernetes.io/limit-connections: '2'\n    nginx.ingress.kubernetes.io/limit-rpm: '60'\n    service.beta.kubernetes.io/do-loadbalancer-protocol: \"http\"\n    service.beta.kubernetes.io/do-loadbalancer-algorithm: \"round_robin\"\n    service.beta.kubernetes.io/do-loadbalancer-http2-ports: \"443,80\"\n    service.beta.kubernetes.io/do-loadbalancer-tls-ports: \"443\"\n    service.beta.kubernetes.io/do-loadbalancer-tls-passthrough: \"true\"\nspec:\n  tls:\n  - hosts:\n    - dev-api.service.com\n    secretName: service-api-tls\n  rules:\n  - host: \"dev-api.service.com\"\n    http:\n      paths:\n      - pathType: Prefix\n        path: \"/\"\n        backend:\n          service:\n            name: service-api\n            port:\n              number: 80\n`\nWhenever I visit the host url I get a 502 error.\nThis is what appears in the nginx ingress log\n```\n`2021/01/13 08:41:34 [error] 319#319: *31338 connect() failed (111: Connection refused) while connecting to upstream, client: IP, server: dev-api.service.com, request: \"GET /favicon.ico HTTP/2.0\", upstream: \"http://10.244.0.112:3000/favicon.ico\", host: \"dev-api.service.com\", referrer: \"https://dev-api.service.com/status\"\n`\n```",
      "solution": "As we ( with @Emmanuel Amodu ) have discussed in comment:\nmistake was to connect to app using wrong port, port `4000` instead of `3000` as defined in `service-api`.\nFor community which will have similar problem please - most important steps for debugging:\n\nChecking netstat -plant output table\nChecking your Nginx Configuration: `$ kubectl exec -it -n   -- cat /etc/nginx/nginx.conf`\nChecking service: `$ kubectl describe svc service-api`",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-01-12T19:18:02",
      "url": "https://stackoverflow.com/questions/65689703/exposing-service-from-kubernetes-nginx-ingress-controller-always-return-502-bad"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 75882549,
      "title": "Not being able to use Basic Auth in NGINX Ingress Controller",
      "problem": "I'm using NGINX Ingress Controller and I want to use Basic Authentication, but I'm getting a 403 Error in the browser.\nI created a secret with `data.auth` base64 obtained from a file created with `htpasswd` and in the Ingress, I've added the annotations\n```\n`annotations:\n  nginx.org/basic-auth-secret: htpasswd\n  nginx.org/basic-auth-realm: \"Authentication Required\"\n`\n```\nwhere `htpasswd` is the name of the secret in the same namespace as the ingress.\nChecking the logs of the Nginx-ingress pod, I can find this\n```\n`[error] 1783#1783: *68296 open() \"/etc/nginx/secrets/my-demo-htpasswd\" failed (2: No such file or directory)\n`\n```\nWhat should I do to get the secrets loaded in the Ingress Controller?",
      "solution": "with \"nginx.org\" you need to use the secret type: nginx.org/htpasswd\n```\n`apiVersion: v1  \nkind: Secret  \nmetadata:  \n  name: basic-auth  \ntype: nginx.org/htpasswd  \nstringData:  \n  htpasswd: \n\n  example \n  htpasswd: foo:$apr1$T6zUs/pB$xvCvBUfMvvIk8r12lZz9C0\n`\n```",
      "question_score": 2,
      "answer_score": 3,
      "created_at": "2023-03-30T00:05:20",
      "url": "https://stackoverflow.com/questions/75882549/not-being-able-to-use-basic-auth-in-nginx-ingress-controller"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 74774268,
      "title": "Setting up Harbor registry in Minikube",
      "problem": "I'm trying to set up a Harbor Registry in Kubernetes cluster locally in Minikube. I am using https://github.com/goharbor/harbor-helm and trying to set it up with the ingress controller. At the moment, I have not changed any defaults (the default is of type 'ingress') but have installed the Nginx Ingress Controller via `minikube addons enable ingress`.\nRight now, the helm chart installs, and I added an entry to my hosts file for `192.168.49.2 core.harbor.domain` but page simply returns a 503 error.\nWhen reviewing the pod logs for the harbor portal, I get this: `ginx: [emerg] socket() [::]:8080 failed (97: Address family not supported by protocol)`\nI'm pretty sure that the reason why I'm getting this is because I need some default values set when installing the chart, but I'm not really sure what those may be.",
      "solution": "I found out what the issue was: I needed to set the `ipFamily.ipv6.enabled` version to false:\n`helm upgrade -i my-release harbor/harbor --set ipFamily.ipv6.enabled=false`",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2022-12-12T17:30:09",
      "url": "https://stackoverflow.com/questions/74774268/setting-up-harbor-registry-in-minikube"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 71174668,
      "title": "Nginx sometimes fails TLS passthrough to Java 17 application",
      "problem": "We have a spring-boot application that runs perfectly fine by itself on both Java 11 and Java 17.\nThe spring-boot application is packaged as a docker container and runs inside gcp/gke kubernetes.\nWe use the nginx ingress to forward the traffic with tls-passthrough.\nWe use a Let's Encrypt certificate for our application.\nThe nginx does not have access to it (AFAICT), but considers it valid.\nWhen using Java 11 everything works fine.\nHowever, when using Java 17 the first (few) requests pass fine, but then I get a certificate error. The nginx generates/has a default ingress certificate, that it uses for the later requests. But I don't understand why it does serve that (sometimes) in the first place.\nThe error is reproducible with browsers and Java applications.\nI did not manage to preproduce it with curl/openssl though.\nAfter a short time/few minutes the error vanishes for the next (few) requests before it emerges again.\nWhen adding the ingress certificate to the trusted certs in browsers I can see that the ingress requests are upgraded to HTTP2, the first few HTTP1 requests all use the correct certificate.\nWe tried with different java 17 base images (openjdk/eclipse-temurin + alpine/ununtu).\nWe tried to explicitly disable http2 in Java and the browser.\nNothing seems to work except for adding the self-signed certificate to the trust-store (which is obviously a no go for production).\nWe weren't able to reproduce this locally, but might be due to our local dev setup being only a simplified version of the cloud environments.\nIf I use kubectl port-forward into the java app container, I cannot reproduce the issue.\nWe use the following versions:\n\nnginx-ingress-1.41.3\ngke v1.21.6-gke.1500\neclipse-temurin 17\nspring-boot 2.6.3 with the default tomcat\n\nTLDR: The nginx-ingress sometimes does not tls-passthrough to our Java 17 app correctly and thus serves an invalid certificate for those requests. (All responses contain the expected/same/valid content except for the certificate).\nHas anyone an idea what is happening and how to fix/avoid that?",
      "solution": "We had the exact same issue, and we believe the cause to be\nhttps://github.com/kubernetes/ingress-nginx/issues/9540\nIf you cannot upgrade, as stated in the issue\n\nIn the meantime, it seems that setting the Java system property jdk.tls.server.enableSessionTicketExtension to false on the server side will disable the TLS feature which is causing this problem.\n\nseemed to solve the problem in our case.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2022-02-18T14:57:48",
      "url": "https://stackoverflow.com/questions/71174668/nginx-sometimes-fails-tls-passthrough-to-java-17-application"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70847804,
      "title": "How to start an Ingress Controller with flags? (microk8s)",
      "problem": "Usually i am able to find most things by searching on the web - however in this case, the instructions on the web talk about - probably very basic stuff that i don't get yet.\nWhat i am trying to achieve: i am trying to install argocd, using microk8s and nginx-ingress. Right now i am stuck at enabling the SSL passthrough for argocd. Currently i configured an ingress-controller according to the instructions of the argocd-documentation and the ingress-controller runs without errors.\nMy guess is that as it's mentioned everywhere that i have to start the ingress controller with the \"--enable-ssl-passthrough\"-flag.\nhttps://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#ssl-passthrough\n\"SSL Passthrough is disabled by default and requires starting the controller with the --enable-ssl-passthrough flag.\"\nNow my problem: How do i do that? - for me, the ingress controller is \"just always running\". I can delete and recreate the controller with the kubectl-command \"create -f ingress.yaml\" - which creates an ingress within the argocd-namespace.\ni kind of lack the basics of kubernetes and don't get how i could stop and restart the ingress-controller with flags (perhaps i mistake what the \"ingress controller\" is too). Does anyone have an idea how i could achieve that?\nI am running microk8s v1.23.1 on Ubuntu 18.04.3 LTS",
      "solution": "If you can edit deployment YAML config to pass argument like\n```\n`kubectl edit deployment  -n  -o yaml\n`\n```\nyou can edit the YAML of the controller like\n```\n`containers:\n    - name: nginx-ingress-controller\n      image: \n      args:\n        - --enable-ssl-passthrough\n`\n```\nIngress annotation if you want to add\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: minimal-ingress\n  annotations:\n    #LIST OF ANNOTATION YOU CAN ADD\n    nginx.ingress.kubernetes.io/secure-backends: \"true\"\n    nginx.ingress.kubernetes.io/ssl-passthrough: \"true\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx-example\n  rules:\n  - http:\n      paths:\n      - path: /testpath\n        pathType: Prefix\n        backend:\n          service:\n            name: test\n            port:\n              number: 80\n`\n```",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2022-01-25T12:24:39",
      "url": "https://stackoverflow.com/questions/70847804/how-to-start-an-ingress-controller-with-flags-microk8s"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 70415874,
      "title": "Mistakes in my ingress yaml file or process?",
      "problem": "I'm trying kubernetes and making some progress, but I'm running into an issue with ingress when trying to make my hello world app publicly available.\nSUCCESS WITH DEPLOYMENT AND SERVICE\nI created a simple `hello world` type of nodejs app and pushed the image to my docker hub `johnlai2004/swarm2`.  I successfully created a deployment and service with this yaml file:\n`nodejs.yaml`\n```\n`apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nodejs-hello\n  labels:\n    app: nodejs-hello\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nodejs-hello\n  template:\n    metadata:\n      labels:\n        app: nodejs-hello\n    spec:\n      containers:\n      - name: nodejs-hello\n        image: johnlai2004/swarm2\n        ports:\n        - containerPort: 3000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: nodejs-hello-service\nspec:\n  selector:\n    app: nodejs-hello\n  type: LoadBalancer\n  ports:\n    - protocol: TCP\n      port: 3000\n      targetPort: 3000\n      nodePort: 30000\n`\n```\nI uploaded these files to a VPS with a new installation of ubuntu 20.04, minikube, kubectl and docker.\nI ran the following commands and got the results I wanted:\n```\n`minikube start --driver=docker\nkubectl apply -f nodejs.yaml\nminikube service nodejs-hello-service\n|-----------|----------------------|-------------|---------------------------|\n| NAMESPACE |         NAME         | TARGET PORT |            URL            |\n|-----------|----------------------|-------------|---------------------------|\n| default   | nodejs-hello-service |        3000 | http://192.168.49.2:30000 |\n|-----------|----------------------|-------------|---------------------------|\n\n`\n```\nWhen I do a `wget http://192.168.49.2:30000`, I get an `index.html` file that says `hello from nodejs-hello-556dc868-6lrdz at 12/19/2021, 10:29:56 PM`.  This is perfect.\nFAILURE WITH INGRESS\nNext, I want to use ingress so that I can see the page at `http://website.example.com`  (replace `website.example.com` with the actual domain that points to my server). I put this file on my server:\n`nodejs-ingress.yaml`\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nodejs-ingress\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"\nspec:\n  rules:\n    - host: website.example.com\n      http:\n        paths:\n        - path: /\n          pathType: Prefix\n          backend:\n            service:\n              name: nodejs-hello-service\n              port:\n                number: 3000\n`\n```\nAnd I ran the commands\n```\n`minikube addons enable ingress\nkubectl apply -f nodejs-ingress.yaml\nkubectl get ingress\nNAME             CLASS    HOSTS                   ADDRESS     PORTS   AGE\nnodejs-ingress      website.example.com     localhost   80      15m\n\n`\n```\nBut when I visit `http://website.example.com` with my browser, the browser says it can't connect.  Using `wget http://website.example.com` gave the same connection issue.\nCan someone point out what I may have done wrong?\n\nUPDATE\nI ran these commands because I think it shows I didn't install ingress-controller in the right name space?\n```\n`kubectl get pod -n ingress-nginx\nNAME                                        READY   STATUS      RESTARTS   AGE\ningress-nginx-admission-create--1-tqsrp     0/1     Completed   0          4h25m\ningress-nginx-admission-patch--1-sth26      0/1     Completed   0          4h25m\ningress-nginx-controller-5f66978484-tmx72   1/1     Running     0          4h25m\n\nkubectl get pod -n default\nNAME                          READY   STATUS    RESTARTS   AGE\nnodejs-hello-556dc868-6lrdz   1/1     Running   0          40m\n`\n```\nSo does this mean my nodejs app is in a name space that doesn't have access to the ingress controller?\n\nUPDATE 2\nI also tried following this guide step by step.\nOne difference I noticed was when I ran the command `kubectl get ingress`, `ADDRESS` says `localhost`.   But in the guide, it says it is supposed to be `172.17.0.15`\n\nDoes this difference matter?  I'm hosting things in a cloud vps called linode.com.   Does that change the way I do things?",
      "solution": "The behaviour you have is expected. Let me explain why. Going point through point, and at the end I will present my tips.\nFirst I think it's worth to present minikube architecture. I'm assuming you have installed minikube using default driver `docker` as you have address `192.168.49.2` which is standard for `docker` driver.\nThe layers are:\n\nyour VM with Ubuntu 20.04\nKubernetes cluster setup by minikube which is docker container with address `192.168.49.2` on the VM\n\nSo... you can not just run `curl` on the VM using a `localhost` address to connect to the service. The `localhost` is referring to the device that you are making curl request (so your VM), not the docker container. That's why you need to use the `192.168.49.2` address.\nYou can type `docker ps -a`, and you will see the container which is an actual Kubernetes cluster. You can exec into it using `docker exec` command and then run `curl` command with the localhost address:\n```\n`user@example-ubuntu-minikube-template-1:~$ curl -H \"Host: hello-world.info\" localhost\ncurl: (7) Failed to connect to localhost port 80: Connection refused\nuser@example-ubuntu-minikube-template-1:~$ docker ps -a\nCONTAINER ID   IMAGE                                 COMMAND                  CREATED      STATUS      PORTS                                                                                                                                  NAMES\n1a4ba3895990   gcr.io/k8s-minikube/kicbase:v0.0.28   \"/usr/local/bin/entr\u2026\"   4 days ago   Up 4 days   127.0.0.1:49157->22/tcp, 127.0.0.1:49156->2376/tcp, 127.0.0.1:49155->5000/tcp, 127.0.0.1:49154->8443/tcp, 127.0.0.1:49153->32443/tcp   minikube\nuser@example-ubuntu-minikube-template-1:~$ docker exec -it 1a sh\n# curl -H \"Host: hello-world.info\" localhost\nHello, world!\nVersion: 1.0.0\nHostname: web-79d88c97d6-nl4c7\n`\n```\nKeep in mind that you can access this container only from the VM that is hosting this container. Without any further configuration it's you can't just access it from the other VMs. It is possible, but not recommended.\nGood explanation in the minikube FAQ:\n\nHow can I access a minikube cluster from a remote network?\n\nminikube\u2019s primary goal is to quickly set up local Kubernetes clusters, and therefore we strongly discourage using minikube in production or for listening to remote traffic. By design, minikube is meant to only listen on the local network.\n\nHowever, it is possible to configure minikube to listen on a remote network. This will open your network to the outside world and is not recommended. If you are not fully aware of the security implications, please avoid using this.\n\nFor the docker and podman driver, use  `--listen-address`  flag:\n```\n`minikube start --listen-address=0.0.0.0\n`\n```\n\nSo I'd avoid it. I will present a better possible solution at the end of the answer.\nYou asked:\n\nBut when I visit  `http://website.example.com`  with my browser, the browser says it can't connect. Using  `wget http://website.example.com`  gave the same connection issue.\n\nCan someone point out what I may have done wrong?\n\nYour computer does not know what it is `website.example.com`. It's not aware that this name is used by your Ingress. If your computer does not find this name in hosts file it will start looking for this over the Internet.\nSo you have some possible solutions:\n\nuse `curl -H 'HOST: website.example.com' http://192.168.49.2:80` - it will work only on the VM where is minikube\nadd host to the hosts file - something like `192.168.49.2 website.example.com` - it will work only on the VM where is minikube\nSetup a bare-metal cluster (more details in the sum up section) and point the domain address to the VM address.  In GCP and AWS you can do it using  Google Cloud DNS or Amazon Route 53. On linode cloud maybe this one - DNS Manager ?\n\nEDIT:\nYou wrote that you have a domain pointed to the server, so please just check the sum up section of my answer.\nAlso you asked:\n\nI ran these commands because I think it shows I didn't install ingress-controller in the right name space?\n\nSo does this mean my nodejs app is in a name space that doesn't have access to the ingress controller?\n\nIt's absolutely normal:\n\nIt will install the controller in the `ingress-nginx` namespace, creating that namespace if it doesn't already exist.\n\nAlso:\n\nI also tried following this guide step by step:  https://kubernetes.io/docs/tasks/access-application-cluster/ingress-minikube/\n\nOne difference I noticed was when I ran the command  `kubectl get ingress`,  `ADDRESS`  says  `localhost`. But in the guide, it says it is supposed to be  `172.17.0.15`\n\nDoes this difference matter? I'm hosting things in a cloud vps called linode.com. Does that change the way I do things?\n\nIt's also normal and expected when using minikube with a docker driver.\nTo sum up / other tips:\n\nMinkube is fine for local testing; you can easily access apps and services using from the host - check Accessing apps.\nHowever, for exposing it outside the network you should consider using solutions like kubeadm or kubespray for cluster setup + MetalLB for LoadBalancer solution. Check \"Bare-metal considerations\" and Exposing a Kubernetes service on a bare-metal cluster over the external network architecture\nIf you are planning to use your service with ingress, don't use LoadBalancer type. It's ok to use ClusterIP.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-12-19T23:41:19",
      "url": "https://stackoverflow.com/questions/70415874/mistakes-in-my-ingress-yaml-file-or-process"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 69616457,
      "title": "Kubernetes ingress is giving me 404 if I don&#39;t use wildcard",
      "problem": "I am working on a microservice app and I use nginx ingress. I setup rules with 3 services, when I mention host in the rules like this bellow it always gives me 404 for all the services\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-srv\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    cert-manager.io/issuer: \"local-selfsigned\"\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/ssl-redirect: \"true\"\nspec:\n  tls:\n    - hosts:\n        - \"tradephlo.local\"\n      secretName: tls-ca\n  rules:\n    - host: \"tradephlo.local\"\n    - http:\n        paths:\n          - path: /api/main/?(.*)\n            pathType: Prefix\n            backend:\n              service:\n                name: tradephlo-main-srv\n                port:\n                  number: 4000\n          - path: /api/integration/?(.*)\n            pathType: Prefix\n            backend:\n              service:\n                name: tradephlo-integration-srv\n                port:\n                  number: 5000\n          - path: /?(.*)\n            pathType: Prefix\n            backend:\n              service:\n                name: tradephlo-client-srv\n                port:\n                  number: 3000\n\n`\n```\nHowever if I put wildcard in the host under the rules it works perfectly\n```\n`rules:\n    - host: \"*.tradephlo.local\"\n`\n```\nI don't want to generate wildcard SSL in the production. Please help me point out what I am doing wrong here.",
      "solution": "The problem is in dash `-` in the following line:\n```\n`rules:\n    - host: \"tradephlo.local\"\n    - http:\n`\n```\nOtherwise, it is 2 different hosts - `tradephlo.local` abd `*`.\nWe can check this with the following command:\n`kubectl describe ing ingress-srv`\nAnd we get this:\n```\n`$ kubectl describe ing ingress-srv\nName:             ingress-srv\nNamespace:        default\nAddress:          xxxxxxxxxx\nDefault backend:  default-http-backend:80 (10.60.0.9:8080)\nTLS:\n  tls-ca terminates tradephlo.local\nRules:\n  Host        Path  Backends\n  ----        ----  --------\n  *\n              /api/main/?(.*)   nginx:80 (yyyyy:80)\n`\n```\nAnd we get this after removed `-`:\n```\n`$ kubectl describe ing ingress-srv\nName:             ingress-srv\nNamespace:        default\nAddress:          xxxx\nDefault backend:  default-http-backend:80 (10.60.0.9:8080)\nTLS:\n  tls-ca terminates tradephlo.local\nRules:\n  Host        Path  Backends\n  ----        ----  --------\n  tradephlo.local\n              /api/main/?(.*)   nginx:80 (yyyyyy:80)\n`\n```\nSo there is no need to use wildcard, when you do this, ingress treats `*.tradephlo.local` as different host and proceeds to * rule.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-10-18T14:54:06",
      "url": "https://stackoverflow.com/questions/69616457/kubernetes-ingress-is-giving-me-404-if-i-dont-use-wildcard"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66722484,
      "title": "Kubernetes HELM - how to create multiple NGINX Ingress controllers one for each Node",
      "problem": "I have two nodes for my cluster: Windows and Linux. And I have one master node.\nFor Linux I installed NGINX controller and everything works perfectly fine!!!\n```\n`helm install nginx-ingress ingress-nginx/ingress-nginx \\\n    -f internal-ingress.yaml \\\n    --set controller.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n    --set defaultBackend.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux \\\n    --set controller.admissionWebhooks.patch.nodeSelector.\"beta\\.kubernetes\\.io/os\"=linux\n`\n```\nSo that NGINX Ingress Controller should target Linux Pod and that works!\nNow I want to create NGINX Ingress Controller to target my second Node which is Windows.\nOnce I tried to create it it threw me `Error: timed out waiting for the condition`\nI tried this command (very similar to working Linux command).\n```\n`helm install nginx-ingress-win ingress-nginx/ingress-nginx -f internal-ingress.yaml \n--set controller.nodeSelector.\"beta\\.kubernetes\\.io/os\"=windows \n--set defaultBackend.nodeSelector.\"beta\\.kubernetes\\.io/os\"=windows \n--set controller.admissionWebhooks.patch.nodeSelector.\"beta\\.kubernetes\\.io/os\"=windows\n`\n```\nIs it possible to have 2 NGINX Ingress Controllers? Why did it timeout? Am I doing something wrong?\nWhat should be the correct command to install NGINX Ingress Controller for Windows?\nThank you",
      "solution": "helm install creates kubernetes objects in the current namespace of your context.\nYou should use separate namespace for nginx-ingress-win release using --create-namespace --namespace namespacename flags\n\nPlease run the helm install command with --debug flag to see what is the problem\n\nFinal Command :\n```\n`helm install nginx-ingress-win ingress-nginx/ingress-nginx -f internal-ingress.yaml \n--set controller.nodeSelector.\"beta\\.kubernetes\\.io/os\"=windows \n--set defaultBackend.nodeSelector.\"beta\\.kubernetes\\.io/os\"=windows \n--set controller.admissionWebhooks.patch.nodeSelector.\"beta\\.kubernetes\\.io/os\"=windows \n --create-namespace --namespace namespacename --debug\n`\n```\n\nPlease provide the reason for having separate nginx controller for linux and windows nodes in the same cluster.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-03-20T15:02:07",
      "url": "https://stackoverflow.com/questions/66722484/kubernetes-helm-how-to-create-multiple-nginx-ingress-controllers-one-for-each"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 66129333,
      "title": "Kubernetes cluster behind ISP router",
      "problem": "I'm trying to create a k3s cluster at home using 3 raspberry pi 4.\nI've sweat a lot setting up the nginx-ingress + letsencrypt pods.\nActually, it seems to work but I can't check it now.\nNow my problem is the following:\nI'm connected to internet using an ISP router (Livebox Orange).\nMy 3 RPI are connected to it and have the following IPs:\n\nMaster : 192.168.1.20\nNode1 : 192.168.1.21\nNode2 : 192.168.1.22\n\nI've linked my domain name to a dynamic DNS pointing to my ISP box IP (yes this sh*tty box can't handle a persitent IP).\nThe Load balancer has a range from 192.168.1.240 to 192.168.1.250.\nNow my question is how to forward port from the ISP to the load balancer ?\nI have a config UI on it which allows me to redirect ports to existing device IP, but as the\nloadbalancer IP is not a real device, I cannot select it.\nI'm sorry I'm a real noob on kubernetes.\nIf you need more details, just ask, I'll provide them.\nThank you in advance.",
      "solution": "For your current case:\nYou need to introduce a new k3s independent component in your network and that can be a reverse proxy like HAProxy, which can be set up to balance requests between 3 IPs.\nOr:\n#1 Rebuild your k3s cluster without Traefik and Service LoadBalancer:\n```\n`curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC='server --no-deploy servicelb --no-deploy traefik --flannel-backend=host-gw --write-kubeconfig-mode 644' sh -\n`\n```\n#2 Deploy MetalLB\nhttps://metallb.universe.tf/configuration/#layer-2-configuration\nwith the configuration:\n```\n`---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  namespace: metallb-system\n  name: config\ndata:\n  config: |\n    address-pools:\n    - name: default\n      protocol: layer2\n      addresses:\n      - 192.168.1.20-192.168.1.22 \n`\n```\nThis will add a functionality to the cluster where any service of load balancer type will be bound to the IP of the node.\nexample from my own:\n```\n`NAME     STATUS   ROLES                  AGE     VERSION        INTERNAL-IP     EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION   CONTAINER-RUNTIME\nnode02   Ready                     13d     v1.20.2+k3s1   192.168.1.202           Alpine Linux v3.13   5.10.12-0-virt   containerd://1.4.3-k3s1\nnode03   Ready                     2d11h   v1.20.2+k3s1   192.168.1.203           Alpine Linux v3.13   5.10.12-0-virt   containerd://1.4.3-k3s1\nnode01   Ready    control-plane,master   13d     v1.20.2+k3s1   192.168.1.201           Alpine Linux v3.13   5.10.12-0-virt   containerd://1.4.3-k3s1\n`\n```\n```\n`NAME                        TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)                                     AGE   SELECTOR\nkube-dns                    ClusterIP      10.43.0.10                53/UDP,53/TCP,9153/TCP                      13d   k8s-app=kube-dns\nmetrics-server              ClusterIP      10.43.254.20              443/TCP                                     13d   k8s-app=metrics-server\ntraefik                     LoadBalancer   10.43.130.1     192.168.1.201   80:31666/TCP,443:31194/TCP,8080:31199/TCP   13d   app=traefik\n`\n```\n#3\nfollow this setup to get traefik going instead of nginx\nhttps://github.com/sleighzy/k3s-traefik-v2-kubernetes-crd\nthe author uses 2 rpis.\n#4\nFrom your router you should forward ports 80/443 to the node which has traffic on.\nYou can get away without an external LoadBalancer because the service traefik in that setup is defined as LoadBalancer and will harbour on one node only. It can be that it migrates between restarts of nodes - you'll have to adjust your router.",
      "question_score": 2,
      "answer_score": 1,
      "created_at": "2021-02-10T01:42:00",
      "url": "https://stackoverflow.com/questions/66129333/kubernetes-cluster-behind-isp-router"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 72761673,
      "title": "Why I do not see any nodes in kubernetes cluster with role master or worker?",
      "problem": "I did kubeadm init on one machine. I followed all the instructions on network etc and end up with this:\n`kubectl get nodes`:\n`NAME              STATUS   ROLES           AGE    VERSION\nslchvdvcybld001   Ready    control-plane   140m   v1.24.2\nslchvdvcydtb001   Ready              136m   v1.24.2\nslchvdvcytst001   Ready              137m   v1.24.2\n`\nAs you can see, no nodes are Master or worker or similar.\nI don't have some special setup, all I did is install it and did init.\nThere are no errors in logs file. Dashboard is in GREEN and everything is in green.\nThese are versions of kubectl and so on:\n`Client Version: v1.24.2\nKustomize Version: v4.5.4\nServer Version: v1.24.2\n`",
      "solution": "Labelling of master node is deprecated.  That's where when  using `kubectl get nodes` its showing role as \"control-plane\" instead of \"control-plane,master\"\nMore details are in following link\nKubeadm: http://git.k8s.io/enhancements/keps/sig-cluster-lifecycle/kubeadm/2067-rename-master-label-taint/README.md",
      "question_score": 1,
      "answer_score": 6,
      "created_at": "2022-06-26T14:37:54",
      "url": "https://stackoverflow.com/questions/72761673/why-i-do-not-see-any-nodes-in-kubernetes-cluster-with-role-master-or-worker"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 68449554,
      "title": "Ingress rule using host",
      "problem": "Can someone please help to spot the issue with `ingress-2` ingress rule? why `ingress-1` is working vs `ingress-2` is not working.\nDescription of my setup, I have two deployments:\n1st deployment is of `nginx`\n2nd deployment is of `httpd`\nBoth of the deployments are exposed via `ClusterIP` services named `nginx-svc` and `httpd-svc` respectively. All the `endpoints` are proper for the services. However, while\nsetting up the ingress for these services, I am not able to setup the ingress using `host` (as described in `ingress-2`). however, when I am using `ingress-1`, things work fine.\n// my host file for name resolution\n```\n`grep myapp.com /etc/hosts\n127.0.0.1        myapp.com\n`\n```\n// deployment details\n```\n`kubectl get deployments.apps\nNAME    READY   UP-TO-DATE   AVAILABLE   AGE\nnginx   3/3     3            3           29m\nhttpd   3/3     3            3           29m\n`\n```\n// service details\n```\n`kubectl get svc\nNAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE\nkubernetes   ClusterIP   10.152.183.1             443/TCP   7h48m\nnginx-svc    ClusterIP   10.152.183.233           80/TCP    28m\nhttpd-svc    ClusterIP   10.152.183.58            80/TCP    27m\n`\n```\n// endpoints details\n```\n`kubectl get ep\nNAME         ENDPOINTS                                      AGE\nkubernetes   10.0.2.15:16443                                7h51m\nnginx-svc    10.1.198.86:80,10.1.198.87:80,10.1.198.88:80   31m\nhttpd-svc    10.1.198.89:80,10.1.198.90:80,10.1.198.91:80   31m\n`\n```\nAttempt-1: `ingress-1`\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-1\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /nginx\n        pathType: Prefix\n        backend:\n          service:\n            name: nginx-svc\n            port:\n              number: 80\n\n      - path: /httpd\n        pathType: Prefix\n        backend:\n          service:\n            name: httpd-svc\n            port:\n              number: 80\n`\n```\n// Example showing that ingress routing is working fine when `ingress-1` is used:\n```\n` curl myapp.com/nginx\n\nWelcome to nginx!\n\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n\nWelcome to nginx!\nIf you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.\n\nFor online documentation and support please refer to\nnginx.org.\nCommercial support is available at\nnginx.com.\n\nThank you for using nginx.\n\n curl myapp.com/httpd\nIt works!\n`\n```\n// following ingress rule is not working as I was expecting\nAttempt-2: `ingress-2`\n```\n`kind: Ingress\nmetadata:\n  name: ingress-2\nspec:\n  rules:\n  - host: \"myapp.com\"\n    http:\n      paths:\n      - pathType: Prefix\n        path: \"/nginx\"\n        backend:\n          service:\n            name: nginx-svc\n            port:\n              number: 80\n      - pathType: Prefix\n        path: \"/httpd\"\n        backend:\n          service:\n            name: httpd-svc\n            port:\n              number: 80\n`\n```\n// I could not spot any issue in the ing describe\n```\n`kubectl describe  ingress ingress-2\nName:             ingress-2\nNamespace:        default\nAddress:          127.0.0.1\nDefault backend:  default-http-backend:80 ()\nRules:\n  Host          Path  Backends\n  ----          ----  --------\n  myapp.com\n                /nginx   nginx-svc:80 (10.1.198.86:80,10.1.198.87:80,10.1.198.88:80)\n                /httpd   httpd-svc:80 (10.1.198.89:80,10.1.198.90:80,10.1.198.91:80)\nAnnotations:    \nEvents:\n  Type    Reason  Age                  From                      Message\n  ----    ------  ----                 ----                      -------\n  Normal  Sync    9m15s (x2 over 10m)  nginx-ingress-controller  Scheduled for sync\n`\n```\n// example showing ingress routing is not working with this ingress resource\n```\n`curl myapp.com/nginx\n\n404 Not Found\n\n404 Not Found\nnginx/1.21.1\n\ncurl myapp.com/httpd\n\n404 Not Found\n\nNot Found\nThe requested URL was not found on this server.\n\n`\n```",
      "solution": "Difference between ingresses\nI created a one node `microk8s` cluster following official documentation and I wasn't able to reproduce behaviour you described which is correct behaviour. Added two pods with `mendhak/http-https-echo` image (highly recommend: very convenient for troubleshooting ingress or understanding how ingress works) and two services for each of pods.\nThe difference between two ingress rules is first ingress rule listens on all domains (HOSTS):\n```\n`$ mkctl get ing -o wide\nNAME        CLASS    HOSTS   ADDRESS     PORTS   AGE\ningress-1   public   *       127.0.0.1   80      2m53s\n\n$ curl -I --header \"Host: myapp.com\" http://127.0.0.1/httpd\nHTTP/1.1 200 OK\n\n$ curl -I --header \"Host: example.com\" http://127.0.0.1/httpd\nHTTP/1.1 200 OK\n\n$ curl -I --header \"Host: myapp.com\" http://127.0.0.1/missing_url\nHTTP/1.1 404 Not Found\n`\n```\nWhile the second ingress rule will serve only `myapp.com` domain (HOST):\n```\n`$ mkctl get ing\nNAME        CLASS    HOSTS       ADDRESS     PORTS   AGE\ningress-2   public   myapp.com   127.0.0.1   80      60s\n\n$ curl -I --header \"Host: myapp.com\" http://127.0.0.1/httpd\nHTTP/1.1 200 OK\n\n$ curl -I --header \"Host: example.com\" http://127.0.0.1/httpd\nHTTP/1.1 404 Not Found\n`\n```\nWhat exactly happens\nLast results in your question actually show that ingress is working as expected. You're getting responses not from `kubernetes ingress` but from pods within the cluster. First response is `404` from `nginx 1.21.0` and second is `404` from `apache`.\nThis happens because ingress sends requests to pods with the same `path` from URL without any transformations. For instance (this output I got using image mentioned above):\n```\n`$ curl myapp.com/httpd\n{\n  \"path\": \"/httpd\"\n...\n`\n```\nWhile both `nginx` and `apache` are serving on `/`.\nHow to resolve it\nNginx ingress has a lot of features and one of them is rewriting which helps to transform `paths` from what ingress gets to what goes to pods.\nFor example, if request goes to `http://myapp.com/nginx` then it will be directed to `nginx` service with `/nginx` path which will cause `nginx` to throw `404` since there's nothing on this `path`.\nIngress rule below fixes this by adding `rewrite-target` to `/` which we need to pass to `nginx` and `apache` services:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: ingress-2\n  annotations:\n#    kubernetes.io/ingress.class: nginx # this should be uncommented if ingress used in \"regular\" cluster\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  rules:\n  - host: myapp.com\n    http:\n      paths:\n      - path: /nginx\n        pathType: Prefix\n        backend:\n          service:\n            name: service-a\n            port:\n              number: 80\n      - path: /httpd\n        pathType: Prefix\n        backend:\n          service:\n            name: service-b\n            port:\n              number: 80\n`\n```\nQuick test how it works:\n```\n`$ curl myapp.com/nginx\n{\n  \"path\": \"/\",\n...\n`\n```\nAnd\n```\n`$ curl myapp.com/httpd\n{\n  \"path\": \"/\",\n...\n`\n```\nAs you can see now `path` is `/`.\nSwitching image to `nginx` and:\n```\n`$ curl myapp.com/nginx\n\nWelcome to nginx!\n\n...\n`\n```\nUseful links\n\nKubernetes ingress\nNginx ingress - rewrite",
      "question_score": 1,
      "answer_score": 8,
      "created_at": "2021-07-20T06:28:21",
      "url": "https://stackoverflow.com/questions/68449554/ingress-rule-using-host"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 65919773,
      "title": "Ingress Nginx Proxy to Outside Website (Webflow hosted)",
      "problem": "I have an EKS cluster, and a separate website built on (and hosted by) Webflow.\nThe cluster is behind `cluster.com` and the website `website.webflow.io`\nWhat I would like to achieve is to proxy requests coming to `cluster.com/website` to `website.webflow.io`\nBased on my research, this problem could/might be solved with the ExternalName service. Unfortunately, it doesn't solve it for me, and it's trying to do a DNS lookup within the cluster. I tried various other configurations with Endpoints as well. The ExternalName seems the most promising of everything I tried that's why I'm attaching the configuration below.\nHere is what my configuration looks like:\n```\n`---\nkind: Service\napiVersion: v1\nmetadata:\n  namespace: development\n  name: external-service\nspec:\n  type: ExternalName\n  externalName: website.webflow.io\n  ports:\n    - port: 443\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  namespace: development\n  name: external-ingress\n  annotations:\n    ingress.kubernetes.io/preserve-host: \"false\"\n    ingress.kubernetes.io/secure-backends: \"true\"\n    ingress.kubernetes.io/upstream-vhost: \"website.webflow.io\"\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\n    nginx.ingress.kubernetes.io/server-snippet: |\n      proxy_ssl_name website.webflow.io;\n      proxy_ssl_server_name on;\nspec:\n  rules:\n  - host: cluster.com\n    http:\n      paths:\n      - path: /website\n        backend:\n          serviceName: external-service\n          servicePort: 443\n\n`\n```\nIs there a straight-forward way to achieve this? What stands out as wrong in the configuration?",
      "solution": "Here is what I did.\nI applied your config but changed the following annotation name:\n```\n`ingress.kubernetes.io/upstream-vhost: \"website.webflow.io\"\n`\n```\nTo the one I have found in the nginx ingress docs:\n```\n`nginx.ingress.kubernetes.io/upstream-vhost: \"website.webflow.io\"\n^^^^^^\n`\n```\nTry it and let me know if it solves it.\nEDIT:\nhere is a complete yaml I used:\n```\n`---\nkind: Service\napiVersion: v1\nmetadata:\n  name: external-service\nspec:\n  type: ExternalName\n  externalName: website.webflow.io\n  ports:\n    - port: 443\n\n---\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: external-ingress\n  annotations:\n    ingress.kubernetes.io/preserve-host: \"false\"\n    ingress.kubernetes.io/secure-backends: \"true\"\n    nginx.ingress.kubernetes.io/upstream-vhost: \"website.webflow.io\"\n    nginx.ingress.kubernetes.io/backend-protocol: \"HTTPS\"\n    nginx.ingress.kubernetes.io/server-snippet: |\n      proxy_ssl_name website.webflow.io;\n      proxy_ssl_server_name on;\nspec:\n  rules:\n  - host: cluster.com\n    http:\n      paths:\n      - path: /website\n        backend:\n          serviceName: external-service\n          servicePort: 443\n`\n```",
      "question_score": 1,
      "answer_score": 6,
      "created_at": "2021-01-27T14:04:49",
      "url": "https://stackoverflow.com/questions/65919773/ingress-nginx-proxy-to-outside-website-webflow-hosted"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 74252668,
      "title": "Kubernetes Ingress path route to different services in different namespaces",
      "problem": "currently I'm trying the following setup:\nI have:\n\none cluster\none Ingress Controller\none url (myapp.onazure.com)\ntwo namespaces for two applications default and default-test\ntwo deployments, ingress objects, services for the namespaces\n\nI can easily reach my app from the default namespace with path based routing '/' as a prefix rule\nNow i have tried to configure the second namespace and following rule: /testing to hit another service\nUnfortunately i get an HTTP404 when i try to hit the following URL myapp.onazure.com/testing/openapi.json\nWhat did I miss?\nWorking Ingress 1\n```\n`kind: Ingress\napiVersion: networking.k8s.io/v1\nmetadata:\n  name: liveapi-ingress-object\n  namespace: default\n  annotations:\n    kubernetes.io/ingress.class: public-nginx\nspec:\n  tls:\n    - hosts:\n        - myapp-region1.onazure.com\n        - myapp-region2.onazure.com\n      secretName: ingress-tls-csi\n  rules:\n    - host: - myapp-region1.onazure.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: liveapi-svc\n                port:\n                  number: 8080\n    - host: myapp-region2.onazure.com\n      http:\n        paths:\n          - path: /\n            pathType: Prefix\n            backend:\n              service:\n                name: liveapi-svc\n                port:\n                  number: 8080\n\n`\n```\nNot working Ingress 2\n```\n`kind: Ingress\napiVersion: networking.k8s.io/v1\nmetadata:\n  name: liveapi-ingress-object-testing\n  namespace: default-testing\n  annotations:\n    kubernetes.io/ingress.class: public-nginx\n    #nginx.ingress.kubernetes.io/rewrite-target: /testing\nspec:\n  tls:\n    - hosts:\n        - myapp-region1.onazure.com\n        - myapp-region2.onazure.com\n      secretName: ingress-tls-csi-testing\n  rules:\n    - host: myapp-region1.onazure.com\n      http:\n        paths:\n          - path: /testing\n            #pathType: Prefix\n            backend:\n              service:\n                name: liveapi-svc-testing\n                port:\n                  number: 8080\n    - host: myapp-region2.onazure.com\n      http:\n        paths:\n          - path: /testing\n            #pathType: Prefix\n            backend:\n              service:\n                name: liveapi-svc-testing\n                port:\n                  number: 8080\n\n`\n```\nMaybe I am missing a rewrite target to simply '/' in the testing namespace ingress?",
      "solution": "Finally I figured out the missing part. I had to add the following statement to the not working ingress object:\n```\n`  annotations:\n    kubernetes.io/ingress.class: public-nginx\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\n`\n```\nPlease see the complete ingress object:\n```\n`kind: Ingress\napiVersion: networking.k8s.io/v1\nmetadata:\n  name: liveapi-ingress-object\n  namespace: default-testing\n  annotations:\n    kubernetes.io/ingress.class: public-nginx\n    nginx.ingress.kubernetes.io/use-regex: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /$1\nspec:\n  tls:\n    - hosts:\n        - myapp.onazure.com\n      secretName: ingress-tls-csi-testing\n  rules:\n    - host: myapp.onazure.com\n      http:\n        paths:\n          - path: /testing/(.*)\n            pathType: Prefix\n            backend:\n              service:\n                name: liveapi-svc-testing\n                port:\n                  number: 8000 \n\n \n`\n```",
      "question_score": 1,
      "answer_score": 3,
      "created_at": "2022-10-30T12:31:12",
      "url": "https://stackoverflow.com/questions/74252668/kubernetes-ingress-path-route-to-different-services-in-different-namespaces"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 68974404,
      "title": "How to rewrite URLs for some specific paths?",
      "problem": "I have read in ingress-nginx documentation that the rewrite is being performed thanks to an annotation like this:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\n  name: rewrite\n  namespace: default\nspec:\n  rules:\n  - host: rewrite.bar.com\n    http:\n      paths:\n      - backend:\n          serviceName: http-svc\n          servicePort: 80\n        path: /something(/|$)(.*)\n`\n```\nI have a case where I have multiple hosts and I want URL rewriting for some particular paths only:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n  name: ingress\nspec:\n  rules:\n    - host: somehost.westeurope.cloudapp.azure.com\n      http:\n        paths:\n        - path: /rest-smtp-sink # I want to rewrite this path\n          pathType: Prefix\n          backend:\n            service:\n              name: rest-smtp-sink-svc\n              port:\n                number: 80\n        - path: /backend # This one too\n          pathType: Prefix\n          backend:\n            service:\n              name: server-svc\n              port:\n                number: 80\n        - path: / # But not this one\n          pathType: Prefix\n          backend:\n            service:\n              name: client-svc\n              port:\n                number: 80\n`\n```\nHowever, the annotation seems to be global. How do I enable URL rewriting for some paths only?",
      "solution": "I managed to get the desired result with this configuration:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  annotations:\n    kubernetes.io/ingress.class: nginx\n    cert-manager.io/cluster-issuer: letsencrypt\n    nginx.ingress.kubernetes.io/force-ssl-redirect: \"true\"\n    nginx.ingress.kubernetes.io/rewrite-target: /$2\n  name: ingress\nspec:\n  rules:\n    - host: somehost.westeurope.cloudapp.azure.com\n      http:\n        paths:\n        - path: /rest-smtp-sink(/|$)(.*)\n          pathType: Prefix\n          backend:\n            service:\n              name: rest-smtp-sink-svc\n              port:\n                number: 80\n        - path: /backend(/|$)(.*)\n          pathType: Prefix\n          backend:\n            service:\n              name: server-svc\n              port:\n                number: 80\n        - path: /()(.*)\n          pathType: Prefix\n          backend:\n            service:\n              name: client-svc\n              port:\n                number: 80\n`\n```\nAs the `nginx.ingress.kubernetes.io/rewrite-target` annotation is global, I've used `/$2` as the rewrite target and `/()(.*)` as a noop for the root path.",
      "question_score": 1,
      "answer_score": 5,
      "created_at": "2021-08-29T17:29:28",
      "url": "https://stackoverflow.com/questions/68974404/how-to-rewrite-urls-for-some-specific-paths"
    },
    {
      "tech": "nginx",
      "source": "stackoverflow",
      "tag": "nginx-ingress",
      "question_id": 75493597,
      "title": "Nginx Ingress getting 504 gateway time-out",
      "problem": "I\u2019m quite new to k8s in general, only been using for smaller projects but made it work. I hope btw this is the right channel to ask questions (in this case about ingress-nginx). I\u2019m trying to setup a cluster with a gateway-api and a few microservices (all written in NestJs). To give a little background, I first had everything in docker-compose and my entry was also a Nginx container with letsencrypt. The whole docker, works great locally.\nThis was the config used for my NGinx Docker:\n```\n`upstream equmedia-api {\n    server equmedia-api:3000;\n}\n\nserver {\n    listen 80 default_server;\n    listen [::]:80 default_server;\n    server_name localhost;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 80;\n    listen 443 ssl http2 default_server;\n    listen [::]:443 ssl http2 default_server;\n    keepalive_timeout 70;\n    server_name subdomain.example.com;\n\n    ssl_session_cache shared:SSR:10m;\n    ssl_session_timeout 10m;\n    ssl_certificate /etc/letsencrypt/live/equmedia.pixeliner.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/equmedia.pixeliner.com/privkey.pem;\n\n    access_log /var/log/nginx/nginx.access.log;\n    error_log /var/log/nginx/nginx.error.log;\n\n    location / {\n        proxy_pass http://equmedia-api;\n        # proxy_redirect off;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n}\n`\n```\nAs you can see, it upstreamed to my api container.\nEventually I wanted to turn the whole deployment into k8s. Seemed like a good followup practice after the small projects.\nI learned about ingress-nginx and gave it my first try, but I seem to have struck a wall.\nHere is the setup I'm trying to achieve:\n\nThrough DigitalOcean the setup will be behind a LoadBalancer.\nHere is my Ingress NGinx controller:\n```\n`apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: equmedia-ingress-api\n  annotations:\n    kubernetes.io/ingress.class: \"nginx\"    \n    cert-manager.io/issuer: \"letsencrypt-prod\"\n    nginx.ingress.kubernetes.io/rewrite-target: \"/\"\n    nginx.ingress.kubernetes.io/proxy-protocol: \"true\"\n    nginx.ingress.kubernetes.io/ssl-proxy-headers: \"X-Forwarded-Proto: https\"\nspec:\n  tls:\n  - hosts:\n    - subdomain.example.com\n    secretName: quickstart-example-tls\n  rules:\n  - host: subdomain.example.com\n    http:\n      paths:\n      - path: /api\n        pathType: Prefix\n        backend:\n          service:\n            name: equmedia-api\n            port:\n              number: 3000\n\n`\n```\nAnd my api service:\n```\n`apiVersion: v1\nkind: Service\nmetadata:\n  annotations:\n    kompose.cmd: kompose convert\n    kompose.version: 1.22.0 (955b78124)\n  creationTimestamp: null\n  labels:\n    io.kompose.service: equmedia-api\n  name: equmedia-api\nspec:\n  ports:\n    - port: 3000\n      targetPort: 3000\n  selector:\n    io.kompose.service: equmedia-api\nstatus:\n  loadBalancer: {}\n\n`\n```\nWhen I try to access \"https://subdomain.example.com/api/health\", I get a 504 Gateway Time-out. Looking at the ingress controller logs I get the following:\n```\n`2023/02/17 15:51:44 [error] 356#356: *336457 upstream timed out (110: Operation timed out) while connecting to upstream, client: 164.92.221.107, server: subdomain.example.com, request: \"GET /api/health HTTP/2.0\", upstream: \"http://10.244.0.228:3000/\", host: \"subdomain.example.com\"\n2023/02/17 15:51:49 [error] 356#356: *336457 upstream timed out (110: Operation timed out) while connecting to upstream, client: 164.92.221.107, server: subdomain.example.com, request: \"GET /api/health HTTP/2.0\", upstream: \"http://10.244.0.228:3000/\", host: \"subdomain.example.com\"\n2023/02/17 15:51:54 [error] 356#356: *336457 upstream timed out (110: Operation timed out) while connecting to upstream, client: 164.92.221.107, server: subdomain.example.com, request: \"GET /api/health HTTP/2.0\", upstream: \"http://10.244.0.228:3000/\", host: \"subdomain.example.com\"\n`\n```\nAnyone that can point me into the right direction, to fix this issue?\nEDIT\nThe outcome for\n`kubectl get pods -l io.kompose.service=equmedia-api`:\n```\n`NAME           READY   STATUS    RESTARTS   AGE\nequmedia-api   1/1     Running   0          2d2h\n`\n```\n`kubectl get svc`:\n```\n`NAME                                            TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)                      AGE\nequmedia-api                                    ClusterIP      10.245.173.11               3000/TCP                     23h\nequmedia-api-rabbitmq                           ClusterIP      10.245.17.225               5672/TCP,15673/TCP           2d17h\nequmedia-api-redis                              ClusterIP      10.245.120.11               6379/TCP                     2d17h\nequmedia-auth-db                                ClusterIP      10.245.94.21                5432/TCP                     2d17h\nkubernetes                                      ClusterIP      10.245.0.1                  443/TCP                      2d17h\nquickstart-ingress-nginx-controller             LoadBalancer   10.245.36.216   179.128.139.106   80:31194/TCP,443:31609/TCP   2d16h\nquickstart-ingress-nginx-controller-admission   ClusterIP      10.245.232.77               443/TCP                      2d16h\n`\n```\nEDIT2:\nI've requested my domain https://subdomain.example.com/api/health through browser, curl and postman. All of them return timeouts.\n`kubectl get pods -A -o wide | grep 10.244.0.228 ` returns:\n```\n`default        equmedia-api                                           1/1     Running   0               2d4h    10.244.0.228   temp-pool-qyhii              \n`\n```\n`kubectl get svc -A | grep 10.244.0.228` returns nothing\nEDIT3:\nHere is the logs of my API:\n```\n`[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [NestFactory] Starting Nest application...\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] AppModule dependencies initialized +136ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] RedisCacheModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] UtilsModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] AxiosWrapperModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] PassportModule dependencies initialized +32ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] JwtModule dependencies initialized +3ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] ConfigHostModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] TerminusModule dependencies initialized +2ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] DiscoveryModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] ConfigModule dependencies initialized +2ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] ConfigModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] BullModule dependencies initialized +0ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] ScheduleModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] BullModule dependencies initialized +61ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] ClientsModule dependencies initialized +17ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] ClientsModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] ClientsModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] ClientsModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] ClientsModule dependencies initialized +7ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] ClientsModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] HealthModule dependencies initialized +8ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] CacheModule dependencies initialized +2ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] MailModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] HttpModule dependencies initialized +3ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] BullModule dependencies initialized +24ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] BullQueueModule dependencies initialized +7ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] PaymentModule dependencies initialized +8ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] CustomerModule dependencies initialized +1ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] ContentModule dependencies initialized +2ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] AdserveModule dependencies initialized +3ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] AuthModule dependencies initialized +2ms\n[Nest] 1  - 02/17/2023, 10:52:27 AM     LOG [InstanceLoader] OpenIdModule dependencies initialized +65ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] HealthController {/api/health}: +18ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/health, GET} route +5ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/health/check-ping, GET} route +2ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/health/check-disk, GET} route +2ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/health/check-memory, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/health/check-microservice/:name, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] OpenIdController {/api/open-id}: +0ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/open-id/login, GET} route +2ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/open-id/user, GET} route +2ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/open-id/callback, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/open-id/logout, GET} route +2ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] AuthController {/api/auth}: +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/auth, GET} route +2ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/auth/signup, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/auth/signin, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/auth/signout, POST} route +2ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/auth/refresh, GET} route +0ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] UserController {/api/user}: +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/user/get-user-id/email?, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/user/get-authenticated-user, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/user/:id/change-user-password, PUT} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/user/:id/delete-user-account, DELETE} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/user/confirm/:token, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/user/forgot-password, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/user/set-new-password/:token, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] UsersController {/api/users}: +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/users, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] PaymentController {/api/payment}: +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/payment/:id, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/payment/create/:id, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/payment/:id, PUT} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] CustomerController {/api/customer}: +0ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/customer, GET} route +0ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/customer/profile/:id, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/customer/create, POST} route +2ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/customer/delete/:id, DELETE} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/customer/update/:id, PUT} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] ContentController {/api/content}: +0ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/content, GET} route +2ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/content/create, POST} route +0ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/content/update/:contentId, PUT} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/content/delete/:contentId, DELETE} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/content/category/:categoryId, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/content/slug/:slug, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] CategoryController {/api/category}: +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/category, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/category/create, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/category/update/:categoryId, PUT} route +0ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/category/delete/:categoryId, DELETE} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] WidgetController {/api/widget}: +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/widget, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/widget/create, POST} route +0ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/widget/update/:widgetId, PUT} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/widget/delete/:widgetId, DELETE} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] AdvertiserController {/api/adserve/advertiser}: +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/advertiser, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/advertiser/:advertiserId, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/advertiser/create, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/advertiser/:advertiserId/campaigns/create, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/advertiser/:advertiserId/campaigns/:campaignId, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/advertiser/:advertiserId/campaigns/:campaignId/create, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/advertiser/:advertiserId/campaigns/:campaignId/assign, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] AdserveController {/api/adserve}: +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/serve, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/redirect, GET} route +0ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] PublisherController {/api/adserve}: +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/publisher, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/publisher/:publisherId, GET} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/publisher/create, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/publisher/:publisherId/zone/create, POST} route +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RoutesResolver] ReportController {/api/adserve/report}: +1ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [RouterExplorer] Mapped {/api/adserve/report, GET} route +0ms\n[Nest] 1  - 02/17/2023, 10:52:28 AM     LOG [NestApplication] Nest application successfully started +58ms\n-- API GATEWAY RUNNING - PORT: 3000  --\n`\n```\nNo errors are logged, and through a port-forward I also see my api working.\nEDIT4:\nHere is the gist with all pods/services/claims/...\nhttps://gist.github.com/pixeliner/2c89048294197155b0d4833ab4045f3c",
      "solution": "Your output text:\n```\n`2023/02/17 15:51:44 [error] 356#356: *336457 upstream timed out (110: Operation timed out) while connecting to upstream, client: 164.92.221.107, server: subdomain.example.com, request: \"GET /api/health HTTP/2.0\", upstream: \"http://10.244.0.228:3000/\", host: \"subdomain.example.com\"\n2023/02/17 15:51:49 [error] 356#356: *336457 upstream timed out (110: Operation timed out) while connecting to upstream, client: 164.92.221.107, server: subdomain.example.com, request: \"GET /api/health HTTP/2.0\", upstream: \"http://10.244.0.228:3000/\", host: \"subdomain.example.com\"\n2023/02/17 15:51:54 [error] 356#356: *336457 upstream timed out (110: Operation timed out) while connecting to upstream, client: 164.92.221.107, server: subdomain.example.com, request: \"GET /api/health HTTP/2.0\", upstream: \"http://10.244.0.228:3000/\", host: \"subdomain.example.com\"\n`\n```\nImplies the request is timing out on the IP `10.244.0.228:3000`\nThings to check:\n\nIs the service IP `10.244.0.228`: `kubectl get svc equmedia-api` (it will likely be of type `ClusterIP`)\n\nPort forward to the service directly: `kubectl port-forward svc/equmedia-api 3000:3000` and then try to access `localhost:3000` in another terminal or in your browser. Does it respond, does it error or does it timeout?\n\nCheck the pods your service is trying to match: `kubectl get pods -l io.kompose.service=equmedia-api` -- does this return any pods? If so, are they in `Ready` state or are they erroring? Do they have a value greater than 0 in the `Restarts` count?\n\nCheck the logs of the pod(s) `kubectl logs -f {pod-name}` and see if it is unable to start up, or if it is repeatedly starting.\n\nUPDATE 1\nPlease add the output of the following commands to your question. Wrap the output with three backticks (`) on a single line before and after to preserve formatting:\n```\n`kubectl get pods -l io.kompose.service=equmedia-api\n`\n```\n```\n`kubectl get svc\n`\n```\n\nUPDATE 2\nSince the IP that your controller is `10.244.0.228` see if any of your pods or services actually have that IP. Please add the output of these commands:\n```\n`kubectl get pods -A -o wide | grep 10.244.0.228\n`\n```\n```\n`kubectl get svc -A | grep 10.244.0.228\n`\n```\n\nUPDATE 3\nI've yet to try deploying the gist, but I have noticed something\nYou have networkpolicies setup and you have labelled your pod\n```\n`apiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    kompose.cmd: kompose convert\n    kompose.version: 1.22.0 (955b78124)\n  creationTimestamp: null\n  labels:\n    io.kompose.network/backend: \"true\" # This matches your network policy here:\n```\n`apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  creationTimestamp: null\n  name: backend\nspec:\n  ingress:\n    - from:\n      - podSelector:\n          matchLabels:\n            io.kompose.network/backend: \"true\"\n  podSelector:\n    matchLabels:\n      io.kompose.network/backend: \"true\"\n`\n```\nNow, this network policy reads (based in the information off this link)\n\"Allow connections from Pods with the label `io.kompose.network/backend=\"true\"` (last three lines) to pods that match the labels `io.kompose.network/backend=\"true\"` (the `ingress.from.podSelector` bit)\nSooo.... assuming I'm reading this correct, the reason the ingress controller is not able to talk to the pod, is because the controller pod does not have a label `io.kompose.network/backend=\"true\"`, and since you did not include that in your gist, I'm assuming you're using the ingress controller chart as a subchart/dependency. And if so, then out of the box, that chart won't have this label. This would explain why we were able to port-forward to the pod and the service directly, but the controller pod was not able to talk to the pod.\nAnd easy way to verify this is to either delete the `backend` networkpolicy, or modify it to allow all ingress traffic as a test (something like the example here)\nIf this works, it will confirm the networkpolicy is blocking the traffic.",
      "question_score": 1,
      "answer_score": 4,
      "created_at": "2023-02-18T14:18:19",
      "url": "https://stackoverflow.com/questions/75493597/nginx-ingress-getting-504-gateway-time-out"
    }
  ]
}